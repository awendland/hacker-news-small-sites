<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 06 Jan 2021 08:51:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 06 Jan 2021 08:51:56 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Embeddable Markdown note-cards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629919">thread link</a>) | @tobeagram
<br/>
January 4, 2021 | https://supernotes.app/blog/posts/embed-your-knowledge/ | <a href="https://web.archive.org/web/*/https://supernotes.app/blog/posts/embed-your-knowledge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><h2>Updates</h2><h3>Tuesday, 22nd December 2020</h3></p><div><div><p>Today we are releasing <a href="https://supernotes.app/changelog">Supernotes 1.7</a>, which introduces embeddable note-cards to Supernotes. Like tweets, our note-cards can be embedded anywhere on the web, from Notion documents to your personal blog. But unlike tweets, our note-cards have extended markdown support and no character limit (although we recommend keeping below 1200), giving you a lot greater flexibility. </p>
<p>It's super easy to create an embeddable note-card, just create a share code and copy the embed from within the share dropdown. Here's a quick walkthrough below:</p>
<p><img alt="How to create an embeddable share code on Supenrotes" src="https://d33wubrfki0l68.cloudfront.net/e0375139aef29ba1fbb28cc7b584b3958be6f2e3/c9b64/faf17916af9b689168b6a5392b6241e1/embedcodetutorial.gif"></p><h5>Open the share dropdown and then click "Create new code". Make sure 'Publicly Viewable' is turned on and then 'Generate Code'. Finally hit the 'Embed' button to copy the embed code.</h5>
<p>Here are our favourite use cases for embeddable note-cards:</p>
<h2>Reusable Checklists</h2>
<p>Embed interactive checklists; for example read the card below and check the list as you go along. You can refresh the page to return to the card to it's original state. Or if you are the author of the card, log in to Supernotes to make permanent changes!</p>

<h2>Highlight Code Snippets</h2>
<p>Make use of Supernotes' code syntax highlighting feature, and quickly share blocks of code with friends. Like this introduction to <code>if</code> statements on Python below:</p>

<h2>Interactive Study Cards</h2>
<p>Create interactive elements such as using spoilers to hide important information –&nbsp;a great revision technique. Here's a brief card on one of our favourite thinkers from the 20th century. Let's see if you can guess the hidden elements correctly!</p>

<p>Overall 2020 been a great year for us, and Connor and I are very proud of how far Supernotes has come - especially with our awesome community. Keep up to date with our development journey over on Twitter (<a href="https://twitter.com/acnebs" target="_blank" rel="nofollow noopener noreferrer">@acnebs</a>, <a href="https://twitter.com/tobiaswhetton" target="_blank" rel="nofollow noopener noreferrer">@tobiaswhetton</a>). And please share your favourite uses of embeddable note-cards with us –&nbsp;we'd love to see them! </p></div></div></div></div></div></div>]]>
            </description>
            <link>https://supernotes.app/blog/posts/embed-your-knowledge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629919</guid>
            <pubDate>Mon, 04 Jan 2021 11:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Smell 52 – Fragile Tests]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629900">thread link</a>) | @mcsee
<br/>
January 4, 2021 | https://maximilianocontieri.com/code-smell-52-fragile-tests | <a href="https://web.archive.org/web/*/https://maximilianocontieri.com/code-smell-52-fragile-tests">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><em>Tests are our safety nets. If we don't trust on their integrity we will be in great danger.</em></p>

<ul>
<li><p>Determinism</p>
</li>
<li><p>Confidence loss</p>
</li>
<li><p>Wasted time</p>
</li>
</ul>

<ol>
<li><p>Test should be in full control. There should be no space for erratic behavior and degrees of freedom.</p>
</li>
<li><p>Remove all tests coupling.</p>
</li>
</ol>



<ul>
<li>Fragile, Intermittent, Sporadic or Erratic tests are common in many organizations. </li>
</ul>
<p>Nevertheless, they mine the developers trust. </p>
<p>We must avoid them.</p>

<h2 id="wrong">Wrong</h2>
<h2 id="right">Right</h2>

<p>Detection can be done with test run statistics. </p>
<p>It is very hard to put some test in maintenance since we are removing a safety net.</p>



<ul>
<li><p>Coupling</p>
</li>
<li><p>Determinism</p>
</li>
</ul>

<p>Fragile tests show system coupling and not deterministic or erratic behavior.</p>
<p>Developers spend lots of time and effort fighting against this false positives.</p>

<p>Photo by <a href="https://unsplash.com/@jilburr">Jilbert Ebrahimi</a> on <a href="https://unsplash.com/s/photos/glass-broken">Unsplash</a></p>
<hr>
<blockquote>
<p>The amateur software engineer is always in search of magic. </p>
</blockquote>
<p><em>Grady Booch</em></p>

<hr>
<p>This article is part of the CodeSmell Series.</p>

</div></div>]]>
            </description>
            <link>https://maximilianocontieri.com/code-smell-52-fragile-tests</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629900</guid>
            <pubDate>Mon, 04 Jan 2021 11:17:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe, Unicorns and Global Tech Diffusion – The End of the American Internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629837">thread link</a>) | @warrior-worrier
<br/>
January 4, 2021 | https://www.mosaicventures.com/patterns/europe-unicorns-and-global-tech-diffusion-the-end-of-the-american-internet | <a href="https://web.archive.org/web/*/https://www.mosaicventures.com/patterns/europe-unicorns-and-global-tech-diffusion-the-end-of-the-american-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍</p><div><p>Silicon Valley was the global cluster for computing, for software and for the consumer internet, and even a decade ago two thirds of all tech venture investing happened in the USA. Europe seemed to punch below its weight, despite a bigger population and a huge single market, some great computer science schools and plenty of entrepreneurs. Maybe Europe just couldn't do tech? </p><p>In truth, that was always something of a misconception. There has always been great and important tech coming out of Europe - Apple’s ARM (Cambridge) chips are made with equipment from ASML (The Netherlands). But Europe is a harder place to build a giant company. It’s many markets, not one, with different consumer behaviour, retail landscapes and competitive dynamics. Instacart can reach more consumers in New York and LA than the top ten markets combined in any European country. Americans are far more mobile (2% of Americans move state each year and 0.2% of Europeans move country), making it easier for them to concentrate in the Silicon Valley cluster, while the European ecosystem is more diffuse. And the UK is ahead of the US on most consumer tech adoption metrics, but less than 40% of Italians made any online purchase in 2019, and the French, Germans and Spanish spend half as much time online as the British. Europe is harder! </p><p>A lot of that is changing. Something over 120 ‘unicorns’ have emerged in Europe in the last decade, the top startup events have tens of thousands of eager attendees, and early stage venture investing is up 4x since 2010 and now within 15% of California levels. The virtuous cycle of startup creation is being put together &nbsp;piece by piece. Some of this is in the areas people talk of as a ‘European advantage’ - fintech, bio and frontier tech - but in fact European tech is now much more widely spread. Most of the unicorns aren’t actually in those ’special pleading’ segments, nor the investing, and at a high level the unicorn story has broadened out massively, from a handful of consumer ‘names' a decade ago to an even spread of big and important consumer and enterprise software companies. </p><p>Indeed, the real story is the generalisation and globalisation of tech company creation. When Apple launched the first Mac back in 1984, less than 7m PCs of every kind were sold that year on the entire planet. Computers have always been interesting and exciting, but they weren’t an important part of many people’s lives, and they were a small business, mostly clustered outside a small city in northern California. But today over 4bn people have a smartphone and there is more ecommerce in China than the US and Europe combined. Anyone will do anything online, and a whole wave of companies is being created to take advantage of that, even, yes, in Europe.</p></div><p>‍</p></div></div>]]>
            </description>
            <link>https://www.mosaicventures.com/patterns/europe-unicorns-and-global-tech-diffusion-the-end-of-the-american-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629837</guid>
            <pubDate>Mon, 04 Jan 2021 11:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China: The Disappearing Millionaires]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629774">thread link</a>) | @aminozuur
<br/>
January 4, 2021 | https://www.arte.tv/en/videos/083456-000-A/china-the-disappearing-millionaires/ | <a href="https://web.archive.org/web/*/https://www.arte.tv/en/videos/083456-000-A/china-the-disappearing-millionaires/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div role="region" aria-label="program.videoplayer" id="video_player" tabindex="-1"><div><div><div></div></div></div></div><div><div><div><p><label for="autoplay-hide-for-large"><span>Autoplay</span><span></span></label></p><p><h2>Up next</h2></p></div><div><div><a href="https://www.arte.tv/en/videos/073399-005-A/re-the-bride-market-in-bulgaria/"><div></div><div><h3>Re: The Bride Market in Bulgaria</h3><p>31 min</p></div></a></div></div></div></div></section><section><div><p>25 min</p><p>Available from 12/11/2019 to 28/05/2022</p></div></section><section><div><p>China's self-made millionaires and billionaires were a major part of the country's success story. But now, they may have fallen out of favour with the CPP. One by one, they go missing, or commit 'suicide.' One billionaire who fled to the US is ringing the alarm.&nbsp;</p></div></section><div><section></section><div><section><br><div><ul><li><div><div><p>Director</p><!-- --><p> :</p></div></div><ul><p><li>Sébastien Le Belzic</li></p></ul></li><li><div><div><p>Producer</p><!-- --><p> :</p></div></div><ul><p><li>Anthony Dufour</li></p></ul></li></ul><ul><li><div><div><p>Author</p><!-- --><p> :</p></div></div><ul><p><li>Sébastien Le Belzic</li></p></ul></li><li><div><div><p>Country</p><!-- --><p> :</p></div></div><ul><p><li>France</li></p></ul></li><li><div><div><p>Year</p><!-- --><p> :</p></div></div><ul><p><li>2019</li></p></ul></li></ul></div></section></div></div></div></div>]]>
            </description>
            <link>https://www.arte.tv/en/videos/083456-000-A/china-the-disappearing-millionaires/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629774</guid>
            <pubDate>Mon, 04 Jan 2021 10:59:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Public APIs to Improve Productivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629676">thread link</a>) | @olanetsoft
<br/>
January 4, 2021 | https://blog.idrisolubisi.com/35-free-public-apis-to-improve-productivity | <a href="https://web.archive.org/web/*/https://blog.idrisolubisi.com/35-free-public-apis-to-improve-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Hi guys! I will be sharing amazing free public API resources that can aid development and I'm pretty sure you gonna love it!</p>
<h3 id="face-api-jshttpsgithubcomjustadudewhohacksface-apijs"><a target="_blank" href="https://github.com/justadudewhohacks/face-api.js">Face API JS</a></h3>
<p>JavaScript API for face detection and face recognition in the browser and Nodejs with tensorflow.js. Using this API, you can predict the age, color, and probable accuracy ratio. Demo projects are placed inside the link.</p>
<h3 id="zoom-video-callhttpsmarketplacezoomusdocsapi-referencezoom-api"><a target="_blank" href="https://marketplace.zoom.us/docs/api-reference/zoom-api">Zoom Video Call</a></h3>
<p>The Zoom API is the primary means for developers to access a collection of resources from Zoom. The Zoom API allows developers to safely and securely access information from Zoom. You can use this API to build private services or public applications on the Zoom App Marketplace. To learn how to get your credentials and create private/public applications, read our Authorization Guide. All endpoints are available via HTTPS and are located at <a href="http://api.zoom.us/v2/" target="_blank">api.zoom.us/v2</a>.</p>
<h3 id="human-apihttpsrapidapicomhumanapiapihumanendpoints"><a target="_blank" href="https://rapidapi.com/humanapi/api/human/endpoints">Human API</a></h3>
<p>human API is a platform that makes human health data available through a RESTful web service. We make it very easy to securely get a human's current or past health data. The API offers accessing data of types; Blood Pressure, Heart Rate, Sleep, Body Fat, Genetics, BMI, Activity, Height, Blood Glucose, Profile, Weight, Location.</p>
<h3 id="instagram-feed-apihttpsinstafeedapicom"><a target="_blank" href="https://instafeedapi.com/">Instagram Feed API</a></h3>
<p>A simple &amp; easy way to access your Instagram feed with REST API without code. If you are looking to add your Instagram feed to your website then this is so easy. If you don't want to do backend to access your Instagram data.</p>
<h3 id="thesportsdbhttpswwwthesportsdbcomapiphp"><a target="_blank" href="https://www.thesportsdb.com/api.php">TheSportsDB</a></h3>
<p>Crowd-Sourced Sports Data and Artwork. An open, crowd-sourced database of sports artwork and metadata with a free API. The content here is only possible thanks to the hard work of our users.</p>
<h3 id="programming-quotes-apihttpsgithubcomskolakodaprogramming-quotes-api"><a target="_blank" href="https://github.com/skolakoda/programming-quotes-api">Programming Quotes API</a></h3>
<p>Programming Quotes API for open source projects. You need these quotes to push your self and other developers to stay motivated to their screens. Famous developers, authors, and entrepreneurs have been added to provide a nicely curated list of quotes. You can call all quotes at one time or you can find out quotes about a specific author. Feel free to use and share with your friends.</p>
<h3 id="stripe-apihttpsstripecomdocsapi"><a target="_blank" href="https://stripe.com/docs/api">Stripe API</a></h3>
<p>Online payment processing for internet businesses. Stripe is a suite of payment APIs that powers commerce for online businesses of all sizes.</p>
<h3 id="twilio-apihttpswwwtwiliocomdocsapi"><a target="_blank" href="https://www.twilio.com/docs/api">Twilio API</a></h3>
<p>The Twilio Messaging API makes it easy to send and receive SMS and MMS messages as well as query meta-data about text messages such as delivery status, associated media, and leverage tools like Copilot to manage your messages globally at scale.</p>
<h3 id="open-library-apihttpsopenlibraryorgdevelopersapi"><a target="_blank" href="https://openlibrary.org/developers/api">Open Library API</a></h3>
<p>Open Library has a RESTful API, best used to link into Open Library data in JSON, YAML, and RDF/XML. Open Library has developed a suite of APIs to help developers get up and running with our data. We encourage interested developers to join the old-tech mailing list to stay up-to-date with the latest news or dive in with our own development team at our bug tracker or our GitHub source code repository.</p>
<h3 id="ui-faceshttpsuifacescoapi-docs"><a target="_blank" href="https://uifaces.co/api-docs">UI Faces</a></h3>
<p>Dummy avatar photos and names provided in filterable JSON format. We offer a JSON API that you can use to filter and embed avatars in your application.</p>
<h3 id="joke-apihttpssv443netjokeapiv2"><a target="_blank" href="https://sv443.net/jokeapi/v2/">Joke API</a></h3>
<p>JokeAPI is a RESTful API that serves uniformly and well-formatted jokes.</p>
<h3 id="giphyhttpsdevelopersgiphycomdocs"><a target="_blank" href="https://developers.giphy.com/docs/">Giphy</a></h3>
<p>Get all your gifs. By integrating with GIPHY, the first and largest GIF search engine, you gain free access to our ever-growing content library of GIFs and Stickers, plus brand new features like animated Emoji and Text — featuring the latest in entertainment, sports, and breaking news from GIPHY's official content partners. The fastest and easiest way to bring the full GIPHY experience directly to your app is with GIPHY SDK. Built with developers and product designers in mind, GIPHY SDK is a top-to-bottom solution for all things GIF in your app. This includes interfacing with GIPHY API, fetching and caching assets, and displaying GIFs and Stickers on-screen in customizable UI templates. With billions of requests a day, it’s safe to say GIPHY knows GIFs. We're excited to share our best-in-class tools with you so your users can have the best GIF experience possible, with all the same features they're already enjoying on Facebook, Slack, Instagram, and more – with just a few lines of code.</p>
<h3 id="ip-geolocation-apihttpsipwhoisio"><a target="_blank" href="https://ipwhois.io/">IP Geolocation API</a></h3>
<p>Free IP Geolocation and IP Address Lookup Location API.</p>
<h3 id="facebook-marketing-apihttpsdevelopersfacebookcomdocsmarketing-apis"><a target="_blank" href="https://developers.facebook.com/docs/marketing-apis">Facebook Marketing API</a></h3>
<p>Manage ads and campaigns using the Facebook API. Marketing APIs are a collection of Graph API endpoints that can be used to help you advertise on Facebook. To get started with advertising on Facebook, we recommend you learn about Facebook's Ad Campaign Structure, to understand the objects you are working with and how they relate to each other. The Marketing API is an HTTP-based API that you can use to programmatically query data, create and manage ads, and perform a wide variety of other tasks.</p>
<h3 id="graphql-jobshttpsapigraphqljobs"><a target="_blank" href="https://api.graphql.jobs/">GraphQL Jobs</a></h3>
<p>Jobs with GraphQL. This API lets you retrieve information in GraphQL query format related to jobs offered by GraphQL. You can sort the data, find remote jobs, and update existing data.</p>
<h3 id="news-apihttpsnewsapiorg"><a target="_blank" href="https://newsapi.org/">News API</a></h3>
<p>Get breaking news headlines, and search for articles from over 30,000 news sources and blogs with our news API. Freaking fast because everything is asynchronously cached for a super-fast response. Free for development and easy integration.</p>
<h3 id="zoom-video-callhttpsfirebasegooglecomdocsml-kitdetect-faces"><a target="_blank" href="https://firebase.google.com/docs/ml-kit/detect-faces">Zoom Video Call</a></h3>
<p>With ML Kit's face detection API, you can detect faces in an image, identify key facial features, and get the contours of detected faces. With face detection, you can get the information you need to perform tasks like embellishing selfies and portraits or generating avatars from a user's photo. Because ML Kit can perform face detection in real-time, you can use it in applications like video chat or games that respond to the player's expressions.</p>
<h3 id="email-verifierhttpsverifiermeetchopracom"><a target="_blank" href="https://verifier.meetchopra.com/">Email Verifier</a></h3>
<p>Free API to weed out disposable, non-existent, or invalid emails without any limits.</p>
<h3 id="audiomackhttpswwwaudiomackcomdata-apidocs"><a target="_blank" href="https://www.audiomack.com/data-api/docs">Audiomack</a></h3>
<p>Audiomack Is a Streaming Music Hub for Artists and Fans. Search for artists, songs, and albums. Take control of what you get back by filtering data with music fields, favorites, artists, title, and id.</p>
<h3 id="spotifyhttpsbetadeveloperspotifycomdocumentationweb-api"><a target="_blank" href="https://beta.developer.spotify.com/documentation/web-api/">Spotify</a></h3>
<p>Fetch data from the Spotify music catalog, manage users' playlists and saved music, get recommendations, control Spotify Connect, and more. Based on simple REST principles, the Spotify Web API endpoints return JSON metadata about music artists, albums, and tracks, directly from the Spotify Data Catalogue.</p>
<h3 id="commercejshttpscommercejscom"><a target="_blank" href="https://commercejs.com/">Commerce.js</a></h3>
<p>eCommerce API w/ support for preorders and subscriptions. API-first eCommerce platform for developers &amp; designers Rapidly creates custom eCommerce experiences on web and mobile with our fully headless platform. Our eCommerce layer handles all the tedious logic for you.</p>
<h3 id="geojshttpswwwgeojsio"><a target="_blank" href="https://www.geojs.io/">GeoJS</a></h3>
<p>IP geolocation with ChatOps integration.</p>
<h3 id="upworkhttpsdevelopersupworkcom"><a target="_blank" href="https://developers.upwork.com/">Upwork</a></h3>
<p>Freelance job board and management system. Upwork Developers Site offers you access to our web services to build your own applications and to integrate our features and workflow to your dashboards, websites, and management systems. Please read the Terms of use prior to using the Upwork Public API. This API lets you create Job Postings, manage existing contracts, make custom payments, close contracts, manage activities for your team, manage/send/receive messages, retrieve time and financial reports, manage work diary, and retrieve metadata information related to available categories/tests/skills and regions.</p>
<h3 id="the-open-movie-databasehttpwwwomdbapicom"><a target="_blank" href="http://www.omdbapi.com/">The Open Movie Database</a></h3>
<p>The OMDb API is a RESTful web service to obtain movie information, all content and images on the site are contributed and maintained by our users. This API allows you to search a title by its name, year, plot and returns a response in either JSON or XML.</p>
<h3 id="postmanhttpswwwpostmancompostmanworkspacepostman-public-workspacecollection12959542-c8142d51-e97c-46b6-bd77-52bb66712c9actxdocumentation"><a target="_blank" href="https://www.postman.com/postman/workspace/postman-public-workspace/collection/12959542-c8142d51-e97c-46b6-bd77-52bb66712c9a?ctx=documentation/">Postman</a></h3>
<p>The Postman API allows you to programmatically access data stored in the Postman account with ease.</p>
<h3 id="fakejsonhttpsfakejsoncom"><a target="_blank" href="https://fakejson.com/">FakeJSON</a></h3>
<p>Fake it till you make it Mock backend API for lightspeed development. Zero installations fakeJSON is ready to use out of the box. Our API endpoint is always online and ready to serve as your application’s mock backend. No database schema or engine to choose from, no npm package to install, no dependencies to check for. Unlimited response possibilities Get the exact backend response you need with more than 100 different fields. If it doesn’t exist, you can even make your own field. No configuration There is no need to configure routes with API requests made to the FakeJSON API endpoint. Just configure the response directly in the JSON request payload. Fast "get to work" time You can get a fully working application in seconds. No deployment requirements to use any of fakeJSON powerful features. Simple to use There is no need to learn a new tool, language, or protocol. What you enter as a payload is what you get. It’s that simple. Consistently fast responses Blazing fast, the fakeJSON API is tuned for speed. Whether it’s 50 or 50,000 units returned, your mock backend will be the least of your concerns.</p>
<h3 id="the-cat-apihttpsdocsthecatapicom"><a target="_blank" href="https://docs.thecatapi.com/">The Cat API</a></h3>
<p>Pictures of cats from Tumblr</p>
<h3 id="text-recognitionhttpsfirebasegooglecomdocsml-kitrecognize-text"><a target="_blank" href="https://firebase.google.com/docs/ml-kit/recognize-text">Text Recognition</a></h3>
<p>With ML Kit's text recognition APIs, you can recognize text in any Latin-based language. Text Recognition can automate tedious data entry for credit cards, receipts, and business cards. With the Cloud-based API, you can also extract text from pictures of documents, which you can use to increase accessibility or translate documents. Apps can even keep track of real-world objects, such as by reading the numbers on trains.</p>
<h3 id="gitlabhttpsdocsgitlabcomeeapi"><a target="_blank" href="https://docs.gitlab.com/ee/api/">Gitlab</a></h3>
<p>Automate GitLab via a simple and powerful API</p>
<h3 id="scraperapihttpswwwscraperapicom"><a target="_blank" href="https://www.scraperapi.com/">ScraperApi</a></h3>
<p>Scraper API handles proxies, browsers, and CAPTCHAs, so you can get the HTML from any web page with a simple API call.</p>
<h3 id="githubhttpsdocsgithubcomenfree-pro-teamlatestrest"><a target="_blank" href="https://docs.github.com/en/free-pro-team@latest/rest">Github</a></h3>
<p>This describes the resources that make up the official GitHub REST API v3. If you have any problems or requests.</p>
<h3 id="github-jobshttpsjobsgithubcomapi"><a target="_blank" href="https://jobs.github.com/api">Github Jobs</a></h3>
<p>Jobs for software developers. GitHub Jobs is a great place to attract the best technical talent for your company's open software development positions. The GitHub Jobs API allows you to search, and view jobs with JSON over HTTP. To get the JSON representation of any search result or job listing, append .json to the URL you'd use on the HTML GitHub Jobs site.</p>
<h3 id="wordsapihttpswwwwordsapicom"><a target="_blank" href="https://www.wordsapi.com/">WordsAPI</a></h3>
<p>Find definitions, related words, and more, with a simple to use RESTful API.</p>
<h3 id="digitalocean-services-apihttpsdevelopersdigitaloceancomdocumentationv2"><a target="_blank" href="https://developers.digitalocean.com/documentation/v2/">DigitalOcean Services API</a></h3>
<p>The DigitalOcean …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.idrisolubisi.com/35-free-public-apis-to-improve-productivity">https://blog.idrisolubisi.com/35-free-public-apis-to-improve-productivity</a></em></p>]]>
            </description>
            <link>https://blog.idrisolubisi.com/35-free-public-apis-to-improve-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629676</guid>
            <pubDate>Mon, 04 Jan 2021 10:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got offers from Amazon, Microsoft, and Bloomberg]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629634">thread link</a>) | @todsacerdoti
<br/>
January 4, 2021 | https://heylucas.net/how-i-got-offers-from-amazon-microsoft-and-bloomberg/ | <a href="https://web.archive.org/web/*/https://heylucas.net/how-i-got-offers-from-amazon-microsoft-and-bloomberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://heylucas.net/content/images/size/w300/2021/01/Thumbnail.png 300w,
                            https://heylucas.net/content/images/size/w600/2021/01/Thumbnail.png 600w,
                            https://heylucas.net/content/images/size/w1000/2021/01/Thumbnail.png 1000w,
                            https://heylucas.net/content/images/size/w2000/2021/01/Thumbnail.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://heylucas.net/content/images/size/w2000/2021/01/Thumbnail.png" alt="How I got offers from Amazon, Microsoft, and Bloomberg">
            </figure>

            <section>
                <div>
                    <p><em>This post is an excerpt of my YouTube video by the same name. You can watch it now:</em></p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/pj57nB1CKHU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="intro">Intro</h2><p>Last year I decided it was time to switch jobs. Interviewing is always a hassle, so I decided to keep track of what worked for me. I'm sharing this in the hopes someone else might benefit from what I've learned.</p><h2 id="how-i-prepared-for-the-phone-screens">How I prepared for the phone screens</h2><p>I kept it simple: LeetCode for practice problems. I didn't aim for an arbitrary number of questions to "be ready".</p><p>Practiced each day for a few hours and used space repetition. I'd cover multiple topics each session. That prevented things from getting too boring.</p><h2 id="how-i-prepared-for-the-onsite-interviews">How I prepared for the onsite interviews</h2><p>Since I had practiced a lot of coding for the phone screens, I put coding in the back-burner.</p><p>Instead, I focused on system design and behavioral questions.</p><p>For system design, <a href="https://www.educative.io/courses/grokking-the-system-design-interview">Grokking the System Design Interview</a> was pretty useful. To supplement that, &nbsp;I also watched YouTube videos to see how different people approached different problems.</p><hr><p>When it came to behavioral prep, I used <a href="https://apps.ankiweb.net/">Anki </a>flashcards. I went through all of Amazon's leadership principles, researched common behavioral questions, and created the cards with my answers. I also made sure to include any follow ups I could think of to my cards.</p><p>This definitely made me memorize my answers.</p><p>This might sound like cheating, but the truth is you're not gonna be able to come up with a story on the spot. You'll ramble. You'll forget details. You'll get confused. Interviewing is already stressful enough. Preparing the questions and answers beforehand will give you a leg up.</p><h2 id="why-i-did-all-of-my-interviews-in-a-single-week">Why I did all of my interviews in a single week</h2><p>Onsite interviews usually take 5 hours. Three onsites in a week totals 15 hours. I won't lie, it sucked. I was pretty exhausted after that week. But at the same time, it didn't suck.</p><p>Doing all the interviews at once gave me momentum and helped me perform well. It also helped me get it over quickly.</p><p>It also gave me a huge advantage: leverage. You see, when you tell companies you already have other onsites, they pay attention. You're suddenly in high demand. That makes them move faster and gives you more power to command a better offer.</p><p>This was the first time I scheduled my interviews like this and, trust me, it made a huge difference.</p><h2 id="that-s-all-folks">That's all folks</h2><p>If you've read this far, thank you! I hope this post was useful and showed you one path you can take to prepare for your interviews. </p><p>If you liked this post, have a look at my <a href="https://www.youtube.com/channel/UCbf0aCU8t_dQTaFf3WOavxg">YouTube channel</a>. I post videos every week, discussing tech, career, and productivity!</p><p>If you'd like to chat, hit me up on <a href="https://twitter.com/0800LUCAS">Twitter</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://heylucas.net/how-i-got-offers-from-amazon-microsoft-and-bloomberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629634</guid>
            <pubDate>Mon, 04 Jan 2021 10:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nothing Is New]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629458">thread link</a>) | @bilegeek
<br/>
January 4, 2021 | https://www.datagubbe.se/nothingnew/ | <a href="https://web.archive.org/web/*/https://www.datagubbe.se/nothingnew/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>
<b>On inventions, improvements and stagnation in the software world.</b>
</p>

<p><i>Early 2021</i></p>

<blockquote>
But 1983 - and the whole decade - came and went without the "new thing".
<br>
<i>-- Alan C. Kay in The Early History of Smalltalk</i>
</blockquote>

<p>
I freely admit it: I'm likely to be the first person to triumphantly 
yell "Exactly!" at any statement claiming that computers were
<a href="https://www.datagubbe.se/ltmag">better before</a>, and that everything is pretty much
<a href="https://www.datagubbe.se/decusab">crap today</a>. Frankly, I'm kind 
of a backwards person: at some point I started enjoying computers more 
because of their rich and interesting history, rather than the magical 
air of futuristic high-tech that first drew me to them.
</p>

<p>
Consequently, I thought I'd agree with a blog post titled 
<a href="https://alarmingdevelopment.org/?p=1475">"The Great Software Stagnation"</a> - written by Jonathan Edwards, 
a former research fellow at MIT, no less!
</p>

<p>
Alas, I did not.
</p>

<p>
For those too lazy to click on links, Edwards roughly states that before 
1996, lots of amazing "software technology" appeared, such as C++, 
Windows, Unix and WWW. Then the Internet boom happened and "programmers 
could get rich quick", which effectively stopped "progress" in the field 
and replaced it with "incremental improvements" that aren't 
"fundamentally new".
</p>

<p>
The problem with this reasoning, in my opinion, is twofold: Firstly, 
1996 is far too late a date to use as a cutoff. Secondly, almost 
anything in any field at any time can, upon close examination, be 
described as derivative of something that appeared earlier. (The 
wonderfully lifelike, masterfully stylistic and cleverly shaded 
paintings in the <a href="https://en.wikipedia.org/wiki/Chauvet_Cave">Chauvet Cave</a> comes to mind as an example 
within art.) This historical backtracking is especially 
applicable to sufficiently complex technology - <i>but that doesn't
necessarily mean something isn't inventive in its own right</i>.
</p>

<h3>Inventions and improvements</h3>

<p>
Who invented the automobile, for example? Without doubt it's a truly 
revolutionary creation, yet it's also mostly a joining together of 
already existing concepts. Nicolas-Joseph Cugnot constructed his steam 
powered "Fardier à vapeur" in 1769, but Ferdinand Verbiest is credited 
with thinking up the concept a hundred years earlier. Of course, Cugnot 
couldn't have built his vehicle without the invention and gradual 
refinement of steam power, with which experiments are recorded as early 
as during biblical times. And, besides - isn't a car really just an 
incremental improvement on the horse and carriage?
</p>

<p>
It wouldn't be controversial to say that the iPhone is a post-1996 
invention with considerable impact on a number of industries. On the 
software side of things, it introduced a new operating system with a new 
paradigm for interacting with a computational device. Of course, neither 
smartphones nor capacitive touchscreens were new in 2007 and Apple 
wasn't even <a href="https://en.wikipedia.org/wiki/LG_Prada">first with combining the two</a>. Thus, arguably, the iPhone was simply 
an incremental improvement on decades-old mobile phones -
and yet it was, of course, something  completely new. Anyone not
classifying it as a "radical  breakthrough" is surely rather alone in
that assessment.
</p>

<p>
Truly atomic and easily identifiable inventions are few, far between and 
often date back a very long time. They're also often discoveries as much 
as they are inventions. Some breakthroughs are old ideas that finally 
become reality thanks to other inventions. I'm pretty sure 
self-driving cars have been a childhood dream for many since at the very least 
Knight Rider in 1982 - and da Vinci's (non-working) concepts for flying 
machines from the late 1400:s have become iconic.
</p>

<h3>It's probably been done before</h3>

<p>
Edwards lists a number of pre-1996 technologies that, in the context of 
his text, can only be interpreted as what he considers to be major 
inventions or breakthroughs. On this point, I agree. I'm not writing 
this to discredit these inventions, or to belittle their inventors - I 
spend almost every day standing on the shoulders of these giants.
</p>

<p>
Most of what's mentioned in the list can however still be traced back to 
something similar that predates it. Lisp, for example, is a curiously 
elegant high level language considering it was invented in the 1950:s. 
The truth is of course that Lisp, despite featuring a lot of novel 
concepts, didn't appear in a vacuum. Its elegance derives heavily from 
mathematical notation and, later, lambda calculus. Other key concepts 
can be found in an earlier language called IPL (Garbage collection however,
is as far as I know, all Lisp).
</p>

<p>
The same can be said about Unix, which builds heavily on concepts in 
Multics, which in turn builds on earlier timesharing systems. Windows 
1.0 was pretty much crap compared to its chronological predecessor, 
Apple's Lisa OS. The story of the Lisa itself is no secret, either: 
Steve Jobs went to Xerox PARC in 1979, took a good look at the Alto and 
Smalltalk, and liked what he saw.
</p>

<p>
Xerox are often blamed for not understanding what they had and giving 
away their killer concept to Jobs, but that's not entirely true. They 
launched the Star in 1981, two years before the Lisa. It was the first 
commercial machine with a desktop metaphor. This was derived from the Smalltalk 
GUI, which was inspired by Douglas Engelbart's NLS (as featured in
<a href="https://en.wikipedia.org/wiki/The_Mother_of_All_Demos">The Mother of All Demos</a>),
which was inspired by <a href="https://en.wikipedia.org/wiki/Sketchpad">Sketchpad</a>. Smalltalk as a language 
builds in part on Simula, which introduced a lot of the concepts of 
modern object oriented programming. C++ is heavily influenced by Simula and,
of course, C.
</p>

<h3>Actual origins</h3>

<p>
This is where we can start identifying some kind of chronological 
tipping point. Simula, Lisp, Sketchpad and Engelbart's NLS - together 
with Algol, Fortran, Basic, artificial intelligence, 
multitasking/timesharing, networking, full screen text editors, 
relational databases and hypertext - all appear in a seemingly golden 
era between roughly 1955 and 1969.
</p>

<p>
This was the infancy of the digital general purpose computer. The ENIAC, 
being the first (although - of course - drawing heavily on earlier 
machines and research), was constructed in 1945. A decade later, the use 
of such machines had spread to comparably wider circles, which not only 
tickled the imaginations of some very fine visionary minds but also in a 
more hands-on sense called for simpler and quicker software development 
practices.
</p>

<h3>Post-1996 examples</h3>

<p>
The Internet boom irrefutably happened some time during the middle of 
the 1990s, so I agree that its effects began to clearly 
materialize in 1996. It's true that most of the makings of current 
software technology were already in place by then, but they too build on 
earlier inventions and improvements.
</p>

<p>
From his list of "new" things, Edwards omits CSS, 
XML (both from 1996), XMLHttpRequest (introduced in 2000) and JSON 
(conceived sometime shortly thereafter). This quartet forms the basis of 
the modern web and enabled things like single page applications. Of 
course one could quite correctly argue that these are simply incremental 
improvements upon earlier concepts, but that's also true of the web 
itself: Engelbart demonstrated clickable links in 1968, laying the foundation
for several following hypertext systems.
</p>

<p>
JavaScript hardly 
appeared out of thin air, either. It was influenced by a plethora of 
other languages and the concept of embedded scripting was already widely 
spread. Microsoft's VBA, for example, appeared two years earlier.
</p>

<p>
The combination of HTML, JavaScript and the DOM can be seen as a continuation
of PostScript, a Turing complete document formatting and presentation language.
</p>

<h3>Cashing in</h3>

<p>
The notion of programming as a get rich quick scheme was surely helped by 
the dotcom bubble, but seemingly unlikely 
overnight success in computing predates the Internet boom by more than a 
decade. I suggest that it's linked to the home computer revolution rather than 
the Eternal September. Bill Gates (no introduction needed), Ken Williams 
(Sierra On-Line), John Carmack (Doom) and Gary Kildall (CP/M) are all
examples of this, but there are many more success stories from this time.
The computer game Lemmings, for example, was released in 1991 and has since
sold a whopping 20 million copies.
</p>

<p>
I also think Edwards inadvertently stumbles into the trap of survivor 
bias. Just like with early home computer programmers, most web developers 
didn't - and still don't - get rich. For every success story there's also
a massive amount of failures - some of them so spectacular they've become
<a href="https://en.wikipedia.org/wiki/Boo.com">legends in 
their own right</a>.
</p>

<h3>Trickle down inventions</h3>

<p>
Claiming that we're still using a 50 year old OS with 30 year old text 
editors to write code in 25 year old languages can be tempting - but as 
I hope I've demonstrated above, the roots of almost all of those can be 
traced even further back and Edwards' choice of baseline technologies
can just as easily be dismissed as mere incremental improvements.
</p>

<p>
The fact that a contemporary programmer can get work done on a 30 or 
even 50 year old system doesn't mean they necessarily want to: there has 
been significant progress since then, albeit in - yes - increments.
</p>

<p>
Editor-wise, a programmer of today sent back to the early 1990:s would 
probably miss things like multi-language support and integration with
version control and linters. Even simple things like columnar marking, syntax 
highlighting and multiple document interfaces weren't standard editor 
features in 1990 - though the concepts were surely invented earlier. 
Python was released in 1991, but our time travelling coder is likely to 
be rather disappointed: list comprehension, while itself nothing new, 
wasn't introduced in the language until nine years later, in 2000.
</p>

<p>
In fact, most programmers probably didn't even use a multitasking 
operating system in 1990: Some improvements trickle down slower than 
others, in part because of hardware limitations, in part because of the 
curious whims of the software market. From a vantage point at MIT, it might 
seem as if little has changed during the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datagubbe.se/nothingnew/">https://www.datagubbe.se/nothingnew/</a></em></p>]]>
            </description>
            <link>https://www.datagubbe.se/nothingnew/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629458</guid>
            <pubDate>Mon, 04 Jan 2021 10:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPS Showdown DigitalOcean vs. Lightsail vs. Linode vs. UpCloud vs. Vultr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629384">thread link</a>) | @sharjeelsayed
<br/>
January 4, 2021 | https://joshtronic.com/2021/01/03/vps-showdown-digitalocean-lightsail-linode-upcloud-vultr/ | <a href="https://web.archive.org/web/*/https://joshtronic.com/2021/01/03/vps-showdown-digitalocean-lightsail-linode-upcloud-vultr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>New year, new VPS Showdown!</p>
<p>While I don’t usually make big changes to these posts month to month, I do try
to refresh them every year or so. This year’s improvements include commas (on
the larger numbers) and charts!</p>
<p>I’ve also made the decision to drop the High Frequency plan from Vultr in favor
of their less expensive plan that marries up with the other provider’s price
point. Since I’ve avoided certain providers because they don’t offer the same
price point, it didn’t make sense to include the differently priced Vultr plan.</p>
<p>With regard to the data, there are a couple of metrics that I’ve decided to
drop. The <code>ab</code> benchmark, which was always at the mercy of my own Internet
connection and the Speed Test. The Speed Test may make a come back in the
future, but since not every provider has a server in the same geographical
region (looking at you AWS), it’s hard to do an apples to apples comparison
since Speed Test only works against close servers. Close servers for one
provider may not be close for another.</p>
<p>As per usual, I’ve spun up 3 server instances and averaged the results.
Additional information about which distro and software versions have been moved
down to the overview section.</p>
<p>Also, for the sake of being a non-biased reviewer, I am no longer going to be
“picking a winner” and will be letting the data stand on it’s own. If nothing
else, I’m tired of typing out “YMMV and you should weigh the needs of your
application against these benchmarks, yadda yadda blah blah blah” every month.</p>
<h2 id="overview">Overview</h2>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Location</td>
<td>New York 1</td>
<td>Virginia, Zone A</td>
<td>Newark, NJ</td>
<td>US-NYC1</td>
<td>New York (NJ)</td>
</tr>
<tr>
<td>Distro</td>
<td>Ubuntu 20.04 LTS</td>
<td>Ubuntu 20.04 LTS</td>
<td>Ubuntu 20.04 LTS</td>
<td>Ubuntu 20.04 LTS</td>
<td>Ubuntu 20.04 LTS</td>
</tr>
<tr>
<td>Kernel</td>
<td>5.4.0</td>
<td>5.4.0</td>
<td>5.4.0</td>
<td>5.4.0</td>
<td>5.4.0</td>
</tr>
<tr>
<td>MySQL</td>
<td>8.0.22</td>
<td>8.0.22</td>
<td>8.0.22</td>
<td>8.0.22</td>
<td>8.0.22</td>
</tr>
<tr>
<td>Redis</td>
<td>5.0.7</td>
<td>5.0.7</td>
<td>5.0.7</td>
<td>5.0.7</td>
<td>5.0.7</td>
</tr>
<tr>
<td>Base Price</td>
<td><strong>$5/month</strong></td>
<td><strong>$5/month</strong></td>
<td><strong>$5/month</strong></td>
<td><strong>$5/month</strong></td>
<td><strong>$5/month</strong></td>
</tr>
<tr>
<td>Hourly Price</td>
<td><strong>$0.007/hour</strong></td>
<td><strong>$0.007/hour</strong></td>
<td>$0.0075/hour</td>
<td><strong>$0.007/hour</strong></td>
<td><strong>$0.007/hour</strong></td>
</tr>
<tr>
<td>RAM</td>
<td><strong>1 GB</strong></td>
<td><strong>1 GB</strong></td>
<td><strong>1 GB</strong></td>
<td><strong>1 GB</strong></td>
<td><strong>1 GB</strong></td>
</tr>
<tr>
<td>CPU</td>
<td><strong>1 Core</strong></td>
<td><strong>1 Core</strong></td>
<td><strong>1 Core</strong></td>
<td><strong>1 Core</strong></td>
<td><strong>1 Core</strong></td>
</tr>
<tr>
<td>Storage</td>
<td>25 GB SSD</td>
<td><strong>40 GB SSD</strong></td>
<td>25 GB SSD</td>
<td>25 GB SSD</td>
<td>25 GB SSD</td>
</tr>
<tr>
<td>Transfer</td>
<td>1 TB</td>
<td><strong>2 TB</strong></td>
<td>1 TB</td>
<td>1 TB</td>
<td>1 TB</td>
</tr>
<tr>
<td>Transfer Overage</td>
<td><strong>$0.01/GB</strong></td>
<td>$0.09/GB</td>
<td><strong>$0.01/GB</strong></td>
<td><strong>$0.01/GB</strong></td>
<td><strong>$0.01/GB</strong></td>
</tr>
<tr>
<td>Backups</td>
<td><strong>$1/month</strong></td>
<td>$2/month</td>
<td>$2/month</td>
<td><strong>$1/month</strong></td>
<td><strong>$1/month</strong></td>
</tr>
<tr>
<td>DNS</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>No</td>
<td><strong>Yes</strong></td>
</tr>
<tr>
<td>Firewall</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>in beta</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
</tr>
<tr>
<td>Load Balancer</td>
<td><strong>$10.00/month</strong></td>
<td>$18.00/month</td>
<td><strong>$10.00/month</strong></td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Block Storage</td>
<td><strong>$0.10/GB</strong></td>
<td><strong>$0.10/GB</strong></td>
<td><strong>$0.10/GB</strong></td>
<td>$0.223/GB</td>
<td><strong>$0.10/GB</strong></td>
</tr>
<tr>
<td>Object Storage</td>
<td>$5/month</td>
<td>$0.023/GB</td>
<td>$5/month</td>
<td>$5/month</td>
<td>$5/month</td>
</tr>
<tr>
<td>Managed Databases</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>2FA/MFA</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
</tr>
<tr>
<td>One-click Apps</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>No</td>
<td><strong>Yes</strong></td>
</tr>
<tr>
<td>Custom Images</td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td><strong>Yes</strong></td>
</tr>
<tr>
<td>Kubernetes</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Container Registry</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>
<h2 id="cpu-info">CPU Info</h2>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>Model Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>DigitalOcean - Instance #1</td>
<td>Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz</td>
</tr>
<tr>
<td>DigitalOcean - Instance #2</td>
<td>Intel(R) Xeon(R) Gold 6141 CPU @ 2.30GHz</td>
</tr>
<tr>
<td>DigitalOcean - Instance #2</td>
<td>Intel(R) Xeon(R) CPU E5-2650L v3 @ 1.80GHz</td>
</tr>
<tr>
<td>Lightsail - All Instances</td>
<td>Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHz</td>
</tr>
<tr>
<td>Linode - All Instances</td>
<td>Intel(R) Xeon(R) CPU E5-2697 v4 @ 2.30GHz</td>
</tr>
<tr>
<td>UpCloud - All Instances</td>
<td>AMD EPYC 7542 32-Core Processor</td>
</tr>
<tr>
<td>Vultr - All Instances</td>
<td>Intel Core Processor (Broadwell, no TSX, IBRS)</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU MHz</td>
<td>2,164.69</td>
<td>2,400.11</td>
<td>2,300.00</td>
<td><strong>2,894.56</strong></td>
<td>2,396.30</td>
</tr>
<tr>
<td>Cache Size (KB)</td>
<td>4,096.00</td>
<td><strong>30,720.00</strong></td>
<td>16,384.00</td>
<td>512.00</td>
<td>16,384.00</td>
</tr>
<tr>
<td>BogoMips</td>
<td>2,666.33</td>
<td>3,200.33</td>
<td>3,066.33</td>
<td><strong>3,859.67</strong></td>
<td>3,192.33</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/cpu-info.png" alt=""></p>
<h2 id="cpu">CPU</h2>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Events per Second</td>
<td>774.74</td>
<td>756.19</td>
<td>680.86</td>
<td><strong>1,656.71</strong></td>
<td>696.10</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td>1.28</td>
<td>1.17</td>
<td>1.35</td>
<td><strong>0.58</strong></td>
<td>1.20</td>
</tr>
<tr>
<td>Average (ms)</td>
<td>1.34</td>
<td>1.32</td>
<td>1.48</td>
<td><strong>0.60</strong></td>
<td>1.46</td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>2.19</td>
<td><strong>2.03</strong></td>
<td>8.58</td>
<td>3.31</td>
<td>8.07</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/cpu-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/cpu-times.png" alt=""></p>
<h2 id="memory">Memory</h2>
<h3 id="read">Read</h3>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ops per Second</td>
<td>2,795,691.79</td>
<td>518,886.12</td>
<td>3,236,535.21</td>
<td><strong>5,508,920.49</strong></td>
<td>3,113,451.43</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
</tr>
<tr>
<td>Average (ms)</td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>0.59</td>
<td><strong>0.19</strong></td>
<td>5.36</td>
<td>0.24</td>
<td>5.01</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/memory-read-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/memory-read-times.png" alt=""></p>
<h3 id="write">Write</h3>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ops per Second</td>
<td>2,784,300.29</td>
<td>518,783.53</td>
<td>3,309,380.29</td>
<td><strong>5,518,340.76</strong></td>
<td>3,095,818.49</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
</tr>
<tr>
<td>Average (ms)</td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>0.66</td>
<td>4.11</td>
<td>2.92</td>
<td><strong>0.24</strong></td>
<td>7.37</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/memory-write-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/memory-write-times.png" alt=""></p>
<h2 id="file-io">File I/O</h2>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reads per Second</td>
<td>1,831.41</td>
<td>1,151.42</td>
<td>1,827.94</td>
<td><strong>2,941.27</strong></td>
<td>1,187.74</td>
</tr>
<tr>
<td>Writes per Second</td>
<td>1,220.88</td>
<td>767.58</td>
<td>1,218.62</td>
<td><strong>1,960.82</strong></td>
<td>791.82</td>
</tr>
<tr>
<td>Fsyncs per Second</td>
<td>3,912.04</td>
<td>2,458.69</td>
<td>3,904.29</td>
<td><strong>6,277.97</strong></td>
<td>2,543.86</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
<td><strong>0.00</strong></td>
</tr>
<tr>
<td>Average (ms)</td>
<td>0.16</td>
<td>0.23</td>
<td>0.14</td>
<td><strong>0.09</strong></td>
<td>0.25</td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>22.31</td>
<td>41.16</td>
<td>19.23</td>
<td><strong>8.33</strong></td>
<td>33.01</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/fileio-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/fileio-times.png" alt=""></p>
<h2 id="mysql">MySQL</h2>
<h3 id="read-only">Read Only</h3>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transactions per Second</td>
<td>4,845.00</td>
<td>4,967.67</td>
<td>4,673.00</td>
<td><strong>9,986.00</strong></td>
<td>4,345.00</td>
</tr>
<tr>
<td>Queries per Second</td>
<td>77,520.00</td>
<td>79,482.67</td>
<td>74,768.00</td>
<td><strong>159,776.00</strong></td>
<td>69,520.00</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td>1.77</td>
<td>1.77</td>
<td>1.76</td>
<td><strong>0.85</strong></td>
<td>1.65</td>
</tr>
<tr>
<td>Average (ms)</td>
<td>2.16</td>
<td>2.01</td>
<td>2.19</td>
<td><strong>1.00</strong></td>
<td>2.32</td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>13.14</td>
<td>27.90</td>
<td>12.81</td>
<td><strong>8.37</strong></td>
<td>19.07</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-ro-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-ro-times.png" alt=""></p>
<h3 id="write-only">Write Only</h3>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transactions per Second</td>
<td>3,262.33</td>
<td>1,830.00</td>
<td>4,276.67</td>
<td><strong>4,729.67</strong></td>
<td>2,659.33</td>
</tr>
<tr>
<td>Queries per Second</td>
<td>19,574.00</td>
<td>10,980.00</td>
<td>25,660.00</td>
<td><strong>28,378.00</strong></td>
<td>15,956.00</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td>1.58</td>
<td>2.82</td>
<td>1.29</td>
<td><strong>1.22</strong></td>
<td>1.66</td>
</tr>
<tr>
<td>Average (ms)</td>
<td>3.57</td>
<td>5.49</td>
<td>2.41</td>
<td><strong>2.11</strong></td>
<td>4.11</td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>59.84</td>
<td>66.92</td>
<td>17.23</td>
<td><strong>16.78</strong></td>
<td>42.90</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-wo-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-wo-times.png" alt=""></p>
<h3 id="read-write">Read Write</h3>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transactions per Second</td>
<td>1,483.33</td>
<td>1,158.00</td>
<td>1,833.33</td>
<td><strong>2,971.33</strong></td>
<td>1,350.00</td>
</tr>
<tr>
<td>Queries per Second</td>
<td>29,666.67</td>
<td>23,160.00</td>
<td>36,666.67</td>
<td><strong>59,426.67</strong></td>
<td>27,000.00</td>
</tr>
<tr>
<td>Minimum (ms)</td>
<td>4.14</td>
<td>5.30</td>
<td>3.73</td>
<td><strong>2.28</strong></td>
<td>4.00</td>
</tr>
<tr>
<td>Average (ms)</td>
<td>7.36</td>
<td>8.69</td>
<td>5.63</td>
<td><strong>3.37</strong></td>
<td>7.69</td>
</tr>
<tr>
<td>Maximum (ms)</td>
<td>74.32</td>
<td>92.03</td>
<td>24.35</td>
<td><strong>15.02</strong></td>
<td>54.58</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-rw-operations.png" alt="">
<img src="https://joshtronic.com/images/vps-showdown/2021/01/mysql-rw-times.png" alt=""></p>
<h2 id="redis">Redis</h2>
<table>
<thead>
<tr>
<th>&nbsp;</th>
<th>DigitalOcean</th>
<th>Lightsail</th>
<th>Linode</th>
<th>UpCloud</th>
<th>Vultr</th>
</tr>
</thead>
<tbody>
<tr>
<td>PING_INLINE</td>
<td>37,467.59</td>
<td>44,725.46</td>
<td>33,059.91</td>
<td><strong>105,898.31</strong></td>
<td>29,047.98</td>
</tr>
<tr>
<td>PING_BULK</td>
<td>35,346.20</td>
<td>44,392.14</td>
<td>32,380.69</td>
<td><strong>104,245.26</strong></td>
<td>27,620.23</td>
</tr>
<tr>
<td>SET</td>
<td>37,304.98</td>
<td>44,364.88</td>
<td>33,737.66</td>
<td><strong>109,179.92</strong></td>
<td>30,326.64</td>
</tr>
<tr>
<td>GET</td>
<td>36,177.53</td>
<td>44,484.49</td>
<td>33,286.67</td>
<td><strong>105,763.57</strong></td>
<td>30,147.23</td>
</tr>
<tr>
<td>INCR</td>
<td>36,529.12</td>
<td>44,546.42</td>
<td>33,823.21</td>
<td><strong>108,389.54</strong></td>
<td>30,653.05</td>
</tr>
<tr>
<td>LPUSH</td>
<td>37,067.48</td>
<td>45,184.20</td>
<td>34,941.31</td>
<td><strong>101,703.12</strong></td>
<td>30,878.10</td>
</tr>
<tr>
<td>RPUSH</td>
<td>37,160.57</td>
<td>45,009.44</td>
<td>34,508.68</td>
<td><strong>101,129.41</strong></td>
<td>30,698.56</td>
</tr>
<tr>
<td>LPOP</td>
<td>37,200.35</td>
<td>45,034.71</td>
<td>34,506.43</td>
<td><strong>101,000.86</strong></td>
<td>30,967.45</td>
</tr>
<tr>
<td>RPOP</td>
<td>37,043.53</td>
<td>44,970.25</td>
<td>34,107.09</td>
<td><strong>103,404.06</strong></td>
<td>30,817.55</td>
</tr>
<tr>
<td>SADD</td>
<td>37,243.79</td>
<td>44,281.57</td>
<td>33,413.33</td>
<td><strong>105,949.33</strong></td>
<td>29,377.70</td>
</tr>
<tr>
<td>HSET</td>
<td>37,255.24</td>
<td>45,225.38</td>
<td>34,684.87</td>
<td><strong>99,664.97</strong></td>
<td>30,599.20</td>
</tr>
<tr>
<td>SPOP</td>
<td>35,316.91</td>
<td>44,707.34</td>
<td>32,978.49</td>
<td><strong>106,994.62</strong></td>
<td>28,421.16</td>
</tr>
<tr>
<td>LRANGE_100 (first 100 elements)</td>
<td>23,561.11</td>
<td>28,754.26</td>
<td>17,517.02</td>
<td><strong>42,870.39</strong></td>
<td>20,503.34</td>
</tr>
<tr>
<td>LRANGE_300 (first 300 elements)</td>
<td>10,412.71</td>
<td>12,664.05</td>
<td>7,105.71</td>
<td><strong>21,035.19</strong></td>
<td>8,300.07</td>
</tr>
<tr>
<td>LRANGE_500 (first 500 elements)</td>
<td>7,358.50</td>
<td>9,114.44</td>
<td>5,499.13</td>
<td><strong>13,687.73</strong></td>
<td>6,022.17</td>
</tr>
<tr>
<td>LRANGE_600 (first 600 elements)</td>
<td>5,993.42</td>
<td>7,459.68</td>
<td>4,552.03</td>
<td><strong>11,243.44</strong></td>
<td>4,792.29</td>
</tr>
<tr>
<td>MSET (10 keys)</td>
<td>29,789.73</td>
<td>36,399.52</td>
<td>31,170.10</td>
<td><strong>56,074.07</strong></td>
<td>23,943.22</td>
</tr>
</tbody>
</table>
<p><img src="https://joshtronic.com/images/vps-showdown/2021/01/redis-operations.png" alt=""></p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope you have enjoyed this month’s VPS Showdown post. If you found this
information helpful and it helped sway your decision for a new VPS hosting
provider, please help me out by signing up via one of my referral links below:</p>
<ul>
<li><a href="https://m.do.co/c/c35d26de972b">DigitalOcean</a>, new accounts receive $100 in credit (good for 60 days).</li>
<li><a href="https://promo.linode.com/joshtronic/">Linode</a>, new accounts receive $100 in credit (good for 60 days).</li>
<li><a href="https://upcloud.com/signup/?promo=XZN2AZ">UpCloud</a>, new accounts receive $25 in credit.</li>
<li><a href="https://www.vultr.com/?ref=8411310-6G">Vultr</a>, new accounts receive $100 in credit (good for 30 days).</li>
</ul>
</article><div>
<h3>Good stuff? Want more?</h3>
<div><p>
Weekly emails about technology, development, and sometimes sauerkraut.
</p><p>100% Fresh, Grade A Content, Never Spam.</p>
</div>



</div></div>]]>
            </description>
            <link>https://joshtronic.com/2021/01/03/vps-showdown-digitalocean-lightsail-linode-upcloud-vultr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629384</guid>
            <pubDate>Mon, 04 Jan 2021 09:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure, blinded medical data analysis with OpenSAFELY]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629325">thread link</a>) | @stuartbman
<br/>
January 4, 2021 | https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3 grey-text="" text-darken-4="">Clinical Need</h3>
<section>
<div>
<p><span>
<div><p>When COVID-19 first hit, governments across the globe had to make tough public health decisions with little information. The measures they put in place to reduce spread can prevent COVID-19-related deaths but can also have <i>negative</i> consequences on physical and mental health😷.</p><p>Understanding what factors determine risk of serious outcomes from COVID-19 can help guide these policies. For example, people who are high risk may be advised to shield at home.</p><p>To understand these risk factors, there was a need to analyse large volumes of medical records. Unfortunately, getting access to these records and <sample>linking them appropriately</sample> typically requires lots of regulatory approvals and takes a long time.</p></div>
</span>
</p>
<div>

<div><p>To really understand COVID, we need to link up clinical appointment notes with test results, death records, etc.</p><p>However, this information is typically kept in different locations.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>As a result, it’s hard to get really big datasets but <sample>the bigger, the better</sample>.</p><p>So what could we do? This research team came up with a great solution…</p></div>
</span>
</p>
<div>

<div><p>The larger the dataset, the greater statistical strength you have for the analysis.</p><p>In a smaller dataset, you might see trends - but then not have enough data to confidently say it is not due to random variation.</p><p>This is really important when looking at lots of different variables contributing to an outcome, as they did in this study.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">What did they do?</h3>
<section>
<div>
<p><span>
<div><p>They assembled a team of clinicians👨‍⚕️, programmers👩‍💻, data scientists👨‍🔬 and epidemiologists🧑‍💼 and came up with a new way of extracting and analysing health data. They called this platform OpenSAFELY.</p><p>The traditional approach is to: (i) clean data and <sample>pseudonymise it</sample> (ii) download it, then (iii) run an analysis.</p></div>
</span>
</p>
<div>

<p>This is a bit like anonymisation, but not as strict. Information that could enable the individual to be identified (such as date of birth or home address) is modified, but can still be re-identified by those (ie. the researchers) using a ‘de-identification key’.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>However, this isn’t particularly secure (what if someone’s laptop gets stolen?), pseudonymisation isn’t fail-safe and it allows <sample>repeated analyses which risks identifying false relationships</sample>.</p><p>This team’s new approach is to upload the code for analysing the data to the electronic health record directly. The code is then run and returns the results. The data never leaves the health record. This maintains privacy and prevents repeated analyses 💯</p><p>They used this to look at the factors affecting risk of dying from COVID-19, in a GP health record dataset of 17 million individuals.</p></div>
</span>
</p>
<div>

<div><p>There’s always a possibility that patterns identified in the data are down to chance.</p><p>If a test has “95% confidence” it means there’s a 5% chance it happened by chance.</p><p>We can bear this in mind when interpreting results. However, what happens if we run multiple analyses, looking for a true result?</p><p>We give the data lots of chances to fall into that 5% that is due to chance.</p><p>With a pressure to publish interesting findings, this can incentivise researchers to run multiple tests in order to find these relationships – which may not be true. These may seem interesting, but they’re bad science.</p><p>This is known as ‘data dredging’ or ‘p-hacking’.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">How does it work?</h3>
<div><p>1️⃣ First, after the researcher decides which data they want to analyse (e.g. all patients with diabetes) — they write some code to extract that from the health records.</p><p>2️⃣ When that code is run, they receive data to download. However, the data is a placeholder. It looks like the real data - but all the values are made up! Knowing the structure of the data helps the researchers write the code.</p><p>3️⃣ The working code is sent over to the health record (packaged up in a wrapper called <a href="https://www.docker.com/">Docker</a>) where it performs the analysis. Only the results are returned to the researchers - the patient data never leaves the health records. So no-one (not even the researchers) see the raw patient data.</p></div>
<h3 grey-text="" text-darken-4="">What did they find?</h3>
<div><p>They looked at data from 17 million people and found COVID-19-related death is increased by:</p><ul><li>Being male</li><li>Being older</li><li>Higher deprivation</li><li>BAME ethnicity (part of this explained by higher prevalence of medical problems and higher levels of deprivation)</li><li>Obesity</li><li>Various other medical conditions (such as diabetes, severe asthma, cancer and dementia)</li></ul></div>
<h3 grey-text="" text-darken-4="">Any limitations?</h3>
<section>
<div>
<p><span>
<div><p>This analysis was done in the early days of the pandemic. This meant we didn’t have the testing capacity we have now🧪. To circumvent this, the researchers included ‘<sample>clinically suspected’ cases</sample> of COVID-19 – and not just ones where it had been confirmed by a COVID-19 test. Some of these ‘positive’ cases may not have actually had COVID-19.</p><p>There were other common issues seen in data analysis on this scale: Some patients had missing data, like obesity, smoking status and ethnicity. Also, health record availability varies between region. They used data from a single GP electronic record company (TPP), whereas some regions (such as Scotland and North-East England use an alternative called EMIS). This means the sample population for the study may not represent the whole population (or indeed populations outside of England).</p></div>
</span>
</p>
<div>

<p>They don't include their definition here, but from the UK Government, this includes: new continuous cough or temperature ≥37.8°C or loss of, or change in, normal sense of smell (anosmia) or taste (ageusia)</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">So what?</h3>
<div><p>It was a great feat to get this platform up-and-running and publish the analysis in such a short space of time. This type of research doesn’t usually happen that fast.</p><p>The study helped public health teams and researchers make decisions. For example, in the UK this provided support for advising at-risk populations to shield🛡.</p><p>This also presents a new paradigm for data analysis of health data, that could enable faster, more secure and more reproducible research going forward. All the code is <a href="https://github.com/opensafely/risk-factors-research">open-source and freely available</a>. This means anybody can inspect the code and other researchers are free to use it.</p><p>Since this paper, the same research group have used this platform to look at the impact on COVID-19 risk of (i) living with school-age children, (ii) HIV, (iii) ethnicity, (iv) taking hydroxychloroquine and (v) steroids with asthma or COPD.</p></div>
</div></div>]]>
            </description>
            <link>https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629325</guid>
            <pubDate>Mon, 04 Jan 2021 09:52:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Perl Didn't Win]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25629189">thread link</a>) | @elvis70
<br/>
January 4, 2021 | https://outspeaking.com/words-of-technology/why-perl-didnt-win.html | <a href="https://web.archive.org/web/*/https://outspeaking.com/words-of-technology/why-perl-didnt-win.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><small><em>page updated on December 31, 2020</em></small></p>

<p>The early days of the (public) Internet felt like living in the science
fiction world of a Bruce Sterling or William Gibson, whether finally being able
to download a web browser with image support (Slipknot?) or realizing that you
were logged into a machine in Australia from the middle of farm country USA and
it was responding to your FTP commands.</p>
<p>To everyone who'd learned how to type on an old PS/1 computer running
WordPerfect for DOS—with the little plastic overlay giving you the
keyboard shortcuts for formatting hints—and for whom Alt-F3 "Reveal
Codes" made word processing make sense, HTML was the easiest thing in the world
to learn (even if the best design you could do was center things with
tables).</p>
<p>Your author remembers the first time he came across a web page which
<em>changed</em> when you reloaded it. Some university student had set up the
official homepage for a band and every new page view displayed a different
snippet of lyrics. These web pages weren't simple documents. They were
<em>programs</em>. This was science fiction. This was living in the future.</p>
<p>Then came forms and server side processing and your author graduated from
college and learned Java and scrounged together spare parts at work to build
his own Linux machine and learned that the Internet wasn't magic science
fiction. It was all programs and protocols, and the greatest magic protocol of
them all at that time was HTTP, especially when combined with the new HTML
extensions for form submissions and the Common Gateway Interface that let a web
server launch programs to process form parameters and produce a fresh batch of
HTML.</p>
<p>CGI programs could be anything. You could write them in a shell script on an
HP-UX or Irix box. You could write them in C. Netscape tried to make money
selling server software where you could write them in JavaScript (and oh how
everyone laughed).</p>
<p>Like almost everyone in the late '90s during the Internet boom, your author
learned Perl.</p>
<h2>Why Perl Won</h2>
<p>Perl was already everywhere, at least on the serious machines you wanted
connected to the Internet. (Microsoft was still struggling to understand why
you'd want to connect to the Internet. Then again, in the 2010s, Microsoft
started to wonder why you would want a computer which <em>didn't</em> behave
exactly like a tablet. Legions of gamers cringe as they consider a Halo 5 where
you must tap your TV screen to fight off the Covenant and Prometheans.) Perl
was everywhere because it was a good language for system administration,
bridging the gap between C and shell. Shell was a terrible language, mostly
because it didn't run the same way everywhere and it didn't handle things like
variables or functions very well.</p>
<p>Perl was everywhere, at least in the Unix world. It was good at manipulating
strings. Back in those days, HTTP and HTML were all stringy protocols. You get
a string, you parse it, and you emit a string. It was a mess, but it was a
simple mess and it was a small mess, so you could get away with it—more
importantly, you could get your work done before you figured out where you'd
gone wrong with string handling in C.</p>
<p>Perl was on version 5 of the language, as exemplified by the second edition
of a book called <em>Programming Perl</em>. You could walk into a room full of
techie cubicles and find that book on at least one desk, all dog-eared and full
of Post-its, because in any group of a couple of dozen
engineers/programmers/techies in those days, one of them was running a little
webserver on a Linux box under his or her desk and odds are he or she was using
Perl.</p>
<p>The code wasn't great. A lot of it was copied and pasted and modified and
downloaded and modified again from the kind of technical support forms that
StackOverflow has mostly thankfully (and almost entirely humorlessly)
supplanted.</p>
<p>But it worked.</p>
<p>Perl <em>did</em> have the advantage of momentum and ubiquity and efficacy
in those days. Then it lost. It seems competitive languages have eaten its
lunch. Why?</p>
<h2>Perl Wasn't and Isn't Perfect</h2>

<p>You can make the argument (and you're correct to do so) that people didn't
learn Perl for the sake of learning Perl. You can also make the argument that
people didn't really learn Perl at all—they learned enough to modify
programs that almost worked right to work a little bit righter. You can argue
that, but you're missing the important point: that's what people
<em>always</em> do. It looks different on the web now these days with bigger
frameworks and more choices and Google and StackOverflow replacing internet
relay chat and random web forums, but it's not materially different now than it
was then.</p>
<p>Goodness knows, Perl's core documentation is an updated version of the
venerable Camel book: thousands of pages of instruction on how the language
works and how to use it, at the fingertips of everyone who used it. If you want
a book, you can get one, but it ships with one.</p>
<p>Some people argue that learning Perl is easy, with the right training, such
as O'Reilly's <a href="https://www.amazon.com/gp/product/1491954329/ref=as_li_tf_il?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491954329&amp;linkCode=as2&amp;tag=trendshare0c-20">Learning
Perl</a> or <a href="https://modernperlbooks.com/books/modern_perl_2016/">Modern Perl 4e</a>,
but that argument relies on improvements made in the 2010s, after Perl had
started to stop winning.</p>
<p>Perl as a language had its quirks and flaws. It still has some of those
flaws and it definitely has those quirks. Perl's ease of using external
binaries within programs made it great for gluing things together, but there
were multiple documented cases of security holes and unintentional bugs from
people using backticks in <a href="http://modernperlbooks.com/books/modern_perl_2014/01-perl-philosophy.html#Y29udGV4dF9waGlsb3NvcGh5">scalar
or list context</a> and not knowing the difference and exposing sensitive
information.</p>
<p>People writing code by copy and paste and modify didn't learn the nuance of
the Perl philosophy which makes context important in part because people
writing code in that fashion don't learn the philosophy of <em>any</em>
language and in part because no Perl tutorial really explained the philosophy
of the language in an accessible fashion until 2010's <a href="https://www.amazon.com/gp/product/0985451947?ie=UTF8&amp;tag=outspeaking-20" rel="nofollow">Modern Perl</a>.</p>
<p>Is learning Perl hard? No. Not learning it is the hard way to learn it, but
Perl is dead easy to learn just enough to be useful.</p>
<h2>Ease of Beginning is Better than Eventual Perfection</h2>
<p>The execution model of CGI programs was simple and awful in its simplicity:
the web server would launch a new separate program and provide all of the data
received by the web browser to that program. It would listen for data produced
by that program and send it to the web browser. That doesn't sound awful, but
if you're reading this, you've probably replaced a couple of smartphones with
many times more memory and processor power than the web servers back in those
days had.</p>
<p>Launching a new program for every page requested was a little bit expensive
once your site became a little bit popular.</p>
<p>Even though that model of operation is conceptually straightforward to
understand (just launch a program), configuring your web server to execute
these programs (written in any language by any user) wasn't as easy as it
sounds. If you had a good system administrator, he or she would have set up the
web server to give every user a specific directory in which to put these CGI
programs where they'd run but not expose the world to security holes. If you
had a Linux box under your desk and you were your own system administrator, you
had to learn about directory structures and permissions and paths and the
details of how your web server was compiled and configured. Again, it was
relatively straightforward, but there was a lot to learn and there were a lot
of ways things could go wrong.</p>
<p>None of this was Perl's fault. It was a consequence of the Unix model
meeting the Internet and a lot of intelligent people figuring out the simplest
way to get something working quickly without necessarily thinking about the
<em>best</em> way to build something which would have to last for 20 years and
counting. (See also DNS, SMTP, FTP, NNTP, IMAP, IMAPS, SSL, TLS, et
cetera.)</p>
<p>Web programs were easier to write in Perl than they were in C because Perl,
as a language, made them easier, but the dominant execution model of Perl
programs was slow and expensive and difficult to configure.</p>
<p>A web server is just a program, however. If you modified the program, you
could make it do anything—including connecting it with a different
programming language. In fact, you could put Perl in the web server so that you
could simplify the configuration of these programs <em>and</em> not pay the
price of loading every program anew for every request.</p>
<p>This is what mod_perl did. Of course, mod_perl was part of making the Apache
httpd web server more configurable by giving it a plugin architecture where you
could write extensions to the web server to customize every part of the web
server request and response cycle, so mod_perl became less a way to make
writing and deploying Perl programs simpler and faster and cheaper and more a
way to write your own extensions to Apache httpd in Perl instead of C (because,
again, Perl was a better language for web programming than C).</p>
<p>This was great, until it wasn't. It addressed part of the problem but it
didn't address other parts of the problem. Installing and configuring mod_perl
wasn't trivially easy. It was downright difficult in some cases. You
<em>could</em> get a speed boost from using it, by trading some memory up front
for less memory used later, but every program attached to mod_perl could
potentially access the memory space of every other program attached to
mod_perl, even if both programs belonged to <em>different</em> users.</p>
<p>mod_php solved this problem. PHP was a terrible language back then, good
mostly for making very simple templates which represented web pages. PHP's
memory model fit mod_php better, though. PHP's deployment model was a lot
simpler, too. No one wanted to write Apache httpd extensions in PHP because it
was a template language, so there was no pressure to make mod_php anything
other than a very simple template processor which happened to be easy to
deploy.</p>
<p>In fact, it was so easy to deploy that people <em>used</em> it. System
administrators set it up because it was so easy to do they couldn't
<em>not</em> do it. People …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outspeaking.com/words-of-technology/why-perl-didnt-win.html">https://outspeaking.com/words-of-technology/why-perl-didnt-win.html</a></em></p>]]>
            </description>
            <link>https://outspeaking.com/words-of-technology/why-perl-didnt-win.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629189</guid>
            <pubDate>Mon, 04 Jan 2021 09:29:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ho-mobile (Vodafone IT MVNO) data breach confirmed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25629064">thread link</a>) | @denysvitali
<br/>
January 4, 2021 | https://www.ho-mobile.it/comunicazione/ | <a href="https://web.archive.org/web/*/https://www.ho-mobile.it/comunicazione/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	
	

	<main>
<div>

	
		
			      <div>
        <div>
          <div>
            <div>
							<p><img src="https://www.ho-mobile.it/etc/designs/lean/i/ho-chisiamo-logo-blue.png" srcset="https://www.ho-mobile.it/etc/designs/lean/i/ho-chisiamo-logo-blue@2x.png 2x, https://www.ho-mobile.it/etc/designs/lean/i/ho-chisiamo-logo-blue@3x.png 3x" alt="ho-logo-color"></p><p>HO. MOBILE DENUNCIA ATTIVITAâ€™ ILLECITA DI IGNOTI<br> SU DATI DI UNA PARTE DELLA PROPRIA BASE CLIENTI</p>
			  <p>Nessuna sottrazione di  dati di traffico,<br>nÃ© bancari o relativi a sistemi di pagamento</p>
			  <p>Innalzati i livelli di sicurezza</p>
			  <p>Stretta collaborazione con le autoritÃ&nbsp; inquirenti</p>
			  <p>COVID-19 ha intensificato i crimini informatici</p>
			  <p>Milano 4 gennaio 2021 - ho. Mobile, come dichiarato ufficialmente lo scorso 28 dicembre, ha avviato indagini in collaborazione con le AutoritÃ&nbsp; investigative su presunte sottrazioni di dati dei suoi clienti di telefonia mobile.<br></p>
			  <p>Dalle ulteriori verifiche effettuate, che sono tuttora in corso, emerge che sono stati sottratti illegalmente alcuni dati di parte della base clienti con riferimento solo ai dati anagrafici e tecnici della SIM. Lâ€™azienda comunica che non sono stati in alcun modo sottratti dati relativi al traffico (sms, telefonate, attivitÃ&nbsp; web, etc.), nÃ© dati bancari o relativi a qualsiasi sistema di pagamento dei propri clienti.<br></p>
			  <p>ho. Mobile denuncia tale attivitÃ&nbsp; illecita a danno dei propri clienti e comunica di aver giÃ&nbsp; sporto denuncia alla AutoritÃ&nbsp; inquirente e informato il Garante della Privacy, con i quali sta lavorando in stretto contatto.<br></p>
			  <p>Purtroppo anche ho. Mobile, come numerose altre aziende, Ã¨ rimasta vittima di attacchi informatici che si sono intensificati e accelerati durante la pandemia.<br></p>
			  <p>In queste ore stiamo procedendo ad informare solo i clienti ho. Mobile coinvolti, e abbiamo giÃ&nbsp; attivato ulteriori e nuovi livelli di sicurezza per mettere la clientela al riparo da potenziali minacce. Ulteriori azioni a protezione dei dati sottratti sono in corso di implementazione e verranno comunicate ai clienti.<br></p>
		      <p>Qualora i clienti vogliano comunque procedere alla sostituzione della propria SIM, potranno richiederne la sostituzione gratuita presso i punti vendita autorizzati.<br></p>
			  <p>Stiamo assistendo a diversi fenomeni speculativi sui social network e pertanto invitiamo i clienti a verificare direttamente con i canali ufficiali di ho. Mobile (sito, app , call center) ogni informazione ed eventuale esigenza di supporto.</p>
            <h2> Domande Frequenti</h2>
			<ul>
			<li>
			<p>Quali dati sono stati sottratti?</p>
			<p>Dalle ulteriori verifiche effettuate, che sono tuttora in corso, emerge che sono stati sottratti illegalmente alcuni dati di parte della base clienti con riferimento ai soli dati anagrafici (nome, cognome, numero di telefono, codice fiscale, email, data e luogo di nascita, nazionalitÃ&nbsp; e indirizzo) e tecnici della SIM. NON sono stati in alcun modo sottratti dati relativi al traffico (telefonate, SMS, attivitÃ&nbsp; web, etc.) nÃ© dati bancari o relativi a qualsiasi sistema di pagamento dei propri clienti.</p>
				
			</li>
					<li>
			<p>Come faccio a sapere se i miei dati sono stati sottratti? </p>
			<p>Riceverai una comunicazione dedicata in caso tu sia stato coinvolto.</p>
				
			</li>
					<li>
			<p>Ho attivato la ricarica automatica. I miei dati bancari sono stati sottratti?</p>
			<p>No, non sono stati in alcun modo sottratti dati relativi al traffico (telefonate, SMS, attivitÃ&nbsp; web, etc.) nÃ© dati bancari o relativi a qualsiasi sistema di pagamento dei clienti.
</p>
				
			</li>
					<li>
			<p>Voglio sostituire la mia SIM, come faccio?</p>
			<p>Puoi recarti presso uno dei nostri rivenditori autorizzati e richiedere il cambio della SIM <b>gratuitamente</b> portando con te la SIM attuale e un documento di identitÃ&nbsp; valido. Trova il negozio piÃ¹ vicino a te su <a href="https://www.ho-mobile.it/trova-negozio.html?show=stores">https://www.ho-mobile.it/trova-negozio.html</a></p>
				
			</li>
							<li>
			<p>Non voglio/posso andare in negozio. Potete spedirmi la SIM?</p>
			<p>Il processo di sostituzione SIM richiede riconoscimento fisico del cliente, pertanto non possiamo in questo momento spedirti la SIM. Puoi recarti presso uno dei nostri rivenditori autorizzati e richiedere il cambio della SIM <b>gratuitamente</b> portando con te la SIM attuale e un documento di identitÃ&nbsp; valido. Trova il negozio piÃ¹ vicino a te su <a href="https://www.ho-mobile.it/trova-negozio.html?show=stores">https://www.ho-mobile.it/trova-negozio.html</a></p>
				
			</li>
<li>
			<p>Sono un cliente ho. Mobile. Cosa devo fare? </p>
			<p>Abbiamo attivato ulteriori livelli di sicurezza per mettere i clienti al riparo dalla minaccia di eventuali frodi. Qualora tu voglia procedere alla sostituzione della tua SIM, potrai richiederla gratuitamente presso i punti vendita autorizzati. Trova il negozio piÃ¹ vicino a te su <a href="https://www.ho-mobile.it/trova-negozio.html?show=stores">https://www.ho-mobile.it/trova-negozio.html</a>.
Ã‰ comunque buona prassi aggiornare regolarmente le password dei tuoi account, scegliendole possibilmente differenti per i diversi siti e prestare attenzione a eventuali accessi anomali. Segnala sempre al fornitore dellâ€™account eventuali operazioni anomale e presta sempre attenzione a non accedere a siti web non sicuri e a non condividere le tue credenziali o altri dati personali via SMS o mail.
</p>
				
			</li>
<li>
			<p>Ho una SIM dati. Come saprÃ² se sono stato coinvolto?</p>
			<p>Solo in caso avessimo evidenze di un tuo coinvolgimento, ti invieremo comunicazione via mail allâ€™indirizzo di posta che hai utilizzato in fase di sottoscrizione dellâ€™offerta.</p>
				
			</li>

<li>
			<p>Il giorno 04/01 la vostra app e i call center non erano raggiungibili. Ha a che fare con tematiche di sicurezza?</p>
			<p>Assolutamente no. Ci impegniamo a ricontattare tutti i clienti che hanno provato a raggiungerci nella giornata del 4 Gennaio nel piÃ¹ breve tempo possibile. Ci scusiamo e ringraziamo in anticipo per la comprensione.</p>
				
			</li>
<li>
			<p>â€¢	Come puÃ² verificarsi una sostituzione SIM a mia insaputa? </p>
			<p>Per effettuare una sostituzione della SIM serve un documento di identitÃ&nbsp; e una denuncia in caso di furto o smarrimento. Non Ã¨ quindi fattibile utilizzando solo i seriali. Il frodatore deve quindi procurarsi un documento di identitÃ&nbsp; e una denuncia falsi. Abbiamo attivato ulteriori misure per individuare eventuali frodatori allâ€™intero dei punti vendita in fase di Sostituzione SIM.</p>
				
			</li>
			</ul>
            </div>
          </div>
        </div>
      </div>


		
	
</div>

	

</main>

	
 


</div></div>]]>
            </description>
            <link>https://www.ho-mobile.it/comunicazione/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629064</guid>
            <pubDate>Mon, 04 Jan 2021 09:06:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Verified Programming in F*: A Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25629058">thread link</a>) | @jstrieb
<br/>
January 4, 2021 | http://fstar-lang.org/tutorial/ | <a href="https://web.archive.org/web/*/http://fstar-lang.org/tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://fstar-lang.org/tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25629058</guid>
            <pubDate>Mon, 04 Jan 2021 09:04:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Equal Pay for Equal Work]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25628990">thread link</a>) | @dustinmoris
<br/>
January 4, 2021 | https://dusted.codes/equal-pay-for-equal-work | <a href="https://web.archive.org/web/*/https://dusted.codes/equal-pay-for-equal-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Remote work is on the rise, the economy is on a decline and businesses are re-structuring themselves around what many consider the new normal. Increasingly more organisations are opening themselves up to the possibility of working remotely beyond just the temporary measure in the fight against COVID-19. Many begin to see remote work as not only a necessary consequence, but rather as a new opportunity to diversify their workforce, increase employee productivity and cut some cost. The biggest cost saving obviously comes from office space, and not just in terms of raw square footage but also in location. When previously companies had to boast huge HQs in expensive areas, now they can spread themselves thinner across more affordable cities. Another big cost saving can come from employee salaries. A more distributed workforce and more work from home opportunities will inevitably mean a bigger talent pool competing for the same open positions, effectively giving employers a bigger choice.</p>
<p>However, when it comes to existing employees' salaries the direction taken by big tech companies couldn't be of starker contrast. Companies like <a href="https://www.cnbc.com/2020/05/21/zuckerberg-50percent-of-facebook-employees-could-be-working-remotely.html">Facebook or Twitter</a> have made it clear that employees who choose to relocate to more affordable cities can expect big cuts to their existing salary whereas companies like <a href="https://redditblog.com/2020/10/27/evolving-reddits-workforce/">Reddit announced that they won't reduce the salary of any of their 600 US workers</a> regardless of where they live.</p>
<p>These recent announcements have revived a <a href="https://www.helpscout.com/blog/remote-employee-compensation/">long standing debate</a> around the topic of <a href="https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">equal pay for equal work</a>. Before COVID-19 <a href="https://about.gitlab.com/blog/2019/02/28/why-we-pay-local-rates/">GitLab has already sparked a lot of controversy</a> around the concept of "cost of living" adjusted salaries. At GitLab two engineers who perform the exact same work could get vastly differently compensated based on where they live. It doesn't require a lot of imagination to understand that such policies can alienate a lot of good people and further contribute to the perception of an ever growing inequality gap. Personally I find cost of living adjusted salaries very problematic as they deflect from the real market forces which come into play. Those should be a decent minimum living wage and the forces of demand &amp; supply. If someone is a professional in a niche market, a rare specialist in a scientific field or an exceptionally sought after engineer then cost of living should have no say in determining their pay. Those so called knowledge workers are often higher in demand than there is supply. A good indicator for the scarcity of one's profession is when their employer recruits talent from all across the world and advertises unique perks such as relocation bonuses, dental care or exceptional holiday packages. These benefits would not exist if there wasn't a fierce competition for a particular skill.</p>
<p>Regardless of the real economics at play, it still comes down to a good old negotiation where each person has to stand up for their own beliefs and reach an agreement on their pay. If you find yourself in a situation where your current salary might be at risk due to recent relocation then hopefully the following write-up can help you to negotiate equal pay for equal work. It is a curated list of relevant points to formulate a strong argument why one should receive the same or perhaps an even better pay for the same work carried out from a remote position.</p>
<h2 id="same-duties-same-pay">Same duties, same pay</h2>
<p>If you're reading this blog post then you're most likely not being paid for your time or place of work. You are being paid for your knowledge, your skills, your duties, the challenges which come with your work and most importantly the responsibilities of your role. Your professionalism and your personal commitment which you bring to your every day job will not diminish when you move into a new place. Whether you work remotely or not, you will still contemplate over that tough work problem in your spare time. You will still lose sleep over that big presentation the next day. You will still stay up late to meet an important deadline by the end of the month. You do it because you take pride in your work. You do it because of a sense of personal accountability to your team. It is those qualities which have earned you the trust of your manager over the years. It is those qualities which earned you a pay rise long ago. Changing postcodes doesn't take away your accomplishments from the past. Changing postcodes shouldn't take away the things which you have already earned before.</p>
<h2 id="same-value-same-pay">Same value, same pay</h2>
<p>The value of your contributions hasn't been compromised by moving house. Customers still pay the same price for the products which you have helped to build. Sales figures didn't drop when you went remote. Why should your employer reduce your pay when they are not passing that cost saving onto their customers by cutting their own price? Based on the same principle why your employer won't reduce their prices when downsizing office, you also shouldn't accept a lower salary after moving place. The concept is the same and you shouldn't accept one principle for them, but another for yourself. As you continue to deliver the same value and quality as before, you equally deserve the same compensation in return.</p>
<h2 id="your-savings-their-savings">Your savings, their savings</h2>
<p>Let's be clear, when you transitioned from office to home it's not like you're the only one who benefited from a lower cost of living as a result. Whatever savings you might have made on your rent, your employer does now too. Every person in an office requires an extra desk. Every additional person requires a fraction more of bathroom space. More people mean bigger kitchens, bigger break out areas, more meeting rooms, larger hallways, bigger stairways and more facilities to comply with fire safety regulations. There is more pressure on lifts to avoid bottle necks during peak times. There is more building maintenance work to be done and more frequent cleaning intervals required. A bigger workforce automatically means more individual needs. Extra bicycle storage rooms, canteens, car parks, private offices, outdoor spaces, a bigger selection of refreshments and a larger variety of office perks are just a few to name. Unless your employer is prepared to share their own operational saving directly with you, why should you share your personal operational saving with them? Fundamentally their savings are theirs, and your savings are yours.</p>
<h2 id="their-profit-your-profit">Their profit, your profit</h2>
<p>Have you ever received a pay rise when your employer re-structured themselves to benefit from lower tax? Have you ever received a pay rise when your employer opened up a new factory in a less regulated place? Have you ever received a pay rise when your employer outsourced a call centre into a country without minimum wage? Probably not, because it was your employer and not you who took the risk. Guess what, when you are courageous enough to relocate to a different country, city or state, then any financial gains from your move are also only yours to claim. This shouldn't be a huge surprise as nothing comes without its own significant risk. Economic security, social safety nets, unemployment benefits, retirement support, access to public health services, cost of qualitative education or medical treatment are often some of the compromises which have to be taken into account. Simple things such as free playgrounds for children, access to public recreational grounds, well maintained parks, a good public transport system funded by tax or basic luxuries such as political stability or the ability to safely park a new car on a public road are many other cost calculations not to be dismissed. Of course this is not always the case, but those considerations are for you to make. Nobody else, particularly not your employer, who has a financial interest of dismissing or downplaying those issues should be making those calculations on your behalf. This is such a basic principle that it's almost offensive to suggest the opposite. Your employer should not decide what sort of lifestyle you deserve.</p>
<h2 id="higher-cost-higher-pay">Higher cost, higher pay</h2>
<p>Contrary to common belief, working from home is not cheap. First of all, working permanently from home requires an entire additional room. If your family lived in a three bedroom house before, now you need four.
Thanks to COVID-19 most will agree that working from a sofa is neither practical, nor sustainable or realistic by any means. A proper office desk and a good ergonomic chair are a necessity at the least. Those requirements alone make a legitimate home office significantly more expensive than many would like to admit. Throw in a couple of monitors, a qualitative web cam, microphone, printer, shredder, peripheral devices, a whiteboard, noise cancelling headphones, a mesh router and a backup laptop (assuming you'll get a work laptop provided) then the true cost of a home office begins to reach eye watering levels.</p>
<p>Some employers will try to provide you those supplies, but any seasoned remote worker will tell you to decline such an offer. After all you're still equipping your own personal home. You shouldn't have to pick from a selection of office desks which don't match your walls. You shouldn't have to settle on a chair which doesn't appeal to your eye. You shouldn't have to accept a black bezelled screen when all your other equipment is in space grey. Most importantly though, you want to treat those things as your own. You don't want to change your monitors when you change your job. You don't want to have to go through your employer to make a warranty claim. You don't want to ask for permission to replace a worn out chair. Instead you want to get a pay rise which allows you to set up your home office in the most productive way. If your employer is smart enough then they will not want to manage all of that inventory (which they never get to see) either.</p>
<p>Speaking of inventory, the true cost of working from home does not stop there yet. When working remotely nothing disrupts productivity more than a low bandwidth internet connection. One cannot …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dusted.codes/equal-pay-for-equal-work">https://dusted.codes/equal-pay-for-equal-work</a></em></p>]]>
            </description>
            <link>https://dusted.codes/equal-pay-for-equal-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628990</guid>
            <pubDate>Mon, 04 Jan 2021 08:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bind The Gap: Festive Edition of monthly digital FP magazine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628895">thread link</a>) | @kowainik
<br/>
January 4, 2021 | https://bindthegap.news/issues/02dec2020.html | <a href="https://web.archive.org/web/*/https://bindthegap.news/issues/02dec2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="all">
  <div>
    <div>
      <div>
          <h2>Issue #2, Dec 2020</h2>
        <p><span> <img src="https://bindthegap.news/assets/images/rails.png" alt="rails image"></span>
      </p></div>
    </div>
    <div>
        <div>
            <div>

            <p><img alt="Bind The Gap Issue #2" src="https://bindthegap.news/assets/images/covers/02Dec2020.png">
            </p>
            <div>
            <div>
                <h2>What's inside?</h2>
                <p><img alt="Bind The Gap Issue #2" src="https://bindthegap.news/assets/images/tocs/02Dec2020.png">

            </p></div>
            </div>
            </div>
            <div>
                     <div>
                        <p><a href="https://bindthegap.news/issues/BindTheGap-02Dec2020.pdf" target="_blank">Download PDF (~16MB)</a>
                        <a href="https://bindthegap.news/issues/BindTheGap-02Dec2020-compressed.pdf" target="_blank">Download compressed PDF (~7MB)</a>
                     </p></div>
            </div>
        </div>
    </div>
  </div>
</section>
<!-- Contact us -->
<section id="subscribe">
  <div>
    <div>
      <div>
        <h2>Subscribe</h2>
        <p><span> <img src="https://bindthegap.news/assets/images/rails.png" alt="rail image"></span>
      </p></div>
    </div>
    <div>
      <!-- Begin Mailchimp Signup Form -->
      <div id="mc_embed_signup">
    <form action="https://news.us2.list-manage.com/subscribe/post?u=af5d0411175f11e83618abf5e&amp;id=b04a7ed805" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" role="form" novalidate="">
    <div id="mc_embed_signup_scroll">
       <p><label for="mce-EMAIL">Email Address<span>*</span></label>
         
       </p>
       

  <div id="mce-responses">
    
    
  </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    
    
    </div>
</form>
</div>
<!--End mc_embed_signup-->

    </div>
    <div>
      <div>
        <div>
          <figure>
            <img src="https://bindthegap.news/assets/images/station-red.png" alt="image">
          </figure>
          <ul>
            <li>Support: <span>xrom.xkov@gmail.com</span></li>
          </ul>
        </div>
        <div>
            <figure>
                <img src="https://bindthegap.news/assets/images/station-orange.png" alt="image">
            </figure>
            <ul>
                <li>Twitter: <a href="https://twitter.com/bind_the_gap" target="_blank">@bind_the_gap</a></li>
            </ul>
        </div>
        <div>
            <figure>
                <img src="https://bindthegap.news/assets/images/station-pink.png" alt="image">
            </figure>
            <ul>
                <li>Twitter: <a href="https://twitter.com/kowainik" target="_blank">@kowainik</a></li>
            </ul>
        </div>
      </div>
      <div>
        <div>
            <figure>
                <img src="https://bindthegap.news/assets/images/station-yellow.png" alt="image">
            </figure>
            <ul>
                <li>Twitter: <a href="https://twitter.com/chshersh" target="_blank">@chshersh</a></li>
            </ul>
        </div>
        <div>
            <figure>
                <img src="https://bindthegap.news/assets/images/station-green.png" alt="image">
            </figure>
            <ul>
                <li>Twitter: <a href="https://twitter.com/vrom911" target="_blank">@vrom911</a></li>
            </ul>
        </div>
        <div>
          <figure>
            <img src="https://bindthegap.news/assets/images/station-purple.png" alt="image">
          </figure>
          <ul>
            <li>Office: <span>London, UK</span></li>
          </ul>
        </div>
      </div>
    </div>
    <div>
      <div>
      <div>
        <ul>
          <li><a href="https://twitter.com/bind_the_gap"><i></i></a></li>
          <li><a href="https://github.com/bindthegap"><i></i></a></li>
          <li><a href="https://ko-fi.com/kowainik" alt="Buy us wine"><i></i></a></li>
        </ul>
      </div>
    </div>
  </div>
</div></section>

<!-- Footer -->
<section id="mind-the-gap">
    <div>
        <div>
            <p>
                <h2> Mind the Gap</h2>
            </p>
        </div>
    </div>
    
</section>


    </div></div>]]>
            </description>
            <link>https://bindthegap.news/issues/02dec2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628895</guid>
            <pubDate>Mon, 04 Jan 2021 08:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The first two hours of Kakoune in two minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628840">thread link</a>) | @lenormf
<br/>
January 4, 2021 | https://lenormf.github.io/community-articles/2021/01/01/first_two_hours_in_two_minutes.html | <a href="https://web.archive.org/web/*/https://lenormf.github.io/community-articles/2021/01/01/first_two_hours_in_two_minutes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <h2>The first two hours of Kakoune in two minutes</h2>

<p>Learning a new editor can be a daunting task, especially when
coming over from a non-modal editor. I personally started with
<a href="https://www.gnu.org/software/emacs/">Emacs</a>, and it took me weeks to be
productive when I started using <a href="http://www.vim.org/">Vim</a>. The modal paradigm
is a powerful tool, but picking it up is generally not a painless experience.</p>

<p>When I discovered <a href="https://kakoune.org/">Kakoune</a> a few years ago, it felt
like the jump from Vim to it was even bigger than the one I’d made when
transitioning over from Emacs to Vim. Despite the two being fairly close on
paper, one still needs to unlearn all the muscle memory patiently cultivated
over the years and grow it back up from scratch. If we ignore the fact that
in those days the only (comparatively sparse) documentation was centralised
in the README file of the project, which might have contributed to why the
jump made itself felt so strongly, new comers still have to primarily
focus their efforts towards learning the “modal language”, or flavour,
of Kakoune.</p>

<p>In order to save them some time, whether they’re disembarking off the Emacs
(non-modal) or Vim (modal) boats, I’ve documented in the following article
some common configuration options. They won’t fit anyone’s workflow exactly
right, I trust the user to tweak the settings how they see fit. They will
however allow turning the two hours it would have taken me to figure out
what lines to write down in my user configuration to get a boilerplate setup
going into two minutes — the time it takes to read this introduction and
save the final
<a href="https://lenormf.github.io/community-articles/assets/download/two_hours_two_minutes/kakrc"><code>kakrc</code></a>
onto one’s system.</p>

<p><img src="https://lenormf.github.io/community-articles/assets/img/two_hours_two_minutes/screenshot.png" alt=""></p>

<h2 id="the-configuration-file">The configuration file</h2>

<p>You’ll find below an inlined, commented configuration file to steal from. You
can also
<a href="https://lenormf.github.io/community-articles/assets/download/two_hours_two_minutes/kakrc">download</a>
it directly, and save it as <code>~/.config/kak/kakrc</code> (or
<code>$XDG_CONFIG_HOME/kak/kakrc</code>).</p>

<div><div><pre><code># Set the colour scheme
colorscheme kaleidoscope-dark

# Width of a tab
set-option global tabstop 4

# Indent with 4 spaces
set-option global indentwidth 4

# Always keep one line and three columns displayed around the cursor
set-option global scrolloff 1,3

# Display the status bar on top
set-option global ui_options ncurses_status_on_top=true

# Display line numbers
add-highlighter global/ number-lines -hlcursor

# Highlight trailing whitespace
add-highlighter global/ regex \h+$ 0:Error

# Softwrap long lines
add-highlighter global/ wrap -word -indent

# Clipboard management mappings
map -docstring "yank the selection into the clipboard" global user y "&lt;a-|&gt; xsel -i&lt;ret&gt;"
map -docstring "paste the clipboard" global user p "&lt;a-!&gt; xsel&lt;ret&gt;"

# Shortcut to quickly exit the editor
define-command -docstring "save and quit" x "write-all; quit"
</code></pre></div></div>

<h2 id="explanations">Explanations</h2>

<p>These explanations expand on the purpose of the lines in the above file,
the salient parts in them, and hopefully give you a bird-eye view of the
various configuration instructions you might recognise in the
<a href="https://github.com/search?utf8=%E2%9C%93&amp;q=kakrc"><code>kakrc</code></a>
configurations of more advanced users.</p>

<p>The details are intentionally glossed over and might seem fuzzy, feel free
to refer to the list of recommended further readings at the end of this
article if you’re curious.</p>

<div><div><pre><code># Set the colour scheme
colorscheme kaleidoscope-dark
</code></pre></div></div>

<p>The Kaleidoscope colour scheme (also known as theme) is a high-contrast,
colour blind friendly palette of colours that should suit the largest subset
of users, at first. You can go for the dark variant (<code>kaleidoscope-dark</code>)
or the light one (<code>kaleidoscope-light</code>).</p>

<p>If you don’t care either way, comment this line and the default theme will
do just fine.</p>

<div><div><pre><code># Width of a tab
set-option global tabstop 4
</code></pre></div></div>

<p>Options are scoped, which means that they can hold different values depending
on the context in which they’re being used. For general configuration
purposes, use the <code>global</code> scope.</p>

<p>The <code>tabstop</code> option holds the amount of space characters that tabulation
characters (stored in a file opened with Kakoune) will be rendered as.</p>

<div><div><pre><code># Indent with 4 spaces
set-option global indentwidth 4
</code></pre></div></div>

<p>This option impacts the behaviour of a couple of primitives (a primitive
is a “key”, more details about keys/primitives below) that indent or
de-indent a line, in normal mode.</p>

<p>In non-modal editors, hitting keys results in the letter associated with them
being inserted into the buffer (the “file”) as-is. In modal editors,
this behaviour applies only to the “insert mode”, which can be entered
by hitting <code>i</code> in normal mode — which is the default mode when starting
Kakoune.</p>

<p>The <code>indentwidth</code> option dictates how many space characters are inserted
or removed when using (respectively) the normal mode primitive <code>&gt;</code> and <code>&lt;</code>.</p>

<p>Note that when editing a file that is recognised by the editor, manual
indentation of lines should not be necessary, as that side-effect will be
handled automatically upon hitting the return key.</p>

<div><div><pre><code># Always keep one line and three columns displayed around the cursor
set-option global scrolloff 1,3
</code></pre></div></div>

<p>When scrolling around a large file, the cursor tends to stick to the borders
of the window if more content needs to be displayed. You can have the window
show more context (i.e. lines and characters) when that happens with the
<code>scrolloff</code> option.</p>

<p>The first integer (<code>1</code> above) in the comma separated pair is the amount of
lines to show above/below the cursor when it hits the top/bottom of the
window, and more lines remain to be displayed in the file.</p>

<p>Similarly, the second integer (<code>3</code> above) is the amount of characters
displayed on the left/right when the cursor hits the left/right hand
window border.</p>

<div><div><pre><code># Display the status bar on top
set-option global ui_options ncurses_status_on_top=true
</code></pre></div></div>

<p>Kakoune follows a server/client architecture, and the behaviour of the user
interface (run by the client) can be tweaked via <code>ui_options</code>. It accepts
a list of equal-sign separated key/value pairs, and the above instructs
the NCurses client (default) to display the status bar on top.</p>

<p>Feel free to comment this line if the default behaviour (status bar on the
bottom) suits you.</p>

<div><div><pre><code># Display line numbers
add-highlighter global/ number-lines -hlcursor
</code></pre></div></div>

<p>Highlighters are decorators for the window or the text it contains. Similarly
to options (c.f. above), they are scoped, but we only care about their
<code>global</code> value. You might have noticed however that the above line uses
<code>global/</code>, and you might be tempted to remove it on account of it being
redundant — don’t, the character is significant.</p>

<p>The <code>number-lines</code> highlighter displays a file’s line numbers on the left
hand side of the screen. The <code>-hlcursor</code> flag allows highlighting the number
of the line that the cursor lies on.</p>

<div><div><pre><code># Highlight trailing whitespace
add-highlighter global/ regex \h+$ 0:Error
</code></pre></div></div>

<p>This line adds a <code>regex</code> highlighter which decorates trailing whitespace
with the built-in <code>Error</code> face. The number refers to the index of the match
within the regex. For instance, <code>0</code> refers to the text matched by the regex
(but not to the entire line).</p>

<div><div><pre><code># Softwrap long lines
add-highlighter global/ wrap -word -indent
</code></pre></div></div>

<p>The <code>wrap</code> highlighter applies “soft wrapping” (e.g. the lines appear
broken up, but no newline characters are inserted into the file itself)
to lines that cannot be fully displayed within the window. The flags passed
to it keep words whole, and the indentation of the lines newly created will
have the same indentation level as their stem.</p>

<div><div><pre><code># Clipboard management mappings
map -docstring "yank the selection into the clipboard" global user y "&lt;a-|&gt; xsel -i&lt;ret&gt;"
map -docstring "paste the clipboard" global user p "&lt;a-!&gt; xsel&lt;ret&gt;"
</code></pre></div></div>

<p>Mappings (also known as “key bindings”, or more simply “bindings”)
allow customising the side effect upon hitting a key. Here is a breakdown
of the two lines above:</p>

<ul>
  <li><code>map</code>: declare a new mapping</li>
  <li><code>-docstring "…"</code>: document what the side effect of the mapping is —
this is optional, but is quite helpful when the mapping is set in the
<code>user</code> mode (c.f. below)</li>
  <li><code>global</code>: mappings are scoped, just like options and highlighters</li>
  <li><code>user</code>: similar to the insert mode, the user mode is entered by hitting
a key (for instance, <code>,</code>) from normal mode (c.f. below for more information)</li>
  <li><code>&lt;key&gt; "…"</code>: upon hitting <code>key</code>, execute the given list of primitives</li>
</ul>

<p>As you can see, quite a few concepts have been packed into merely two
instructions.</p>

<p>In terms of functionality, these two mappings copy the current selection
to the clipboard and paste whatever is in it. They’re triggered by hitting
the comma <code>,</code> key followed by respectively <code>y</code> and <code>p</code>.</p>

<p>Read on if you’re not familiar with modal edition, or want to compare
the declaration of mappings in Kakoune with other modal editors.</p>

<p><strong>The user mode</strong><br>
Mappings allow overriding the behaviour of a given key, but since they all
have a specific purpose (c.f. primitives below) by default, one would have
to forego whatever functionality the key being overridden provided with,
in order to instantiate a custom mapping.</p>

<p>The user mode is entered from normal mode upon hitting the comma <code>,</code> key,
and allows “user mappings” to be declared within it. It’s a way to address
the above problem: you don’t have to override default keys/primitives,
you can just place them one keystroke away (“behind” the comma <code>,</code> key)
and be free to pick any key you see fit.</p>

<p><strong>Primitives</strong><br>
The difference between “key” and “primitive” is one of semantic, and both can
commonly be used interchangeably.</p>

<p>Keys are referred to as the letter (or symbol, for example the return key)
that is printed on them, on a QWERTY keyboard.</p>

<p>Primitives are triggered by single keys or a combination of them, and can
be invoked from a prompt (interactively) or script (programmatically). They
are referred to using a custom notation that allows combining letters and
modifiers (c.f. below).</p>

<p>When placing those cryptic definitions back into the context of the clipboard
management mappings above, we get:</p>

<ul>
  <li><code>&lt;a-|&gt;</code>: holding the alt and pipe <code>|</code> keys together to invoke the <code>&lt;a-|&gt;</code>
primitive, which pipes the current selection into a given shell command</li>
  <li><code>&lt;a-!&gt;</code>: holding the alt and <code>!</code> keys together to invoke the <code>&lt;a-!&gt;</code>
primitive, which inserts the output of a given shell command into the file</li>
  <li><code>&lt;ret&gt;</code>: the return key, to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lenormf.github.io/community-articles/2021/01/01/first_two_hours_in_two_minutes.html">https://lenormf.github.io/community-articles/2021/01/01/first_two_hours_in_two_minutes.html</a></em></p>]]>
            </description>
            <link>https://lenormf.github.io/community-articles/2021/01/01/first_two_hours_in_two_minutes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628840</guid>
            <pubDate>Mon, 04 Jan 2021 08:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Lisp Short Story)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628609">thread link</a>) | @plumsempy
<br/>
January 3, 2021 | https://plumsempy.com/2021/01/04/lisp-short-story/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2021/01/04/lisp-short-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><header id="masthead" role="banner">
			<!-- .site-branding -->

							<nav id="site-navigation" aria-label="Main Navigation">

					
					

									</nav><!-- #site-navigation -->
			
			
		</header><!-- #masthead -->

	
	<div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1342">

	

	
	<div>
		
<p>I received a Lisp book for Christmas from mom (and no she does not have a PhD but knows how to find wishlists and sort by price). I am going through it now and I found a function definition that is endlessly amusing me as a Python developer. I am hoping to bring you the same warm fuzzies momentarily.</p>



<p>Imagine we have a name, “Mr Rick Sanchez”. We would like a function to return the first name of this name, “Rick”. </p>



<p>Usually what I might do is to split the string and get the second argument; then handle edge cases like the empty string yadda yadda. Then discover “Dr Mr Rick Sanchez”, another special case, and then get smart and <code>while current in TITLES</code> iterate over my string to find the first name. </p>



<p>All this is fine and it would work after 10 minutes, 2 syntax errors and 3 utterances of sh!t. But also look at this lisp implementation:</p>



<pre><code>(defun first-name (name)
  (if (member (first name) *titles*)
  (first-name (rest name))
  (first name)))</code></pre>



<p>I mean it is recursive and has cute functions like <code>first</code> and <code>rest</code>, but I think what I like most about it, is that it doubled down on the simple first-word-of-the-string approach with a smart maneuver and did not add more complexity by more loops and <code>current</code> variables and edge cases. This is probably partially Lisp and partially Peter Norvig; nonetheless it is very amusing.</p>



<h3>Still here? see me convert it to Python</h3>



<p>I tried writing exactly that in Python: a function of 3 lines beautiful as poetry. And here it is: </p>



<pre><code>def first_name(name):
    if first(name) in TITLES:
        return first_name(rest(name))
    return first(name)</code></pre>



<p>and here is all the duct tape that assisted us in accomplishing this ideal, thank you:</p>



<pre><code>def noner(func):
    def wrapped(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except:
            return None
    return wrapped

@noner
def first(string):
    return string.split()[0]

@noner
def rest(string):
    return ' '.join(string.split()[1:])</code></pre>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div><!-- #content -->

		<!-- #colophon -->

</div></div>]]>
            </description>
            <link>https://plumsempy.com/2021/01/04/lisp-short-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628609</guid>
            <pubDate>Mon, 04 Jan 2021 07:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Analysis of Privacy on the App Store]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628543">thread link</a>) | @erwinmatijsen
<br/>
January 3, 2021 | https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html | <a href="https://web.archive.org/web/*/https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><article>
  
  <div><p>In iOS 14.3, Apple added their new <a href="https://developer.apple.com/app-store/app-privacy-details/">app privacy details</a> to App Store listings. App privacy details, which are sometimes compared to the nutritional labels on foodstuff, are details about the data an app collects and the purposes and use of such data. What can we learn by analysing this data?</p>

<p>From the 14<sup>th</sup> of December 2020, all new apps and app updates have to provide information on the data the app collects. This is used to power the app privacy details labelling. On Twitter, videos scrolling through the privacy listing for Facebook circulated immediately after the 14.3 release.</p>

<p>This system is somewhat flawed, because app developers can, at least in theory, lie about the data they collect. Some apps that profess to collect no data, actually turn out to collect a bunch if you read their privacy policy. However, the punishment for being caught lying, removal from the App Store, is a strong deterrent and it’s safe to assume most developers will have been truthful in their accounts.</p>

<p>An interesting side-effect of this, is that Apple has now made available the same data that can be found in terse and hard to parse privacy policies as simple and structured data that can be parsed and analysed. In this post I will do just that i.e. collect and analyse the privacy details for thousands of the most popular apps on the App Store.</p>

<h2 id="collecting-the-data">Collecting the Data</h2>

<p>If you just want to read the juicy details feel free to skip to the <a href="#analysis">analysis</a>.</p>

<p>Apple makes the privacy labelling data available for each app on the App Store via an API used by the App Store apps. By reverse engineering the App Store apps I’ve figured out how to make the API divulge this data on a per app basis.</p>

<p>This only gets me the privacy data for a single app, but I want to analyse popular apps. A good source of popular apps are the charts the App Store provides on a per app category basis. An example of this is “Top Free” apps in “Education”. These listings contain up to 200 apps per category and price point(i.e. free or paid).</p>

<p>On the UK store, which is the store I’ve used for all this analysis, there are 24 categories. Each of which have top charts with up to 200 paid and 200 free apps. This means the theoretical total number of apps is 9600. However, because some apps occupy chart positions in multiple categories and because the charts also contain app bundles the actual number is lower.</p>

<p>The full list of categories is:</p>

<table>
  <thead>
    <tr>
      <th><strong>Category</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Book</td>
    </tr>
    <tr>
      <td>Business</td>
    </tr>
    <tr>
      <td>Developer Tools</td>
    </tr>
    <tr>
      <td>Education</td>
    </tr>
    <tr>
      <td>Entertainment</td>
    </tr>
    <tr>
      <td>Finance</td>
    </tr>
    <tr>
      <td>Food &amp; Drink</td>
    </tr>
    <tr>
      <td>Graphics &amp; Design</td>
    </tr>
    <tr>
      <td>Health &amp; Fitness</td>
    </tr>
    <tr>
      <td>Lifestyle</td>
    </tr>
    <tr>
      <td>Magazines &amp; Newspapers</td>
    </tr>
    <tr>
      <td>Medical</td>
    </tr>
    <tr>
      <td>Music</td>
    </tr>
    <tr>
      <td>Navigation</td>
    </tr>
    <tr>
      <td>News</td>
    </tr>
    <tr>
      <td>Photo &amp; Video</td>
    </tr>
    <tr>
      <td>Productivity</td>
    </tr>
    <tr>
      <td>Reference</td>
    </tr>
    <tr>
      <td>Shopping</td>
    </tr>
    <tr>
      <td>Social Networking</td>
    </tr>
    <tr>
      <td>Sports</td>
    </tr>
    <tr>
      <td>Travel</td>
    </tr>
    <tr>
      <td>Utilities</td>
    </tr>
    <tr>
      <td>Weather</td>
    </tr>
  </tbody>
</table>

<h2 id="structure-of-the-data">Structure of the Data</h2>

<p>If you don’t care about the exact details and structure of the data feel free to skip to the <a href="#analysis">analysis</a>.</p>

<p>The structure of the data returned by the App Store API is</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>&lt;number&gt;</span><span>,</span><span>
  </span><span>"type"</span><span>:</span><span> </span><span>"apps"</span><span>,</span><span>
  </span><span>"href"</span><span>:</span><span> </span><span>&lt;href&gt;</span><span>,</span><span>
  </span><span>"attributes"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"privacyDetails"</span><span>:</span><span> </span><span>&lt;privacy-details&gt;</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre></figure>

<p>The <code>&lt;privacy-details&gt;</code> section of this document is the important bit. It’s an array where each item has the following structure.</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"privacyType"</span><span>:</span><span> </span><span>&lt;human-readable-description&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;string-identifier&gt;</span><span>,</span><span>
  </span><span>"description"</span><span>:</span><span> </span><span>&lt;human-readable-description&gt;</span><span>,</span><span>
  </span><span>"dataCategories"</span><span>:</span><span> </span><span>&lt;data-categories&gt;</span><span>,</span><span>
  </span><span>"purposes"</span><span>:</span><span> </span><span>&lt;data-purposes&gt;</span><span>
</span><span>}</span></code></pre></figure>

<p>The <code>&lt;string-identifier&gt;</code> is one of</p>

<table>
  <thead>
    <tr>
      <th><strong>Identifier</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DATA_LINKED_TO_YOU</td>
    </tr>
    <tr>
      <td>DATA_NOT_COLLECTED</td>
    </tr>
    <tr>
      <td>DATA_NOT_LINKED_TO_YOU</td>
    </tr>
    <tr>
      <td>DATA_USED_TO_TRACK_YOU</td>
    </tr>
  </tbody>
</table>

<p><code>DATA_NOT_COLLECTED</code> is used as a marker in which case <code>dataCategories</code> and <code>purposes</code> are both empty and this is the only element in the <code>privacyDetails</code> array.</p>

<p><code>DATA_USED_TO_TRACK_YOU</code> contains details on data used to track you across websites and apps owned by other companies, Apple’s description is <em>The following data may be used to track you across apps and websites owned by other companies:</em>. For this entry <code>purposes</code> will be empty and <code>dataCategories</code> contain the different data types that are tracked across apps and websites owned by other companies.</p>

<p><code>DATA_LINKED_TO_YOU</code> and <code>DATA_NOT_LINKED_TO_YOU</code> both contain data types with purposes specific granularity. This means that <code>dataCategories</code> will be empty and the different data types are in <code>purposes</code>. Apple’s description for <code>DATA_LINKED_TO_YOU</code> and <code>DATA_NOT_LINKED_TO_YOU</code> are <em>The following data, which may be collected and linked to your identity, may be used for the following purposes:</em> and <em>The following data, which may be collected but is not linked to your identity, may be used for the following purposes:</em> respectively.</p>

<p><code>&lt;data-purposes&gt;</code> is an array of purposes with the following structure:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"purpose"</span><span>:</span><span> </span><span>&lt;human-readable-purpose&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;purpose-identifier&gt;</span><span>,</span><span>
  </span><span>"dataCategories"</span><span>:</span><span> </span><span>&lt;data-categories&gt;</span><span>,</span><span>
</span><span>}</span></code></pre></figure>

<p>The different values for <code>&lt;purpose-identifier&gt;</code> are:</p>

<table>
  <thead>
    <tr>
      <th><strong>Purpose</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ANALYTICS</td>
    </tr>
    <tr>
      <td>APP_FUNCTIONALITY</td>
    </tr>
    <tr>
      <td>DEVELOPERS_ADVERTISING</td>
    </tr>
    <tr>
      <td>OTHER_PURPOSES</td>
    </tr>
    <tr>
      <td>PRODUCT_PERSONALIZATION</td>
    </tr>
    <tr>
      <td>THIRD_PARTY_ADVERTISING</td>
    </tr>
  </tbody>
</table>

<p>These are described by Apple in their <a href="https://developer.apple.com/app-store/app-privacy-details/#data-type-usage">documentation</a>, but I’ve added them here for completeness.</p>

<table>
  <thead>
    <tr>
      <th>Purpose</th>
      <th>Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Third-Party Advertising</td>
      <td>Such as displaying third-party ads in your app, or sharing data with entities who display third-party ads</td>
    </tr>
    <tr>
      <td>Developer’s Advertising or Marketing</td>
      <td>Such as displaying first-party ads in your app, sending  marketing communications directly to your users, or sharing data with  entities who will display your ads</td>
    </tr>
    <tr>
      <td>Analytics</td>
      <td>Using data to evaluate user behavior, including to  understand the effectiveness of existing product features, plan new  features, or measure audience size or characteristics</td>
    </tr>
    <tr>
      <td>Product Personalization</td>
      <td>Customizing what the user sees, such as a list of recommended products, posts, or suggestions</td>
    </tr>
    <tr>
      <td>App Functionality</td>
      <td>Such as to authenticate the user, enable features,  prevent fraud, implement security measures, ensure server up-time,  minimize app crashes, improve scalability and performance, or perform  customer support</td>
    </tr>
    <tr>
      <td>Other Purposes</td>
      <td>Any other purposes not listed</td>
    </tr>
  </tbody>
</table>

<p>Lastly <code>&lt;data-categories&gt;</code> is an array of objects with the following structure:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"dataCategory"</span><span>:</span><span> </span><span>&lt;human-readable-purpose&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;data-category-identifier&gt;</span><span>,</span><span>
  </span><span>"dataTypes"</span><span>:</span><span> </span><span>[</span><span>&lt;human-readable-data-type&gt;</span><span>],</span><span>
</span><span>}</span></code></pre></figure>

<p>The full list of data types and the categories they belong to is:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"IDENTIFIERS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"User ID"</span><span>,</span><span>
    </span><span>"Device ID"</span><span>
  </span><span>],</span><span>
  </span><span>"USAGE_DATA"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other Usage Data"</span><span>,</span><span>
    </span><span>"Advertising Data"</span><span>,</span><span>
    </span><span>"Product Interaction"</span><span>
  </span><span>],</span><span>
  </span><span>"DIAGNOSTICS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Performance Data"</span><span>,</span><span>
    </span><span>"Other Diagnostic Data"</span><span>,</span><span>
    </span><span>"Crash Data"</span><span>
  </span><span>],</span><span>
  </span><span>"CONTACT_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Name"</span><span>,</span><span>
    </span><span>"Other User Contact Info"</span><span>,</span><span>
    </span><span>"Phone Number"</span><span>,</span><span>
    </span><span>"Email Address"</span><span>,</span><span>
    </span><span>"Physical Address"</span><span>
  </span><span>],</span><span>
  </span><span>"PURCHASES"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Purchase History"</span><span>
  </span><span>],</span><span>
  </span><span>"LOCATION"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Coarse Location"</span><span>,</span><span>
    </span><span>"Precise Location"</span><span>
  </span><span>],</span><span>
  </span><span>"USER_CONTENT"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other User Content"</span><span>,</span><span>
    </span><span>"Photos or Videos"</span><span>,</span><span>
    </span><span>"Audio Data"</span><span>,</span><span>
    </span><span>"Emails or Text Messages"</span><span>,</span><span>
    </span><span>"Customer Support"</span><span>,</span><span>
    </span><span>"Gameplay Content"</span><span>
  </span><span>],</span><span>
  </span><span>"CONTACTS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Contacts"</span><span>
  </span><span>],</span><span>
  </span><span>"OTHER"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other Data Types"</span><span>
  </span><span>],</span><span>
  </span><span>"BROWSING_HISTORY"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Browsing History"</span><span>
  </span><span>],</span><span>
  </span><span>"SEARCH_HISTORY"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Search History"</span><span>
  </span><span>],</span><span>
  </span><span>"HEALTH_AND_FITNESS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Health"</span><span>,</span><span>
    </span><span>"Fitness"</span><span>
  </span><span>],</span><span>
  </span><span>"FINANCIAL_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Credit Info"</span><span>,</span><span>
    </span><span>"Payment Info"</span><span>,</span><span>
    </span><span>"Other Financial Info"</span><span>
  </span><span>],</span><span>
  </span><span>"SENSITIVE_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Sensitive Info"</span><span>
  </span><span>]</span><span>
</span><span>}</span></code></pre></figure>

<p>Let’s do some analysis of this data</p>

<h2 id="analysis">Analysis</h2>

<p>The data set I’ve collected contains 9082 combinations of apps and a position in a given category chart. In total there are 9040 unique apps in this data set.</p>

<p>Most charts contain 200 or nearly 200 apps, however <strong>Graphics &amp; Design(Paid)</strong>, <strong>Developer Tools(Paid)</strong>, and <strong>Magazines &amp; Newspapers(Paid)</strong> all have fewer than 90 apps so I’m dropping them from further analysis.</p>

<p>Because the privacy details have only been required for new apps and updates since mid December, not all apps contain information about privacy details. After removing those apps 3164 apps remain in the data set. Breaking this down by chart, several charts have less than 25 apps so I am dropping them from further analysis too. This leaves 3027 apps in the data set.</p>

<p>In total the following charts have been dropped:</p>

<ul>
  <li>Education(Paid)</li>
  <li>Navigation(Paid)</li>
  <li>Sports(Paid)</li>
  <li>Business(Paid)</li>
  <li>Food &amp; Drink(Paid)</li>
  <li>Shopping(Paid)</li>
  <li>Medical(Paid)</li>
  <li>Magazines &amp; Newspapers(Paid)</li>
</ul>

<p>For the analysis there are a few different data points that are interesting:</p>

<ul>
  <li>Apps that collect data this is linked to the user and how many such data types they collect.<sup>*</sup></li>
  <li>Apps that collect no data.</li>
  <li>Third Party tracking, i.e. tracking users across apps and websites owned by other companies and the how many(max 32) such data types they collect.</li>
</ul>

<p>* Data that is linked to the user for the purpose of supporting app functionality, that is the <code>APP_FUNCTIONALITY</code> purpose, is legitimate and will be exclude from the following analysis. This leaves 160 data types spread across 5 purposes.</p>

<p>I am excluding data that is collected but not linked to the user, in part to keep down the length of the analysis and in part because it’s the least interesting. I’ll probably do a follow up post on it later.</p>

<p>The questions I’ll be looking at for this analysis are:</p>

<ol>
  <li><a href="#free-vs-paid">Do free apps collect more data?</a></li>
  <li><a href="#worst-charts">Which are the worst charts?</a></li>
  <li><a href="#worst-apps">Which apps in the whole data set are the worst?</a></li>
  <li><a href="#oxymorons">Which apps lie subtly about the nature of data they collect?</a></li>
</ol>

<p>But first let’s have a quick look at the data set.</p>

<p><em>Note: The images in this post can be clicked to show larger versions</em></p>

<p><a href="https://hugotunius.se/img/app-privacy/data-collected-histogram-plot.svg"><img src="https://hugotunius.se/img/app-privacy/data-collected-histogram-plot.svg?1609805186" alt="Histogram plot of data types collected. The apps that collect zero such data types dominate"></a></p>

<p>As we can see here, most apps collect no data outside of that which supports the app’s functionality. To get a better view of the apps that do collect data, let’s remove the majority of apps that don’t.</p>

<p><a href="https://hugotunius.se/img/app-privacy/data-collected-histogram-non-zero-plot.svg"><img src="https://hugotunius.se/img/app-privacy/data-collected-histogram-non-zero-plot.svg?1609805186" alt="Histogram plot of data types collected with zero values removed."></a></p>

<p>Still the amount of data collected is fairly low, but there’s a curious set of outliers somewhere around 120 data types collected. All of those outliers have something in common, see if you can figure it out before I reveal the answer later in the post.</p>

<p>How about third party tracking?</p>

<p><a href="https://hugotunius.se/img/app-privacy/ttp-histogram-plot.svg"><img src="https://hugotunius.se/img/app-privacy/ttp-histogram-plot.svg?1609805186" alt="Histogram plot of third party tracking data types collected. The apps that collect zero such data types dominate"></a></p>

<p>Again most apps don’t collect any data types for third party tracking. Let’s repeat the process from above by removing those that do no tracking.</p>

<p><a href="https://hugotunius.se/img/app-privacy/ttp-histogram-non-zero-plot.svg"><img src="https://hugotunius.se/img/app-privacy/ttp-histogram-non-zero-plot.svg?1609805186" alt="Histogram plot of third party tracking data types collected with zero values removed."></a></p>

<p>Now that we have an overview of …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html">https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html</a></em></p>]]>
            </description>
            <link>https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628543</guid>
            <pubDate>Mon, 04 Jan 2021 07:11:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tyranny of Ideas (2019}]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628432">thread link</a>) | @axiomdata316
<br/>
January 3, 2021 | https://nadiaeghbal.com/ideas | <a href="https://web.archive.org/web/*/https://nadiaeghbal.com/ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ?="">
        <p>China Miéville’s novel <em>Embassytown</em> describes a world in which an alien species, the Ariekei, becomes enthralled by a human’s ability to speak their language. What starts out as novelty gives way to obsession, and they become addicted to his voice, their lives falling to pieces, wandering the streets like zombies, tearing the world apart in search of more “god-drug”. Their obsession has nothing to do with the person behind it, but rather the thing he can provide.</p>

<p>Lately, I’ve amused myself by operating through the lens that the world is run by ideas, rather than people. We tend to discuss <a href="https://en.wikipedia.org/wiki/Memetics">mimetic effects</a> in relation to mass <em>consumption</em> – its distributive effects – but less-frequently discussed is how mimetics affect creators themselves.</p>

<p>I like thinking of people as vessels, which provides a refreshing counterbalance to the well-trodden <a href="https://en.wikipedia.org/wiki/Great_man_theory">“great man theory”</a>. Rather than viewing people as agents of change, I think of them as intermediaries, voice boxes for some persistent idea-virus that’s seized upon them and is speaking through their corporeal form. You might think of this as <em>“great prophet theory”</em>.</p>

<p>Ideas ride us into battle like warhorses. We can witness, participate in, and even lead these battles, but their true meaning eludes us. We don’t really know where ideas come from, nor how to control them.</p>

<h2 id="birthing-new-ideas">Birthing new ideas</h2>

<p>Consider the obsessiveness with which creators birth new ideas into the world, which we’ve clinically termed <em>“intrinsic motivation”</em>, but don’t really seem to understand beyond that. We can observe that it is happening, but we don’t know what actually <em>causes</em> someone to drive themselves nearly to death just so they can give an idea a beating heart and a chance at survival in the world. <em>“Because I had to”</em> or <em>“Because I couldn’t stop thinking about it”</em> are symptoms, not causes.</p>

<p><img src="https://nadiaeghbal.com/assets/img/ideas/goodyear.png" alt="goodyear">
<em>One of my favorite recent examples. <a href="https://twitter.com/rivatez/status/1115627936411815937">Via Twitter</a></em></p>

<p>Once ideas find an audience, they’re hard to eradicate. Many a surprised creator has found that they’ve lost control over an idea, watching helplessly as it’s shaped and reinterpreted in ways they didn’t intend.</p>

<p>It is enormously difficult for a successful creator to escape their own idea, because ideas need hosts to survive. Their audience owns them now: creators become like the god-drug to the Ariekei, delivering their goods to a babbling crowd that frantically demands more, more.  The creator must battle their own idea in order to survive, taming it back into submission, or risk being subsumed by its demands.</p>

<p>For whatever reason, I often think about Lil Wayne’s rock album <a href="https://en.wikipedia.org/wiki/Rebirth_(Lil_Wayne_album)"><em>Rebirth</em></a> here, perhaps because the title is so wistfully aspirational. Lil Wayne tried in vain to “rebirth” himself, but he was widely panned by an audience that wanted him to produce rap, not rock. Because of his prior success, Lil Wayne became a vessel for a certain type of sound that we craved more of. He became “that person” for “that idea”.</p>

<h2 id="the-constraints-of-reputation">The constraints of reputation</h2>

<p>Even after an idea becomes sufficiently popular to survive in the world without a host, it’s still difficult for creators to escape them, because ideas bond to their hosts in the form of <em>reputation</em>, like a virus that lives in one’s body forever. Reputation is the aggregation of ideas that have swarmed your body. Reputation is a list of your chronic afflictions.</p>

<p>It’s strange to think that personal reputation is becoming simultaneously more and less valuable today. Reputation is the currency that powers our social systems – a symbol of your unique value – but at the same time, it’s easier than ever to find substitutes for a particular sound, style, aesthetic, or way of thinking. I think it’s a sign that ideas are winning over people, or perhaps just making their tyranny better known to us, an ominous signal flare shot into the sky.</p>

<p>The way in which we listen to music, for example, has changed. We don’t listen to entire albums as much as we used to. We don’t know as much about artists as we used to. Instead, we combine and recombine until we find precisely the sound we’re looking for, pumping god-drug into our veins, without really caring who’s behind it. Like an artist on an autogenerated Spotify playlist, my “thing” is interchangeable with a lot of other people’s “things” that would give my audience the same fix.</p>

<p>Returning to the Lil Wayne example, if Lil Wayne ever put his foot down and decided to stop making rap, we’d find another artist just like him, someone else who satisfies our desires. Lil Wayne commands an audience when it comes to rap. But his reputation is a devil’s contract: continue to make the same thing, and you’ll be rewarded, but don’t stray too far from the original concept.</p>

<p>Similarly, when an exceptional artist meets an untimely death, we don’t necessarily mourn them because of who they are. After all, we only really know their identity through the lens of the thing they produced for us. We mourn them because their product is scarce, and we can no longer get our fix. When someone says, e.g. <em>“Nobody ever played guitar like Jimi Hendrix”</em>, they’re saying that they crave a sound that feels hard to find elsewhere, not that they miss Jimi Hendrix himself.</p>

<p>Reputation has local value – it’s what distinguishes you within your world – but global demand for most people’s output is fairly elastic. In order to give people what they want, reputation is commoditized, bundled and traded on a global market. Spotify Discover Weekly satisfies the consumer by commodifying the creator. Today, internet creators can build up large audiences without ever becoming truly famous; they may command substantial local power, but their global value is very narrow.</p>

<h2 id="regaining-control">Regaining control</h2>

<p>How do creators preserve optionality? How do they maintain separation between themselves and their ideas, and avoid being consumed by demand?</p>

<p>One approach is to resist definition entirely, which seems like the obvious answer, but is hard to actually pull off well, because it requires engaging in constant battle against the many ideas that will inevitably swarm you. Still, some people find this to be a fun challenge in itself, requiring quite a bit of stealth to swim among the dark ocean depths without being detected.</p>

<p>The more I’ve kept an eye out for this approach, the more examples I’ve noticed among public figures. They’re the ones who always seem to keep coming up with interesting ideas, the generative thinkers that everyone likes to marvel at, but who manage to say a lot and a little at the same time. Kanye West is the canonical example that comes to mind: it’s hard to pin down what exactly he does, or what he thinks about, and yet the things he does seem uniquely “Kanyesque”.</p>

<p>The second approach is to compartmentalize, which is more tedious to manage, but probably easier for most to pull off. We tend to assume that people use pseudonyms or alts for privacy reasons. But alts aren’t always about hiding who you are, but rather keeping your ideas separate from some root identity (ex. one’s legal name), so that you can still remember who you are when the ideas aren’t riding you. [1]</p>

<p>Sex worker Stoya <a href="https://www.nytimes.com/2014/03/09/opinion/sunday/can-we-learn-about-privacy-from-porn-stars.html">once likened her choice</a> of an alt to “deciding on a user name for any Internet service or website”:</p>

<blockquote>
  <p>My stage name is less about withholding parts of myself or maintaining privacy than it is a symbol of the idea that I am more than just my job or any other isolated slice of my identity.</p>
</blockquote>

<p>My favorite example of this: a friend, who’s a mother of two, recently reflected that her daughter started calling her by her first name, because she wanted to know who she was beyond being her mom. The terms “mom” and “dad” are alts that protect the self, who exists <em>a priori</em> to being a parent.</p>

<p><img src="https://nadiaeghbal.com/assets/img/ideas/multiple-bios.png" alt="multiple bios">
<em>Compartmentalizing: multiple bios for multiple selves. <a href="https://lee94josh.com/About-Me">Via Josh’s website</a></em></p>

<p>Finally, to some extent, I find something sort of satisfying about accepting that ideas have a life of their own. Wielded carefully, they can shield, rather than drain, the creator. For example, actors and directors sometimes talk about making a big box-office hit, so they can do their artsy side project without feeling pressure to pander to an audience. If everyone manages a portfolio of ideas, some will be cash cows, some are risky bets, and others will be just for fun.</p>

<p>Ideas are fascinators that sparkle and dangle in front of the creator, distracting an eager audience from the person behind the curtain. Submitting to the tyranny of ideas gives us the freedom to explore who we are apart from our public reputations. If ideas are living entities that exist separately from our selves, what remains of us?</p>

<h3 id="notes">Notes</h3>

<p>[1] I am skeptical that alts don’t creep into your root identity anyway, but at least you can switch between modes in a more explicit way.</p>

    </div></div>]]>
            </description>
            <link>https://nadiaeghbal.com/ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628432</guid>
            <pubDate>Mon, 04 Jan 2021 06:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making sense of what happened is hard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25628392">thread link</a>) | @kiyanwang
<br/>
January 3, 2021 | https://surfingcomplexity.blog/2021/01/02/making-sense-of-what-happened-is-hard/ | <a href="https://web.archive.org/web/*/https://surfingcomplexity.blog/2021/01/02/making-sense-of-what-happened-is-hard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><a href="https://twitter.com/scottnasello">Scott Nasello</a> recently introduced me to Dr. Hannah Harvey’s <a href="https://www.thegreatcoursesplus.com/the-art-of-storytelling-from-parents-to-professionals">The Art of Storytelling</a>. I’m about halfway through her course, and I absolutely love it, and I keep thinking about it in the context of learning from incidents. While I have long been an advocate of <a href="https://surfingcomplexity.blog/2019/08/24/in-service-of-the-narrative/">using narrative structure when writing up incidents</a>, Harvey’s course focuses on oral storytelling, which is a very different sort of format. </p>



<p>In this context, I was thinking about an operational surprise that happened on my team a few months ago, so that I could use it as raw material to construct an oral story about it. But, as I reflected on it, and read my own (lengthy) writeup, I realized that there was one thing I didn’t fully understand about what happened.</p>



<p>During the operational surprise, when we attempted to remediate the problem by deploying a potential fix into production, we hit a latent bug that had been merged into the main branch ten days earlier. As i was re-reading the writeup, there was something I didn’t understand. How did it come to be that we went ten days without promoting that code from the main branch of our repo to the production environment?</p>



<p>To help me make sense of what happened, I drew a diagram of the development events that lead up to the surprise. Fortunately, I had documented those events thoroughly in the original writeup. Here’s the diagram I created. I used this diagram to get some insight into how bug T2, which was merged into our repo on day 0, did not manifest in production until day 10.</p>



<p>This diagram will take some explanation, so bear with me. </p>



<figure><a href="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg"><img data-attachment-id="1725" data-permalink="https://surfingcomplexity.blog/diagram-2/" data-orig-file="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg" data-orig-size="1452,1122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="diagram" data-image-description="" data-medium-file="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=300" data-large-file="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=1024" src="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=1024" alt="" srcset="https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=1024 1024w, https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=150 150w, https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=300 300w, https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg?w=768 768w, https://lorinhochstein.files.wordpress.com/2021/01/diagram.jpg 1452w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>There are four bugs in this story, denoted T1,T2, A1, A2. The letters indicate the functionality associated with the PR that introduced them: </p>



<ul><li>T1, T2 were both introduced in a pull request (PR) related to refactoring of some functionality related to how our service interacts with <a href="https://netflix.github.io/titus/">Titus</a>.  </li><li>A1, A2 were both introduced in a PR related to adding functionality around artifact metadata.</li></ul>



<p>Note that bug T1 masked T2, and bug A1 masked A2.</p>



<p>There are three vertical lines, which show how the bugs propagated to different environments.</p>



<ul><li><em>main (repo)</em> represents code in the main branch of our repository.</li><li><em>staging</em> represents code that has been deployed to our staging environment.</li><li><em>prod</em> represents code that has been deployed to our production environment.</li></ul>



<p>Here’s how the colors work:</p>



<ul><li><em>gray</em> indicates that the bug is present in an environment, but hasn’t been detected</li><li><em>red</em> indicates that the effect of a bug has been observed in an environment. Note that if we detect a bug in the prod environment, that also tells us that the bug is in staging and the repo.</li><li><em>green</em> indicates the bug has been fixed</li></ul>



<p>If a horizontal line is red, that means there’s a known bug in that environment. For example, when we detect bug T1 in prod on day 1, all three lines go red, since we know we have a bug.</p>



<p> A horizontal line that is purple means that we’ve pinned to a specific version. We unpinned prod on day 10 before we deployed.</p>



<p>The thing I want to call out in this diagram is the color in the <em>staging </em>line. once the <em>staging</em> line turns red on day 2, it only turns black on day 5, which is the Saturday of a long weekend, and then turns red again on the Monday of the long weekend. (Yes, some people were doing development on the Saturday and testing in staging on Monday, even though it was a long weekend. We don’t commonly work on weekends, that’s a different part of the story). </p>



<p>During this ten day period, there was only a brief time when staging was in a state we thought was good, and that was over a weekend. Since we don’t deploy on weekends unless prod is in a bad state, it makes sense that we never deployed from staging to prod until day 10.</p>



<p>The larger point I want to make here is that getting this type of insight from an operational surprise is <em>hard</em>, in the sense that it takes a lot of effort. Even though I put in the initial effort to capture the development activity leading up to the surprise when I first did the writeup, I didn’t gain the above insight until months later, when I tried to understand this particular aspect of it. I had to ask a certain question (how did that bug stay latent for so long), and then I had to take the raw materials of the writeup that I did, and then do some diagramming to visualize the pattern of activity so I could understand it. In retrospect, it was worth it. I got a lot more insight here than: “root cause: latent bug”.</p>



<p>Now I just need to figure out how to tell this as a story without the benefit of a diagram.</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2021-01-02T14:42:29-08:00">January 2, 2021</time><time datetime="2021-01-02T14:45:49-08:00">January 2, 2021</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://surfingcomplexity.blog/2021/01/02/making-sense-of-what-happened-is-hard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628392</guid>
            <pubDate>Mon, 04 Jan 2021 06:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Emilua to Node.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25628180">thread link</a>) | @delduca
<br/>
January 3, 2021 | https://emilua.gitlab.io/blog/post/comparing-emilua-to-nodejs/ | <a href="https://web.archive.org/web/*/https://emilua.gitlab.io/blog/post/comparing-emilua-to-nodejs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <div>
<p><img src="https://emilua.gitlab.io/blog/node.png" alt="node">
</p>
</div>
<p>Emilua is an execution engine for Lua. It fills a role similar to NodeJS for
Javascript. Apart from being an execution engine, the two have leaps and leaps
of differences.</p>
<p>I believe a good first post for this blog would be to clarify the differences
between NodeJS and Emilua. NodeJS is very popular and people try to port its API
to different
languages<sup>[<a id="_footnoteref_1" href="#_footnote_1" title="View footnote.">1</a>]</sup><sup>[<a id="_footnoteref_2" href="#_footnote_2" title="View footnote.">2</a>]</sup><sup>[<a id="_footnoteref_3" href="#_footnote_3" title="View footnote.">3</a>]</sup>. Even
non-users of Javascript know NodeJS. By describing Emilua in terms of
differences against NodeJS I hope to offer a turbo heads-up. Comparisons also
offer me the opportunity to touch on many other topics that I enjoy.</p>
<p>I’ll also try to make it brief. If needed be, links to some lengthy posts from
other authors that already covered the topic in detail will be included.</p>
<div>
<h2 id="_one_color">One color</h2>
<div>
<p>The first difference is Emilua’s commitment to avoid
<a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">Bob
Nystrom' two colors problem</a>. The problem has been extensively covered
elsewhere:</p>

<div>
<p>NodeJS redundant interfaces</p>
<div>
<pre><code data-lang="javascript">tls = require('tls');
fs = require('fs');

options = {
    // sync interfaces
    key: fs.readFileSync('server-key.pem'),
    cert: fs.readFileSync('server-cert.pem')
};

// async interfaces
server = tls.createServer(options, function(socket) {
    // ...
});</code></pre>
</div>
</div>
<p>In a nutshell, every function in Emilua has the ability to suspend the caller
function. The runtime will schedule every fiber behind the scenes, and you don’t
need to wrap the function operator call based on the resources the callee will
make use of.</p>
<p>Whereas manuals from some frameworks will instruct you to annotate every call
that might block with <code>await</code>…​</p>
<div>
<p>Pseudocode example on <code>await</code></p>
<div>
<pre><code>n = await read(sock, buf);
await write(sock, buf[:n]);
// ...</code></pre>
</div>
</div>
<p>Emilua won’t force you to do the same. IO scheduling is a transparent
resource. IO scheduling is not part of the function type signature. You don’t
need to break the API just because your function implementation just now
requires IO activity.</p>
</div>
</div>
<div>
<h2 id="_is_it_a_coroutine_or_is_it_a_fiber">Is it a coroutine…​ or is it a fiber?</h2>
<div>
<p>The previous point may have been extensively debated, and it was in this debate
that comparisons among the following styles was appropriate:</p>
<div>
<ul>
<li>
<p>Events and polling.</p>
</li>
<li>
<p>Callbacks.</p>
</li>
<li>
<p>Signals &amp; slots.</p>
</li>
<li>
<p>Observers.</p>
</li>
<li>
<p>Promises.</p>
</li>
<li>
<p>Functional patterns.</p>
</li>
<li>
<p>Coroutines.</p>
</li>
</ul>
</div>
<p>But Emilua is built around fibers and it is inappropriate to compare fibers and
the previous choices. I’ll now compare fibers and coroutines to make this subtle
point.</p>
<p>Coroutines may be an old concept that suggest language constructs capable to
suspend and resume a function
context<sup>[<a id="_footnoteref_4" href="#_footnote_4" title="View footnote.">4</a>]</sup>, but fibers come from attempts to
provide user-space threads, and, as such, will adhere to threads vocabulary. The
presence of threads vocabulary imply a scheduler (i.e. if you call
<code>mutex.lock()</code>, your code doesn’t need to know which fiber to awake next as this
will be taken care of by the scheduler). This difference is noted by authors of
fiber libraries, but rarely stated explicitly, so it’s worth to link one of the
few texts that make explicit the difference:</p>
<div>
<blockquote>
<p>The difference between a fibers facility and just coroutines is that with
fibers, you have a scheduler as well.</p>
</blockquote>

</div>
<p>The difference is important because if you have threads vocabulary, you have not
only vocabulary to express concurrent tasks, but also vocabulary to tame this
very concurrency with mutexes, condition variables, and the like. None of the
previous options of this list — callbacks, promises, coroutines, etc — had such
sync primitives.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
What Ruby calls fibers…​ well, they are nice and all, but I don’t believe
they understood the concept, so ping them about it.
</td>
</tr>
</tbody></table>
</div>

<p>Here’s a small example, an implementation for the very simple socket-pair
algorithm. First in NodeJS:</p>
<div>
<div>
<pre><code data-lang="javascript">var net = require('net');

function socket_pair(callback) {
    var result = {}

    var server = net.createServer(function(sock) {
        server.close()
        if (result.err) {
            return
        }
        if (result.sock) {
            callback(null, [ sock, result.sock ])
        } else {
            result.sock = sock
        }
    })

    server.on('error', function(err) {
        if (result.err) {
            return
        }
        result.err = err
        callback(err)
    })

    server.listen(0, '127.0.0.1', function() {
        var sock = new net.Socket()
        sock.connect(server.address().port, '127.0.0.1', function() {
            if (result.err) {
                return
            }
            if (result.sock) {
                callback(null, [ sock, result.sock ])
            } else {
                result.sock = sock
            }
        })
        sock.on('error', function(err) {
            if (result.err) {
                return
            }
            server.close()
            result.err = err
            callback(err)
        })
    });
}</code></pre>
</div>
</div>
<p>Do notice how NodeJS’s lack of sync primitives forces you to write your own
synchronization (the <code>result</code> rendezvous point in the example). Now take a look
at how Emilua will make the task much simpler by enabling you to use the
<code>fiber.join()</code> sync vocabulary:</p>
<div>
<div>
<pre><code data-lang="lua">local ip = require 'ip'

function socket_pair()
    local acceptor = ip.tcp.acceptor.new()
    local addr = ip.address.loopback_v4()
    acceptor:open(addr)
    acceptor:bind(addr, 0)
    acceptor:listen()

    local f = spawn(function()
        local sock = ip.tcp.socket.new()
        sock:connect(addr, acceptor.local_port)
        return sock
    end)

    local sock = acceptor:accept()
    acceptor:close()
    return sock, f:join()
end</code></pre>
</div>
</div>
<p>And there is a little something else. Preemptiveness isn’t a property exclusive
to OS-provided threads. Runtimes from some languages will manage to deliver just
this property to fibers as well. Emilua will stay out of preemptiveness
(i.e. you’re guaranteed to have a safer environment) just like many others. But
if you’re restricted to cooperative multitasking, you managed to migrate some
scheduling decisions from runtime to compile-time. Most frameworks will stop
here, but Emilua will go just one mile further.</p>
<p>If you moved some scheduling decisions to compile-time, it makes sense to also
move sync primitives to compile-time…​ or, rather…​ <em>scheduling
constraints</em>. Ideally, your code wouldn’t compile when these constraints aren’t
respected. I’m not there yet and there are static analysers waiting to be
written, but the vocabulary to encode the user expectation in Lua is here. The
vocabulary works like C’s <code>assert()</code>. One alternative would be to just rely on
<code>mutex</code>es as usual, but there are these little abusers — like me — of
deterministic suspension points that you’ll never tame, so I’m adding this
little tool anyway to prevent further damage.</p>
</div>
</div>
<div>
<h2 id="_opinionated_concurrency_style">Opinionated concurrency style</h2>
<div>
<p>Bob Nystrom’s warning about two colors wasn’t enough.</p>
<div>
<blockquote>
<p>Choose your async model; we don’t mind; we encourage experimentation.</p>
<p>If you don’t like callbacks and event emitters, use coroutines and write
blocking style code without actually blocking your event loop!</p>
</blockquote>

</div>
<p>From experience with Boost.Asio, I noticed that you can’t just defer the choice
to the user and get rid of making one. What happened to Boost.Asio is that you
cannot appropriately support any one model.</p>
<div>
<ul>
<li>
<p>Limitations from one model infect other models (e.g. orientation towards IO
objects and not threads). This point by itself could give a lengthy article,
but nowadays I’m less concerned with convincing people and more concerned with
respecting my own precious time, so you’ll only have my word here.</p>
</li>
<li>
<p>You cannot rely on the strengths that are exclusive to one model (e.g. disable
interruption at critical blocks). It may seem redundant with the previous
point because it’s just another face of the same coin.</p>
</li>
<li>
<p>You just created a new model. <em>Your “unopinionated” model is a meta-model</em>
that forces every library provider to write convoluted code. Again, another
lengthy article that will not receive a share of my time. If you’re curious,
try looking for libraries built around Boost.Asio that work with the
completion token protocol.</p>
</li>
</ul>
</div>
<p>Emilua cares about serving one concurrency style and serving it well: fibers.</p>
<div>
<blockquote>

<p>Boost.Fiber doesn’t need fibers::future::then - just suspend the fiber. If
you need more concurrency than that, launch another fiber. then() is
redundant with coroutine and fiber concurrency.</p>
</blockquote>
<p>
— Nat Goodspeed<br>
<cite>Boost mailing list, 2018</cite>
</p>
</div>
</div>
</div>
<div>
<h2 id="_active_style">Active style</h2>
<div>
<p>A friend of mine teached me this principle early on that affected all my future
projects: <em>design your abstractions where the user is an active party on
scheduling decisions</em>. I’ve been calling it the active style and people usually
don’t get it what it is about, but consequences of this design are better
understood (e.g. <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">dealing with
back-pressure</a>).</p>
<p>Ryan Dahl’s successor for NodeJS also got this point covered:</p>
<div>
<blockquote>
<p>Node’s counterpart to promises was the EventEmitter, which important APIs are
based around, namely sockets and HTTP. Setting aside the ergonomic benefits of
async/await, the EventEmitter pattern has an issue with back-pressure. Take a
TCP socket, for example. The socket would emit "data" events when it received
incoming packets. These "data" callbacks would be emitted in an unconstrained
manner, flooding the process with events. Because Node continues to receive new
data events, the underlying TCP socket does not have proper back-pressure, the
remote sender has no idea the server is overloaded and continues to send
data. To mitigate this problem, a pause() method was added. This could solve the
problem, but it required extra code; and since the flooding issue only presents
itself when the process is very busy, many Node programs can be flooded with
data. The result is a system with bad tail latency.</p>
</blockquote>

</div>
</div>
</div>
<div>
<h2 id="_emilua_is_more_explicit">Emilua is more explicit</h2>
<div>
<p>Emilua is also just more explicit. Many years ago, NodeJS actually
attracted me. Its API (at the time) was better than the HTTP server libs that
I’d design. It helped to push me forward. Unfortunately it feels like it stopped
in time and didn’t preserve this "pusher" feeling.</p>
<p>What attracted me at the time was its lower-level approach to web protocols. I</p></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilua.gitlab.io/blog/post/comparing-emilua-to-nodejs/">https://emilua.gitlab.io/blog/post/comparing-emilua-to-nodejs/</a></em></p>]]>
            </description>
            <link>https://emilua.gitlab.io/blog/post/comparing-emilua-to-nodejs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25628180</guid>
            <pubDate>Mon, 04 Jan 2021 05:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Competitive Ethics: FiveThirtyEight for Morality]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25627688">thread link</a>) | @mwcvitkovic
<br/>
January 3, 2021 | https://milan.cvitkovic.net/writing/ethics/ | <a href="https://web.archive.org/web/*/https://milan.cvitkovic.net/writing/ethics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <blockquote>
<p>If antinatalists are right that having children is wrong, does it matter once the antinatalists go extinct?</p>
</blockquote>
<blockquote>
<p>If you build an “ethical” AI that keeps getting deleted by its “unethical” AI peers,
have you accomplished your mission of building ethical AI?</p>
</blockquote>
<blockquote>
<p>Is religious tolerance a fatal flaw in liberal democracy if religions with illiberal doctrines can always become a majority?</p>
</blockquote>
<blockquote>
<p><strong>If we’re going to think hard about what’s right, shouldn’t we also think hard about what wins?</strong></p>
</blockquote>
<hr>
<p><em>Competitive ethics</em> (I’d be happy to find a better term) is the study of ethical ideas as strategies or phenotypes
that are competing for mindshare.  This is opposed to the usual study of ethics,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> which is concerned with what’s right and what’s wrong.</p>
<blockquote>
<p><strong>Competitive ethics is to morality as FiveThirtyEight is to politics.</strong></p>
</blockquote>
<p>FiveThirtyEight doesn’t tell us which candidate’s positions are correct, and we don’t expect them to.
We expect them to tell us who will win.</p>
<p>Unlike applied ethics (“How should I act in this specific situation?"),
normative ethics (“What criteria should I use to do applied ethics?"),
or meta-ethics (“How should I think about normative ethics?"), competitive ethics is amoral.
Not immoral: amoral.
It’s not concerned with right and wrong, just with predictions and understanding.</p>
<h3 id="how-ethics-compete">How ethics compete</h3>
<p>There are many lines of thinking relevant to this question, but I can’t find any that address it directly.</p>
<p>The most relevant are cultural selection theory, memetics, and neoevolution, though these
are too tied up with evolutionary theory.
The subfields of <a href="https://plato.stanford.edu/entries/morality-biology/">evolutionary ethics</a> and <a href="https://plato.stanford.edu/entries/game-ethics/">game-theoretic ethics</a>
stick to normative or occasionally meta-ethical questions, and don’t seem to have studied what happens when ethical
systems go toe-to-toe.</p>
<p>Other work studies the relationship between the ethics people espouse, the ethics they consciously believe, and how they actually behave.
All three can, of course, be quite distinct.
<a href="https://en.wikipedia.org/wiki/Preference_falsification">Preference falsification</a>, social contagion theory, and behavioral economics are the relevent disciplines here.
Even <a href="https://heinonline.org/HOL/LandingPage?handle=hein.journals/arzjl19&amp;div=9&amp;id=&amp;page=">the legal profession</a> has touched on this.
Professed ethics are the fastest to change, <em>a la</em> preference falsification.
It’s an open question whether or not ethical beliefs change faster than behavior.</p>
<p>Another important issue is the fuzzy line between biologically-determined preferences and ethics.
The former clearly influence the latter in a single individual, and the latter influences the former across generations.
Plus, the more technology lets us intervene on biology, the fuzzier the line gets.
Wibren Van Der Berg’s <a href="https://www.semanticscholar.org/paper/Dynamic-Ethics-Burg/0e8a2f0d733e97a2fb8b226c89679518ef6606fa#citing-papers">Dynamic Ethics</a> is the closest work to addressing this, though it’s a work of normative ethics.
He says for example: “Our dynamic society requires a dynamic morality and thus a form of ethical
reflection which can be responsive to change.”
A <a href="https://www.semanticscholar.org/paper/Nanotechnology-and-Technomoral-Change-Swierstra/8b9bc75dd29727959f2182ab9ce363419e2bd548">few</a>
<a href="https://www.semanticscholar.org/paper/Anticipating-the-Interaction-between-Technology-and-Boenink-Swierstra/3211402ba6d43e414b23ad5b51d15421a876f141">others</a> have touched this question, but not many.</p>
<p>One interesting problem framing is ethics as a distributed or hierarchical controller, in the control theory sense.
This brings a host of ideas to the discussion about what might make ethical systems more or less stable, including Good System theories (e.g. <a href="http://pespmc1.vub.ac.be/books/Conant_Ashby.pdf">“every good regulator of a system must be a model of that system”</a>),
the potential optimality of false beliefs,
and the advantageous of certain types of internal variability.</p>
<h3 id="case-studies">Case studies</h3>
<h4 id="natalism-and-heritability">Natalism and heritability</h4>
<p>The most straightforward way ethical systems compete is by the degree of natalism and heritability they entail:
how many offspring do their believers produce, and how effectively are they passed from parents to children?</p>
<p>The best recent work on this topic is from demographers like Eric Kaufmann.
In his book <a href="https://www.amazon.com/Shall-Religious-Inherit-Earth-Twenty-First-ebook/dp/B004DL0OCG/">Shall the Religious Inherit the Earth?</a>,
Kaufmann lays out the remarkable growth trends of religious fundamentalist groups in the modern world.
Fundamentalist religious groups whose ethics encourage high fertility and strict adherence to the faith are contrasted with
modern Western cultures whose ethics deride (or at least don’t encourage) fertility and encourage freedom of thought.
Norms against homosexuality are also relevant to this question, at least in a world where homosexual couples have no or low fertility.</p>
<p>Most fundamentalist groups rely on the generosity of their host society to flourish as they do — e.g.
the ultraorthodox in Israel, who generally don’t have jobs — so it’s not clear when this will hit the breaking point.
Additionally, different natalist groups have differing success in retaining members: the ultraorthodox seem good at it, movements like quiverfull seem less so.
While I’m biased to think ethics of free thought are more attractive than ultraorthodox ethics, ethics of free thought combined with low fertility may not be sustainable.
After all, <a href="https://jcl.algosphere.org/abstract-child.pdf">nothing reproduces better than reproduction</a>.</p>
<p>More broadly than religion, there is a correlation between female power in society — especially regarding control over reproduction — and lower natality.
This is a bit worrying for the future of women’s rights, especially if male power is correlated to both natalism <em>and</em> warlike or proselytizing behavior.
Then again, weapons technology and fertility technology may completely change these dynamics.</p>
<h4 id="euthenasia-and-suicide">Euthenasia and suicide</h4>
<p>Norms against euthenasia and suicide are a counterpart to natalism.
One would expect such beliefs to be excellent at propagating themselves,
yet many cultures have practices of euthenasia or ritual suicide, so the competitiveness of such norms is not clear-cut.</p>
<p>Relatedly, anti-suicide ideas — Camus’s absurdism, perhaps — may have an interesting niche:
if you’re the only idea keeping someone alive, you’ve got an (at least temporary) monopoly on their life.</p>
<p>Would a society that fully embraced euthenasia and destigmatized suicide suffer the same fate as an antinatalist society?
I suspect it would be composed mostly of people who wanted to be alive, which could work in its favor.
But in the face of a changing world that might quickly become not-fun-to-live-in, perhaps anti-death norms are more competitive in the long run.
Then again, one might only need a <a href="https://www.nature.com/articles/nature08504">minority of the population to maintain these norms</a> to get most of the benefit.</p>
<h4 id="nihilism-and-motivation">Nihilism and motivation</h4>
<p>I know of no work studying the comparative effects of ethical belief systems on motivation.
In fact, I don’t know whether it’s demonstrable that motivated individuals are more successful.
But assuming it does, and assuming ethics like moral nihilism demotivate people (or at least fail to motivate them), the long-term viability of these ethical systems is questionable.
Going further, it may be that selfish ethical systems (e.g. Ayn Rand, Gordon Gekko) are more associated with motivation and success than
egalitarian ethical systems.</p>
<p>Causality and correlation are hard to tease apart here, but doing so isn’t necessary.
An ethical system can win both by granting success to its holders or by being adopted by successful individuals.</p>
<h4 id="exclusivity-and-conversion-rates">Exclusivity and Conversion Rates</h4>
<p>Much like a sales team, the success of an ethical belief is determined by its conversion rate and its retention rate.
These two factors are sometimes at odds: exclusive ideologies often have higher retention rates, but inclusive ideologies are easier to join.</p>
<p>Take the far-left vs. the far-right in the US.
Social justice movements with ethics of “it’s not my job to educate you” probably repel many potential converts, but they provide their adherents with a feeling of being in an exclusive club.
On the other hand, I’ve heard that far-right groups are much more welcoming to newcomers — or at least willing to explain their doctrine and answer questions — than far-left groups.</p>
<p>The old question “Why aren’t there any libertarian states?” also comes to mind.</p>
<h4 id="ai-alignment">AI alignment</h4>
<p>Eliezer Yudkowsky is purported to have said “You are personally responsible for becoming more ethical than the society you grew up in.”
This quotation is interesting in that (1) it’s a normative claim about normative claims, and (2) it assumes that ethics has a direction.</p>
<p>While I like the sentiment, it’s reminiscent of when people make biologists cringe by saying things like “humans are more evolved than snails.”
Evolution doesn’t have a partial ordering by which some species can be more or less evolved than others.
From the competitive ethics perspective, neither do ethics.</p>
<p>Most people who work in AI alignment <a href="https://www.lesswrong.com/posts/GermiEmcS6xuZ2gBh/what-ai-safety-researchers-have-written-about-the-nature-of">treat human values</a> the way scientists treat complex systems they can’t fully model: there exist some true, foundational human ethics, and while we can’t articulate them, we can still try to hue to them.
I’m far from convinced that these true, foundational human ethics exist.
And even if you think you’ve found them, if the AI you build according to them keeps getting deleted by its â€œunethicalâ€� AI peers, have you accomplished your mission of building ethical AI?</p>
<p>I have trouble engaging with AI alignment research that doesn’t put competitive ethical questions front and center.</p>
<h4 id="when-you-can-truly-change-your-mind">When you can truly change your mind</h4>
<p>The entire AI alignment section applies to human beings, too, in a future where people can change their beliefs with neurotechnology.</p>
<h3 id="extensions-of-competitive-ethics">Extensions of competitive ethics</h3>
<p>Competitive ethics on its own is amoral.
But it can be a building block for other ideas.</p>
<p>Consider a meta-ethics — call it <em>ethical consistentism</em> maybe — where the probability of a moral statement being correct is proportional to its survival.
To be clear: this isn’t a creepy social Darwinism or might-makes-right idea since it’s a meta-ethics, not a normative claim.
Or one could propose a a weaker version of this: an ethical system shouldn’t directly or indirectly lead to itself not being believed.
This is analagous to logical consistency in mathematics.
Of course, if we’re going to treat ethical systems as competitive phenotypes, it seems only fair to treat meta-ethical systems (ethical consistentism included) as phenotypes too.  So the recursion begins…</p>
<p>Competitive ethics is also sortof nihilism 2.0, or at least relativism 2.0.
Of course right and wrong are ridiculous …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://milan.cvitkovic.net/writing/ethics/">https://milan.cvitkovic.net/writing/ethics/</a></em></p>]]>
            </description>
            <link>https://milan.cvitkovic.net/writing/ethics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627688</guid>
            <pubDate>Mon, 04 Jan 2021 03:32:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Bury Carbon? Let Plants Do the Dirty Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25627540">thread link</a>) | @prthkms
<br/>
January 3, 2021 | http://cshl.nautil.us/article/657/how-to-bury-carbon-let-plants-do-the-dirty-work | <a href="https://web.archive.org/web/*/http://cshl.nautil.us/article/657/how-to-bury-carbon-let-plants-do-the-dirty-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>F</span>orty-nine million years ago, a small aquatic fern called <em>Azolla</em> wrested control of Earthâ€™s climate. At the time, the landlocked Arctic Ocean developed a surface layer of freshwater, which allowed the ferns to grow unchecked in a wide-open environment. Billions of tons of plants died and sank to the bottom of the ocean, taking with them the carbon they had sucked from the air when they were alive.&nbsp;</p>

<p>The consequences were extreme. Geologic evidence indicates that atmospheric carbon dioxide levels plummeted more than 80 percent over 800,000 years, sharply ratcheting down Earthâ€™s thermostat. Prior to the inferred â€œ<a href="https://www.geolsoc.org.uk/Geoscientist/Archive/June-2014/The-Arctic-Azolla-event" target="_blank">Azolla Event</a>,â€� most of the globe was lush and tropical. Afterward, the Arctic cooled by nearly 40 degrees Fahrenheit, the poles froze, and our planet entered a lurching cycle of ice ages that continue to this day.&nbsp;</p>
<p>The Azolla Event was an environmental catastrophe for life in the Eocene epoch. Today, though, it is a source of inspiration—even optimism—in dealing with human-driven climate change. For years, some researchers have promoted the idea of geoengineering, using technology to offset the effects of carbon emissions. Such schemes are commonly dismissed as pie in the sky, but the Azolla Event suggests otherwise. After all, if a bunch of dumb ferns could naturally perform carbon sequestration on such a tremendous scale, why couldnâ€™t clever humans deliberately do the same thing?&nbsp;</p>
<p>â€œItâ€™s clear that plants have been able to contribute to really big geological events in the Earth's history,â€� says <a href="https://www.cshl.edu/research/faculty-staff/rob-martienssen/" target="_blank">Rob Martienssen</a>, a plant geneticist at <a href="https://www.cshl.edu/">Cold Spring Harbor Laboratory</a> in Long Island. â€œBeing able to harness that power and speed it up seems like a realistic goal to me.â€�&nbsp;</p>

<p><span>P</span>lanting another enormous fern garden in Arctic waters isnâ€™t an option this time around. The <em>Azolla</em> plants saw to that, eliminating their own habitat when they transformed the global climate (humans, take note). As a stand-in, Martienssen has set his sights on duckweed, the ubiquitous, scum-like greenery that spreads across stagnant ponds in summer. â€œJust like <em>Azolla</em>, itâ€™s an aquatic plant that grows extremely rapidly. It really does the same thing,â€� he says.&nbsp;</p>
<p>Each individual duckweed plant consists of little more than a single, oval leaf roughly the size of a grain of rice that floats atop still or slow-moving freshwater. What they lack in size, though, the plants make up for in fortitude. Duckweed is one of the fastest-growing plants on Earth. A colony can double in mass every two days and is so hardy that it can grow in wastewater, according to bioengineer Jay Cheng of North Carolina State University.</p>
<p>Martienssen became intrigued by the extraordinary vigor of duckweed about a decade ago, partnering with Brookhaven National Labs to explore its potential as a raw material for making liquid fuels to replace petroleum. In principle, plant-based fuels would be endlessly renewable and carbon neutral—that is, the plants would absorb just as much carbon during their growth as they would emit when burned, adding no net carbon to the environment. Although he is still pursuing the biofuel angle, supported by a $6.5 million grant from the U.S. Department of Energy, Martienssen has since been bitten by a more radical idea: If we could harvest vast quantities of fast-growing duckweed and dispose of them <em>Azolla</em>-style, we could take their carbon out of the environment entirely.&nbsp;</p>
<blockquote><em>Our climate woes come from burning ancient plants. This would be like reversing the fossil-fuel industry.</em></blockquote>
<p>Step one would be finding a way to transform masses of duckweed into an efficient carbon-absorption machine. Growing normally, aquatic plants like duckweed have been <a href="http://theazollafoundation.org/azollas-uses/as-a-co2-sequester/" target="_blank">estimated</a> to take in up to 10 times as much carbon per acre as a healthy forest—good, but not good enough. In an industrialized setting, Martienssen proposes, engineers could use air-capture technology to pipe in extra carbon dioxide that would boost the plantsâ€™ growth, accelerating the process. â€œWe would grow them in indoor farms with LEDs,â€� he says. â€œWeâ€™d need very little water, since can grow in very shallow water or even in tubes or bags, to produce huge amounts of duckweed.â€�<br></p>
<p>Even so, this would be a long-term project; after all, it took the <em>Azolla</em> ferns 800,000 years to remove most of Earthâ€™s carbon dioxide. Fortunately, we donâ€™t need to go nearly that far. Rolling back modern atmospheric carbon dioxide levels by just 10 percent would have significant climate benefits, and it would reduce the job to the equivalent of 8,000 years of <em>Azolla</em> growth. Intensive cultivation could then speed things up considerably. â€œIf we use an indoor environment with highly enriched carbon dioxide, maybe we could get the number to 80 years,â€� Martienssen says. â€œThese are back-of-the-envelope calculations, but it seems to me that with the right investment and economic incentives, we really could do it,â€� he says.&nbsp;</p>
<p>That would then lead to step two, finding a place to dispose of all that duckweed. Sure, it could be treated like industrial waste and stuffed into airtight containers, but Martienssen is drawn to a more elegant solution. He notes that peat bogs around the world are being systematically drained and burned, destroying valuable ecosystems and further boosting greenhouse emissions. Harvested duckweed could potentially be converted into artificial peat and used to build up the bogs. Once buried, peat remains sequestered for thousands of years or more.</p>
<p>There would be a tidy symmetry in this approach. Much of our current climate woes come from digging up and burning ancient plants that transformed into fossil fuels. â€œMaking synthetic peat deposits would be like reversing the fossil-fuel industry,â€� Martienssen says. â€œIt would be running the process backward and doing something a bit more natural.â€�</p>

<figure><img src="https://s3.amazonaws.com/nautilus-vertical/cshl_2144a9870900c6d23d24f9dec054a0bd.jpg" alt="salk institute"><br></figure>
<figure><figcaption><span>Engineered "ideal plants" are being designed to put carbon into the ground, and keep it there. </span><br><span>Salk Institute</span></figcaption></figure>
<p><span>T</span>he biggest obstacle to using duckweed for climate control is the magnitude of the job. Really, that is the existential obstacle to any proposed geoengineering scheme, because the scale of human greenhouse emissions is so ridiculously vast. Last year, human activities released the equivalent of 43 billion tons of carbon dioxide, according to an&nbsp;<a href="https://www.carbonbrief.org/analysis-global-fossil-fuel-emissions-up-zero-point-six-per-cent-in-2019-due-to-china" target="_blank">analysis</a>&nbsp;by the climate-research group Carbon Brief; thatâ€™s the mass of a good-size mountain. A bit over half that amount gets absorbed the land and water, leaving an extra 19 billion tons floating around in the atmosphere.&nbsp;</p>
<p>As Martienssenâ€™s calculations show, there is no easy way to make that much carbon disappear, even with the help of fast-growing plants. At the Salk Institute for Biological Sciences in La Jolla, California, plant biologist&nbsp;<a href="https://www.salk.edu/scientist/wolfgang-busch/" target="_blank">Wolfgang Busch</a>&nbsp;thinks that Martienssen has the right idea but is approaching it the wrong way, or at least, not the easiest way. Cultivating duckweed would require creating a vast new industry. Busch points out that we already have a global infrastructure of plants that could be adapted to reduce carbon emissions—farms.&nbsp;</p>
<p>â€œIf you reinvent the wheel, it will take a long time. In agriculture, you already have people planting updated seeds every year,â€� he says.&nbsp;</p>
<p>The way itâ€™s practiced today, farming is actually part of the problem. â€œSoil carbon content has been reduced dramatically over the past century in industrialized, monoculture agriculture,â€� Busch explains. The carbon that was stripped out of the dirt has gone straight into the air, contributing significantly to climate change. Meanwhile, the crops themselves are no help. Farmers harvest and till, harvest and till, over and over, cycling carbon in and out of their fields with no net carbon absorption.&nbsp;</p>
<p>In 2017, a group at Salk led by plant biologist Joanne Chory founded the&nbsp;<a href="https://www.salk.edu/harnessing-plants-initiative/" target="_blank">Harnessing Plants Initiative</a>&nbsp;to find ways to make farming part of the solution instead. Busch, an expert in root growth, joined the project and became its co-director. The group soon zeroed in on the idea of genetically altered crops that would put carbon back into the soil, and then keep it there.&nbsp;</p>
<blockquote>As soon as you talk about messing with the plants that people eat, both consumers and producers get worried.</blockquote>
<p>Busch and his group hit on two types of genetic medication that could do just that. Plants could be altered to grow deeper root systems that would leave more of the roots (and their carbon content) buried in the soil after harvest. More dramatically, the Salk researchers realized that they could also engineer crops so that their roots would produce suberin, a waxy compound found in cork. Much like the cork in a wine bottle, fragments of the&nbsp;suberin-infused roots would then take an extremely long time to decompose. Up above, harvesting would go on as usual; down below, the roots of the crops would accumulate in the soil, building up its stored carbon. In essence, every square foot of farmland would become an <em>Azolla</em> event in miniature, entombing a little puff of atmospheric carbon dioxide.&nbsp;<br></p>
<p>Like Martienssen, Busch runs what-if numbers to make his approach could have a meaningful impact. â€œThere's already more than 600 million hectares of cropland worldwide,â€� he says. â€œThere are five target crops we think we can deal with: corn, soy, wheat, rice, canola. We considered that at some point in the future, 70 percent of those crops could be enhanced. Then we asked, â€˜What would happen if we could stabilize 30 percent of the biomass in the root mass?â€™ You end up with 5.5 gigatons of carbon dioxide per year, which is roughly 30 percent of the annual surplus [human emissions] that is leaked in the atmosphere. That was to us encouraging.â€�</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/cshl_156ce010cbc0f9ed987e37bea694500d.jpg" alt="Globe-4g"><figcaption><span>Global croplands (bright green) offer a tremendous area for carbon sequestration. </span><br><span>USGS</span></figcaption></figure>

<p><span>A</span>s soon as you talk about messing with the plants that people eat, Busch knows, both consumers and producers get worried. Will the crops be safe? Will they be just as good to eat? And even if they satisfy those basic …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://cshl.nautil.us/article/657/how-to-bury-carbon-let-plants-do-the-dirty-work">http://cshl.nautil.us/article/657/how-to-bury-carbon-let-plants-do-the-dirty-work</a></em></p>]]>
            </description>
            <link>http://cshl.nautil.us/article/657/how-to-bury-carbon-let-plants-do-the-dirty-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627540</guid>
            <pubDate>Mon, 04 Jan 2021 03:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Great Covid Class War – The Bellows]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25627525">thread link</a>) | @mrfusion
<br/>
January 3, 2021 | https://www.thebellows.org/the-great-covid-class-war/ | <a href="https://web.archive.org/web/*/https://www.thebellows.org/the-great-covid-class-war/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<amp-auto-ads type="adsense" data-ad-client="ca-pub-8554251701278654" i-amphtml-layout="container"></amp-auto-ads> 
<p>On January 19, 2020, Washington state reported the first US case of coronavirus. By the end of March, <a href="https://www.bbc.com/news/world-us-canada-52103066" target="_blank" rel="noreferrer noopener">245 million Americans</a> were under stay-at-home restrictions to “<a href="https://www.washingtonpost.com/graphics/2020/world/corona-simulator/" target="_blank" rel="noreferrer noopener">flatten the curve</a>.” Mainstream news terrorized the public with <a href="https://www.nytimes.com/2020/03/13/science/coronavirus-math-mitigation-distancing.html" target="_blank" rel="noreferrer noopener">exponential</a> graphs, threats of a medical supply <a href="https://www.medtechdive.com/news/hhs-officials-warn-of-medical-supply-shortages-amid-coronavirus-outbreak/573011/" target="_blank" rel="noreferrer noopener">shortage</a>, and displays of <a href="https://www.youtube.com/watch?v=TnLCYqk20YU" target="_blank" rel="noreferrer noopener">hygiene theater</a>. Appeals to science were weaponized to enforce conformity, and the media portrayed anti-lockdown protesters as <a href="https://www.thenation.com/article/politics/lockdown-protest-media/" target="_blank" rel="noreferrer noopener">backwards</a>, <a href="https://www.nytimes.com/2020/04/21/us/politics/coronavirus-protests-trump.html" target="_blank" rel="noreferrer noopener">astroturfed</a> <a href="https://www.wired.com/story/anti-lockdown-protests-online/" target="_blank" rel="noreferrer noopener">white nationalists</a> bent on endangering the public.&nbsp;</p>



<p>Today millions of Americans have <a href="https://www.nytimes.com/2020/10/15/us/politics/federal-aid-poverty-levels.html" target="_blank" rel="noreferrer noopener">fallen into poverty</a> or are on the verge of destitution. Stimulus money has largely been used as a <a href="https://www.propublica.org/article/how-the-coronavirus-bailout-repeats-2008s-mistakes-huge-corporate-payoffs-with-little-accountability" target="_blank" rel="noreferrer noopener">handout to corporations</a>, and over <a href="https://www.forbes.com/sites/christiankreznar/2020/09/16/small-businesses-are-closing-at-a-rapid-pace-with-restaurants-and-retailers-on-the-west-coast-among-the-hardest-hit/?sh=4542ee185033" target="_blank" rel="noreferrer noopener">160,000 small businesses</a> have closed. In March and April <a href="https://www.cnn.com/2020/04/30/economy/unemployment-benefits-coronavirus/index.html" target="_blank" rel="noreferrer noopener">30 million Americans</a> filed for unemployment. Now temporary job losses are <a href="https://www.cnbc.com/2020/10/13/covid-related-unemployment-is-now-permanent-for-almost-4-million.html" target="_blank" rel="noreferrer noopener">becoming permanent</a>. 12 million unemployed people may see their <a href="https://www.politico.com/news/2020/12/11/coronavirus-relief-unemployment-444645" target="_blank" rel="noreferrer noopener">benefits lapse</a> even if Congress passes a new aid deal. Homelessness is <a href="https://www.cbsnews.com/news/covid-19-homelessness-new-york-city/" target="_blank" rel="noreferrer noopener">spiking</a>, 11.4 million households owe <a href="https://www.bloomberg.com/news/articles/2020-12-10/u-s-households-may-be-70-billion-behind-on-rent" target="_blank" rel="noreferrer noopener">$70 billion</a> in back rent and fees, and <a href="https://www.cnn.com/2020/08/07/economy/eviction-stimulus/index.html" target="_blank" rel="noreferrer noopener">40 million</a> people are at risk of eviction. In some states, food bank lines stretch for <a href="https://thehill.com/policy/finance/527462-long-lines-form-at-food-banks-across-country-ahead-of-thanksgiving" target="_blank" rel="noreferrer noopener">miles</a>, and <a href="https://www.feedingamerica.org/sites/default/files/2020-05/Brief_Local%20Impact_5.19.2020.pdf" target="_blank" rel="noreferrer noopener">1 in 4 children</a> are expected to experience food insecurity.&nbsp;</p>



<p>Meanwhile, Walmart and Target <a href="https://www.nytimes.com/2020/08/19/business/coronavirus-walmart-target-home-depot.html" target="_blank" rel="noreferrer noopener">reported record sales</a>. Amazon <a href="https://www.theguardian.com/technology/2020/oct/29/amazon-profits-latest-earnings-report-third-quarter-pandemic" target="_blank" rel="noreferrer noopener">tripled</a> its profits and Jeff Bezos made <a href="https://www.msn.com/en-us/money/companies/jeff-bezos-has-gotten-70-billion-richer-in-the-past-12-months-here-are-11-mind-blowing-facts-that-show-just-how-wealthy-the-amazon-ceo-really-is/ss-BB194gAv?ocid=msedgntp" target="_blank" rel="noreferrer noopener">$70 billion</a>. Billionaires have collectively made over <a href="https://www.forbes.com/sites/niallmccarthy/2020/11/27/us-billionaires-added-1-trillion-to-their-collective-wealth-since-the-start-of-the-pandemic-infographic/?sh=3d09d39366ce" target="_blank" rel="noreferrer noopener">$1 trillion</a> since March. Alphabet, Amazon, Apple, Facebook, and Microsoft now make up <a href="https://www.nytimes.com/2020/08/19/technology/big-tech-business-domination.html" target="_blank" rel="noreferrer noopener">20% of the stock market</a>’s total worth. The tech industry has achieved an unparalleled level of wealth and dominance. Data, which has been <a href="https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data" target="_blank" rel="noreferrer noopener">more valuable than oil</a> since 2017, is expected to expand its <a href="https://www.wsj.com/articles/why-the-u-s-economy-will-take-off-in-2021-11607612401" target="_blank" rel="noreferrer noopener">economic footprint</a>.</p>



<div id="block_5fda90a336c0f">
    <p>
		“This is not an unforced error or a good policy idea implemented poorly. It is an economic agenda disguised as a health protocol.”    </p>
</div>


<p>Unemployment, hunger, institutional breakdown, and the destruction of social bonds are not symptoms of a virus. They are the indirect violence of class warfare. The pandemic is a convenient scapegoat for the largest upward wealth transfer in modern human history. Under the pretext of a public health policy, elites have successfully waged a counterrevolution that will result in the erosion of working conditions and quality of life for generations to come.&nbsp;</p>



<h5><strong>A Self-Fulfilling Prophecy</strong></h5>



<p>Death, disease, and pandemics have always been part of human life and they always will be. <a href="https://www.cdc.gov/nchs/fastats/deaths.htm" target="_blank" rel="noreferrer noopener">2.8 million</a> Americans die every year and <a href="https://ourworldindata.org/causes-of-death" target="_blank" rel="noreferrer noopener">56 million</a> people die worldwide. Each year <a href="https://www.who.int/data/gho/data/themes/tuberculosis" target="_blank" rel="noreferrer noopener">1.3 million</a> people die of tuberculosis, <a href="https://www.unicef.org/press-releases/ten-things-you-didnt-know-about-malaria#:~:text=Almost%20half%20the%20world's%20population,global%20malaria%20control%20is%20slipping." target="_blank" rel="noreferrer noopener">445,000</a> die of malaria, and <a href="https://www.health.com/condition/cold-flu-sinus/how-many-people-die-of-the-flu-every-year" target="_blank" rel="noreferrer noopener">290,000-650,000</a> die of influenza. In 1968 <a href="https://www.britannica.com/event/1968-flu-pandemic" target="_blank" rel="noreferrer noopener">1-4 million</a> people died in the H2N3 influenza pandemic, during which businesses and schools <a href="https://nypost.com/2020/05/16/why-life-went-on-as-normal-during-the-killer-pandemic-of-1969/" target="_blank" rel="noreferrer noopener">stayed open</a> and large events were held.&nbsp;</p>



<p>Indefinite closures have never before been used as a disease control method on a global scale. These experimental restrictions were shaped by the <a href="https://www.theguardian.com/science/2020/mar/25/coronavirus-exposes-the-problems-and-pitfalls-of-modelling" target="_blank" rel="noreferrer noopener">discredited</a> <a href="https://www.imperial.ac.uk/news/196234/covid-19-imperial-researchers-model-likely-impact/" target="_blank" rel="noreferrer noopener">Imperial College Model</a> which <a href="https://www.nytimes.com/2020/03/17/world/europe/coronavirus-imperial-college-johnson.html" target="_blank" rel="noreferrer noopener">predicted</a> 2.2 million US deaths. Many <a href="https://www.wsj.com/articles/is-the-coronavirus-as-deadly-as-they-say-11585088464" target="_blank" rel="noreferrer noopener">epidemiologists</a> and <a href="https://www.nytimes.com/2020/03/20/opinion/coronavirus-pandemic-social-distancing.html" target="_blank" rel="noreferrer noopener">doctors</a> questioned these doomsday projections and pointed out that there was <a href="https://www.statnews.com/2020/03/17/a-fiasco-in-the-making-as-the-coronavirus-pandemic-takes-hold-we-are-making-decisions-without-reliable-data/" target="_blank" rel="noreferrer noopener">not sufficient data</a> to justify lockdowns. The virus has a <a href="https://www.cdc.gov/coronavirus/2019-ncov/hcp/planning-scenarios.html" target="_blank" rel="noreferrer noopener">low</a> mortality rate, especially for people <a href="https://www.sciencedirect.com/science/article/pii/S0013935120307854" target="_blank" rel="noreferrer noopener">under 65</a>, and <a href="https://www.kark.com/news/new-cdc-report-shows-94-of-covid-19-deaths-in-us-had-underlying-medical-conditions/" target="_blank" rel="noreferrer noopener">94%</a> of US covid deaths have occurred with comorbidities. Most <a href="https://www.wsj.com/articles/the-failed-experiment-of-covid-lockdowns-11599000890" target="_blank" rel="noreferrer noopener">statistical analysis</a> does <a href="https://www.frontiersin.org/articles/10.3389/fpubh.2020.604339/full#SM6" target="_blank" rel="noreferrer noopener">not show</a> lockdown measures to be an effective strategy for <a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(20)30208-X/fulltext" target="_blank" rel="noreferrer noopener">reducing mortality</a>.</p>



<p>In March unprecedented policies were rationalized through shocking <a href="https://www.theguardian.com/world/2020/mar/13/italian-doctor-an-experience-i-would-compare-to-a-world-war" target="_blank" rel="noreferrer noopener">stories</a> and <a href="https://www.youtube.com/watch?v=_J60fQr0GWo" target="_blank" rel="noreferrer noopener">videos</a> from northern Italy. The region’s crowded ICUs were presented as a warning for the rest of Europe and the US. Unknown to many was the fact that Lombardy had been severely impacted by <a href="https://www.nytimes.com/2020/11/19/business/lombardy-italy-coronavirus-doctors.html" target="_blank" rel="noreferrer noopener">ongoing privatization efforts</a> and a <a href="https://www.statista.com/statistics/557042/hospitals-in-italy/" target="_blank" rel="noreferrer noopener">shrinking hospital system</a> regularly overwhelmed by <a href="https://www.sciencedirect.com/science/article/pii/S1201971219303285" target="_blank" rel="noreferrer noopener">influenza</a>. This omission by mainstream media played a key role in developing the mythology that economic shutdown could magically eradicate a virus. In reality lockdowns have accelerated a cycle of austerity and created a self-fulfilling prophecy of perpetual crisis.&nbsp;</p>



<p>Chronic <a href="https://www.cbsnews.com/news/nursing-home-deaths-coronavirus-understaffing/" target="_blank" rel="noreferrer noopener">understaffing</a> and <a href="https://www.nytimes.com/2020/10/29/nyregion/nursing-home-workers-pandemic-jobs.html" target="_blank" rel="noreferrer noopener">lockdown-induced layoffs</a> in nursing homes severely exacerbated covid’s death toll. 40% of US covid deaths are <a href="https://www.forbes.com/sites/jemimamcevoy/2020/06/16/nursing-homes-account-for-over-40-of-us-coronavirus-deaths/?sh=54afb581300b" target="_blank" rel="noreferrer noopener">linked to nursing homes</a>. 1 in 6 covid deaths in Vermont were <a href="https://theintercept.com/2020/12/02/vermont-nursing-home-covid-genesis/" target="_blank" rel="noreferrer noopener">from a single facility</a>. In New York (the state with the <a href="https://www.statista.com/statistics/1109011/coronavirus-covid19-death-rates-us-by-state/" target="_blank" rel="noreferrer noopener">second highest</a> covid deaths per million) hospitals sent over 6,300 elderly covid patients <a href="https://www.nbcnewyork.com/news/coronavirus/new-york-hospitals-sent-6300-recovering-covid-patients-to-nursing-homes/2502812/" target="_blank" rel="noreferrer noopener">back into nursing homes</a>. Unprotected, underserved, and alone, the elderly are also afflicted by the “<a href="https://www.nytimes.com/2020/10/30/us/nursing-homes-isolation-virus.html" target="_blank" rel="noreferrer noopener">slow killer</a>” of loneliness. Isolation increases risk of <a href="https://www.health.harvard.edu/mind-and-mood/loneliness-and-isolation-raise-risk-for-stroke-and-heart-disease-study-suggests" target="_blank" rel="noreferrer noopener">heart disease, stroke</a>, and <a href="https://www.alzinfo.org/articles/feeling-lonely-increases-alzheimers-risk-2/" target="_blank" rel="noreferrer noopener">Alzheimer’s</a>. It is <a href="https://www.webmd.com/balance/news/20180504/loneliness-rivals-obesity-smoking-as-health-risk" target="_blank" rel="noreferrer noopener">as deadly</a> as obesity or smoking 15 cigarettes a day.</p>



<p>Financial insecurity will exacerbate these health risks for the elderly. Economic shutdown has <a href="https://www.ft.com/content/d1fce3e7-428b-4b8a-ab6a-119a38fa1e7d" target="_blank" rel="noreferrer noopener">weakened</a> global pension funds and they may not recover. Millions of Baby Boomers have been forced into <a href="https://www.forbes.com/sites/jackkelly/2020/11/19/nearly-30-million-baby-boomers-forced-into-unwanted-retirement/?sh=4fb8019d5d7d" target="_blank" rel="noreferrer noopener">early retirement</a> without adequate savings. Many Americans are <a href="https://www.cnbc.com/2020/09/14/americans-are-forced-to-raid-retirement-savings-during-the-pandemic.html" target="_blank" rel="noreferrer noopener">dipping into their retirement funds early</a>. The Congressional Budget Office projects that $2.8 trillion in Social Security funds will be <a href="https://thehill.com/policy/finance/528268-covid-19-damage-to-social-security-to-extend-beyond-pandemic" target="_blank" rel="noreferrer noopener">used up in a decade</a> due to the impact of un- and underemployment on lowering contributions.</p>



<div id="block_5fda90f836c10">
    <p>
		“Income is the main determinant of covid mortality.”    </p>
</div>


<p>Outcomes of lockdown are equally grim for children. Even if K-12 schools reopen in January 2021, the average student will have lost <a href="https://www.washingtonpost.com/education/students-falling-behind/2020/12/06/88d7157a-3665-11eb-8d38-6aea1adb3839_story.html" target="_blank" rel="noreferrer noopener">7 months of instruction</a>. Because literacy and education levels are a main <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2713445/" target="_blank" rel="noreferrer noopener">predictor of longevity</a>, these learning losses represent years of life stolen from students. Moreover, cases of severe abuse and mental-health related ER visits <a href="https://apnews.com/article/anxiety-mental-health-boston-coronavirus-pandemic-massachusetts-004adb5ee0ef17ff4b5e2e294e36ff3d" target="_blank" rel="noreferrer noopener">are surging for children</a>. They will also experience <a href="https://www.nytimes.com/2020/11/25/opinion/sunday/covid-quarantine-children-immune-systems.html" target="_blank" rel="noreferrer noopener">weakened immune systems</a> due to lack of exposure to seasonal viruses and natural pathogens.</p>



<p>For people with chronic health conditions or those in need of urgent medical treatment, the short- and long-term consequences of lockdown are disastrous. In the United States, cancer screenings fell by <a href="https://www.radiologybusiness.com/topics/healthcare-economics/cancer-screenings-epic-ehr-covid-19-coronavirus" target="_blank" rel="noreferrer noopener">86-94%</a> in the spring. Many hospitals <a href="https://www.beckershospitalreview.com/finance/47-hospitals-closed-filed-for-bankruptcy-this-year.html" target="_blank" rel="noreferrer noopener">had to close</a> due to lack of revenue from routine surgeries and procedures. Hospitals are expected to lose a total of <a href="https://www.aha.org/news/headline/2020-06-30-aha-report-hospital-financial-losses-covid-19-expected-top-323-billion#:~:text=An%20AHA%20report%20released%20today,least%20%24323%20billion%20in%202020." target="_blank" rel="noreferrer noopener">$323 billion</a> this year. <a href="https://www.npr.org/2020/05/10/853524764/amid-pandemic-hospitals-lay-off-1-4m-workers-in-april" target="_blank" rel="noreferrer noopener">1.4 million hospital staff</a> were laid off in April while private health insurance companies <a href="https://www.nytimes.com/2020/08/05/health/covid-insurance-profits.html" target="_blank" rel="noreferrer noopener">doubled their earnings</a>.&nbsp;</p>



<p>In the absence of meaningful investments in healthcare infrastructure, the covid mitigation strategies being pushed by federal, state, and local governments are neither credible nor effective. Elected officials routinely amplify raw case numbers in order to stoke fear and blame individuals for viral spread. As a result, we are currently “saving lives” by killing people. This is not an unforced error or a good policy idea implemented poorly. It is an economic agenda disguised as a health protocol.</p>



<h5>The New Caste System&nbsp;</h5>



<p>California Governor Gavin Newsom sends his children to <a href="https://www.politico.com/states/california/story/2020/10/30/newsom-sends-his-children-back-to-school-classrooms-in-california-1332811" target="_blank" rel="noreferrer noopener">in-person private school</a> while mandating virtual education for California public schools. He announced a <a href="https://www.theguardian.com/world/2020/dec/06/california-covid-lockdown-us-new-cases-hospitalisations-deaths-stay-at-home-order" target="_blank" rel="noreferrer noopener">second statewide lockdown</a> just a few weeks after attending an indoor, unmasked <a href="https://www.politico.com/news/2020/11/18/newsom-lobbyist-dinner-party-437892" target="_blank" rel="noreferrer noopener">dinner with lobbyists</a> at a Michelin three star restaurant where meals can cost up to <a href="https://sf.eater.com/2020/9/3/21421335/french-laundry-yountville-thomas-keller-indoor-dining-rich-people" target="_blank" rel="noreferrer noopener">$850 per person</a>. Newsom is just one of many <a href="https://www.nytimes.com/2020/11/23/nyregion/cuomo-thanksgiving-mother.html" target="_blank" rel="noreferrer noopener">politicians</a>, elites, and <a href="https://www.wsj.com/articles/mask-mischief-11595625179" target="_blank" rel="noreferrer noopener">bureaucrats</a> who break the rules. A static social order is being solidified. In our new caste system the wealthy have political and social <a href="https://www.bloomberg.com/news/articles/2020-12-03/u-k-to-exempt-high-value-business-travelers-from-quarantine" target="_blank" rel="noreferrer noopener">privileges</a> because they are considered clean and disease-free, while the more low-income someone is, the more they are treated as contaminated.&nbsp;</p>



<p>The goal of lockdown enthusiasts in the “work from home” caste is to shift risk away from themselves and onto essential workers and the poor. <a href="https://www.bbc.com/worklife/article/20201023-coronavirus-how-will-the-pandemic-change-the-way-we-work" target="_blank" rel="noreferrer noopener">Only 40%</a> of the workforce can afford to stay home. <a href="https://www.commonwealthfund.org/publications/issue-briefs/2020/aug/looming-crisis-health-coverage-2020-biennial#:~:text=In%20the%20first%20half%20of%202020%2C%2043.4%20percent%20of%20U.S.,uninsured%20rate%20was%2012.5%20percent." target="_blank" rel="noreferrer noopener">43% of US adults</a> do not have adequate health insurance, and only 31% of low-paid workers have <a href="https://www.pewresearch.org/fact-tank/2020/03/12/as-coronavirus-spreads-which-u-s-workers-have-paid-sick-leave-and-which-dont/" target="_blank" rel="noreferrer noopener">paid sick leave</a> compared to 92% of high-paid workers. “Stay home” is the self-congratulatory mantra of professionals who believe that their virtuous behavior prevents them from contracting covid. In fact, income is the <a href="https://prospect.org/coronavirus/covid-19-class-war-death-rates-income/" target="_blank" rel="noreferrer noopener">main determinant</a> of covid mortality.</p>



<p>Lockdown fanatics have helped manufacture consent for a brutal reorganization of labor that will plunge millions of people into serfdom. The work-from-home lifestyle is only possible through the labor of logistics workers who transport, sort, and deliver goods. Currently about <a href="https://www.nytimes.com/live/2020/12/04/business/us-economy-coronavirus" target="_blank" rel="noreferrer noopener">10 million jobs</a> that existed in February have not been replaced. Many workers have been forced to take on part-time, no-contract work, a labor model that is <a href="https://qz.com/1556194/the-gig-economy-is-quietly-undermining-a-century-of-worker-protections/" target="_blank" rel="noreferrer noopener">rolling back</a> decades of hard-fought protections.&nbsp;&nbsp;</p>



<p>Under the Obama/Biden administration, 94% of new jobs created were gig work, and in 2017 <a href="https://www.ilo.org/washington/WCMS_642303/lang--en/index.htm#:~:text=The%20Bureau%20of%20Labor%20Statistics,to%2043%20percent%20in%202020." target="_blank" rel="noreferrer noopener">34% of the workforce</a> was employed through the gig economy. Shutdowns are accelerating this trend, with food delivery apps <a href="https://www.nytimes.com/2020/11/30/nyregion/bike-delivery-workers-covid-pandemic.html" target="_blank" rel="noreferrer noopener">growing their profits</a> as workers struggle to get by. Subscription platforms like OnlyFans saw a <a href="https://www.sfchronicle.com/bayarea/article/Coronavirus-took-their-jobs-away-OnlyFans-let-15175650.php" target="_blank" rel="noreferrer noopener">surge in accounts</a> at the beginning of lockdown. In March the company saw a <a href="https://www.nytimes.com/2020/04/10/style/camsoda-onlyfans-streaming-sex-coronavirus.html" target="_blank" rel="noreferrer noopener">75% increase in users and 60,000 new creators</a>. Lockdown has made OnlyFans a <a href="https://www.bloomberg.com/news/articles/2020-12-05/celebrities-like-cardi-b-could-turn-onlyfans-into-a-billion-dollar-media-company" target="_blank" rel="noreferrer noopener">billion dollar business</a>, but the majority of creators make less than <a href="https://www.xsrus.com/writing/explain/onlyfans/" target="_blank" rel="noreferrer noopener">$145 a month</a>.&nbsp;</p>






<p>Internationally, workplace closures and supply chain disruptions will result in the loss of <a href="http://ilo.org/global/about-the-ilo/newsroom/news/WCMS_743036/lang--en/index.html" target="_blank" rel="noreferrer noopener">305 million</a> jobs. <a href="https://www.ilo.org/global/topics/employment-promotion/informal-economy/publications/WCMS_743534/lang--en/index.htm" target="_blank" rel="noreferrer noopener">1.6 billion</a> informal economy workers are at risk of losing their livelihoods. This devastation will be compounded by famine and the increased <a href="https://www.nytimes.com/2020/08/03/health/coronavirus-tuberculosis-aids-malaria.html" target="_blank" rel="noreferrer noopener">spread of untreated diseases</a> like <a href="https://www.sciencedaily.com/releases/2020/06/200624103257.htm" target="_blank" rel="noreferrer noopener">tuberculosis</a>. In July closed food markets were linked to <a href="https://apnews.com/article/lifestyle-ap-top-news-understanding-the-outbreak-hunger-international-news-5cbee9693c52728a3808f4e7b4965cbd" target="_blank" rel="noreferrer noopener">10,000 child deaths a month</a>. <a href="https://www.nytimes.com/2020/04/11/business/coronavirus-destroying-food.html" target="_blank" rel="noreferrer noopener">Food is being discarded</a> and crops are rotting in the fields while the number of people facing acute hunger this year has doubled to <a href="https://www.nytimes.com/2020/04/22/world/africa/coronavirus-hunger-crisis.html">265 </a><a href="https://www.nytimes.com/2020/04/22/world/africa/coronavirus-hunger-crisis.html" target="_blank" rel="noreferrer noopener">million</a>.&nbsp;</p>



<p>At the start of the covid crisis, vocal segments of the American left argued that economic shutdown was a way to resist <a href="https://jacobinmag.com/2020/03/donald-trump-wall-street-coronavirus-profits" target="_blank" rel="noreferrer noopener">billionaires</a> and <a href="https://www.dsausa.org/democratic-left/we-need-a-global-democratic-socialist-response-to-covid-19/" target="_blank" rel="noreferrer noopener">capitalism</a>. This demonstrated a deep misunderstanding of the way <a href="https://www.investopedia.com/financial-edge/0411/5-investors-that-are-both-rich-and-smart.aspx" target="_blank" rel="noreferrer noopener">financiers can profit</a> from economic contraction. Many on the left chose to ignore the Biblical scale of the destruction that economic stoppages would cause, arguing that the covid crisis was an <a href="https://jacobinmag.com/2020/03/quarantine-coronavirus-economy-left-organizing" target="_blank" rel="noreferrer noopener">opportunity</a>. Today the left continues to advance the illusion that <a href="https://jacobinmag.com/2020/11/joe-biden-coronavirus-pandemic-relief" target="_blank" rel="noreferrer noopener">meaningful relief</a> is possible, while workers’ pensions are plundered, children’s futures disappear, and <a href="https://www.cnn.com/2020/10/07/economy/global-poverty-rate-coronavirus/index.html" target="_blank" rel="noreferrer noopener">150 …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebellows.org/the-great-covid-class-war/">https://www.thebellows.org/the-great-covid-class-war/</a></em></p>]]>
            </description>
            <link>https://www.thebellows.org/the-great-covid-class-war/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627525</guid>
            <pubDate>Mon, 04 Jan 2021 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Explore Mental Models]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25627377">thread link</a>) | @FlyMoreRockets
<br/>
January 3, 2021 | https://www.mentalmodelsbox.com/explore | <a href="https://web.archive.org/web/*/https://www.mentalmodelsbox.com/explore">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><div><div><h2>Hanlon's Razor</h2><p>Never attribute to malice that which is adequately explained by stupidity.</p></div></div><div><div><h4>Description</h4><p>Hanlon's razor asks for reflection in situations where we perceive behavior  to be intentionally malicious. A useful exercise is to rethink the scenario  by replacing the malicious intent with reasons such as stupidity, stress or  just plain old misunderstanding.</p><h4>Examples</h4><ul><li><p>Your five-year old probably isn't making a mess to make your life miserable  but rather because they're a toddler.</p></li><li><p>A social networking website probably didn't flag your content out of malice  but rather due to a faulty algorithm.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Occam's Razor</h2><p>When comparing hypotheses, the one with the fewest assumptions should be selected.</p></div></div><div><div><h4>Description</h4><p>Occam's razor originally stated that entities should not be multiplied unnecessarily. In other words, don't complicate things when you don't need to. By shaving off unnecessary additions, the resulting explanation tends  to be less ambiguous, easier to verify, and just plain simpler. Occam's  Razor is often mentioned when selecting a simple solution over a complex  one. Note that this is a slightly stronger form than the principle  intended--reality can be complex and there are cases where the simple  solution is not correct.</p><h4>Examples</h4><ul><li><p>A sore throat during during the winter is probably the result of a cold even though the symptoms match a rare terminal disease on WebMD.</p></li><li><p>The pyramids being built by humans has far less assumptions than the pyramids being built by aliens.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>First Principles Reasoning</h2><p>Break complex problems into foundational elements and use these elements to build your reasoning.</p></div></div><div><div><h4>Description</h4><p>A first principle is a foundational assumption or proposition that cannot be derived from other assumption or propositions. By attempting to break down problems into first principles and re-constructing solutions using these building blocks, you're less likely to be biased by prior assumptions. This in turn can lead to more innovative solutions.</p><h4>Examples</h4><ul><li><p>A child repeatedly asking "why?" to answers for an initial question is intuitively thinking in first principles.</p></li><li><p>A company building a cheaper product than competitors by investigating ways of using the raw materials firsthand instead of just following existing conventions.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Proximate and Root Causes</h2><p>Discovering the root cause of an event involves looking deeper than the immediate causes for that event.</p></div></div><div><div><h4>Description</h4><p>A proximate cause is the event most closely associated with or immediately responsible for an observed result. This may differ from the root cause. Getting to a root cause often requires a deep dive into the situation using approaches like <a href="https://en.wikipedia.org/wiki/Socratic_questioning">Socratic questioning</a> or the <a href="https://en.wikipedia.org/wiki/5_Whys">5 Whys</a></p><h4>Examples</h4><ul><li><p>Post-mortem reports for critical failures generally outline proximate causes and how they stem from the root cause. For instance a website was down due servers running out of disk space which was in turn a result of a bug which in turn was a result of poor testing and so on.</p></li><li><p>A child repeatedly asking "why?" to answers for an initial question is trying to get to the root cause.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Social Proof</h2><p>We tend to copy the behavior of others, especially during times of uncertainty.</p></div></div><div><div><h4>Description</h4><p>Social proof is a term used to describe our tendency to follow the behavior of others. This tendency is amplified if we are uncertain about the situation. Social proof generally guides us into making fewer mistakesâ€”if many folks are doing something, itâ€™s usually the correct thing to do. However, this â€œauto-pilotâ€� behavior can be easily exploited to manipulate our decision making process. For instance, to lead us towards a decision that serves someone else's interests or is incorrect.</p><h4>Examples</h4><ul><li><p>Laugh tracks in TV shows and hired clappers in a theater performance can trick us into perceiving the content to be funnier or higher quality than it actually is.</p></li><li><p>Testimonials increase our likelihood of buying a product, especially when they indicate popularity. Terms like â€œbest sellingâ€� or â€œrecommended by 9 out of 10 professionalsâ€� are marketing applications of social proof.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Survivorship Bias</h2><p>We tend to focus on things that survived and overlook things that didn't. This can lead to overly optimistic beliefs.</p></div></div><div><div><h4>Description</h4><p>Survivorship bias occurs when we develop a skewed view of a situation by concentrating on the people or things that survived. Things that didn't survive lack visibility and are overlooked. A common result of survivorship bias is overly optimistic beliefs. By focusing primarily on the success stories, we fail to fully understand why the "failures" did not survive, often just assuming that it's due to a lack of qualities found in the survivors. Looking for counter examples when deriving patterns from success stories can be a useful exercise in combating survivorship bias.</p><h4>Examples</h4><ul><li><p>sWe often attribute the success of famous entrepreneurs solely to their behavior and overlook things like luck and timing. By ignoring the failed companies that followed similar approaches, we might be overly optimistic about the likelihood of our own entrepreneurial success.</p></li><li><p>It's easy to perceive music from the past as being higher quality than contemporary works. Music from the past, however, has gone through a selection process where higher quality works have survived. With contemporary music, we hear the mediocre along with the good.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Reciprocity</h2><p>We tend to feel obligated to repay positive actions towards us (e.g. favors, gifts) even if they are unwanted.</p></div></div><div><div><h4>Description</h4><p>Reciprocity refers to a social norm in which we feel a sense of obligation when receiving positive actions towards us. For instance, receiving a favor or gift can trigger feelings of indebtedness to repay the act in someway. While reciprocity allows one to build relationships and exchanges, it can be exploited to gain someone's compliance to a request. This is because feelings of obligation can be felt even when receiving a positive action we do not want.</p><h4>Examples</h4><ul><li><p>Before attempting to sell something, a salesperson may give you a small gift (e.g. a pen or a free sample). Even if this gift is unwanted, receiving it can still trigger a need to repay the gift, usually in the form of purchasing whatever is being sold.</p></li><li><p>A common compliance technique is to start by making a large request that's likely to be rejected followed by a second, smaller request. The second request, which is the intended request, is more likely to be accepted as it's seen as a favor.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Hindsight Bias</h2><p>The feeling that we could have predicted an event after it occurs (i.e. we "knew it all along").</p></div></div><div><div><h4>Description</h4><p>Hindsight bias is the feeling we get when we perceive an event as being predictable, even though there's little evidence to suggest we could have predicted it. Once the event has occurred, it's easy to work backwards and find explanations. While hindsight bias can result in increased confidence and performance, too much can lead to overconfidence and an inability to learn from experience. For instance, by assuming that we could have done better than others after knowing the results of their actions, we lost an opportunity to understand why those actions were made.</p><h4>Examples</h4><ul><li><p>In court, judgement of a defendant can be clouded by hindsight bias. The jury, knowing the outcome of the defendant's actions, might feel as if they could have predicted the outcome.</p></li><li><p>We may feel that people in the past were less intelligent or innovative than those of the present without acknowledging that they did not access to present day information. Related: <a href="https://en.wikipedia.org/wiki/Historian%27s_fallacy">Historian's fallacy</a> and <a href="https://en.wikipedia.org/wiki/Chronological_snobbery">chronological snobbery</a>.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Confirmation Bias</h2><p>We have a tendency to perceive things in a way that re-enforces or aligns with our preexisting beliefs.</p></div></div><div><div><h4>Description</h4><p>Confirmation bias is a cognitive bias that causes us to see things in a way that confirms our preexisting beliefs. Because it involves selectively collecting and recalling information, the end result is a biased view point. In addition, confirmation bias may also cause us to ignore information that doesn't support our views. Closely related is the feeling of <a href="https://en.wikipedia.org/wiki/Cognitive_dissonance">cognitive dissonance</a> which refers to the discomfort we feel when holding contradictory beliefs.</p><h4>Examples</h4><ul><li><p>In social media, we're often shown content that we're more likely to agree with. This amplifies confirmation bias--we only see things consistent with our beliefs resulting a sort of "echo chamber". For more on this, see <a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a>.</p></li><li><p>Belief in farfetched conspiracy theories can often be a result of confirmation bias. If one tries hard enough, they can find things that seem to support the theory while ignoring the evidence that refutes it.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Scarcity</h2><p>We tend to place higher value on things that are rare and lower value on things that are abundant.</p></div></div><div><div><h4>Description</h4><p>Scarcity refers to our tendency to place value on things according to how rare they are. It's often used as a mental shortcut to assess the value of something based on how easy or difficult is it to acquire. Scarcity doesn't just apply to objects--it can also be applied to things like time and information. For instance, we might place high value on spending some time with a busy individual or getting access to confidential information. Since scarcity can increase our desire for something, it's often artificially created to sell something. A good strategy to combat this desire is to remember that scarcity only increases our desire to obtain something and doesn't affect the actual value we'll extract from it.</p><h4>Examples</h4><ul><li><p>Sales techniques likes setting deadlines on promotions or indicating that limited quantities are available are designed to drive up scarcity driven desire for the item being sold.</p></li><li><p>When information is censored, we not only feel a stronger desire to know about it and but also tend to be more favorable to it.</p></li></ul></div></div></div></div><br><div><div><div><div><h2>Pareto Principle</h2><p>For many scenarios, 80% of the effects stem from 20% of the causes. This is often referred to as the 80/20 rule.</p></div></div><div><div><h4>Description</h4><p>In 1896, economist <a href="https://en.wikipedia.org/wiki/Vilfredo_Pareto">Vilfredo Pareto</a> found that 20% of the population in Italy owned 80% of the land. This ratio is commonly cited in wealth distribution (the richest 20% …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mentalmodelsbox.com/explore">https://www.mentalmodelsbox.com/explore</a></em></p>]]>
            </description>
            <link>https://www.mentalmodelsbox.com/explore</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627377</guid>
            <pubDate>Mon, 04 Jan 2021 02:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operatingsystemlessness]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25627281">thread link</a>) | @panic
<br/>
January 3, 2021 | https://a-nickels-worth.dev/posts/osless/ | <a href="https://web.archive.org/web/*/https://a-nickels-worth.dev/posts/osless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>I have found it difficult to keep track of all the new
container-related terminology: container orchestrators, serverless,
cloud native, and so forth. I think a term that hasn’t gotten much
usage yet, <em>operatingsystemless</em> (<a href="http://blogdelsinkcom.azurewebsites.net/containerless/">mentioned
here</a>), is a
really apt way of understanding where compute is going and hopefully
will gain some increased adoption. This is based on an observation
that the trend over the last two decades, for production systems, has
been to increasingly reduce the usage of any explicit use of most
operating system features. Ultimately, production systems may evolve
to some form of Unikernel-like format(s), although it is hard to say
exactly what that would look like.</p>
<p>For the purposes of this blog entry I’m going to wildly oversimplify
and classify compute workloads into two camps:</p>
<ol>
<li><strong>Interactive</strong> applications; workloads intended to be run on a
single machine, with a human logged in and, if not actively
interacting with the software, at least able to check in from time
to time and fix problems as they arise</li>
<li><strong>Production</strong> systems; workloads intended to be run on many
machines, without many humans close by; humans can be paged in
(ideally by automated systems) to fix problems, but only at
significant cost</li>
</ol>
<p>When my present company first deployed a major website in the late
1990s, Unix was the natural choice for the production systems.
Although designed for interactive workloads (multi-user workstations),
engineers working on our systems were familiar with Unix, and the
company needed to move fast. Unix was (and still is) an excellent
operating system for software development. Although there is no law of
physics stating that one must use the same operating system in both
production and development environments, there was no other practical
alternative at the time.</p>
<p>Our website had, roughly, the following architecture (circa 1999):</p>
<pre><code>webserver (x8)           database (cluster)
--------------           ------------------

httpd (master)        /--floating-ip
  \_ httpd (child)|  /
  \_ httpd (child)|_/
  \_ httpd (child)|
  \_ httpd (child)|
</code></pre><p>I won’t focus too much on the database side of things, just the
webservers. On each of the webserver machines, using Unix had a number
of missing features and even anti-features, when it came to
production services, which I’ll outline in the next few sections.</p>
<h2 id="process-management">Process Management</h2>
<p>You’ll notice in the diagram above that there was nothing to make sure
the master <strong>httpd</strong> process actually stayed up. In fact, we had a
Perl script that would sweep across all the webservers and make sure
those processes were running. This was because Unix was not really
designed for this kind of lights-out automated scenario. Unix has been
geared towards humans sitting at workstations. There are myriad ways
that processes can get
<a href="https://en.wikipedia.org/wiki/Sleep_(system_call)#Uninterruptible_sleep">stuck</a>
(or become <a href="https://en.wikipedia.org/wiki/Zombie_process">zombies</a>).
In production those states are difficult to handle correctly; one
would prefer they not exist. In the interactive workstation case,
they’re acceptable annoyances.</p>
<p>Process management is also primitive. For a production system one
wants <a href="http://erlang.org/documentation/doc-4.9.1/doc/design_principles/sup_princ.html">supervision
tree</a>
semantics to ensure fail-fast, crash-only systems that are naturally
self-healing:</p>
<ol>
<li>One can be certain that specific processes are always present, yet
also do not restart so quickly (under error conditions) that they
swamp the CPU</li>
<li>If a parent process dies, all child processes automatically die as
well</li>
<li>If a child process dies with an error code, the parent process must
explicitly inform the operating system that it handled the error,
otherwise it, too, dies</li>
<li><a href="https://en.wikipedia.org/wiki/Zombie_process">Zombie processes</a> are not possible</li>
</ol>
<p>As another example of a missing feature, the Perl script mentioned
above had code that would try to ensure that all the child processes
of a webserver were actually killed, even if they themselves spawned
children. Unix does not provide this sort of behavior, and we were
never able to fix all the potential race conditions.</p>
<p>As a result, the industry has produced numerous “process managers”,
over the years, outside of the operating system proper, none of which
are wholly satisfactory: SYSV init, upstart, systemd, runit, monit,
daemontools, etc. All of these systems have their pros and cons, but I
think fully robust production-oriented process management cannot be
solved outside of the kernel. Without kernel-level guarantees, there
will always be edge cases where processes spawn endlessly, fail to
restart, etc.</p>
<p>The industry-wide trend in response to this has been to stop launching
multiple processes on the same (logical) machine at all, leveraging
new kernel features like chroot, namespaces and cgroups.</p>
<h2 id="terminal-handling">Terminal Handling</h2>
<p>Unix has a complex set of <a href="https://www.linusakesson.net/programming/tty/">terminal handling
capabilities</a> necessary
for multiple human users on the same machine. This capability is
useless for a service with thousands of machines running
non-interactive workloads. And no terminals in sight. Although
terminal handling is useful for those times when an engineer is trying
to diagnose a problem, even this is considered an anti-pattern. Partly
to accommodate terminal handling, Unix has an unnecessarily complex
process model centered around interactive control of processes.</p>
<h3 id="job-control">Job Control</h3>
<p>Closely intertwined with Unix support for terminals is Unix job
control functionality. It was not designed for production systems. The
most obvious example is the <a href="https://en.wikipedia.org/wiki/Job_control_(Unix)#Implementation">terminal
stop</a>
feature, allowing a human to suspend a running process by hitting a
key on the keyboard like Control-Z. In a headless service, processes
should never “stop” in this way. The mere presence of the concept of a
“stopped” process means either one more aspect of Unix one must
ignore, or else one more aspect to ensure never happens via
monitoring.</p>
<h3 id="sessions">Sessions</h3>
<p>Also closely related to terminal handling is the Unix idea of
<a href="https://pubs.opengroup.org/onlinepubs/9699919799/">sessions</a>.
Sessions are groups of processes that can be, as a group, associated
(or disassociated) from an interactive terminal. Although the name
“session” sounds like it might be useful, the implementation is
irrelevant for production systems.</p>
<h2 id="scheduling">Scheduling</h2>
<p>Scheduling on a single machine, with one process (or at least very
few), becomes a lot simpler, as there is only one (or, again, a very
few) process to schedule. At the same time, in production systems the
more important kind of scheduling occurs across a cluster of machines.
For example, scheduling two processes near or far from each other (for
either performance or blast radius purposes), requires cluster wide
knowledge of which workloads are related to each other and where they
are already running. Scheduling more processes of a certain type
because a queue or load-balancer has become backed-up requires both
knowing about the load balancer, knowing if/where there is free
capacity, and knowing what type of process to spawn in order to fix
that particular type of backlog. For reliability, this knowledge must
be distributed across the cluster, not just tracked on a single
machine.</p>
<h2 id="users-and-groups">Users and Groups</h2>
<p>One of the first pain points when using Unix for production, was
answering the question, “what users and groups should my processes run
as?” While we naturally did not want anything to run as root, picking
arbitrary users and groups at all was an annoyance. User and group
membership on an individual machine does not have much meaning in a
production environment. At best, it helped keep two services on the
same machine (which one needed to do from time to time, for cost
reasons, in the pre-VM era) somewhat separate from each other. This,
though, required complex management system to push the right user and
group configuration to every machine.</p>
<p>Worse, the things one would want to control (for example which
database servers were accessible to the process) also require
knowledge and ownership that exists outside of the production
machines. Over the network, everybody is <code>nobody</code>, even <code>root</code> users.</p>
<p>Overall, for production systems, machine-local users and groups just
add a lot of hassle without much benefit.</p>

<p>To get a sense of how little of Unix is necessary for distributed
systems, it’s worth taking a look at <a href="https://raw.githubusercontent.com/google/gvisor/3ac00fe9c3396f07a1416ff7fc855f6f9a3c4304/pkg/sentry/syscalls/linux/linux64.go">gVisor’s list of supported
system
calls</a>.
This serves as a reasonable, albeit conservative, proxy for what a
modern “container” needs from an operating system. Note that under 50%
of all Linux syscalls are fully supported, and some of those
(<code>getgid</code>, etc) clearly aren’t necessary in the long run.</p>
<table>
<thead>
<tr>
<th>Count</th>
<th>Status</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr>
<td>165</td>
<td>Supported</td>
<td>47.5%</td>
</tr>
<tr>
<td>89</td>
<td>Partially Supported</td>
<td>25.6%</td>
</tr>
<tr>
<td>48</td>
<td>Error With Event</td>
<td>13.8%</td>
</tr>
<tr>
<td>25</td>
<td>Cap Error</td>
<td>7.2%</td>
</tr>
<tr>
<td>20</td>
<td>Error</td>
<td>5.7%</td>
</tr>
<tr>
<td><strong>347</strong></td>
<td><strong>TOTAL</strong></td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>Overall there is a trend moving away from using traditional
workstation operating system features at all:</p>
<ol>
<li>Either a single process per “machine”, using multiple threads, if
necessary, or else using multiple processes but in a strict
supervision tree as outlined earlier</li>
<li>All IPC is over the network abstraction, even if physically local</li>
<li>No users or groups</li>
<li>Scheduling decisions made based on external factors (e.g., work
queue depth)</li>
<li>Little to no use of signals and no terminal handling features</li>
</ol>

      </div></div>]]>
            </description>
            <link>https://a-nickels-worth.dev/posts/osless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627281</guid>
            <pubDate>Mon, 04 Jan 2021 02:14:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quitting a New Job]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25627276">thread link</a>) | @jrmski
<br/>
January 3, 2021 | https://yolken.net/blog/quitting-a-new-job | <a href="https://web.archive.org/web/*/https://yolken.net/blog/quitting-a-new-job">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
    <div>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Two years ago, I did something that I’d never done in my career before- I left a job
(at <a href="https://nuro.ai/">Nuro</a>) only a few months after starting it. In this post, I want to explain
what happened and what I learned from the experience.</p>

<h2 id="what-happened">What happened</h2>

<h4 id="the-job-switch">The job switch</h4>

<p>Back in the spring of 2019, I decided to leave <a href="https://www.stripe.com/">Stripe</a>, where I’d
been a software engineer for about a year and a half. The full details are best left
to a separate post, but at a high level I just wasn’t very happy with my personal situation; the
work I was doing in compute infrastructure had the unfortunate combination of being both
overly stressful and underappreciated. At the same time, I felt like my career prospects
were limited because the upper rungs of Stripe’s engineering individual contributor (IC) ladder put
a lot of emphasis on cross-team coordination and other, managerial-like activities that I didn’t
enjoy and felt I wasn’t very good at.</p>

<p>Given how hot the job market was at the time and the number of other, seemingly more interesting
opportunities available, I figured that I had nothing to lose by interviewing elsewhere.</p>

<p>After a few weekends of furiously-paced <a href="https://yolken.net/blog/master-coding-interviews">Leetcoding</a>, I was ready.
Unlike my previous job searches, there wasn’t any particular company that I was aspiring
to get into; instead, I just went through my <a href="https://yolken.net/blog/six-years-of-emails">backlog of recruiting emails</a>
and wrote back to a bunch that looked interesting. Among the messages I responded to was one
about <a href="https://nuro.ai/">Nuro</a>, an autonomous vehicle startup that was attempting to do driverless
grocery delivery.</p>

<p>Over the following weeks, I went through the full recruitment slog, starting with lots of
recruiter phone calls, then following up with technical phone screens for a subset of
those, then doing onsite interviews for a subset of those. In the end, I got offers from seven
places, including Nuro.</p>

<p>During the process, I didn’t fall in love with any of the options. But, there
was something that made me feel more optimistic about Nuro than the other choices. Being a
hardware-oriented, robotics company, it was just really different from all of my previous employers,
and, after years of feeling stuck in my career, maybe different was good.</p>

<p>The company was super secretive about its technology; I wasn’t allowed to tour the office, for
instance, because they had hardware prototypes lying around that only employees were allowed to
see. I also wasn’t invited to ride along in their test cars, which would have been both fun and
informative. The external signs were good, though- they had raised a billion dollars from Softbank
and others, and the employee reviews on <a href="https://www.glassdoor.com/">Glassdoor</a> were gushing.</p>

<p>Aside from being in a somewhat different space than my previous employers, another potential
downside was the commute. Stripe and my three jobs before that were all within a 15 minute walk
of my apartment in San Francisco. Nuro’s office was 40 miles away in Mountain View, which was
more than an hour each way by train. But, I had done longer commutes earlier in my career and figured
that I could handle it.</p>

<p>In the end, I went with my impulses and signed the offer. I had my last day at Stripe, took a short
vacation, and then showed up at the Nuro office, brimming with optimism, for my first day two weeks
later.</p>

<h4 id="realizing-my-mistake">Realizing my mistake</h4>

<p>Unfortunately, that optimism lasted for a grand total of 2 days. By Wednesday of my first week,
as I was riding the train home, I realized that I had made a mistake. My colleagues were
friendly and smart, and the company was doing interesting things, but the job just felt like a
lifestyle downgrade to me.</p>

<p>At Stripe and each of my jobs before that, I had had a short commute to a beautiful office, and
got to experience the instant gratification associated with developing purely software-based
products. Now, I was stuck taking a crowded train to a dark office littered with hardware parts,
working on a product that would take many years to reach mass-market adoption due to pesky little
things like manufacturing and road safety.</p>

<p>I had left Stripe seeking an upgrade, but instead I got a downgrade. And, while minor improvements
were possible, it seemed unlikely that things would completely change for the better in the near
term.</p>

<h4 id="getting-back-on-track">Getting back on track</h4>

<p>At this point, I had three choices:</p>

<ol>
  <li>Quit immediately</li>
  <li>Start exploring new opportunities but don’t quit until something better is lined up</li>
  <li>Stick it out for at least a year</li>
</ol>

<p>My first instinct was to take option 1 and just go back to Stripe. When I reached out to my HR
contact, though, I found out that I’d have to go through team matching again and also get a new
offer; even though I’d left on good terms less than a month before, I couldn’t just revert back to
my previous position and pay. This was disappointing, but after giving it a little more thought,
I figured it was for the best because I had left Stripe for specific reasons; going back
to my old job wouldn’t fix those or make me feel better about them.</p>

<p>Another variant of option 1 would be to quit and take one of the other offers I had gotten
during my search. But, I had already rejected those for what I thought were good reasons,
so this didn’t feel like the best way out.</p>

<p>Option 3 was the one that would look the least bad from a resume perspective, and this seems to be
what a lot of people in tech do when they don’t like a job. But, life is short, I was really feeling
unhappy with the choice I had made, and I figured it wasn’t really fair to my colleagues at Nuro to
stick in a job that my heart wasn’t in.</p>

<p>So, in the end, I decided that option 2 was the best fit for me. I continued at Nuro and did my best
to get up-to-speed and to contribute to my team’s work, but at the same time jumped right back
into the job market. In addition to keeping things open with Stripe, I
<a href="https://yolken.net/blog/triplebyte-review">tried Triplebyte</a>, responded to more recruiter emails, and also
reached out to some former colleagues about the companies they were now at.</p>

<p>I then went through the whole recruitment process with a new set of companies. This time,
though, I was a lot pickier about where I interviewed (nothing in hardware or with long commutes!);
after a few weeks, I had four new choices including an updated offer from Stripe. After
a good amount of due diligence, significantly more than I had done in my previous search, I
decided to go to <a href="https://segment.com/">Segment</a>.</p>

<p>When I put in my notice at Nuro, people were surprised that I was leaving so soon, but ultimately
were understanding. I left, took a short vacation, and then started at Segment. Thankfully,
the new job was a much better fit for me, and I’m much happier now!</p>

<h2 id="lessons-learned">Lessons learned</h2>

<h4 id="do-your-due-diligence">Do your due diligence</h4>

<p>Switching jobs is a big deal, and it shouldn’t be done impulsively. Ideally, your due
diligence before signing a new offer should include:</p>

<ol>
  <li>Meeting with the team you’ll be working with in a low-stress, non-interview setting</li>
  <li>Touring the office and understanding what your specific workspace will be like</li>
  <li>Trying out the commute for a few days (if it’s significantly different than your current one)</li>
  <li>Trying out any new languages/technologies that you’ll be using on the job</li>
  <li>Getting hands-on demos of the company’s products (if they’re not freely accessible to consumers
  already)</li>
  <li>Seeing a summary of the company’s income and expenses over time (if not public)</li>
</ol>

<p>Learning about these things doesn’t guarantee that you’ll be happy in your new job, but it
at least reduces the risk of any unexpected surprises after you start.</p>

<h4 id="its-ok-to-quit-after-a-few-weeks-just-dont-make-it-a-pattern">It’s ok to quit after a few weeks (just don’t make it a pattern)</h4>

<p>When I started my second job search, I was worried that the short
tenure in the job I was trying to leave would be a turn-off to perspective employers. In reality,
however, it wasn’t a big deal- people asked about it, but seemed satisfied with my 20 second
summary and then moved on to other things.</p>

<p>The sense I get is that you’re allowed to quit a new job once in your career without any
repercussions. If you do it multiple times, however, then recruiters and hiring managers might
have second thoughts about interviewing you without strong internal references or some other signal
that you’ll be a good employee.</p>

<h4 id="switch-teams-before-quitting">Switch teams before quitting</h4>

<p>As I noted in a <a href="https://yolken.net/blog/leaving-a-job">previous post</a>, switching teams is a lot easier than
switching jobs. I didn’t do this before I left Stripe because there weren’t any other teams that I
was super enthusiastic about at the time. But, in retrospect, I probably should have given this a
try before quitting.</p>

<p>Even if the new team hadn’t been a perfect fit, it would have at least bought some time and given
me some additional experience that could help in future work. This is what I did at Google
and Airbnb, and in both cases the “second team” was what really opened up new opportunities for me.</p>

  </div>

  
</article>
    </div>
  </div></div>]]>
            </description>
            <link>https://yolken.net/blog/quitting-a-new-job</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627276</guid>
            <pubDate>Mon, 04 Jan 2021 02:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which journalists write the most ‘unsafe’ articles?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25627150">thread link</a>) | @babelsquid
<br/>
January 3, 2021 | https://adalytics.io/blog/journalists-with-the-most-unsafe-content | <a href="https://web.archive.org/web/*/https://adalytics.io/blog/journalists-with-the-most-unsafe-content">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>A previous <a href="https://adalytics.io/blog/tens-of-thousands-of-news-articles-are-labeled-as-unsafe-for-advertisers">Adalytics</a> post discussed how tens of thousands of articles on the <em>New York Times</em>, <em>Wall Street Journal</em>, <em>Forbes</em>, and <em>CNBC</em> websites appear to be marked as ‘unsafe’ by brand safety ad tech vendors. The post documented that those brand safety values appear to be utilized in ad auctions and ad server requests, meaning they could potentially be affecting news publishers’ ad revenues.&nbsp;</p><p>Earlier this year, journalists at a hedge-fund owned California newspaper <a href="https://www.bizjournals.com/sacramento/news/2020/10/19/mcclatchy-tie-pay-to-clicks.html">declared</a> they were fighting an effort to tie performance reviews based on the “the popularity of their stories as measured by clicks.” Most major news publishers retain a long-standing separation between the revenue and editorial departments of their organizations. However, the mere possibility that ad revenue could in some rare instances bias managerial decisions warrants a further investigation into the factors that may influence the monetary value of a journalist’s content.

This analysis focuses on how content from individual journalists and contributors at The <em>New York Times</em> (NYT), <em>Wall Street Journal</em> (WSJ), <em>CNBC</em>, and <em>Forbes</em> are categorized as safe or unsafe by ad tech vendors. Notably, a number of war correspondents and Pulitzer Prize winners have more than two thirds of their news articles marked as ‘unsafe’ for certain digital ads to display on. Nicholas <a href="https://en.wikipedia.org/wiki/Nicholas_Kristof">Kristof</a>, a double Pulitzer Prize winner who frequently advocates for human rights, has over 300 of his NYT articles (60.5%) labeled as brand unsafe. </p><p>A <a href="https://adalytics.io/blog/tens-of-thousands-of-news-articles-are-labeled-as-unsafe-for-advertisers">previous</a> exploratory analysis of 22,722 recent New York Times articles revealed that 30.3% appeared to be labeled as unsafe by Οracle Grapeshοt. In this analysis, a more comprehensive dataset of 332,710 nytimes.com articles from 2015 to 2020 was assembled. For each of these articles that used Javascript code from Grapeshοt, a given page was considered to be ‘safe’ if it contained the term ‘gv_safe’ (based on information released in Grapeshοt’s documentation), and ‘unsafe’ if it included any labels such as ‘gv_crime’, ‘gv_adult’ or other unsafe categories. A large number (but not all) articles contained clearly labeled ‘author’ meta tags and ‘section’ meta tags that could be used to group articles.</p><p>The table below indicates which New York Times journalists and contributors had the largest proportion of their content labeled as ‘unsafe’. </p><p>Ali <a href="https://www.nytimes.com/by/ali-winston">Winston</a>, an investigative reporter who  “covers the New York City Police Department” and covered issues of criminal justice and surveillance across the United States, had more than 96% of his articles labeled as unsafe. Numerous foreign correspondents who cover warzones, such as Thomas <a href="https://www.nytimes.com/by/thomas-gibbons-neff">Gibbons-Neff</a> and Rukmini <a href="https://www.nytimes.com/by/rukmini-callimachi">Callimachi</a> (four time Pulitzer Prize finalist), had more than 90% of their articles labeled as ‘unsafe’. Double Pulitzer Prize winner and human rights activist Nicholas <a href="https://en.wikipedia.org/wiki/Nicholas_Kristof">Kristof</a> had 305 out of his 504 (60.5%) articles labeled as ‘unsafe’.</p><p><i>Table of observed Οracle Grapeshοt brand safety values from <a href="https://nytimes.com/">nytimes.com</a>, grouped by journalist or author.</i></p><p>Additionally, it’s clear that certain sections of the New York Times are disproportionately likely to be labeled as ‘unsafe’. For example, 79.3% articles in the "<a href="https://www.nytimes.com/section/obituaries">Obituaries</a>" section and 53.2% articles in the “<a href="https://www.nytimes.com/section/world">World</a>” section are labeled as unsafe. This is likely due to the fact that journalists often have to use keywords related to "death" when covering such topics, which may automatically trigger a negative classification.</p><p><i>Table of observed Οracle Grapeshοt brand safety values from <a href="https://nytimes.com/">nytimes.com</a>, grouped by section.</i></p><p>As discussed in the previous <a href="https://adalytics.io/blog/tens-of-thousands-of-news-articles-are-labeled-as-unsafe-for-advertisers">analysis</a>, the Wall Street Journal (as well as other News Corp owned web properties) appear to be using brand safety technology provided by Οracle’s Mοat division and Cοmscοre. The two vendors provide labels which appear to be incorporated into network requests to ad auctions and header bidding services.</p><p>Based on an analysis of 30,033 wsj.com pages, it appears that a number of journalists have more than 90% of their work labeled as ‘unsafe’ by either Mοat or Cοmscοre. Zusha <a href="https://www.wsj.com/news/author/zusha-elinson">Elison</a>, who covers various gun and police related topics, had 92% of his articles labeled as “moat_unsafe” often due to “gv_arms” or “gv_death_injury”. Ben <a href="https://www.wsj.com/news/author/ben-chapman">Chapman</a>, who “covers criminal justice for The Wall Street Journal in New York”, had at least 104 of his articles marked as "moat_unsafe".</p><p>Katherine <a href="https://www.wsj.com/news/author/katherine-clarke">Clarke</a>, who covers residential real estate, appears to have 74 out of 132 articles (56%) labeled as “brandsafe: unsafe” by Comscore.</p><p><i>Table illustrating how many articles by each WSJ journalist were labeled as "unsafe" by either Mοat or Cοmscοre</i></p><p>There are a number of notable journalists, columnists, and writers who focus primarily on covering various advertising or digital marketing related topics. It appears that these writers are not exempt from having their content classified as “unsafe” by various vendors.</p><p>Megan <a href="https://www.cnbc.com/megan-graham/">Graham</a>, a reporter who covers advertising and marketing for CNBC and previously worked at Ad Age, had 23 out of her cnbc.com 219 articles (11%) marked as “moat_unsafe”. 15 were unsafe due to “gv_death_injury”, 7 were marked as unsafe due to “gv_arms”, and 3 were marked as unsafe due to “gv_tobacco”. The cnbc.com website also appears to use semantic <a href="https://adtechdaily.com/2018/06/21/admantx-launches-its-new-hyper-granular-contextual-taxonomy-for-more-precise-contextual-targeting-in-the-gdpr-era/">contextual intelligence</a> technology from Admantx, a company that was <a href="https://integralads.com/news/integral-ad-science-acquires-admantx/">acquired</a> by Integral Ad Sciences (IAS) in 2019. The Admantx technology does not appear to have binary classifications for “safe” or “unsafe”, but rather, seems to allow individual advertisers to avoid showing their ads on webpages that contain individual keywords. This hypothesis is supported by the presence of what appear to be individual brands’ keyword lists in various Javascript network calls. </p><p><img src="https://lh3.googleusercontent.com/81MYYg9VNJb3Dn0IgzFKip0n_Klq2cgY1uOaLrpTRilIF-jJehcKjDJ5Rj3qVl_mKdU1BZVlXY6yFJ_hR4EhjHWloojQSNqi8_eObPXERggchiZgg0hLhnUV4yvFtLEalnJoI4zx" alt="Screenshot of Chrome Developer Tools showing IAS Admantx response values for an article on cnbc.com by Megan Graham"></p><p>The presence of a string ending in “_Neg” or “_Negative” may indicate that a given brand is blocking their digital ads from rendering on a given webpage due to the presence of certain keywords in that context (i.e. “Fidelity_Negative” may indicate that Fidelity wants to avoid having their ads show on that specific webpage). In Megan Graham’s case, 132 of her 219 cnbc.com articles contain the label "Barclays_Negative2" in the admantx.com network response. For example, 202 out 219 of her cnbc.com articles contain the Admantx label 'ErnstYoung_Neg', which may indicate that the British professional services firm Ernst &amp; Young want to avoid placing their ads on 92% of Graham’s articles because they consider them to be brand “unsafe”. Some of the keyword lists include interesting names, such as “IBM_JeffreyEpstein”, which appeared on 154 of Graham’s articles, or “FlexShares_Coronavirus” which appeared on 130 of her webpages.</p><p><i>Table illustrating which IAS Admantx category and keyword labels appear most frequently across CNBC reporter Megan Graham’s 219 articles. Some of these labels may correspond to brand specific keyword blocklists, which prevent a given brand’s digital ads from rendering on a given webpage. For example, the presence of “ErnstYoung_Neg” may indicate that the professional services firm Ernst &amp; Young is blocking their ads from showing on 202 of Megan Graham’s CNBC articles due to presence of certain keywords on those pages.</i></p><p>Sheila <a href="https://www.reuters.com/journalists/sheila-dang">Dang</a>, an advertising-focused Reuters reporter, had 7 out of 193 of her articles labeled as "moat_unsafe". Her February <a href="https://www.reuters.com/article/us-football-nfl-superbowl-advertising-idUSKBN1ZX2JO">article</a> about how "<em>Doritos take top spot in Super Bowl Ads</em>" was categorized as "gv_arms" - this likely corresponds to a Oracle Data Cloud "avoidance category" <a href="https://www.oracle.com/a/ocom/docs/corporate/acquisitions/grapeshot-methodology.pdf">which</a> "avoids webpage textual content
around guns and weapons". Another <a href="https://www.reuters.com/article/us-cbs-results/cbs-beats-wall-street-estimates-for-quarterly-revenue-idUSKBN1KN2SQ">article</a> from August, 2018 about how "<em>CBS beats Wall Street estimates for quarterly revenue</em>", was labeled as "moat_unsafe" due "gv_crime". This is likely a reference to an avoidance category <a href="https://www.oracle.com/a/ocom/docs/corporate/acquisitions/grapeshot-methodology.pdf">about</a> "sex and violent" crime segments.</p><p>Similarly to Megan Graham, many of Dang's articles also contain Admantx labels which may correspond to brand specific keyword exclusion lists. It appears that a large French luxury goods conglomerate may be blocking their ads from 75.1% of Dang's <em>reuters.com</em> articles. Several large software and banking corporations also appear to take issue with some keywords that appear on 60% of Dang's news pieces.</p><p><i id="reuters-shiela-dang-brandsafety-airtable">Table of IAS Admantx and Oracle Moat brand safety labels for 193 <a href="https://reuters.com/">reuters.com</a> articles by Shiela <a href="https://www.reuters.com/journalists/sheila-dang">Dang</a>. The table has three tabs. The first tab shows each individual article, and IAS Admantx labels were observed for that given article. Some of these may potentially correspond to client specific keyword exclusion lists. The second tab contains an aggregate summary of how many of Dang's articles contained a given label. The third tab includes data about which of Dang's Reuters articles were labeled as "moat_unsafe" and the associated <a href="https://www.oracle.com/a/ocom/docs/corporate/acquisitions/grapeshot-methodology.pdf">avoidance</a> categories.</i></p><p>Dr. Augustine <a href="https://www.forbes.com/sites/augustinefou">Fou</a>, a cybersecurity and anti-ad fraud consultant who previously taught digital marketing strategy at NYU, had posted 123 articles on Forbes’ CMO <a href="https://www.forbes.com/cmo-network/">network</a> section. Of these, 59 articles (48% of total) were marked as “moat_unsafe”, with 58 labeled as “gv_crime”, while <a href="https://www.forbes.com/sites/augustinefou/2020/06/03/its-4am-do-you-know-where-your-ads-ran/">one</a> was labeled as unsafe due to “gv_adult”.</p><p>Tiffany <a href="https://www.nytimes.com/by/tiffany-hsu">Hsu</a>, a New York Times media reporter focusing on advertising and marketing, had 121 out of 358 of her articles (33.8%) between 2015 and 2020 marked as “unsafe” by Οracle Grapeshοt.</p><p><img src="https://lh3.googleusercontent.com/TKqPLZgegyHSMeuA0Jt4IWwQRykvl2oI1GK5h0PbewzwvaLzCcICCQMUdpQ9A725WHckDGNmEqFocHayq0E7MJJXeXcNpennBljYshws-I8VXdUJ9lC85ysQAS-wLYdRAYOXXQof" alt="null"><i>Screenshot of Chrome Developer Tools illustrating that a recent <a href="https://www.nytimes.com/2020/12/07/business/media/holiday-commercials-coronavirus-pandemic.html">article</a> by New York Times journalist Tiffany Hsu was marked as “unsafe” due to “gv_death_injury”</i></p><p>It appears that a large number of Hsu’s nytimes.com articles are labeled as containing hate speech (“gv_hatespeech”), or depicting or promoting crime, terrorism, or adult content (“gv_crime”, “gv_terrorism”, “gv_adult”, respectively). Additionally, a number of large brands, such as MasterCard (“neg_mastercard”), Chanel (“neg_chanel”), Google (“neg_google”) and Capital One (“neg_capitalone”) appear to be blocking their digital ads from web pages containing Hsu’s content.</p><p><i>Table illustrating which 121 of New York Times reporter Tiffany Hsu’s articles were labeled “unsafe” by Οracle Grapeshοt. The last column includes what appear to be company or brand …</i></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adalytics.io/blog/journalists-with-the-most-unsafe-content">https://adalytics.io/blog/journalists-with-the-most-unsafe-content</a></em></p>]]>
            </description>
            <link>https://adalytics.io/blog/journalists-with-the-most-unsafe-content</link>
            <guid isPermaLink="false">hacker-news-small-sites-25627150</guid>
            <pubDate>Mon, 04 Jan 2021 01:47:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SchemeMosaic: A free musical concatenative synthesis system in S7 Scheme]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25626927">thread link</a>) | @notorious-dto
<br/>
January 3, 2021 | http://xelf.me/scheme-mosaic.html | <a href="https://web.archive.org/web/*/http://xelf.me/scheme-mosaic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="outline-container-orgccf40df">
<h2 id="orgccf40df">Description</h2>
<div id="text-orgccf40df">
<p>
SchemeMosaic is a digital music mashup tool inspired by Steven Hazel's
<a href="http://awesame.org/soundmosaic/">soundmosaic</a>. The main technique employed is concatenative
synthesis. You can find out more about that <a href="https://en.wikipedia.org/wiki/Concatenative_synthesis">on wikipedia.</a>
</p>

<p>
SchemeMosaic is written in S7 Scheme as an extension to the <a href="https://ccrma.stanford.edu/software/snd/">Snd
editor</a>, and is released under the GPL Version 3. Right now
SchemeMosaic is under construction, and only tested with Snd 20.9 and
greater. (Snd itself is distributed under an MIT-like license.)
</p>

<p>
The goal is to reimplement soundmosaic with improved sound quality,
new features, and musical intelligence so that it can slice and
dice beats and remap tones (and, possibly someday, morph songs into
each other with the use of Autotalent and other algorithms.)
</p>

<p>
SchemeMosaic is designed to assist with making various kinds of
electronic music, such as so-called chopped and screwed or
vaporwave music. When you run SchemeMosaic, the input file is
sliced into (usually) beat-sized regions; these beat-slices are
then subject to chopping (rearrangement, repetition, skipping) and
screwing (pitch-shifting, time-stretching, and other effects.) With
various helper functions, SchemeMosaic will automatically chop and
screw according to your specifications. This can include arbitrary
Scheme code with the full power of Snd at your disposal.
</p>

<p>
Here is an Emacs image-dired view of a database:
</p>


<p><img src="http://xelf.me/snippets.png" alt="snippets.png">
</p>

<p>
The current version has GUI support via Emacs, for fully interactive
chop-and-screw sessions. The goal is a kind of exploratory
concatenative synthesis. Output can be saved to WAV or FLAC for use
with other applications such as Audacity, Mixxx, LMMS, Ardour, and so
on.
</p>

<p>
SchemeMosaic can use Soundtouch to guess the tempo (beats per minute)
of a song. The soundstretch command line program must be installed. If
you can't get that working, or if the result is inaccurate, try out
the BPM detection in <a href="http://mixxx.org/">Mixxx</a> and enter the number it reports into
SchemeMosaic.
</p>
</div>
</div><div id="outline-container-orgb9f020e">
<h2 id="orgb9f020e">Highlights</h2>
<div id="text-orgb9f020e">
<p>
2021-02-05: SchemeMosaic can now use a neural network to guess whether
a given sound slice contains a kick, snare, or cymbal. See this video:
<a href="http://xelf.me/scheme-mosaic-beat-slicer-wizard-demo-2.mkv">MKV file</a> or <a href="https://www.youtube.com/watch?v=aa_ntQGECg4">YouTube</a>. I plan to include more types of percussion and
other tasks for the neural network soon, and this is a very exciting
new portion of the work.
</p>

<p>
2021-01-02: Here is <a href="http://xelf.me/slicer-3.png">a screenshot</a> of SchemeMosaic running with the
snazzy "Nano" config.
</p>

<p>
2021-01-02: <a href="http://xelf.me/slicer-2.png">New screenshot</a> of improved Beat Slicer Wizard with new
features.
</p>

<p>
2021-01-01: New video of Beat Slicer Wizard: <a href="http://xelf.me/scheme-mosaic-beat-slicer-wizard-demo-1.mkv">MKV file</a> or <a href="https://www.youtube.com/watch?v=4E6-nVQ28BQ">YouTube</a>.
</p>

<p>
2020-12-30: I'm working on a new Beat Slicer Wizard. <a href="http://xelf.me/slicer.png">Click for screenshot.</a>
</p>

<p>
2020-12-29: New audio experiments: <a href="http://xelf.me/scanners-ex.mp3">1</a> <a href="http://xelf.me/cool-loops-2.mp3">2</a> <a href="http://xelf.me/thetamax.mp3">3</a>. I've also added functions
that can use XMP to split an XM song into separate tracks and import
them at the proper BPM, soon to be wrapped in a nice "Module wizard"
that should help SchemeMosaic interoperate with the world of
Module tracking.
</p>

<p>
2020-12-27: I'm working on a Beatbox wizard, where you beatbox into
the mic with your mouth and SchemeMosaic attempts to come up with a
sampled beat to match. It's a very crude proof of concept, but have a
listen to <a href="http://xelf.me/beatbox-demo-2.mp3">this two-part mp3</a> that begins with me beatboxing and then
switches to a resynthesized version matched from a database of sliced
drum loops. Here is also <a href="http://xelf.me/beatbox-demo-4.mp3">another demo.</a> And <a href="http://xelf.me/beatbox-demo-5.mp3">another</a>.
</p>

<p>
2020-12-26: I've added various "Wizards" to help with getting started
and doing common tasks. Here are the screenshots: <a href="http://xelf.me/wizards-1.png">Wizards 1</a> <a href="http://xelf.me/wizards-2.png">Wizards 2</a>
</p>

<p>
2020-12-24: A Merry Witch-House Christmas to you! Here is the latest
content from the world of SchemeMosaic:
</p>

<ul>
<li><a href="http://xelf.me/resource-E1.mp3">http://xelf.me/resource-E1.mp3</a> An old Farbrausch demoscene beat
chopped-and-screwed with auto-matched "Witch-House" music sliced
from dozens of tracks. Pretty wild results!</li>
<li>New demo video: <a href="https://www.youtube.com/watch?v=VQbI8zMMrww">YouTube video</a> or <a href="http://xelf.me/scheme-mosaic-demo-2020-2.mkv">MKV file</a></li>
<li>Other recent audio: <a href="http://xelf.me/scheme-mosaic-2020-2.mp3">http://xelf.me/scheme-mosaic-2020-2.mp3</a></li>
<li>Older example: an <a href="http://xelf.me/coherent-4.mp3">audio sample</a> of SchemeMosaic automatically
matching vocal and guitar elements to a backing track that is also
chopped and screwed, with a bit of postprocessing in Mixxx and
Audacity.</li>
</ul>


<p><img src="http://xelf.me/screenshot-thumbnail.png" alt="screenshot-thumbnail.png">
</p>

<ul>
<li><a href="http://xelf.me/screenshot.png">(Click for full view)</a> A nice screenshot of the Chopper/Looper
interfaces. You can now dynamically switch databases on the fly
during a session by specifying the database folder in the
approprate spreadsheet cell. You can loop the resulting files with
Ecasound, or open them in Audacity. More to come!</li>
</ul>
</div>
</div><div id="outline-container-org55f9ed0">
<h2 id="org55f9ed0">Licensing</h2>
<div id="text-org55f9ed0">
<p>
EmacsMosaic and SchemeMosaic are Free Software released under the
terms of the GNU General Public License, Version 3. You can find a
copy included in the Mosaic project directory, in a file called
LICENSE. You can also find the full text at:
</p>

<ul>
<li><a href="https://www.gnu.org/licenses/gpl-3.0.html">https://www.gnu.org/licenses/gpl-3.0.html</a></li>
</ul>

<p>
Several Emacs Lisp library components are also included. These are:
</p>

<ul>
<li>midi.el, jack.el, and ecasound.el (by Mario Lang, GPL)</li>
<li>ladspa.el (by T.V. Raman, GPL)</li>
<li>inf-snd.el (by Michel Scholz, MIT License)</li>
<li>cell.el (by David O'Toole, GPL)</li>
</ul>

<p>
See each file for full copyright and licensing information.
</p>

<p>
Audio functionality is built on Bill Schottstaedt's Snd editor and the
Ecasound HDR application. The Mosaic project installation includes
full licensing information and sources for the included Emacs Lisp
components; on platforms where Ecasound and Snd are shipped alongside
Mosaic, full sources are included for the applications themselves as
well. Please see their respective websites for more information.
</p>

<ul>
<li><a href="http://nosignal.fi/ecasound/">http://nosignal.fi/ecasound/</a> GPL.</li>
<li><a href="https://ccrma.stanford.edu/software/snd/snd/snd.html">https://ccrma.stanford.edu/software/snd/snd/snd.html</a> Snd is
distributed under an MIT-like license.</li>
</ul>

<p>
On Windows systems, Mosaic works with Cygwin and a number of its
packages. See <a href="http://cygwin.org/">http://cygwin.org/</a> for full information on Cygwin.
</p>

<p>
The `defun-memo' facility is based on code by Peter Norvig
for his book "Paradigms of Artificial Intelligence
Programming". The modified version is redistributed here.
</p>

<p>
You can find more information on Norvig's book, and the full license
for the `defun-memo' code, at his website:
</p>

<ul>
<li><a href="http://www.norvig.com/paip.html">http://www.norvig.com/paip.html</a></li>
<li><a href="http://www.norvig.com/license.html">http://www.norvig.com/license.html</a></li>
</ul>

<p>
The neural network implementation is in the public domain, by Scott
E. Fahlman for Carnegie-Mellon University.
</p>
</div>
</div><div id="outline-container-orgdcb0227">
<h2 id="orgdcb0227">Overview of usage</h2>
<div id="text-orgdcb0227">
<p>
This document covers SchemeMosaic internals. Check out
<a href="http://xelf.me/emacs-mosaic.html">http://xelf.me/emacs-mosaic.html</a> for information on using SchemeMosaic
through Emacs.
</p>

<p>
The sound slices that SchemeMosaic processes are called
regions. SchemeMosaic keeps a special hash table where a set of
properties for each region are recorded. Each property list is the
descriptor of its region. As stored in the hash table
*REGION-&gt;PROPERTIES*, these data together with the corresponding
regions constitute the database being used for concatenative
synthesis. The descriptors are the keys used to search for sounds in
the database. You can match against the entire database, or any subset
at a time.
</p>

<p>
The objects that generate sound mosaics are called synths. The main
way of getting things done is to call GENERATE-REGIONS on synths of
various synth classes, and mix, match, and chain them. SPLICE-SYNTHS
or other functions can be used to combine synths. 
</p>

<p>
The object system used by SchemeMosaic is the one included with Snd,
defined in stuff.scm and s7test.scm, plus a few tweaks of my
own. To avoid conflicts with other programs, I append a caret to the
names of the main OO symbols so that you use DEFINE-CLASS^,
DEFINE-METHOD^, and MAKE-INSTANCE^. The system it implements is a
simplified CLOS.
</p>

<p>
To find your project files easily, you may wish to set
(MOSAIC-PROJECT-DIRECTORY) to something like
/home/username/myproject/ and then make calls to (PROJECT-FILE
FILENAME).
</p>

<p>
Further below is a dictionary for all the important elements of
SchemeMosaic. To get an overview of how things work, check out the
following entries:
</p>

<ul>
<li>SYNTH - Base class for SchemeMosaic sound generators.</li>
<li>MOSAIC-SYNTH - Chop'n'screw utility class.</li>
<li>SHIFT-MATCH-SYNTH - Pitch-shift near-matches (or not-so-near matches) to the target.</li>
<li>STRETCH-MATCH-SYNTH - Time-stretch different length regions to the target length.</li>
<li>SEARCH-MATCH-SYNTH - Search databases and match snippets to target.</li>
<li>FILE-SYNTH - Load any sound file into a new synth.</li>
<li>MAKE-INSTANCE^ - Make a new object of any class.</li>
<li>MOSAIC-PROJECT-DIRECTORY - Where SchemeMosaic looks for files.</li>
<li>PROJECT-FILE - How to look for files.</li>
<li>REMEMBER-REGION-PROPERTIES - Selecting what you want to match.</li>
<li>MATCH-PROPERTIES - Finding regions that matching properties exactly.</li>
<li>FUZZY-MATCH-PROPERTIES - Matching regions more flexibly.</li>
<li>MATCH-REGIONS - Matching up regions whose properties match.</li>
<li>SHIFT-MATCH-REGIONS - Pitch shifting to correct suboptimal matches.</li>
<li>SHUFFLE - Rearranging and processing groups of regions.</li>
<li>GENERATE-REGIONS - The synth computes its output.</li>
<li>FIND-REGIONS - Cache output on demand.</li>
<li>MERGE-SOUND - Concatenate regions into a single sound.</li>
<li>SYNTH-SOUND - Concatenate a synth's output into a single sound.</li>
<li>MIX-SOUNDS - Mix two sounds.</li>
<li>CHAIN-SYNTHS - Connect the input of one synth to the output of another.</li>
<li>SPLICE-SYNTHS - Use sound from one synth and structure from another.</li>
</ul>
</div>

<div id="outline-container-orga1b6b6e">
<h3 id="orga1b6b6e">Differences between SchemeMosaic and the original soundmosaic</h3>
<div id="text-orga1b6b6e">
<ul>
<li>SchemeMosaic, by default, applies click reduction when merging
fragments.</li>
<li>SchemeMosaic does not scale source regions to match the amplitude
of the target region. This may be added as an option so that
results can follow the amplitude contour of the target if desired,
but doing it by default can cause problems with a cappella
vocals. If a quiet area is matched to a louder one, soundmosaic
will scale it up. When this is applied to the near-silences between
words in an a cappella vocal track, the result is bursts of loud
noise in between better matches.</li>
<li>SchemeMosaic can pitch-shift suboptimal pitch matches, and has
many other new features.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc9c8031">
<h3 id="orgc9c8031">Known issues</h3>
<div id="text-orgc9c8031">
<ul>
<li>Time-stretching needs improvement. It isn't terrible, but sounds
too reverberated for my taste. Some "new improved"
stretching/shifting functions are under construction, and are named
STRETCH-REGION* and SHIFT-REGION* instead of SHIFT-REGION and
STRETCH-REGION. SchemeMosaic will try to offer several options in
each category while choosing reasonable defaults.</li>
<li>Som…</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://xelf.me/scheme-mosaic.html">http://xelf.me/scheme-mosaic.html</a></em></p>]]>
            </description>
            <link>http://xelf.me/scheme-mosaic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626927</guid>
            <pubDate>Mon, 04 Jan 2021 01:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Write For Your Reader, a weekend project for nested writing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25626591">thread link</a>) | @aaron5
<br/>
January 3, 2021 | https://paaronmitchell.com/w4r/ | <a href="https://web.archive.org/web/*/https://paaronmitchell.com/w4r/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://paaronmitchell.com/w4r/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626591</guid>
            <pubDate>Mon, 04 Jan 2021 00:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas for Your Startup's Blog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25626496">thread link</a>) | @mooreds
<br/>
January 3, 2021 | https://draft.dev/learn/posts/startup-blog-ideas | <a href="https://web.archive.org/web/*/https://draft.dev/learn/posts/startup-blog-ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
<article>
  <div>
    
    <p><img src="https://draft.dev/learn/assets/posts/startup-blog-ideas.jpg" alt="Lead image for 50+ Ideas for Your Startup's Blog">
    </p>
    
    

    <p>
      
      Published in
        
          <a href="https://draft.dev/learn/posts/">posts</a>
        
      by
      
       Karl Hughes&nbsp;&nbsp;&nbsp;—&nbsp;
      5 minute read
    </p>

    
      <p>Coming up with ideas for your startup’s blog can be mentally taxing. While an <a href="https://ahrefs.com/blog/seo-audit/">SEO audit</a> can help you find opportunities in Google results, it can leave your blog topics feeling a little bit flat.</p>

<p>One strategy is to publish a mix of SEO-driven content with more creative, shareable posts that help you build organic backlinks and social proof. If you want to make sure you <a href="https://draft.dev/learn/posts/ideas">always have some ideas in the hopper</a>, you need to put a healthy backlog of creative blog post ideas into <a href="https://draft.dev/learn/posts/publishing-calendar">your publishing calendar</a></p>


      


      
<p>Over the past decade, I’ve written a lot of blog posts and I’ve seen many of these ideas work for myself or clients. While not every idea in this list is going to be a good fit for your startup, these might help spark your creativity.</p>

<h2 id="50-startup-blog-post-ideas">50+ Startup Blog Post Ideas</h2>

<h3 id="1-product-awareness">1. Product Awareness</h3>
<p>These ideas are great if your startup is still in the launch and product-market fit phase. Once you start building a collection of posts explaining your product, you can send these to prospective customers to help make your case.</p>

<p>Later on, as your product gains traction, these posts will offer Google searchers authoritative information that guides them into your funnel. If you’re going to start blogging, covering these topics should be at the top of your list.</p>

<ul>
  <li>Highlight a little-known feature of your product.</li>
  <li>Highlight various use cases for your product.</li>
  <li>Write a “how to” guide for using/buying/setuping up your product.</li>
  <li>Create a customer case study.</li>
  <li>“10 ways to solve problem X” (One of which includes your product).</li>
  <li>Mythbusting a problem your product solves.</li>
  <li>Compare your product to your competition.</li>
  <li>Do a screencast or record a video using your product.</li>
  <li>Share an excerpt from an ebook, white paper, webinar, etc. with a call to action to download it.</li>
  <li>Respond to frequently asked questions about your product.</li>
</ul>

<h3 id="2-interviews-and-surveys">2. Interviews and Surveys</h3>
<p>Another interesting way to generate content without quite as much writing work is to compile data from customers, partners, and prospects. I have published many interview posts and compiled the advice from an interview series into a comprehensive guide.</p>

<p>This strategy can net you dozens of blog posts with just a few hours of work, and your interviewees might even share it with their audience.</p>

<ul>
  <li>Interview customers who are using your product.</li>
  <li>Interview industry specialists.</li>
  <li>Interview someone who used to work for a competitor.</li>
  <li>Interview a professor, recent graduate, or someone who just retired from your industry.</li>
  <li>Interview speakers or sponsors at a conference.</li>
  <li>Ask a question or conduct a poll on <a href="https://twitter.com/">Twitter</a> and share the results.</li>
  <li>Do a survey with Survey Monkey (or <a href="https://draft.dev/learn/tools/surveys">one of these other tools</a>) among your community members.</li>
  <li>Get experts to offer a tip and do a round-up of their recommendations.</li>
  <li>Feature guest posts from industry experts.</li>
</ul>

<h3 id="3-roundups">3. Roundups</h3>
<p>Lists of tools, tips, and ideas (like this one) are among the most widely-shared and easily read content on the internet. Readers can skim the piece quickly and use the roundup as a jumping-off point for solving their problems, and <a href="https://www.grizzle.io/listicles/">they tend to rank well in Google</a>.</p>

<p>Here are a few ideas for generating lists that might do well on your blog:</p>

<ul>
  <li>Compile a list of popular sites in your industry (be sure to notify them and encourage them to share).</li>
  <li>Compile the most popular social media posts in your industry this month/year/week.</li>
  <li>Create a list of benefits for doing something.</li>
  <li>Create a list of things to avoid.</li>
  <li>Find tips in other content, create a list of those tips, and give links to those articles as the sources.</li>
  <li>Share a list of conference takeaways.</li>
  <li>Collect the top motivational YouTube videos, ebooks, webinars, or infographics for your audience.</li>
  <li>Collect Tweets from a webinar or conference hashtag, and offer your own takeaways in the blog post.</li>
  <li>Create a list of trends to watch.</li>
  <li>Make a list of products that complement yours well.</li>
  <li>Collect a list of social media accounts people in your industry should follow.</li>
</ul>

<h3 id="4-thought-leadership">4. Thought Leadership</h3>
<p>Positioning your startup’s founders as important leaders in the space is a good way to build your brand and showcase your expertise. Some founders do this naturally, and others work with a ghostwriter. Either way, people in your leadership team should make a point to do some thought leadership content as you get your blog started.</p>

<ul>
  <li>Take a stand on a controversial issue.</li>
  <li>Make a prediction related to your industry.</li>
  <li>Industry trends commentary.</li>
  <li>Side-by-side comparison of complementary company/service.</li>
  <li>Review a book your customers should read.</li>
  <li>Point out common mistakes in your industry and offer solutions on how to fix or avoid them.</li>
  <li>Relate your content to a current event or a celebrity (eg: “5 Lessons from Lady Gaga” or “What the Election Teaches Us About…”).</li>
  <li>Take the contrarian position on someone else’s article that you disagree with.</li>
  <li>Share your slides from a recent presentation.</li>
  <li>Respond to industry research with your own perspective. Offer a fresh angle to spark conversation.</li>
  <li>Do an in-depth case study about one company, or offer a few examples of how other companies do something successfully.</li>
  <li>Offer industry takeaways about breaking news.</li>
</ul>

<h3 id="5-team-company-and-culture-focus">5. Team, Company, and Culture Focus</h3>
<p>Finally, if you’re looking to build more content that attracts talent or showcases your team, here are a few ideas:</p>

<ul>
  <li>Highlight your culture, mission, or values.</li>
  <li>Write about “What we’re not”.</li>
  <li>Create a music video for your company.</li>
  <li>Interview each member of your team about their career and experience.</li>
  <li>Post photos from a recent event/conference.</li>
  <li>Post screenshots from a virtual event.</li>
  <li>Videos/photos of employees behind the scenes.</li>
  <li>If someone gets promoted, talk about how/why they were successful.</li>
  <li>Post about the current season or holiday.</li>
  <li>Sum up the year that was.</li>
</ul>

<p>Finally, if you’re looking for writers to help you generate more content on your startup’s blog, <a href="https://draft.dev/">check out our services at Draft.dev</a>. We focus exclusively on technical content written by subject matter experts, so you’ll get industry-leading knowledge without distracting your engineers.</p>

    

    

    
      <div>
  
  <p><img src="https://draft.dev/learn/assets/authors/karl.png" alt="Karl Hughes"></p><h4>
    By Karl Hughes
    
      <a href="https://twitter.com/karllhughes" target="_blank" title="@karllhughes on Twitter"><i></i></a>
    
    
      <a href="https://www.karllhughes.com/" target="_blank" title="Karl Hughes's website"><i></i></a>
    
  </h4>
  <p>Karl is a former startup CTO and the founder of Draft.dev. He writes about technical blogging and content management.</p>
</div>

    

    <section>
  <a href="https://draft.dev/?utm_source=academy&amp;utm_medium=banner&amp;utm_campaign=post&amp;utm_content=/posts/startup-blog-ideas#playbook">
    <img alt="The Technical Content Manager's Playbook" src="https://draft.dev/assets/images/image02.jpg?v67688666733061">
  </a>
  <h3>Build a Blog that Software Developers Will Read</h3>
  <p><a href="https://draft.dev/?utm_source=academy&amp;utm_medium=banner&amp;utm_campaign=post&amp;utm_content=/posts/startup-blog-ideas#playbook">The Technical Content Manager’s Playbook</a> is a collection of resources you can use to manage a high-quality, technical blog:</p>
  <ul>
    <li>A template for creating content briefs</li>
    <li>An Airtable publishing calendar</li>
    <li>A technical blogging style guide</li>
  </ul>
  
</section>



    
       <!-- End Comment Area -->

    
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</section></div>]]>
            </description>
            <link>https://draft.dev/learn/posts/startup-blog-ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626496</guid>
            <pubDate>Sun, 03 Jan 2021 23:58:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Debug Things]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25626433">thread link</a>) | @rodarmor
<br/>
January 3, 2021 | https://rodarmor.com/blog/how-to-debug-things/ | <a href="https://web.archive.org/web/*/https://rodarmor.com/blog/how-to-debug-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <li>
        <p>What is happening?</p>
      </li>
      <li>
        <p>What is a hypothesis that would explain why this is happening?</p>
      </li>
      <li>
        <p>How can you test this hypothesis?</p>
      </li>
      <li>
        <p>Test it! What did you do?</p>
      </li>
      <li>
        <p>Did it work? If not, write down what happened and go back to step 2.</p>
      </li>
      <li>
        <p>You're done! Nice work!</p>
      </li>
    </div></div>]]>
            </description>
            <link>https://rodarmor.com/blog/how-to-debug-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626433</guid>
            <pubDate>Sun, 03 Jan 2021 23:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letting Go of Nostalgia Urbanism]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25626389">thread link</a>) | @oftenwrong
<br/>
January 3, 2021 | https://www.granolashotgun.com/granolashotguncom/2mvygaw3y67fx5bqrvno2lp452zifc | <a href="https://web.archive.org/web/*/https://www.granolashotgun.com/granolashotguncom/2mvygaw3y67fx5bqrvno2lp452zifc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">
      
        
      

      


      <main id="page" role="main">
        
          <article data-page-sections="5f8a230fe5c0524b4b548b6c" id="sections">
  
    <section data-test="page-section" data-section-theme="" data-section-id="5f8a230fe5c0524b4b548b6e" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
    &quot;imageOverlayOpacity&quot;: 0.15,
    &quot;video&quot;: {
      &quot;playbackSpeed&quot;: 0.5,
      &quot;filter&quot;: 1,
      &quot;filterStrength&quot;: 0,
      &quot;zoom&quot;: 0
    },
    &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
    &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
    &quot;customSectionHeight&quot;: 10,
    &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
    &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
    &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
    &quot;customContentWidth&quot;: 50,
    &quot;sectionTheme&quot;: &quot;&quot;,
    &quot;sectionAnimation&quot;: &quot;none&quot;,
    &quot;backgroundMode&quot;: &quot;image&quot;
  }" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5fc05d374e98326c0225b385"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_24622"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465889069-LJNKEZ3VLTU2R7MCOFSI/ke17ZwdGBToddI8pDm48kAzR-hM4gcNvb9chCN6oIxdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITdJ3NWP77uMzRAwh5D8T4qCZWTudfzugHEpqJeCRufA/Screen+Shot+2020-11-27+at+12.22.29+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465889069-LJNKEZ3VLTU2R7MCOFSI/ke17ZwdGBToddI8pDm48kAzR-hM4gcNvb9chCN6oIxdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITdJ3NWP77uMzRAwh5D8T4qCZWTudfzugHEpqJeCRufA/Screen+Shot+2020-11-27+at+12.22.29+AM.png" data-image-dimensions="867x574" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.22.29 AM.png" data-load="false" data-image-id="5fc0b95f7acac6192ade7d83" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465889069-LJNKEZ3VLTU2R7MCOFSI/ke17ZwdGBToddI8pDm48kAzR-hM4gcNvb9chCN6oIxdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITdJ3NWP77uMzRAwh5D8T4qCZWTudfzugHEpqJeCRufA/Screen+Shot+2020-11-27+at+12.22.29+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_18440"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606464959156-405INH9IEHU8FW46W7EW/ke17ZwdGBToddI8pDm48kJtMYPrFdeIySldACffy7OoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcfDcX1AvjFW7nkNyNEaPiGFJ6cZDPheO8EizRE9YbUyOEzPI7OPymHAjIz1PiTps-/Screen+Shot+2020-11-27+at+12.14.44+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606464959156-405INH9IEHU8FW46W7EW/ke17ZwdGBToddI8pDm48kJtMYPrFdeIySldACffy7OoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcfDcX1AvjFW7nkNyNEaPiGFJ6cZDPheO8EizRE9YbUyOEzPI7OPymHAjIz1PiTps-/Screen+Shot+2020-11-27+at+12.14.44+AM.png" data-image-dimensions="1015x567" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.14.44 AM.png" data-load="false" data-image-id="5fc0b5bb3570fb44d11ff30e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606464959156-405INH9IEHU8FW46W7EW/ke17ZwdGBToddI8pDm48kJtMYPrFdeIySldACffy7OoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcfDcX1AvjFW7nkNyNEaPiGFJ6cZDPheO8EizRE9YbUyOEzPI7OPymHAjIz1PiTps-/Screen+Shot+2020-11-27+at+12.14.44+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_22150"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465819158-SJ81LE3X0CYBISODBZ0V/ke17ZwdGBToddI8pDm48kJCaJXb43ybX31vxUqWzpjdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJs0sHYeEN3bks1m5kcLkvOL3od5fOqSPVU6s7BKhGqc/Screen+Shot+2020-11-27+at+12.28.39+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465819158-SJ81LE3X0CYBISODBZ0V/ke17ZwdGBToddI8pDm48kJCaJXb43ybX31vxUqWzpjdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJs0sHYeEN3bks1m5kcLkvOL3od5fOqSPVU6s7BKhGqc/Screen+Shot+2020-11-27+at+12.28.39+AM.png" data-image-dimensions="866x571" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.28.39 AM.png" data-load="false" data-image-id="5fc0b918145a8629dcce1b16" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465819158-SJ81LE3X0CYBISODBZ0V/ke17ZwdGBToddI8pDm48kJCaJXb43ybX31vxUqWzpjdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJs0sHYeEN3bks1m5kcLkvOL3od5fOqSPVU6s7BKhGqc/Screen+Shot+2020-11-27+at+12.28.39+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_26300"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465937544-L3JB7XR0OKFZNKLOZ1WP/ke17ZwdGBToddI8pDm48kJgoC33qUKS50BFDhprU9vpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIh9W0N4PmhLwTREodEvxRdcqtIyUg2O931PlHHyWUedw/Screen+Shot+2020-11-27+at+12.21.11+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465937544-L3JB7XR0OKFZNKLOZ1WP/ke17ZwdGBToddI8pDm48kJgoC33qUKS50BFDhprU9vpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIh9W0N4PmhLwTREodEvxRdcqtIyUg2O931PlHHyWUedw/Screen+Shot+2020-11-27+at+12.21.11+AM.png" data-image-dimensions="769x574" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.21.11 AM.png" data-load="false" data-image-id="5fc0b98f145a8629dcce22ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606465937544-L3JB7XR0OKFZNKLOZ1WP/ke17ZwdGBToddI8pDm48kJgoC33qUKS50BFDhprU9vpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIh9W0N4PmhLwTREodEvxRdcqtIyUg2O931PlHHyWUedw/Screen+Shot+2020-11-27+at+12.21.11+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-419c6a0771684686d35c"><div><p>Everyone has a natural habitat. For some people it’s a big house in the suburbs. For others it’s a cabin in the woods. Some people thrive in a high rise tower in the central business district. Mine is a Main Street town of the kind that peaked about a century ago. But there’s another more obscure environment that’s harder to define because it’s more about cultural imperatives rather than physical structures or location.</p><p>A reader reached out to me with a query. He and his wife and three daughters are in search of “a slower, more nature and community bound life, but without leaving behind people who read books, et cetera. I'm forever looking for where Henry Miller's Big Sur is today, or Provincetown, or even the Upper West Side of 1960, or the San Francisco of the early 90s. We have some money, but we don't want to be around people who are money driven.”</p><p>First, note that the desired location isn’t specifically urban or rural. There’s a huge spread between Manhattan and the rugged California coast at Big Sur. Provincetown and San Francisco are in-between versions of Main Street towns at different scales. And I don’t detect an inherent exclusion of a quality suburb in the statement either. The quest is about the intangibles that a place might provide.</p><p>I have to acknowledge the tension inherent in the quote. There’s a yearning for high culture, meaningful engagement with neighbors, and an attractive landscape. These things tend to cost extra and can be scarce. But there’s also a rejection of crass materialism.</p><p>Wouldn’t it be great to live in exactly the right place at the right time when everything was still super authentic and affordable, but simultaneously unique and undiscovered? The whole thing is problematic and, let’s be honest, a bit tone deaf in terms of class and such. I understand the impulse. I will admit to sharing this same desire myself. So how to square these romantic notions with external reality without being a complete ass about it? I’ll start by poking holes in the nostalgia.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_35196"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467279919-LOL0OAP45LDQJY7ZK31J/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.52.19+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467279919-LOL0OAP45LDQJY7ZK31J/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.52.19+AM.png" data-image-dimensions="866x572" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.52.19 AM.png" data-load="false" data-image-id="5fc0becceaf37e3b64b927f2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467279919-LOL0OAP45LDQJY7ZK31J/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.52.19+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_33097"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467235290-KHEN4ZOP0R9VXEBJXVKG/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.51.33+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467235290-KHEN4ZOP0R9VXEBJXVKG/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.51.33+AM.png" data-image-dimensions="866x572" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 12.51.33 AM.png" data-load="false" data-image-id="5fc0bea0fa04221c713d25bf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606467235290-KHEN4ZOP0R9VXEBJXVKG/ke17ZwdGBToddI8pDm48kL4maJ-2XkJtJYDWpYvzIhtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPj9CXki_2ufCT0xLt2clBEcTqdSN4NAs59Ef5Y9UQGk/Screen+Shot+2020-11-27+at+12.51.33+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606454661608_33388"><div><p>I got a flashback to my best friend Joann circa 1985. She was accepted to a prestigious art school in Manhattan and I helped her get settled into her first rented room. It was in pre-gentrification Times Square in what had once been a dentist office complete with linoleum floors, synthetic wood paneling, orange fiberglass chairs, and fluorescent lights. It felt like a public bus. There was no air conditioning in the sweltering heat of a New York summer. The makeshift kitchenette was equipped with an electric hot plate and an elderly microwave. Technically it wasn't a legal residence, but neither the authorities nor the landlord seemed to care. Code enforcement came years later - with Disney.</p><p>She rented her room from a married couple who painted and made documentary films about their artist friends in the city. Joann paid reduced rent in exchange for babysitting the couple's three year old son. Her bedroom was exactly the size of her mattress since the partition walls had been installed for maximum efficiency. The bedroom door opened outward toward the corridor and she would just fall in on the bed and hang her possessions on hooks like a boat. This was the version of urban loft living that never made it to the pages of Architectural Digest.</p><p>They all lived there because it was relatively cheap and the location allowed them to be close to the people and activities they cared about. They had an extraordinarily high tolerance for alcoholic schizophrenic neighbors. The accommodations were meant to be functional. They didn't strive to transform the place into anything beyond what it was. The apartment was filled with their art and film making equipment and the many visitors they collaborated with. The city was their living room, kitchen, and back garden.</p><p>While Joann was living there the couple bought a modest second home in rural Pennsylvania for about the cost of a nice car. Their goal was simple - provide a place to balance city life and enjoy the countryside with their kid without spending a lot of money. The house was absolutely nothing special and they made no effort to renovate the property beyond basic mechanical repairs. It wasn't in a bougie town with nice restaurants or themed boutiques. They hadn’t searched for a subdivision in a good school district. It was just a random spot in a farm field near nothing in particular.</p><p>What mattered most to them was the freedom that came with low overhead. Their city friends would migrate out with them for summer and winter holidays and they created their own cuisine, art, and conversation. And they read lots of books. They just weren't interested in much beyond the inner world they were busy creating themselves. They didn’t need to purchase culture from a fashionable postal code. They made their own. I learned a lot from that family and their example.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_14048"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606462756627-LKB104C89YPWN3EIBAZP/ke17ZwdGBToddI8pDm48kO1cgRulIxBmY7n2s6bOjt1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwZu4wMekelLZTX9Do1t5WT83_H9gLMBOoSUJpIR7ABjTuwWFeXoyRlDq-iPR6KshY/Screen+Shot+2020-11-26+at+11.38.30+PM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606462756627-LKB104C89YPWN3EIBAZP/ke17ZwdGBToddI8pDm48kO1cgRulIxBmY7n2s6bOjt1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwZu4wMekelLZTX9Do1t5WT83_H9gLMBOoSUJpIR7ABjTuwWFeXoyRlDq-iPR6KshY/Screen+Shot+2020-11-26+at+11.38.30+PM.png" data-image-dimensions="635x473" data-image-focal-point="0.5,0.5" alt="Source" data-load="false" data-image-id="5fc0ad23645712565457b115" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606462756627-LKB104C89YPWN3EIBAZP/ke17ZwdGBToddI8pDm48kO1cgRulIxBmY7n2s6bOjt1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwZu4wMekelLZTX9Do1t5WT83_H9gLMBOoSUJpIR7ABjTuwWFeXoyRlDq-iPR6KshY/Screen+Shot+2020-11-26+at+11.38.30+PM.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606454661608_14342"><div><p>Some years later I had a friend who worked at the <a href="https://www.stonybrook.edu/pkhouse/" target="_blank">Pollock-Krasner House and Study Center</a> on the far tip of Long Island which is now administered by Stony Brook University. In 1945 modern artist <a href="https://en.wikipedia.org/wiki/Jackson_Pollock" target="_blank">Jackson Pollock</a> and his wife, fellow artist <a href="https://en.wikipedia.org/wiki/Lee_Krasner" target="_blank">Lee Krasner</a>, bought the little house on an acre and a half with water views for $5,000. That’s the current inflation adjusted equivalent of $73,000 today. Their patron <a href="https://en.wikipedia.org/wiki/Peggy_Guggenheim" target="_blank">Peggy Guggenheim</a> provided the $2,000 down payment. Back then the average family earned $2,595 a year so a home could be bought with two years pay.</p><p>This was at a time when the Hamptons were still sleepy country villages and the national economy was only just emerging from wartime rationing. Their neighbors were farmers and fishermen, not financiers or movie stars. They had access to what was sold at the local general store, but not much else. And they were three hours from the city. Pollock struggled with his internal demons until his death in a drunken car wreck along with his mistress in 1956. The life of an artist isn’t always picturesque up close.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_45411"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469139165-360Z7NOQIXK2D93P1Z81/ke17ZwdGBToddI8pDm48kP1KCea1J2teI4nwUS_MuBJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIeT5PEy-wOpHUnASXsuEU6btuDXT-pSBSTw-kS8e3eJU/Screen+Shot+2020-11-27+at+1.23.59+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469139165-360Z7NOQIXK2D93P1Z81/ke17ZwdGBToddI8pDm48kP1KCea1J2teI4nwUS_MuBJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIeT5PEy-wOpHUnASXsuEU6btuDXT-pSBSTw-kS8e3eJU/Screen+Shot+2020-11-27+at+1.23.59+AM.png" data-image-dimensions="768x572" data-image-focal-point="0.5,0.5" alt="Source" data-load="false" data-image-id="5fc0c611f3de5e49b5829922" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469139165-360Z7NOQIXK2D93P1Z81/ke17ZwdGBToddI8pDm48kP1KCea1J2teI4nwUS_MuBJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIeT5PEy-wOpHUnASXsuEU6btuDXT-pSBSTw-kS8e3eJU/Screen+Shot+2020-11-27+at+1.23.59+AM.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_51302"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469778524-O2QI25BL1101T0515BD7/ke17ZwdGBToddI8pDm48kB0xX4-mxxlwxJNUAch3Es9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz8zLL_-grWEp2-40-OAbFGLN4T0Q-J2YCtG4E7dTOhFuIuEYppAGA1b9YlKHw3whE/Screen+Shot+2020-11-27+at+1.35.08+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469778524-O2QI25BL1101T0515BD7/ke17ZwdGBToddI8pDm48kB0xX4-mxxlwxJNUAch3Es9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz8zLL_-grWEp2-40-OAbFGLN4T0Q-J2YCtG4E7dTOhFuIuEYppAGA1b9YlKHw3whE/Screen+Shot+2020-11-27+at+1.35.08+AM.png" data-image-dimensions="730x480" data-image-focal-point="0.5,0.5" alt="Source" data-load="false" data-image-id="5fc0c88f9b1ed03538f9eb46" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469778524-O2QI25BL1101T0515BD7/ke17ZwdGBToddI8pDm48kB0xX4-mxxlwxJNUAch3Es9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz8zLL_-grWEp2-40-OAbFGLN4T0Q-J2YCtG4E7dTOhFuIuEYppAGA1b9YlKHw3whE/Screen+Shot+2020-11-27+at+1.35.08+AM.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_47512"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469305712-UKTZWLZ9BR2UJCJ136DX/ke17ZwdGBToddI8pDm48kFdIy3Yn5IOvQ4xRbRIt-QxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAAX1XxvvpTW-ZttZhUL8nSL6LcxCQwsRzJp9SYG5yYU/Screen+Shot+2020-11-27+at+1.26.38+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469305712-UKTZWLZ9BR2UJCJ136DX/ke17ZwdGBToddI8pDm48kFdIy3Yn5IOvQ4xRbRIt-QxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAAX1XxvvpTW-ZttZhUL8nSL6LcxCQwsRzJp9SYG5yYU/Screen+Shot+2020-11-27+at+1.26.38+AM.png" data-image-dimensions="866x576" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 1.26.38 AM.png" data-load="false" data-image-id="5fc0c6b6f8cdb769c600f90b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469305712-UKTZWLZ9BR2UJCJ136DX/ke17ZwdGBToddI8pDm48kFdIy3Yn5IOvQ4xRbRIt-QxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAAX1XxvvpTW-ZttZhUL8nSL6LcxCQwsRzJp9SYG5yYU/Screen+Shot+2020-11-27+at+1.26.38+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_49118"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469348456-E32BPGWYWORRPXR4JLMJ/ke17ZwdGBToddI8pDm48kEGbrvEkgXJCmz84el9gnudZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIXJemV0MUCjmECKRP05BN0sK9OQlYoVaQ_x8oiKRNrPs/Screen+Shot+2020-11-27+at+1.27.28+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469348456-E32BPGWYWORRPXR4JLMJ/ke17ZwdGBToddI8pDm48kEGbrvEkgXJCmz84el9gnudZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIXJemV0MUCjmECKRP05BN0sK9OQlYoVaQ_x8oiKRNrPs/Screen+Shot+2020-11-27+at+1.27.28+AM.png" data-image-dimensions="767x571" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 1.27.28 AM.png" data-load="false" data-image-id="5fc0c6e24e98326c022e809c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606469348456-E32BPGWYWORRPXR4JLMJ/ke17ZwdGBToddI8pDm48kEGbrvEkgXJCmz84el9gnudZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIXJemV0MUCjmECKRP05BN0sK9OQlYoVaQ_x8oiKRNrPs/Screen+Shot+2020-11-27+at+1.27.28+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606454661608_45702"><p>The Big Sur of <a href="https://en.wikipedia.org/wiki/Henry_Miller" target="_blank">Henry Miller</a>'s day in the 1940s and 50s was a remote stretch of rocky woods with none of the bells and whistles that came later. <a href="https://www.esalen.org/" target="_blank">Esalen</a> hadn't yet been established. The organic locavore caterers and spa treatments were still decades away. So were the exquisite country estates that now populate the forest. Miller and the oddball collection of pre-hippie touchy feely types were there because it was beautiful and cheap.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1606454661608_55944"><p>Miller’s first few books were banned in the United States because they were too racy for American culture at that time. He was on his third wife when he settled in at Big Sur and that marriage ended in divorce as well. Once his two children were grown he was an older man living in a small cottage in the forest alone much of the time. Miller helped establish the mystique of Big Sur, but the wealth that followed made his lifestyle difficult for others to replicate on a normal budget.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_59524"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472315723-2923678WQOWVJNZFCSFT/ke17ZwdGBToddI8pDm48kAHKzNBNL9lRgJntdUYVI7JZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQR_zMGaPiJWwaGr7RQo514WyMOmYilE_Bsyh3dPjGc0/Screen+Shot+2020-11-27+at+2.06.17+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472315723-2923678WQOWVJNZFCSFT/ke17ZwdGBToddI8pDm48kAHKzNBNL9lRgJntdUYVI7JZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQR_zMGaPiJWwaGr7RQo514WyMOmYilE_Bsyh3dPjGc0/Screen+Shot+2020-11-27+at+2.06.17+AM.png" data-image-dimensions="862x570" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 2.06.17 AM.png" data-load="false" data-image-id="5fc0d27a18e72e5fdbf69f8b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472315723-2923678WQOWVJNZFCSFT/ke17ZwdGBToddI8pDm48kAHKzNBNL9lRgJntdUYVI7JZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQR_zMGaPiJWwaGr7RQo514WyMOmYilE_Bsyh3dPjGc0/Screen+Shot+2020-11-27+at+2.06.17+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606454661608_61674"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472389115-XWQBGKHA07X8SEONTIRY/ke17ZwdGBToddI8pDm48kLEXWr63S8hiZkLgAU1_8A1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIRUFFKnsTJCBAf15irvV3SPDYJ87BYIlJ-KlI4tuuTMg/Screen+Shot+2020-11-27+at+2.14.22+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472389115-XWQBGKHA07X8SEONTIRY/ke17ZwdGBToddI8pDm48kLEXWr63S8hiZkLgAU1_8A1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIRUFFKnsTJCBAf15irvV3SPDYJ87BYIlJ-KlI4tuuTMg/Screen+Shot+2020-11-27+at+2.14.22+AM.png" data-image-dimensions="863x574" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-11-27 at 2.14.22 AM.png" data-load="false" data-image-id="5fc0d2c2f81c9a2a0cc187ab" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f8a22c7ac50d7106c90ad62/1606472389115-XWQBGKHA07X8SEONTIRY/ke17ZwdGBToddI8pDm48kLEXWr63S8hiZkLgAU1_8A1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIRUFFKnsTJCBAf15irvV3SPDYJ87BYIlJ-KlI4tuuTMg/Screen+Shot+2020-11-27+at+2.14.22+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606454661608_59813"><p>The Provincetown of Eugene …</p></div></div></div></div></div></div></div></article></div></div></div></section></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.granolashotgun.com/granolashotguncom/2mvygaw3y67fx5bqrvno2lp452zifc">https://www.granolashotgun.com/granolashotguncom/2mvygaw3y67fx5bqrvno2lp452zifc</a></em></p>]]>
            </description>
            <link>https://www.granolashotgun.com/granolashotguncom/2mvygaw3y67fx5bqrvno2lp452zifc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626389</guid>
            <pubDate>Sun, 03 Jan 2021 23:41:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the correct pronunciation of “gyro”?]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25626352">thread link</a>) | @throw0101a
<br/>
January 3, 2021 | https://talesoftimesforgotten.com/2021/01/03/what-is-the-correct-pronunciation-of-gyro/ | <a href="https://web.archive.org/web/*/https://talesoftimesforgotten.com/2021/01/03/what-is-the-correct-pronunciation-of-gyro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>In the United States, there is something of an intense debate over how the word&nbsp;<em>gyro</em>&nbsp;is supposed to be pronounced. Many people pronounce it /ˈdʒaɪɹoʊ/ (or, to use fauxnetics, “JAI-roh’). Many other people, however, insist that it is supposed to be pronounced /ˈjiː.ɹoʊ/ (that is, “YEE-roh” in fauxnetics). This debate even made it into the recent Disney Pixar animated film&nbsp;<em>Soul</em>, which includes a flashback scene in which a mischievous unborn soul named “Twenty-Two” is portrayed as arguing with the spirit of the ancient Greek mathematician Archimedes (lived c. 287 – c. 212 BCE) over the correct pronunciation of the word.</p>



<p>If I were an ordinary pedant, I would simply tell you that the pronunciation /ˈjiː.ɹoʊ/ is correct and that the people who say /ˈdʒaɪɹoʊ/ are wrong. I, however, am no ordinary pedant. On the contrary, I am the most obnoxious and loathsome kind of pedant: a pedant who has spent years studying the Greek language at the university level and who knows far too much about it for my own good.</p>



<p>Therefore, I feel the need to point out that<em>&nbsp;neither&nbsp;</em>of the pronunciations given above is reflective of the actual pronunciation of the word in Modern Greek, since the nominative singular form of the word in Greek is actually γύρος (<em>gýros</em>), with an /s/ sound on the end, and the nominative plural form is actually γύροι (<em>gýroi</em>). Moreover, I feel the need to explain exactly&nbsp;<em>why</em>&nbsp;the way the word is spelled in English is so different from how it is pronounced in Greek and to explain precisely how the debate over the pronunciation of the word arose.</p>



<p><strong>A little background</strong></p>



<p>In order to understand the roots of the present controversy over how the word&nbsp;<em>gyro</em>&nbsp;should be pronounced, we need to understand why Greek words are often transliterated in ways that don’t reflect how they are actually pronounced.</p>



<p>In order to understand this, we need to go all the way back to Classical Attic Greek, the dialect of the Greek language that was spoken in the region of Attike, which includes the city of Athens, in the fifth and fourth centuries BCE, since, as strange as it may sound, the modern system of transliterating Greek words into English is based primarily on equivalences between Greek letters as they were pronounced in the Classical Attic dialect and Roman letters as they were pronounced in Classical Latin over two thousand years ago.</p>



<p>In Classical Attic Greek, γυρός was not the name of a particular kind of sandwich, but rather simply an adjective meaning “round.” Here’s the breakdown of how the word would have been pronounced in Athens in the fifth century BCE:</p>



<ul><li>In Classical Attic Greek, the letter ⟨γ⟩ was usually pronounced as the voiced velar plosive /g/ like the letter ⟨g⟩ in the English word&nbsp;<em>got</em>.</li></ul>



<ul><li>The letter ⟨υ⟩ was usually pronounced as the close front rounded vowel sound /y/ like the letter ⟨ü⟩ in the German word&nbsp;<em>über</em>.</li></ul>



<ul><li>The letter ⟨ρ⟩ was pronounced as the voiced alveolar trill /r/ like the letter ⟨r⟩ in Modern Spanish or Italian.</li></ul>



<ul><li>The letter ⟨o⟩ was pronounced as a short close-mid back rounded vowel /o/ similar to the sound made by the letter ⟨o⟩ in the English word&nbsp;<em>tote</em>.</li></ul>



<ul><li>The letter ⟨σ⟩, which is conventionally written ⟨ς⟩ when it occurs at the end of a word, was pronounced as the voiceless alveolar sibilant /s/ like the letter ⟨s⟩ in the English word&nbsp;<em>this</em>.</li></ul>



<p>Thus, in Classical Attic Greek, the word γυρός was pronounced /ɡyː.rós/.</p>



<p>During the Hellenistic Period (lasted c. 323 – c. 30 BCE), a new dialect of the Greek language known as “Koine” developed. Koine Greek was based primarily on Classical Attic Greek, but it was also influenced to some extent by other ancient Greek dialects. It became widely spoken throughout the entire eastern Mediterranean.</p>



<p>In Koine, the adjective γυρός was nominalized to become the second-declension masculine noun γῦρος, which means “circle,” “ring,” or “rotation.” Through this nominalization, the accent shifted from an acute accent on the ultima (i.e., the last syllable) to a circumflex accent on the penult (i.e., the second to last syllable), resulting in the noun form being pronounced /ɡŷː.ros/.</p>



<div><figure><img src="https://qph.fs.quoracdn.net/main-qimg-851fdc9c4f7c7e20256617b08febf0ff" alt=""></figure></div>



<p><em>ABOVE: Diagram </em><a href="https://commons.wikimedia.org/wiki/File:Circle-withsegments.svg"><em>from Wikimedia Commons</em></a><em> of a circle. The word γῦρος or γύρος in Greek literally means “circle” or “rotation.”</em></p>



<p><strong>Sound shifts in Koine and Medieval Greek</strong></p>



<p>At some point between the second century BCE and the third century CE, the consonant sounds represented by the letter ⟨γ⟩ shifted. From roughly this period onwards, ⟨γ⟩ became pronounced as a voiced velar fricative /ɣ/ before the vowels ⟨α⟩, ⟨ο⟩, and ⟨ω⟩. Meanwhile, it became pronounced as a voiced palatal fricative /ʝ/ before the front vowels ⟨ε⟩, ⟨η⟩, ⟨ι⟩, and ⟨υ⟩. This is a sound very similar to, but slightly different from, the voiced palatal approximant, which is generally represented in English by the consonantal ⟨y⟩.</p>



<p>Other changes in the pronunciation of the Greek language took place during the Middle Ages. By the Middle Byzantine Period, it seems that uneducated people in the countryside of Greece had begun to pronounce the letter ⟨υ⟩ as the close front unrounded vowel /i/, which is the sound made by the letter ⟨i⟩ in the English word&nbsp;<em>machine</em>. This shift occurred as part of a well-attested process known as “iotacism,” which resulted in the letters ⟨ι⟩, ⟨η⟩, and ⟨υ⟩, which had originally represented three different sounds in Classical Attic Greek, coming to all eventually represent the same sound in Standard Modern Greek.</p>



<p>This shift in the popular rural pronunciation seems to have greatly perturbed the educated elites at the time. In around the eleventh century CE, the Greek writer Michael the Grammarian wrote a satirical poem in which a speaker complains about the way uneducated people in the countryside were pronouncing the letter upsilon. He declares:</p>



<blockquote><p>“Ἐμοὶ πατρίς, βέλτιστε, τραχὺ χωρίον,<br>ὅπου περ ἀνδρῶν καὶ βοῶν ἶσαι φρένες,<br>οἳ το κρύον λέγουσιν ἀφρόνως κρίον,<br>καὶ τὸ ξύλον λέγουσιν ἀγροίκως ξίλον.”</p></blockquote>



<p>This means (in my own translation):</p>



<blockquote><p>“My fatherland, oh dearest one, is a coarse village,<br>where the minds of men and cows are just the same.<br>They foolishly say ‘κρίον’ instead of ‘κρύον’<br>and they boorishly say ‘ξίλον’ instead of ‘ξύλον.’”</p></blockquote>



<p>Over time, the pronunciation that Michael derided as coarse and uncivilized seems to have won out; in Standard Modern Greek, the letters ⟨υ⟩ and ⟨ι⟩ are both pronounced /i/. Thus, in Standard Modern Greek, the word γύρος is pronounced /ˈʝiros/.</p>



<div><figure><img src="https://qph.fs.quoracdn.net/main-qimg-134df5ea1d53237216706a67acb61eb8" alt=""></figure></div>



<p><em>ABOVE: Scene of everyday agricultural workers from an eleventh-century Greek manuscript of the gospels. It’s very likely that such laborers would have pronounced ⟨υ⟩ as /i/, while the scribe who copied the manuscript probably pronounced it /y/.</em></p>



<p><strong>Origin of the gyros sandwich</strong></p>



<p>Now that I’ve explained the origin of the Greek word γύρος and the history of its pronunciation, I should probably explain where the sandwich of this name originates from and how the name came to be applied to the sandwich.</p>



<p>Today in modern Greece, a cook who is preparing a gyros begins by roasting the meat vertically on a skewer and slicing pieces of meat away when they are done cooking. In Greece and Kypros, gyroi are normally made using pork, but a cook may sometimes choose to use chicken, beef, or lamb meat instead. Once the meat has been removed from the skewer, the cook usually serves it wrapped in pita bread as a sandwich. Often, it is served with tzatziki sauce, onions, and tomatoes.</p>



<p>The modern gyros didn’t arise all at once; many innovations had to be made before the gyros as we know it today could be invented. The first of these innovations was the invention of the idea of cooking meat on spits. This idea is extremely ancient; we know that people in the Aegean Islands were already roasting meat on horizontal spits at least over 3,600 years ago, and they were probably doing it long before that as well. Archaeologists excavating the Bronze Age site of Akrotiri on the Greek island of Thera unearthed stone firedogs dating to the seventeenth century BCE or earlier with notches clearly designed to hold skewers for roasting meats.</p>



<p>The<em>&nbsp;Iliad</em>, an ancient Greek epic poem that was most likely composed in around the early seventh century BCE, describes Chryses, the Trojan priest of the god Apollon, roasting meat on horizontal wooden skewers in book one, lines 458–466. The Athenian comic playwright Aristophanes (lived c. 446 – c. 386 BCE) references similar cooking practices in his plays&nbsp;<em>Acharnians</em>&nbsp;(line 1007),&nbsp;<em>The Clouds</em>&nbsp;(line 178),&nbsp;<em>The Wasps</em>&nbsp;(line 354), and&nbsp;<em>The Birds</em>&nbsp;(lines 388 and 672). Today, meats grilled on horizontal spits are known in Greece as&nbsp;<em>souvlakia</em>; they are distinct from, but similar, to gyroi.</p>



<div><figure><img src="https://qph.fs.quoracdn.net/main-qimg-c228d22c101b2ef5001f3316b9d400dc" alt=""></figure></div>



<p><em>ABOVE: Photograph&nbsp;<a href="https://commons.wikimedia.org/wiki/File:Akrotiri_terracotta_firedogs_with_zoomorphic_finials.jpg" target="_blank" rel="noreferrer noopener">from Wikimedia Commons</a>&nbsp;of a pair of stone firedogs used for roasting meat on skewers, discovered at the site of Akrotiri on the Greek island of Thera, dating to the seventeenth century BCE or earlier</em></p>



<p>The various other ingredients that are used in gyroi today also had to be introduced to Greece. Some of these ingredients were introduced to the Greek diet relatively early. Notably, pita bread—or at least a very similar kind of flatbread—is known to have existed in ancient Greece. The Greek Egyptian writer Athenaios of Naukratis, who wrote sometime in around the late second or early third century CE, quotes a description of the cooking process for a kind of flatbread known as&nbsp;<em>apanthrakis</em>&nbsp;in his book&nbsp;<em>Wise Men at Dinner</em>&nbsp;3.110b. The description reads as follows, as translated by S. Douglas Olson:</p>



<blockquote><p>“The&nbsp;<em>apanthrakis</em>&nbsp;is more delicate than wafer bread. This type too is probably produced on top of coals, like what Attic authors refer to as an&nbsp;<em>enkryphia</em>. The inhabitants of Alexandria offer it to Kronos and put it out in his temple for anyone who wants some to eat.”</p></blockquote>



<p>Similarly, onions, which are often served on gyroi today, were fairly common in ancient Greek cuisine and they are often mentioned as an ingredient in surviving ancient Greek recipes.</p>



<div><figure><img src="https://qph.fs.quoracdn.net/main-qimg-4fa6dc17e477e2a54726dedfcc0c3d06" alt=""></figure></div>



<p><em>ABOVE: Photograph&nbsp;<a href="https://commons.wikimedia.org/wiki/File:Nablus_souq_pita_118_-_Aug_2011.jpg" target="_blank" rel="noreferrer noopener">from Wikimedia …</a></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://talesoftimesforgotten.com/2021/01/03/what-is-the-correct-pronunciation-of-gyro/">https://talesoftimesforgotten.com/2021/01/03/what-is-the-correct-pronunciation-of-gyro/</a></em></p>]]>
            </description>
            <link>https://talesoftimesforgotten.com/2021/01/03/what-is-the-correct-pronunciation-of-gyro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626352</guid>
            <pubDate>Sun, 03 Jan 2021 23:36:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autism = Deficient Innervation of Auditory Pathway, Lack of Reflexive Synapse]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25626258">thread link</a>) | @Mandragora
<br/>
January 3, 2021 | https://www.manwhore.org/autismus-terminus-finis/ | <a href="https://web.archive.org/web/*/https://www.manwhore.org/autismus-terminus-finis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<div>

<div>
<div>
<p><strong>By The Wizard Mandragora</strong><br>
<span>April 19, 2019</span></p>

</div>
</div>

 
<p>The onset of the worldwide autism epidemic has seemed a bizarre and unknowable phenomenon, existing through a wide range of symptoms and debilitating conditions. The underlying causes, however, are deceptively simple.</p>
<p>Long held birthing practices in hospitals have been abandoned in lieu of more “progressive” policies, and though seemingly innocuous, the results have been <span>disastrous</span>.</p>
<p>The human error involved in the onset of autism is very simple. Doctors have stopped spanking babies’ bottoms at birth, accused of abuse or trauma-inducing practices. Circumcision has also been on a widespread decline. Venupuncture at birth or shortly soon after is unheard as well for the same reasons. <span>All</span>&nbsp;of these have contributed to the massive spike in autism, for <span>ONE</span>&nbsp;very important underlying reason:</p>
<p>Without the PAIN stimulus, the baby is stuck in a biologically immature, semi-wake state leftover from the womb. The PAIN stimulus at birth is what compels the 1) baby’s CRY, which innervates the auditory pathway, the postnatal neuronal maturation process and begins&nbsp;the process of spatially encoding the environment (this tonotopy becomes the basis for the ocular system as well as finger joint/grasping abilities). It is also responsible for 2) the jump start of the reflexive processes to synapse at the brainstem for quick reaction speed, as well as internal endogenous processes such as the gastrocolic reflex (this is why autistic children are chronically constipated, fussy eaters). And, 3) the initiation of the <span>Ascending Reticular Activating System</span>, the body’s <span>wake up</span>&nbsp;call, which the auditory system is tasked with initially triggering after leaving the womb.</p>
<p>These three main underlying “missing factors” define the causal mechanisms of the autism epidemic.</p>
<p><span>1. Postnatal Auditory Development</span><br>
The most important thing to understand is that the auditory pathway is the <span>first</span>&nbsp;step of sensory organization and <span>begins</span>&nbsp;the brain’s understanding of its external environment. Every <span>other</span>&nbsp;sensory encoding system begins with the auditory system. Why? Because sound is the <span>only</span>&nbsp;sense we can actually initially physically “interfere” with and <span>interpret</span> the results. Meaning we can put out a stimulus <span>ourselves</span>, that interacts with and <span>interferes</span>&nbsp;with existent noise and environmental conditions. Our brains then decipher and interpret&nbsp;the results to spatially encode the environment so as to be able to interact with it.&nbsp;<a href="http://www.acousticintegrity.com/acousticintegrity/Hugo_Zuccarelli.html">Hugo Zuccarelli</a>&nbsp;first established this in 1980 with his discovery of&nbsp;<a href="https://en.wikipedia.org/wiki/Holophonics">holophonics</a>&nbsp;as well as his proposal that the human ear and auditory system work as an <span><a href="https://en.wikipedia.org/wiki/Interferometry">interferometer</a></span>. The ramifications of his discovery, however, were lost on the medical community.</p>
<p>In animals like bats this auditory feedback system is very large, as they have adapted to acquiring food from their environments strictly by use of sound, e.g. sonar. In primates this system is smaller, because we only use the auditory pathway primarily until we fine-tune our finger motor skills, <i>and</i>&nbsp;our visuospatial system kicks in.&nbsp;Once&nbsp;human vision orients itself <span>based</span>&nbsp;on the auditory encoding of the environment, the biological Law of Precedence takes effect and strict emphasis on the auditory system is abandoned.</p>
<p>This is why babies <span>coo</span>. They are pinging their environments and learning to orient and fine-tune their ability to recognize and interact with physical stimuli, and focus their eyes.&nbsp;Their finger grasping and understanding of the positioning of their own joints, fingers, and body positioning becomes more honed and fine-tuned as they coo and grasp.</p>
<p>Autistic babies have also been observed to fail the “tilting test”, e.g. they fall over without catching themselves like normal babies.&nbsp;This is because the vestibular system is innervated at the same time as the auditory pathway as they both make up the vestibulocochlear nerve. Without this primal innervation, the saccule and utricle never become sensitive to linear acceleration and head-tilting.</p>
<p><span>2.&nbsp;</span><span>Nociception/”PAIN”</span><br>
The mechanoreceptors associated with physical insult to the human body initiate internal reflexive “smooth muscle” processes such as peristalsis, sphincter relaxation, and proper pulmonary function. The <span>lack</span>&nbsp;of this stimulus results in many of the known conditions and symptoms of autism.</p>
<p>Glutamate and Substance P/NK<span>1</span>&nbsp;binding work together to trigger proper intestinal smooth muscle contraction and control. This results in peristalsis, sphincter relaxation, even vomiting.&nbsp;This is why without the required “stimulus” autistic babies are chronically constipated, and extremely fickle eaters.</p>
<p>Acetylcholine and nitric oxide production work together to coordinate proper pulmonary function for clearing airways of pathogens. This is why&nbsp;doctors and medical personnel have begun to take notice of the differences in sound that autistic babies make versus normal babies. ASD babies are known to make cries that are higher pitched and with smaller intervals between, because they are not drawing breath properly. Mothers have also reported being confused by the sounds their babies make, not knowing or being able to interpret what’s wrong so they can properly care for them.</p>
<p>These normal bodily processes are all initially triggered by “noxious stimuli”, e.g. PAIN.</p>
<p><span>3.&nbsp;</span><span>Ascending Reticular Activating System</span><br>
“Residual muscle tension” which keeps us still during sleep, needs to be cut as fast as possible, otherwise it’s like living in a slow waking state and we simply cannot survive on our own. Bottom line, the human body and mind need to be able to react&nbsp;<em>reflexively</em> to the external environment.</p>
<p>Our body’s waking system, the <span>ascending reticular activating system</span>, is stimulated directly by sound and touch. “Neurons of the reticular formation, particularly those of the ascending reticular activating system, play a crucial role in maintaining behavioral&nbsp;<a title="Arousal" href="https://en.wikipedia.org/wiki/Arousal">arousal</a>&nbsp;and&nbsp;<a title="Consciousness" href="https://en.wikipedia.org/wiki/Consciousness">consciousness</a>.”&nbsp;In 1949 Dr. Magoun recorded potentials within the medial portion of the brain stem and discovered that auditory stimuli directly fired portions of the <a href="https://en.wikipedia.org/wiki/Reticular_formation">reticular activating system</a>.</p>
<p><span>Robotics</span><br>
This has profound&nbsp;implications for robotics, as without this baseline understanding of sensory integration, scientists have been stuck attempting to create robots that walk/move with zero predictable precision. Without the auditory integration and understanding of their environment, robots are stuck “learning” their environment over and over again every time they take a step as visual processing systems are a <span>secondary</span>&nbsp;source of information-gathering. They cannot be fine-tuned and honed without an auditory platform upon which to be based off of.</p>
<p>Smart cars will now be able to be programmed to be much more “aware” of their surroundings, and be able to navigate much&nbsp;more accurately.</p>
<p><span>Conclusion</span><br>
All of this is easily explained by the simple logic that it makes no biological sense&nbsp;for a baby to start any of these processes until it’s outside the womb. It’s not supposed to be moving around grasping for things, gastrointestinal processes are not needed until the baby is ready to start processing food itself, and of course a baby in the womb cannot safely use its own airways.</p>
<p>To make sense of this it would serve to go back and examine <span>very closely</span>&nbsp;how an entire generation of medical professionals was <i>shamed</i> into giving up practices long-held as routine and necessary since before recorded human history.</p>
<p>But there’s more to the scenario, another disturbingly false pocket of data being propagated worldwide with ruinous results,&nbsp;a false sense of communal sharing of information among young families that preaches the “evils” of vaccinations. We’ve just seen firsthand the dangers of this, epidemics in western states, reports of single individuals unknowing of their condition, passing on antiquated diseases to dozens of people.&nbsp; But there’s a heinous concurrence at work here, because&nbsp;the <span>hidden</span>&nbsp;horror is to realize that all it can take is a <i>single</i> vaccination to <span>CURE the autism condition</span>. Venupuncture provides the same level of stimulus as a spank at birth, and can serve to finally fully integrate a child’s senses correctly. The process isn’t immediate, and it <i>may</i>&nbsp;take a bit of reinforcement, but it’s there.</p>
<p>There’s a special kind of destructive irony to the fact vaccinations are being presented as the <i>cause</i>&nbsp;of autism. Which of course serves to make parents of autistic children even less likely to vaccinate.</p>
<p>This is also&nbsp;why&nbsp;there are reports of medical professionals and school teachers wondering why some children were ever diagnosed in the first place, it’s because&nbsp;that child ended up experiencing some type of injury and subsequently completed the auditory/reflexive circuit on their own. Everyone <span>else</span>&nbsp;is imbuing their child with a <i>powerful</i> learning disability. In fact I would not hesitate to say that the autistic condition is a hellish reality, to be trapped in a perceptual prison, a primitive, <a href="https://drhyman.com/blog/2010/05/12/functionalapproach/">psychedelic drug trip</a> with no escape. They can’t make sense of what they see or hear, they know only confusion, fear, and oblong shapes that fill their visual field with threatening gestures, emitting loud echoing noises that blanket their landscape with unknowable, imperceptible monsters.</p>
<p>Because of the curvature of our eyes, we are born with an inverted view. Light and visual info coming into the eye gets refracted upside down onto the retina, over time the brain learns to correctly orient the image. It’s clear autistic children have major problems with their vision and ocular systems. Some may presumably never learn to invert the image their retinas project, or only partially, many presumably experience a warped view of reality.</p>
<p>It’s no wonder autistic children experience chronic levels of stress, inflammation and anxiety; their lives are living nightmares. <br></p><p> <a href="https://www.manwhore.org/drills-based-training-with-mw/">
<br><img src="https://www.manwhore.org/wp-content/uploads/2019/04/mw-post1.png">
<br>Click Here For More Info</a></p>

<p>In fact, parents must strongly beware of social media sources that force highly chaotic visuals onto their viewers, such as the mobile app Tik Tok, which literally works to blur …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.manwhore.org/autismus-terminus-finis/">https://www.manwhore.org/autismus-terminus-finis/</a></em></p>]]>
            </description>
            <link>https://www.manwhore.org/autismus-terminus-finis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626258</guid>
            <pubDate>Sun, 03 Jan 2021 23:22:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nocoiner predictions: 2021 will be year of comedy gold]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25626184">thread link</a>) | @amycastor
<br/>
January 3, 2021 | https://amycastor.com/2021/01/02/2021-the-year-of-comedy-gold-and-other-bitcoin-skeptic-predictions/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/01/02/2021-the-year-of-comedy-gold-and-other-bitcoin-skeptic-predictions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5196">
		<div>
		
<p>The last year has been particularly annoying for nocoiners—those of us who don’t hold crypto and view bitcoin as a Ponzi, like a Ponzi, or <a href="http://www.tr0lly.com/bitcoin/bitcoin-is-not-a-literal-ponzi-scheme/">something more complex</a>.</p>



<p>We have had to endure Tether minting tethers with abandon ($17 billion worth in 2020 alone) and bitcoiners obnoxiously cheering bitcoin’s new all-time highs, the latest being <a href="https://www.coindesk.com/bitcoin-hits-30k-for-1st-time-ever">$33,000</a>. Considering bitcoin began 2020 at around $7,500, that is a long way up. (<a href="https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/">Things went full crazy in March</a>.) But we believe 2021 will be a year of comedy gold when this giant hill of dung all comes tumbling down.  </p>



<p>I’ve spoken with several notable bitcoin skeptics, gathered their thoughts, and compiled a list of new year predictions. They shared their prophecies on Tether (a stablecoin issuer that has so far minted $21 billion in dubiously backed assets to pump the crypto markets), new regulations and the future of bitcoin.&nbsp;</p>



<p>Here is what they had to say:</p>



<h2><strong>Nicholas Weaver: T’will be the year the music stops</strong></h2>



<p>“This is the year the music stops,” Nicholas Weaver, a researcher at the International Computer Science Institute in Berkeley, told me.&nbsp;</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg"><img loading="lazy" data-attachment-id="5212" data-permalink="https://amycastor.com/nicholas-weaver-2/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nicholas-weaver-2" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=300" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=400" src="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=400" alt="" width="257" height="257" srcset="https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=257 257w, https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=150 150w, https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg?w=300 300w, https://amyhcastor.files.wordpress.com/2021/01/nicholas-weaver-2.jpg 400w" sizes="(max-width: 257px) 100vw, 257px"></a></figure></div>



<p>Weaver has been following bitcoin since 2011. His work is largely funded by the National Science Foundation. He believes the bitcoin ecosystem is running low on cash. (This is the fate of all Ponzi schemes. Ultimately, they run out of new investors and when that happens, the scheme collapses.) In the case of bitcoin, he believes real dollars in the system are rapidly being replaced by fake ones in the form of tethers.</p>



<p>“Tether has been squeezing every dollar out of the system, and there aren’t enough suckers,” he said, meaning there aren’t enough folks waiting in line to buy bitcoin at its ever increasing prices. “When the dollar stock goes to zero, the system will collapse completely because you get a mining death spiral.”</p>



<p>Miners reap 900 newly minted bitcoin per day in the form of block rewards. If they can’t sell those for enough fiat money to pay their monstrous power bills, it makes no sense for them to stay in business. And since their job is to secure the bitcoin network, bitcoin will become vulnerable to repeated attacks.</p>



<p>Also, governments are finally waking up, said Weaver, alluding to new global efforts to clamp down on money laundering, capital outflows, and the financing of terrorism via cryptocurrencies.&nbsp;</p>



<p>He foresees Tether getting the <a href="https://www.nytimes.com/2013/05/29/nyregion/liberty-reserve-operators-accused-of-money-laundering.html">Liberty Reserve treatment</a> any day now. He also thinks China will decide “screw it, bitcoin is evading capital controls as a primary purpose, let’s cut off the subsidized electricity.” </p>



<p>Without cheap electricity, bitcoin miners—most of whom are in China—may find it difficult to stay afloat.&nbsp;Already bitcoin miners in Inner Mongolia <a href="https://decrypt.co/39718/bitcoin-miners-in-china-lose-access-to-cheap-electricity">no longer receive electricity at subsidized rates</a>.&nbsp;</p>



<h2><strong>Jorge Stolfi: I can’t make price predictions</strong></h2>



<p>A computer science professor in Brazil, Jorge Stolfi wants to avoid making predictions on bitcoin’s price. He’s been following bitcoin since 2013—and has seen it through two prior bubbles—so he knows too well that anything can happen. </p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg"><img data-attachment-id="5227" data-permalink="https://amycastor.com/stolfi/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg" data-orig-size="300,168" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="stolfi" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg?w=300" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg?w=300" src="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg?w=300" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg 300w, https://amyhcastor.files.wordpress.com/2021/01/stolfi.jpeg?w=150 150w" sizes="(max-width: 300px) 100vw, 300px"></a></figure></div>



<p>“I really don’t know how far the insanity can go. The crypto market is 100% irrational, sustained entirely by ignorance and misinformation,” he said. “How can anyone make predictions about that?”&nbsp;</p>



<p>Stolfi is a denizen of <a href="https://www.reddit.com/r/Buttcoin/">r/Buttcoin</a>, a subreddit that makes fun of bitcoin, where he painstakingly explains the finer points of crypto nonsense to the unenlightened. In 2016, he submitted a <a href="https://www.sec.gov/comments/sr-cboebzx-2018-040/srcboebzx2018040-4064523-169183.pdf">letter</a> to the U.S. Securities and Exchange Commission warning against the risks of a bitcoin exchange-traded fund and comparing bitcoin to a Ponzi scheme. (The SEC has shot down every bitcoin ETF proposal to date on the basis that bitcoin’s price is too easy to manipulate.)</p>



<p>“And since price determines everything else in the crypto space, I can’t make predictions on pretty much everything else,” Stolfi continued. “For example, If the price were to crash below $10,000, I bet that we would have a lot of comedy gold coming from MicroStrategy.”&nbsp;</p>



<p>Over the last several months, the enterprise software company, has funneled $1.2 billion of its funds into bitcoin. As a result, Michael Saylor, the company’s CEO, now spends most of his time on Twitter shilling bitcoin.&nbsp;In September, Saylor <a href="https://twitter.com/michael_saylor/status/1307029562321231873">compared</a> bitcoin to “a swarm of cyber hornets serving the goddess of wisdom, feeding on the fire of truth, exponentially growing ever smarter, faster, and stronger behind a wall of encrypted energy.”</p>



<p>Stolfi also thinks that we will probably forget about several coins that were big in the past, like Bitcoin SV (BSV) and IOTA, maybe even bitcoin cash (BCH). “And we will also forget about blockchain technology.”</p>



<h2><strong>Frances Coppola: Crypto exchanges will become like licensed banks&nbsp;</strong></h2>



<p>Over the last week, Frances Coppola has been battling an army of bitcoin trolls and sock puppets on Twitter after suggesting that <a href="https://twitter.com/Frances_Coppola/status/1345395222243586050">bitcoin is not scarce</a> in any meaningful sense.&nbsp;</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg"><img data-attachment-id="5222" data-permalink="https://amycastor.com/frances-coppola/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg" data-orig-size="260,260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frances-coppola" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg?w=260" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg?w=260" src="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg?w=260" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg 260w, https://amyhcastor.files.wordpress.com/2021/01/frances-coppola.jpg?w=150 150w" sizes="(max-width: 260px) 100vw, 260px"></a></figure></div>



<p>Scarcity is a key part of the myth bitcoiners perpetuate to make people think bitcoin is valuable in the same way gold is and to create a sense of buying urgency—quick, grab some before it’s all gone!—so naturally, bitcoiners responded by dog piling on her. She isn’t happy about it.&nbsp;</p>



<p>“I hope bitcoin crashes and burns because I am so bloody furious, but I think it will be a while yet before it does—maybe about June,” she said.&nbsp;</p>



<p>Coppola is a UK-based freelance writer, who spent 17 years in the banking industry. She wrote the book, “<a href="https://www.amazon.com/Case-Peoples-Quantitative-Easing/dp/1509531300">The Case For People’s Quantitative Easing</a>,” and has 58,000 Twitter followers.</p>



<p>The cause of bitcoin’s upcoming crash, she believes, will be an epic battle between the Wild West of crypto and regulators, a topic she covered in a recent <a href="https://www.coindesk.com/bitcoin-financial-system-fight-it">Coindesk article.</a></p>



<p>If the regulators win, crypto exchanges will become like licensed banks and have to comply with things like the Dodd-Frank Act, a sweeping law that reined in mortgage practices and derivatives trading after the 2008 financial crash, she said. On the other hand, if the regulators lose, she believes their next move will be to protect retail investors.</p>



<p>“We’d see drastic restrictions on what interactions banks can have with crypto, perhaps a total ban on retail-deposit-takers having crypto exchanges and stablecoins as clients,” she said.&nbsp;</p>



<p>“We might also see something akin to a Glass-Steagall Act for crypto exchanges and stablecoins, so that retail deposits are fully segregated by law from trading activity.” By that, she means exchanges won’t be able to lend retail deposits to margin traders or use them to fund speculative positions in crypto derivatives.&nbsp;</p>



<h2><strong>David Gerard: Bitcoiners will get their big boy wish</strong></h2>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg"><img data-attachment-id="5213" data-permalink="https://amycastor.com/david-gerard/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="david-gerard" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg?w=225" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg?w=225" src="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg?w=225" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg 225w, https://amyhcastor.files.wordpress.com/2021/01/david-gerard.jpeg?w=150 150w" sizes="(max-width: 225px) 100vw, 225px"></a></figure></div>



<p>After years of begging for bitcoin to be taken seriously as a form of money, bitcoiners will be getting exactly what they asked for, said David Gerard, a bitcoin skeptic and author of <a href="https://www.amazon.com/Libra-Shrugged-Facebook-Tried-Money-ebook/dp/B08KK9SZP6">“Libra Shrugged,”</a> a book on Facebook’s attempt to take over the money.&nbsp;</p>



<p>This year will see more regulation of crypto, as coiners discover to their dismay just how incredibly regulated real-world finance is, he said. “Just wait until someone sits them down and explains regulatory real-time compliance feeds.”</p>



<p>What does Gerard think about Tether? “I could predict the guillotine will finally fall on Tether, but I predicted that for December 2017, and these guys are just amazing in their ability to dodge the blade just one more day,” he said.</p>



<p>Since 2018, the New York Attorney General has been investigating Tether and its sister company, crypto exchange Bitfinex, for fraud. Over the summer, the New York Supreme Court ruled that the companies need to hand over their financial records to show once and for all just how much money really is underlying the tethers they keep printing. The NYAG <a href="https://iapps.courts.state.ny.us/nyscef/ViewDocument?docIndex=2AsYgvjJAsSdalpfkInbHA==">said</a> Bitfinex/Tether have agreed to do so by Jan. 15.</p>



<p>Gerard also foresees that there will continue to be no use cases for crypto that absolutely anything else does better. “Everything the <a href="http://buttcoinfoundation.org/">Buttcoin Foundation</a> was talking about in 2011 is still dumb and broken,” he said.</p>



<h2><strong>Trolly McTrollface: Crypto will go to Mars</strong></h2>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg"><img data-attachment-id="5208" data-permalink="https://amycastor.com/trolly/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg" data-orig-size="159,159" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="trolly" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg?w=159" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg?w=159" src="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg?w=159" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg 159w, https://amyhcastor.files.wordpress.com/2021/01/trolly.jpg?w=150 150w" sizes="(max-width: 159px) 100vw, 159px"></a></figure></div>



<p>Elon Musk says he is <a href="https://www.cnbc.com/2020/12/01/elon-musk-highly-confident-spacex-will-land-humans-on-mars-by-2026.html">“highly confident”</a> that his company SpaceX will be sending humans to Mars in six years. Naturally, Musk wants to set up a self-sustaining city on the red planet. And, come to think of it, the city will need its own crypto, something like Dogecoin or <a href="https://www.marscoin.org/">Marscoin</a>. Otherwise, how else will its citizens pay for things?</p>



<p>Pseudonymous crypto blogger Trolly McTrollface has this prophecy for 2021: “Elon Musk creates its own cryptocurrency, and adds it to the<a href="https://twitter.com/search?q=%24TSLA&amp;src=cashtag_click"> $TSLA</a> balance sheet. It ends the year in the top 10 crypto list by market cap.”</p>



<figure><div>

</div></figure>



<h2><strong>Nouriel Roubini: Bitcoin’s bubble will explode</strong></h2>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg"><img data-attachment-id="5224" data-permalink="https://amycastor.com/nouriel/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg" data-orig-size="231,261" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 10D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1091122330&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;75&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nouriel" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg?w=231" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg?w=231" src="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg?w=231" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg 231w, https://amyhcastor.files.wordpress.com/2021/01/nouriel.jpg?w=133 133w" sizes="(max-width: 231px) 100vw, 231px"></a></figure></div>



<p>Nouriel Roubini, an economics professor at New York University, doesn’t mince words when it comes to crypto predictions. He simply told me: “The Bitcoin bubble will burst in 2021. Triggers will be reg/law enforcement action.”&nbsp;</p>



<p>There is good reason to take him seriously. Roubini famously warned of the 2008 financial crisis, a prophecy that earned him the moniker “Dr. Doom.”&nbsp;He is also <a href="https://www.vanityfair.com/news/2013/09/dr-doom-s-bubble-burst-nouriel-roubini-s-hot-tub-gets-heave-ho">known for his parties</a>, which leads a few of us nocoiners to believe that bitcoiners’ are fundamentally driven by bitterness over the fact that we have better soirées.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">My 12-parts thread on Bitcoin/Shitcoins. I stand by my views: the higher they bubble, the harder they will fall once the criminal Tether manipulation is crashed &amp; FOMO driven retail/institutional suckers get burned hard as in 2018. The parabolic rise in BTC has no fundamentals <a href="https://t.co/xSLEsQ44Nq">https://t.co/xSLEsQ44Nq</a></p>— Nouriel Roubini (@Nouriel) <a href="https://twitter.com/Nouriel/status/1339633118341304320?ref_src=twsrc%5Etfw">December 17, 2020</a></blockquote></div>
</div></figure>



<h2>David <strong>Golumbia: The insanity will continue—unless it stops</strong></h2>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg"><img data-attachment-id="5219" data-permalink="https://amycastor.com/david-golumbia/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg" data-orig-size="183,275" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="david-golumbia" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg?w=183" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg?w=183" src="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg?w=183" alt="" srcset="https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg 183w, https://amyhcastor.files.wordpress.com/2021/01/david-golumbia.jpeg?w=100 100w" sizes="(max-width: 183px) 100vw, 183px"></a></figure></div>



<p>If the past is any prediction of the future, bitcoin and other crypto promoters will continue to deceive the public with outright lies about “investing” in tokens until the big tokens collapse. That’s the view held by David Golumbia, known for writing about the cult of bitcoin. He is the author …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/01/02/2021-the-year-of-comedy-gold-and-other-bitcoin-skeptic-predictions/">https://amycastor.com/2021/01/02/2021-the-year-of-comedy-gold-and-other-bitcoin-skeptic-predictions/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/01/02/2021-the-year-of-comedy-gold-and-other-bitcoin-skeptic-predictions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626184</guid>
            <pubDate>Sun, 03 Jan 2021 23:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My best practices to make your home not just smart but also secure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25626072">thread link</a>) | @hinsencamp
<br/>
January 3, 2021 | https://100daysofhardware.com/blog/smart-home-security-best-practices/ | <a href="https://web.archive.org/web/*/https://100daysofhardware.com/blog/smart-home-security-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><section><div><p>Most people who are interested in smart home automation start very enthusiastically into their new hobby, automating as much as they can within their home.
Many are completely unaware of the cybersecurity risk they introduce to their homes, allowing cybercriminals to access their private space just by some clicks.</p><p>In this article, you get an idea about threads in home automation and four simple &amp; effective best security practices, so you can build-out your home smarter without exposing you to additional risk!</p><h2>Security Threads in Home Automation</h2><p>Home automation has hit the mainstream market in recent years. Previously only a limited group of tech enthusiasts was enjoying the benefits of controlling their homes via their DIY automation systems. Now, we look at a young but fast-growing industry, which offers a wide range of consumer-graded devices like thermostats, televisions, smart locks, and lights. This fast evolution of the ecosystem is shaped by many new inexperienced vendors, vast user adoption and continuously changing technology. Consequently, this boom has drawn a lot of attention from cybercriminals and hackers. It's an ideal habitat for malicious intruders.</p><p>Most of these virtual intruders probably wouldn't empty your home right away, but the increasing amount of connected devices already makes you vulnerable against all kinds of threads. But, once you connect your projects to the web, you are exposed to pretty much any malicious user on the planet, interested in hijacking your devices.</p><p>Consequently, if you're learning about home automation and plan to build some DIY projects around the use case, you’ll want to invest some time to understand secure implications too.</p><p>Hence, we're going to unpack four easy but powerful precautions you can take to defend your DIY smart home ecosystem against cyber-attacks.</p><h2>Simple &amp; Effective Defence Practices</h2><h3>1. Secure your Router</h3><p>It's common sense that locking your front door, or at least keeping it closed is a simple way to prevent intrusion, right? In cybersecurity, not securing your router, is like leaving your front door wide open while you are on holiday.</p><p>It's key to understand, that your router should be untouchable, as it connects all of your IoT devices. Here are some simple tips and tricks to get there.</p><h4>Change the Router's Default Name</h4><p>As a first step, change your router's default name. Usually, it's the model name given by the manufacturer. Knowing which hardware you use, gives cybercriminals a great advantage to gain access to your network as this makes it easy to exploit your model's vulnerabilities. So simply give your router a unique name that can’t be traced to you or your home address.</p><h4>Generate a Complex Password</h4><p>Another simple but powerful precaution is to generate a complex password that consists of uppercase, lowercase letters, numbers, and special characters. The longer the password, the better. To make your life easier, consider using a password generator so your password is truly random.</p><p>Also, it's recommended to use a strong encryption protocol — like WPA2 instead of WPA or WEP. WPA2 encryption has the advantage to protect your Wi-Fi access points and also secures your network.</p><p>If available go even for the WPA3 protocol, it is the next revolution in router protection and leverages 128-bit encryption.</p><h4>Use Multiple Passwords</h4><p>Using different login credentials for every IoT device is another easy step to stop intruders from freely navigating through your system. With different passwords in place, even if one device is compromised, others remain unaffected.</p><p>To make it easier to create and manage and securely store your passwords consider using a password manager app. The only password you must remember the main keyword to access your app.</p><h3>2. Set Up A Separate Network for IoT Devices</h3><p>In general, it's important to keep control of your network. You always want to remain in total control over access and modification of your router and all linked smart home devices.</p><p>If you got a modern router you can start implementing this idea, by creating a guest network separate from your primary network. This way, your relatives, friends, and guests will all access a separate network that doesn’t tie to your IoT devices. That way, you protect your password from unnecessary exposure.</p><h3>3. Ensure All Devices Are Always Up-To-Date</h3><p>Keeping your devices' firmware always up-to-date helps to limit your risk of attack and ensures you got all available security patches available.
Unfortunately, many routers and IoT devices, do not update their corresponding apps automatically.
Best you create a list of all your devices to verify, which once you can make update automatically and which need your special care. Set yourself a reminder to check for updates for your devices that need manual updates. For the rest, always install updates right away.</p><h3>4. Enable Two-Factor Authentication</h3><p>To verify your identity, you get a one-time password (OTP) or a verification code sent to your smartphone or email address. That way, you make it harder for intruders, as they would need to gain access to those accounts first before they could get into your IoT devices.
Most commercial IoT devices have a built-in two-factor feature, if you build your project there are a couple of companies that offer 2FA as a service. Most of these solutions are easy to integrate and still affordable.</p><p>Hopefully, the best practices outlined above sharpened your awareness of cybersecurity and encourage you to take charge of your digital as you do for your analog security.</p><hr></div></section></main></div></div>]]>
            </description>
            <link>https://100daysofhardware.com/blog/smart-home-security-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25626072</guid>
            <pubDate>Sun, 03 Jan 2021 22:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to import highlights from kindle device in Roam]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625970">thread link</a>) | @jacopo
<br/>
January 3, 2021 | https://jacopomartolini.com/how-to-import-kindle-highlights-in-roam-research | <a href="https://web.archive.org/web/*/https://jacopomartolini.com/how-to-import-kindle-highlights-in-roam-research">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>03.01.2021</time> — <a href="https://jacopomartolini.com/tags/roam">Roam</a> — <span>2<!-- --> min read</span></p><section><hr><p>I often use the highlight feature while reading on my Kindle, but rarely I get back to them.
For those occasions, where I would like to get back to a particular passage of a book, having them well organised and at reach is not always possible for books that are stored on Kindle.</p><p>There are several ways to access and export Kindle highlights:</p><ul><li><p>Export from the Amazon webpage:&nbsp;<a href="https://read.amazon.com/notebook">https://read.amazon.com/notebook</a>. Amazon let you export the highlights through the notebook page and app, then they can be imported with existing services like:</p><ul><li><a href="https://kindle-formatter.vercel.app/">https://kindle-formatter.vercel.app/</a></li><li><a href="https://github.com/krystofl/kindle-notes-to-md">https://github.com/krystofl/kindle-notes-to-md</a></li></ul><p>Note that, Amazon’s own Kindle account page doesn’t show highlights from books that weren’t purchased from the Kindle store. You can export one book at a time, which is useful for regular updates but, very tedious for first time, big batch, export.</p></li><li><p><a href="https://help.readwise.io/article/71-how-does-the-readwise-to-roam-export-integration-work">Readwise</a> seems the best option for centralising highlights from across various platforms. For Evernote export feature there is a plan of $7.99/month, which, in my case, seems too expensive.</p></li><li><p><a href="https://en.toolinbox.net/Klib/">Klib</a> is a Mac application to manage highlights and notes for Kindle &amp; Apple Books that allow the export for Evernote and markdown. The unlimited version has a price of $14.99.</p></li><li><p>You can plug in your Kindle into your computer and copy the 'My Clippings.txt' file. This document contains all the highlights you made, even from books that aren't loaded from Kindle store. The result is a file similar to this:
<span>
      <span></span>
  <img alt="myclippings" title="myclippings" src="https://jacopomartolini.com/static/4568282573e58422049080a309acf5f1/7d769/myclippings.png" srcset="https://jacopomartolini.com/static/4568282573e58422049080a309acf5f1/5243c/myclippings.png 240w,https://jacopomartolini.com/static/4568282573e58422049080a309acf5f1/ab158/myclippings.png 480w,https://jacopomartolini.com/static/4568282573e58422049080a309acf5f1/7d769/myclippings.png 960w,https://jacopomartolini.com/static/4568282573e58422049080a309acf5f1/f0baf/myclippings.png 1390w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span>
As you can see the format is not very friendly, entries are chronologically entered and difficult to navigate.</p></li></ul><p>In order to import them as single book in Roam, I've created a script to split the My Clipping file and aggregate highlights by book title:</p><p><a href="https://github.com/jacopom/kindleToRoam">https://github.com/jacopom/kindleToRoam</a></p><p>The result is a markdown file for each book with the following formatting:</p><ul><li>book title as filename<ul><li><strong>Author:</strong></li><li><strong>Reading Status:</strong></li><li><strong>Date Finished:</strong></li><li><strong>Why:</strong></li><li><strong>Tags:</strong> #book</li><li><strong>Notes:</strong></li></ul></li></ul><p>In order to execute the script:</p><ul><li>clone or download the repo</li><li>plug your kindle and navigate to the 'Documents' folder</li><li>make a copy of 'My Clippings.txt' in the same folder of kindleToRoam.py</li><li>open terminal and navigate to the folder</li><li>execute the command:</li></ul><ul><li>import your freshly formatted book entries in Roam Research</li></ul><p>The imported book are then manually revised to add tags and references, and apply <a href="https://fortelabs.co/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/">progressive summarization </a>.</p><p>This article also has been helpful in the setup of my library on Roam:
<a href="https://superorganizers.every.to/p/how-i-took-notes-on-250-books-in">https://superorganizers.every.to/p/how-i-took-notes-on-250-books-in</a></p><p>In the near future I would like to convert this script in a webpage and add other customisations in the output format. If interested in collaborating, <a href="https://twitter.com/jacopomar">my dm's are open</a>  😉</p></section></div></div>]]>
            </description>
            <link>https://jacopomartolini.com/how-to-import-kindle-highlights-in-roam-research</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625970</guid>
            <pubDate>Sun, 03 Jan 2021 22:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polyglot HTML/Zip file using zip encryption (pass: thisisapage)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625877">thread link</a>) | @gildas
<br/>
January 3, 2021 | https://gildas-lormeau.github.io/private/ | <a href="https://web.archive.org/web/*/https://gildas-lormeau.github.io/private/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gildas-lormeau.github.io/private/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625877</guid>
            <pubDate>Sun, 03 Jan 2021 22:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GDPR for Personal Websites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625841">thread link</a>) | @recursivelambda
<br/>
January 3, 2021 | https://hampuswessman.se/2021/01/gdpr-for-personal-websites/ | <a href="https://web.archive.org/web/*/https://hampuswessman.se/2021/01/gdpr-for-personal-websites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p><a href="https://hampuswessman.se/categories/law">Law</a> |
<time datetime="2021-01-03T18:46:00Z">2021-01-03</time>.
16
min read (3790 words).</p></header><p>A short guide to how the European Union’s General Data Protection Regulation
(GDPR) affects personal websites such as blogs.</p><p><strong>WARNING</strong>: the material on this page does not constitute legal advice. The
information may be incorrect or misleading. Any use of this information is
entirely at your own risk. In no event shall the author be liable for any
damages or other liabilities.</p><p>Topics:</p><nav id="TableOfContents"><ol><li><a href="#introduction">Introduction</a></li><li><a href="#what-is-the-gdpr">What is the GDPR?</a></li><li><a href="#gdpr-and-the-eu-cookie-law">GDPR and the EU cookie law</a></li><li><a href="#important-definitions">Important definitions</a></li><li><a href="#when-does-the-gdpr-apply">When does the GDPR apply?</a><ol><li><a href="#processing-of-personal-data">Processing of personal data</a></li><li><a href="#exceptions-to-the-scope">Exceptions to the scope</a></li><li><a href="#purely-personal-activity">Purely personal activity</a></li></ol></li><li><a href="#what-is-needed-to-comply">What is needed to comply?</a><ol><li><a href="#lawfulness-of-processing">Lawfulness of processing</a></li><li><a href="#processing-without-identification">Processing without identification</a></li><li><a href="#transparency-and-privacy-policies">Transparency and privacy policies</a></li><li><a href="#responsibility-as-a-controller">Responsibility as a controller</a></li><li><a href="#transfer-of-data-outside-eu">Transfer of data outside EU</a></li></ol></li><li><a href="#scenarios">Scenarios</a><ol><li><a href="#static-site-generators">Static site generators</a></li><li><a href="#google-analytics">Google Analytics</a></li><li><a href="#personal-posts-on-facebook-or-twitter">Personal posts on Facebook or Twitter</a></li><li><a href="#you-are-in-the-uk">You are in the UK</a></li></ol></li><li><a href="#learning-more">Learning more</a></li></ol></nav><h3 id="introduction">Introduction</h3><p>This text will assume that you are the owner of a small personal website and
will explore some ways that EU’s General Data Protection Regulation (GDPR)
affects you. The GDPR is large and complicated, so this blog post will by
necessity only show you the tip of the iceberg. As we all know, more dangers may
lurk below the surface.</p><p>Make sure to seek out official information or hire a lawyer if you ever need to
comply with the GDPR and please point out any errors that you discover here so
that I can correct them. Don’t take my word. For that reason, I will provide
plenty of references and links throughout.</p><p>Personally, I have an interest in law since long back. I studied to become a
Swedish lawyer for a year back in 2007 (before I switched area) and I try to
stay at least a bit up-to-date, especially as it relates to the software
industry. I’ve read a few short books about the GDPR, several books about EU law
(including university education), and I have read through the legal text.</p><p>The GDPR is the major data privacy protection legislation within the European
Union since it went into force<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> on 25 May 2018. Few have likely missed the
intense media coverage at the time as companies struggled to comply with the new
rules.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> The GDPR itself is an EU regulation from 2016 named <a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">Regulation (EU)
2016/679</a>.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> See the
<a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">link</a> for the official source in
all EU languages (no language has precedence)<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</p><p>The goals of the GDPR are to give EU citizens better control over their personal
data and to harmonise rules across the EU to simplify for businesses.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> EU has
several types of legislation. As an EU regulation<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>, the GDPR is directly
binding across the EU.</p><p>The right to privacy is not a new concept. It’s already expressed as Article 8
in the <a href="https://www.echr.coe.int/Pages/home.aspx?p=basictexts">European Convention on Human
Rights</a> and Article 12 in
the <a href="https://www.un.org/en/universal-declaration-human-rights/">United Nation’s Universal Declaration of Human
Rights</a>. There are
similar legislation across the world too, such as
<a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda_brief/">PIPEDA</a>
in Canada and <a href="https://oag.ca.gov/privacy/ccpa">CCPA</a> in California. One thing
to keep in mind here is that it’s far from obvious how legislation interacts
across borders.</p><p>The European Commission provides an official website about <a href="https://ec.europa.eu/info/law/law-topic/data-protection/data-protection-eu_en">Data protection in
the
EU</a>
with their own overview.</p><h3 id="gdpr-and-the-eu-cookie-law">GDPR and the EU cookie law</h3><p>The GDPR is not the only privacy legislation in the EU. There’s also the
<a href="https://edps.europa.eu/data-protection/our-work/subjects/eprivacy-directive_en">ePrivacy
Directive</a>
(<a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:32009L0136">Directive
2009/136/EC</a>),
which is sometimes called simply the “cookie law”<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. The GDPR didn’t repeal
this directive and there’s a new <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52017PC0010">proposed
regulation</a>
to replace it, so it seems to be here to stay in some form too.</p><p>This blog post will focus only on the GDPR.</p><h3 id="important-definitions">Important definitions</h3><p>There are a couple of definitions<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> that are necessary to know before we
continue. Note how some definitions are much wider in the context of the GDPR
than in common language use, which provides a potential trap unless we pay close
attention to the terms.</p><dl><dt>Personal data</dt><dd><em>Information</em> that is <em>related</em> to an identified or <em>identifiable natural
person</em> (the <em>data subject</em>).</dd><dt>Natural person</dt><dd>A <em>natural person</em> is the same as a physical person, i.e. an individual human
being. Compare to <em>legal person</em>, such as a company.<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup></dd><dt>Identifiable natural person</dt><dd>A natural person who <em>can be identified</em>, directly or <em>indirectly</em>, for
example by reference to either:<ol><li>An identifier such as a name, an identification number, location data, or
an online identifier.</li><li>One or more factors specific to the physical, physiological, genetic,
mental, economic, cultural, or social identity of the natural person.</li></ol></dd><dt>Processing</dt><dd>Anything done with personal data, automatically or manually, such as
collecting, storing, retrieving, adapting, using, or similar.</dd><dt>Controller</dt><dd>A natural person or organisation that controls and determines the purpose of
processing of personal data.</dd><dt>Processor</dt><dd>A natural person or organisation that processes personal data on behalf of the
controller.</dd><dt>Personally identifiable information (PII)</dt><dd>Synonymous to what the GDPR calls <em>personal data</em>.<sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> Useful and common term
used elsewhere, but not within the GDPR itself.</dd></dl><p>To avoid getting bogged down in details, I will simplify the rules here to make
them easier to comprehend. I won’t cover all exceptions or special cases, even
as it relates to personal websites.</p><p>The GDPR applies to:</p><ul><li>Processing of personal data, whether automated or not.<sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></li><li>Given that either:<sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup><ul><li>The controller or processor is located in the European Union.</li><li>The data subject is located in the European Union.</li></ul></li></ul><p>If the controller or processor is not located in the EU, the GDPR is only
applicable for data processing related to:</p><ul><li>Offering goods or services, whether paid or free.</li><li>Monitoring of the data subject’s behaviour within the EU.</li></ul><p>So far, it’s clear that more or less all processing of personal data within the
EU (even by controllers or processors outside of the Union) is within scope.</p><h4 id="processing-of-personal-data">Processing of personal data</h4><p>To determine if the GDPR applies, it’s necessary to figure out what activities
it considers to be <em>processing of personal data</em>. As we’ve seen above,
<em>processing</em> means almost any activity related to data (especially if
automated). It’s still important to determine who is responsible for the
processing, i.e. the controller.</p><p>Identifying <em>personal data</em> requires more consideration. The scope is extensive
and almost all websites will process at least some personal data. Note that it’s
enough that a natural person related to the data <em>could</em> be identified even
indirectly by putting together different pieces of data for it to be <em>personal
data</em>.</p><p>Examples of personal data include:<sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup></p><ul><li>Full name</li><li>Home address</li><li>E-mail address of an individual</li><li>IP address</li><li>Cookie identifier</li><li>Advertising identifiers on phones</li><li>Location data</li></ul><p>To avoid data being <em>personal data</em>, it needs to be fully anonymised.
Pseudonymisation where additional data could be used to identify the data
subject is still personal data.<sup id="fnref:14"><a href="#fn:14" role="doc-noteref">14</a></sup></p><p>Since almost all web servers keep access logs with IP addresses, to be able to
avoid abuse and deal with outages, even a fully static website typically
processes some personal data. This leads me to believe that the GDPR applies to
some extent to basically all websites.</p><h4 id="exceptions-to-the-scope">Exceptions to the scope</h4><p>There are some exceptions to the GDPR’s scope:<sup id="fnref:15"><a href="#fn:15" role="doc-noteref">15</a></sup></p><ul><li>Activities that fall outside the scope of EU law. In other words, it only
covers what it can cover.</li><li>Processing of personal data performed by a natural person in the course of a
<em>purely personal or household activity</em>.</li></ul><p>The second exception above gives us another important consideration that affects
whether, and to what extent, a personal website is within the scope of the GDPR.
More on this below. There are also some interesting exceptions to individual
rules that will be covered later.</p><h4 id="purely-personal-activity">Purely personal activity</h4><p>To further investigate what is meant by <em>purely personal or household activity</em>,
let’s have a look at <a href="https://gdpr-info.eu/recitals/no-18/">recital 18</a> from the
preamble of the GDPR:</p><blockquote><p>This Regulation does not apply to the processing of personal data by a natural
person in the course of a purely personal or household activity and thus with
no connection to a professional or commercial activity. Personal or household
activities could include correspondence and the holding of addresses, or
social networking and online activity undertaken within the context of such
activities. However, this Regulation applies to controllers or processors
which provide the means for processing personal data for such personal or
household activities.</p></blockquote><p>In other words, when you process personal data in your spare time related purely
to your personal life or household or talk to your friends, this is outside the
reach of the GDPR. Same thing when this is done by posting something on
Facebook, Twitter, or YouTube. In this case, these companies are the
<em>controllers</em> and they are responsible under the GDPR, but you are not.</p><p>If you use a blog service for your personal blogging, the same might apply here.
The blogging platform is the controller and the GDPR doesn’t apply to you
personally. All the time, this assumes that any processing of personal data by
you is strictly within the context of purely personal activities and that the
blog service is the controller for any other data processing.</p><p>The situation changes if you decide to provide a blog directly to the public,
where you control the entire blog. A few aspects are different in this scenario.
First, any processing of personal data relating to public blog visitors is no
longer in the context of a <em>purely personal or household activity</em> since it
involves unsuspecting strangers whose right to privacy the GDPR is meant to
protect and who are outside of your personal or household life. Second, there’s
no longer another <em>controller</em> for you to point at. You are now clearly the
controller who makes the overall decisions about the website and as such the
GDPR is fully applicable. Third, if you provide a <em>professional</em> (or
<em>commercial</em>) service in any way, you are definitely outside of this exception
even if you make no money. These are several ways to reach the same conclusion.</p><p>It’s naturally hard to draw the exact line for purely personal activities. Only
the <a href="https://europa.eu/european-union/about-eu/institutions-bodies/court-justice_en">Court of Justice of the European
Union</a>
can decide what the correct interpretation is. There are, luckily, multiple
rulings that give precedents for this.</p><p>Court rulings, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hampuswessman.se/2021/01/gdpr-for-personal-websites/">https://hampuswessman.se/2021/01/gdpr-for-personal-websites/</a></em></p>]]>
            </description>
            <link>https://hampuswessman.se/2021/01/gdpr-for-personal-websites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625841</guid>
            <pubDate>Sun, 03 Jan 2021 22:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A basic intuition for copyright law and GPL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625836">thread link</a>) | @neongreen
<br/>
January 3, 2021 | https://tek.brick.do/c324939a-8ca2-4156-8e93-96e4a2c6b05a | <a href="https://web.archive.org/web/*/https://tek.brick.do/c324939a-8ca2-4156-8e93-96e4a2c6b05a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tek.brick.do/c324939a-8ca2-4156-8e93-96e4a2c6b05a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625836</guid>
            <pubDate>Sun, 03 Jan 2021 22:30:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing Native Azure CLI on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625789">thread link</a>) | @qrybam
<br/>
January 3, 2021 | https://www.thectgrid.com/blog/installing-azure-cli-apple-silicon-macos-m1/ | <a href="https://web.archive.org/web/*/https://www.thectgrid.com/blog/installing-azure-cli-apple-silicon-macos-m1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <div>
            
            <p><i></i> Jan. 3, 2021, 10:14 p.m.</p>
            <p><strong><em>Update 4th Jan 2021: If you don't need Python 3.9, installing azure-cli natively can be done&nbsp;by using this homebrew formula:&nbsp;<a href="https://formulae.brew.sh/formula/azure-cli">https://formulae.brew.sh/formula/azure-cli</a>. Note: there's an open issue with upgrading:&nbsp;<a href="https://github.com/Azure/azure-cli/issues/16417">https://github.com/Azure/azure-cli/issues/16417</a>.</em></strong></p>

<p>Anyone else having trouble installing Azure CLI natively on Apple Silicon? You may remember some <a href="https://www.thectgrid.com/blog/apple-silicon-right-tool-remote-work-economy/">rough edges being mentioned in our previous post</a>.&nbsp;If like me you're a big user of Azure's cloud services and you've got your hands on a new M1 MacBook Pro or MacBook Air, then you might have noticed that installing some software isn't as straight forward as it used to be. In this post I'll take you through the steps I took to install Azure CLI natively on your Apple Silicon Mac.</p>

<p><a href="https://docs.microsoft.com/en-gb/cli/azure/install-azure-cli-macos">Official install docs</a></p>

<p><em>Note: this post is likely to become old pretty quickly given the pace at which things are being fixed for M1.</em></p>

<h2>Install HomeBrew</h2>

<p>As of the last few days, homebrew now supports Apple Silicon Mac natively which means no more <a href="https://docs.brew.sh/Installation#alternative-installs">manual steps</a> on the M1, just go to the <a href="https://brew.sh/">homebrew homepage</a> and install as normal. It should install into <code>/opt/homebrew/</code>, you can test it by running <code>$ brew</code> in the terminal.</p>

<h2>Install wget</h2>

<p>This step is the simplest in this whole process, savour it:</p>

<pre><span>brew install&nbsp;wget</span></pre>

<h2>Install Python 3</h2>

<p>Install Python 3 with this command:</p>

<pre><span>brew install python3</span></pre>

<p>It will download and build targetting Apple Silicon ARM. We now need to check you can access python3 via the Terminal and that the right version is being loaded (MacOS comes with older versions of both Python2 and Python3):</p>

<pre><span>type&nbsp;-a&nbsp;python3
python3 is /usr/bin/python3</span></pre>

<p>If a path going via your homebrew folder isn't at the top of the list, e.g. <code>python3 is /opt/homebrew/opt/python@3.9/bin/python3.9</code> , you can simply create an alias for it in your <code>~/.zshrc</code> file.</p>

<p>Open <code>~/.zshrc</code> with either nano or vim:</p>

<pre><span>nano ~/.zshrc</span></pre>

<p>and add these lines:</p>

<pre><span>alias&nbsp;python3='/opt/homebrew/opt/python@3.9/bin/python3.9'
alias&nbsp;pip3='/opt/homebrew/bin/pip3'</span></pre>

<p>Save (<code>Control + O</code>) and exit (<code>Control + X</code>), and run this for the changes to take effect:</p>

<pre><span>source&nbsp;~/.zshrc</span></pre>

<p>Now check that your homebrew version of python3 is at the top of your <code>type -a</code> list:</p>

<pre><span>type&nbsp;-a&nbsp;python3
python3 is an alias&nbsp;for&nbsp;/opt/homebrew/opt/python@3.9/bin/python3.9
python3 is /usr/bin/python3</span></pre>

<p>You can run the same test for <code>pip3</code>. If the homebrew version is at the top of the <code>type -a pip3</code> list then you're good to go!</p>

<h2>Wall of Compilation Errors: pip3 install azure-cli</h2>

<p>Normally it would be enough to run:</p>

<pre><span>pip3 install azure-cli</span></pre>

<p>and this would've been the end of the post had it not been for the wall of compilation errors I received as pip attempted to compile the dependencies for azure-cli. The following packages needed manual intervention:</p>

<ul>
	<li>
	<p>cffi</p>
	</li>
	<li>
	<p>cryptography</p>
	</li>
	<li>
	<p>bcrypt</p>
	</li>
	<li>
	<p>PyNaCl</p>
	</li>
</ul>

<p>After spending some hours troubleshooting these errors I was close to throwing in the towel, calling it a day on native brew/python and moving over to rosetta2. And then a breakthrough...</p>

<h3>Build cffi</h3>

<p>Building and installing the <code>cryptography</code> package requires <code>cffi</code> to be installed, and OpenSSL lib include files to be in your PATH. Both of these need manual attention:</p>

<ul>
	<li>
	<p>cffi doesn't build via pip</p>
	</li>
	<li>
	<p>OpenSSL isn't in the path</p>
	</li>
</ul>

<p>To build and install cffi follow these steps:</p>

<ol>
	<li>
	<p>Install libffi</p>
	</li>
</ol>

<pre><span>brew install pkg-config libffi</span></pre>

<ol start="2">
	<li>
	<p>Take note of the path to this libffi.pc file:</p>
	</li>
</ol>

<pre><span>find&nbsp;/opt/homebrew/ |&nbsp;grep&nbsp;"Cellar.*libffi.pc"
/opt/homebrew/Cellar/libffi/3.3/lib/pkgconfig/libffi.pc</span></pre>

<ol start="3">
	<li>
	<p>Grab the sources from <a href="https://pypi.org/project/cffi/">https://pypi.org/project/cffi/</a>:</p>
	</li>
</ol>

<pre><span>wget&nbsp;https://files.pythonhosted.org/packages/66/6a/98e023b3d11537a5521902ac6b50db470c826c682be6a8c661549cb7717a/cffi-1.14.4.tar.gz
​
tar&nbsp;-xzvf&nbsp;cffi-1.14.4.tar.gz
cd&nbsp;cffi-1.14.4</span></pre>

<ol start="4">
	<li>
	<p>Edit setup.py and add the path for libffi.pc that you noted down in step 2 to <code>include_dirs</code>:</p>
	</li>
</ol>

<p><span><code>setup.py</code></span></p>

<pre><span>import&nbsp;sys,&nbsp;os
import&nbsp;subprocess
import&nbsp;errno
​
# on Windows we give up and always import setuptools early to fix things for us
if&nbsp;sys.platform&nbsp;==&nbsp;"win32":
&nbsp; &nbsp;import&nbsp;setuptools
​
​
sources&nbsp;= ['c/_cffi_backend.c']
libraries&nbsp;= ['ffi']
include_dirs&nbsp;= ['/usr/include/ffi',
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;'/usr/include/libffi',
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;'/opt/homebrew//Cellar/libffi/3.3/lib/pkgconfig/']
​
...</span></pre>

<ol start="5">
	<li>
	<p>Build</p>
	</li>
</ol>

<pre><span>python3 setup.py install</span></pre>

<p>cffi is done! Now to the next dependency ...</p>

<h3>Build cryptography</h3>

<p>azure-cli requires an older version (&lt;3.0.0) of cryptography, which in turn needs the OpenSSL library. First grab OpenSSL via brew:</p>

<pre><span>brew install&nbsp;openssl</span></pre>

<p>Grab the lib path:</p>

<pre><span>find&nbsp;/opt/homebrew |&nbsp;grep&nbsp;"Cellar.*openssl.*/lib$"
​
/opt/homebrew/Cellar/openssl@1.1/1.1.1i/lib</span></pre>

<p>Now install version 2.9.2 and reference the OpenSSL lib and include folders from above:</p>

<pre><span>pip3 install&nbsp;cryptography==2.9.2&nbsp;--global-option=build_ext&nbsp;--global-option="-L/opt/homebrew/Cellar/openssl@1.1/1.1.1i/lib"&nbsp;--global-option="-I/opt/homebrew/Cellar/openssl@1.1/1.1.1i/include"</span></pre>

<p>Only two more dependencies to go.</p>

<h3>Build bcrypt and PyNaCl</h3>

<p>Both bcrypt and PyNaCl have the same steps:</p>

<ul>
	<li>
	<p>Download sources</p>
	</li>
	<li>
	<p>Manual install</p>
	</li>
</ul>

<h4>bcrypt</h4>

<p>Go to <a href="https://pypi.org/project/bcrypt/">https://pypi.org/project/bcrypt/</a> and download sources, unpack, and run setup.py:</p>

<pre><span>wget&nbsp;https://files.pythonhosted.org/packages/d8/ba/21c475ead997ee21502d30f76fd93ad8d5858d19a3fad7cd153de698c4dd/bcrypt-3.2.0.tar.gz
​
tar&nbsp;-xzvf&nbsp;bcrypt-3.2.0.tar.gz
cd&nbsp;bcrypt-3.2.0
python3 setup.py install</span></pre>

<h4>PyNaCl</h4>

<p>Go to <a href="https://pypi.org/project/PyNaCl/">https://pypi.org/project/PyNaCl/</a>, get sources and do the same:</p>

<pre><span>wget&nbsp;https://files.pythonhosted.org/packages/cf/5a/25aeb636baeceab15c8e57e66b8aa930c011ec1c035f284170cacb05025e/PyNaCl-1.4.0.tar.gz
​
tar&nbsp;-xzvf&nbsp;PyNaCl-1.4.0.tar.gz
cd&nbsp;PyNaCl-1.4.0
python3 setup.py install</span></pre>

<h3>Install azure-cli</h3>

<p>Finally, you should have everything you need to install azure-cli via pip. Go ahead and try it:</p>

<pre><span>pip3 install azure-cli</span></pre>

<p>Good luck and thanks for reading!</p>
          </div>
        </div>
    
      </div>
    </div></div>]]>
            </description>
            <link>https://www.thectgrid.com/blog/installing-azure-cli-apple-silicon-macos-m1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625789</guid>
            <pubDate>Sun, 03 Jan 2021 22:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from Idea to Landing Page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625676">thread link</a>) | @vuciv1
<br/>
January 3, 2021 | https://jerseyfonseca.com/blogs/swapiverseprelaunch | <a href="https://web.archive.org/web/*/https://jerseyfonseca.com/blogs/swapiverseprelaunch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p><img src="https://jerseyfonseca.com/projects/images/swapiverse/landingpage.png"></p><p>
            Last night, <a href="https://www.dwold.com/">David</a> and I put up our 
            <a href="https://www.swapiverse.com/">Swapiverse's landing page</a>. 
            It's a simple idea: trade books you have for books you want. I had the 
            same stresses most people have. Where do I get my users? How do I do 
            SEO? I can't afford ads! Am I wasting my time? However, we've quickly 
            seen a really high conversion rate with organic marketing! I want to 
            share what I think has helped us find an idea worth showing people.  
        </p>
        <h2>Finding A Problem I Have</h2>
        <p>
            I used to go out and seek problems to solve. I would code something up 
            for these problems I have never personally experienced, but knew others had. 
            It's no coincidence that these were always my least successful projects. Why 
            have I been looking for other people's problems? I have enough of them on my own!
        </p>
        <p>
            Last year, I made <a href="https://jerseyfonseca.com/projects/bujo.html">Vim Bujo</a>, a minimal task manager 
            for vim. I made it for myself - to solve a problem I personally had: how do I 
            manage a todo list without leaving my workflow? It should not have been to 
            my surprise that this was my first open source project with consistent users. 
            I know deep down about the problem they are facing, because I have the same one! 
        </p>
        <p>
            This time, my problem was buying books. Since I just graduated from 
            The University of Chicago, <a href="https://www.unigo.com/colleges/university-of-chicago/reviews/what-is-the-stereotype-of-students-at-your-school-is-this-stereotype-accurate">"the place where fun goes to die,"</a> 
            I have been experiencing more free time than I've had in the last four years. 
            There were no brutal nights up late studying, reading for class, or even partying 
            with students! Sure there are some nights where I need to stay a bit later at work, 
            but nothing in comparison to what college was like. With all this free time, I've 
            found lots of hobbies. I go bouldering a few times a week, and have finally been 
            reading books.  
        </p>
        <h3>Inspiration Strikes</h3>
        <p>
            Now, I'm admittedly a slow reader. I have ADHD and get distracted really easily! 
            However, with all this free time, I've been able to plow through books pretty quickly. 
            When I ran out, my partner and I went to a bookstore where I bought four books, for... $80!!!
        </p>
        <p>
            $80?!? Jeez. These are all recent bestsellers, I'm sure someone also reading a recent 
            bestseller would be willing to trade with me after they're done. Wait... That would 
            be awesome! I save money, I help the environment, and I get to connect with someone 
            over what we read!
        </p>
        <h2>Researching Competition</h2>
        <p>
            I started looking up products that do this, and, as always, it already exists. 
            In fact, a lot of them exist! I've learned not to be discouraged by this, though. 
            That means that my idea has a market. Furthermore, I believe in myself to do it 
            even better. Maybe this is just because I'm arrogant, but we have to believe that 
            we can do it better if we want to create things!
        </p>
        <p>
            I signed up for just about every competitor I can find. I used their sites and apps extensively. 
            I studied how their process works. I took notes on where the user experience was strong, and 
            just as importantly, where it was weak. I researched their audiences, their keywords, their 
            social media presence, etc.. This was probably the most important part of the entire process. I 
            can't create a better product, if I don't know the ins and outs of the competing products. 
        </p>
        <p>
            After a few weeks of this, I was ready to begin working on Swapiverse.
        </p>
        <h2>Making The Pre-Launch Landing Page</h2>
        <p>
            I believe that this is where I struggled the most. I wanted my landing page to 
            be perfect! Of course I did; who doesn't? I read <a href="https://www.indiehackers.com/@pedrocortes/694e691963">articles</a> 
            on building a great landing page and tried to get it all right. Unfortunately, there 
            were so many areas that I felt were slacking. Even worse, there was so much more I wanted to add. 
        </p>
        <p>
            At this point, we were a few days past our deadline to finish our landing page. 
            I knew that getting something out is better than nothing, so we decided to launch it anyway.  
            The most important criteria were fulfilled: users knew what the site does, they knew how to sign up, 
            and they could find all our other social medias. Of course, this page will be iterated on, but 
            I couldn't help but feel as though if I try to perfect it now, I will never finish my MVP.
        </p>
        <h3>Realizing My Resources Aren't Infinite</h3>
        <p>
            I find that I end up comparing my landing site to that of Facebook, Stripe, etc.. But I need to remind 
            myself that Facebook pays countless engineers hundreds of thousands of dollars to make their landing 
            page perfect. One day when Swapiverse is a billion dollar tech giant, I'll be able to make it perfect. 
            But for now, as a dev with a fulltime job, I'll accept my limitations. Heck, I'm not even a frontend developer!
        </p>
        <h3>Realizing Most Sites Aren't Pretty</h3>
        <p>
            The More I think about it, the more I realize that most websites aren't as gorgeous or functional as 
            they could be... I come across bugs and clunky UIs with just about every site or app I use! On top of 
            that, I don't even care when I really like the site/app I'm using. 
        </p>
        <h2>Sharing Our Landing Page</h2>
        <p>
            Our marketing tactics have been inspired by Paul Graham's advice: 
            <a href="http://paulgraham.com/ds.html"> Do Things That Don't Scale</a>.
            If I want my first users, I just gotta grind it out and go out there and get them.
        </p>
        <h3>Reaching Out To People On Social Media</h3>
        <p>
            The golden answer for us has just been to find the right people and DM them. 
            You're going to be rejected a lot, but if you are genuinely excited and solving 
            a problem of theirs, they're going to be interested in your solution! Have a really 
            succinct starter message, and as soon as you get a positive response back, hit them 
            with the link. Our conversion rate when we DM people on social media has been much 
            higher than we anticipated.
        </p>
        <h3>Telling Our Friends</h3>
        <p>
            I am lucky enough to have good friends. We genuinely care about each other. 
            The moment I tell them that I am building something, they are instantly willing 
            to sign up and use it! While we gain a lot of users from social media marketing, 
            nothing is better than the support of those you care about. 
        </p>
        <h2>Now Onto Building The Rest...</h2>
        <p>
            There's a long way to go, but don't underestimate the success of getting your first 
            users. Thanks for reading, and I hope you'll stay in touch :)
        </p>
    </div></div>]]>
            </description>
            <link>https://jerseyfonseca.com/blogs/swapiverseprelaunch</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625676</guid>
            <pubDate>Sun, 03 Jan 2021 22:04:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ for Swift Developers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625656">thread link</a>) | @chunkyguy
<br/>
January 3, 2021 | https://whackylabs.com/swift/cpp/languages/2021/01/03/cpp-for-swift-devs/ | <a href="https://web.archive.org/web/*/https://whackylabs.com/swift/cpp/languages/2021/01/03/cpp-for-swift-devs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <main>
        <article>
  
  <time datetime="2021-01-03T13:30:00+00:00">03 Jan 2021</time>
  <p>Swift in a sense is very much like C++, and when I say C++ I mean C++11 and beyond. One could also say that Swift is <em>cleaner</em> C++, or C++ without the backwards compatibility baggage from the 80s. To give an idea here’s a minimal <em>modern</em> C++ code:</p>

<div><div><pre><code><span>#include &lt;iostream&gt;       // 1
</span><span>using</span> <span>namespace</span> <span>std</span><span>;</span>      <span>// 2</span>
<span>auto</span> <span>main</span><span>()</span> <span>-&gt;</span> <span>int</span> <span>{</span>      <span>// 3</span>
  <span>cout</span> <span>&lt;&lt;</span> <span>"Hello world!"</span><span>;</span> <span>// 4</span>
  <span>return</span> <span>0</span><span>;</span>               <span>// 5</span>
<span>}</span>
</code></pre></div></div>

<p>Now lets break them down from Swift perspective.</p>


<p>Swift equivalent would be <code>import iostream</code>. Frameworks usually come with an umbrella header as a single file, so typically we need to add only one include statement per framework like in Swift. But unlike Swift, we need to add include statements for every file we want to use from our own code.</p>

<div><div><pre><code><span>#include &lt;framework&gt;      // external framework
#include "path/to/file.h" // local file
</span></code></pre></div></div>

<div><div><pre><code><span>using</span> <span>namespace</span> <span>std</span><span>;</span> <span>// 2</span>
</code></pre></div></div>

<p>Unlike Swift, C++ has a proper support for namespaces. So if two types in different frameworks have same type name they can be resolved using their namespaces. For example <code>fwkA::JSON</code> and <code>fwkB::JSON</code>. To get a more Swift like behavior we can add <code>using</code> to indicate that the symbols do not need their namespace for every single usage.</p>

<div><div><pre><code><span>auto</span> <span>main</span><span>()</span> <span>-&gt;</span> <span>int</span> <span>{</span> <span>// 3</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>This is the modern way of writing functions in C++. In classic fashion this function could also be written as:</p>

<div><div><pre><code><span>int</span> <span>main</span><span>()</span> <span>{</span>
  <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Hello world!"</span><span>;</span>
  <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<div><div><pre><code><span>cout</span> <span>&lt;&lt;</span> <span>"Hello world!"</span><span>;</span> <span>// 4</span>
</code></pre></div></div>

<p>Like Swift we can also override operators in C++. In this case the <code>iostream</code> library provides <code>cout</code> which is an object of type <code>ostream</code> that outputs to <em>standard output stream</em>. <code>iostream</code> also provides overrides for <code>operator &lt;&lt;</code> for many common types like for <code>string</code> that we’re using above. But it can also work for our custom types if we provide the <code>operator &lt;&lt;</code> for our type. The Swift equivalent to this would be the <code>CustomStringConvertible</code> protocol.</p>



<p>And finally since our function requires a return type <code>int</code> we have to end our function with a <code>return</code> statement.</p>

<p>With a basic introduction, now let us take a look at C++ in a bit more detail from Swift perspective.</p>

<ul>
  <li><a href="#variables">Variables</a></li>
  <li><a href="#string">String</a></li>
  <li><a href="#array">Array</a></li>
  <li><a href="#dictionary">Dictionary</a></li>
  <li><a href="#optional">Optional</a></li>
  <li><a href="#function">Function</a></li>
  <li><a href="#closures">Closures</a></li>
  <li><a href="#classes">Classes</a></li>
  <li><a href="#error-handling">Error handling</a></li>
  <li><a href="#generics">Generics</a></li>
</ul>

<h2 id="variables">Variables</h2>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
var myVariable = 42
myVariable = 50 
let myConstant = 42
</code></pre></td>
<td><pre><code>
auto myVariable = 42;
myVariable = 50;
const auto myConstant = 42;
</code></pre></td>
</tr></tbody>
</table>

<p>Just like in Swift types can be deduced by the compiler using <code>auto</code>, but if required we can always also provide the type information explicitly.</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
let myFloat: Float = 3.14
</code></pre></td>
<td><pre><code>
float myFloat = 3.14;
</code></pre></td>
</tr></tbody>
</table>

<p>Unlike Swift, type conversions can also occur implicitly in C++. This needs to be carefully watched out for to avoid hard to find bugs. For other cases we need to explicitly convert data from a type to another. For example <code>int</code> to <code>string</code></p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
let label = "The width is "
let width = 94
let widthLabel = label + String(width)
</code></pre></td>
<td><pre><code>
auto label = "The width is ";
auto width = 94;
auto widthLabel = label + to_string(width);
</code></pre></td>
</tr></tbody>
</table>

<h2 id="string">String</h2>

<p>String interpolation in C++ isn’t as good as with Swift. But nonetheless we can construct <code>string</code> with either explicit string conversion, like we saw above</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
let apples = 3
let oranges = 5
let appleSummary = "I have \(apples) apples."
let fruitSummary = "I have \(apples + oranges) pieces of fruit."
</code></pre></td>
<td><pre><code>
auto apples = 3;
auto oranges = 5;
auto appleSummary = "I have " + to_string(apples) + " apples.";
auto fruitSummary = "I have " + to_string(apples + oranges) + " pieces of fruit.";
</code></pre></td>
</tr></tbody>
</table>

<p>Or using <code>ostringstream</code> which works just like <code>cout</code> and makes use of <code>operator &lt;&lt;</code></p>

<div><div><pre><code><span>auto</span> <span>apples</span> <span>=</span> <span>3</span><span>;</span>
<span>ostringstream</span> <span>ss</span><span>;</span>
<span>ss</span> <span>&lt;&lt;</span> <span>"I have "</span> <span>&lt;&lt;</span> <span>apples</span> <span>&lt;&lt;</span> <span>" apples."</span><span>;</span>
<span>auto</span> <span>str</span> <span>=</span> <span>ss</span><span>.</span><span>str</span><span>();</span>
</code></pre></div></div>

<p>which can then further be reduced to:</p>

<div><div><pre><code><span>auto</span> <span>str</span> <span>=</span> <span>(</span><span>ostringstream</span><span>()</span><span>&lt;&lt;</span><span>"I have "</span><span>&lt;&lt;</span><span>apples</span><span>&lt;&lt;</span><span>" apples."</span><span>).</span><span>str</span><span>();</span>
</code></pre></div></div>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
let apples = 3
let oranges = 5
let appleSummary = "I have \(apples) apples."
let fruitSummary = "I have \(apples + oranges) pieces of fruit."
</code></pre></td>
<td><pre><code>
auto apples = 3;
auto oranges = 5;
auto appleSummary = (ostringstream()&lt;&lt; "I have "&lt;&lt;apples&lt;&lt;" apples.").str();
auto fruitSummary = (ostringstream()&lt;&lt;"I have "&lt;&lt;(apples + oranges)&lt;&lt;" pieces of fruit.").str();
</code></pre></td>
</tr></tbody>
</table>

<h2 id="array">Array</h2>

<p>Swift <code>Array</code> equivalent in C++ is <code>vector</code>. Here’s how you use it</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
var shoppingList = ["catfish", "water", "tulips"]
shoppingList[1] = "bottle of water"
shoppingList.append("blue paint")
</code></pre></td>
<td><pre><code>
auto shoppingList = vector&lt;string&gt;{"catfish", "water", "tulips"};
shoppingList[1] = "bottle of water";
shoppingList.push_back("blue paint");
</code></pre></td>
</tr></tbody>
</table>

<p>And this is how you iterate a <code>vector</code></p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
for item in shoppingList {
  print(item)
}
</code></pre></td>
<td><pre><code>
for (auto &amp; item : shoppingList) {
  cout &lt;&lt; item &lt;&lt; endl;
}
</code></pre></td>
</tr></tbody>
</table>

<p>The <code>&amp;</code> here means that we wish to use <code>item</code> as a reference. If we were to use <code>auto item</code> it would always create a new copy.</p>

<h2 id="dictionary">Dictionary</h2>

<p>Swift <code>Dictionary</code> equivalent in C++ is <code>map</code>. Here’s how you use it</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
var occupations = [
  "Malcolm": "Captain",
  "Kaylee": "Mechanic",
]
occupations["Jayne"] = "Public Relations"
</code></pre></td>
<td><pre><code>
auto occupations = map&lt;string, string&gt; {
  {"Malcolm", "Captain"},
  {"Kaylee", "Mechanic"},
};
occupations["Jayne"] = "Public Relations";
</code></pre></td>
</tr></tbody>
</table>

<p>And this is how you iterate over a <code>map</code></p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
for (key, value) in occupations {
  print("\(key) : \(value)")
}
</code></pre></td>
<td><pre><code>
for (auto&amp; [key, value]: occupations) {
  cout &lt;&lt; key &lt;&lt; " : " &lt;&lt; value &lt;&lt; endl;
}
</code></pre></td>
</tr></tbody>
</table>

<h2 id="optional">Optional</h2>

<p>Swift developers love <code>Optional</code> types. Fortunately for us, C++ also got <code>optional</code> types starting c++17. Although not as fancy as with Swift, but the core idea is the same: A type that either has the value or not. Here’s an example:</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
func greeting(_ required: Bool) -&gt; String? {
  return required ? Optional("Hello") : nil;
}

func main() -&gt; Int {
  let s = greeting(false) ?? "Hi"
  print(s) // Hi

  if let str = greeting(true) {
    print(str) // Hello
  }

  return 0
}
</code></pre></td>
<td><pre><code>
auto greeting(bool required) -&gt; optional&lt;string&gt; {
  return required ? optional{"Hello"} : nullopt;
}

auto main() -&gt; int {
  auto s = greeting(false).value_or("Hi");
  cout &lt;&lt; s &lt;&lt; endl; // Hi

  if (auto str = greeting(true)) {
    cout &lt;&lt; *str &lt;&lt; endl; // Hello
  }

  return 0;
}
</code></pre></td>
</tr></tbody>
</table>

<p>The <code>*str</code> can be thought of as force unwrapping in Swift, <code>str!</code>. And after <em>dereferencing</em> we can either use the <code>.</code> or the handy <code>-&gt;</code> operator to access the variable.</p>

<div><div><pre><code><span>(</span><span>*</span><span>str</span><span>).</span><span>size</span><span>();</span>
<span>str</span><span>-&gt;</span><span>size</span><span>();</span>
</code></pre></div></div>

<h2 id="function">Function</h2>

<p>C++ functions do not have argument labels</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
func greet(_ person: String, on day: String) -&gt; String {
    return "Hello \(person), today is \(day)."
}

greet("John", on: "Wednesday")
</code></pre></td>
<td><pre><code>
auto greetPersonOnDay(string person, string day) -&gt; string {
  return (ostringstream()&lt;&lt;"Hello "&lt;&lt;person&lt;&lt;", today is "&lt;&lt;day&lt;&lt;".").str();
}

greetPersonOnDay("John", "Wednesday")l
</code></pre></td>
</tr></tbody>
</table>

<p>But if you really miss having named arguments there are many tricks of all shapes and sizes out there. The simplest is to use a <code>struct</code> for arguments</p>

<div><div><pre><code><span>struct</span> <span>Args</span> <span>{</span> <span>string</span> <span>person</span><span>,</span> <span>day</span><span>;</span> <span>};</span>
<span>auto</span> <span>greet</span><span>(</span><span>Args</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>string</span> <span>{</span>
  <span>return</span> <span>(</span><span>ostringstream</span><span>()</span><span>&lt;&lt;</span><span>"Hello "</span><span>&lt;&lt;</span><span>args</span><span>.</span><span>person</span><span>&lt;&lt;</span><span>", today is "</span><span>&lt;&lt;</span><span>args</span><span>.</span><span>day</span><span>&lt;&lt;</span><span>"."</span><span>).</span><span>str</span><span>();</span>
<span>}</span>

<span>greet</span><span>({.</span><span>person</span> <span>=</span> <span>"John"</span><span>,</span> <span>.</span><span>day</span> <span>=</span> <span>"Wednesday"</span><span>})</span>
</code></pre></div></div>

<h2 id="closures">Closures</h2>

<p>C++ has a good support for closures. Here’s an example:</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
func hasAnyMatches(list: [Int], condition: (Int) -&gt; Bool) -&gt; Bool {
  for item in list {
    if condition(item) {
      return true
    }
  }
  return false
}

func lessThanTen(number: Int) -&gt; Bool {
  return number &lt; 10
}

var numbers = [20, 19, 7, 12]
hasAnyMatches(list: numbers, condition: lessThanTen)
</code></pre></td>
<td><pre><code>
auto hasAnyMatches(vector&lt;int&gt; list, function&lt;bool(int)&gt; condition) -&gt; bool {
  for (auto item : list) {
    if (condition(item)) {
      return true;
    }
  }
  return false;
}

auto lessThanTen(int number) -&gt; bool {
  return number &lt; 10;
}

auto numbers = vector&lt;int&gt; {20, 19, 7, 12};
hasAnyMatches(numbers, lessThanTen);
</code></pre></td>
</tr></tbody>
</table>

<p>That said, C++ still doesn’t has all the fancy functional operations like <code>map</code>, <code>filter</code>, <code>...</code> that we get with Swift, but they’re coming soon with <a href="https://en.cppreference.com/w/cpp/ranges">C++20 ranges</a>. For now we can use <code>transform</code> as an equivalent to Swift <code>map</code></p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
numbers.map({ (number: Int) -&gt; Int in
  let result = 3 * number
  return result
})
</code></pre></td>
<td><pre><code>
transform(numbers.begin(), numbers.end(), numbers.begin(), [](auto number) -&gt; auto {
  auto result = 3 * number;
  return result;
});
</code></pre></td>
</tr></tbody>
</table>

<p>The C++ code here would actually mutate the <code>numbers</code>. If we want the truly Swift <code>map</code> equivalent we would have to create an empty <code>vector</code> and append data to it</p>

<div><div><pre><code><span>auto</span> <span>mappedNumbers</span> <span>=</span> <span>vector</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>{};</span>
<span>transform</span><span>(</span><span>numbers</span><span>.</span><span>begin</span><span>(),</span> <span>numbers</span><span>.</span><span>end</span><span>(),</span> <span>back_inserter</span><span>(</span><span>mappedNumbers</span><span>),</span> <span>[](</span><span>auto</span> <span>n</span><span>)</span> <span>{</span> 
  <span>return</span> <span>3</span> <span>*</span> <span>n</span><span>;</span> 
<span>});</span>
</code></pre></div></div>

<h2 id="classes">Classes</h2>

<p>Unlike Swift in C++ there isn’t much difference between a <code>struct</code> and a <code>class</code> with the only difference being that a C++ struct has all members <code>public</code> by default whereas a <code>class</code> has all members as <code>private</code> by default. Whether the instance is mutable or not depends on how it is declared.</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
class Shape {

  func simpleDescription() -&gt; String {
    return "A shape with \(numberOfSides) sides."
  }

  var numberOfSides = 0
}

var shape = Shape()
shape.numberOfSides = 7
var shapeDescription = shape.simpleDescription()
</code></pre></td>
<td><pre><code>
class Shape {
public:
  auto simpleDescription() -&gt; string {
    return (ostringstream()&lt;&lt;"A shape with "&lt;&lt;numberOfSides&lt;&lt;" sides.").str();
  }

  int numberOfSides = 0;
};

auto shape = Shape();
shape.numberOfSides = 7;
auto shapeDescription = shape.simpleDescription();
</code></pre></td>
</tr></tbody>
</table>

<p>Initializer (or constructor as they are called in C++) have a slightly different syntax</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
class Shape {

  init(name: String) {
    self.name = name
  }

  func simpleDescription() -&gt; String {
    return "A shape with \(numberOfSides) sides."
  }

  var numberOfSides = 0
  var name: String
}
</code></pre></td>
<td><pre><code>
class Shape {
public:
  Shape(string name)
    : name(name) {
  }

  auto simpleDescription() -&gt; string {
    return (ostringstream()&lt;&lt;"A shape with "&lt;&lt;numberOfSides&lt;&lt;" sides.").str();
  }

  int numberOfSides = 0;
  string name;
};
</code></pre></td>
</tr></tbody>
</table>

<p>In C++ subclasses need to be more explicit than Swift.</p>

<table>
<thead><tr><th>Swift</th><th>C++</th></tr></thead>
<tbody><tr>
<td><pre><code>
class Square: Shape {

  init(sideLength: Double, name: String) {
    self.sideLength = sideLength
   …</code></pre></td></tr></tbody></table></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://whackylabs.com/swift/cpp/languages/2021/01/03/cpp-for-swift-devs/">https://whackylabs.com/swift/cpp/languages/2021/01/03/cpp-for-swift-devs/</a></em></p>]]>
            </description>
            <link>https://whackylabs.com/swift/cpp/languages/2021/01/03/cpp-for-swift-devs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625656</guid>
            <pubDate>Sun, 03 Jan 2021 22:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accelerating JPEG Coding with Multiple Threads]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25625650">thread link</a>) | @matylla
<br/>
January 3, 2021 | https://optidash.ai/blog/accelerating-jpeg-coding-with-multiple-threads | <a href="https://web.archive.org/web/*/https://optidash.ai/blog/accelerating-jpeg-coding-with-multiple-threads">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>After the JPEG standard was released in 1992, JPEG images became synonymous with digital photography and are used in almost every application which works with photo quality images. The reason the adoption of the standard was fast and nearly universal is that it makes use of multiple techniques simultaneously to reduce the compressed file size. One of those is an understanding of the limits of the human visual system and which information is important to preserve versus which is less important and can be removed.</p><h2 id="the-jpeg-coding-algorithm">The JPEG coding algorithm</h2><p>There are several steps needed to compress an image using the JPEG method (see image below). To begin, it is usually converted from RGB into the YCbCR colorspace. The reason this is necessary is to allow sub-sampling of the pixels. The human eye is more sensitive to changes in luminance than changes in chrominance. This allows the chroma channels to be downsampled while keeping the luma channel at full resolution. The image can lose 50% of its data with this step and the perceived degradation is quite minimal. The image is then divided into 8x8 MCUs or minimum coded units (the equivalent terminology for video codecs is Macro Blocks). These MCUs are square blocks of pixels which are compressed based on the similarity to each other. The pixels in each MCU are transformed from the spatial domain to the frequency domain with a <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform" rel="noopener noreferrer" target="_blank">Discrete Cosine Transform</a> (DCT). The operation allows for the easy removal of high frequency information (fine detail) to further compress the image. The more high frequency coefficients are removed, the smaller the file and the blurrier the image becomes. This effectively controls the “Q Value” or compression amount used by encoders.</p><figure><img srcset="https://optidash.ai/assets/images/blog/accelerating-jpeg-coding-with-multiple-threads/jpeg-coding.png, https://optidash.ai/assets/images/blog/accelerating-jpeg-coding-with-multiple-threads/jpeg-coding@2x.png 2x" alt="JPEG coding steps"><figcaption>JPEG coding steps</figcaption></figure><p>One of the many clever ideas incorporated into the standard is to use the similarity in DC value (essentially the brightness) between adjacent MCUs to further reduce the data size by compressing just the change from one to the next instead of encoding the entire value. This is depicted above in the “DPCM coding” block. This is a great idea, but it creates a small problem. By having each successive MCU’s DC value(s) depend on a delta from the previous, it means that if there is an error in the data, the MCUs from that point on down will all be wrong.</p><p>Making matters slightly worse is that the compressed symbols which encode the image data (shown above as “Huffman coding”) are Variable Length Codes (VLC). A single wrong bit can corrupt the data from that point forward. Back in the ‘old’ days when JPEG was invented, this was a very real concern because images were often transmitted over channels (e.g. acoustic modem) that may not have had robust error correction or stored on media (e.g. floppy disks) that were prone to errors. Knowing that the data may suffer from errors, a feature was added to the standard to mitigate the amount of the image that would be corrupted by bad data. The idea was to periodically reset the previous DC value to 0, forcing the next MCU to encode its entire value as a delta from 0. This means that any corrupted DC values will only affect pixels up to the next restart point.</p><p>This is implemented with Restart Markers. They are 2-byte markers placed in between the MCUs at regular intervals (e.g. every 100 MCUs). If a data corruption occurs, it’s easy to scan forward in the file to the next restart marker (JPEG markers are always on byte boundaries and preceded by 0xFF). Once the next restart marker is found, the image can be properly decoded from that point on since the number of MCUs between each restart marker is known.</p><h2 id="the-ever-evolving-use-of-digital-images">The ever evolving use of digital images</h2><p>Starting not long after the JPEG standard was released, computer networks and storage were getting more reliable and incorporated error detection and correction (e.g. TCP/IP). The solid state storage cards used in digital cameras were quite reliable and the restart markers were ‘forgotten’ for a while since they made the files slightly larger without giving much perceived benefit. During that period, computer software was mostly designed to run on a single processor using a single thread. The fact that a JPEG image needed to be decoded in a single pass due to its use of variable length codes and a string of successive delta values for the MCU didn’t cause any problems for software since it was designed to run as a single thread anyway.</p><p>In the last few years however, computers and our use of JPEG images have changed dramatically. Nearly every computing device has multiple CPUs and runs an operating system with multiple threads (even phones). The other change is that people are taking, editing and viewing billions of JPEG photos on their mobile phones. Each generation of phones produce larger and higher resolution images. For anyone working with tons of photos, the time to encode and decode them has become increasingly important because of the sheer volume and size of new images being generated.</p><figure><img srcset="https://optidash.ai/assets/images/blog/accelerating-jpeg-coding-with-multiple-threads/images-chart.png, https://optidash.ai/assets/images/blog/accelerating-jpeg-coding-with-multiple-threads/images-chart@2x.png 2x" alt="The sum of transfer size kilobytes of all external images requested by the page."><figcaption>The average transfer size of images requested by the web page. Data source: <a href="https://httparchive.org/reports/state-of-images#bytesImg" target="_blank" rel="noopener noreferrer">HTTP Archive</a></figcaption></figure><h2 id="repurposing-a-good-idea-into-an-even-better-idea">Repurposing a good idea into an even better idea</h2><p>Computers have been getting more powerful on a mostly continuous trajectory since the 1970s. A general term used to describe the continuous improvements in silicon processing called <a href="https://en.wikipedia.org/wiki/Moore%27s_law" rel="noopener noreferrer" target="_blank">Moore’s Law</a> was coined many years ago to commemorate Gordon Moore’s prediction that computers will double the number of transistors every 18 months. This has held mostly true for the transistor count, but the maximum speed of computers has basically hit a dead end due to the physical limitations of silicon and power+heat issues. Since individual processor speed hasn’t advanced much in the last few years, the emphasis has shifted to employing many processors to complete tasks faster by working in parallel. In today’s computing environment, it’s advantageous to be able to divide a task into sections and assign them to multiple CPUs. Not all tasks are possible to divide because each successive part may depend on the results from the previous. JPEG encoding and decoding are normally difficult to divide into pieces and run in parallel because of the way each successive MCU depends on the previous one and the use of variable length codes.</p><p>However… A convenient benefit of restart markers is that the VLC data is reset to a byte boundary (after the marker) and the MCU DC delta value is also reset. This means that both JPEG encoding and decoding could be divided into multiple threads with the use of restart markers. For encoding, the image could be divided into symmetrical strips and each strip could be encoded by a different processor. When each processor completes that task, the output of each can then be ‘glued’ together using restart markers. For decoding, the task can be spread across as many processors as there are restart markers. The only extra effort needed is to scan forward in the compressed data looking for the restart markers first since the size of the compressed data between each varies and there is no ‘directory’ in JPEG files showing where the restart markers are located.</p><h2 id="real-world-example">Real World Example</h2><p>With multi-threaded applications, the performance rarely scales 1:1 with the number of CPUs utilized (e.g. splitting a task into 12 threads on 12 CPU cores doesn’t mean it will run 12x faster). There is extra overhead in managing the threads and the memory is usually a single entity shared among the processors. Let’s run a test on the following image:</p><figure><img srcset="https://optidash.ai/assets/images/blog/accelerating-jpeg-coding-with-multiple-threads/jpeg-timings-image.jpg" alt="JPEG timings example image"><figcaption>Image credit: <a href="https://unsplash.com/@matthewhenry" target="_blank" rel="noopener noreferrer">Matthew Henry</a> on Unsplash</figcaption></figure><p>Among other techniques, at Optidash we incorporate this idea of using restart markers to greatly accelerate both the decoding and encoding of images. The image above was run through one of our testing tools on a 2018 MacBook Pro 15” laptop with a 6-core Intel i7 processor. Here are the results:</p><div><table><thead><tr><td>Number of CPUs</td><td>Image decode time</td><td>Image encode time</td></tr></thead><tbody><tr><td>1</td><td>53ms</td><td>264ms</td></tr><tr><td>3</td><td>25ms</td><td>104ms</td></tr><tr><td>6</td><td>18ms</td><td>61ms</td></tr></tbody></table></div><p>As you can see in the table above, there is a measurable advantage to splitting JPEG coding into multiple parts and assigning them to different CPUs. Depending on the task, the speed rarely scales linearly when using more CPUs. In this case, the intense use of large areas of memory limits how much benefit multiple CPUs can improve the overall speed.</p><p>Here’s some pseudocode which demonstrates how a multi-threaded JPEG encoder might look:</p><pre><code>void ThreadedWriteJPEG(assorted JPEG parameters, int numThreads) {
    int slice;
    pthread_t tinfo;

    // set completion counter
    sliceRemaining = numThreads;

    // Start a thread for each slice
    for (slice = 0; slice &lt; numThreads; slice++) {
        pthread_t tinfo;

        // Use a ‘slice’ structure to hold info about each thread’s work
        // This includes a pointer to the start of that strip of pixels
        // and the number of lines to compress

        &lt;setup slice structure for each thread’s work&gt;

        pthread_create(&amp;tinfo, NULL, JPEGBuffer, &amp;slices[slice]);
    } // for each slice

    // wait for all worker threads to finish
    WaitForThreads(&amp;sliceRemaining);

    // merge slices into a single file and write it
    WriteJPEGBuffer(slices, numThreads);
}
</code></pre></article></div>]]>
            </description>
            <link>https://optidash.ai/blog/accelerating-jpeg-coding-with-multiple-threads</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625650</guid>
            <pubDate>Sun, 03 Jan 2021 22:00:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Learnings Condensed To: “Dos and Don'ts in DIY Hardware Projects”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625633">thread link</a>) | @hinsencamp
<br/>
January 3, 2021 | https://100daysofhardware.com/blog/Dos-and-Donts-in-hardware-projects/ | <a href="https://web.archive.org/web/*/https://100daysofhardware.com/blog/Dos-and-Donts-in-hardware-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><section><div><p>The buzz around&nbsp;5G, AI, Blockchain, and IoT has enabled many new hardware use cases.</p><p>Thus, hardware development experiences a surge in practicality and popularity. This makes it the most exciting time since 20 years to get into electronics and hardware!
As a result, more and more hobbyists get excited to about the niche. Many, without putting the necessary care into their projects.
This practice might lead to self-inflicted </p><p> security breaches in smart homes</p><p> or other serious flaws.</p><p>To avoid such beginner's pitfalls and make your journey into electronics and hardware development a success, here are a few general Do’s and Don’ts to guide you.</p><h2>Don’t: Cutting Cost by all Means</h2><p>Components can eat up your project budget quickly. Keeping track of expenses is important in any development scenario.</p><p>However, fixating too much on the cost of your project and optimizing too early can distract you from making progress, delay or even hinder the successful completion.
You shouldn't start buying components at cheap &amp; dodgy overseas suppliers directly, just to save some bugs.
The potential negative implications are not worth it. Read more about this, in our </p><p>Hardware Guide</p><p>.</p><h2>Do: Push for prototypes</h2><p>One way to keep cost under control without sacrificing parts quality is to focus on building prototypes early on.</p><p><a href="https://blog.seebo.com/iot-prototypes/">Oren Ezra of Seebo</a> writes:</p><blockquote><p>“Prototypes can be used to test behaviors, software and firmware interactions in advance, that will affect the final <!-- -->[result]<!-- -->."</p></blockquote><p>A working prototype will tell you what’s easy or difficult to build and how much a fully build-out project might cost.
You can also build independent prototypes of individual parts of your project.
Instead of buying all components at once in the beginning, you can first only buy some components to build your prototypes.
When you have verified the practical feasibility of your design, you can incrementally acquire the missing parts.</p><h2>Do: Choose the right dev platform</h2><p>We are bombarded with new development platforms every day. Choosing the right hardware platform is now becoming a critical task for successful hardware development. When you build prototypes, make sure all the functionalities of the final project are validated.
The most popular development platforms are Arduino, Raspberry Pi and Galileo. Some are scalable, whereas others are more customizable, or secure. These have a huge community and many projects are powered by them. Apart from the community support, there are so many add-on modules available for these platforms for different purposes such as display, connectivity, motors, etc.</p><p>The principle of "fail fast, fail early" applies here. You should verify early on, if you work with the right platform. Otherwise, if you find out late that you have picked the wrong platform, you might spend a lot of time with design translation (both software &amp; hardware).
The latest point in time to migrate to a new platform should be after you completed prototyping and before starting the production development.</p><h2>Don’t: Underestimate manufacturing</h2><p>Often developers get so wrapped up in the theoretical part of hardware design they forget to give proper thought to the actual printed circuit board (PCB) manufacturing process.
Designing and making projects that physically work takes trial and error. You need to plan extra time to development and testing your PCB design and run through multiple manufacturing loops till you eliminated all layout flaws.</p><p>If possible, get into contact with the PCB manufacturers early on. Find out about the specifications they recommend for your kind of project, and whether your initial design would be feasible.</p><h2>Do: Decide on the Technology for Connectivity</h2><p>Cellular or WIFI connectivity? It might look like a straight forward decision, but it's crucial to know your use case. When your project should work outside of your own home network, WiFi can be error prone as many networks are not friendly to unknown IoT devices.</p><p>As a result, you’re much better off looking at&nbsp;cellular connective technologies&nbsp;like LPWA or LTE-M1, which are low cost. use less energy and can be battery-powered.</p><h2>Don’t: Assume you know everything</h2><p>Even if it's not your first project anymore, and you have already gained some experienced, don’t fall into the trap that you don’t have anything to learn.</p><p>Electronics, hardware and IoT are complex and ever-evolving fields with strands of expertise that spread from circuit design to product interaction design and a hundred places in between.
Thus, it's almost impossible for one individual to be considered an hardware expert, and even difficult for a whole team.</p><p>Best, you actively seek out areas you are not confident in and build projects around it to improve.
However, don’t let this dishearten you. While you may not be experts in hardware development, you are an expert on your own project. Focus on how your vision and mission and the details will fall naturally into place over time.</p><hr></div></section></main></div></div>]]>
            </description>
            <link>https://100daysofhardware.com/blog/Dos-and-Donts-in-hardware-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625633</guid>
            <pubDate>Sun, 03 Jan 2021 21:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$0-$500k/Mo in Peanut Butter Sales Using TikTok Influencers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25625497">thread link</a>) | @247hustler
<br/>
January 3, 2021 | https://collabstr.com/blog/How-a-Small-Business-Used-TikTok-Influencers-to-Drive-500k-a-Month-in-Sales | <a href="https://web.archive.org/web/*/https://collabstr.com/blog/How-a-Small-Business-Used-TikTok-Influencers-to-Drive-500k-a-Month-in-Sales">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
            <p>A small business based out of South Dakota was able to turn an initial investment of $2,500 into over $500,000 a month in sales, all by leveraging the power of TikTok Influencers.</p>

<p>Craig Mount and Erika Peterson started their peanut butter company, Nerdy Nuts, out of their home in the summer of 2019. The idea stemmed from a feeling of uncertainty, when Petersonâ€™s go-to peanut butter plug shut down, thatâ€™s when Craig Mount purchased an Olde Tyme PN1 nut grinder for $870 on Ebay. The grinder was eventually forgotten about, until Peterson put it to use in the summer of 2019, and just like that, <a href="https://nerdynuts.com/">Nerdy Nuts</a> was born.</p>

<h2>Starting Small</h2>

<p>The couple started small, with two flavors, honey roasted and white chocolate. They would begin selling their new peanut butter at local farmers markets, and their booth would consistently bring in around $1,000 every Sunday, not bad for what they considered a â€œlow-stressâ€� side hustle.</p>

<p>Although their decision to start small was solely based off the fact that the couple was busy raising and child and working their day jobs, this turned out to be a massive factor that ultimately contributed to their success. Selling at the farmers market meant that they had a lot of face-to-face interactions with their customers, this allowed for them to hand out samples and gather real-time feedback on their product, â€œIt became an excellent testing ground â€“ and a perfect way for us to iterateâ€� said Mount. This real time feedback allowed for Nerdy Nuts to iterate at a rapid pace, something that wouldâ€™ve been more difficult if they decided to cast a wider net at the start.</p>

<h2>Branding &amp; Early Success</h2>

<p>After doing some market research, Mount decided that Nerdy Nuts should be branded as a flavorful and fun brand, considering that a majority of direct-to-consumer (D2C) peanut butter brands were more focused on advertising themselves as â€œhealthyâ€� or â€œketo-friendlyâ€�. </p>

<p>By deciding to go the â€œfunâ€� approach with their branding, Nerdy Nuts opened up the door to many more possibilities when it came to growth tactics and marketing, one example of this would be their US election candidate inspired flavors. In June of 2019, Nerdy Nuts decided to launch a specialty line of flavors based on the favorite foods of each US election candidate.</p>

<p><img src="https://d5ik1gor6xydq.cloudfront.net/blog/29/nerd_nuts_peanut_butter.jpg" alt="Nerdy Nuts used TikTok influencers to boost sales."></p><p>This tactic ultimately landed Nerdy Nuts their first taste of virality, when their story was picked up by Fox Business. Within 48 hours of their national talk show appearance, the company made $20,000 in sales. This early virality showed the small business that there was demand beyond the farmers markets that they were used to, so they transitioned their focus to becoming a D2C brand and ditched the farmers market/retail approach. This decision would not only give them a larger reach, but also be more cost-effective than running a storefront.</p>

<h2>TikTok Virality</h2>

<p>Months after their first taste of going viral, Nerdy Nuts was once again a viral sensation, but this time on TikTok. This was nothing compared to the virality they experienced with Fox News, it was even better, â€œthese influencers made the Fox News sales look like a jokeâ€� said Mount.</p>

<p>The growing company was experimenting with different marketing approaches when they decided to try out influencers on TikTok. Mount reached out to Ali Grace Morsell and Hailey Peters, both of which had around 500,000 followers on the platform at the time. He offered both influencers free product, â€œthey were just so flabbergasted that anyone would want to send them something for free.â€� <a href="https://thehustle.co/how-a-tiny-peanut-butter-company-grew-to-500k-per-month-in-sales/">said Mount</a>. Aside from offering them the product for free, Mount also promised the influencers a 10% cut of all sales.</p>

<p>I think itâ€™s safe to say that things went better than expected. The influencers posted about the product and racked up over a million views, which <a href="https://thehustle.co/how-a-tiny-peanut-butter-company-grew-to-500k-per-month-in-sales/">ultimately resulted in 5,947 sales</a>. The hashtag #nerdynuts currently has just under 2 million views alone, definitely a contributing factor to the $165.2k in sales during the month of July, not too shabby for a small peanut butter company out of South Dakota.</p>

<p><img src="https://d5ik1gor6xydq.cloudfront.net/blog/29/hashtag.jpg" alt="The Nerdy Nuts TikTok hashtag has over 2 million views."></p><p>Sales continued to increase until August of 2020, when the company topped over $500,000 in sales â€“ a 20x increase from just a few months prior.</p>

<h2>Breaking Down the Strategy</h2>

<p>Mount is well aware that not everyone can just recruit some influencers and expect to go viral on TikTok, heâ€™s seen other influencer collabs flop, so what made the Nerdy Nuts collab pop? Whether or not Mount is aware of it, there are some key decisions he made that allowed for the Nerdy Nuts collab to become a success.</p>

<h3>1. Choosing the Right Influencers</h3>

<p>The most obvious, yet crucial, aspect of running an influencer campaign is definitely <a href="https://collabstr.com/blog/Crucial-Steps-to-Identifying-The-Best-Instagram-Influencers-in-Your-Industry">choosing the right influencers</a> for the job. If you take a look at <a href="https://www.tiktok.com/@happyhealthyhailey?source=h5_m">Hailey</a> and <a href="https://www.tiktok.com/@aligracemorsell?source=h5_m">Aliâ€™s</a> TikTok pages, it wonâ€™t take much to realize that these are both middle-aged woman that have children and have food-focused pages, both ideal candidates for a brand like Nerdy Nuts.</p>

<p>By being very picky with the influencers you choose to represent your brand, not only are you getting in front of an audience that is actually interested in hearing about your product, but youâ€™re working with an influencer that would be highly likely to enjoy your product as well. Ali and Hailey both have a young family, so theyâ€™re most likely already cooking all the time, experimenting with new foods and packing their childrenâ€™s lunches. By choosing influencers that are highly relevant to your niche, you are ensuring you get someone that is just as passionate about your brand.</p>

<h3>2. Having a Good Product</h3>

<p>This one is not as obvious as the previous point, but it is still an important piece of the puzzle. We mentioned in our influencer marketing <a href="https://collabstr.com/blog/how-hismile-teeth-built-a-multi-million-dollar-brand-using-influencers">case study on HiSmile Teeth</a>, that the founders ensured they had a product that people actually wanted before sending it out to influencers. The bottom line is, if you have a product that nobody wants, then influencers are not going to want to promote it because at the end of the day they are consumers too.</p>

<p>By starting small and only selling at farmers markets, without knowing it, Nerdy Nuts was perfecting their product as much as possible to get it ready for the mass market. It was apparent that customers were loving the product, so by sending it out to influencers, the company was giving them a product that they most-likely would have enjoyed or even bought without the company asking.</p>

<p>While this point may not be directly correlated to the success of an influencer marketing campaign on TikTok, it most definitely plays an important role. Weâ€™ve seen cases of this before, <a href="https://collabstr.com/blog/The-Greatest-Example-of-Influencer-Marketing-On-Instagram-Fashion-Nova">such as with Fashion Nova</a>, where having a product that consumers genuinely loved ended up resulting in a viral feedback loop.</p>

<h3>3. Leave the Creativity to the Creators</h3>

<p>If you take a look at the content posted by Hailey and Ali as part of their original Nerdy Nuts campaign, you will notice that the content came off as very authentic and genuine, this is because the creativity was left to the creators.</p>

<p>When working with influencers on any platform, it is important to be aware of type of content they post and ensure that your vision aligns with theirs. The last thing you want to do is force an influencer to post a piece of content about your brand that comes off as disingenuous or scripted. Content coming from an influencer is not a TV or radio ad, so it shouldnâ€™t come off as one.</p>

<p>In order to the maximize your ROI, it is important to understand your boundaries when working with influencers.</p>

<p><b>Your responsibilities:</b></p>
<ul>
    <li>Sourcing and vetting the influencers.</li>
    <li>Getting the product to the influencer.</li>
    <li>Making influencer aware of campaign goals.</li>
</ul>

<p><b>Influencer responsibilities:</b></p>
<ul>
    <li>Formulating the creative strategy and creating the content.</li>
</ul>

<h2>Final Thoughts</h2>

<p>If youâ€™re reading this thinking to yourself â€œdamn, I should try using TikTok influencersâ€� youâ€™re in luck, because just as Nerdy Nuts discovered for themselves, TikTok influencers are highly underrated and undervalued at the time of writing this article. Influencers are also a topic we discuss in our <a href="https://collabstr.com/blog/The-Ultimate-Guide-to-TikTok-for-Brands-in-2020">ultimate guide to TikTok for brands in 2020</a>, we think they're an essential part to anybodies marketing strategy.</p>

<p>While 500,000 followers on TikTok may not be as valuable as 500,000 followers on Instagram, reaching nearly 2 million people organically just by gifting your product to an influencer is unheard of on any other platform aside form TikTok. </p>

<p>Nerdy Nuts is a prime example of how small direct-to-consumer businesses can leverage the power of influencer marketing. If youâ€™re looking to source some influencers for your campaign, and youâ€™re not sure where to start, check out <a href="https://collabstr.com/">Collabstr.</a></p>
        </div></div>]]>
            </description>
            <link>https://collabstr.com/blog/How-a-Small-Business-Used-TikTok-Influencers-to-Drive-500k-a-Month-in-Sales</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625497</guid>
            <pubDate>Sun, 03 Jan 2021 21:38:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obsidian Note Taking App Thoughts]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25625340">thread link</a>) | @ednico
<br/>
January 3, 2021 | https://www.thefortunelabs.com/knowledge/obsidian-note-taking-app/ | <a href="https://web.archive.org/web/*/https://www.thefortunelabs.com/knowledge/obsidian-note-taking-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Obsidian is described as “A second brain, for you, forever”. It is a desktop app (available for Windows, Mac and Linux) that acts as a knowledge base working on top of a local folder of plain text Markdown files.</p>



<p>The app is developed by the hugely talented Licat (Shida Li) and Silver (Erika Xu) who also brought us the delightful&nbsp;<a href="https://dynalist.io/" target="_blank" rel="noreferrer noopener">Dynalist</a>&nbsp;(an outliner note-taking tool similar to <a href="https://www.thefortunelabs.com/knowledge/logseq-the-note-taking-app/">Logseq</a>).</p>



<p>The app is offered as a free download, although sponsoring the devs is possible by upgrading your license through a one-time payment (USD 25+). By upgrading the license, we gain insider builds (early releases) and access to the exclusive dev channel on Discord.</p>



<h2>Why Obsidian?</h2>



<p>Your notes are saved locally on your machine in plain text markdown format, allowing you to easily transfer your notes to other apps or open them with Notepad, in essence, there is no vendor lock-in. You are in complete control of your notes and files and can use Google Drive, GitHub, Dropbox etc. to sync your notes between different machines.</p>



<p>Having control over my notes gives me peace of mind. I am free to do what I want with them, and even though with the Obsidian app I can use various functions (backlinks, graph view, etc.) I know that should the app disappear, the content is mine and will forever be mine.</p>



<p>The ease of using the app could not be more straightforward. Once downloaded and installed, you are greeted with a welcome screen similar to the one below:</p>



<div><figure><img loading="lazy" width="800" height="650" src="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=800%2C650&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?w=800&amp;ssl=1 800w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=300%2C244&amp;ssl=1 300w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=768%2C624&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?w=800&amp;ssl=1 800w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=300%2C244&amp;ssl=1 300w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=768%2C624&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-Welcome.png?resize=800%2C650&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>From here you can either create a new vault (notes repository) or open an existing vault. You can also open the “help vault” which includes several help files such as a formatting guide, and appearance customisation guides amongst other how-tos.</p>



<p>Once you have created / opened a vault, you can start taking notes at your heart’s content. You are free to choose to structure your notes the way you wish. You can have folders similar to traditional note-taking tools or go structure free and store all your notes in one main directory.</p>



<p>The beauty of creating links between your notes (with a simple [[“name”]] link) means that you should always be able to find what you are looking for and generate ideas (see <a href="https://www.thefortunelabs.com/personal-knowledge-management/">Personal Knowledge Management</a>) from your notes.</p>



<p>The app works in markdown format with the possibility of rendering the preview side by side, as shown below. You can also have more than one note open simultaneously by opening additional panes that can be infinitely split and resized. This is great if you want to cross-reference notes or create a work product from multiple notes.</p>



<div><figure><img loading="lazy" width="1024" height="543" src="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1024%2C543&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1024%2C543&amp;ssl=1 1024w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=300%2C159&amp;ssl=1 300w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=768%2C408&amp;ssl=1 768w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1536%2C815&amp;ssl=1 1536w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?w=1920&amp;ssl=1 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1024%2C543&amp;ssl=1 1024w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=300%2C159&amp;ssl=1 300w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=768%2C408&amp;ssl=1 768w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1536%2C815&amp;ssl=1 1536w, https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?w=1920&amp;ssl=1 1920w" data-lazy-src="https://i2.wp.com/www.thefortunelabs.com/wp-content/uploads/2021/01/Obs-edit-and-preview.png?resize=1024%2C543&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The markdown format may feel a little overwhelming at first, but things get easier after taking a few notes. The other benefit of having notes in markdown or rendered view is that it is easy to copy and paste the text into an online blogging platform or a Word document. For instance, I created this post in Obsidian and copied and pasted the text to WordPress and voila.</p>



<p>Having said the above, the lack of a What You See Is What You Get (WYSIWYG) type interface is a little annoying in my point of view. Sometimes the markdown format is confusing to read, or if you are in preview mode, you need to go back to edit mode to tweak the text. The good news is that this is on the <a href="https://trello.com/b/Psqfqp7I/obsidian-roadmap" target="_blank" rel="noreferrer noopener">roadmap</a>. Fingers crossed this comes soon.</p>



<p>In addition to the devs being hugely talented and ever-present to answer questions and chat on the Discord, the speed of development is phenomenal. Nearly every other week, we are presented with an update that includes new features and bug fixes.</p>



<h2>Features</h2>



<p>There are a significant amount of features available in Obsidian, so I thought to include below what I consider to be the main ones:</p>



<ul><li>Offline – <em>can access whether connected or not. Notes are stored offline and are yours</em></li><li>Backlinking – <em>easily see which pages link to the page</em></li><li>Random Note – <em>opens a random note which is useful for discovering old content</em></li><li>Daily Note – <em>create today’s note at the click of a button</em></li><li>Starred Notes – c<em>an star “favourite” notes for easy access</em></li><li>To-do list – <em>easily create to-do lists</em></li><li>Outline – <em>see the structure of your note and easily navigate to other sections by clicking</em></li><li>Search – <em>easily find what you are looking for</em></li><li>Graph View –&nbsp;v<em>isualise a page or your notes collection in a graph with many different filter / view options</em></li></ul>



<p>I have included below a brief video I did of the main features available in Obsidian.</p>



<figure><p>
<iframe title="Obsidian Introduction - A alternative Roam Research app for Notes / PKM / To Do / Journal" width="1200" height="675" src="https://www.youtube.com/embed/SJYHMCbqZbc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>In addition to the above main features, there are a couple of additional features which warrant a separate mention. These are:</p>



<h2>Publish</h2>



<p>A useful feature of Obsidian is Obsidian Publish where you can take your notes and convert them into an online digital garden / blog. The simplicity of doing this through “no code” means that there is no prior technical knowledge required. You only need to sign up (USD 8 per month per site (early-bird price)), choose a name, select which notes to publish and there you have it – your own personal online space.</p>



<p>The outcome can look something like this <a href="https://publish.obsidian.md/help/Index" target="_blank" rel="noreferrer noopener">example</a>. Developments are in the pipeline to allow for custom domains and other tweaks to make it more personal and improve the experience.</p>



<h2>Plugins</h2>



<p>With the ability to install and use third-party plugins and such a large community of users, many plugins are available to choose from to customise the app to suit your needs. The plugins are easily installed in the app (simply click install on the plugins browser page within Obsidian) and allow you to do things like:</p>



<h3>Mind Map</h3>



<p>View your note as a mind map. For example, activating the mind map view on this article results in the following diagram:</p>







<p>I find this plugin great as although you can see the note’s outline using the Obsidian outline feature, this allows you to visualise it differently.</p>



<h3>Calendar</h3>



<p>Enables a Calendar View to visualise and navigate between daily notes and easily create a daily note for a past, or future date.</p>







<h2>Areas of Improvement / Wish List</h2>



<p>There are a few areas of improvement which I feel would elevate the app even further. These improvements include:</p>



<ul><li>A What You See Is What You Get (WYSIWYG) type editor interface,</li><li>Mobile app to view / take notes on mobile,</li><li>Ability to see more information on notes in bulk (like date created, last modified, word count).</li></ul>



<h2>Conclusion</h2>



<p>With a few tweaks and the addition of a WYSIWYG interface, this app has the potential to become a top note taking app. Notes are stored locally, so are yours and forever yours. The features available in the app allow you to take notes, visualise your notes and generate ideas easily.</p>



<h2>More Information</h2>



<p>For more details be sure to check out:</p>



<ul><li><a href="https://obsidian.md/" target="_blank" rel="noreferrer noopener">Obsidian Website</a></li><li><a href="https://discord.gg/9CGnTWD" target="_blank" rel="noreferrer noopener">Discord</a></li></ul>



<p>Thank you for reading, and I hope you found this guide on Obsidian useful.</p>
		</div></div>]]>
            </description>
            <link>https://www.thefortunelabs.com/knowledge/obsidian-note-taking-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625340</guid>
            <pubDate>Sun, 03 Jan 2021 21:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being an Amazon Seller in 2020; Year in Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25625213">thread link</a>) | @molsonhart
<br/>
January 3, 2021 | https://www.molsonhart.com/blog/being-an-amazon-seller-in-2020-year-in-review | <a href="https://web.archive.org/web/*/https://www.molsonhart.com/blog/being-an-amazon-seller-in-2020-year-in-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5fd69ad7154d727871f4df3b" id="sections">
  
    <section data-test="page-section" data-section-theme="white-bold" data-section-id="5fd69ad7154d727871f4df41" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
  &quot;playbackSpeed&quot;: 0.5,
  &quot;filter&quot;: 1,
  &quot;filterStrength&quot;: 0,
  &quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--medium&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;white-bold&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5ff2092310ee9f592297a9a5"><div><div><div data-block-type="2" id="block-a38a3213ae5c216da82c"><div><p>I’m the founder and CEO of Viahart, an educational toy company. We did about $7.4 million in sales in 2020, mostly through e-commerce channels like Amazon and Walmart.com. This article is going to tell you what that was like and how things were different in 2020 than in 2019.</p><p>To give you some context, let me tell you a bit about our business. We design building toys, plush animals, and active play toys. We manufacture them in Cambodia, Vietnam, China, and the USA (not as much as we’d like), and then we sell them mainly online. We operate our own warehouse in Texas, and we also use Amazon’s network of fulfillment centers to get you our products.</p><p>Marketplace Breakdown of Sales in 2020</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_9884"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698700158-FL9H2YBM9PJQZCCB3JQW/ke17ZwdGBToddI8pDm48kPW2tKbN9zz-tLEnmW0K2IRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwAIQ1_cGwzFzAnJnJwZIMSNjYOvmIkhgi6XA01c8Ete8_nSTqR4Cw9c24S9jmf9_Y/2021-01-03_12-31-06.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698700158-FL9H2YBM9PJQZCCB3JQW/ke17ZwdGBToddI8pDm48kPW2tKbN9zz-tLEnmW0K2IRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwAIQ1_cGwzFzAnJnJwZIMSNjYOvmIkhgi6XA01c8Ete8_nSTqR4Cw9c24S9jmf9_Y/2021-01-03_12-31-06.png" data-image-dimensions="739x445" data-image-focal-point="0.5,0.5" alt="Our website (green) was 1.3%" data-load="false" data-image-id="5ff20d8b5de1995715ba6a2d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698700158-FL9H2YBM9PJQZCCB3JQW/ke17ZwdGBToddI8pDm48kPW2tKbN9zz-tLEnmW0K2IRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwAIQ1_cGwzFzAnJnJwZIMSNjYOvmIkhgi6XA01c8Ete8_nSTqR4Cw9c24S9jmf9_Y/2021-01-03_12-31-06.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Our website (green) was 1.3%</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_10174"><p>The main takeaway here is that Amazon accounted for 93.4% of our sales in 2020. For companies which sell on Amazon, this fairly typical. Two years ago, it was 98.1%. It’s risky to have so much of your sales concentrated in a single platform, but we’ve at least made progress. As <a href="https://medium.com/swlh/amazon-needs-a-competitor-and-walmart-aint-it-5997977b77b2">explained here</a>, it’s really challenging for companies like our own to not be dependent on Amazon for revenue.</p></div><div data-aspect-ratio="60.82036775106082" data-block-type="5" id="block-yui_3_17_2_1_1609697572806_11785"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698720038-5PYNPM6L35PCZFWFGSJQ/ke17ZwdGBToddI8pDm48kJxHft6rwxAAeJKBNf8LehRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyDkdC1gWWJJtIyTuFtPyzmGI_rZhmDqwObUyTfH7HuJtIsaBfVLmerqSzlBDO_kM4/2021-01-03_12-31-19.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698720038-5PYNPM6L35PCZFWFGSJQ/ke17ZwdGBToddI8pDm48kJxHft6rwxAAeJKBNf8LehRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyDkdC1gWWJJtIyTuFtPyzmGI_rZhmDqwObUyTfH7HuJtIsaBfVLmerqSzlBDO_kM4/2021-01-03_12-31-19.png" data-image-dimensions="707x430" data-image-focal-point="0.5,0.5" alt="Amazon is the most expensive e-commerce platform to sell on." data-load="false" data-image-id="5ff20d9f6ed34a73677cf247" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609698720038-5PYNPM6L35PCZFWFGSJQ/ke17ZwdGBToddI8pDm48kJxHft6rwxAAeJKBNf8LehRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyDkdC1gWWJJtIyTuFtPyzmGI_rZhmDqwObUyTfH7HuJtIsaBfVLmerqSzlBDO_kM4/2021-01-03_12-31-19.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Amazon is the most expensive e-commerce platform to sell on.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_14361"><div><p>The desire to get more sales off-Amazon doesn’t just come from the risk that they suspend our company from their platform. It’s also about the cost of selling there relative to other channels. If we sell $100 worth of product on <a href="https://www.amazon.com/viahart">our Amazon store</a>, on average, we get $48.25 back. At <a href="https://www.walmart.com/search?query=viahart&amp;redirect=false">our Walmart.com store</a>, we get $54.50 and on <a href="https://www.ebay.com/str/viahart">eBay store</a>, we get $57.50 back. On <a href="https://viahart.com/">our website (which could use a bath!)</a>, by virtue of not having a commission and by having much lower per unit shipping costs driven by larger orders (the more you ship, the cheaper it is to ship per unit), we get $83.10 back!</p><p>What’s driving those cost differences between the big marketplaces Amazon, eBay, and Walmart? It’s not shipping. It costs us roughly the same to ship out of our warehouse as it does for us to use Amazon’s FBA. eBay’s has slightly lower commissions, but the main reasons for the cost differences between these marketplaces are:</p><ol data-rte-list="default"><li><p>Refunds - It could be Amazon’s customer service or perhaps the customers themselves, but Amazon grants more refunds (2.6% of revenue) than either Walmart (1.9%) or famously seller friendly eBay (1%)</p></li><li><p>Storage - It costs a lot of money to store your products in Amazon’s fulfillment centers. We spent 2.4% of our Amazon revenue on storage. Amazon’s service was very spotty this year, but being able to reach 99.99% of America within 1-2 days is pretty awesome and this is a big driver of why Amazon owns 93.4% of our sales.</p></li><li><p>Advertising - Depending on what website A/B testing they’re doing, as many as 6 out of the top 7 results in an Amazon search can be advertising.  Even when a customer searches for your brand, if you want to be seen before your competition, you need to pay Amazon. We paid them 3.55% of our Amazon revenue in 2020. As less competitive marketplaces, we did not see the need to pay for advertising on eBay or Walmart. </p></li></ol></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_20928"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609700126295-ID13YPW1XHGJXB4WMDNL/ke17ZwdGBToddI8pDm48kL44xIHFFSDZxZ24lLalh2cUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnLWsplxJycS2ZC4W0pkg7tcvEJKVjhREkS1BB6uZyBzMW_T1ew2o-whLGJPhnYX5Nw/2021-01-03_12-52-32.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609700126295-ID13YPW1XHGJXB4WMDNL/ke17ZwdGBToddI8pDm48kL44xIHFFSDZxZ24lLalh2cUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnLWsplxJycS2ZC4W0pkg7tcvEJKVjhREkS1BB6uZyBzMW_T1ew2o-whLGJPhnYX5Nw/2021-01-03_12-52-32.png" data-image-dimensions="2500x930" data-image-focal-point="0.5,0.5" alt="On Amazon, on the left, the top four search results are advertising. Walmart, on the right has no advertising for the same search." data-load="false" data-image-id="5ff2131bfc8ee327dd3ad105" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609700126295-ID13YPW1XHGJXB4WMDNL/ke17ZwdGBToddI8pDm48kL44xIHFFSDZxZ24lLalh2cUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnLWsplxJycS2ZC4W0pkg7tcvEJKVjhREkS1BB6uZyBzMW_T1ew2o-whLGJPhnYX5Nw/2021-01-03_12-52-32.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>On Amazon, on the left, the top four search results are advertising. Walmart, on the right has no advertising for the same search.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_24926"><div><p>Based on what I’ve seen, the typical established Amazon seller has margins of around 15%. At that level of margin, moving your sales from Amazon to eBay would result in a 38% improvement in profits, which is huge. Shifting those sales from Amazon to one’s own website would represent a more than 3x increase in profits! Of course, if this were easy, we would have done it already. Unfortunately, getting traffic to one’s website is oftentimes a costly affair and it could be expected that a good portion of those profits would go to Facebook or Google.</p><p>Logistics and Covid-19 or Why It’s Better to Be Lucky Than Good</p><p>When the lockdowns first hit in the United States, it caused a massive shift in spending from brick-and-mortar to e-commerce. When government assistance arrived, it turbocharged online consumer spending even further. So for almost everyone in the e-commerce industry, 2020 was the best year they’ve ever had.</p><p>That said, it was a logistics nightmare, all year. And as a result, the rewards of this e-commerce boom were not spread evenly across all channels throughout the year.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_31343"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701198410-AKGQ5A0WWINFG0O6IDOT/ke17ZwdGBToddI8pDm48kB3tkWS0Ao_ok4cIpF98wuZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITeek5T9LqU69WVryce2g3v-scQCjyXyBsR0pk6Lmsgk/2021-01-03_13-12-12.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701198410-AKGQ5A0WWINFG0O6IDOT/ke17ZwdGBToddI8pDm48kB3tkWS0Ao_ok4cIpF98wuZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITeek5T9LqU69WVryce2g3v-scQCjyXyBsR0pk6Lmsgk/2021-01-03_13-12-12.png" data-image-dimensions="984x712" data-image-focal-point="0.5,0.5" alt="This is a graph of orders shipping out of our warehouse 2020 vs. 2019. Note that the scale on the left is different for each year. We shipped nearly 6x as much out of our warehouse in 2020." data-load="false" data-image-id="5ff2174c0db4f45ccbd2fdc7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701198410-AKGQ5A0WWINFG0O6IDOT/ke17ZwdGBToddI8pDm48kB3tkWS0Ao_ok4cIpF98wuZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITeek5T9LqU69WVryce2g3v-scQCjyXyBsR0pk6Lmsgk/2021-01-03_13-12-12.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This is a graph of orders shipping out of our warehouse 2020 vs. 2019. Note that the scale on the left is different for each year. We shipped nearly 6x as much out of our warehouse in 2020.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_33408"><p>On or around 03/18/2020, Amazon’s 2 day prime became 30 day prime, and as a result our shipping volume shifted away from their fulfillment centers to our warehouse. It seems also to have caused would-be Amazon customers to shift their purchasing volume to other websites, like Walmart.com, which for us increased its year over year sales 5.38x.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_39351"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701712712-MO83QCTY7GZMJY87CVKE/ke17ZwdGBToddI8pDm48kHLVhsXYfBa9CSB440eVOMFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIFy6oNF1lmTV_Lm-J07-QvTI4iHprRNMRNdKg_eAzyOQ/2021-01-03_13-21-25.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701712712-MO83QCTY7GZMJY87CVKE/ke17ZwdGBToddI8pDm48kHLVhsXYfBa9CSB440eVOMFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIFy6oNF1lmTV_Lm-J07-QvTI4iHprRNMRNdKg_eAzyOQ/2021-01-03_13-21-25.png" data-image-dimensions="934x472" data-image-focal-point="0.5,0.5" alt="We were lucky to see massive growth on Amazon.com for most of 2020." data-load="false" data-image-id="5ff2194f5abd827cad88383b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701712712-MO83QCTY7GZMJY87CVKE/ke17ZwdGBToddI8pDm48kHLVhsXYfBa9CSB440eVOMFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIFy6oNF1lmTV_Lm-J07-QvTI4iHprRNMRNdKg_eAzyOQ/2021-01-03_13-21-25.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>We were lucky to see massive growth on Amazon.com for most of 2020.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_41156"><p>From 01/01/2020 through 11/26/2020 our sales were up 75% on Amazon.com, but headaches for Amazon reappeared again around Black Friday to Cyber Monday weekend. From 11/27/2020 through 12/31/2020 sales were up only 20% over 2019’s same period. From 12/15/2020 through the end of the year, our sales in 2020 were lower than they were in 2019. For a year when e-commerce was up nearly double, that is indicative of a pretty serious problem.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_43482"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701811955-E5JQ6F2LHL3GHKRUOST8/ke17ZwdGBToddI8pDm48kCqonrkbXnaBLCoNarsHWIhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PImsxrl4HBSGamRZq5fo5n_Pece17mu9-8WhAaVOkVUPs/2021-01-03_13-23-16.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701811955-E5JQ6F2LHL3GHKRUOST8/ke17ZwdGBToddI8pDm48kCqonrkbXnaBLCoNarsHWIhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PImsxrl4HBSGamRZq5fo5n_Pece17mu9-8WhAaVOkVUPs/2021-01-03_13-23-16.png" data-image-dimensions="921x466" data-image-focal-point="0.5,0.5" alt="We were expecting a huge end of year, especially as toy sellers, but Christmas never came." data-load="false" data-image-id="5ff219b3461d8d43a3039798" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609701811955-E5JQ6F2LHL3GHKRUOST8/ke17ZwdGBToddI8pDm48kCqonrkbXnaBLCoNarsHWIhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PImsxrl4HBSGamRZq5fo5n_Pece17mu9-8WhAaVOkVUPs/2021-01-03_13-23-16.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>We were expecting a huge end of year, especially as toy sellers, but Christmas never came.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_45690"><div><p>Notice what happened on 12/15/2020. That’s when our units shipped fell below 2019’s. It’s unclear what happened, but I suspect that Amazon’s shipping from their warehouses was slower than in years past and as a result, people, no longer confident that they could receive their gifts in time for Christmas, reduced their purchasing on Amazon.com.</p><p>Review Inflation on Amazon.com</p><p>With Amazon accounting for 93.4% of our sales, it also accounts for 93.4% of our focus. In analyzing our year, one of things that I noticed was that some of our best sellers had lost traction. Items that we had been selling profitably since 2014, started to sell a lot less well relative to the competition. What happened? I suspect review inflation (not be confused with fake reviews, which is a separate issue).</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1609697572806_59949"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702362400-607YVOPRZMHBW0ROWA92/ke17ZwdGBToddI8pDm48kPCJRlIARzuaDg9l-H-2ddRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIrSbQbSn9pmBgrefiR7JyHGc6lcoPQJT0WUplZ_fQG8o/2021-01-03_13-32-15.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702362400-607YVOPRZMHBW0ROWA92/ke17ZwdGBToddI8pDm48kPCJRlIARzuaDg9l-H-2ddRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIrSbQbSn9pmBgrefiR7JyHGc6lcoPQJT0WUplZ_fQG8o/2021-01-03_13-32-15.png" data-image-dimensions="754x492" data-image-focal-point="0.5,0.5" alt="Click the stars to rate the item. You don’t even need to say anything about the product. Your star rating will appear. This makes reviewing easier." data-load="false" data-image-id="5ff21bd90493bd28274b95dd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702362400-607YVOPRZMHBW0ROWA92/ke17ZwdGBToddI8pDm48kPCJRlIARzuaDg9l-H-2ddRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIrSbQbSn9pmBgrefiR7JyHGc6lcoPQJT0WUplZ_fQG8o/2021-01-03_13-32-15.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Click the stars to rate the item. You don’t even need to say anything about the product. Your star rating will appear. This makes reviewing easier.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_64022"><p>One of the best ways to get someone to buy your product is social proof. One way to establish social proof is to have a lot of reviews for your item. Again, it’s not just the quality of the reviews, but the quantity that is important to customers trying to make a decision. Our older items had a lot of reviews, given that they had been sold since 2014. However, Amazon implemented a change. They’ve lowered the bar to reviewing, by offering the new rating feature.</p></div><div data-aspect-ratio="32.077625570776256" data-block-type="5" id="block-yui_3_17_2_1_1609697572806_52634"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702505514-E7H8UL7OG7JIO2QWW2V0/ke17ZwdGBToddI8pDm48kHjBiKdJRhws-x2c18DvE6gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCwi2nME2icKUeV0KMtYZBk1GgFIQqGLBrrVRPthNW8Gk8OSh1IsVkNwB0G8v0ekL/2021-01-03_13-29-19.png" data-image="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702505514-E7H8UL7OG7JIO2QWW2V0/ke17ZwdGBToddI8pDm48kHjBiKdJRhws-x2c18DvE6gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCwi2nME2icKUeV0KMtYZBk1GgFIQqGLBrrVRPthNW8Gk8OSh1IsVkNwB0G8v0ekL/2021-01-03_13-29-19.png" data-image-dimensions="1058x340" data-image-focal-point="0.5,0.5" alt="The stable light-green line is a graph of the number of reviews on of our best sellers had over the past couple of years." data-load="false" data-image-id="5ff21c69289de731b3e467b3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5fd69ac52cabbf38e7a2ca58/1609702505514-E7H8UL7OG7JIO2QWW2V0/ke17ZwdGBToddI8pDm48kHjBiKdJRhws-x2c18DvE6gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCwi2nME2icKUeV0KMtYZBk1GgFIQqGLBrrVRPthNW8Gk8OSh1IsVkNwB0G8v0ekL/2021-01-03_13-29-19.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>The stable light-green line is a graph of the number of reviews on of our best sellers had over the past couple of years.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1609697572806_66008"><div><p>You can see that reviews started to rise in 2020, which makes sense, given that there was a massive acceleration in sales and more sales means more reviews, but then in late July, things got really crazy. For us, this meant that newer competing products could “catch up” with our older established products, and as a result ours lost ground. It’s unclear why Amazon did this. Perhaps it was to combat their fake review problem, or perhaps it was to increase the social proof on their website, to make it look like a lot more purchases were happening on Amazon.com than Walmart.com.</p><p>Other Interesting E-commerce Observations</p><ol data-rte-list="default"><li><p>$4.6 million dollars worth of product were added to carts on our website in 2020. We finished the year with $97,000 in sales.</p></li><li><p>The conversion rate on our website was 0.7% in 2020. The conversion rate for a typical Amazon …</p></li></ol></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.molsonhart.com/blog/being-an-amazon-seller-in-2020-year-in-review">https://www.molsonhart.com/blog/being-an-amazon-seller-in-2020-year-in-review</a></em></p>]]>
            </description>
            <link>https://www.molsonhart.com/blog/being-an-amazon-seller-in-2020-year-in-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25625213</guid>
            <pubDate>Sun, 03 Jan 2021 21:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Look Up Unknown Phone Numbers Using Facebook Reset Password]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25624982">thread link</a>) | @punkspider
<br/>
January 3, 2021 | https://bytexd.com/look-up-unknown-phone-numbers/ | <a href="https://web.archive.org/web/*/https://bytexd.com/look-up-unknown-phone-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This tutorial is meant to help find clues as to who is calling you when you’re receiving calls from an unknown phone number (a number that is displayed on your phone’s screen, but you don’t recognize).</p><p>It’s quite short and simple, and I hope it helps, as it’s written with the intention of tracking whoever may be bothering or harassing you.</p><p>First I’d like to clear up the following meanings:</p><ul><li><strong>unknown phone number</strong> – a phone number that is displayed on my phone’s screen but I don’t have the caller’s information</li><li><strong>private phone number</strong> – a number that’s not displayed on my screen when someone is calling because the caller is withholding their number.</li></ul><p>I wanted to quickly clear this up because I suspect some interpret the term of <strong>unknown phone number</strong> as <strong>private phone number/call</strong>, and I don’t want to take up someone’s time with information that’s not useful to them.</p><h2 id="method-1-finding-the-facebook-account-associated-with-the-unknown-number">Method 1 – Finding the Facebook account associated with the unknown number</h2><p>With this method we’ll try to have Facebook show us the account associated with the phone number by trying to login with it and then clicking <code data-enlighter-language="raw">Forgot Password?</code>, which will lead us to the next page where Facebook shows us the associated account.</p><p>Please also keep in mind that I am not an expert in this area. Although I don’t think that investigating an unknown phone number in this manner is an offence in any way, I do think you should proceed at your own risk.</p><p>Another thing to keep in mind is that even though this method probably has a good chance of working, the number may not be associated with a Facebook account.</p><p>Also, since it will look like you’re trying to log in, Facebook will probably notify the user in some form. In my case I just got notified that I can enable one click login, for security reasons.</p><p><img width="593" height="532" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7.png.webp 593w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7-300x269.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7-380x341.png.webp 380w" data-sizes="(max-width: 593px) 100vw, 593px" alt="word image 7" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 12" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7.png.webp 593w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7-300x269.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-7-380x341.png.webp 380w"></p><p>I’m not certain of other cases, however. I’m assuming that there could be situations where Facebook informs the user that some one from <code data-enlighter-language="raw">{your_ip}</code>, <code data-enlighter-language="raw">{your_location}</code> using an <code data-enlighter-language="raw">{operating_system}</code> is trying to login.</p><p>So it may be prudent to use at least a VPN when doing this.</p><h3 id="quick-demo-video">Quick Demo [Video]</h3><h3 id="1-visit-facebook-while-logged-out">1. Visit Facebook while logged out</h3><p>You can just open a separate Incognito/Private window in your browser and go to <a href="https://facebook.com/" rel="noopener" data-wpel-link="exclude">https://facebook.com</a> and you’ll be greeted by the landing page with the login form.</p><p><img width="1272" height="700" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8.png.webp 1272w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-300x165.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-1024x564.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-768x423.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-380x209.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-800x440.png.webp 800w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-1160x638.png.webp 1160w" data-sizes="(max-width: 1272px) 100vw, 1272px" alt="word image 8" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 14" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8.png.webp 1272w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-300x165.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-1024x564.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-768x423.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-380x209.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-800x440.png.webp 800w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-8-1160x638.png.webp 1160w"></p><p>You can see that you can use the Email or Phone Number associated with an account to log in.</p><h3 id="2-fill-in-the-phone-number-and-a-random-password">2. Fill in the phone number and a random password</h3><p>Next, in the <strong>Email or Phone Number </strong>field, fill in the phone number you’re trying to trace. Remember to fill it along with the <a href="https://countrycode.org/" rel="noopener external" data-wpel-link="external" target="_blank">country code<span></span></a> of the phone number.</p><p>As a quick example, a phone number with a Germany country code looks like this <code data-enlighter-language="raw">+4915735987904</code>, where <strong>+49</strong> is the country code. Disclaimer – That phone number is from an online “receive free sms” site, and isn’t associated with a person.</p><p>In the <strong>Password </strong>field you can enter anything, such as simply <code data-enlighter-language="raw">test</code>, as we’re not actually trying to log in their account.</p><p>Click <strong>Log In</strong> and you should soon see Facebook letting you know that you’ve entered an incorrect password.</p><p><img width="1122" height="610" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9.png.webp 1122w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-300x163.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-1024x557.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-768x418.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-380x207.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-800x435.png.webp 800w" data-sizes="(max-width: 1122px) 100vw, 1122px" alt="word image 9" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 15" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9.png.webp 1122w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-300x163.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-1024x557.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-768x418.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-380x207.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-9-800x435.png.webp 800w"></p><h3 id="3-click-on-forgot-password">3. Click on Forgot Password</h3><p>Now click on the <code data-enlighter-language="raw">Forgot Password?</code> link.</p><p>We won’t be actually trying to reset the associated account password, in the case that the number really does have an associated account.</p><p>We just want to see the next page, where we should see the profile name and picture of the associated account, if there is one.</p><p>Facebook assumes that the person associated with that phone number tried to log in, and when we click <code data-enlighter-language="raw">Forgot Password?</code>, it shows the profile name, picture, obfuscated email address, and again the phone number, to confirm that is indeed the account whose password we want to reset.</p><p>I believe this is meant to be helpful to users, should they mistype their phone number, so Facebook makes sure they’re trying to reset their own passwords and not someone else’s.</p><h3 id="4-check-the-associated-account">4. Check the associated account</h3><p>That’s it. The page you’ll be seeing should look something like this.</p><p><img width="1122" height="693" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10.png.webp 1122w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-300x185.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-1024x632.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-768x474.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-380x235.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-800x494.png.webp 800w" data-sizes="(max-width: 1122px) 100vw, 1122px" alt="word image 10" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 16" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10.png.webp 1122w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-300x185.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-1024x632.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-768x474.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-380x235.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-10-800x494.png.webp 800w"></p><p>It is possible that the number calling you isn’t associated with a Facebook account, however. In which case it will probably show something like this:</p><p><img width="1254" height="510" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11.png" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11.png" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11.png 1254w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-300x122.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-1024x416.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-768x312.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-380x155.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-800x325.png.webp 800w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-1160x472.png.webp 1160w" data-sizes="(max-width: 1254px) 100vw, 1254px" alt="word image 11" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 17" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11.png 1254w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-300x122.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-1024x416.png.webp 1024w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-768x312.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-380x155.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-800x325.png.webp 800w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-11-1160x472.png.webp 1160w"></p><h2 id="method-2-check-their-whatsapp-profile-picture">Method 2 – Check their WhatsApp Profile Picture</h2><p>This method is probably used by many, but I haven’t found it featured in top results when trying to reverse look up phone numbers, I figure it’s worth mentioning.</p><h3 id="1-add-the-unknown-number-to-your-contact-list">1. Add the unknown number to your contact list</h3><p>I assume it doesn’t have a high success rate, but it’s pretty low effort and I think it’s worth a shot.</p><p>Just add the phone number to your contacts under whatever name you’d like, and then look up that contact in WhatsApp to check out if they have a profile pic.</p><p>That profile pic may be either a selfie or something that can help you identify if you know that person.</p><h3 id="2-reverse-image-search-the-profile-picture-video">2. Reverse Image Search the Profile Picture [Video]</h3><p>If you think the image is not very generic, and it’s likely they used it on other websites, such as social media, you can also perform a reverse image search using <a href="https://images.google.com/" rel="noopener external" data-wpel-link="external" target="_blank">https://images.google.com<span></span></a> and see if something comes up.</p><p>I know this is probably nothing new, but an additional thing you can do is limit the image search to a specific site.</p><p>For example if you search someone’s profile picture and get a good deal of results with all sorts of websites, and additional similar images that aren’t an exact match, you can limit the search to just one social media site, such as Twitter.</p><p>To do this you use the <code data-enlighter-language="raw">site:example.com</code> operator.</p><p>For example if we want to limit our reverse image search to Twitter, we’d search for the image first, and then replace the existing text in the Google search bar with <code data-enlighter-language="raw">site:twitter.com</code></p><h4 id="quick-demo-video-2">Quick Demo Video</h4><p>The steps are:</p><ol><li>Go to <a href="https://images.google.com/" rel="noopener external" data-wpel-link="external" target="_blank">https://images.google.com<span></span></a></li><li>Drag the image onto the search bar, or click the little camera icon and insert the URL to the image, or select <strong>Upload an image</strong> and then <strong>Choose File</strong> and then browse for the picture on your computer.</li><li>Next, Google will show us what matches were found.I’ll use this website’s social media profile pic as an example.<p>As you can see, Google sees our profile pic as being similar to many other images, and provides a list of many other websites associated with those images.</p><p><img width="665" height="683" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12.png.webp 665w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12-292x300.png.webp 292w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12-380x390.png.webp 380w" data-sizes="(max-width: 665px) 100vw, 665px" alt="word image 12" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 19" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12.png.webp 665w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12-292x300.png.webp 292w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-12-380x390.png.webp 380w"></p></li><li>Since we’re interested in mainly social media websites to have a good chance of identifying someone, we’ll filter the results by limiting the search only to Twitter, in this example.<p>You can, of course, try other social media websites popular in your region.</p><p>So in the search bar we’ll just remove the text, in this case <strong>digital alberta</strong>, and replace it with <code data-enlighter-language="raw">site:twitter.com</code>.</p><p>After the search is complete, we can see that even though it’s not the first result, we’ve still found the Twitter profile associated with the image.</p><p><img width="732" height="1270" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13.png.webp 732w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-173x300.png.webp 173w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-590x1024.png.webp 590w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-380x659.png.webp 380w" data-sizes="(max-width: 732px) 100vw, 732px" alt="word image 13" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 20" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13.png.webp 732w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-173x300.png.webp 173w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-590x1024.png.webp 590w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-13-380x659.png.webp 380w"></p></li></ol><p>I hope these methods come in useful or give you some peace of mind in some cases when you’re having issues with numbers you don’t recognize.</p><h2 id="other-methods">Other Methods</h2><p>Here I’ll just list other methods that could work. They rarely work for me, but I figure that since you’re already here, the info may be useful to you.</p><h3 id="1-looking-up-a-number-by-searching-it-in-the-facebook-search-bar">1. Looking up a number by searching it in the Facebook search bar</h3><p>I didn’t mention this one in the main part of the content because others have written about it, and I assume it’s quite well known.</p><p>Additionally, users have the option of restricting who can look them up by searching their associated phone number.</p><p><img width="919" height="390" src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14.png.webp" data-src="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14.png.webp" data-srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14.png.webp 919w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-300x127.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-768x326.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-380x161.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-800x339.png.webp 800w" data-sizes="(max-width: 919px) 100vw, 919px" alt="word image 14" title="Look Up Unknown Phone Numbers using Facebook Reset Password or WhatsApp 21" srcset="https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14.png.webp 919w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-300x127.png.webp 300w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-768x326.png.webp 768w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-380x161.png.webp 380w,https://y7p8z3w8.stackpathcdn.com/wp-content/uploads/2020/12/word-image-14-800x339.png.webp 800w"></p><h3 id="2-looking-up-a-number-using-other-popular-apps-or-websites">2. Looking up a number using other popular Apps or Websites</h3><p>While I’ve found success with apps or websites for reverse phone lookups, there are still some issues with such tools. For me at least.</p><ul><li>Some apps ask for access to your contact list on your phone, so they add more names to their database. I’m not comfortable with that.</li><li>Reverse Phone Lookup sites may either not work very well, or may only work with USA phone numbers</li></ul><h2 id="conclusion">Conclusion</h2><p>I hope this comes in useful for you and if you have anything at all to add or you encounter any issues, then I’d love to hear from you. Feel free to contact us via the comment section or our <a href="https://bytexd.com/contact/" data-wpel-link="internal">email/social media</a>.</p></div></div>]]>
            </description>
            <link>https://bytexd.com/look-up-unknown-phone-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624982</guid>
            <pubDate>Sun, 03 Jan 2021 20:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rust module system for Python users]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25624929">thread link</a>) | @arxanas
<br/>
January 3, 2021 | https://blog.waleedkhan.name/rust-modules-for-python-users/ | <a href="https://web.archive.org/web/*/https://blog.waleedkhan.name/rust-modules-for-python-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
    <p>Every time I go back to Rust, I have to figure out how the module system works again. Here are some of my notes comparing it to Python’s module system.</p>

<p>These notes are for Rust 2018.</p>

<ul id="markdown-toc">
  <li><a href="#crates" id="markdown-toc-crates">Crates</a></li>
  <li><a href="#packages" id="markdown-toc-packages">Packages</a></li>
  <li><a href="#file-layout" id="markdown-toc-file-layout">File layout</a>    <ul>
      <li><a href="#crate-roots" id="markdown-toc-crate-roots">Crate roots</a></li>
      <li><a href="#module-lookups" id="markdown-toc-module-lookups">Module lookups</a></li>
      <li><a href="#nested-modules" id="markdown-toc-nested-modules">Nested modules</a></li>
    </ul>
  </li>
</ul>

<h3 id="crates">Crates</h3>

<p>A <strong>crate</strong> is a build target in Rust. A crate can either be a library or a binary. It can be built with <code>cargo build</code>.</p>

<p>In Python, libraries are called “packages”. Binaries are an entirely heterogenous concept, typically installed by configuring <a href="https://packaging.python.org/specifications/entry-points/">entry points</a>. Such a binary doesn’t even need to be Python code (for example, it can be a shell script instead).</p>

<h3 id="packages">Packages</h3>

<p>A <strong>package</strong> in Rust consists of up to one library crate and any number of binary crates. (It’s required that there be at least one library or binary crate.)</p>

<p>In Python, a single “distribution package” (i.e. one that you can <code>pip install</code>) can contain multiple “import packages” (i.e. one that you can <code>import</code>), while Rust allows at most one import package per distribution package.</p>

<h3 id="file-layout">File layout</h3>

<h4 id="crate-roots">Crate roots</h4>

<p>Python places <code>__init__.py</code> at the root of a package to indicate that it’s importable as a package. Similarly, Rust conventionally puts <code>lib.rs</code> at the root of a crate as the library <strong>crate root</strong>. (Unlike Python, the name can be re-configured, but <code>lib.rs</code> is the default.)</p>

<p>In Python, <code>__main__.py</code> corresponds to the main entry point for the module when run with <code>python -m</code>. Rust conventionally puts <code>main.rs</code> as a binary crate root. (This can also be renamed, which is probably desirable if you have more than one binary.)</p>

<h4 id="module-lookups">Module lookups</h4>

<p>In Python, all modules are available by importing them via their filesystem path name. For example, <code>import foo.bar</code> first looks for a <code>foo/</code> directory on the <code>PYTHONPATH</code>. Then it looks for a <code>bar/</code> package or a <code>bar.py</code> module underneath the <code>foo/</code> directory.</p>

<p>In Rust, modules also correspond to their paths on the filesystem (by default; <a href="https://doc.rust-lang.org/reference/items/modules.html#the-path-attribute">you can use the <code>path</code> attribute</a> to change this behavior). However, they are not immediately <code>use</code>-able just because the corresponding file is present! They must be declared with a <code>mod foo;</code> declaration in the crate root file (e.g. <code>lib.rs</code>).</p>

<h4 id="nested-modules">Nested modules</h4>

<p>In Python, a nested module <code>foo.bar</code> is implemented either by <code>foo/bar.py</code> or <code>foo/bar/__init__.py</code>. You can’t use both. If you want to have sub-modules of <code>foo.bar</code>, you’ll place additional modules or packages under <code>foo/bar/</code>.</p>

<p>A statement like <code>from foo.bar import qux</code> could either be importing a symbol declared in <code>foo/bar/__init__.py</code> or the module <code>foo/bar/qux.py</code>. Some developers choose to explicitly re-export the public interface of <code>bar</code> in <code>__init__.py</code> for clarity, and prefix sub-modules with underscores (e.g. <code>_qux.py</code> instead of <code>qux.py</code>).</p>

<p>In Rust, you use <code>foo/bar.rs</code> to declare members of the namespace <code>foo::bar</code>. If you also want to have sub-namespaces of bar (e.g. <code>foo::bar::qux</code>), then you additionally create the <code>bar/</code> directory alongside <code>bar.rs</code>. To access a sub-namespace <code>qux</code> inside <code>bar.rs</code>, the line <code>mod qux;</code> must be added to <code>bar.rs</code>. (This is similar to how we have to add <code>mod foo;</code> at the top-level <code>lib.rs</code>.)</p>

<p>To re-export the namespace and make it available to all users outside of <code>bar</code>, it should be changed to <code>pub mod qux;</code>.</p>

<p>The main take-away is that Rust requires the explicit re-exporting of nested modules using <code>mod</code> at each step of the hierarchy, while Python does not.</p>

  </div>

</article>












      </div>
    </div></div>]]>
            </description>
            <link>https://blog.waleedkhan.name/rust-modules-for-python-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624929</guid>
            <pubDate>Sun, 03 Jan 2021 20:28:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned from a Year of Haskell]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624905">thread link</a>) | @wespiser_2018
<br/>
January 3, 2021 | https://wespiser.com/posts/2021-01-03-Lessons-Learned-From-A-Year-Of-Haskell.html | <a href="https://web.archive.org/web/*/https://wespiser.com/posts/2021-01-03-Lessons-Learned-From-A-Year-Of-Haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="content">
            
            <p>
    Posted on January  3, 2021
    
</p>


<ul>
<li>I spent the year as a software engineer writing Haskell, and switched to remote work during the pandemic with everyone else.<br>
</li>
<li>Wrote a lot of code, and focused on Haskell as a language for software engineering.<br>
</li>
<li>Completed 3 courses from Georgia Tech on bayesian statistics, computer networking, and embedded compilers, as part of a masters program I’ll finish in 2021.<br>
</li>
<li>Wrote more Haskell code this year than probably all other years combined, and made it through 2020 feeling pretty good about things. I’ll mark that in the win column!</li>
</ul>

<p>I’m writing this post as a collection of my thoughts on the last year, and a reflection on the major things I’ve learned.<br>
The majority of my Haskell experience is in the form of writing code for web servers that talk to databases serve up APIs, although I am very interested in compilers and language research!</p>
<h2 id="outline">Outline</h2>
<ul>
<li>On The Practice Of Software Engineering</li>
<li>Haskell Observations</li>
<li>Musings On Type Level Programming</li>
<li>Build Systems</li>
<li>The Year In Readings</li>
<li>Summary</li>
</ul>
<h2 id="on-the-practice-of-software-engineering">On The Practice of Software Engineering</h2>
<p>Software engineering is about understanding the trade offs (performance, latency, domain modelling, et cetera), and implementing a solution that solves a problem with a solution space of development time, cost, and quality. Not every project you engage in will focus on code quality, but working at a company where some projects can focus on quality is a tremendous joy and enriching experience, and am very thankful to my teammates who made this possible!</p>
<p>One of the best exercises I had this year was going through my PRs and consolidating all the comments by theme, which taught me as much about my own code as what other people think about code in general.</p>
<p>An important perspective when writing code, is understanding how that software will exist through time, what demands will be placed on it, and how the fundamental assumptions will inevitably change. A big lesson for me this year is learning that a system can start out well, but through product mis-alignment, tight time constraints, and feature expansion, it can become an irreplaceable web of sadness littered through your code base too costly to remove!</p>
<p>On a psychological note, through trial and error I realized I only have so many “high performance” hours in a week where you can be sustainably productive without lowering the quality of the hours you work. Some corporations have even found workers are even more productive with 3 day weeks versus 5! <a href="https://web.archive.org/web/20191105011855/http://nypost.com/2019/11/04/microsoft-japans-3-day-weekends-boost-productivity-by-40/">source</a> I’m not saying we should go that far, but when you’re home all the time coding in a pandemic, balance is key to staying fresh and effective!</p>
<h2 id="haskell-observations">Haskell Observations</h2>
<p>Contributing to ghc is HARD!<br>
It’s a complex and old code base, and although there is plenty of documentation, it takes a ton of work to be able to understand ghc well enough to contribute at the level needed to fix bugs and implement new features. That said, there is a ton of documentation work that still needs to be done, and is pretty beginner friendly work!</p>
<p>Use Template Haskell to generate code only as a last resort! The available alternatives, including deriving instances, have grown rich with options over the past few years, and these alternatives are less likely to eat up your compiler time or make cross-compilation an herculean task! Quasiquoters are a notable exception to this, as are inserting filenames/git commits at compile time, the key is to use it sparingly!</p>
<p><a href="https://haskell.pl-a.net/">Haskell Planetarium</a> as a link aggregation has enough content to be readable everyday, and along with <a href="https://haskellweekly.news/">Haskell Weekly</a> are my <code>goto</code> sources of Haskell related content.</p>
<p>Next, and pretty obviously, <strong>you can use Haskell to deliver value in business</strong>. This is already established, but watching different teams write similar web services at their direction showed me that there is a lot of variety within the ecosystem.</p>
<p>Based on my experience, answers the following questions will vary from project to project, and asking them will get you oriented in a new project pretty quickly:</p>
<ul>
<li>Which prelude is being used?<br>
</li>
<li>How are effects handled?<br>
</li>
<li>How are API routes defined?<br>
</li>
<li>How do you interact with the database and manage a transaction session?<br>
</li>
<li>How do you write an sql query?<br>
</li>
<li>What’s the nature of the “expression problem” for internal data types?<br>
</li>
<li>What is the strategy for manipulating internal objects, i.e.&nbsp;lens/generic lens?<br>
</li>
<li>How are log messages generated?<br>
</li>
<li>What’s the testing strategy, is a fuzziness generator used?<br>
</li>
<li>How do you run the tests locally, given the architecture?</li>
</ul>
<p>By the <a href="https://en.wikipedia.org/wiki/Expression_problem">Expression Problem</a> I mean which typeclasses are needed to be derived or defined, like <code>ToJSON</code> or serialization. I’d like to add that the overwhelming majority of effects I’ve seen have been handled using <a href="https://hackage.haskell.org/package/mtl">mtl</a> and/or <code>IO</code>, but we appear to be close on extensible effects, and the work done on <a href="https://github.com/hasura/eff">eff</a> looks promising!</p>
<h2 id="musings-on-type-level-programming">Musings On Type Level Programming</h2>
<p>A theme for this year for me was exploring the intersection between type level programming and good software engineering practices. It’s one thing to know Haskell, it’s another to write beautiful code that’s as easy to understand as it is to maintain. As a prior, my stance on new, complex Haskell features is to “write junior code”. However, given a sufficiently experienced team familiar with type level programming, the trade-offs of the features themselves can be evaluated per se…</p>
<h3 id="haskell-type-level-solutions-worth-their-weight">Haskell Type Level Solutions Worth Their Weight</h3>
<ul>
<li><a href="https://hackage.haskell.org/package/squeal-postgresql">squeal</a>, takes a while to learn, but with generated schemas helping write some code, a deep embedding tied to the schema is very maintainable. A key aspect of getting this solution to work is to have a repeatable way to generate the same schema that’s used in production. Ours is (<a href="https://github.com/mwotton/squealgen">squealgen</a>), which works great!<br>
</li>
<li><a href="https://hackage.haskell.org/package/generic-lens">generic-lens</a>. For a long time, I avoided lenses, but with <code>DuplicateRecordFields</code> and <code>OverloadedLabels</code> <code>generic-lens</code> provides some great utilities beyond lens/prism for manipulating structures that I’ve come to rely on.<br>
</li>
<li><a href="https://hackage.haskell.org/package/servant">servant</a> great for defining routes for clients/servers, and even the streaming stuff can work!<br>
</li>
<li><a href="https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/deriving_via.html">DerivingVia</a>, very useful way to extend newtypes and generic deriving, and gives you a way to write a lot of maintainable code in a few short lines.</li>
</ul>
<h3 id="haskell-type-level-programming-ideas-ive-unsuccessfully-tried-to-apply-but-am-holding-out-hope-for">Haskell Type Level programming ideas I’ve unsuccessfully tried to apply, but am holding out hope for…</h3>
<ul>
<li><strong>Type level witnesses</strong>: although they did work for a specific problem, getting kind constraints to play nicely with associated libraries turned out harder than I imagined, and I’m not 100% convinced the added complexity if worth the effort.<br>
</li>
<li><strong>GADTs</strong>: Know the type for each individual data constructor? Sounds good! I just haven’t had a problem where this is exactly what I’ve needed.<br>
</li>
<li><strong>Existensial Types</strong>: There is a bug that prevents generic deriving from “just working” reasonably in the last situation I tried them, and I’d rather just use an alternative approach, like a smart constructor, over writing my own generic instance. <a href="https://gitlab.haskell.org/ghc/ghc/-/issues/10514">GHC bug report</a>.</li>
</ul>
<h2 id="build-systems">Build Systems</h2>
<p>I’m not sure what else to say here, other than build systems in Haskell leave something to be desired!<br>
Stack works, but doesn’t cache well, and there’s the dreaded <code>flat namespace error</code> and related errors that sometimes are most easily fixed by manually removing the offending library, or worst case removing your <code>.stack</code> directories.<br>
Alternatively, Nix is an efficient and robust build system, but is really complicated, and takes a non-trivial amount of time to learn and set up if you’re going to use that for your CI build system. I want to learn Nix and use it for personal projects, it’s just a question of priorities, and figuring out how to get it to work with <code>ghcid</code>.<br>
In 2021, I should really try <code>cabal</code> :)</p>
<h3 id="my-development-environment">My development environment</h3>
<p>The Haskell development environment has really improved over the last few years, and here’s the setup I eventually settled on:</p>
<ul>
<li>iTerm2 on MacOS, using <code>tmux</code> as a window/panel manager.<br>
</li>
<li><code>neovim</code> as my version of <code>vim</code> for writing code.<br>
</li>
<li><code>hasktags</code> to “jump to definition” with <code>vim</code> shortcuts. Not perfect with <code>OverladedLabels</code> within a large code base, but good enough!<br>
</li>
<li><code>hoogle</code> command line utility to search for polymorphic function types or package sources.<br>
</li>
<li><a href="https://hackage.haskell.org/">Hackage</a> online to browse docs. (press ‘s’ on a package page to open a search prompt).<br>
</li>
<li>A variety of tools using <code>fzf</code> for searching within and for files, and browsing git diffs and commits.<br>
</li>
<li><a href="https://hackage-search.serokell.io/">Serokell’s Regex Hackage Search</a> which just came out, but something I think could be very useful for arbitrary searches over Hackage!<br>
</li>
<li><code>ghcid</code> is pretty amazing, and I’m not sure how I wrote Haskell without it! It gives fast incremental recompilation, and can be configured to run a test suite or bash command on completion.</li>
</ul>
<p>The haskell development environment is getting better all the time, and although I’ve set up Haskell Language Server a few times for small side projects, I haven’t taken the time to try it on a larger code base, despite the extremely helpful project devs!</p>
<p>My ideal tool, would be something that consolidates the different search interfaces (hackage, regex on hackage, local search, jump to definition, et cetera), to create a utility that jumps to definition or docs given what’s in scope for a given module or even project.</p>
<h2 id="the-year-in-readings">The Year In Readings</h2>
<p>Here’s a sampling of the “essential” articles I came across in 2020.</p>
<ul>
<li><a href="https://www.stephendiehl.com/posts/decade.html">Haskell for a New Decade</a> a good reading to start off the year!<br>
</li>
<li><a href="https://tech.channable.com/posts/2020-04-07-lessons-in-managing-haskell-memory.html">Lessons in Managing Haskell Memory</a> is a really interesting article about speeding up code execution time using “compact regions”. Memory management in strict, typed functional programming languages is a pretty wide open area, “compact regions” are a worthy approach!<br>
</li>
<li><a href="https://blog.josephmorag.com/posts/mcc0/">Micro C</a> A Micro C compiler written in Haskell. A nice little compiler project!<br>
</li>
<li><a href="https://serokell.io/blog/haskell-type-level-witness">Type Witnesses In Haskell</a> Is a great write up by Sandeep Chandrika explaining type witnesses, and how to use them to ensure illegal state are not representable!<br>
</li>
<li><a href="http://takenobu-hs.github.io/downloads/haskell_ghc_illustrated.pdf">GHC illustrated for hardware persons</a> is an architectural diagram of the ghc backend, and includes information on exactly how ghc is able to run a lazy functional language on stock …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wespiser.com/posts/2021-01-03-Lessons-Learned-From-A-Year-Of-Haskell.html">https://wespiser.com/posts/2021-01-03-Lessons-Learned-From-A-Year-Of-Haskell.html</a></em></p>]]>
            </description>
            <link>https://wespiser.com/posts/2021-01-03-Lessons-Learned-From-A-Year-Of-Haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624905</guid>
            <pubDate>Sun, 03 Jan 2021 20:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Platonic Solids in C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624897">thread link</a>) | @dsieger
<br/>
January 3, 2021 | https://www.danielsieger.com/blog/2021/01/03/generating-platonic-solids.html | <a href="https://web.archive.org/web/*/https://www.danielsieger.com/blog/2021/01/03/generating-platonic-solids.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p><span>03 Jan 2021</span></p><p><img src="https://www.danielsieger.com/images/generating_platonics_teaser.png" alt="Platonic solids in front of blurry C++ code"></p> <p>This is a short tutorial on generating polygonal surface meshes of the five <a href="https://en.wikipedia.org/wiki/Platonic_solid">Platonic solids</a> in C++. You can learn a few basics of working with meshes along the way. I’m using the <a href="https://www.pmp-library.org/">Polygon Mesh Processing Library</a> for implementation. The code is straightforward, so you can easily adapt it to another data structure or programming language.</p> <h2 id="motivation">Motivation</h2> <p>My primary motivation for this article is very simple:</p> <ul> <li>You want to generate a mesh of a Platonic solid</li> <li>Here is some straightforward C++ code to do so</li> </ul> <p>Now why exactly would this be interesting? Well, having the possibility to generate a mesh with known properties is useful in many situations. Here are three examples:</p> <ol> <li>Generating example data for an algorithm you are developing</li> <li>Generating shapes in your application without shipping meshes</li> <li><a href="https://www.danielsieger.com/blog/2018/09/11/unit-testing-geometric-algorithms.html">Unit testing geometric algorithms</a></li> </ol> <p>Generating simple shapes also is a canonical example for doing your first steps using a mesh library, a sort of “Hello, mesh!”. If you are new to working with meshes, this is a great starting point to get familiar with the basics.</p> <h2 id="bootstrapping">Bootstrapping</h2> <p>I’m using the <a href="https://www.pmp-library.org/">Polygon Mesh Processing Library</a> (PMP) as mesh data structure in this tutorial. However, any modern mesh data structure providing basic functions such as adding vertices and polygonal faces should be sufficient for this tutorial. Skip this section if you’re using another data structure.</p> <p>If you want to quickly visualize the resulting meshes, I recommend downloading and compiling the PMP <a href="https://github.com/pmp-library/pmp-template">project template</a>, which contains a ready-to-use mesh viewer. Just clone the repository:</p> <div><div><pre><code>git clone <span>--recursive</span> https://github.com/pmp-library/pmp-template.git
</code></pre></div></div> <p>Build the project:</p> <div><div><pre><code><span>cd </span>pmp-template <span>&amp;&amp;</span> <span>mkdir </span>build <span>&amp;&amp;</span> <span>cd </span>build <span>&amp;&amp;</span> cmake .. <span>&amp;&amp;</span> make
</code></pre></div></div> <p>Run the viewer:</p>  <p>During this tutorial, I’ll define a few functions to generate the different shapes. It’s easiest to add those functions to the <code>MyViewer</code> class and call them on a keyboard shortcut. Here’s how to do this:</p> <ul> <li>Find the <code>MyViewer::keyboard()</code> function in your favorite IDE</li> <li>Add a new case label such as <code>GLFW_KEY_G</code> to the <code>switch</code> statement</li> <li>Add the function you want to call</li> <li>Add a call to <code>update_mesh()</code> to update the viewer</li> <li>Re-compile and run <code>./myviewer</code>
</li> </ul> <p>That’s all you need to get started, so let’s go!</p> <h2 id="the-five-platonic-solids">The Five Platonic Solids</h2> <p>The Platonic solids are a set of well-known convex <a href="https://en.wikipedia.org/wiki/Polyhedron">polyhedra</a> with particular properties, e.g., all faces are of the same type, the faces are regular (all angles and sides are the same), and the same number of faces are incident to each vertex. In 3D space, there are only five polyhedra satisfying these criteria: The tetrahedron, hexahedron, octahedron, dodecahedron, and the icosahedron. Here they are, from left to right:</p> <p><img src="https://www.danielsieger.com/images/platonic_solids.png" alt="The five Platonic solids"></p> <p>The Platonic solids date back to the time of the ancient Greeks, if not earlier. They played a key role in Plato’s philosophy, hence the name. If you are interested, see the Wikipedia <a href="https://en.wikipedia.org/wiki/Platonic_solid">article</a> for more information.</p> <h2 id="the-tetrahedron">The Tetrahedron</h2> <p>Let’s begin with the simplest Platonic solid, the tetrahedron. Four vertices and four triangular faces, that’s all. Here’s the code:</p> <div><div><pre><code><span>SurfaceMesh</span> <span>tetrahedron</span><span>()</span>
<span>{</span>
  <span>SurfaceMesh</span> <span>mesh</span><span>;</span>

  <span>// choose coordinates on the unit sphere</span>
  <span>float</span> <span>a</span> <span>=</span> <span>1.0</span><span>f</span> <span>/</span> <span>3.0</span><span>f</span><span>;</span>
  <span>float</span> <span>b</span> <span>=</span> <span>sqrt</span><span>(</span><span>8.0</span><span>f</span> <span>/</span> <span>9.0</span><span>f</span><span>);</span>
  <span>float</span> <span>c</span> <span>=</span> <span>sqrt</span><span>(</span><span>2.0</span><span>f</span> <span>/</span> <span>9.0</span><span>f</span><span>);</span>
  <span>float</span> <span>d</span> <span>=</span> <span>sqrt</span><span>(</span><span>2.0</span><span>f</span> <span>/</span> <span>3.0</span><span>f</span><span>);</span>

  <span>// add the 4 vertices</span>
  <span>auto</span> <span>v0</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>));</span>
  <span>auto</span> <span>v1</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>c</span><span>,</span> <span>d</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v2</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>c</span><span>,</span> <span>-</span><span>d</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v3</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>b</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>a</span><span>));</span>

  <span>// add the 4 faces</span>
  <span>mesh</span><span>.</span><span>add_triangle</span><span>(</span><span>v0</span><span>,</span> <span>v1</span><span>,</span> <span>v2</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_triangle</span><span>(</span><span>v0</span><span>,</span> <span>v2</span><span>,</span> <span>v3</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_triangle</span><span>(</span><span>v0</span><span>,</span> <span>v3</span><span>,</span> <span>v1</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_triangle</span><span>(</span><span>v3</span><span>,</span> <span>v2</span><span>,</span> <span>v1</span><span>);</span>

  <span>return</span> <span>mesh</span><span>;</span>
<span>}</span>
</code></pre></div></div> <h2 id="the-hexahedron">The Hexahedron</h2> <p>The code for the hexahedron isn’t that much more complicated. You just have to add a few more points and faces: Eight vertices, six quadrilateral faces:</p> <div><div><pre><code><span>SurfaceMesh</span> <span>hexahedron</span><span>()</span>
<span>{</span>
  <span>SurfaceMesh</span> <span>mesh</span><span>;</span>

  <span>// choose coordinates on the unit sphere</span>
  <span>float</span> <span>a</span> <span>=</span> <span>1.0</span><span>f</span> <span>/</span> <span>sqrt</span><span>(</span><span>3.0</span><span>f</span><span>);</span>

  <span>// add the 8 vertices</span>
  <span>auto</span> <span>v0</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v1</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v2</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>a</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v3</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>a</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v4</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>a</span><span>));</span>
  <span>auto</span> <span>v5</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>a</span><span>));</span>
  <span>auto</span> <span>v6</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>a</span><span>,</span> <span>a</span><span>));</span>
  <span>auto</span> <span>v7</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>a</span><span>,</span> <span>a</span><span>));</span>

  <span>// add the 6 faces</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v3</span><span>,</span> <span>v2</span><span>,</span> <span>v1</span><span>,</span> <span>v0</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v2</span><span>,</span> <span>v6</span><span>,</span> <span>v5</span><span>,</span> <span>v1</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v5</span><span>,</span> <span>v6</span><span>,</span> <span>v7</span><span>,</span> <span>v4</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v0</span><span>,</span> <span>v4</span><span>,</span> <span>v7</span><span>,</span> <span>v3</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v3</span><span>,</span> <span>v7</span><span>,</span> <span>v6</span><span>,</span> <span>v2</span><span>);</span>
  <span>mesh</span><span>.</span><span>add_quad</span><span>(</span><span>v1</span><span>,</span> <span>v5</span><span>,</span> <span>v4</span><span>,</span> <span>v0</span><span>);</span>

  <span>return</span> <span>mesh</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>The next shape in the series is the octahedron. You could do exactly the same as above and manually specify all vertex coordinates and face indices. However, this becomes tedious rather quickly.</p> <p>Instead, you can do something slightly more intelligent and exploit the fact that every convex polyhedron has a <a href="https://en.wikipedia.org/wiki/Dual_polyhedron">dual polyhedron</a>.</p> <h2 id="interlude-computing-the-dual-polyhedron">Interlude: Computing the Dual Polyhedron</h2> <p>The dual polyhedron is a bit like a twin—or maybe it is more like <a href="https://en.wikipedia.org/wiki/Strange_Case_of_Dr_Jekyll_and_Mr_Hyde">Dr. Jekyll and Mr. Hyde</a>? I’ll leave it up to you. Here’s the slightly more formal definition: For each convex polyhedron, there is a <em>dual polyhedron</em> with a face for each vertex and a vertex for each face of the original polyhedron. Here’s an illustration of the concept of duality:</p> <p><img src="https://www.danielsieger.com/images/dual_w_zoom.png" alt="Illustration of the concept of a dual mesh."></p> <p>The original mesh is a triangle mesh of a sphere, edges shown in dark gray. The edges of the dual mesh are highlighted in teal. Each vertex of the dual mesh corresponds to a face in the original mesh; each vertex of the original mesh corresponds to a polygonal face in the dual mesh. Note that computing the dual also is a practical way to convert a triangle mesh into an general polygon mesh. Here is how you can compute the dual:</p> <div><div><pre><code><span>void</span> <span>dual</span><span>(</span><span>SurfaceMesh</span><span>&amp;</span> <span>mesh</span><span>)</span>
<span>{</span>
  <span>// the new dual mesh</span>
  <span>SurfaceMesh</span> <span>tmp</span><span>;</span>

  <span>// a property to remember new vertices per face</span>
  <span>auto</span> <span>fvertex</span> <span>=</span> <span>mesh</span><span>.</span><span>add_face_property</span><span>&lt;</span><span>Vertex</span><span>&gt;</span><span>(</span><span>"f:vertex"</span><span>);</span>

  <span>// for each face add the centroid to the dual mesh</span>
  <span>for</span> <span>(</span><span>auto</span> <span>f</span> <span>:</span> <span>mesh</span><span>.</span><span>faces</span><span>())</span>
    <span>fvertex</span><span>[</span><span>f</span><span>]</span> <span>=</span> <span>tmp</span><span>.</span><span>add_vertex</span><span>(</span><span>centroid</span><span>(</span><span>mesh</span><span>,</span> <span>f</span><span>));</span>

  <span>// add new face for each vertex</span>
  <span>for</span> <span>(</span><span>auto</span> <span>v</span> <span>:</span> <span>mesh</span><span>.</span><span>vertices</span><span>())</span> <span>{</span>
    <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>Vertex</span><span>&gt;</span> <span>vertices</span><span>;</span>
    <span>for</span> <span>(</span><span>auto</span> <span>f</span> <span>:</span> <span>mesh</span><span>.</span><span>faces</span><span>(</span><span>v</span><span>))</span>
      <span>vertices</span><span>.</span><span>push_back</span><span>(</span><span>fvertex</span><span>[</span><span>f</span><span>]);</span>

    <span>tmp</span><span>.</span><span>add_face</span><span>(</span><span>vertices</span><span>);</span>
  <span>}</span>

  <span>// swap old and new meshes, don't copy properties</span>
  <span>mesh</span><span>.</span><span>assign</span><span>(</span><span>tmp</span><span>);</span>
<span>}</span>
</code></pre></div></div> <p>Admittedly, this code is a little more specific to the PMP library. I’m using the <code>centroid()</code> function to compute the center of a face. Here’s the definition:</p> <div><div><pre><code><span>Point</span> <span>centroid</span><span>(</span><span>const</span> <span>SurfaceMesh</span><span>&amp;</span> <span>mesh</span><span>,</span> <span>Face</span> <span>f</span><span>)</span>
<span>{</span>
  <span>Point</span> <span>c</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
  <span>Scalar</span> <span>n</span><span>(</span><span>0</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>v</span> <span>:</span> <span>mesh</span><span>.</span><span>vertices</span><span>(</span><span>f</span><span>))</span> <span>{</span>
    <span>c</span> <span>+=</span> <span>mesh</span><span>.</span><span>position</span><span>(</span><span>v</span><span>);</span>
    <span>++</span><span>n</span><span>;</span>
  <span>}</span>
  <span>c</span> <span>/=</span> <span>n</span><span>;</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>I am also using the built-in property mechanism to attach data to mesh entities (<code>mesh.add_face_property...</code>). Here, I’m storing and retrieving the vertices added to the dual mesh. If you want to keep it simple, you can also use a <code>std::vector</code> for managing this information.</p> <p>I’m also using two frequently used operations when working with meshes:</p> <ol> <li>I’m using <em>iterators</em> to go through all mesh entities (faces, vertices)</li> <li>I’m using a <em>circulator</em> to traverse all faces <em>incident</em> to a vertex.</li> </ol> <p>The circulator is in the <code>for (auto f : mesh.faces(v))</code> part. If you are using a different data structure, you need to figure out how to do this for yourself. Check the API documentation of your library. Or just switch to PMP! <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p> <h2 id="the-octahedron">The Octahedron</h2> <p>With the new function to compute the dual mesh in place, we have all it takes to generate another Platonic solid. The octahedron is the dual polyhedron of the hexahedron, which we can already generate using the <code>hexahedron()</code> function. All that’s left is to combine the two:</p> <div><div><pre><code><span>SurfaceMesh</span> <span>octahedron</span><span>()</span>
<span>{</span>
  <span>auto</span> <span>mesh</span> <span>=</span> <span>hexahedron</span><span>();</span>
  <span>dual</span><span>(</span><span>mesh</span><span>);</span>
  <span>return</span> <span>mesh</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>Now that’s a function to my liking: Create something, do something, and return the result. As simple and clear as it gets. Comparing the original hexahedron and the dual octahedron shows that there is an issue, though: The dual mesh is much smaller and inside the original hexahedron.</p> <p><img src="https://www.danielsieger.com/images/oct_in_hex_300.png" alt="The dual octahedron contained in the original hexahedron"></p> <h2 id="normalizing-positions-on-the-unit-sphere">Normalizing Positions on the Unit Sphere</h2> <p>For the functions defined so far, I took care to compute the vertex coordinates in such a way that they are on the unit sphere. It would be nice to have the same property for the dual meshes as well. A simple solution is to project the vertices of the dual mesh back to the unit sphere. Here’s a function for doing exactly that:</p> <div><div><pre><code><span>void</span> <span>project_to_unit_sphere</span><span>(</span><span>SurfaceMesh</span><span>&amp;</span> <span>mesh</span><span>)</span>
<span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>v</span> <span>:</span> <span>mesh</span><span>.</span><span>vertices</span><span>())</span> <span>{</span>
    <span>auto</span> <span>p</span> <span>=</span> <span>mesh</span><span>.</span><span>position</span><span>(</span><span>v</span><span>);</span>
    <span>auto</span> <span>n</span> <span>=</span> <span>norm</span><span>(</span><span>p</span><span>);</span>
    <span>mesh</span><span>.</span><span>position</span><span>(</span><span>v</span><span>)</span> <span>=</span> <span>(</span><span>1.0</span> <span>/</span> <span>n</span><span>)</span> <span>*</span> <span>p</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Now let’s use this in our function generating the octahedron:</p> <div><div><pre><code><span>SurfaceMesh</span> <span>octahedron</span><span>()</span>
<span>{</span>
  <span>auto</span> <span>mesh</span> <span>=</span> <span>hexahedron</span><span>();</span>
  <span>dual</span><span>(</span><span>mesh</span><span>);</span>
  <span>project_to_unit_sphere</span><span>(</span><span>mesh</span><span>);</span>
  <span>return</span> <span>mesh</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>And this is what the result looks like:</p> <p><img src="https://www.danielsieger.com/images/oct_hex_sphere.png" alt="Octahedron and hexahedron within a sphere"></p> <p>Much better. The two shapes have all their points nicely aligned on the unit sphere, just as we want them to be.</p> <h2 id="icosahedron-and-dodecahedron">Icosahedron and Dodecahedron</h2> <p>Finally, let’s tackle the remaining two polyhedra, icosahedron and dodecahedron. The two are dual to another, so we only need to generate one of them by hand and then compute the other one using the <code>dual()</code> function. I’m choosing the icosahedron for the manual implementation:</p> <div><div><pre><code><span>SurfaceMesh</span> <span>icosahedron</span><span>()</span>
<span>{</span>
  <span>SurfaceMesh</span> <span>mesh</span><span>;</span>

  <span>float</span> <span>phi</span> <span>=</span> <span>(</span><span>1.0</span><span>f</span> <span>+</span> <span>sqrt</span><span>(</span><span>5.0</span><span>f</span><span>))</span> <span>*</span> <span>0.5</span><span>f</span><span>;</span> <span>// golden ratio</span>
  <span>float</span> <span>a</span> <span>=</span> <span>1.0</span><span>f</span><span>;</span>
  <span>float</span> <span>b</span> <span>=</span> <span>1.0</span><span>f</span> <span>/</span> <span>phi</span><span>;</span>

  <span>// add vertices</span>
  <span>auto</span> <span>v1</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>0</span><span>,</span> <span>b</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v2</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>b</span><span>,</span> <span>a</span><span>,</span> <span>0</span><span>));</span>
  <span>auto</span> <span>v3</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>b</span><span>,</span> <span>a</span><span>,</span> <span>0</span><span>));</span>
  <span>auto</span> <span>v4</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>0</span><span>,</span> <span>b</span><span>,</span> <span>a</span><span>));</span>
  <span>auto</span> <span>v5</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>0</span><span>,</span> <span>-</span><span>b</span><span>,</span> <span>a</span><span>));</span>
  <span>auto</span> <span>v6</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>0</span><span>,</span> <span>b</span><span>));</span>
  <span>auto</span> <span>v7</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>0</span><span>,</span> <span>-</span><span>b</span><span>,</span> <span>-</span><span>a</span><span>));</span>
  <span>auto</span> <span>v8</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>b</span><span>));</span>
  <span>auto</span> <span>v9</span>  <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>a</span><span>,</span> <span>0</span><span>,</span> <span>b</span><span>));</span>
  <span>auto</span> <span>v10</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>a</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>b</span><span>));</span>
  <span>auto</span> <span>v11</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>b</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>0</span><span>));</span>
  <span>auto</span> <span>v12</span> <span>=</span> <span>mesh</span><span>.</span><span>add_vertex</span><span>(</span><span>Point</span><span>(</span><span>-</span><span>b</span><span>,</span> <span>-</span><span>a</span><span>,</span> <span>0</span><span>));</span>

  <span>project_to_unit_sphere</span><span>(</span><span>mesh</span><span>);</span>

  <span>// …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.danielsieger.com/blog/2021/01/03/generating-platonic-solids.html">https://www.danielsieger.com/blog/2021/01/03/generating-platonic-solids.html</a></em></p>]]>
            </description>
            <link>https://www.danielsieger.com/blog/2021/01/03/generating-platonic-solids.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624897</guid>
            <pubDate>Sun, 03 Jan 2021 20:25:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California's Future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624765">thread link</a>) | @amasad
<br/>
January 3, 2021 | https://dcgross.com/california-future | <a href="https://web.archive.org/web/*/https://dcgross.com/california-future">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: California builds the TCP/IP, other cultures build the websites. Both valuable, but different. Megaprojects and marketplaces.]</p> <p><strong>The Internet is a galaxy of networks.</strong> Airbnb, Wish, Doordash, Uber, and others are all just networks. Networks have existed for a very long time (from the East India Trading Company to UPS), and the Internet is the latest platform for them.</p> <p>Networks are often started by a particular mercantile energy. Think of your typical souk operator: a swashbuckling, extroverted shop owner. Not an introverted technologist.</p> <p><strong>The introvert builds, the extravert operates</strong>. The personality of the platform inventor (trains, airplanes, ethernet, satellites) is different from the operator: The Wright Brothers are very different people from Michael O’Leary.</p> <p>In the early days, operating companies are hybrid cultures as only people who know how to operate on platforms are the locals. Early operators of railroads were friendly with the Vanderbilts; early creators of Internet platforms hail from Silicon Valley.</p> <p><strong>California was a psychometric hybrid</strong>. Networks are chaotic, have aggressive performance-driven cultures, suffer tension with employee activism (with Rockefeller it was unions; with Zuckerberg it’s social justice), and are very competitive. Travis Kalanick is a prototypical network-operator, but Uber was a hybrid culture with too much of the California gene that didn’t tolerate his Viking leadership.</p> <p>Silicon Valley created the latest network-platform, but it might not have the perfect culture to operate it.</p> <p>Maybe things split:</p> <p><strong>1. Operator Cultures: Miami (London/NY/Berlin/etc)</strong>. Miami is a very extroverted city. It attracts extroverts. Many think that this energy, combined with ludicrous amounts of partying, mean it won’t spawn serious startups. While I don’t think Miami will spawn the next TCP/IP, someone might start the next Uber there. The company won’t write much code, will not become known for technical excellence, and that’s fine! Once the railroad is built you don’t need to understand locomotion to become an oil baron.</p> <p>It’s like Hollywood: LA has the actors, but the pipes are built in Los Gatos by Netflix.</p> <p><strong>2. Infrastructure Culture: California</strong>. Silicon Valley’s culture is a kind of spiritual religion – one of technological progress. Founders often don’t start their company for money; they start it because it seems cool. Because it seems like a neat idea. From UNIX to ibuprofen, the dreamy pursuit of odd ideas with no immediate financial focus has lead to our greatest scientific discoveries and human achievement. This is the power of California.[1]</p> <p>While Miami can be the city of network operators, California (and Texas) feel like the home of Megaprojects. Where the next platforms are built. The Internet, VR, satellites, space elevators, rockets, etc. These are things you build for the spirit. Not because it’ll make a quick buck.</p> <p><strong>San Francisco</strong>. San Francisco might never return. While the Bay Area is incredible, SF is a deteriorating product. Like a bad gym, Covid expired the credit card, and customers are realizing – heck – it’s not worth renewing my membership.</p> <p>In 2021 and beyond, I imagine people will diffuse to the Bay Area. Just like things were in 2008. Palo Alto, Mountain View, Sonoma, etc. The decade-long mismanagement of SF may be viewed as one of the most squandered opportunities of the modern era.</p> <p><strong>In closing,</strong> I imagine California will remain home for the Megaprojects and other cities like Miami can become generators of new networks. Both highly lucrative – Google and Uber are fine companies.</p> <hr> <p>[1] I’ve always wondered if feelings of spirituality and connection to Earth tend to form in societies with high-contrast scenery and altitude. Miami has none of this and California is abundant in it.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/california-future</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624765</guid>
            <pubDate>Sun, 03 Jan 2021 20:07:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biohackers Perform First Plasma Dilution Experiment on Humans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624545">thread link</a>) | @cr4zy
<br/>
January 3, 2021 | https://www.lifespan.io/news/biohackers-perform-first-plasma-dilution-experiment-on-humans/ | <a href="https://web.archive.org/web/*/https://www.lifespan.io/news/biohackers-perform-first-plasma-dilution-experiment-on-humans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This technique is a human modification of the Conboys' mouse experiments.</p><div>
																
								
								
<p>We interviewed <a href="https://rlegroup.net/rle_about">a group of Russian biohackers</a> who performed a plasma dilution experiment on themselves<b>.</b> This experiment, the first of its kind, was based on previous mouse studies by Drs. Irina and Michael Conboy.</p>
<p>Some molecules, while essential for various body functions, can be harmful when overproduced. Inflammatory cytokines, such as transforming growth factor beta 1 (TGF-ß1), interleukin 6 (IL6), and tumor necrosis factor alpha (TNFa) are good examples. The concentration of these cytokines in our blood rises with age, provoking inflammaging, the chronic inflammation that is associated with aging. It has been long speculated that reducing the harmful molecules in circulation can attenuate aging.</p>

<p>Back in 2005, Drs. <a href="https://www.lifespan.io/profile/irina-conboy/">Irina</a> and Michael Conboy created a furor with their research on parabiosis, which links two vascular systems together. The Conboys connected the vascular systems of young and old mice and showed that as a result of the blood exchange, old mice became younger and vice versa [1]. This discovery spurred a flurry of research activity; for instance, earlier this year,<a href="https://www.lifespan.io/news/blood-factors-reverse-epigenetic-age-by-half-in-rats/"> we reported on some highly promising results</a> of adding a cocktail of young blood factors to the bloodstreams of aging mice. However, the Conboys have always maintained that it is what we take out of the bloodstream that matters more. A few months ago, they showed that mere dilution of blood plasma with saline can produce a considerable rejuvenating effect (read<a href="https://www.lifespan.io/news/diluting-blood-plasma-rejuvenates-old-mice/"> our June interview with them</a>). Later, in November, <a href="https://www.lifespan.io/news/diluting-aged-blood-rejuvenates-old-brains/">they published another paper</a> that demonstrated restoration of cognitive functions following plasma dilution.</p>
<p>However, all this research has been done on mice, which led a small group of Russian biohackers to take matters in their own hands. Biohacking is a form of citizen science: do-it-yourself biology experiments. For biohackers focused on longevity, this includes performing experimental treatments (often on themselves) or repurposing existing treatments to improve health and, hopefully, wind back biological age.</p>
<p>The group’s scientific advisor, <a href="https://www.lifespan.io/profile/alexander-fedintsev/">Alexander Fedintsev</a> (<a href="https://www.lifespan.io/news/a-new-hallmark-of-aging-proposed/">read our interview with him</a>) devised a protocol for plasma dilution in humans and a panel of biomarkers to watch. Then, following some logistical wizardry, the procedure was performed on two volunteers. Though not a scientific study per se, this experiment produced interesting, overall positive, results that can potentially influence and guide further research. Our interviewees think that biohacking, when done right, may become an important factor in the longevity field.</p>
<p><b>Alexander Fedintsev (scientific advisor)</b><img loading="lazy" src="https://www.lifespan.io/wp-content/uploads/2020/12/Alexander-Fedintsev_avatar-225x225-1.jpg" alt="" width="225" height="225" srcset="https://www.lifespan.io/wp-content/uploads/2020/12/Alexander-Fedintsev_avatar-225x225-1.jpg 225w, https://www.lifespan.io/wp-content/uploads/2020/12/Alexander-Fedintsev_avatar-225x225-1-150x150.jpg 150w, https://www.lifespan.io/wp-content/uploads/2020/12/Alexander-Fedintsev_avatar-225x225-1-45x45.jpg 45w" sizes="(max-width: 225px) 100vw, 225px"></p>
<p><b>How did your group first get interested in the idea of plasma dilution? I understand that Irina Conboy’s work had a certain influence?</b></p>

<p>Not just influence. It played a central role. The Conboys’ study was published in May. It showed that simple plasma dilution can recapitulate most of the benefits of parabiosis. The original parabiosis results hinted on the existence of certain systemic factors of aging and at the possibility of its reversal. This recent study made the procedure easier and eliminated ethical controversies. The procedure is almost similar to donating blood plasma. Only the liquid fraction is drawn. It does not contain blood cells, such as erythrocytes, leukocytes, and thrombocytes – just the liquid part with signaling molecules dissolved in it. So, the Conboys drew half of the plasma from their mice and replaced it with normal saline and some albumin. Albumin is an important transport protein, and they probably thought that extracting that much albumin from the bloodstream can be harmful, so they wanted to replenish it. This simple procedure yielded some interesting results: it triggered muscle regeneration in mice, liver regeneration in older animals, and improved neurogenesis. Recently, in late November, I think, another study was published that showed some real cognitive improvement following this procedure. So, now we have some serious proof that blood contains signaling molecules that harm the organism, but there is no data on whether this procedure actually prolongs lifespan. I think there is a reason for it. It is highly unlikely that this procedure results in any meaningful life extension. I think most of the effect is on healthspan rather than on lifespan. It is still good news, since we currently have very few ways to extend healthspan.</p>
<p><b>Why did you decide to participate in this small-scale experiment on humans?</b></p>
<p>Our team has existed for some time now. It is a small community of biohackers. It seemed like a great way to quickly test this intervention, get some results fast, and tell people about it.</p>
<p><b>What was your role?</b></p>
<p>I designed the experiment, developed the biomarker panel that we used, and worked on the logistics on how to make it all happen considering our modest means. We could not just follow the Conboys’ mouse study protocol, so we found a way to adapt it to a human experiment in order to do something very close to what the Conboys did.</p>
<p><b>What kind of problems did you encounter while working on the protocol?</b></p>
<p>The first problem that made us delay the experiment for six months was the pandemic. We could have done it sooner, the experiment being so simple. The second problem was that current medical protocols for plasma dilution in humans limit the amount of plasma that can be drawn, so it had to be done in several sittings. We had to calculate how many times we needed to draw plasma so that, in total, about half of the plasma would be replaced. Then, we had to figure out how to inject albumin. The medics who drew the plasma refused to do it, so albumin had to be injected immediately after the plasma donation by a different doctor. Then, there was the development of the biomarker panel – we had to figure out what to look at and at which day since the experiment.</p>
<p><b>How did you choose the tests for the panel?</b></p>
<p>It would have been interesting to look at cognitive and muscular markers, but both our participants were too young: 50-60 years old. They probably do not have sarcopenia or cognitive decline yet, so there was no way for us to measure it. We chose different biomarkers, such as liver function – both of our participants had had some abnormalities in their liver biomarkers. We wanted to check kidney function because it declines with age. We checked the immune system, because as we age, the number of naïve T cells declines, and these are indispensable for fighting new infections. Immunosenescence is a hot topic in times of COVID. Hematopoietic cell aging is characterized by a shift towards myeloid progenitors. We looked at the ratio of neutrophils and lymphocytes, how it changed. Cholesterol is another important marker in the lipid profile of blood. We did a very comprehensive lipid profile that included a rare biomarker that many labs do not check for – oxidized low-density lipoproteins (Ox-LDL). I can say that this marker plummeted all the way down to its normal level in one participant that had it elevated prior to the procedure. We also checked for various hormones, including insulin-like growth factor (IGF), that are related to aging and lifespan, and many other markers, including biochemical ones, such as urea and uric acid, along with oxidative stress markers, such as lipid peroxidation products and glutathione. Contrary to epigenetic clocks, these markers can be clinically interpreted.</p>
<p><b>Do you plan to publish the results, maybe as a case study?</b></p>

<p>We have all the data published as a Google spreadsheet on our website so that researchers can see it. We do not plan to publish an article. First, I am convinced that soon we will have full-scale clinical trials of this method, maybe by the Conboys, and there is something in the works here in Russia as well. I do not know how valuable our data is, considering our sample size was just two people. We just wanted to see whether it was possible to arrange such an intervention in humans using the means we had at our disposal, and whether it would do any good. Now we know it actually did some good, in terms of the number of naïve T-cells, levels of oxidized LDL. The drop in Ox-LDL levels was probably due not simply to dilution but to some deeper processes, because in one participant, these levels declined, while in the other they went up from an originally low level. So, in both participants, LDL levels normalized and stayed normal for at least two weeks. Liver markers improved by a lot, and the myelocyte/lymphocyte ratio improved. There were some controversial results, such as one participant having insulin levels decline four-fold but not the other one.</p>
<p><b>Seems like we are looking at an optimization of certain parameters rather than just up- or downregulation.</b></p>
<p>Yes, the shift sometimes happened in opposite directions. It contradicts the hypothesis that all this procedure does is plasma dilution. It is important to add that we included some inflammation markers, such as C-reactive protein and IL-6. Most of these markers went down in both participants, which points to a decline in systemic inflammation. These markers are very important from the standpoint of aging.</p>
<p><b>Which results were unexpected?</b></p>
<p>For instance, cholesterol went up in one of the volunteers. We expected it to go down in both participants because of the dilution. Probably, cholesterol levels can go back to normal faster than we thought. Also, the insulin levels. We also did not quite anticipate the 40% surge in the number of naïve T cells. The ratio between naïve T-cells and memory T-cells went up too – by as much as 30%.</p>
<p><b>Do you have an explanation for it?</b></p>
<p>Not yet, and I would wait for more data before hypothesizing. We only had two participants, it could be random.</p>
<p><b>Do you plan to expand the project? Maybe recruiting new participants?</b></p>
<p>We would like to have more people tested, but we do not plan to turn it into a large study. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lifespan.io/news/biohackers-perform-first-plasma-dilution-experiment-on-humans/">https://www.lifespan.io/news/biohackers-perform-first-plasma-dilution-experiment-on-humans/</a></em></p>]]>
            </description>
            <link>https://www.lifespan.io/news/biohackers-perform-first-plasma-dilution-experiment-on-humans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624545</guid>
            <pubDate>Sun, 03 Jan 2021 19:47:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magic: The Gathering, Integer Linear Programming, & Arbitrage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624348">thread link</a>) | @joebergeron
<br/>
January 3, 2021 | https://www.joe-bergeron.com/posts/Magic:%20The%20Gathering,%20Integer%20Lineaer%20Programming,%20&%20Arbitrage/ | <a href="https://web.archive.org/web/*/https://www.joe-bergeron.com/posts/Magic:%20The%20Gathering,%20Integer%20Lineaer%20Programming,%20&%20Arbitrage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joe-bergeron.com/posts/Magic:%20The%20Gathering,%20Integer%20Lineaer%20Programming,%20&amp;%20Arbitrage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624348</guid>
            <pubDate>Sun, 03 Jan 2021 19:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Namida, a simple CSS for styling semantic HTML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25624250">thread link</a>) | @kemar
<br/>
January 3, 2021 | https://kemar.github.io/namida/ | <a href="https://web.archive.org/web/*/https://kemar.github.io/namida/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>

            

            <header>
                <h2>The <code>header</code> element</h2>
                <p>The <code>header</code> element represents a group of introductory or navigational aids.</p>
            </header>

            <article>
                <header>
                    <h2>The <code>article</code> element</h2>
                </header>
                <p>The <code>article</code> element represents a complete, or self-contained, composition in a document, page, application, or site and that is, in principle, independently distributable or reusable, e.g. in syndication. This could be a forum post, a magazine or newspaper article, a blog entry, a user-submitted comment, an interactive widget or gadget, or any other independent item of content.</p>
            </article>

            <section>
                <h2>The <code>section</code> element</h2>
                <p>The <code>section</code> element represents a generic section of a document or application. A section, in this context, is a thematic grouping of content, typically with a heading.</p>
            </section>

            <nav>
                <h2>The <code>nav</code> element</h2>
                <p>The <code>nav</code> element represents a section of a page that links to other pages or to parts within the page: a section with navigation links</p>
                <ul>
                    <li><a href="#">Link 1</a></li>
                    <li><a href="#">Link 2</a></li>
                    <li><a href="#">Link 3</a></li>
                </ul>
            </nav>

            <h2>The <code>address</code> element</h2>
            <address>
                The <code>address</code> element represents the contact information for its nearest <code>article</code> or <code>body</code> element ancestor. For more details see <a href="https://html.spec.whatwg.org/multipage/sections.html#the-address-element">The <code>address</code> element</a>.
            </address>

            

            
            <h2>These elements represent headings for their sections.</h2>
            <h3>The semantics and meaning of these elements are defined in the section on headings and sections.</h3>
            <h4>These elements have a rank given by the number in their name.</h4>
            <h5>The <code>h1</code> element is said to have the highest rank.</h5>
            <h6>The <code>h6</code> element has the lowest rank, and two elements with the same name have equal rank.</h6>

            <hgroup>
                
                <h2>The <code>hgroup</code> element represents the heading of a section, which consists of all the <code>h1</code>–<code>h6</code> element children of the <code>hgroup</code> element.</h2>
                <h3>The element is used to group a set of <code>h1</code>–<code>h6</code> elements when the heading has multiple levels, such as subheadings, alternative titles, or taglines.</h3>
                <h4>The rank of an <code>hgroup</code> element is the rank of the highest-ranked <code>h1</code>–<code>h6</code> element descendant of the <code>hgroup</code> element, if there are any such elements, or otherwise the same as for an <code>h1</code> element (the highest rank).</h4>
                <h5>Other <code>h1</code>–<code>h6</code> elements of heading content in the <code>hgroup</code> element indicate subheadings or subtitles or (secondary) alternative titles.</h5>
                <h6>The section on headings and sections defines how <code>hgroup</code> elements are assigned to individual sections.</h6>
            </hgroup>

            

        </section>

        <section>

            

            <!-- The p element -->
            <p>The <code>p</code> element represents a paragraph.</p>
            <p>While paragraphs are usually represented in visual media by blocks of text that are physically separated from adjacent blocks through blank lines, a style sheet or user agent would be equally justified in presenting paragraph breaks in a different manner, for instance using inline pilcrows.</p>

            <!-- The hr element -->
            <hr>

            <!-- The pre element -->
            <pre><code>function Panel(element, canClose, closeHandler) {
              this.element = element;
              this.canClose = canClose;
              this.closeHandler = function () { if (closeHandler) closeHandler() };
            }</code></pre>

            <!-- The blockquote element -->
            <blockquote>
                <p>The <code>blockquote</code> element represents a section that is quoted from another source.</p>
            </blockquote>

            <!-- The ol element -->
            <ol>
                <li>Switzerland</li>
                <li>United Kingdom</li>
                <li>
                    United States
                    <ol>
                        <li>Alabama</li>
                        <li>Delaware</li>
                        <li>New York</li>
                    </ol>
                </li>
                <li>Norway</li>
            </ol>

            <!-- The ul element -->
            <ul>
                <li>Switzerland</li>
                <li>United Kingdom</li>
                <li>
                    United States
                    <ul>
                        <li>Alabama</li>
                        <li>Delaware</li>
                        <li>New York</li>
                    </ul>
                </li>
                <li>Norway</li>
            </ul>

            <!-- The menu element -->
            <menu>
                <li></li>
                <li></li>
                <li></li>
            </menu>

            <!-- The dl element -->
            <dl>
                <dt>If you have exactly five gold coins</dt>
                <dd>You get five victory points</dd>
                <dt>If you have one or more gold coins, and you have one or more silver coins</dt>
                <dd>You get two victory points</dd>
                <dt>If you have one or more silver coins</dt>
                <dd>You get one victory point</dd>
                <dt>Otherwise</dt>
                <dd>You get no victory points</dd>
            </dl>

            <!-- The figure element -->
            <figure>
                <img src="https://kemar.github.io/namida/assets/img/strawberry.png" alt="">
                <figcaption>Strawberry</figcaption>
            </figure>

            <!-- The main element -->
            <p>The main element must not appear as a descendant of the section element. It cannot appear here so it has been moved to wrap all the content.</p>

            <!-- The div element -->
            <p>The <code>div</code> element has no special meaning at all. It represents its children. It can be used with the <code>class</code>, <code>lang</code>, and <code>title</code> attributes to mark up semantics common to a group of consecutive elements. It can also be used in a <code>dl</code> element, wrapping groups of <code>dt</code> and <code>dd</code> elements.</p>

        </section>

        <section>

            

            <table>
                <thead>
                    <tr>
                        <th>Element</th>
                        <th>Purpose</th>
                        <th>Example</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>
                            <code>a</code>
                        </td>
                        <td>
                            Hyperlinks
                        </td>
                        <td>
                            Visit my <a href="#">drinks</a> page
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>em</code>
                        </td>
                        <td>
                            Stress emphasis
                        </td>
                        <td>
                            I must say I <em>adore</em> lemonade.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>strong</code>
                        </td>
                        <td>
                            Importance
                        </td>
                        <td>
                            This tea is <strong>very hot</strong>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>small</code>
                        </td>
                        <td>
                            Side comments
                        </td>
                        <td>
                            These grapes are made into wine. <small>Alcohol is addictive.</small>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>s</code>
                        </td>
                        <td>
                            Inaccurate text
                        </td>
                        <td>
                            Price: <s>£4.50</s> £2.00!
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>cite</code>
                        </td>
                        <td>
                            Titles of works
                        </td>
                        <td>
                            The case <cite>Hugo v. Danielle</cite> is relevant here.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>q</code>
                        </td>
                        <td>
                            Quotations
                        </td>
                        <td>
                            The judge said <q>You can drink water from the fish tank</q> but advised against it.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>dfn</code>
                        </td>
                        <td>
                            Defining instance
                        </td>
                        <td>
                            The term <dfn>organic food</dfn> refers to food produced without synthetic chemicals.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>abbr</code>
                        </td>
                        <td>
                            Abbreviations
                        </td>
                        <td>
                            Organic food in Ireland is certified by the <abbr title="Irish Organic Farmers and Growers Association">IOFGA</abbr>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>ruby</code>, <code>rt</code>, <code>rp</code>
                        </td>
                        <td>
                            Ruby annotations
                        </td>
                        <td>
                            <ruby> OJ <rp>(</rp><rt>Orange Juice</rt><rp>)</rp></ruby>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>data</code>
                        </td>
                        <td>
                            Machine-readable equivalent
                        </td>
                        <td>
                            Available starting today! <data value="UPC:022014640201">North Coast Organic Apple Cider</data>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>time</code>
                        </td>
                        <td>
                            Machine-readable equivalent of date- or time-related data
                        </td>
                        <td>
                            Available starting on <time datetime="2011-11-18">November 18th</time>!
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>code</code>
                        </td>
                        <td>
                            Computer code
                        </td>
                        <td>
                            The <code>fruitdb</code> program can be used for tracking fruit production.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>var</code>
                        </td>
                        <td>
                            Variables
                        </td>
                        <td>
                            If there are <var>n</var> fruit in the bowl, at least <var>n</var>÷2 will be ripe.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>samp</code>
                        </td>
                        <td>
                            Computer output
                        </td>
                        <td>
                            The computer said <samp>Unknown error -3</samp>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>kbd</code>
                        </td>
                        <td>
                            User input
                        </td>
                        <td>
                            Hit <kbd>F1</kbd> to continue.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>sub</code>
                        </td>
                        <td>
                            Subscripts
                        </td>
                        <td>
                            Water is H<sub>2</sub>O.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>sup</code>
                        </td>
                        <td>
                            Superscripts
                        </td>
                        <td>
                            The Hydrogen in heavy water is usually <sup>2</sup>H.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>i</code>
                        </td>
                        <td>
                            Alternative voice
                        </td>
                        <td>
                            Lemonade consists primarily of <i>Citrus limon</i>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>b</code>
                        </td>
                        <td>
                            Keywords
                        </td>
                        <td>
                            Take a <b>lemon</b> and squeeze it with a <b>juicer</b>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>u</code>
                        </td>
                        <td>
                            Annotations
                        </td>
                        <td>
                            The mixture of apple juice and <u>eldeflower</u> juice is very pleasant.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>mark</code>
                        </td>
                        <td>
                            Highlight
                        </td>
                        <td>
                            Elderflower cordial, with one <mark>part</mark> cordial to ten <mark>part</mark>s water, stands a<mark>part</mark> from the rest.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <code>bdi</code>
                        </td>
                        <td>
                            Text directionality …</td></tr></tbody></table></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kemar.github.io/namida/">https://kemar.github.io/namida/</a></em></p>]]>
            </description>
            <link>https://kemar.github.io/namida/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624250</guid>
            <pubDate>Sun, 03 Jan 2021 19:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Couple life: dating apps don’t destroy love]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624228">thread link</a>) | @rustoo
<br/>
January 3, 2021 | https://www.unige.ch/communication/communiques/en/2020/les-applications-de-rencontres-ne-detruisent-pas-lamour/ | <a href="https://web.archive.org/web/*/https://www.unige.ch/communication/communiques/en/2020/les-applications-de-rencontres-ne-detruisent-pas-lamour/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<article>
					<div>
						<section>
<h3><em>Contrary to earlier concerns, a UNIGE study has shown that people who met their partners on dating applications have often stronger long-term relationship goals, and that these new ways of meeting people encourage socio-educational and geographical mixing.</em></h3>
<p>&nbsp;<img src="https://www.unige.ch/communication/communiques/files/cache/82b59834f7de268776ae014db3c22b8b_f2121.jpg" alt="page_garde_Potarca.jpg" width="750" height="329"></p>
<p><em>© All rights reserved<br></em></p>
<div><p><strong>Mobile apps have revolutionised the way people meet in Switzerland and elsewhere in recent years. Unlike traditional dating sites, these apps do not feature detailed user profiles but are largely based on rating photos using a swipe review system. As dating apps escalated in popularity, so has criticism about them encouraging casual dating only, threatening the existence of long-term commitment, and possibly damaging the quality of intimacy. There is no scientific evidence, however, to validate these claims. A study by the University of Geneva (UNIGE), Switzerland, provides a wealth of information about couples who met through dating apps, drawing on data from a 2018 Swiss survey. The results, published in the journal <em>PLOS ONE</em>, indicate that app-formed couples have stronger cohabitation intentions than couples who meet in a non-digital environment. What is more, women who found their partner through a dating app have stronger desires and intentions to have children than those who found their partner offline. Despite fears concerning a deterioration in the quality of relationships, partners who met on dating apps express the same level of satisfaction about their relationship as others. Last but not least, the study shows that these apps play an important role in modifying the composition of couples by allowing for more educationally diverse and geographically distant couples.</strong></p><p>The meteoric rise of romantic encounters on the internet is on its way of becoming the leading place where couples are formed in Switzerland, on a par with meeting via friends. “The Internet is profoundly transforming the dynamics of how people meet,” confirms Gina Potarca, a researcher at the Institute of Demography and Socioeconomics in UNIGE’s Faculty of Social Sciences, and holder of an Ambizione research grant awarded by the Swiss National Science Foundation to study the effects of digital ways of communicating on marriage formation and sorting. “It provides an unprecedented abundance of meeting opportunities, and involves minimal effort and no third-party intervention.” These new dating technologies include the smartphone apps like Tinder or Grindr, where users select partners by browsing and swiping on pictures. These apps, however, have raised fears: “Large parts of the media claim they have a negative impact on the quality of relationships since they render people incapable of investing in an exclusive or long-term relationship. Up to now, though, there has been no evidence to prove this is the case,” continues Dr Potarca.</p></div>
<p><br><strong>Facilitated encounters</strong></p>
<p>The Geneva-based researcher decided to investigate couples’ intentions to start a family, their relationship satisfaction and individual well-being, as well as to assess couple composition. Dr Potarca used a 2018 family survey by the Swiss Federal Statistical Office. The analysis presented in this study looks at a sub-sample of 3,235 people over the age of 18 who were in a relationship and who had met their partner in the last decade. <br>Dr Potarca found that dating websites – the digital tools for meeting partners that preceded apps – mainly attracted people over the age of 40 and / or divorcees who are looking for romance. “By eliminating lengthy questionnaires, self-descriptions, and personality tests that users of dating websites typically need to fill in to create a profile, dating apps are much easier to use. This normalized the act of dating online, and opened up use among younger categories of the population.”</p>
<p><br><strong>Searching for a lasting relationship</strong></p>
<p>Dr Potarca sought to find out whether couples who met on dating apps had different intentions to form a family. The results show that couples that formed after meeting on an app were more motivated by the idea of cohabiting than others. “The study doesn’t say whether their final intention was to live together for the long- or short-term, but given that there’s no difference in the intention to marry, and that marriage is still a central institution in Switzerland, some of these couples likely see cohabitation as a trial period prior to marriage. It’s a pragmatic approach in a country where the divorce rate is consistently around 40%.” In addition, women in couples that formed through dating apps mentioned wanting and planning to have a child in the near future, more so than with any other way of meeting.</p>
<p>But what do couples who met in this way think about the quality of their relationship? The study shows that, regardless of meeting context, couples are equally satisfied with their lives and the quality of their relationship.</p>
<p><br><strong>Couples with a diverse socio-educational profile</strong></p>
<div><p>The study highlights a final aspect. Dating apps encourage a mixing of different levels of education, especially between high-educated women and lower educated men. Partners having more diversified socio-educational profiles “may have to do with selection methods that focus mainly on the visual,” says the researcher. Since users can easily connect with partners in their immediate region (but also in other spaces as they move around), the apps make it easier to meet people more than 30 minutes away – leading to an increase in long-distance relationships. <br>“Knowing that dating apps have likely become even more popular during this year’s periods of lockdown and social distancing, it is reassuring to dismiss alarming concerns about the long-term effects of using these tools,” concludes Dr Potarca. </p></div>							<span> December 30, 2020</span>
														<hr>
							<a href="https://www.unige.ch/communication/communiques/en/2020/">&nbsp;&nbsp;2020</a>
						</section>
						
					</div>
				</article>
			</div></div>]]>
            </description>
            <link>https://www.unige.ch/communication/communiques/en/2020/les-applications-de-rencontres-ne-detruisent-pas-lamour/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624228</guid>
            <pubDate>Sun, 03 Jan 2021 19:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Stein's Paradox]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25624118">thread link</a>) | @antognini
<br/>
January 3, 2021 | https://joe-antognini.github.io/machine-learning/steins-paradox | <a href="https://web.archive.org/web/*/https://joe-antognini.github.io/machine-learning/steins-paradox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bump">
  
    


<section>


  
  



    
    
      <article>
        

        <h2 id="the-paradox">The paradox</h2>

<p>Stein’s paradox is among the most surprising results in statistics.  The basic
idea is easily stated, but it is difficult to understand how it could possibly
be true.  The premise is this: suppose that I have a Gaussian distribution with
a variance of unity and some mean which I don’t tell you.  I then draw a single
sample from this distribution, give it to you, and ask you to guess the mean.
What do you do?  Well, you don’t have a lot of information to go on here, so
you just guess that the mean is the number I gave you.  This is a good guess!
(We will make the notion of a “good guess” a little more precise later on.)</p>

<p>No big surprise there.  Now we play again, but this time, my distribution is a
<em>two</em>-dimensional Gaussian.  The covariance is the identity matrix (so this is
equivalent to sampling from two independent one-dimensional Gaussians).  But
again I have not told you the mean (which is now a two-dimensional vector).
Once more I draw a single sample from the distribution, hand it over to you,
and ask you to guess the mean.  You simply guess that the mean is the sample I
have given you.  Once more you have guessed well!</p>

<p>Now we do the same thing in three dimensions.  I draw a single sample, hand it
over to you, and ask you to guess the mean.  Just as before, you guess that the
mean is the sample I gave you.  But this is no longer a good guess!  Stein’s
paradox is that if we play this game in three dimensions or more, a better
guess is to say that the mean is this:</p>

\[\hat{\mu} = \textrm{ReLU} \left(1 - \frac{D - 2}{|\mathbf{x}|^2} \right)
\mathbf{x},\]

<p>where \(D\) is the dimensionality of the Gaussian, and \(\mathbf{x}\) is the
sample drawn from the distribution.  This is the so-called “James-Stein
estimator.”</p>

<p>Who would have thought!  What is going on here?</p>

<h2 id="what-makes-a-guess-good">What makes a guess good?</h2>

<p>Before we go on, we should clarify exactly what we mean by a “good guess.”  We
are trying to do what is called “parameter estimation” in statistics — based
on a sample from a distribution, we want to infer some underlying parameter (or
parameters) of the distribution.  (In this case the parameter we are interested
in is the mean.)  In order to quantify how good or bad our estimate is we
choose a function called a “loss function.”  There is some freedom in choosing
a loss function, but the mean squared error is a common choice and has a lot of
valuable properties.  Stein’s paradox assumes that we are using the mean
squared error.  So if we guess that the mean is \(\hat{\mu}\) and the true
value of the mean is \(\mu\), then the loss is</p>

\[\mathcal{L} = |\hat{\mu} - \mu|^2.\]

<p>Now, of course, we need some rule to go from the sample \(\mathbf{x}\) to the
estimate \(\hat{\mu}\).  This rule is just a function of some kind, say,
\(f(\mathbf{x})\).  This function has the special name of an “estimator.”  We
can choose whatever function we want here.  Our original guess was to just use
\(f(\mathbf{x}) = \mathbf{x}\).  But another choice here is to say
\(f(\mathbf{x}) = \mathbf{x} + 7\), or \(f(\mathbf{x}) = \sin(\mathbf{x}) /
\mathbf{x}^{71}\), or even just \(f(\mathbf{x}) = 31\).  It doesn’t take much
imagination to see that there are an infinite number of possible choices.  But
presumably some of these choices are better than others.  How do we know which
ones are good?</p>

<p>Statisticians use the concept of <em>risk</em> for this purpose.  Risk is simply the
expected value of your loss function.  One thing that can be a little confusing
is that the risk is a function of <em>both</em> your choice of estimator <em>and</em> the
true value of the parameter itself.  So in the original game where you’re
guessing the mean of a one-dimensional Gaussian, the risk will be a function of
whatever rule you decide to use and the actual, unknown value of the mean.</p>

<p>The fact that the risk is a function of the true value of the parameter makes
things a little tricky.  If you’re trying to decide between two estimators, you
might find that one estimator works better for certain values that the
parameter can take, and the other works better for others.  As a dumb example,
let’s go back to guessing the mean of a one-dimensional Gaussian.  Our original
estimator was \(\hat{\mu} = x\).  But another, perfectly valid, estimator is
\(\hat{\mu} = 7\).  In other words we ignore the sample entirely and say that
the mean is 7 no matter what.  Generally this doesn’t seem like a smart thing
to do.  But if the mean turns out to actually be pretty close to 7, on average
this will be the better guess!  Specifically, the risk of our initial estimator
is</p>

\[\begin{eqnarray}
\mathcal{R}_{x} &amp; = &amp; \mathbb{E} \left[ \left(x - \mu \right)^2 \right] \\
&amp; = &amp; \int (x - \mu)^2 e^{-(x-\mu)^2 / 2} \, dx \\
&amp; = &amp; 1.
\end{eqnarray}\]

<p>And the risk on our second, dumb estimator is</p>

\[\begin{eqnarray}
\mathcal{R}_{\textrm{dumb}} &amp; = &amp; \mathbb{E} \left[ \left(7 - \mu\right)^2 
\right] \\
&amp; = &amp; \int (7 - \mu)^2 e^{-(x - \mu)^2 / 2} \, dx \\
&amp; = &amp; (7 - \mu)^2.
\end{eqnarray}\]

<p>As long as the true mean, \(\mu\), happens to be between 6 and 8, the dumb
estimator of just saying 7 actually has lower risk!</p>

<p>Based on this example it might seem that we’re stuck.  Since we don’t know the
true value of the mean, we can’t generally say if one estimator is better than
another.  And indeed this is often the case.  But there are certain situations
where this is not true.  If we have two estimators and one of them has a lower
risk <em>for any possible value the parameter can take</em>, we can say that one is
definitively better than the other.  In statistical parlance, we say that the
worse estimator is “inadmissable.”</p>

<p>In more precise terms, Stein’s paradox states that in three dimensions or more,
the naive estimator (just guessing that the mean is \(\mathbf{x}\)) is
inadmissable because the risk of the James-Stein estimator is lower for any
possible mean I could choose.</p>

<h2 id="what-is-the-james-stein-estimator-doing">What is the James-Stein estimator doing?</h2>

<p>Before we can understand <em>why</em> the James-Stein estimator gives you a better
guess than the naive estimator \(\textbf{x}\), we should understand <em>what</em>
exactly it’s doing.  The idea is that we take the naive guess \(\textbf{x}\)
and then we scale it towards the origin by some amount.  The factor by which we
scale it is:</p>

\[\textrm{ReLU}\left(1 - \frac{D - 2}{| \textbf{x}|^2} \right).\]

<p>The ReLU function simply takes the maximum of its argument and zero, so this
scale factor will be either positive or zero.  Let’s suppose that it’s
positive.  In this case we scale it towards the origin more if the magnitude of
the sample is smaller and less if it is lower.  In the limit of \(|\textbf{x}|
\to \infty\) we don’t change it at all and our guess reduces to the naive
estimator \(\textbf{x}\).</p>

<p>In the other limit, if \(|\textbf{x}|\) is very small, then the ReLU function
will kick in and just set the scale factor to zero.  Hence anytime we get a
sufficiently small sample we throw it out and just guess that the mean is zero
instead.  And all else being equal we will shrink our estimate more in higher
dimensional spaces than in lower dimensional spaces.</p>

<p>So that is what the James-Stein estimator is doing.  Why does it work?  Before
we can answer that we need to take a quick detour.</p>

<h2 id="samples-in-high-dimensional-spaces">Samples in high dimensional spaces</h2>

<p>High dimensional spaces are counterintuitive.  One of the counteruintitive
properties of high dimensional distributions is this: a sample from a symmetric
high dimensional distirbution is highly likely to be further from the origin
than the mean.  Specifically, for an isotropic \(D\)-dimensional Gaussian, the
difference between the average distance to a sample and the distance to the
mean grows as \(\sim\)\(\sqrt{D}\).</p>

<p>It’s a little strange to put it this way, but isn’t so surprising with a little
bit of thought.  Even in two dimensions we can see that this is the case just
by drawing it:</p>

<p><img src="https://joe-antognini.github.io/assets/posts/steins-paradox/circle-origin.png"></p>

<p>The shaded area of the circle is less than half the area, so we are less likely
to choose a sample closer to the origin than the mean.  What perhaps makes this
counterintuitive is that in two dimensions a fairly large fraction of the
circle is still shaded.  But as the dimensionality increases, this fraction
decreases exponentially.  Once the dimensionality is even moderately large we
are highly unlikely to sample a point in this shaded region.</p>

<p>One caveat here is that this effect decreases the larger the mean is.  You can
imagine that as we move the circle further away from the origin, the shaded
fraction gets closer and closer to ½.  So long as the mean is sufficiently
large, the probability of sampling a point closer to the origin than the mean
can be close to ½ even in high dimensional spaces; it just requires a very
large mean.  We can start to see here the connection to the James-Stein
estimator, which also gets very close to the naive estimator \(\mathbf{x}\) as
the mean (and hence \(|\mathbf{x}|\)) gets very large.</p>

<p>What we are doing by shrinking the estimate towards the origin is correcting
for the tendency of the typical sample to be slightly further away from the
origin than the mean.  This correction allows us to reduce the overall risk of
the estimate. [<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">1</a></sup>]</p>

<h2 id="how-arbitrary-is-the-origin-really">How arbitrary is the origin, really?</h2>

<p>Stein’s paradox is particularly strange because there are actually two
counterintuitive things going on:</p>

<ol>
  <li>The origin is arbitrary, so why does moving your estimate towards the origin
help?</li>
  <li>Why does this not work in one or two dimensions?</li>
</ol>

<p>Let’s take a look at the first of these.  A central principle in physics is
that of relativity — coordinate systems are arbitrary, so the laws of physics
must be valid in all of them.  Surely this is also true in statistics as well.
We can choose the origin to be wherever we like, so it cannot contain any
information.  But this sensible assertion is false.  Statistics is not physics.</p>

<p>If we truly had no information about the mean, what value would the sample
have?  If it could really be <em>anything</em> then presumably its value would …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joe-antognini.github.io/machine-learning/steins-paradox">https://joe-antognini.github.io/machine-learning/steins-paradox</a></em></p>]]>
            </description>
            <link>https://joe-antognini.github.io/machine-learning/steins-paradox</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624118</guid>
            <pubDate>Sun, 03 Jan 2021 19:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL shorteners set ad tracking cookies]]>
            </title>
            <description>
<![CDATA[
Score 410 | Comments 172 (<a href="https://news.ycombinator.com/item?id=25624112">thread link</a>) | @firloop
<br/>
January 3, 2021 | https://ylukem.com/blog/url-shorteners-set-ad-tracking-cookies | <a href="https://web.archive.org/web/*/https://ylukem.com/blog/url-shorteners-set-ad-tracking-cookies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>
January 2, 2021
☼ <a href="https://ylukem.com/tagged/writing">writing</a>
</p>
<p>This Christmas, a family member sent me a <span>URL</span> to a family Zoom call. However, they didn’t send me a direct link to Zoom. Instead, they sent me a<span></span> <span>“</span>tinyurl.com” link.</p>
<p>When I clicked on the link, my <span>URL</span> bar flashed an intermediate domain that was neither Zoom nor TinyURL. Later, I used cURL to see where this <span>URL</span> was really going.</p>
<pre><code>$ curl -v https://tinyurl.com/examplezoom
...
&gt; GET /examplezoom HTTP/2
&gt; Host: tinyurl.com
...
&lt; location: https://redirect.viglink.com?key=a7e37b5f6ff1de9cb410158b1013e54a&amp;u=https%3A%2F%2Fzoom.us%2Fj%2F123456789&amp;prodOvrd=RAC</code></pre>
<p>
<em>(all <span>HTTP</span> responses abridged for clarity)</em>
</p>
<p>Sure enough, the redirect wasn’t clean at all. TinyURL was first sending me to <a href="https://en.wikipedia.org/wiki/VigLink" target="_blank">VigLink</a><a href="#footnote-1WA7" id="ref-1WA7"><sup>1</sup></a>. VigLink is an advertising (tracking) company that specializes in affiliate marketing.</p>
<p>Following the redirect in cURL reveals another unsavory fact. VigLink <em>sets cookies</em> before they send me to the intended destination on Zoom.</p>
<pre><code>$ curl -v <span>'https://redirect.viglink.com?key=a7e37b5f6ff1de9cb410158b1013e54a&amp;u=https%3A%2F%2Fzoom.us%2Fj%2F123456789&amp;prodOvrd=RAC'</span>
&gt; GET /?key=a7e37b5f6ff1de9cb410158b1013e54a&amp;u=https%3A%2F%2Fzoom.us%2Fj%2F123456789&amp;prodOvrd=RAC HTTP/1.1
&gt; Host: redirect.viglink.com
...
&lt; Set-Cookie: vglnk.PartnerRfsh.p=; Domain=.viglink.com; Path=/; SameSite=None; Expires=Thu, 01 Jan 1970 00:00:00 GMT; Secure
&lt; Set-Cookie: vglnk.Agent.p=v-c935c520ecc561fe60a9418874e023b7; Domain=.viglink.com; Path=/; SameSite=None; Expires=Mon, 01 Feb 2021 16:52:34 GMT; Secure</code></pre>
<p>These cookies give them the ability<a href="#footnote-2WA7" id="ref-2WA7"><sup>2</sup></a> to track me across every other site that uses their advertising tech. Who knows what VigLink is doing with my data, but I personally wouldn’t trust an advertising company to keep my browsing history to themselves.</p>
<p>Furthermore, they didn’t give me a chance to opt-out of this tracking. I’m currently based in Europe and I would expect to see at least an interstitial asking for consent to be tracked. <a href="https://tinyurl.com/privacy.php" target="_blank">TinyURL’s privacy policy</a>, last updated in 2012, has no mention of either third party data-sharing nor the cookies they share from affiliates.</p>
<p>This isn’t a phenomenon limited to TinyURL. More common <span>URL</span> shorteners like t.co (Twitter) and bit.ly set cookies when you click on a link. While neither redirect you to an advertising company like TinyURL, Twitter’s primary business model is advertising, and <a href="https://bitly.com/pages/privacy" target="_blank">bit.ly’s privacy policy</a> says they share data with third parties to<span></span> <span>“</span>…provide advertising products and services…”</p>
<p>Don’t use <span>URL</span> shorteners. And if you click on a link from a <span>URL</span> shortener, I recommend using tools like the <a href="https://addons.mozilla.org/en-US/firefox/addon/temporary-containers/" target="_blank">Temporary Containers Firefox extension</a> to limit the scope of ad tracking. Personally, I took the time to send Sovrn (VigLink’s parent company) a <a href="https://ylukem.com/files/_viglink-gdpr-email.png"><span>GDPR</span> request</a>, and made sure to give them my tracking cookie. I’ll update this blog and <a href="https://ylukem.com/newsletter">my newsletter</a> if I actually get anything substantive back.</p>
<section>
<hr>
<ol>
<li id="footnote-1WA7"><p>Their main website was initially blocked by my ad-blocking software. I figured I’d just link to Wikipedia here.<a href="#ref-1WA7">↩</a></p></li>
<li id="footnote-2WA7"><p>Browsers like Safari and Firefox are getting better at catching these drive-by attempts to set cookies. I applaud those efforts, but since this type of tracking works in many cases and is explicitly limited by privacy law, I think it’s still noteworthy.<a href="#ref-2WA7">↩</a></p></li>
</ol>
</section>
<br>

 

</div></div>]]>
            </description>
            <link>https://ylukem.com/blog/url-shorteners-set-ad-tracking-cookies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25624112</guid>
            <pubDate>Sun, 03 Jan 2021 19:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vale's Generational References]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25623780">thread link</a>) | @verdagon
<br/>
January 3, 2021 | https://vale.dev/blog/generational-references | <a href="https://web.archive.org/web/*/https://vale.dev/blog/generational-references">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
    <div>
  

        <div>
          <div>
  

          <div>
            
    
<p>Speed and safety without garbage collection, reference counting, or borrow checking!</p>

              <p><span>Jan 5 2021</span> </p>
      
</div>
<section>
<p>
Vale's <b>hybrid-generational memory</b> is a new memory model that combines all the best parts of existing memory strategies: it's as easy as garbage collection, as deterministic as reference counting, and could even be as fast as borrow checking. <a href="#note0" data-noteid="0">0</a> <a href="#note1" data-noteid="1">1</a>
</p>
<p>
The <b>generational reference</b> is the keystone of the entire approach, the lynchpin that makes it all work. Keep reading to learn how it works!
</p>

</section>
<section>
<p>
Note that hybrid-generational memory is <b>still in development</b>. We have some very promising early results, so we're sharing the idea to show you where Vale is headed. If you want to be part of this and bring hybrid-generational memory into the world, come <a href="https://vale.dev/contribute">join us</a> and help make it happen!
</p>

</section>
<section>
<h2 id="built-on-single-ownership">
 Built on Single Ownership</h2>
<p>
Recall that in Vale, an object is freed when its <b>owning reference</b> goes out of scope. An object always has exactly one owning reference pointing to it. <a href="#note2" data-noteid="2">2</a>
</p>
<p>
We can have as many <b>non-owning</b> references as we want.
</p>
<p>
Our goal here is to make it so when we dereference a non-owning reference, the program safely halts (or does something else <a href="#note3" data-noteid="3">3</a>) instead of triggering memory unsafety. <a href="#note4" data-noteid="4">4</a>
</p>

</section>
<section>
<p>
To keep the language simple and the learning curve easy, we explicitly don't want to force a borrow checker on the user. However, we'd like an approach that has as little <a href="https://vale.dev/blog/hybrid-generational-memory#afterword-how-might-it-compare-to-rust">run-time overhead</a> as the borrow checker.
</p>

</section>
<section>
<h2 id="generational-malloc-and-the-sacred-integer">
 Generational Malloc and the Sacred Integer</h2>
<p>
Generational references use <b>generational malloc</b>, which is like regular malloc, except at the top of every allocation is a <b>generation number</b>, which tracks how many objects have previously been at this memory location.
</p>
<p>
One could also think of it as describing "I am the <b>n</b>th inhabitant of this memory location".
</p>
<p>
Freeing an object will increment its generation number. Nobody else ever modifies it.
</p>

</section>
<section>
<p>
Later on, we use this number to see if a particular object is still alive, explained further below.
</p>

</section>
<section>
<p>
Generational malloc would normally be an adjustment to mimalloc or jemalloc, but we can simulate it with our own <span>genMalloc</span> and <span>genFree</span> functions:
</p>
<ul>
<li>
<span>genFree</span> increments the generation number, and instead of calling <span>free</span> <a href="#note5" data-noteid="5">5</a><a href="#note6" data-noteid="6">6</a>, remembers the allocation in a free-list. There's a free-list for every size class (16b, 24b, 32b, &lt;=48b, &lt;=64b, &lt;=128b, etc).
</li>
<li>
<span>genMalloc</span> pulls from a free-list if possible. If it's empty, it calls <span>malloc</span> and initializes the generation number to 1.
</li>
</ul>
<p>
You can find our experimental implementation in <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a>.
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Generational References</p>
    


      </nav>
      
    

      <div>
        <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
 Vale has three release modes:
</p>
<ul>
<li>
Resilient mode, which is fast and memory safe; it will halt the program when we try to dereference a freed object.
</li>
<li>
Assist mode, for development, to detect potential problems even earlier.
</li>
<li>
Unsafe mode, which turns off all safety.
</li>
</ul>
<p>
Resilient mode uses hybrid-generational memory.
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
See <a href="https://vale.dev/blog/hybrid-generational-memory">Hybrid-Generational Memory</a> for a full explanation (and some comparison with Rust!)
</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
Similar to C++ and Rust; objects don't have a ref-count.
</p>

</section>
</div>
<div id="note3" data-noteid="3">
<p><span>3</span></p><section>
<p>
The program doesn't necessarily need to halt, we could cause some stack unwinding to a safe point instead.
</p>

</section>
</div>
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
Similar to how, in Rust, we might halt the program when we access a <span>RefCell</span> or try to "dereference" a generational index to a dead object.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
 Our experimental implementation doesn't release memory back to the OS until exit, but when a page is empty, the final version will release the page back to the operating system and map its virtual memory to a read-only page containing all 0xFF.
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
 When an allocation's generation can't be incremented any more, it's not used again (at least until we can re-map the page).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="generational-reference-more-than-just-a-pointer">
 Generational Reference: More than just a pointer!</h2>

</section>
<section>
<p>
Vale's references are <b>generational references</b>. A generational reference has two things:
</p>
<ul>
<li>
A pointer to the object.
</li>
<li>
A "target generation" integer.
</li>
</ul>
<p>
To create a reference to an object, we get its allocation's generation number, and include it in the reference.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="dereferencing">
 Dereferencing</h3>

</section>
<section>
<p>
To dereference a generational reference, we do a "liveness check" to see whether the allocation's generation number <b>still matches</b> our reference's target generation. <a href="#note7" data-noteid="7">7</a>
</p>
<p>
This prevents use-after-free problems, and makes Vale completely memory safe.
</p>

</section>
<section>
<p>
It's as if the reference is saying:
</p>
<p><b>"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"</b>
</p>

</section>
<section>
<p>
and the person who opens the door says:
</p>
<p><b>"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."</b> <a href="#note8" data-noteid="8">8</a>
</p>
<p>
or instead:
</p>
<p><b>"Yes! That is me. Which of my fields would you like to access?"</b>
</p>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
 This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world instead of just a specific vector.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
 This will safely halt the program, unless the user is explicitly checking whether something is alive (such as for a weak reference).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="speed">
 Speed</h2>

</section>
<section>
<p>
Generational references are only the first steps towards hybrid-generational memory, but we decided to run some early experiments to see how it compares to existing memory models.
</p>
<p>
For this experiment, we benchmarked <a href="#note9" data-noteid="9">9</a> <a href="#note10" data-noteid="10">10</a> three flavors of Vale:
</p>
<ul>
<li>
<b>Unsafe</b>, with no memory safety, the equivalent of C++ (minus caveats, see below!)
</li>
<li>
<b>RC</b>, where we use naive reference counting for all our objects.
</li>
<li>
<b>GM</b>, which uses generational references.
</li>
</ul>

</section>
<section>
<div>
  <table>
    <thead>
      <tr>
        <th>Mode</th>
        <th>Speed&nbsp;(seconds)</th>
        <th>Overhead Compared to Unsafe (seconds)</th>
        <th>Overhead Compared to Unsafe (%)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>Unsafe</th>
        <td>43.82&nbsp;seconds</td>
        <td>n/a</td>
        <td>n/a</td>
      </tr>
      <tr>
        <th>RC</th>
        <td>54.90&nbsp;seconds</td>
        <td>+11.08&nbsp;seconds</td>
        <td>+25.29%</td>
      </tr>
      <tr>
        <th>GM</th>
        <td>48.57&nbsp;seconds</td>
        <td>+4.75&nbsp;seconds</td>
        <td>+10.84%</td>
      </tr>
    </tbody>
  </table>
</div>


</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
 We used the <a href="https://github.com/ValeLang/Vale/tree/master/benchmarks/BenchmarkRL/vale">BenchmarkRL</a> terrain generator to gather these numbers, with different values for the <span>--region-override</span> flag: <span>unsafe-fast</span>, <span>naive-rc</span>, and <span>resilient-v3</span> respectively.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
 Here, we benchmarked against other flavors of Vale, to isolate the differences between unsafe, reference-counting, and generational references.
</p>
<p>
Once we implement full hybrid-generational memory, we'll be benchmarking against C++ and Rust, stay tuned!

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
Generational references have only 10.84% overhead, <b>less than half the cost of reference counting!</b> These are very promising results, and suggest that full hybrid-generational memory could be incredibly fast.
</p>

</section>
<section>
<p>
Try it out! In the Vale release, you can find a benchmark folder with scripts to run the benchmarks. You can find the source code for the various approaches <a href="https://github.com/ValeLang/Vale/tree/master/Midas/src/c-compiler/region">here</a> (feel free to swing by the <a href="https://discord.gg/SNB8yGH">discord server</a> and we can point you to the right files).
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
<b>Note these caveats!</b> To isolate the difference between generational references and the other approaches:
</p>
<ul>
<li>
In all flavors, we only allocate objects on the heap, except for primitives. Future versions will add stack allocations.
</li>
<li>
We used genHeap.c for all versions, though only GM ever touches the generation number, the other versions ignore it. Future versions will integrate generational malloc into jemalloc or mimalloc directly.
</li>
</ul>
<p>
Once we address these limitations, we can get more precise benchmarks against the other approaches.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h2 id="why-is-this-so-fast">
 Why is this so fast?</h2>

</section>
<section>
<p>
Generational references are much easier for the CPU to handle than reference-counted references, because:
</p>
<ul>
<li>
Generational references have no aliasing/dealiasing overhead, just on dereference.
</li>
<li>
Generational references cause less cache misses.
</li>
<li>
Liveness checks' branching is easier to predict than RC decrements' branching.
</li>
</ul>

</section>
<section>
<p>
We explain these two differences more below.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="no-aliasing-costs">
 No Aliasing Costs</h3>

</section>
<section>
<p>
Reference counting is costly:
</p>
<ul>
<li>
Whenever we "alias" (make a new reference to an object), we have to dereference the object to increment its counter.
</li>
<li>
Whenever we "dealias" (throw away a reference), we have to:
</li>
<ul>
<li>
Dereference the object to decrement its counter,
</li>
<li>
If the counter is zero, deallocate it.
</li>
</ul>
</ul>
<p>
For example:
</p>

    <div>
      
      <p><span><span>fn <span>launchShip</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>, <span><span><span>armada</span></span> <span>&amp;<span><span>List</span>&lt;<span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>)</span> <span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<br>    <p>  <span><span>armada</span><span>.</span><span>add</span>(<span>ship</span>)</span>;</p><p>  <br>  <br>  <br>  <br>  <br>  <br>}</p></span></span></span></p>
    </div>
  
<p>
As you can see, reference counting incurs a cost whenever we alias or dealias. <b>Generational references don't have that cost.</b> The above snippet would have zero overhead if it used generational references.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
Instead, generational references incur a cost whenever we dereference an object:
</p>

    <div>
      
      <p><span><span>fn <span>getShipName</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>)</span> <span><span>str</span> </span><span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<p>  <br>  <br>  <span>ret <span><span>ship</span><span>.</span><span>name</span></span>;</span><br>}</p></span></span></span></p>
    </div>
  

</section>
<section>
<p>
This is cheaper because <b>programs dereference less than they alias and dealias:</b> our sample program had 4.7 million counter adjustments, but only 1.3 million liveness checks. <a href="#note11" data-noteid="11">11</a> <a href="#note12" data-noteid="12">12</a>
</p>

</section>
<section>
<h3 id="more-cache-friendly">
 More Cache Friendly</h3>
<p>
Reference counting is not very "cache friendly". Adding and subtracting integers is basically free on modern CPUs, but the real bottleneck in modern programs is how <i>far</i> those integers are: if it's been recently accessed, it's in the nearby cache, and only takes a few CPU cycles to fetch. Otherwise the CPU will "cache miss" and have to bring it in all the way from RAM, which could take <b>hundreds</b> of cycles. <a href="#note13" data-noteid="13">13</a>
</p>
<p>
In our reference-counted <span>launchShip</span> example, the <span>ship.__ref_count++</span> could take a few cycles if <span>ship</span> is already in the cache, or hundreds of cycles if it's not.
</p>

</section>
<section>
<p>
Generational references are more cache friendly:
</p>
<ul>
<li>
When a generational reference goes away, we don't need to reach into memory (unlike RC, where we have to decrement a counter).
</li>
<li>
We don't need to increment when aliasing (see previous section); we don't need to reach into memory to increment.
</li>
</ul>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
 Half of these are aliasings and half are …</p></section></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vale.dev/blog/generational-references">https://vale.dev/blog/generational-references</a></em></p>]]>
            </description>
            <link>https://vale.dev/blog/generational-references</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623780</guid>
            <pubDate>Sun, 03 Jan 2021 18:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have Meetings, Only When Necessary, Mostly One-on-One]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25623605">thread link</a>) | @AltonWells
<br/>
January 3, 2021 | https://www.wells.ai/thoughts/have-meetings-only-when-necessary-mostly-one-on-one | <a href="https://web.archive.org/web/*/https://www.wells.ai/thoughts/have-meetings-only-when-necessary-mostly-one-on-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍</p><div><p>I have an internal bias towards most meetings, one perhaps that isn't all that original but it goes something like this. </p><p><strong>Email &gt; Slack &gt;&nbsp;Phone Call &gt; Text Message &gt; Written Letter &gt;&nbsp;Morse Code&nbsp;&gt;&nbsp;Smoke Signal &gt;&nbsp;Guttural Screaming &gt; "<em>Meeting</em>".</strong></p></div><p>‍</p><p>Even in this all to frequentness and easy era of zoom calls and google meets I still find many if not most meetings that I'm called into to be not exactly pointless but lets say misguided and most certainly a pseudo-criminal waste of time. This has been something i've been passionate about for a few years and made particularly poignant after transferring over from start-up land to more traditional commercial business. Thats not to say that all meetings are bad, !true, some are absolutely necessary, enjoyable and useful (<em>Good</em> Scums, Retrospectives, Big Decisions) but many meetings suffer from a lack of structure or a specific emphasis that lead them into the land of arbitrary updates and non-specific conversation that aren't all that productive and like the good saying goes: "Could be handled over an email". So like any new year i've decided to set a goal, more of a personal optimization really, which goes something like this: </p><p>‍</p><blockquote>‍<br>Have meetings, only when necessary, mostly one-on-one.<br>‍</blockquote><p>‍</p><p>‍<br>There are <strong>a lot </strong>of perspectives about meetings. These are some of the results from a quick internet&nbsp;search:&nbsp;</p><ul role="list"><li><a href="https://freakonomics.com//2009/07/28/read-this-if-you-hate-meetings/">Read this if you hate meetings</a></li><li><a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/" target="_blank">Meetings: where work goes to die </a></li><li><a href="https://forge.medium.com/walking-meetings-will-change-the-way-you-work-dce8b61f9e04">Why walking meetings work </a></li><li><a href="https://timharford.com/2019/08/what-we-get-wrong-about-meetings-and-how-to-make-them-worth-attending/" target="_blank">What we got wrong about meetings and how to make them work</a></li><li><a href="https://blog.valuemotive.com/are-daily-scrum-meetings-worth-it-6c6fb915bec4?gi=7f787159ed1e">Are daily scrum meetings worth it?</a></li><li><a href="https://www.linkedin.com/pulse/20130701022638-22330283-a-simple-rule-to-eliminate-useless-meetings">Simple rule for eliminating useless meetings </a></li><li><a href="http://www.bbc.co.uk/news/business-43809674">Elons: Walk out of meetings when you're not adding value</a></li><li><a href="https://www.thinkbusiness.ie/articles/jeff-bezos-rules-productive-meetings-amazon/">Jeffs: Start with silence, write it down, keep it small<br>‍</a>‍</li></ul><p>Obviously one could go on but I think it's a fair assessment to say there seems to be in some organizations cultural issues with meetings. Reading through these articles I was able to abstract little tidbits of advice about meetings, how to hold them, when to have them, how to structure them, what to do once you're in them, etc. but the resounding undertone of most was "There are a lot of bad meetings out there, here's what you can do to try fix them, good luck". So instead of regurgitating the various types of meeting participants (<a href="http://www.paulgraham.com/makersschedule.html">Managers vs Makers, Essential Paul Graham</a>)&nbsp;or to write hyperbole on the super stars of techs most prominent practices (<a href="https://www.inc.com/justin-bariso/jeff-bezos-knows-how-to-run-a-meeting-here-are-his-three-simple-rules.html">Jeff Bezos</a>, <a href="https://www.inc.com/jeff-haden/productivity-rules-elon-musk-says-every-effective-leader-should-embrace.html">Elon Musk</a>, <a href="https://www.businessinsider.com/twitter-square-ceo-jack-dorsey-meetings-2015-12">Jack Dorsey</a>, Etc.). I'll simply stick with what I&nbsp;intend to adopt for this new year. </p><h3>Have Meetings</h3><p>Working with people is unavoidable, you need to do it to do virtually any job in any workplace, they cant be absolutely avoided nor should they. In product management they are a very real functional requirement of the role, work with the teams to get the product out the door and work with the customers to make it what they want. In development "meetings" are a different thing all together often times they're more like active collaborations or jazzing through a problem they're personal, in-depth, and require attention to numerous details. </p><p>Regardless of what function you play in any organization you need to have meetings. Personally I recommend having a set agenda for manager style meetings with specific outcomes (decisions)&nbsp;that you hold the group to. If you don't need to be in a meeting don't be afraid to say it and if you're asked to explain yourself, explain yourself. If you find a meeting has reached a plateau or natural end, don't hesitate to wrap it up, your time and everyone else's is more valuable than bitcoin. If you want to have a meeting about blue sky opportunities, growth, collaborations go for a walk or get lunch (with masks if you're comfortable) those moments are special and deserve the relaxed enhancement of food and activity. Finally if you find yourself leading a meeting hold yourself directly and personally responsible for the quality and outcomes of those meetings even if it's with the CEO, it is 100% your job to make the meeting work. </p><p>‍</p><h3>Only When Necessary</h3><p>We live in the golden era of personal communication, use it.</p><p>If you find a meeting that is regularly scheduled is ineffective or pointless move it to a weekly update over email. If you have someone asking for a meeting, quite literally ask them if they can write it out or handle the conversation of slack, iMessage, chat. Very many a meeting can more effectively be handled over written word and should be. </p><p>‍<br>Typed english is far less ambiguous and requires far more thought than top-of-mind spoken word. </p><p>‍</p><h3>Mostly One-on-One</h3><div><p>Information exchange is tricky. Humans can transmit huge amounts of information through nuance, tone, body language, word, etc. In large groups much of that nuance gets turned from signal into noise. If you're going to have a meeting, try to have a meeting directly with one person at a time. Its where information <strong>exchange</strong> is at it's highest and flows the best. </p><p>If you're meeting in a group (Stand-Ups, Scrums, Whatever) contribute where you need to contribute, be there if necessary, and focus to the best of your ability on making that time as valuable as possible. If you find yourself in one of these "pointless" group meetings do a quick calculation on the dollar cost of this time and ask yourself what can be done to fix it or make it better. </p></div><p>‍</p><p>‍</p><p>At the end of the day, theres no specific solution for the all the potential meetings problems. Like everything, each group has unique situations that lead to how these interactions are handled. Whatever you end up doing, just remember your time is valuable and so is everyone else's, treat it like such.</p><p>‍</p><p>Also shout out to<a href="https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions"> Brandon Smith for his recent post on coding</a>, it gave me the idea for this blog. </p></div></div>]]>
            </description>
            <link>https://www.wells.ai/thoughts/have-meetings-only-when-necessary-mostly-one-on-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623605</guid>
            <pubDate>Sun, 03 Jan 2021 18:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distant Future Warnings: The challenges of communicating with eternity (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25623561">thread link</a>) | @Bluestein
<br/>
January 3, 2021 | https://www.cbc.ca/radio/ideas/distant-future-warnings-the-challenges-of-communicating-with-eternity-1.4158805 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/ideas/distant-future-warnings-the-challenges-of-communicating-with-eternity-1.4158805">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Radioactive waste and toxic mining byproducts will remain deadly for thousands of years – maybe forever. Deep in the arsenic-contaminated underground at Giant Mine near Yellowknife, contributor Garth Mullins wonders how we can warn the distant future. Is it even possible to send messages that can outlast governments, languages, cultures, nations – maybe even humans?</p><div><p><span><span><div><div title="Distant Future Warnings: The challenges of communicating with eternity" role="button" tabindex="0"><div><div aria-labelledby="967710787762-metadata-" title="Distant Future Warnings: The challenges of communicating with eternity"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/257/947/DistantFutureWarnings_2500kbps_852x480_967716931783.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Radioactive waste and toxic mining byproducts will remain deadly for thousands of years – maybe forever. Generations in the distant future will need to know about about the places this stuff is buried, and to stay away. Deep in the arsenic-contaminated underground at Giant Mine near Yellowknife, contributor Garth Mullins wonders how we can warn the distant future. Is it even possible to send messages that can outlast governments, languages, cultures, nations – maybe even humans?<!-- --> <!-- -->1:00</span></span></span></p><p><span><div><div role="button" tabindex="0" title="Distant Future Warnings: The challenges of communicating with eternity"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/845/411/ideas-640x320.jpg" alt=""></p><p><span>Ideas</span><span>53:59</span><span>Distant Future Warnings: The challenges of communicating with eternity</span></p></div></div></div></span></p><p><span><p><em>**This episode originally aired June 14, 2017.</em></p>  <p>Radioactive waste and toxic mining byproducts will remain deadly for thousands of years – maybe forever. Generations in the distant future will need to know about the places this stuff is buried, and to stay away. Deep in the arsenic-contaminated underground at Giant Mine near Yellowknife, contributor Garth Mullins wonders how we can warn the distant future. Is it even possible to send messages that can outlast governments, languages, cultures, nations – maybe even humans?</p>  <div><p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/distant-future-warnings-garth-mullins.jpg 300w,https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/distant-future-warnings-garth-mullins.jpg 460w,https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/distant-future-warnings-garth-mullins.jpg 620w,https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/distant-future-warnings-garth-mullins.jpg 780w,https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/distant-future-warnings-garth-mullins.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4159001.1497623417!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/distant-future-warnings-garth-mullins.jpg"></p></div><figcaption>Garth Mullins listens to the sound of frozen arsenic, 250 feet underground at Yellowknife's Giant Mine. <!-- --> <!-- -->(Lisa Hale)</figcaption></figure></span><br> <em>"You'd climb down into this box and, using a scraper, would scrape this six inches of arsenic off the walls of the scrubber. And we would dump the arsenic into the tailings dam and out the other side into the environment."</em> – David Searle, former mine worker describes cleaning mill machinery at the Con Mine in Yellowknife in the early 1950s.</p><p> &nbsp; <em>"If we're looking about trying to contain arsenic trioxide or some other kind of contamination over 5,000 years and you don't want people to go there then how do you do that? How do you do something that doesn't just make people want to go check it out?" </em>– Joan Kuyek lifetime community organizer, mining analyst and author.</p><p> &nbsp; <em>"They got the gold and we got the shaft"</em> – Johanne Black, Yellowknives Dene&nbsp;First Nation.</p></div>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/distant-future-warnings-giant-mine.jpg 300w,https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/distant-future-warnings-giant-mine.jpg 460w,https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/distant-future-warnings-giant-mine.jpg 620w,https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/distant-future-warnings-giant-mine.jpg 780w,https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/distant-future-warnings-giant-mine.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4159059.1497385166!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/distant-future-warnings-giant-mine.jpg"></p></div><figcaption>Old sign at the perimeter of the Giant Mine site.<!-- --> <!-- -->(Garth Mullins)</figcaption></figure></span>Places like the Giant Mine with its 237,000 tonnes of arsenic trioxide and the U.S. Waste Isolation Pilot Plant with its buried radioactive waste will be dangerous for a very long time.</p>  <p>There are thousands of these legacy sites around the world. They'll need to contain their deadly contents in perpetuity. But facilities fail. Monuments crumble. Language drifts. Context changes. Governments don't last. The future may be riddled with climate disaster, corrupted data, coup, regime change and war. How can our warnings survive this chaos? How can we even imagine the deep future when Homo sapiens have only been around for two hundred thousand years?</p>  <p>Perhaps the answer isn't in design or technology, but in us. We are the message – the signal. And so will our kids be. And their kids. And theirs. Over generations that signal can fade to static. It'll need amplification. Resources. Mandates. Budgets. Protective legislation. Encoding in popular culture.</p>  <p>The Giant Mine is on the territory of the <strong><a href="http://ykdene.com/">Yellowknives Dene First Nation</a></strong>, who've been passing information down the generations since time immemorial. <strong>Johanne Black</strong>, Director of Lands Management, said her nation was the first watchdog. "It was just one impact after another. We're still living in the same place right across from the Giant Mine, and we're still watching the operations." Black said "the Dene way of communicating is to pass on oral history" and that her nation won't forget what happened at&nbsp;the Giant Mine.</p>  <p><strong>Guests in this episode:</strong></p>  <ul>   <li><strong>Joan Kuyek</strong> is a lifetime community organizer, mining analyst and author.<br> &nbsp;</li>   <li><strong>​Johanne Black</strong> is Director of Lands Management, Yellowknives Dene First Nation.<br> &nbsp;</li>   <li><strong>Arn Keeling</strong> is a professor of geography at Memorial University with a focus on mining and environmental history in Northern Canada.<br> &nbsp;</li>   <li><strong>John Sandlos</strong> is a professor of history at Memorial University, studying the impact of northern mining and toxins on Indigenous communities.&nbsp;<br> &nbsp;</li>   <li><strong>David Searle</strong> was a mine worker in the 1950s, later a lawyer and an NWT MLA in the 1970s.<br> &nbsp;</li>   <li><strong>Natalie Plato</strong> is the Deputy Project Director for the Giant Mine Remediation Project.<br> &nbsp;</li>  </ul>  <p><strong>Further reading:&nbsp;&nbsp;</strong></p>  <ul>   <li><em>Mining and Communities in Northern Canada</em>, Editors: Arn Keeling and John Sandlos, University of Calgary Press, 2015,&nbsp;<strong><a href="http://press.ucalgary.ca/books/9781552388044" target="_blank">available from the&nbsp;publisher as a free e-book</a></strong>.<br> &nbsp;</li>   <li><em><strong><a href="http://www.iiirm.org/publications/Articles%20Reports%20Papers/Environmental%20Restoration/resolve.htm" target="_blank">Taking Control: Opportunities for and Impediments to the Use of Socio-Cultural Controls for Long-Term Stewardship of U.S. Department of Energy Legacy Waste Sites</a></strong></em>,&nbsp;a report by the International Institute for Indigenous Resource Management. November 22-23, 2004.<br> &nbsp;</li>   <li><em><strong><a href="http://miningwatch.ca/publications/2011/10/4/theory-and-practice-perpetual-care-contaminated-site" target="_blank">The Theory and Practice of Perpetual Care of Contaminated Sites</a></strong>, </em>Joan Kuyek.<em>&nbsp;</em>Submission by Alternatives North to the Mackenzie Valley Environmental Impact Review Board Giant Mine environmental assessment.<br> &nbsp;</li>   <li><em>The Death of Nature; Women, Ecology and the Scientific Revolution</em>, Carolyn Merchant, Harper &amp; Row, 1980&nbsp;<br> &nbsp;</li>   <li><em>We Stand On Guard</em>, a graphic novel by Brian K. Vaughan and Steve Skroce, Image Comics, Inc. 2001.<br> &nbsp;</li>   <li><em>&nbsp;A Canticle for Leibowitz</em>, Walter M. Miller Jr., Bantam, 1959&nbsp;<br> &nbsp;</li>   <li>101 Things to Do With A Hole in the Ground, Georgina Pearlman, Eden Project (Publisher) 2009&nbsp;</li>  </ul>  <p>&nbsp;<br> <strong>Related websites: </strong></p>  <ul>   <li><strong><a href="http://www.toxiclegacies.com/" target="_blank">Toxic Legacies Project</a></strong> – Research on the history of arsenic contamination at Northern mines. &nbsp;<br> &nbsp;</li>   <li><strong><a href="http://www.guardiansofeternity.ca/" target="_blank">Guardians of Eternity – Confronting Giant Mine's Toxic Legacy</a></strong>. A film by France Benoit<br> &nbsp;</li>   <li><strong><a href="http://www.slate.com/articles/health_and_science/green_room/2009/11/atomic_priesthoods_thorn_landscapes_and_munchian_pictograms.html" target="_blank">Atomic priesthoods, thorn landscapes and munchian pictograms: how to communicate the dangers of nuclear waste to future civilizations</a></strong>, Juliet Lapidos. Slate. November 16, 2009<br> &nbsp;</li>   <li>The podcast <strong><a href="http://99percentinvisible.org/episode/ten-thousand-years/" target="_blank">99% Invisible</a></strong> looks at some of the design challenges of creating markers to last 10,000 years at the Waste Isolation Pilot Plant site.&nbsp;<br> &nbsp;</li>   <li><strong><a href="https://www.aadnc-aandc.gc.ca/eng/1100100027364/1100100027365" target="_blank">The Giant Mine Remediation Project</a></strong> is an intergovernmental body responsible for management of contamination at the Giant Mine.<br> &nbsp;</li>   <li><strong><a href="http://gmob.ca/" target="_blank">The Giant Mine Oversight Board</a></strong> is an independent body charged with monitoring, advising and advocating on management and remediation of the Giant Mine site.<br> &nbsp;</li>   <li><strong><a href="http://ykdene.com/" target="_blank">Yellowknives Dene First Nation</a></strong>.The Giant Mine is located on YKDFN territory.&nbsp;<br> &nbsp;</li>   <li><strong><a href="http://www.videoproject.com/Into-Eternity.html" target="_blank">Into Eternity</a></strong> –&nbsp;a documentary that "explores the scientific and philosophical questions long-term nuclear waste storage poses."<br> &nbsp;</li>   <li><strong><a href="http://www.bbc.co.uk/programmes/b08g7tv3" target="_blank">Radioactive Art</a></strong> is a BBC documentary that looks at whether artists can warn future generations about nuclear legacies with their work.</li>  </ul>    <hr>  <p><em>**This episode was produced by Garth Mullins, Lisa Hale &amp; Dave Redel. Readings by Erin Noel and Peter Brown.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/ideas/distant-future-warnings-the-challenges-of-communicating-with-eternity-1.4158805</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623561</guid>
            <pubDate>Sun, 03 Jan 2021 18:07:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Concept Creep]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25623497">thread link</a>) | @apsec112
<br/>
January 3, 2021 | https://poly.land/2018/11/30/concept-creep-gaslighting/ | <a href="https://web.archive.org/web/*/https://poly.land/2018/11/30/concept-creep-gaslighting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
								<p>Concept creep has to be one of my biggest pet peeves.</p>
<p>What’s concept creep? It’s pretty much what it sounds like. Concept creep occurs when a concept that originally meant something very specific later comes to encompass a much broader set of unrelated, or only loosely related, phenomena.</p>
<p>Psychology has been particularly plagued by concept creep. <a href="https://www.tandfonline.com/doi/abs/10.1080/1047840X.2016.1082418?journalCode=hpli20&amp;">According to Nick Haslam</a>, who is credited with coining the phrase:</p>
<p>Many of psychology’s concepts have undergone semantic shifts in recent years. These conceptual changes follow a consistent trend.&nbsp; Concepts that refer to the negative aspects of human experience and behavior have expanded their meanings so that they now encompass a much broader range of phenomena than before. This expansion takes “horizontal” and “vertical” forms: concepts extend outward to capture qualitatively new phenomena and downward to capture quantitatively less extreme phenomena…In each case, the concept’s boundary has stretched and its meaning has dilated.&nbsp;Although conceptual change is inevitable and often well motivated, concept creep runs the risk of pathologizing everyday experience and encouraging a sense of virtuous but impotent victimhood.</p>
<h2>Codependency, Narcissism, and Emotional Labor Are Very Specific Things</h2>
<p>Many concepts have fallen prey to this effect. One notable example is&nbsp;<a href="https://poly.land/2018/04/13/polyamory-helped-ditch-codependence-find-healthy-interdependence/">codependency,</a>&nbsp;which had a very specific meaning when it was first coined in substance abuse circles (the state of another person being co-addicted to substances by proxy, owing to their close relationship with an addict) but now is used by the general population to describe an entire array of behaviors that have nothing to do with the original concept and aren’t necessarily even pathological depending on the particular context (thinner than average boundaries, people pleasing, dependence in general, etc.).</p>
<p>A similar fate has befallen&nbsp;<em>narcissism.&nbsp;</em>There are actually pretty specific criteria for narcissistic traits, behavior, and of course the full blown personality disorder. However, it’s fashionable now for lay folks to label anyone that behaves like a jerk a “narcissist,” where many times the person in question is actually showing a pattern of behavior more consistent with other cluster B disorders (i.e., antisocial, borderline, histrionic). Or they’re just being kind of jerky and inconsiderate — but in a way that’s divorced from anything that’s really beyond the diagnostic pale. Because just because someone’s annoying or acting in a hurtful way, it doesn’t make them disordered.</p>
<p>It’s happening virtually everywhere you look. The Atlantic ran a piece recently on how <a href="https://www.theatlantic.com/family/archive/2018/11/arlie-hochschild-housework-isnt-emotional-labor/576637/?fbclid=IwAR02EtM3N1RaZiq3fF48-uz32pWWoJ0iCxM-Tab6N7WPHV7-np4Vxl406zM">emotional labor has suffered concept creep</a>, an article which features an interview with the sociologist who originally coined the term.</p>
<h2>Not All Psychological or Emotional Invalidation Is Gaslighting.</h2>
<p>However, I would have to say that in my own work these days, I’m most frequently dealing with concept creep in regards to gaslighting.</p>
<p>The term <em>gaslighting</em> originally referred to a very specific form of psychological manipulation. Its origins stem from a play from the 1930s called&nbsp;<em>Gaslight</em>, in which a man tries to make his wife and other people think she’s insane by messing with small aspects of her environment and then telling her she’s wrong and possibly insane when she later points it out to him. In one instance, this literally involves <em>dimming gaslight</em>s in the house while he’s up to some shenanigans (he’s not a nice dude and also killed another lady and is rooting around looking for the dead woman’s jewels), thus the name.</p>
<p>So the term gaslighting informally came to describe an effort to manipulate someone’s perception of reality in a way that can make someone else feel crazy and doubt their own sanity. Where classically this process was dependent on a person messing with physical objects in one’s external environment, it’s also come to be understood that it’s possible to gaslight someone through less concrete methods: Lying, misdirection, denial, etc.</p>
<p>This is fine and a fairly minor extension of the original more literal use.</p>
<p>What <em>is</em> a problem, however, is that people have started to use it refer not just to this specific form of manipulation but instead to refer to <em>any</em> form of psychological invalidation.</p>
<p>One common misapplication I’ve seen many times in my travels is the following: In situations in which your partner disagrees with you about a subject that’s actually quite ambiguous and you get hurt by it, people are quite eager to jump in and say that the partner is gaslighting you. But that’s not what gaslighting is. Not every hurtful interpersonal conflict is (in fact, while gaslighting certainly happens, it’s relatively rare compared to other more common forms of maladaptive relating).</p>
<h2>Emotional Invalidation Versus Gaslighting</h2>
<p>However, it’s trendy so people are using the word&nbsp;<em>a lot —&nbsp;</em>whether they really&nbsp;<em>should&nbsp;</em>or not. Often what’s being mistakenly described as gaslighting these days is at best an honest disagreement over something ambiguous — or at worst, it’s an instance of emotional invalidation.</p>
<p>What’s emotional invalidation? It’s when someone else tells you that your emotions or thoughts aren’t valid. This can happen in a number of ways. Someone can simply ignore them and go about their merry way without considering them. Or they can outright judge you for them (“that’s a stupid way to feel”). They can even reject your own assessment of your emotional state by telling you, “Oh that’s not how you really feel.”</p>
<p>Is emotional invalidation hurtful? Absolutely.</p>
<p>Is emotional invalidation gaslighting? Nope, not really.</p>
<p>A better example of gaslighting would be if someone told you that they never had conversations with you that you know you did and tell you that you must be crazy or overworked if you think that actually happened. Or if they’re hiding things on you and telling you that you must be mistaken about those items getting lost (especially if they put them back in their original place later, causing you to doubt your sanity).</p>
<h2>But What Does It All Mean, Basil?</h2>
<p>Okay, so <a href="https://poly.land/2018/11/02/that-doesnt-need-to-be-a-word-is-an-incredibly-boring-stance/">language is evolving</a>. Whoop de freaking doo. That’s what language does, right? Maybe it’s annoying to prescriptivists (like a lot of other things), but what’s the big deal?</p>
<p>Well, concept creep has consequences.</p>
<p>In addition to Nick Haslam’s concerns above about pathologizing the everyday, I also find myself frustrated by the difficulty concept creep poses to communication. Where those terms once held some utility in talking with others, I find more often than not that when I’m attempting to problem-solve relationship issues with an individual that I absolutely cannot take any of that at face value. If they say that their partner is gaslighting them or they tell me that their ex was a narcissist, that ends up being <em>incredibly</em> low-yield information. Instead of learning anything important from those descriptors, I find myself expending considerable energy in followup questions, uncovering exactly what they think those words mean. What happened? What behaviors are we talking about?</p>
<p>Where several years ago, I was much more likely to have the individual describe the actual behavior at default, it’s more likely these days for people to start using labels instead as a shortcut. And ones they are often not applying correctly.</p>
<p>To be fair, there’s always going to be a place for that kind of followup in the helping professions. And people are generally unreliable narrators, incredibly biased and subjective sources of information, something you basically always have to keep in mind when you’re working with them and talking over complex social issues with them.</p>
<p>But concept creep really does seem to have gotten worse in recent years.</p>
<p>*</p>
<p>Books by Page Turner:</p>
<p><a href="http://amzn.to/2yIldEG">A Geek’s Guide to Unicorn Ranching</a></p>
<p><a href="http://amzn.to/2BMAoSi">Poly Land: My Brutally Honest Adventures in Polyamory&nbsp;</a></p>

<div><p>Liked it? Take a second to support Poly.Land on Patreon!</p><p><a rel="nofollow" target="_blank" href="https://www.patreon.com/polyland"><img src="https://poly.land/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png"></a></p></div>							<hr>	
														
							</div></div>]]>
            </description>
            <link>https://poly.land/2018/11/30/concept-creep-gaslighting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623497</guid>
            <pubDate>Sun, 03 Jan 2021 18:00:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become an Ethical Hacker]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25623102">thread link</a>) | @spectnullbyte
<br/>
January 3, 2021 | https://patchthenet.com/articles/how-to-become-an-ethical-hacker/ | <a href="https://web.archive.org/web/*/https://patchthenet.com/articles/how-to-become-an-ethical-hacker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                                                    
<p>Any person who is seriously considering to become an ethical hacker should be aware of the challenges they might face. If you think that you will get to the expert level in a few weeks or months, then I’m sorry to bring you the bad news: It won’t be easy. In fact, it will take you years to reach a level that will allow you to seriously challenge real-world systems and finally monetize your hacking skills (Legally, of course). </p>



<p>Therefore, if you are not ready to put in the time and effort, then this might not be the right place for you.</p>



<p>With this introduction, I am not trying to discourage you. I am simply trying to make sure that you have enough motivation and willpower to achieve this goal.</p>



<p>So, with all this being said, you have given it some thought and now you’ve decided that you’re ready to give it all it takes to become an ethical hacker?</p>



<p>Well, that’s good. By taking this decision, you’ve already made the first step.</p>



<p>There is only one problem: Where should you start?</p>



<p>Well don’t worry about that, you’ve come to the right place. In this post, I provide a step-by-step guide on how to become an ethical hacker. I have also added links to resources that can help you at each step of your way. </p>



<p>All tutorials and learning materials that I have included here are completely free. This way, you don’t have to spend your money on expensive courses.</p>



<p>So, if you’re ready to become an ethical hacker, let’s go ahead and get started with the first step.</p><div><figure><img src="https://patchthenet.com/wp-content/uploads/2021/01/cyber-security-cybersecurity-computer-security-3480163-1024x682.jpg" alt="how to become an ethical hacker"></figure></div><h2>1. Learn the fundamentals</h2>



<p>Before you can learn about hacking and security, you should first have a solid foundation of computer skills. This is a very important step, one that you should not skip. </p>



<p>If you lack an understanding of how underlying computer systems work, then you will always rely on tools developed by other hackers. People who do that are called <strong>script kiddies</strong>, and, believe me, you do not want to be called that.</p>



<p>So, for this first step, here is what you should learn</p>



<h3>Computer networks</h3>



<p>Computer networks are everywhere. Even now, you are connected to one. It is almost impossible to find a computer system not connected to a network.</p>



<p>Computer networks can be connected to the Internet, or they can be completely isolated. Either way, knowing how these networks operate is necessary if you want to find out what vulnerabilities they might have.</p>



<p>There are plenty of resources on the web that provides tutorials and courses about computer networks. <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=QKfk7YFILws" target="_blank">The Bits and Bytes of Computer Networking</a> is a great course made by Google for beginners. Another useful resource is <a rel="noreferrer noopener" href="https://www.professormesser.com/network-plus/n10-007/n10-007-training-course/" target="_blank">The Network+ Training Course</a> by Professor Messer. You can also check our computer networking tutorials for beginners on <a href="https://patchthenet.com/computer-networking/">Patchthenet</a>.</p>



<h3>Linux</h3>



<p>I have nothing against Windows, but when it comes to hacking, I cannot help but swear by Linux. I mean, what’s not to like? It is an open-source, freely available operating system that you can customize however you wish.</p>



<p>Hackers and pen-testers use Linux because it provides tons of open-source tools that they can use and change as they wish. In fact, there are distributions of Linux, like Kali and Parrot, that are designed specifically for pen-testing. It would therefore be wise to learn Linux if you want to benefit from all these advantages.</p>



<p>Websites like <a rel="noreferrer noopener" href="https://ryanstutorials.net/linuxtutorial/" target="_blank">ryanstutorials</a> or <a rel="noreferrer noopener" href="https://linuxjourney.com/" target="_blank">linuxjourney</a> are good resources that can help you get started with Linux.</p>



<h3>Programming languages</h3>



<p>Learning a programming language will allow you to code your own tools and scripts. You can, for example, automate tasks like scanning for certain types of vulnerabilities, or you can code your own exploits.</p>



<p>If you do not know how to code, then you will be forced to use tools developed by other hackers and you won’t be able to modify them and adjust them to your needs. This will severely limit your possibilities.</p>



<p>If you’re new to programming, Python can be a good start. It is a powerful scripting tool. You would be surprised at what you can make using this simple language. It is also a very popular language, so you won’t have any problem finding the support you need from the Python community. </p>



<p>As a first step, you can watch the <a href="https://www.youtube.com/watch?v=_uQrJ0TkZlc" target="_blank" rel="noreferrer noopener">Python for Beginners</a> course by Mosh on Youtube. After that, you can practice your coding skills on <a href="https://www.hackerrank.com/" target="_blank" rel="noreferrer noopener">Hacker Rank</a>.</p>



<h2>2. Learn Ethical Hacking</h2>



<p>Once you’re feeling confident you’ve mastered the fundamentals, you can start learning about hacking. But this is not as simple as it sounds.</p>



<p>Hacking is a very wide subject. It spans many fields. You can pursue only one or two specific fields or you can follow a rather general approach and take in the entire hacking spectrum.</p>



<p>A third option, one that I personally recommend, is to learn at first all domains at a high-level without diving too deep into each of them. This will provide you a general understanding which will allow you to choose one field that you might find yourself leaning toward. Then, once you’ve made up your mind, you can work your way to become more proficient in your chosen field. </p>



<p>I discuss here some of the fields that you can follow if you want to become an ethical hacker.</p>



<h3>Web Application Security</h3>



<p>Almost every organization has a presence on the web. Websites have become an essential thing to have for any organization that wants to attract customers, reach out to partners, or simply communicate with the public.</p>



<p>Securing web applications is therefore a priority for many organizations, especially those that rely on their web content to bring in revenue. A lot of these organizations are paying for hackers to perform penetration testing on their web applications in order to help secure them against malicious hackers.</p>



<p>Performing penetration testing on web applications demands a certain level of proficiency in web programming languages such as <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=OK_JCtrrv-c" target="_blank">PHP</a> and <a href="https://javascript.info/" target="_blank" rel="noreferrer noopener">Javascript</a>. You should be able to review the source code and scan it for vulnerabilities. </p>



<p>You should also learn about the most common web application vulnerabilities. The best source for this is <a href="https://owasp.org/www-project-top-ten/" target="_blank" rel="noreferrer noopener">The OWASP Top Ten</a>.</p>



<p>After that, you can read the <a href="https://owasp.org/www-project-web-security-testing-guide/" target="_blank" rel="noreferrer noopener">OWASP Web Security Testing Guide</a>, which is considered by many to be the best reference for web application pen-testers.</p>



<h3>Reverse Engineering</h3>



<p>Reverse engineering is a powerful skill that you want to have under your belt. It allows you to understand the architecture and the inner design of a hardware or software system.</p>



<p>In the case of software, developers rely on reverse engineering tools to duplicate or add new functionalities to a product even if they do not have access to the source code. While this might not necessarily be illegal, attackers have found another, less honest way, to use them. They can reveal the inner design and expose vulnerabilities in the system, like ways to bypass controls or getting access to confidential information.</p>



<p><a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=iyAyN3GFM7A&amp;list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN" target="_blank">LiveOverflow </a>is a great channel that provides good tutorials and videos about binary exploitation, cracking and software reverse engineering. </p>



<h3>Network security</h3>



<p>Networks are often the entry point for attackers that wish to gain access to a system. This is all the more true when the attacker has physical access to the target network, like for example through an accessible public Wi-Fi.</p>



<p>Securing a network is not an easy task. There is a large attack surface that presents a risk and so many things that can go wrong. For instance, you can have the most secure configuration on your network devices, but if your switch room is not as highly protected, then an attacker that manages to gain access to the room will easily compromise your network and make all your work pointless.</p>



<p>If you want to simulate how attackers might gain access to a network, you should learn how to look for these security weaknesses. Make sure to examine every facet of your target: Physical location of network devices, compromised endpoints, weak configurations, accessible wireless networks, and so on.</p>



<p>You can watch the <a href="https://www.youtube.com/watch?v=3Kq1MIfTWCE" target="_blank" rel="noreferrer noopener">Network Penetration Testing</a> course by Heath Adams on Youtube. It is a full course that will help you make the first steps in network hacking. </p>



<h3>Cryptography</h3>



<p>Since ancient times, cryptography has been a tool used to protect communications between allies from intercepting enemies. For a long time, simple algorithms were enough. However, in recent decades, and with the fast-growing processing power of modern computers, we got used to newer algorithms being developed and then cracked years afterwards. This trend appears to be continuing for years to come, especially with the advent of quantum computing which will render most of the currently strong algorithms insecure.</p>



<p>I should note, however, that cracking current algorithms is not a task for us mere mortals. Secure algorithms like AES-256 are practically impossible to hack.</p>



<p>Still, while cracking the algorithm itself is not feasible, it is completely realistic to hack its implementation.</p>



<p>There is a <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=2aHkqB2-46k&amp;list=PL419GdFFJL5V5nSp380lP9o9kTC_My3u8&amp;index=1" target="_blank">24-lecture series</a> on Youtube by Christof Paar that I highly recommend if you are serious about learning cryptography.</p>



<h3>Active Directory</h3>



<p>Almost every company in the world uses Active Directory. It is the one tool that administrators use to manage permissions and access to network resources, and so you shouldn’t be surprised if I tell you that it represents a constant target for malicious hackers. </p>



<p>You should be knowledgeable of the vulnerabilities and weaknesses that exist in AD. You should also learn how they can be exploited so you can help secure them against attackers. </p>



<p><a href="https://adsecurity.org/" target="_blank" rel="noreferrer noopener">Adsecurity</a> is a good website that provides great tips and attack methods related to active directory. Another resource is the “<a href="https://www.varonis.com/blog/pen-testing-active-directory-environments-part-introduction-crackmapexec-powerview/" target="_blank" rel="noreferrer noopener">Pen Testing Active Directory Environments</a>” by Varonis.</p>



<h2>3. Practice</h2>



<p>The only thing that can make you an ethical hacker is hacking. You can read every book ever written about this subject, but reading on its own does not make you skilled. Only experience does. </p>



<p>Fortunately, you do not have …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://patchthenet.com/articles/how-to-become-an-ethical-hacker/">https://patchthenet.com/articles/how-to-become-an-ethical-hacker/</a></em></p>]]>
            </description>
            <link>https://patchthenet.com/articles/how-to-become-an-ethical-hacker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623102</guid>
            <pubDate>Sun, 03 Jan 2021 17:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I logged my activities at 15-minute intervals for the whole year]]>
            </title>
            <description>
<![CDATA[
Score 601 | Comments 267 (<a href="https://news.ycombinator.com/item?id=25623010">thread link</a>) | @HuangYuSan
<br/>
January 3, 2021 | https://samplesize.one/blog/posts/my_year_in_data/ | <a href="https://web.archive.org/web/*/https://samplesize.one/blog/posts/my_year_in_data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

  		<p>At around this time last year, I was being flooded with various articles on new year's resolutions and yearly summaries - as is typical in early January. I was trying to decide whether there is anything I hoped to change in my life. One of the big points on my 'roadmap to becoming a better human' google doc (everyone has one, right?) was being more aware of what happens with my time (what do I spend it on? am I sure I'm making <em>most</em> of it?). This sounded like an actionable new year's resolution, so I decided to give it a try. However, I tend to get a bit intense sometimes and so I kind of logged all my activities at 15-minute intervals for the whole year.</p>
<h4>You did what!?</h4>
<p>I logged my activities at 15-minute intervals for the whole year.</p>
<p>Here, check out this screenshot from my google sheet (btw, the spreadsheet title is just "Life"):</p>
<p><img src="https://samplesize.one/img/spreadsheet_banner.png" alt="A screenshot of a google sheet I used to track my data with different activities coloured differently" title="Life"></p>
<h3>Why would you do this!?</h3>
<p>I wanted to see what happens with my time. I knew I was spending quite a lot of it on social media, but I wasn't sure how much exactly. I also knew I was working quite a lot and wanted to quantify exactly how much (spoiler alert: not that much). I hoped that keeping track of what I do would help me to identify chunks of time that were being wasted and to turn them into <em>quality</em> time.</p>
<p>It was also a purely scientific curiosity - there were many less important questions that I was curious to find answers to: do I get less sleep while at uni? How much time do I spend with people vs on my own? What are the effects of drinking alcohol? and many others.</p>
<h3>Ok, sure, whatever. How much effort did this take?</h3>
<p>Not that much actually!</p>
<p>When I started, I was fully expecting to get bored with the whole thing and stop after maybe a month or so. Surprisingly, logging what I do turned out to be quite easy. As you might have noticed, I get quite excited about data so seeing my spreadsheet getting bigger and more colourful was enough of an incentive to keep me going. In the few instances, when I came close to stopping, a strong FOMD (fear of missing data) would always get me back on it.</p>
<h4>Technicalities</h4>
<p><a href="#data">I don't care, I want to see the data.</a></p>
<ul>
<li>I decided to log my activities in 15-minute intervals - I wanted to be able to catch shorter activities (especially procrastination) but didn't want it to be too crazy (though I might have lost the right to decide what is crazy when I started the whole project)</li>
<li>I was using google sheets to log my data. I liked them because are online by default allowing me to log my data both on my laptop and my phone, the drag-to-copy cell content function makes it easy to log longer activities and the conditional formatting makes the spreadsheet nice and colourful providing instant gratification. You can access my template <a href="https://docs.google.com/spreadsheets/d/1XBUFCJGVL73kFvD0yO5e63fLfRuebemcqhnQoafXad4/edit?usp=sharing">here</a>.</li>
<li>I divided my activities into broad categories to make noting them down easier. Some categories were divided further into subcategories.
For me, the categories were:
<ul>
<li><strong>sleeping:</strong></li>
<li><strong>focused work</strong> - what I really understand as productivity:
<ul>
<li><strong>uni</strong> - university (until June) and PhD (since October)</li>
<li><strong>self-improvement</strong> - job applications, but also working on my personal projects (like writing code to analyse my data, or learning to draw)</li>
<li><strong>admin</strong> - answering emails, filling forms etc (btw filling my time tracking spreadsheet was in this category)</li>
<li><strong>organising</strong> - things like organising events for a society, conferences and other extracurricular things</li>
<li><strong>German</strong> - to track language learning</li>
</ul>
</li>
<li><strong>low-focus work</strong> - same subcategories as in focused work. Low-focus work included activities that were more mechanical and didn't require too much brain power. For example, admin or organising my notes would be low-focus, while reading papers or writing essays would be focused work.</li>
<li><strong>socialising</strong></li>
<li><strong>culture</strong> (with subcategories: <strong>books</strong>, <strong>films</strong>, <strong>documentaries</strong>, <strong>TV shows</strong>, and <strong>other</strong>)</li>
<li><strong>human function</strong> - the boring stuff I need to do to stay alive (showering, making food, eating and things like that. On trips also setting tents etc)</li>
<li><strong>other quality time</strong> - things that didn't really fit into the other categories. Subcategories: <strong>blogs</strong>, <strong>podcasts</strong>, <strong>news</strong>, <strong>games</strong>, <strong>YouTube</strong>, <strong>chilling</strong> (for the times when I needed to just lie down or stare at the wall), and <strong>other</strong>)</li>
<li><strong>travelling</strong> - time spent in buses/cars/planes etc</li>
<li><strong>exercising</strong> - deliberate exercise - running, cycling, exercise routines</li>
<li><strong>exercising (lower intensity)</strong> - mostly walking/slow cycling, but also stretching</li>
<li><strong>procrastinating</strong> - mostly social media</li>
<li><strong>idle</strong> - waiting in queues etc</li>
</ul>
</li>
</ul>

<h2>The data</h2>
<p>Alright, so now that I hopefully managed to calm you down, let's use the data I have to answer a few questions:</p>
<h4>What did I do in 2020?</h4>
<p><img src="https://samplesize.one/img/year_props.png" alt="A calendar showing how much time in total I spent on different activities"></p>
<p>Turns out my top three activities of the year are sleeping (7h 45min on average per day and I'm very proud of this), working (6h 20 min on average per day) and socialising (3h 25 min on average per day). It is mostly what I would expect except that it always scares me how much time we actually spend unconscious. I can't decide whether 1h 20 min spent on human function (eating and showering etc) is a lot or not (a downside of a small sample size, I guess). On one hand, I could probably use that time to do more fun things but on the other hand maybe I should just chill.
The procrastination time (on average 10 mins per day) is definitely less than it actually is - I will talk more about it in the productivity section below.</p>
<p>Another cool feature of the way I was logging my data was that I could log more than one activity into a single time slot (walking and listening to a podcast is a classic). This means that the total time spent on all activities sums up to more than 365 days - you can see this as 'extra days' on the plot above. Turns out that this year, I had 395 surplus hours or 16.5 surplus days. I hope I didn't spend them on human function.</p>
<p>Some of the categories from the plot above were divided into more helpful subcategories:</p>
<p><img src="https://samplesize.one/img/High_intensity_work.png" alt="A calendar showing how much time I spent on different subcategories within focused work">
<img src="https://samplesize.one/img/Low_intensity_work.png" alt="A calendar showing how much time I spent on different subcategories within low-focus work"></p>
<p>By far, most of my work was towards uni and PhD - 51 days in total. After excluding the time from June to September, when I had holidays, this gives around 5hrs of work per day. While this includes weekends, this does not seem like a lot, especially that weekends are not really well respected at uni.</p>
<p>Finding out how little focused work I do, even on the days that feel productive, was one of the biggest surprises of analysing my data. It turns out that a typical working day (9-17) would usually only give around 5-6 hours of actual work, while the rest of time would dissolve on low-focus work, chatting to people, coffee breaks and other little distractions. While there were days when I would reach 8 hours of focused work (for focused uni work I had 32 such days this year), they required either spending the whole day (9-22) working or a <em>lot</em> of effort to stay focused. Both were quite tiring and unsustainable in the long run. I guess the lesson here is that when it comes to focused work, the 8-hour working day is an unattainable target and should not be used as a benchmark.</p>
<p>I also do a lot of admin - nearly half of all the time I spend on culture. This is fairly sad and a potential action point for the future.</p>
<p><img src="https://samplesize.one/img/culture.png" alt="A calendar showing how much time I spent on different subcategories within culture"></p>
<p>I spent a fair amount of time reading books - nearly 1.5h per day on average! I'm quite happy with this since this is a habit I consciously worked to develop this year. During this time, I have read 35 books (12,715 pages according to Goodreads<sup id="fnref1">
<a href="#fn1" rel="footnote">1</a> </sup>
). If you want some recommendations, my top three would be: A Gentleman in Moscow, The Places in Between, and Little Fires Everywhere. On the other hand, I can't really find films or TV shows that I would really get into, so if you have any that you love, let me know! Also a bonus: the 'documentaries' are really just Louis Theroux and I don't regret a single minute.</p>
<p><img src="https://samplesize.one/img/Quality.png" alt="A calendar showing how much time I spent on different subcategories within quality time" title="Other quality time subcategories"></p>
<h4>How did the time spent on different activities change over the months?</h4>
<p><img src="https://samplesize.one/img/hrs_per_month_timeline.png" alt="A stacked plot showing how the average daily hours spent on different activities changed throughout the months"></p>
<p>As above, the hours sum to more than 24 because of logging two activities in a single time slot if I was doing them simultaneously.</p>
<p>You can quite clearly identify the 'hard lockdown' times - April+May and November. In both periods, there is a noticeable increase in working hours, reduction in socialising and increase in culture. In the spring I was finishing my Master's thesis and revising for my exams so I would expect the increase in productivity regardless of lockdown. However, seeing the same pattern in November (when we were discouraged from coming to office) seems to suggests that I am actually working more when working from home. This is probably due to both fewer distractions but also to the lack of alternatives. Normally, I would often stop working to meet friends. During the lockdown, when this is not an option, I often just continue working.</p>
<p>I would love to talk about all the other categories, but the post is getting quite lengthy so you can explore them here (another bonus: look for my binge of playing Zoo Planet):</p>

<h4>Hacking my monkey brain to increase productivity</h4>
<p>As I was analysing at my data throughout the year, I was quite disappointed in how little I worked and was looking for a way to increase it.
Inspired by <a href="https://putanumonit.com/2017/05/09/time-well-spent/">this post</a> I decided to gamify my productivity by giving myself points for activities I wanted to do more of.
I was hoping that they would act as sources of instantenous pleasure for my monkey brain (which wants fun <em>now</em> and doesn't really care about future me) to make it do things that might be less fun but beneficial in the long run.
Given that I already had data on my activities throughout the day, assigning points was pretty straightforward.</p>
<p>I would get:</p>
<ul>
<li>4 points per hour for the most productive activities (focused work towards uni &amp; self-improvement and exercising)</li>
<li>3 points for reading books</li>
<li>2 points for reading blogs, listening to podcasts, lower intensity work etc</li>
<li>0 points for things that are important but I do them anyway (socialising, sleep etc)</li>
<li>-4 points for procrastination</li>
</ul>
<p>And here are my points for this year:</p>
<p><img src="https://samplesize.one/img/points.png" alt="A calendar with days coloured according to the amounts of points I got on a given day"></p>
<p>and their distributions throughout the months:</p>
<p><img src="https://samplesize.one/img/points_per_month.png" alt="A plot of the distributions of points throughout the months"></p>
<p>Turns out my monkey brain is <text><strong>crazy</strong> </text> about points. The moment I started, every day became an exercise in optimisation. You can see that from April, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samplesize.one/blog/posts/my_year_in_data/">https://samplesize.one/blog/posts/my_year_in_data/</a></em></p>]]>
            </description>
            <link>https://samplesize.one/blog/posts/my_year_in_data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25623010</guid>
            <pubDate>Sun, 03 Jan 2021 17:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Mac to Linux]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622969">thread link</a>) | @christian_fei
<br/>
January 3, 2021 | https://cri.dev/posts/2021-01-03-mac-linux/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2021-01-03-mac-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>I am switching from Mac to Linux.</p>
<p>This is how the adventure started to find the best linux distro, with a seemless user experience and minimum maintenance.</p>
<p>In the past months I experimented with various distros:</p>
<ul>
<li>bare debian</li>
<li>Pop!_OS</li>
<li>Ubuntu</li>
<li>Elementary OS</li>
</ul>
<p>I didn’t even want to get my hands dirty with Arch. To each their own, right?</p>
<p>Read below to read my experience and to which distro I settled using.</p>
<h2>Experience recap</h2>
<h3>with bare debian</h3>
<p>Driver support for WiFi and Bluetooth were absent out of the box.</p>
<p>Still too much to adjust and tweak to get a decent user experience.</p>
<p>Not for me.</p>
<h3>with Pop!_OS</h3>
<p>Seemed like a fresh approach to the linux distro landscape, but I had major hiccups when it comes to display drivers.</p>
<p>Weird issues like blank screen after switching to HDMI external display. Troublesome boots when display was attached.</p>
<p>Weird glitches and graphical artifacts when resizing windows.</p>
<p>No issues with drivers.</p>
<p>I bet it works great on System76 machines though.</p>
<h3>with Ubuntu</h3>
<p>Glitches when working with external monitors.</p>
<p>Blank screen after booting connected via HDMI.</p>
<p>Weird behaviour when putting laptop in clamshell mode. Either not turning on, or shortly showing the login screen and then going to sleep.</p>
<p>No issues with drivers.</p>
<p>Recurrent issues with the confusing Software center versions not compatible with the applications on it.</p>
<p>Amazon EKS keeped popping up as a “promoted” application, without the possibility to remove it.</p>
<p>Bye Ubuntu.</p>
<h3>Elementary OS</h3>
<p>No issues with drivers.</p>
<p>No issues with external monitor. Wake and sleep with HDMI works like expected.</p>
<p>No blank screen when booting from external monitor.</p>
<p>Decent software center (with donations built in), also using snap was great.</p>
<p>Slight issues when disconnecting the external monitor and using the laptop, works after a few tries.</p>
<p>So far so good.</p>
<h2>Elementary OS is good enough for me</h2>
<p>The user experience is stunningly similar to what I was used to with a Mac.</p>
<p>Switching windows is intuitive.</p>
<p>If you forget a shortcut, just press <code>&lt;SUPER&gt;</code>.</p>
<p>With <code>snap</code> it almost feels like using <code>brew</code> and <code>brew cask</code>.</p>
<p>Using it in clamshell mode works like a charm.</p>
<p>The system even wakes up from sleep using a Bluetooh logitech keyboard with mouse (namely the Logitech k400 I think).</p>
<p><s>Still need to find a better Terminal emulator, because I’m not really fond of the one built-in. Perhaps time to try Alacritty?</s></p>
<p><a href="https://dottorblaster.it/2020/12/back-to-linux/">dottorblaster.it</a> suggested <a href="https://gnunn1.github.io/tilix-web/">Tilix</a>, and I can relate: it’s pretty awesome and provides a similar experience to iTerm.</p>
<p>This is how I am writing this very blog post.</p>
<p><img src="https://cri.dev/assets/images/posts/mac-linux/elementary-os-preview.png" alt="elementary os preview"></p>
<h2>Applications</h2>
<h3>Terminal</h3>
<p><a href="https://gnunn1.github.io/tilix-web/">Tilix</a> with ZSH (coming from iTerm and fish shell)</p>
<p><img src="https://cri.dev/assets/images/posts/mac-linux/tilix.png" alt="tilix"></p>
<h2>Browser</h2>
<p>Brave (coming from Firefox + Brave)</p>
<p><img src="https://cri.dev/assets/images/posts/mac-linux/brave.png" alt="brave"></p>
<h2>Editor</h2>
<p>VSCode + vim</p>
<h2>Miscellaneous</h2>
<ul>
<li>
<p>Ideogram for emoji picking (that’s important nowadays)</p>
</li>
<li>
<p><code>snap</code> + <code>apt</code> (perhaps flatpak in the future if I feel the need)</p>
</li>
<li>
<p><code>NewsBoat</code> as RSS reader</p>
</li>
</ul>
</div></div>]]>
            </description>
            <link>https://cri.dev/posts/2021-01-03-mac-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622969</guid>
            <pubDate>Sun, 03 Jan 2021 17:00:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modernizing the Law to Enable Electronic Wills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622878">thread link</a>) | @troydavis
<br/>
January 3, 2021 | https://willing.com/learn/modernizing-the-law-to-enable-electronic-wills.html | <a href="https://web.archive.org/web/*/https://willing.com/learn/modernizing-the-law-to-enable-electronic-wills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>This paper is endorsed by the <a href="https://willing.com/index.html" target="_blank" rel="noopener">Willing.com</a> Legal Advisory Board, whose members include Daniel L. Mosley, Robert H. Sitkoff, and John H. Langbein.</p>
<p><strong>A Note from Willing:</strong></p>
<p>Since launching in 2015, we heard from a lot of customers who struggled with the requirements for creating a will. They wanted to know: Can’t I just sign online, electronically? Can I store my will online with Willing?” In each case, the answer was no, unfortunately not — wills still live in the physical, pen-and-ink world, and their execution calls for the physical presence of witnesses and a notary.</p>
<p>We learned that the execution requirements were causing some people to procrastinate indefinitely when it came to making a will, or to make mistakes when signing that meant they hadn’t created a valid will when they thought they had. We wanted to come up with a solution. So, we worked with our Legal Advisory Board and other experts to examine the law in depth and think about how it could be updated to leverage technology while preserving its important functions. The result was this paper, which provided the foundation for our efforts to pass the Electronic Wills Act in a number of states.</p>
<p>As the legislation has moved along, we’ve heard both strong support and strong opposition. Naturally — and rightly — folks who practice in this area care a lot about getting it right. We also care a lot about getting it right, and to that end we welcome any and all input. We want nothing more than to have a constructive relationship with all interested parties, because we know it’ll make for better laws. If you’d like to engage with us, please do so by reaching out to <a href="mailto:ewills@willing.com">ewills@willing.com</a>.</p>
<h2>Abstract</h2>
<p>To make a valid will, all American states require a person to comply with a set of formalities that trace back to a pair of statutes enacted by Parliament centuries before the invention of the light bulb. These formalities generally require a will to be in writing, signed by the testator, and witnessed by at least two people. There are good reasons for requiring formalities to make a will. Nevertheless, the traditional will formalities have not adapted to an evolving technological context in which nearly all transactions—including massive end-of-life transfers under pension plans, brokerage accounts, life insurance policies, and the like—can be made electronically. Accordingly, this paper argues in favor of legislation authorizing electronic wills made in compliance with a set of electronic formalities suited to the modern age. These reforms would improve access to will-making while facilitating the integration of wills with the many other methods of deathtime transfer that operate outside the law of wills.</p>
<h2>I. INTRODUCTION</h2>
<p>Technology is everywhere in modern American life. Using computers, smartphones and tablets, people can purchase almost any conceivable item and communicate instantaneously with others around the world. At the same time, businesses have used technology to become more efficient and profitable, and governments have employed technology to serve their citizens more quickly, conveniently and effectively.<sup><a id="fnref1" href="#fn1">[1]</a></sup></p>
<p>The law has made these advances possible by actively fostering the use of technology in commerce. Statutes such as the Electronic Signatures in Global and National Commerce Act (“E-SIGN”), which Congress enacted in 2000, and the Uniform Electronic Transactions Act (“UETA”), which the Uniform Law Commission promulgated in 1999 and which has been enacted in nearly every state, have firmly established the principle that electronic documents and signatures should be given the same legal effect as paper and ink.<sup><a id="fnref2" href="#fn2">[2]</a></sup> Modern commercial life would be impossible without these statutes—they make it possible for people to do their banking online, purchase a book on <a href="http://amazon.com/">Amazon.com</a> and order an Uber car to pick them up.</p>
<p>The law governing the execution of wills is a notable exception to the technological and legal progress that has improved people’s lives in recent decades.<sup><a id="fnref3" href="#fn3">[3]</a></sup> In order to make a valid will, most American states require a person making a will (the “testator”) to satisfy three core “will formalities”: (1) <em>writing</em>—the will must be in the form of a writing;<sup><a id="fnref4" href="#fn4">[4]</a></sup> (2) <em>signature</em>—the will must be signed by the testator; and (3)&nbsp;<em>attestation</em>—the will must be signed by at least two witnesses, who attest to the testator’s signature.<sup><a id="fnref5" href="#fn5">[5]</a></sup> These three core formalities predate the invention of the light bulb—across the country, they have remained largely unchanged for hundreds of years and, as we will see, are not generally thought to apply to electronic media.</p>
<p>At the same time, a system parallel to the law of wills allows individuals to pass property at death without going through probate court or complying with the will formalities. “Nonprobate” modes of transfer, such as inter vivos trusts, life insurance, and transfer-on-death bank, brokerage and pension accounts contain the majority of Americans’ wealth,<sup><a id="fnref6" href="#fn6">[6]</a></sup> but are governed by other bodies of law, and thus are not subject to the will formalities.<sup><a id="fnref7" href="#fn7">[7]</a></sup> Because these other bodies of law have embraced technology to a greater extent than the law of wills—and in fact are subject to both E-SIGN and UETA, which validate electronic documents and signatures—electronic media are already familiar, and even sanctioned, in the context of the most common deathtime transfers. <sup><a id="fnref8" href="#fn8">[8]</a></sup></p>
<p>Yet there are good reasons for the will formalities. As we discuss below, the formalities are intended to provide evidence of the testator’s intent, caution him as to the significance of making a will and protect him from fraud and duress. They have endured in part because “[w]hen the court is asked to implement the testator’s intention, he will inevitably be dead and unable to authenticate or clarify his declarations.”<sup><a id="fnref9" href="#fn9">[9]</a></sup> In the technological age, however, when many other significant transactions (including nonprobate wealth transfers) can be made electronically, the question arises whether the formalities should adapt to accommodate digital execution.</p>
<p>We believe that the process of making and validating a will can be effectively translated into an electronic format that preserves the functions of the original formalities. This would bring the advantages of technology to bear on end‑of‑life planning, allowing more people to provide for a thoughtful disposition of their property at death. Accordingly, this paper will argue for laws expressly permitting electronic wills by way of a digital writing, signature and attestation (and, where applicable, electronic notarization) using well-established technologies already recognized in commercial contexts, including in the nonprobate system. In making this argument, we both (a)&nbsp;acknowledge the value of the formalities and their present inseparability from many states’ law of wills; and (b)&nbsp;endorse the sound policy of Congress, and of nearly every American state, that electronic documents and signatures should be treated exactly the same as paper documents and ink signatures—and we urge the application of that policy to the law of wills.</p>
<p>In Part&nbsp;II below, we discuss the ways property can be transferred at death, including the uses and benefits of wills. We continue in Part&nbsp;III to survey the history and policy basis of the will formalities. In Part&nbsp;IV, we identify trends in statutory and case law that suggest that jurisdictions in America and abroad are already moving toward the policies we endorse in this paper. We also discuss the prominent role of technology in the nonprobate system. We conclude in Part&nbsp;V by explaining how the will formalities can be adapted to the modern age and noting the many benefits of modernization.</p>
<h2>MODES OF PROPERTY SUCCESSION</h2>
<p>There are two main ways that property is transferred at death: (a)&nbsp;through the “probate system”, which is governed by the law of wills (or in the absence of a will, by the laws of “intestacy” discussed below), and (b)&nbsp;the “nonprobate system”, which is not governed by the laws of wills <em>or</em> intestacy, but rather by the law governing the mode of transfer at issue. As we will see, the nonprobate system has assumed a far greater importance in the last 50&nbsp;years—today, Americans are able to pass (and in many cases, <em>do</em> pass) virtually all of their property outside the probate system, without being required to comply with the safeguards of the will formalities. This “nonprobate revolution” points toward the legal and practical basis for the modernization of the will formalities that we endorse in this paper.</p>
<h3>Wills and the Probate System</h3>
<p>Under American law, “[p]roperty owners have the nearly unrestricted right to dispose of their property as they please”,<sup><a id="fnref10" href="#fn10">[10]</a></sup> both during their lives and at their deaths. This policy of “freedom of disposition” is the “organizing principle of the American law of succession”,<sup><a id="fnref11" href="#fn11">[11]</a></sup> and has been recognized by the U.S. Supreme Court as a Constitutionally protected property right.<sup><a id="fnref12" href="#fn12">[12]</a></sup> As the American Law Institute has stated, “American law does not grant courts any general authority to question the wisdom, fairness, or reasonableness of the donor’s decisions about how to allocate his property. The main function of the law of wills is to <em>facilitate</em> rather than <em>regulate</em>.”<sup><a id="fnref13" href="#fn13">[13]</a></sup> As Harvard Law School Professor Robert H. Sitkoff has described it:</p>
<p>“The American law of succession embraces freedom of disposition, authorizing dead hand control, to an extent that is unique among modern legal systems. Within the American legal tradition, a property owner may exclude his or her blood relations and subject his or her dispositions to ongoing conditions&nbsp;.&nbsp;.&nbsp;.&nbsp;The right of a property owner to dispose of his or her property on terms that he or she chooses has come to be recognized as a separate stick in the bundle of rights called property.”<sup><a id="fnref14" href="#fn14">[14]</a></sup></p>
<p>A will is the traditional legal tool that allows an individual to exercise his freedom of disposition. By making a will, a person can choose what happens to his property following his death—in other words, a will says <em>who</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willing.com/learn/modernizing-the-law-to-enable-electronic-wills.html">https://willing.com/learn/modernizing-the-law-to-enable-electronic-wills.html</a></em></p>]]>
            </description>
            <link>https://willing.com/learn/modernizing-the-law-to-enable-electronic-wills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622878</guid>
            <pubDate>Sun, 03 Jan 2021 16:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to open a file in Emacs: a story about Lisp, technology, and human progress]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25622756">thread link</a>) | @mpereira
<br/>
January 3, 2021 | https://www.murilopereira.com/how-to-open-a-file-in-emacs/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/how-to-open-a-file-in-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A short story about Lisp, technology, and human progress.</p><div><h2 id="part-one-a-lispy-adventure">Part One: A Lispy Adventure</h2><figure><img src="https://www.murilopereira.com/portals_short.jpg" alt="Figure 1: Arun Chanchal"><figcaption><p>Figure 1: <a href="https://www.behance.net/gallery/54991949/Photomanipulation-Portals">Arun Chanchal</a></p></figcaption></figure><p>I’ve recently joined a company that for security reasons doesn’t allow their
source code on laptops. Development happens strictly on workstations inside
their private networks, with some using their text editor’s support for
remote file editing and others running editors on those machines via SSH.</p><p>Adapting to this situation has indirectly led me into a bit of a rabbit
hole, forcing me to acknowledge my core values, better understand the
relation between progress and human flourishing, and ponder about the
question: why technology?</p><p><em>(Chapters are mostly self-contained.)</em></p><h3 id="the-computing-experience">The computing experience</h3><p>One of the oldest pieces of software still in use was recently described as</p><blockquote><p>A sort of hybrid between Windows Notepad, a monolithic-kernel operating
system, and the International Space Station.</p></blockquote><p>Of course, they were talking about Emacs. And yes, it is kinda true.</p><figure><img src="https://www.murilopereira.com/tron.jpg"></figure><p>I’ve been using Emacs for a while and had opportunities to use it to work
on projects in remote machines. There are a few quirks, but after changing
a setting here and there, <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/tramp/Quick-Start-Guide.html">Tramp</a> is mostly usable. Tramp makes it possible
to transparently treat remote directories, files, commands, and more, <em>as if
they were local</em>. Opening a remote buffer via <code>M-x find-file /ssh:user@remote-host:/some/project</code> and having tools like Magit and Eshell
work out of the box feels like magic.</p><p>I'm not aware of similar functionality in Vim, but VSCode users recently
got
<a href="https://code.visualstudio.com/docs/remote/remote-overview">something pretty close</a>.</p><p>Emacs runs either as a standalone graphical application (GUI) or in a
terminal emulator (TUI). In terms of features, GUI Emacs can be seen as a
superset of TUI Emacs. Among many other things, it makes it possible to
display:</p><ul><li>images, PDFs, rendered web pages (even YouTube!)</li><li>graphical popups (with code documentation, linting tips, compilation
errors, completion candidates, etc.)</li><li>heterogeneous fonts (distinct sizes, families, emphases, etc.)</li></ul><p>TUI Emacs has the terminal emulator (and also commonly tmux) limiting
and conflicting with the clipboard, keybindings, colors, and more. None of
these limitations are present in GUI Emacs.</p><p>For these and other reasons I use GUI Emacs and Tramp to work on remote
projects instead of TUI Emacs via SSH. Some do the opposite, and that’s
fine too! Even with the limitations shown above, TUI Emacs is very
powerful, and its performance in an SSH session is still superior to Tramp.</p><p>Even so, one might think displaying images in Emacs is not a big deal. Just
<code>open image.png</code> and get an actual image viewer application to render it,
right? Things get interesting in a remote Tramp buffer: <code>M-x find-file image.png</code> will display the <em>remote</em> image right there in your <em>local</em> Emacs
instance. Or in case you’re in a remote <em>dired</em> buffer, pressing <code>RET</code> on an
image file will do the same. It’s a non-disruptive workflow that allows one
to remain in the comfort of Emacs.</p><p>dired is a built-in file manager.</p><p>If you’re not an Emacs user, chances are the previous sentence doesn’t carry
much weight. <em>What’s good about staying inside Emacs</em>?</p><p>It is safe to assume that most of your <em>development</em>, or more broadly, your
<em>computing environment</em> is represented below:</p><ul><li>operating system (macOS, GNU/Linux distribution, Windows, etc.)</li><li>window manager (the one provided by your OS, i3, Openbox, XMonad, etc.)</li><li>terminal emulator (iTerm2, xterm, rxvt, alacritty, etc.)</li><li>shell (bash, zsh, fish, etc.)</li><li>terminal multiplexer (tmux, GNU Screen, etc.)</li><li>text editor or IDE (Vim, VSCode, Xcode, IntelliJ IDEA, etc.)</li><li>email, web browsing, multimedia, and communications</li></ul><p>Each item above is a discrete computer program. They’re extensible in
disconnected ways, and to varying degrees. They’re <em>islands</em>. Most of the
time integrating them is an uphill battle, and commonly just plain
impractical. Having used a computing environment centered around TUI Vim
and tmux for a decade, I know the pain of trying to make the shell, the
terminal, and every command line application running in it have the same
look, feel, and behavior of being inside Vim. It is impossible.</p><p>The emergence of the web browser as a software platform is in part an answer
to this disconnectedness.</p><p>In contrast, Emacs unifies and equalizes the computing experience as much
as one desires, so that it happens—and is extended—in a single,
cohesive environment.</p><figure><img src="https://www.murilopereira.com/alt_tab_small.jpg" alt="Figure 3: My computing environment."><figcaption><p>Figure 3: My computing environment.</p></figcaption></figure><p>People commonly <a href="https://www.reddit.com/r/emacs/comments/jjxatm/whats%5Fyour%5Fjob%5Fwhats%5Fyour%5Fdaily%5Femacs%5Fworkflow/">use Emacs</a> to process their email inbox, communicate in
chat, navigate the web, write code, and prose. At their core, these
activities are one and the same: text-editing. Being able to perform them
using the same keybindings and functionality for movement, search, text
manipulation, completion, undo-redo, copy-paste, is already a big deal, but
it’s not all: their integration into a single environment unlocks pleasant
and efficient workflows that would be much less convenient elsewhere.</p><p>Creating a to-do item for something your partner just asked you (while you
were concentrated on a task) that will show up automatically on your agenda
tomorrow? Just a few keystrokes and you’re back to the task. Converting
some text notes you quickly scribbled down into a beautiful PDF via LaTeX,
uploading it to S3, and referencing the URL in a reworded existing git
commit message? If you’re an experienced Emacs user, chances are you can
<em>visualize</em> effortlessly and efficiently executing these actions without ever
leaving Emacs.</p><p>This interconnectedness is part of the value of computing environments like
the one provided by Emacs. The whole becomes greater than the sum of its
parts.</p><p>Programmability gives it a further dimension of value: parts can be
combined as you see fit, in arbitrary and possibly unforeseen ways.</p><p>Now, back to the <em>displaying an image from a remote host</em> use case. For that,
I can think of some alternatives:</p><ul><li><code>scp</code> the image file between hosts and <code>open</code> it locally</li><li>Mount the remote filesystem and <code>open</code> it locally</li><li><code>ssh</code> into the remote host from a modern terminal emulator capable of
rendering images and use a program like <a href="https://sw.kovidgoyal.net/kitty/kittens/icat.html">icat</a></li></ul><p>In Emacs, you just press enter.</p><h3 id="opening-a-file">Opening a file</h3><p>At work I contribute to a moderately-sized monorepo at 70 thousand files,
8-digit lines of code and hundreds of PRs merged every day. One day I
opened a remote buffer at that repository and ran <code>M-x find-file</code>.</p><p><code>find-file</code> is an interactive function that shows a narrowed list
of files in the current directory, prompts the user to filter and scroll
through candidates, and for a file to open.</p><p>Emacs froze for <em>5 seconds</em> before showing me the <code>find-file</code> prompt. Which
isn’t great, because when writing software, opening files is actually
something one needs to do all the time.</p><figure><img src="https://www.murilopereira.com/find_file_linux.png"></figure><p>Luckily, Emacs is “the extensible, customizable, self-documenting real-time
display editor”, and comes with profiling capabilities: <code>M-x profiler-start</code>
starts a profile and <code>M-x profiler-report</code> displays a call tree showing how
much CPU cycles are spent in each function call after starting the profile.
Starting a profile and running <code>M-x find-file</code> showed that all time was being
spent in a function called <code>ffap-guess-file-name-at-point</code>, which was being
called by <code>file-name-at-point-functions</code>, an <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/emacs/Hooks.html#:~:text=A%20few%20hooks%20are%20abnormal,are%20used%20in%20some%20way.">abnormal hook</a> run when <code>find-file</code>
is called.</p><p>If you're familiar with Vim you can think of Emacs <i>hooks</i> as
Vim <i>autocommands</i>, only with much better ergonomics.</p><p>I checked the documentation for <code>ffap-guess-file-name-at-point</code> with <code>M-x describe-function ffap-guess-file-name-at-point</code> and it didn’t seem
to be something essential, so I removed the hook by running <code>M-x eval-expression</code>, writing the form below, and pressing <code>RET</code>.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>remove-hook</span> <span>'file-name-at-point-functions</span> <span>'ffap-guess-file-name-at-point</span>)
</code></pre></td></tr></tbody></table></div></div><p>This solved the immediate problem of Emacs blocking for 5 seconds every
time I ran <code>find-file</code>, with no noticeable drawbacks.</p><div><p>As I write this I attempt to reproduce the issue by re-adding
<code>ffap-guess-file-name-at-point</code>
to
<code>file-name-at-point-functions</code>.
I can't reproduce it anymore. The initial issue might have been</p><ul><li>caused by having manually mutated the Emacs environment via ad-hoc code
evaluation (drifting from the state defined in configuration)</li><li>caused by settings or packages that aren't in my configuration anymore</li><li>fixed by settings or packages that were recently added to my
configuration</li><li>fixed by some recent package upgrade</li></ul><p>Or some combination of the above. I have no idea exactly what.
Which is to say: maintaining Emacs configurations is complicated.</p></div><h3 id="searching-files">Searching files</h3><p>I could now navigate around and open files. The next thing I tried in this
remote git repository was searching through project files. The great
<em>projectile</em> package provides the <code>projectile-find-file</code> function for that,
but I had previously given up making projectile perform well with remote
buffers; given how things are currently implemented it seems to be
<a href="https://www.google.com/search?q=projectile+tramp">impractical</a>. So I installed the <em>find-file-in-project</em> package for use on
remote projects exclusively: <code>M-x package-install find-file-in-project</code>.</p><p>Most Emacs commands are accessible via key combinations, with defaults
that can be customized to be anything you want. I'll stick to referencing
command names themselves instead of their default keybindings.</p><p>Both <code>projectile-find-file</code> and <code>find-file-in-project</code> (aliased as <code>ffip</code>):</p><ul><li>show a narrowed list of all project files in the minibuffer</li><li>prompt the user to filter and scroll through candidates</li><li>open a file when <code>RET</code> is pressed on a candidate.</li></ul><figure><img src="https://www.murilopereira.com/projectile_find_file_linux.png"></figure><p>To disable projectile on remote buffers I had the following form in my
configuration.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>defadvice</span> <span>projectile-project-root</span> (<span>around</span> <span>ignore-remote</span> <span>first</span> <span>activate</span>)
  (<span>unless</span> (<span>file-remote-p</span> <span>default-directory</span> <span>'no-identification</span>) <span>ad-do-it</span>))
</code></pre></td></tr></tbody></table></div></div><p>Which causes the <code>projectile-project-root</code> function to not run its usual
implementation on remote buffers, but instead return <code>nil</code> unconditionally.
<code>projectile-project-root</code> is used as a way to either get the project root
for a given buffer (remote or not), or as a boolean predicate to test if
the buffer is in a project (e.g., a git repository directory). Having it
return <code>nil</code> on remote buffers effectively disables projectile on remote
buffers.</p><p>Emacs</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/how-to-open-a-file-in-emacs/">https://www.murilopereira.com/how-to-open-a-file-in-emacs/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/how-to-open-a-file-in-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622756</guid>
            <pubDate>Sun, 03 Jan 2021 16:32:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Futurist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622725">thread link</a>) | @user_235711
<br/>
January 3, 2021 | https://dawntrowelljones.com/2020/10/the-futurist/ | <a href="https://web.archive.org/web/*/https://dawntrowelljones.com/2020/10/the-futurist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-scaled.jpg"><img loading="lazy" src="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-1024x683.jpg" alt="" width="450" height="300" srcset="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-1024x683.jpg 1024w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-300x200.jpg 300w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-768x512.jpg 768w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-1536x1024.jpg 1536w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_215611859-cred-2048x1365.jpg 2048w" sizes="(max-width: 450px) 100vw, 450px"></a>Since childhood, I’ve been imagining the future. Maybe it’s a compulsion or a personality quirk. I actually have to make a point sometimes of focusing on the present. I’m older now and have more experiences under me – and I must say ever-expanding worries! – but at the same time, if the present becomes too much, there’s always the consolation that things will not stay this way. Times are troubling, and we can assume something’s out of whack, but it’s an encouraging thought that all unbalanced systems will try to right themselves. You knock a glass of water and the water will swish up the side of the glass, then swish up the other side, until natural processes bring it to rest.</p>
<p><a href="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-scaled.jpg"><img loading="lazy" src="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-741x1024.jpg" alt="" width="150" height="207" srcset="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-741x1024.jpg 741w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-217x300.jpg 217w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-768x1062.jpg 768w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-1111x1536.jpg 1111w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-1481x2048.jpg 1481w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_62246432-cred-scaled.jpg 1851w" sizes="(max-width: 150px) 100vw, 150px"></a>It’s my job as a futurist to imagine how events will swing in directions we’d consider positive and not-so-positive. Dystopian stories about the future are usually about things going wrong, a dismal failure, yet with hope. I have dabbled with dystopia, but to be really plausible, things can’t be going wrong for everyone – unless we’re talking about a cataclysm. Otherwise, there’s a lot of room between utopia and dystopia. They’re both unlikely.</p>
<p>Over time there will be mind-blowing innovations that never see full production or use because they interfere too much with the social systems in place. Do we want to serve our innovations or do we want to improve our lives? If there’s a highly fuel-efficient and reliable engine design patent with fewer movable parts in a black-box style case capable of disrupting a large segment of the working economy, which has fought and worked hard for its position, well, expect the patent to be bought and shelved. The product will never see the light of day. Though this may sound like a conspiracy theory, it’s already happened. But I want to say that you don’t need coordinated actors to get this kind of result. Usually, it’s a confluence of compatible drives toward an outcome that brings about great movements. Unrelated efforts may seem to have a single guiding hand, but sometimes streams just flow together and gouge out a river. They don’t have to intend to be a river to become one.</p>
<p><a href="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-scaled.jpg"><img loading="lazy" src="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-1024x684.jpg" alt="" width="250" height="167" srcset="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-1024x684.jpg 1024w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-300x200.jpg 300w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-768x513.jpg 768w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-1536x1025.jpg 1536w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_100959482-cred-2048x1367.jpg 2048w" sizes="(max-width: 250px) 100vw, 250px"></a>And sometimes the flow is siphoned off, takes a different channel, and it’ll feel like regression as the river bed dries up. Sometimes people lose faith in whatever beliefs hold them together, when their social systems stop being meaningful to them anymore – nobody knows why the Maya wandered away from their great cities, but I’ve heard this stated as one of the possibilities. When people walk off, they reassemble somewhere else in some other stylized fashion, reflective of the old ways but not the same. Keeping all this in mind, I may end up describing a future that appears simultaneously advanced and regressive. Cyberpunk, as a style, features technological advances with social disintegration. When I envision a future, I imagine it’ll be both technologically and socially more advanced and regressed. I expect we’ll make good and bad decisions. People will enjoy innovations and mostly integrate them, but not entirely. Sometimes the old ways will appeal more, particularly if the new ones are out of sync with basic human needs. We are a form of animal. We aren’t above nature. We’re a part of nature, and nature craves stability. We’ll sense imbalance, and sooner or later, we’ll correct for it. This is the strange dichotomy of cyberpunk, to my mind. But you could slice and dice less cleanly in a near-future tale.</p>
<p>If this looks like my side of a discussion I’ve already had with somebody, it’s because it is. My partner in the discussion was not wrong to suggest a “science-y” item I’d portrayed in a story was “retro” – it was, though the story also included other future technology on which the plot depended. This dichotomy was deliberate: I had to imagine a future where innovation had gone beyond where we are now, beyond where we expect to be, and still further, beyond a point where society would have taken a step back. The best quick real example I can come up with is the likely transformations facing social media, for in their current manipulative form they’re making people somewhat sick. All over the world, dangerously anxious. It’s like some sort of Harlow experiment (infant monkeys raised by wire cages) – there will likely be long-term ramifications because we won’t “check” the process in time. A rise and fall and then another rise. But I have no doubt that they are unsustainable as they are.</p>
<p>Like other authors, I take inspiration from works I’ve loved and apply some plain-old observations of human nature. Like myths, patterns will carry through. But I want to add to the discussion, if I can – to use other people’s imaginings as a launching pad, an intimation, an influence, or an aspect. Technologically and culturally, let’s say there’ll always be three steps forward and one or two back – setbacks, disruptions like war or even greater innovations too hard to assimilate but it takes us a minute to figure it out. Meanwhile “emergent” stuff’s going on! Emergence: that’s the most thrilling to me. It might be fair to say that my stories are about emergence. Something is born, a change. That’s the sort of futurist I am. Bad and good leads to good and bad, ad infinitum. Well, at least for some time. Barring cataclysm. It’s all about how and where to slice.</p>
<hr>
<p>As a side note, I’ve been able to pursue the venerable art of storytelling because my husband and I live somewhat cheaply. How did we learn to live so cheap? <em>The Great Recession</em>. See? Good can come from bad, even an experience as painful as that one was. (Of course, 2020 says, “Hold my beer….”) A positive mental outlook makes a tremendous difference, and we’ve been happy living lives that make sense to us. Out here on the fringe, perhaps. So, it amuses me to no end that we will likely continue thus humbly until one of my book darlings, my spiders, my own precious “children of time,” gets out there and earns me a decent living. Please and thank you!</p>
<p>I feel so Dickensian, saying that. Patience, patience.</p>
<p>Anyway, these are my thoughts – a little short and abstract, I know, but hopefully of interest. This is about as involved as I can handle at the moment, for politics and the state of the world have grown rather heavy to me and my brain does not want to let go. To try to write about those issues right now would be too depressing for both me and you, I think. I certainly don’t want to do that to you. Take care! And very importantly, be kind to yourself. I keep saying that, but I really mean it. If we can send magic (wink, wink) through the internet, then consider this a benediction, or a prayer.</p>
<p><a href="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-scaled.jpg"><img loading="lazy" src="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-1024x640.jpg" alt="" width="450" height="281" srcset="https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-1024x640.jpg 1024w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-300x188.jpg 300w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-768x480.jpg 768w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-1536x960.jpg 1536w, https://secureservercdn.net/50.62.194.59/324.700.myftpupload.com/wp-content/uploads/2020/10/2020-10-05-AdobeStock_312590249-cred-2048x1280.jpg 2048w" sizes="(max-width: 450px) 100vw, 450px"></a></p>
			</div></div>]]>
            </description>
            <link>https://dawntrowelljones.com/2020/10/the-futurist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622725</guid>
            <pubDate>Sun, 03 Jan 2021 16:28:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an IDE from scratch in 60 days]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622721">thread link</a>) | @joubert
<br/>
January 3, 2021 | https://skyalt.com/blog/sprint.html | <a href="https://web.archive.org/web/*/https://skyalt.com/blog/sprint.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="header2">
	<div>
<p>
<i>
In the <a href="https://skyalt.com/blog/repl.html">last article</a>, I wrote about the new IDE and programming language. It's just a prototype(not easy to read C code and many important features are missing), so the next logical move is to re-write it to the production-ready product.
</i></p><p><i>

Coincidentally, <a href="https://www.startupschool.org/">Startup school</a> is announcing YC Build Sprint, starting on August 24. My goal of the Sprint is to rewrite and launch SkyAlt. Can I build IDE in 4 weeks? Hell no, but maybe 8. Let's find out.
</i></p><p><i>

I will program in different fields. From rendering/UI, over network/cryptography, to parser/interpreter. Let the hacking begin!
</i></p></div>



	<h2>Week 1</h2>
	<div><p>
The first thing I wanna build is the ability to run SkyAlt on the server(run apps) and connect from a remote client(rendering, keyboard, mouse). For rendering, I chose SDL, mainly because it supports many operation systems. Network connections are TCP/IP handled by SDL_Net with simple custom protocol. Connections are encrypted. For that, I'm using functions from the OpenSSL library. The client needs a valid key to log-in.
</p><p>

The Protocol synchronize communication so the Client tells the server when it's ready for the next frame data. Also If the frame takes more time to finish, then Server tells the Client how much work on the frame was done and the Client shows the progress. The bottom-left conner shows FPS(frames per seconds) and bandwidth.
</p><p>

Rendering is bases on SDL2, SDL_image, SDL_ttf(fonts). It can draw rectangles, images, texts. The server sends only UTF-8 text, so fonts are on Client only. Every letter of the text is handled by my code(left, right, center align, ...). If apps include images(icons, ...), they are on the server, which sends (as files) them to the client's cache, where they are decompressed and converted into texture.
</p><p>

Also, I have one source code, but thanks to #define I can compile it like a Server(run apps) or a Client(remote, only rendering, mouse, keys) or a ClientServer(all inside).
</p><p>

By end of the week, I optimize the protocol cache for images and texts. Also, I clean up the code a little bit.
</p><p>

The video shows Client-Server where Server is sending commands(there are no apps, yet) what to draw to Client(window). Looks awful, but there is a lot of engineering behind it.
	</p></div>
	<video controls="" poster="https://skyalt.com/blog/sprint/3.png">
	<source src="https://skyalt.com/blog/sprint/3.mp4" type="video/mp4">
	</video> 



	<h2>Week 2</h2>
	<div><p>
The week starts with working on the dictionary. SkyAlt is dynamically-typed(static typing will be optional later, something like Javascript -&gt; Typescript) and the memory model is an associative array(dictionary data structure, every record has value and sub-records and so on). I chose this model because I care a lot about developer's experience and If you think about it, in statically typed language you have to start with designing data structures and if you run the program it does nothing because there are no algorithms and that's frustrating. I want SkyAlt users to start with algorithms right away and <b>thanks to REPL and preview they can see what they are making from the beginning</b>. Overall time to build an app is the same, but the experience is different.
</p><p>

The next day, I write and run a few extra tests for the dictionary and slowly pivot my focus into integrating the dictionary to the SkyAlt memory model(record - sub-records). I constantly think about performance vs memory footprint for the dictionary.
</p><p>

Then I write .json importer and exporter.
</p><p>


I start working on Parser for the SkyAlt language. I try to parse some simple source codes, fixing a few bugs and it seems to work. So for the next few days, I work on the Interpreter and improving parser as well. I run more and more advanced tests.
</p><p>

There was a problem with the order of parsing assets(files), when one app uses multiple assets and that assets use other assets and there can be cycles, but around an hour later I solve it.
</p><p>

The video shows allocating 10M records and creating 5 sub-records for everyone. Then it's computing summary of one sub-record: The first 'sum' is for pure implementation in C, the second 'sum' is for search sub-record through the dictionary. Then It's just deallocating memory.
	</p></div>
	<video controls="" poster="https://skyalt.com/blog/sprint/8.png">
	<source src="https://skyalt.com/blog/sprint/8.mp4" type="video/mp4">
	</video> 



	<h2>Week 3</h2>
	<div><p>
I start the week with implementing catching pressed keys, mouse buttons &amp; position on Client and sending them on Server. The great thing about SDL is that everything is UTF-8(across different OSs).
</p><p>

Then I try to compile code on Linux. I fixed a lot of bugs and many warnings(GCC is more aggressive than MSVC). I also optimized a few places in code so there is less (de)alloc every frame. FPS goes up. This is probably the worst day working on this project so far. So many things were broken.
</p><p>

The next day I focus on the UI layout system. Early on working on project I set that <b>content is more important than design</b>(layout, shapes, colors). So when you work with SkyAlt language, It's super easy to create GUI and define layouts under them, but of course there are tradeoffs. There is only one layout(grid layout), but it can expand/stretch(different screen sizes). I end up the day with a system where you can set column/row size and optional maximum size. Also, It's super easy for developers to change column/row size.
</p><p>

Implementing scrolling(mouse wheel, arrows, home/end/pageUp/pageDown) was quick since most of the parts already exist, so I only connect them together.
</p><p>

I start working on a Single-line editbox - text selection, copy/paste.
</p><p>


I finish the week by fixing bugs, few performance issues and cleaning the code. I'm not really making aggressive optimizations, because <b>I need to see the big picture first</b>. I also avoid multi-threading.
</p><p>

Sorry, I didn't make a video.
	</p></div>



	<h2>Week 4</h2>
	<div><p>
Ok, 4th week, here we come.
</p><p>

I had to rewrite code that handling layouts. It's using less memory, hopefully, bug-free and cleaner code.
</p><p>

I fixed text-align, working with keys and implemented dialogs(center screen or like a context menu). Also, You can change GUI theme colors.
</p><p>

The Info panel on the client shows server FPS. This is not the real number of frames computed, because it computes only frames which the client needs(max. 60), but it's a number of frames which the server is possible to compute.
</p><p>

I start working on the Multi-line editbox - text selection, copy/paste. You can also scroll text! Uff;)
</p><p>

The video shows work in progress Settings app, where you will be able to change language, theme, etc. You can also change the row size. That was just for testing purposes, I've removed it after capturing video.
	</p></div>
	<video controls="" poster="https://skyalt.com/blog/sprint/26.png">
	<source src="https://skyalt.com/blog/sprint/26.mp4" type="video/mp4">
	</video> 



	<h2>Week 5</h2>
	<div><p>
When you work hard for a few weeks, why not work harder?
</p><p>

When you change language, all assets are automatically re-parse. Also, You can put an image(file) into an asset folder and App can render it.
</p><p>

I've finished the Settings app from the previous week and make the Menu app(New/Open project, Settings, About, etc.). You can switch between Windowed / Fullscreen mode and save app(code, data, translations). Also I make the Translation app, where you can translate apps to different languages.
</p><p>

I rewrite how URL works: checking for cycles, safely removing records and better language syntax. I hope, I will not have to touch it again.
</p><p>

I implement Context help - when you move the mouse over the button, edit-box, etc. the description shows up with little delay.
</p><p>

I try making a more advanced version of multi-line edit-box to use it as a code editor. So I add line numbers, syntax highlighting, showing warnings/errors in code. I add auto-break lines that are longer than a view into Multi-line. Also work on selections: 2 clicks for selecting a word and 3 clicks for the line.
</p><p>

The next day I start implementing Folding. When you call a function in source-code, you can "expand" it and It will show you the body of the function.
</p><p>

I spend some time putting down CPU usage when the user is not active. When the user stops moving the mouse and pressing keys, it will go to 0%(no drawing) and every 5seconds it will go 0.2%(drawing one frame, so the user can see possible new/changed data) =&gt; minimum CPU clock speed. On another side, When the user is active, then it renders 60 frames per second and has a maximum CPU clock speed. That's how ImGui works. I will try to deal with that later.
</p><p>

I finally trace one stupid memory-leak which I knew of for over a week. I fixed save() when record(text) has quote character inside.
</p><p>

For the first time, my TODO list starts to become shorter.
</p><p>

The video shows basic code editor with (un)folding capability. There is a small bug which I fixed after making this video: when I unfold function, it unfolds all function with the same name.
	</p></div>
	<video controls="" poster="https://skyalt.com/blog/sprint/41.png">
	<source src="https://skyalt.com/blog/sprint/41.mp4" type="video/mp4">
	</video> 



	<h2>Week 6</h2>
	<div><p>
Still motivated, I'm not slowing down!
</p><p>

I start with the cleaning code from the previous week. I compile it for Linux and discover some new warnings in code and few bugs.
</p><p>

I implement accounts. You can log-in with a username and 128bits key. Also, the Client window remembers position and size when it's closed and opened again.
</p><p>

I work on REPL. You can Alt+click into code and it will execute code up to that line and show you in preview. You can also Alt+click into app preview and it will unfold code to the line which draws the part of the app. It works well and it's quick. Although it doesn't work very well when an app has more than one layer(context menu, dialogs). I'll back into that later.
</p><p>

I also fix not-precise syntax/error highlights and change syntax highlight colors. Also, I fix the saving/reading json file. This is quite normal, I change code in one part and in some cases, I will have to change some other parts of the code as well. That's why I optimize code only when it hurts because optimize code is harder to rewrite.
</p><p>

The video shows simple IDE, where you can edit code(left) and see a preview of the app(right). You can also see folding and REPL in action.
	</p></div>
	<video controls="" poster="https://skyalt.com/blog/sprint/49.png">
	<source src="https://skyalt.com/blog/sprint/49.mp4" type="video/mp4">
	</video> 



	<h2>Week 7</h2>
	<div><p>
On Monday, I noticed that If the code in SkyAlt language had errors, the Interpreter would still execute it. So I quickly fix that.
I also implement key shortcuts(copy, cut, paste, etc.) and text selection with arrows. Also, the parser will not run when you are …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://skyalt.com/blog/sprint.html">https://skyalt.com/blog/sprint.html</a></em></p>]]>
            </description>
            <link>https://skyalt.com/blog/sprint.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622721</guid>
            <pubDate>Sun, 03 Jan 2021 16:28:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discover MIDI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622628">thread link</a>) | @_han
<br/>
January 3, 2021 | https://imitone.com/discover-midi/ | <a href="https://web.archive.org/web/*/https://imitone.com/discover-midi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://imitone.com/discover-midi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622628</guid>
            <pubDate>Sun, 03 Jan 2021 16:17:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reveal, REPLs and Networking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622599">thread link</a>) | @tosh
<br/>
January 3, 2021 | https://vlaaad.github.io/reveal-repls-and-networking | <a href="https://web.archive.org/web/*/https://vlaaad.github.io/reveal-repls-and-networking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><time datetime="2021-01-02 00:00:00 +0000">January 02, 2021</time>
    
  </p>

  
  

  <p>I recently got a question whether it’s possible to configure <a href="https://vlaaad.github.io/vlaaad.github.io/reveal/">Reveal</a> in such a way that it works across 3 machines:</p>
<ul>
  <li>machine A runs editor;</li>
  <li>machine B runs only Reveal;</li>
  <li>machine C runs target server.</li>
</ul>

<p>It also reminded me of <a href="https://suvratapte.com/nREPL-middleware/">an article</a> I read awhile ago about nREPL middlewares that gives a good overview of how those work, but unfortunately contains a mistake in a section where it discusses Clojure REPL, where it states that:</p>

<blockquote>
  <p>there is no easy way to start this REPL on a socket. So if you are using this REPL, you cannot connect to it from remote machines. So the default REPL clearly cannot be used as your daily development REPL. That is where the need for other types of REPLs comes in.</p>
</blockquote>

<p>I enjoy using simple tooling, and REPL is a wonderful example of such a concept (it’s not a single tool really) that enables a variety of non-trivial use-cases. In this post I’ll try to explain what makes it special as well as give an example of using the configurability of REPL.</p>

<h2 id="what-repl-is-what-nrepl-isnt">What REPL is, what nREPL isn’t</h2>

<p>REPL is Read-Eval-Print Loop, a programming environment that enables you to interact with a running Clojure program and modify it by evaluating one code expression at a time. An important characteristic of REPL is that every part of REP is independent and thus swappable:</p>
<ul>
  <li><em>Read</em> is a protocol on character streams — one of the most widely available and simple transports. You can swap Read easily: consume from standart input, consume from network, consume from pre-recorded REPL interaction to replay it etc;</li>
  <li><em>Eval</em> is the full power of Clojure, and you can augment it when necessary by e.g. starting new REPLs with <a href="https://github.com/TristeFigure/lexikon/blob/master/src/lexikon/core.clj#L129-L148">lexical scope</a> which might be seen as a break point on steroids;</li>
  <li><em>Print</em> is a way to show the output of code evaluation to the user, by default it transforms values to text, but you can do much more than that with a tool like <a href="https://vlaaad.github.io/vlaaad.github.io/reveal/">Reveal</a> that acts as a REPL output panel that enables inspection and visualization super powers;</li>
</ul>

<p>nREPL, despite its name, is not a REPL, it’s a eval RPC server. It does not have independent Read Eval and Print concepts, instead its main building blocks are <a href="https://nrepl.org/nrepl/0.8/design/handlers.html">handlers</a>, <a href="https://nrepl.org/nrepl/0.8/design/transports.html">transport</a> and <a href="https://nrepl.org/nrepl/0.8/design/middleware.html">middlewares</a>. It’s a different model that, like REPL, gives some powers and takes some powers away. I personally find REPL model simpler, more powerful and more approachable, so I use it, but YMMV.</p>

<h2 id="starting-repl-socket-server">Starting REPL socket server</h2>

<p>It is trivial to start a REPL that can be reached from a remote machine, you won’t even need any external dependencies, it’s all there in <a href="https://clojure.github.io/clojure/clojure.core-api.html#clojure.core.server/start-server">clojure.core.server</a> namespace. The easiest way to start it is to specify a JVM property that <a href="https://clojure.org/reference/repl_and_main#_launching_a_socket_server">starts socket server</a> automatically on the JVM startup, but for simplicity we will call it directly as a function:</p>
<div><div><pre><code>clj <span>\</span>
<span>-X</span> clojure.core.server/start-server <span>\</span>
:name <span>'"repl"'</span> <span>\</span>
:port 5555 <span>\</span>
:accept clojure.core.server/repl <span>\</span>
:server-daemon <span>false</span>
</code></pre></div></div>
<p>This <a href="https://insideclojure.org/2020/09/04/clj-exec/">clj-exec</a> invocation supplies all required args to <code>clojure.core.server/start-server</code> fn:</p>
<ul>
  <li><code>:name</code> is a server identifier that can be used to stop the server;</li>
  <li><code>:port</code> is a socket REPL port;</li>
  <li><code>:accept</code> is a symbol indicating a repl function.</li>
</ul>

<p>Remaining <code>:server-daemon</code> argument is needed to keep the JVM running while REPL server is active, you won’t need this argument if you are using <code>start-server</code> from the REPL.</p>

<p>If you are unfamiliar with clj-exec, this invocation is analogous to a following clojure form:</p>
<div><div><pre><code><span>(</span><span>clojure.core.server/start-server</span><span>
  </span><span>'</span><span>{</span><span>:name</span><span> </span><span>"repl"</span><span>
    </span><span>:port</span><span> </span><span>5555</span><span>
    </span><span>:accept</span><span> </span><span>clojure.core.server/repl</span><span>
    </span><span>:server-daemon</span><span> </span><span>false</span><span>})</span><span>
</span></code></pre></div></div>

<h2 id="connecting-to-remote-socket-repl">Connecting to remote socket REPL</h2>

<p>You can connect to it using <code>nc</code> and start sending forms:</p>
<div><div><pre><code>nc localhost 5555
user=&gt; (+ 1 2 3)
6
</code></pre></div></div>
<p>How about nesting REPLs to connect to this REPL server from another clojure REPL? There is no built-in way to do it, but the implementation of <a href="https://github.com/vlaaad/remote-repl">REPL client</a> is less than 50 lines of code, thanks to the simplicity of REPL concept. Let’s try it out:</p>
<div><div><pre><code>clj \
-Sdeps '{:deps {vlaaad/remote-repl {:mvn/version "1.1"}}}'
Clojure 1.10.1
user=&gt; (require '[vlaaad.remote-repl :as rr])
nil
user=&gt; (rr/repl :port 5555)
;; at this point, forms sent to the repl are evaluated in the remote process
user=&gt; clojure.core.server/*session*
{:server repl, :client "1"}
user=&gt; :repl/quit
;; now we are back to evaluating in our local process.
nil
user=&gt; 
</code></pre></div></div>



<p>How about using Reveal to connect to this server? Reveal is a tool that needs structured REPL output to process it properly, it can’t really work on REPL prompts like <code>user=&gt;</code>. There is <a href="https://oli.me.uk/clojure-socket-prepl-cookbook/">prepl</a> (programmable REPL), which is a socket REPL with output structured as edn maps — bread and butter of Clojure. To connect Reveal to remote socket REPL server it needs to be a prepl, like that:</p>
<div><div><pre><code>clj <span>\</span>
<span>-X</span> clojure.core.server/start-server <span>\</span>
:name <span>'"repl"'</span> <span>\</span>
:port 5555 <span>\</span>
:accept clojure.core.server/io-prepl <span>\</span>
:server-daemon <span>false</span>
</code></pre></div></div>
<p>If you are curious how this REPL’s output looks like, here is an example at the command line:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {vlaaad/remote-repl {:mvn/version "1.1"}}}'</span> <span>\</span>
<span>-X</span> vlaaad.remote-repl/repl <span>\</span>
:port 5555

<span>(</span>+ 1 2 3<span>)</span>
<span>{</span>:tag :ret, :val <span>"6"</span>, :ns <span>"user"</span>, :ms 9, :form <span>"(+ 1 2 3)"</span><span>}</span>
</code></pre></div></div>
<p>Reveal can talk to this prepl server out of the box with its <a href="https://vlaaad.github.io/reveal/#remote-prepl">remote-prepl</a>:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {vlaaad/reveal {:mvn/version "1.2.182"}}}'</span> <span>\</span>
<span>-X</span> vlaaad.reveal/remote-prepl <span>\</span>
:port 5555

<span>(</span>+ 1 2 3<span>)</span>
<span>{</span>:tag :ret, :val 6, :ns <span>"user"</span>, :ms 2, :form <span>"(+ 1 2 3)"</span><span>}</span>
</code></pre></div></div>
<p>Console output is the same, but there is now a Reveal window that shows evaluations results:</p>

<p><img src="https://vlaaad.github.io/assets/2021-01-02/remote-prepl.png" alt=""></p>

<h2 id="reveal-clients-clients">Reveal client’s clients</h2>

<p>Now, lets get back to the original question of having REPL configuration where editor is on machine A, Reveal on machine B and target process on machine C. We already have most of the pieces laid out, the only missing part is how to setup reveal to run as a server that is itself a client, and that part is <code>:args</code> — additional arguments to a repl function specified by <code>:accept</code> symbol.</p>

<p>Lets setup it piece by piece. I’ll use everything on the same machine because I’m lazy, but the real world example will differ only in having to specify <code>:host</code> in addition to <code>:port</code> in clients. Here is machine C with ClojureScript prepl just for fun:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {org.clojure/clojurescript {:mvn/version "1.10.764"}}}'</span> <span>\</span>
<span>-X</span> clojure.core.server/start-server <span>\</span>
:name <span>'"cljs"'</span> <span>\</span>
:accept cljs.server.browser/prepl <span>\</span>
:port 5555 <span>\</span>
:server-daemon <span>false</span>
</code></pre></div></div>

<p>Machine B, that uses Reveal to connect to C while acting as a REPL server:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {vlaaad/reveal {:mvn/version "1.2.182"}}}'</span> <span>\</span>
<span>-X</span> clojure.core.server/start-server <span>\</span>
:name <span>'"reveal"'</span> <span>\</span>
:accept vlaaad.reveal/remote-prepl <span>\</span>
:args <span>'[:port 5555]'</span> <span>\</span>
:port 6666 <span>\</span>
:server-daemon <span>false</span>
</code></pre></div></div>

<p>Finally, we can connect from machine A to machine B on port <code>6666</code>, and that will make it open a Reveal window with connection to machine C:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {vlaaad/remote-repl {:mvn/version "1.1"}}}'</span> <span>\</span>
<span>-X</span> vlaaad.remote-repl/repl <span>\</span>
:port 6666
</code></pre></div></div>
<p>Evaluating code like <code>js/window</code> on machine A will make ClojureScript evaluate code in the browser on machine C and send it to machine B where Reveal will show the output:</p>

<p><img src="https://vlaaad.github.io/assets/2021-01-02/cljs-prepl.png" alt=""></p>

<h2 id="conclusion">Conclusion</h2>

<p>Once I’ve got the simplicity of REPL, I’ve got a lot more power at my disposal, with a significantly smaller cognitive footprint and improved understanding of underlying stack (e.g. Clojure evaluation semantics). If you don’t know it, you don’t know it; if you know it, you enjoy it.</p>

<p>What do you think?</p>


</div>




    </div></div>]]>
            </description>
            <link>https://vlaaad.github.io/reveal-repls-and-networking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622599</guid>
            <pubDate>Sun, 03 Jan 2021 16:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure? (2018)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 169 (<a href="https://news.ycombinator.com/item?id=25622528">thread link</a>) | @bribri
<br/>
January 3, 2021 | https://briansunter.com/blog/why-clojure/ | <a href="https://web.archive.org/web/*/https://briansunter.com/blog/why-clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper" data-testid="home"><main id="main"><section id="container-centre"><div><p>Why not the programming language I'm already using or some other language? What makes Clojure uniquely well suited for modern software development?</p><ul><li>Pure functions and immutable data are the easiest units of software to reason about</li><li>Deep support for immutable data structures</li><li>S-Expressions (parens) are re-usable and composable</li><li>Great support for destructuring, pattern matching, and working with maps in general</li><li>Most "features" from other languages can be added as extensions via macros or in terms of the language itself. Polymorphism, "types", inheritance, pattern matching, "go channels"</li><li>Interactive Programming: extremely fast feedback loop and experimentation with the REPL</li><li>Powerful and simple testing due to emphasis on pure functions and values</li><li>Good interop with the worlds most popular languages: Java and Javascript</li><li>Excellent concurrency support: immutability, software transactional memory, "Go Channels" (CSP), agents, everything in the JVM/Java</li><li>Subjectively good design - Strong notions of things like time, identity, state, and equality</li></ul><p>Instead of mutating objects, Clojure encourages you to use immutable data structures. In many languages you create a mutable array object and append to it.</p><pre><code><span>var</span> myArray <span>=</span> <span>[</span><span>'one'</span><span>,</span> <span>'two'</span><span>,</span> <span>'three'</span><span>]</span><span>;</span><p><span>function</span> <span>addOne</span><span>(</span><span>item</span><span>)</span> <span>{</span><br>  myArray<span>.</span><span>push</span><span>(</span>item<span>)</span><span>;</span><br><span>}</span></p><p>myArray</p></code></pre><p>We mutate the original array.</p><pre><code><span>addOne</span><span>(</span><span>'four'</span><span>)</span><span>;</span><br>myArray</code></pre><p>In Clojure, whenever you "append" to a vector (array) you get a "new" vector and the original does not change. Anyone with a reference to the original can always count on it being the same.</p><pre><code><span>(</span><span>def</span> my-vector <span>[</span><span>"one"</span> <span>"two"</span> <span>"three"</span><span>]</span><span>)</span><br>my-vector</code></pre><p><code>conj</code> returns a new vector with the arguments appended.</p><pre><code><span>(</span><span>def</span> my-new-vector <span>(</span><span>conj</span> my-vector <span>"four"</span><span>)</span><span>)</span><br>my-new-vector<br></code></pre><p>The original vector is unchanged.</p><pre><code>my-vector<br></code></pre><p>Functions like <code>reverse</code> return a new vector, rather than mutating the original.</p><pre><code><span>const</span> myArray <span>=</span> <span>[</span><span>"one"</span><span>,</span> <span>"two"</span><span>,</span> <span>"three"</span><span>]</span><span>;</span><br>myArray<span>.</span><span>reverse</span><span>(</span><span>)</span><span>;</span><p>myArray</p></code></pre><pre><code><span>(</span><span>def</span> my-vector <span>[</span><span>"one"</span> <span>"two"</span> <span>"three"</span><span>]</span><span>)</span><br><span>(</span><span>reverse</span> my-vector<span>)</span><br></code></pre><p>Our original vector is unchanged.</p><pre><code>my-vector</code></pre><p>This encourages us to use compositions of functions instead of functions that mutate objects. The benefit of this might not be immediately obvious, but this shift encourages writing programs in a way that's simpler. Programs made up of small reusable components are easier to change later. We just need to focus on the scope of the function, the inputs, and the outputs. We don't need to worry about prior state.</p><p>The first thing you will notice in Clojure is how many parens there are and how dense the code is. It takes some getting used to, but the parens have a lot of benefits.</p><p>We can always rewrite syntax repetition with macros and there are plenty of techniques for reducing the number of parens including "threading" operators like <code>-&gt;&gt;</code>. The following is equivalent to the header.</p><pre><code><span>(</span><span>-&gt;&gt;</span> but<br>     there<br>     are<br>     so<br>     many<br>     parens<span>)</span></code></pre><p>Function calls are different in Clojure than most languages. It is represented by a list where the first element is the function and the rest are the arguments to that function.</p><pre><code><br><span>(</span><span>defn</span> my-function<br>  <span>[</span>arg1 arg2<span>]</span><br>  <span>(</span><span>str</span> arg1 arg2<span>)</span><span>)</span><p><span>(</span>my-function <span>"first"</span> <span>"second"</span><span>)</span></p></code></pre><p>The syntax is extremely regular. It's natural to wrap a function in another function.</p><pre><code><span>(</span>my-function <span>(</span>my-function <span>"first"</span> <span>"second"</span><span>)</span> <span>"third"</span><span>)</span></code></pre><p>Since all functions including built in functions are called the same way, it's easy to swap any function out with another, including built-ins.</p><pre><code><span>(</span><span>if</span> <span>(</span><span>=</span> <span>42</span> <span>42</span><span>)</span> <span>"True"</span> <span>"False"</span><span>)</span><br><span>(</span>my-if <span>(</span><span>=</span> <span>42</span> <span>42</span><span>)</span> <span>"True"</span> <span>"False"</span><span>)</span></code></pre><p>The parens replace a lot of the curly brace notation in other languages.</p><pre><code><span>function</span> <span>myFunction</span><span>(</span><span>arg1<span>,</span> arg2</span><span>)</span> <span>{</span><br>  <span>if</span> <span>(</span>arg1<span>)</span> <span>{</span><br>    <span>return</span> arg1<span>;</span><br>  <span>}</span> <span>else</span> <span>{</span><br>    <span>return</span> arg2<span>;</span><br>  <span>}</span><br><span>}</span></code></pre><pre><code><span>(</span><span>defn</span> my-function<br>  <span>[</span>arg1 arg2<span>]</span><br>  <span>(</span><span>if</span> <span>(</span><span>not</span> <span>(</span>blank? arg1<span>)</span><span>)</span><br>     arg1<br>     arg2<span>)</span><span>)</span></code></pre><p>Go has support for asynchronous "go channels" due to special syntax baked into the language. Clojure added the same features and syntax as a third party library. In Javascript you have to wait for syntax to be adopted or use a transpiler but in Clojure it could by implemented by anyone as a library.</p><pre><code>messages <span>:=</span> <span>make</span><span>(</span><span>chan</span> <span>string</span><span>)</span><br><span>go</span> <span>func</span><span>(</span><span>)</span> <span>{</span> messages <span>&lt;-</span> <span>"ping"</span> <span>}</span><span>(</span><span>)</span><br>msg <span>:=</span> <span>&lt;-</span>messages<br>fmt<span>.</span><span>Println</span><span>(</span>msg<span>)</span></code></pre><pre><code><span>(</span>def c <span>(</span><span>chan</span> <span>10</span><span>)</span><br><span>(</span><span>go</span> <span>(</span><span>&gt;</span><span>!</span> c <span>"hello"</span><span>)</span><span>)</span><br><span>(</span><span>println</span> <span>(</span><span>&lt;</span><span>!</span><span>!</span> c<span>)</span><span>)</span></code></pre><p>Clojure is really good at extracting data from maps and sequences. It is a really good for "data programs", that are mostly calling an API, transforming a sequence, and calling another API.</p><h2>Positional Destructuring</h2><pre><code><span>(</span><span>def</span> large-list '<span>(</span><span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span> <span>8</span> <span>9</span> <span>10</span><span>)</span><span>)</span><br><span>(</span><span>let</span> <span>[</span><span>[</span><span>a</span> <span>b</span> <span>c</span><span>]</span> large-list<span>]</span><br>  <span>(</span><span>str</span> <span>a</span> <span>b</span> <span>c</span><span>)</span><span>)</span></code></pre><h2>Destructuring with named optional parameters and defaults</h2><pre><code><span>(</span><span>defn</span> configure <span>[</span><span>val</span> options<span>]</span><br><span>(</span><span>let</span> <span>[</span><span>{</span><span>:keys</span> <span>[</span>debug verbose<span>]</span><br>       <span>:or</span> <span>{</span>debug <span>false</span><span>,</span> verbose <span>false</span><span>}</span><span>}</span> options<span>]</span><br><span>(</span><span>str</span> <span>"val="</span> <span>val</span> <span>" debug="</span>debug <span>" verbose="</span>verbose<span>)</span><span>)</span><span>)</span><p><span>(</span>configure <span>"foo!"</span> <span>{</span><span>:debug</span> <span>true</span><span>}</span><span>)</span></p></code></pre><p>Having a fast feedback loop is crucial to be productive. When I first started programming I would write some code, compile, then manually test my changes, maybe with a debugger. Then I discovered TDD with an auto test runner, which gave me a faster feedback loop, since I could be reasonably confident my program worked without having to recompile for every change. The fastest feedback loop I've discovered so far is the Clojure REPL with editor integration. With Emacs and CIDER I can execute code in my editor as I write it. Having a fast feedback loop for exploratory coding before writing tests helps me be a lot more productive and write higher quality code. Other languages also have REPLs but I feel Clojure is uniquely well suited to this workflow because of its immutable functional nature.</p><p>Testing is simpler when most things are maps and pure functions. This is an example from the "Gilded Rose Kata".</p><pre><code>    <span>@Test</span> <span>public</span> <span>void</span><br>        <span>BackstagePassQualityControl</span> qualityControl <span>=</span> <span>new</span> <span>BackstagePassQualityControl</span><span>(</span><span>)</span><span>;</span><p>    <span>shouldNeverIncreaseQualityToMoreThanFifty</span><span>(</span><span>)</span> <span>{</span><br><span>Item</span> backstagePass <span>=</span> <span>anItem</span><span>(</span><span>)</span><br>                <span>.</span><span>withName</span><span>(</span>BACKSTAGE_PASS_ITEM_NAME<span>)</span><br>                <span>.</span><span>build</span><span>(</span><span>)</span><br>        backstagePass<span>.</span><span>setSellIn</span><span>(</span>FIVE_DAYS<span>)</span><span>;</span><br>        backstagePass<span>.</span><span>setQuality</span><span>(</span><span>50</span><span>)</span><span>;</span></p><p>        qualityControl<span>.</span><span>updateQualityFor</span><span>(</span>backstagePass<span>)</span><span>;</span></p><p>        <span>assertThat</span><span>(</span>backstagePass<span>.</span><span>getQuality</span><span>(</span><span>)</span><span>,</span> <span>is</span><span>(</span><span>50</span><span>)</span><span>)</span><span>;</span><br>    <span>}</span></p></code></pre><pre><code><span>(</span><span>def</span> max-quality-pass<br>  <span>{</span><span>:quality</span> <span>50</span><br>   <span>:sell-in</span> <span>5</span><span>}</span><span>)</span><p> <span>(</span>deftest test-backstage-pass-peak<br>  <span>(</span>testing <span>"Quality never goes over 50"</span><br>    <span>(</span>is <span>(</span><span>=</span> <span>50</span> <span>(</span><span>:quality</span> <span>(</span>i/update-item max-quality-pass<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span></p></code></pre><p>Clojure has good interop with the worlds most popular languages. You can tap into the Java ecosystem for foundational libraries like the AWS SDK or database clients. Clojurescript has an excellent wrapper around React called Reagent. You can write your entire stack in Clojure, meaning a single person can be extremely productive. The interop story isn't perfect though: although it works technically, the difference between the programming models does have some friction. This can usually be solved by writing a wrapper.</p><pre><code><span>(</span>System/getProperty <span>"java.vm.version"</span><span>)</span></code></pre><p>Now that Moore's Law is ending, we can't rely on speed increases of a single core anymore. We need to write code that can take advantage of multiple cores and that can correctly run in parallel. I don't feel good about using some languages like Python or Javascript that are single inherently single threaded. Languages like Java or C++, which weren't designed with concurrency in mind are hard to use correctly. Clojure's data structures are thread safe by default and it has numerous concurrency primitives. The language design de-emphasis the us of state and emphasizes the use of values instead.</p><p>I initially disliked clojure coming from my semi strongly typed Java and C++. If you use types you have to consider their downsides and the cost of the coupling introduced by type information flowing through your program. After using Clojure, I find things like the "builder pattern" contrived. There is usually only a few types of true "data" and the rest of the program are subsets and combinations of the data, which don't always deserve an explicit name or type. I feel using languages that encourage classes encourages you to make abstractions too early, and making the wrong abstraction is much worse than repetition. A lot of the "bugs" you catch at compile time are often self inflicted bookeeping mistakes due to the increased complexity. I think testing is a much stronger form of software validation and will catch the errors that types would have.</p><p>The design choices and tradeoffs in Clojure were made deliberately. There are much fewer sharp edges and historical accidents in Clojure than any other language I've used. Clojure is opinionated on the way you write software but if you buy into that opinion, using pure functions and immutable data structures, the experience is very streamlined.</p><p>I remember having to learn the difference between comparing primitives and objects in Java. Code like this feels unintuitive.</p><h2>Equality</h2><pre><code><span>Integer</span> a <span>=</span> <span>new</span> <span>Integer</span><span>(</span><span>1</span><span>)</span><span>;</span><br><span>Integer</span> b <span>=</span> <span>new</span> <span>Integer</span><span>(</span><span>1</span><span>)</span><span>;</span><p><span>if</span> <span>(</span>a <span>==</span> b<span>)</span><span>{</span><br>  <span>System</span><span>.</span>out<span>.</span><span>println</span><span>(</span><span>"True"</span><span>)</span><br><span>}</span> <span>else</span> <span>{</span><br>  <span>System</span><span>.</span>out<span>.</span><span>println</span><span>(</span><span>"False"</span><span>)</span><br><span>}</span></p><p><span>if</span> <span>(</span>a<span>.</span><span>equals</span><span>(</span>b<span>)</span><span>)</span><span>{</span><br>  <span>System</span><span>.</span>out<span>.</span><span>println</span><span>(</span><span>"True"</span><span>)</span><br><span>}</span> <span>else</span> <span>{</span><br>  <span>System</span><span>.</span>out<span>.</span><span>println</span><span>(</span><span>"False"</span><span>)</span><br><span>}</span></p></code></pre><p>Comparing object equality is almost never what I want to do and I don't think it's a good default behavior.</p><pre><code><br><span>(</span><span>{</span>foo<span>:</span> <span>"bar"</span><span>}</span> <span>===</span> <span>{</span>foo<span>:</span> <span>"bar"</span><span>}</span><span>)</span></code></pre><p>This does what I expect, and I don't need to know the difference between <code>=</code>, <code>equals</code>, <code>==</code>, <code>===</code>, <code>deepEqual</code>, and <code>deepStrictEqual</code>.</p><pre><code><span>(</span><span>=</span> <span>{</span><span>:foo</span> <span>"bar"</span><span>}</span> <span>{</span><span>:foo</span> <span>"bar"</span><span>}</span><span>)</span></code></pre><p>There is only <code>=</code> for structural equality and no assignment operator. The only <code>false</code> value is <code>nil</code> and everything else is <code>true</code>.</p><h2>Polymorphism without classes</h2><p>Clojure is described as having "polymorphism a la carte", which means it has the benefits of inheritance and interface without being forced to use it and without many of the downsides.</p><p>In Java, we could do something like this to represent a shape that can be extended in other areas of the program.</p><pre><code><span>abstract</span> <span>class</span> <span>Shape</span> <span>{</span><br>    <span>public</span> <span>double</span> <span>area</span><span>(</span><span>)</span> <span>{</span><br>        <span>return</span> <span>0</span><span>;</span><br>    <span>}</span><br><span>}</span><p><span>class</span> <span>Rectangle</span> <span>extends</span> <span>Shape</span> <span>{</span><br>    <span>protected</span> <span>int</span> width<span>,</span> height<span>;</span></p><p>    <span>public</span> <span>Rectangle</span><span>(</span><span>int</span> width<span>,</span> <span>int</span> height<span>)</span> <span>{</span><br>        <span>this</span><span>.</span>width <span>=</span> width<span>;</span> <span>this</span><span>.</span>height <span>=</span> height<span>;</span><br>    <span>}</span></p><p>    <span>public</span> <span>double</span> <span>area</span><span>(</span><span>)</span> <span>{</span><br>        <span>return</span> width <span>*</span> height<span>;</span><br>    <span>}</span><br><span>}</span></p><p><span>class</span> <span>Triangle</span> <span>extends</span> <span>Shape</span> <span>{</span><br>    <span>protected</span> <span>int</span> a<span>,</span> b<span>,</span> c<span>;</span></p><p>    <span>public</span> <span>Triangle</span><span>(</span><span>in…</span></p></code></pre></div></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://briansunter.com/blog/why-clojure/">https://briansunter.com/blog/why-clojure/</a></em></p>]]>
            </description>
            <link>https://briansunter.com/blog/why-clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622528</guid>
            <pubDate>Sun, 03 Jan 2021 16:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Is My UDP Packet? – Finding Packet Drop Location]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25622436">thread link</a>) | @ahmetozer
<br/>
January 3, 2021 | https://ahmetozer.org/Finding-Packet-Drop-Location.html | <a href="https://web.archive.org/web/*/https://ahmetozer.org/Finding-Packet-Drop-Location.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-Finding-Packet-Drop-Location" class="page" role="article"><header><p> <time datetime="2021-01-02T00:00:00+00:00">02 Jan 2021</time> on <span>Blog</span></p></header><p><img src="https://ahmetozer.org/uploads/2021/where-is-my-packet.jpg" alt="route"></p><p>Yesterday I write a blog about finding outgoing and incoming latency data with <a href="https://github.com/ahmetozer/uping">uping</a>.</p><p>While testing the program with different ports, I have an issue with port 53.<br> You know port 53 is used for DNS, maybe ISP or data center apply a rule for the safer network. Let’s try to look a path is anyone drops my packet. I execute traceroute command to the server with port 53.<br> <img src="https://ahmetozer.org/uploads/2021/2021-01-02-1.jpg" alt="route"><br> Seems like a no problem but for a now.</p><p>Does the packet arrive at the server? To ensure, I inspect my server traffic with tcpdump. <img src="https://ahmetozer.org/uploads/2021/uping-error.jpg" alt="route"><br> The packets are arrived into the server and responded without any error.<br> So I also tested in different Source IP which is announced in UK (in real, Ip is physically located in Marmaris). It does not have any issue, it means port 53 is not closed for everyone in my server.</p><h2 id="where-is-my-packet">Where is My Packet?</h2><p>We see the packet in tcpdump, so my packets drop at between server to the client which is an incoming path for client.<br> Let’s look at it.<br> <img src="https://ahmetozer.org/uploads/2021/2021-01-02-2.jpg" alt="route"></p><p>It seems like has a problem. In normal, the packet will be arriving 18th hop but in this time it does not arrive. Here are other packets.<br> <img src="https://ahmetozer.org/uploads/2021/2021-01-02-3.jpg" alt="route"></p><p>17th hop is my home router, so the problem is happening at 15th or 16th hop.</p><p>Here is full route path, I also draw route path on maps and added as an image beginning of this post.</p><div><div><pre><code><span>        &gt; Istanbul (Gayrettepe Turknet) &gt; Sofia (Cogent) &gt; Belgrade (Cogent) &gt; Vienna (Cogent) &gt; Munich (Cogent) &gt; Frankfurt (Cogent) &gt; Amsterdam (Cogent) &gt;</span>
client                                                                                                                                                        Server
        &lt; Istanbul (Gayrettepe Turknet) &lt; Istanbul (Acibadem TurkTelekom)                       &lt; Frankfurt (TurkTelekom) &lt; Level3 (Frankfurt) &lt; Amsterdam &lt;
</code></pre></div></div><h3 id="but-why">But WHY?</h3><p>Port 53 is used for DNS and Port 53 is a sweet port for non protected servers to use as reflection attacks. 15th or 16th hop is my Service provider and they might apply a white list for port 53.</p><p>Let’s control this idea.<br> I temporally run <code>socat</code> for forwarding Port 53 is to common Public DNS server on the server-side.</p><div><div><pre><code>docker run <span>-it</span> <span>--rm</span> <span>--network</span> host ahmetozer/cna socat UDP4-RECVFROM:53,fork UDP4-SENDTO:1.1.1.1:53
</code></pre></div></div><p>On the client side, I execute nslookup for testing.</p><div><div><pre><code><span>$ </span>nslookup example.com server
Server:         research1.sv.local
Address:        research1.sv.local#53

Non-authoritative answer:
Name:   google.com
Address: 216.58.214.14
Name:   google.com
Address: 2a00:1450:400e:804::200e
</code></pre></div></div><p><img src="https://media.giphy.com/media/k6r6lTYIL9j9ZeRT51/giphy.gif" alt="Wait a second"></p><p>So what happened my other packets?</p><p>If the port sensitive for data it means very great firewall between me and server (16th hop) to check is it real DNS question or all packets forwarded to some proxy.</p><p>It is another post and I will write in this week.</p><p>I hope you liked this blog. If so don’t forget to share, stay safe and see you next blog.</p></article></div>]]>
            </description>
            <link>https://ahmetozer.org/Finding-Packet-Drop-Location.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622436</guid>
            <pubDate>Sun, 03 Jan 2021 15:54:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Statusline Generator]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622416">thread link</a>) | @montalbano
<br/>
January 3, 2021 | https://tdaly.co.uk/projects/vim-statusline-generator/ | <a href="https://web.archive.org/web/*/https://tdaly.co.uk/projects/vim-statusline-generator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <div><p>
          statusline preview:</p>
        </div>
        <hr>
        
        
        
      </div>
      <p>
        .vimrc code:<br>
        
      </p>
      <p>To see what colours your environment can use, run this command in vim <span>:run syntax/colortest.vim</span></p>
    </div></div>]]>
            </description>
            <link>https://tdaly.co.uk/projects/vim-statusline-generator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622416</guid>
            <pubDate>Sun, 03 Jan 2021 15:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to make New Year's resolutions work for you]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622400">thread link</a>) | @MatysekM
<br/>
January 3, 2021 | https://www.deprocrastination.co/blog/how-to-make-new-years-resolutions-work-for-you | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-make-new-years-resolutions-work-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/consistency_confidence_0_tw.png" alt="How to make New Year’s resolutions work for you" referrerpolicy="no-referrer"></p><p><strong>Most New Year's resolutions fail</strong>. To be precise, it’s around 80%.&nbsp;<a href="https://www.inc.com/marla-tabaka/why-set-yourself-up-for-failure-ditch-new-years-resolution-do-this-instead.html#:~:text=Seriously%2C%20you%20are%20rare%20indeed,is%20in%20the%20tradition%20itself.">[1]</a></p><p>Why do people still repeat something that mostly doesn’t work?</p><p>Because people love the concept of a fresh start.</p><p>From a certain date,&nbsp;<em>I’ll change my life, I’ll lose weight, start a business, I’ll be perfect</em>.</p><p>Can you hear the hope in this? Even if we’re unsatisfied with the current state of things, we can see our future brighter. Even if we’re fat and currently eating the 5th donut, we can feel somehow good about ourselves because we’re planning to stop doing this after a certain date.</p><p>The problem with resolutions is that we overestimate our abilities and time available in the future. We think that in the future we'll have much more time than right now. We make this mistake because we think about our future plans only in vague and unclear terms, but we’ll be probably just as busy as we are now.</p><p>We also think that our willpower will be much stronger than now. We think we won’t give up this time. It will be different.</p><p>This lets us get away with being lazy now and not trying. We basically throw all the effort on our future selves. However, when the date arrives and it’s time to change, most of us can’t do it.</p><p>Even if the previous paragraphs might sound discouraging, we still think that New Year’s resolutions can work. Drawing a thick line behind your past is helpful in changing yourself.</p><p>However, you need to think about New Year’s resolutions differently.</p><h2>How to make New Year’s resolutions work</h2><h3>1. Don’t say what the hell</h3><p><a href="https://www.deprocrastination.co/blog/how-to-start-working-after-you-procrastinated-the-whole-day">As we’ve covered here</a>, when people screw up something (like their diet) they say&nbsp;<em>what the hell</em>&nbsp;and binge eat everything.</p><p>This is the common reason why New Year’s resolutions fail. Once people fail at doing their new chosen behavior, they start thinking that it doesn’t matter now, and stop trying (or resume their bad habits again).</p><p>For example, people create a complicated “perfect” morning routine: Wake up at 6 am, do yoga for 15 minutes, write in a diary, take a cold shower... A few days in, they don’t wake up on time and they say:&nbsp;<em>I failed to wake up on time, my routine can’t be perfect anymore,</em>&nbsp;and they don’t do anything else. But it doesn’t have to be that way.</p><p>Let’s say you decide you finally want to start publishing your blog posts and you commit to writing for 30 minutes every day. You’re two weeks in and you forgot to write yesterday. Most people will be really mad about not writing yesterday and many will say:&nbsp;<em>I screwed up, I didn’t follow the plan</em>, and then they don’t write that day or the next day, and then stop writing altogether.</p><p><strong>However, you don’t need to be perfect. That wasn’t the goal. The goal was to publish on your blog. You can still do that. Missing one day doesn’t mean anything in the long run.</strong></p><p>If you fail, forgive yourself and instead of saying&nbsp;<em>what the hell</em>, resume right now or the next day.</p><p>At this point in time, you might also not feel like you want to get after the original goal anymore. In this case, examine why you wanted to achieve the goal in the first place. Weak or impersonal reasons often lead to abandoning it rather quickly.</p><p>That’s why you should only choose to change the most painful things or pursue the things you want the most. Reasons like I heard it’s good for my career, my family wants me to do it, or it’s good to know multiple languages won’t cut it. Your reasons for changing should be strong and personal.</p><p>When you have strong reasons for why you wanted to change, you realize that doing anything at all is better than doing nothing. You understand that you don’t have to say&nbsp;<em>what the hell</em>&nbsp;because the goal wasn’t to be perfect, but better.</p><h3>2. Know that difficult times will come</h3><p><a href="https://www.deprocrastination.co/blog/how-to-change-yourself">As we’ve covered in How to change yourself</a>, the first wave of inspiration and motivation runs out eventually. This is when the real progress happens.</p><p>In the beginning, when everything is going great, we start wearing rose tinted glasses that make us overestimate our ability to control and change ourselves.</p><p>We think that we know it all.</p><p>The bad news is that after the first thrill runs out (usually takes a week or two), it gets more difficult. This is also when most people fail.</p><p>When it gets more difficult, that’s when you need to use your discipline to stick through with the behavior.</p><p>We tell you this not to discourage you, but to help you stay realistic. When you know that there will be some hard days, you won’t be surprised. Many people quit because they think everything will go smoothly and then they hit an obstacle and bail.</p><p>The good news is, if you stick with your new behavior for 3-4 weeks, it will become significantly easier later on.</p><p>Expect that you’ll need to use your willpower to&nbsp;<a target="_blank" href="https://www.deprocrastination.co/blog/3-tricks-to-start-working-despite-not-feeling-like-it">act despite not feeling motivated.</a></p><h3>3. Mindset shift: Start thinking about helping your future self</h3><p>When the difficult times come, we often get into a mindset of despising the endeavors we’ve decided to pursue. We feel like we&nbsp;<em>have to</em>&nbsp;do them and we don’t want to. We would rather do something easy like watching Netflix, playing video games, or checking social media.</p><p>You already know that you should remind yourself why you wanted to make a change in the first place. However, sometimes even this doesn’t help. Certain activities that are beneficial for you in the long term don’t feel great in the moment.</p><p>There is a simple mindset shift that can make hard things easier to do:&nbsp;<strong>You’re helping your future self.</strong></p><p>When you start thinking about helping your future self, instead of thinking about just suffering now with no payoff, everything gets easier.</p><p>Think about it in this way: Whenever you procrastinate, you make things harder for your future self. There isn’t a way to escape responsibilities forever. On the other hand, if you start working consistently, you make it easier for your future self. Additionally, your future self will eventually become your present self. It’s still you after all.</p><p>Everything you are or have is the result of the choices your past self made for you.</p><p>Eating healthy so you’re not fat?&nbsp;<em>Thank your past self for that.</em></p><p>Learned a valuable skill and can get a job easily?&nbsp;<em>Thanks, past me, I can buy nice things.</em></p><p>Finished a task ahead of deadline?&nbsp;<em>Great, I can now enjoy free time.</em></p><p>Next time, you feel like you don’t feel like working, remind yourself that every task you do successfully will help your future self. And when you get to that point in the future, you'll feel proud of the choices you made.</p><h3>4. Become accountable to someone</h3><p>One of the easiest ways to stick with a behavior is by becoming accountable to someone else.</p><p>We think we can hold ourselves accountable, but that often fails in reality. We’re great at coming up with rationalizations for why we ate that cake, skipped that workout, or checked social media in the middle of our workday.</p><p>I didn’t do it because ____________. We can always come up with good reasons for why we didn’t do something. We do this to protect our conscience because we don’t like to face the truth.</p><p>When you become accountable to someone else, however, rationalizations become way more difficult. The other person can easily tell whether you’re bullsh*ting or not.</p><p>Here are some ways to use accountability to your advantage.</p><h4>1. Take on a new habit with a friend</h4><p>One frequent use of this is the "gym buddy system." It can be hard to get ourselves to do a hard activity like working out, and commit to it.</p><p>However, if we make a pact with a friend to show up every Monday, Wednesday, and Friday after work and do a workout, we add a bit of extra pressure that helps us actually show up. We don't want to disappoint our friend, do we?</p><p>Do you have a friend who wants to do something you also want to do? Working out, journalling, studying...?</p><p>Make an agreement, set a time, and hold each other accountable!</p><h4>2. Make a bet</h4><p>Another way to motivate yourself can be making a bet.</p><p>You can also do this with friends or you can use a service like&nbsp;<a href="https://www.stickk.com/">StickK</a>or&nbsp;<a href="https://www.beeminder.com/">Beeminder.com</a>.</p><p>Both services allow you to place a financial bet - if I don't do X, I will lose X money.</p><p>Beeminder gets data from a variety of sources - you can set a goal of writing a certain number of words every day or running X miles and connect it to Google docs or Strava, and if you don't honor your commitment, you'll lose money.</p><p>Sometimes pressure is productive. Want to heighten the stakes? Make a bet.</p><h4>3. Join Deschool program</h4><p>If you want to get serious about this,&nbsp;<a href="https://www.deprocrastination.co/program">join our Deprocrastination Deschool.</a>&nbsp;We'll hold you accountable and help you make the changes you need to make.</p><p>We’re launching the next run on the 4th of January.</p><p>First, we will help you figure out why you procrastinate.</p><p>Then each week, we'll help you find 1-2 changes that you can make to improve your productivity and procrastinate less. If you enroll, we'll personally help you improve your habits and decisions around productivity.</p><p>You will overcome procrastination step by step and we will make sure that you stay accountable and fulfil your New Year’s resolutions.</p><p><a href="https://www.deprocrastination.co/program">Find out more here</a>&nbsp;if you're interested.</p><h2>Summary</h2><p>Here's how to make New Year's resolutions actually work:</p><ol><li><p>Don't say what the hell</p></li><li><p>Know that difficult will come</p></li><li><p>Mindset shift: Start thinking about your future self</p></li><li><p>Become accountable to someone</p><ol><li>Take on a new habit with a friend</li><li>Make a bet</li><li>Join the Deschool program</li></ol></li></ol><p>If you promise yourself that you'll change, make sure you set yourself up to win, not fail.</p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-make-new-years-resolutions-work-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622400</guid>
            <pubDate>Sun, 03 Jan 2021 15:47:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to read a query plan from Postgres EXPLAIN]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622190">thread link</a>) | @deafcalculus
<br/>
January 3, 2021 | http://www.sagargv.com/blog/how-to-read-postgres-explain/ | <a href="https://web.archive.org/web/*/http://www.sagargv.com/blog/how-to-read-postgres-explain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><em>Dec 31, 2020</em></p>
<p>Got a web app responding too slowly because of a database query?
The query plan is what you'd want to look at.
Let's look at the execution plan that Postgres shows you when you
use the EXPLAIN statement and see how to interpret that.</p>
<p>The <a href="https://www.postgresql.org/docs/9.4/using-explain.html">Postgres documentation on using EXPLAIN</a>
is excellent, but I thought writing a concise version will serve as a note to my future self.
To start off, let's run with a simple schema of three tables: (a) Users,
(b) Articles, and (c) Orders.</p>
<pre><code>users:
 id |      email
----+------------------
  1 | jon@example.com
  2 | Jane@example.com
</code></pre>

<pre><code>articles:
 id |    name
----+-------------
  1 | Playstation
  2 | Xbox
</code></pre>

<pre><code>orders:
 id | user_id | article_id | qty
----+---------+------------+-----
  1 |       1 |          1 |   2
  2 |       1 |          2 |   1
  3 |       2 |          1 |   4
  4 |       2 |          2 |   3
</code></pre>

<p>Suppose we want to query the <code>users</code> table by the email address, the plan that
postgres generates is:</p>
<pre><code>EXPLAIN SELECT * FROM users WHERE email='jon@example.com';
---------------------------------------------------------------------------------
 Index Scan using users_email_index on users  (cost=0.15..8.17 rows=1 width=222)
   Index Cond: ((email)::text = 'jon@example.com'::text)
</code></pre>

<p>Since we have an index on the email column, postgres has decided to use that
to search the users table. If we didn't have that index, it would do a sequential
scan over the entire table:</p>
<pre><code>EXPLAIN SELECT * FROM users WHERE email='jon@example.com';
----------------------------------------------------------
 Seq Scan on users  (cost=0.00..14.00 rows=2 width=222)
   Filter: ((email)::text = 'jon@example.com'::text)
</code></pre>

<p>To get all the orders of a user, the query plan is:</p>
<pre><code> EXPLAIN SELECT *
    FROM orders
    INNER JOIN users
        ON orders.user_id=users.id
    WHERE users.email='jon@example.com';
------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.30..40.57 rows=6 width=238)
   -&gt;  Index Scan using users_email_index on users  (cost=0.15..8.17 rows=1 width=222)
         Index Cond: ((email)::text = 'jon@example.com'::text)
   -&gt;  Index Scan using orders_userid_index on orders  (cost=0.15..32.31 rows=9 width=16)
         Index Cond: (user_id = users.id)
</code></pre>

<p>What's going on here? First, postgres is using the index on the email column
to search the users table for users for email jon@example.com.
For each matching row (we expect a single matching row in this example),
an index scan is performed over the orders table get all orders for that user id.
Translated to pseudocode:</p>
<pre><code>for user in users.filter(email='jon@example.com'): # uses the email index
    for order in orders.filter(user_id=user.id): # uses the userid index
        yield (user, order)
</code></pre>

<p>Now, let's try joining all the three tables to get the full details of all the orders of a user:</p>
<pre><code>EXPLAIN SELECT *
    FROM orders
    INNER JOIN users
        ON orders.user_id=users.id
    INNER JOIN articles
        ON orders.article_id=articles.id
    WHERE users.email='jon@example.com';
------------------------------------------------------------------------------------------------
 Nested Loop  (cost=0.45..41.71 rows=6 width=460)
   -&gt;  Nested Loop  (cost=0.30..40.57 rows=6 width=238)
         -&gt;  Index Scan using users_email_index on users  (cost=0.15..8.17 rows=1 width=222)
               Index Cond: ((email)::text = 'jon@example.com'::text)
         -&gt;  Index Scan using orders_userid_index on orders  (cost=0.15..32.31 rows=9 width=16)
               Index Cond: (user_id = users.id)
   -&gt;  Index Scan using articles_pkey on articles  (cost=0.15..0.19 rows=1 width=222)
         Index Cond: (id = orders.article_id)
</code></pre>

<p>This is similar to joining the two tables, but we have another loop to join the third table.
In pseudocode, this is what's going on:</p>
<pre><code>for user in users.filter(email='jon@example.com'): # uses the email index
    for order in orders.filter(user_id=user.id): # uses the userid index
        for article in articles.filter(id=order.article_id): # uses article_id primary key
            yield (user, order, article)
</code></pre>

<p>Instead of an index scan, you might come across a bitmap heap scan like this:</p>
<pre><code> EXPLAIN SELECT *
    FROM orders
    INNER JOIN users
        ON orders.user_id=users.id
    WHERE users.email='jon@example.com';
----------------------------------------------------------------------------------------
 Nested Loop  (cost=4.37..23.02 rows=6 width=238)
   -&gt;  Index Scan using users_email_index on users  (cost=0.15..8.17 rows=1 width=222)
         Index Cond: ((email)::text = 'jon@example.com'::text)
   -&gt;  Bitmap Heap Scan on orders  (cost=4.22..14.76 rows=9 width=16)
         Recheck Cond: (user_id = users.id)
         -&gt;  Bitmap Index Scan on orders_userid_index  (cost=0.00..4.22 rows=9 width=0)
               Index Cond: (user_id = users.id)
</code></pre>

<p>In a plain index scan, postgres fetches a row pointer from the index and immediately
fetches that row from the table. But with a bitmap index scan, all the tuple pointers
that match the filtering condition are gathered and an in-memory bitmap data structure
is created. From this, the actual tuples in the table are visited in physical location order.
This improves locality of accesses to the table and matters a lot for spinning rust HDDs but
can also help with SSDs too. What's that "recheck condition"? If the bitmap gets large,
postgres converts it to a lossy bitmap that stores only physical pages instead of individual
tuples. So when the tuples are read from the physical pages, postgres has to recheck which
tuples in that page match the filtering condition. Bitmap scans also do well when there
are multiple filtering conditions using ORs and ANDs since the bitmap data structure supports
these operations efficiently.</p>
<p>Postgres collects statistics about the content of the tables. If it expects very few rows
to match the filtering condition, an index scan is preferred. If many rows are expected to
satisfy the filtering condition, a bitmap scan is preferred. If a substantial portion of the table
is likely to be fetched, the sequential scan wins. One of the authors of Postgres, Tom Lane, has
an email thread on <a href="https://www.postgresql.org/message-id/12553.1135634231@sss.pgh.pa.us">this topic</a>.</p>
<p>The <a href="https://stackoverflow.com/a/49024533">three types of joins</a> you're likely to come across in a
query plan are: (a) Nested loop join, (b) Hash join, and (c) Merge join. For example, here is a hash join:</p>
<pre><code> EXPLAIN SELECT *
    FROM orders
    INNER JOIN users
        ON orders.user_id=users.id
    WHERE users.email='jon@example.com';
--------------------------------------------------------------------
 Hash Join  (cost=14.03..47.45 rows=12 width=238)
   Hash Cond: (orders.user_id = users.id)
   -&gt;  Seq Scan on orders  (cost=0.00..28.50 rows=1850 width=16)
   -&gt;  Hash  (cost=14.00..14.00 rows=2 width=222)
         -&gt;  Seq Scan on users  (cost=0.00..14.00 rows=2 width=222)
               Filter: ((email)::text = 'jon@example.com'::text)
</code></pre>

<p>The hash join can be used only when the join condition is the equality operator.
Postgres constructs an in-memory hash table of the filtered users and scans the
orders table and retains those tuples which have a matching user id in the
constructed hash table.</p>
<p>The nested loop is the preferred option when at least one side of the join has very
few matching tuples. Hash join is used when both sides of the join have a large number of tuples.
Merge join is preferred when both sides of the join are large but can be sorted on the joining
condition using an index.</p>
<p>All the SQL statements used in this article are <a href="http://www.sagargv.com/blog/how-to-read-postgres-explain/explain.sql">here</a>.</p>
<p>PS</p>
<p>Check out <a href="https://www.getpause.com/">Pause</a>, a leave tracking app that I'm helping to build</p>
<hr>
<p>
    <a href="http://www.sagargv.com/blog/">Archive</a> ·
    <a href="http://www.sagargv.com/blog/atom.xml">RSS</a> ·
    <a href="http://eepurl.com/doq18z" rel="nofollow" target="_blank">Mailing list</a>
</p>

        </div></div>]]>
            </description>
            <link>http://www.sagargv.com/blog/how-to-read-postgres-explain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622190</guid>
            <pubDate>Sun, 03 Jan 2021 15:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chessformer: A Grid-Based Puzzle Platformer with Chess Pieces]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622174">thread link</a>) | @ArtWomb
<br/>
January 3, 2021 | https://rob1221.itch.io/chessformer | <a href="https://web.archive.org/web/*/https://rob1221.itch.io/chessformer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="community_topic_posts_widget_45000"><div><div data-post="{&quot;user_id&quot;:3788504,&quot;id&quot;:2381692}" id="post-2381692"><div><a href="https://itch.io/profile/omakoto"></a><div><p>Great puzzle game!&nbsp;&nbsp;I love it. Suggestion -- I&nbsp;played it on a phone and accidentally hit the reset / back buttons multiple times. It'd be great if there's a confirmation. Also, please add undo! The last stage was very annoying because of these problems..</p></div></div></div><div data-post="{&quot;user_id&quot;:2373852,&quot;id&quot;:2374748}" id="post-2374748"><div><a href="https://itch.io/profile/michele123"></a><div><p>I was waiting for this! Nice puzzle.</p></div></div></div><div data-post="{&quot;user_id&quot;:1171980,&quot;id&quot;:2372758}" id="post-2372758"><div><a href="https://itch.io/profile/k4d3nv4nc137"></a><div><p>Wake me up when the YouTube walkthroughs arrive.</p></div></div></div><div data-post="{&quot;user_id&quot;:3338482,&quot;id&quot;:2372282}" id="post-2372282"><div><a href="https://itch.io/profile/dorianmariefr"></a><div><div><p>stuck at lvl 12, those pawns are annoying</p>
<p>edit: go it, not moving them too much and the tower can pass-through</p>
<p>edit: now lvl 16, hmmm, i can't even think of a possible exit</p>
<p>edit: got it, thought of an exit with the tower first and made it with a three pieces column</p><p>edit: now 21, no idea except to get the key easy</p></div></div></div></div><div><div data-post="{&quot;user_id&quot;:1396358,&quot;id&quot;:2372698}" id="post-2372698"><div><a href="https://itch.io/profile/henrycgs"></a><div><p>It's really easy to get the key in 21. Just use the tower to press the button (get on the platform then drop onto the button) and move the king to the left and get off the button temporarily so the king can cross the gap.</p></div></div></div></div><div data-post="{&quot;user_id&quot;:1652589,&quot;id&quot;:2372138}" id="post-2372138"><div><a href="https://itch.io/profile/dsdevs"></a><div><div><p>I didn't intend to, but I played the whole thing in one session, I got so into it!</p>
<p>The concept is great and works really well, but the game is also very well polished and thought out, great job.</p>
<p>The difficulty balance is almost perfect. A few of the puzzles had me scratching my head, but I was never frustrated.</p>
<p>My only critique is that the sound that plays when you get to promote a pawn doesn't really work for me. It doesn't go with the music, and is a bit jarring. That's it, though. Other than that I loved it!</p><p>I also really appreciate the mobile support, it works well with a touch screen.</p></div></div></div></div><div data-post="{&quot;user_id&quot;:839108,&quot;id&quot;:2372032}" id="post-2372032"><div><a href="https://itch.io/profile/mdotedot"></a><div><p>Very Nice! One of your best once!</p></div></div></div><div data-post="{&quot;user_id&quot;:2963123,&quot;id&quot;:2371629}" id="post-2371629"><div><a href="https://itch.io/profile/cin316"></a><div><p>Wow, this game is really great!&nbsp; The mechanics are simple but create an intuitive&nbsp; and fun puzzle game.&nbsp; The levels are well designed and introduce the game mechanics well.&nbsp; I especially like level 10.</p></div></div></div><div data-post="{&quot;user_id&quot;:3157094,&quot;id&quot;:2370905}" id="post-2370905"><div><a href="https://itch.io/profile/ab0minable"></a><div><p>Interesting but cool game!</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://rob1221.itch.io/chessformer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622174</guid>
            <pubDate>Sun, 03 Jan 2021 15:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Stop Endless Discussions]]>
            </title>
            <description>
<![CDATA[
Score 313 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25622149">thread link</a>) | @candost
<br/>
January 3, 2021 | https://candost.blog/how-to-stop-endless-discussions/ | <a href="https://web.archive.org/web/*/https://candost.blog/how-to-stop-endless-discussions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>I often see people believe in their solution and think theirs are better than the others'. They defend their cases without having an exact reason. These situations often create long and meaningless discussions that go nowhere. Often they result in conflicts and people being offended by others' behavior.</p><p>Some people take action and implement their idea. Act fast, fail fast, and learn quicker. But this doesn't work when two or more people discuss how to implement a change or use new hyped technology. When people only talk a bit and implement a new hype, it often ends up with resentment. When we act and embrace failing that fast, we cannot keep someone accountable.</p><p>On the other hand, some people try to get everyone's confirmation to implement something that affects a large group. This strategy doesn't work either. Because it's impossible to get everyone on the same page, each person has a different opinion. When we try convincing everyone, we cannot implement anything at all. We just talk, and decisions come later than we need.</p><p>That's why we need to balance both taking action and asking people to present their opinion on a topic. This balance is achievable with an excellent process. I helped build this balanced process in an organization where we aimed to solve another problem - the lack of feedback. We introduced a process called <strong>Request For Comments (RFC). </strong>It is a common feedback mechanism in the software world presented by the Internet Society (ISOC) and used currently in the Rust language.</p><p>The RFC process uses a document written by someone about their proposal on a topic. It has <strong>a specific timeframe</strong> and <strong>everyone can give feedback</strong> on it. The RFC and feedbacks are posted <strong>publicly</strong>. Everyone can join the discussion. The goal is to include as many people as possible to access more points of view and spread the knowledge simultaneously. The good thing is that people focus on the proposed idea and give their feedback based on facts instead of only beliefs. On the other hand, it has a way bigger effect.</p><p>While the initial goal of the RFC is collecting feedback, I think it achieves a way more significant benefit by only <strong>writing the document itself</strong>. Writing shapes thoughts. Everyone has an opinion on any topic. But people who write their ideas form them into great content that is based on the facts.</p><p>Writing helps to clear the mind. When we write on any topic, we separate our proposal from ourselves. It's still part of us. But since we plan to present it to the public and leave it there forever, we start being careful. And most of the time, we are not starting with blank white paper.</p><p>The RFC processes use either a template or follow one standard style in documents. The aim is to help the authors to explain their plan in a structured way and, at the same time, make giving feedback easier. Each section of the document has its own goal, which helps separate the intent from the idea in a certain way.</p><p>We used <a href="https://web.stanford.edu/class/educ303x/wiki-old/uploads/Main/SRI_NABC.doc">the NABC model from Stanford</a>. The model starts with defining the <em><strong>N</strong></em>eed, followed by <em><strong>A</strong></em>pproach, <em><strong>B</strong></em>enefits, and lastly, <em><strong>C</strong></em>ompetitors. Separating the Need from the Approach is very smart. While writing the need, the authors have to understand it very well. The approach and benefits sections are pretty straightforward, where authors define their strategy and list down the advantages. Since most people focus on them when they talk about ideas, it's also easy to write. Then the competition section comes. It is the part the authors have to consider competitors of their proposal. Thinking about an alternative solution instead of their suggestion requires people to focus on the problem instead of blindly loving and defending their solutions. With these four parts, the NABC is a pretty good model. But it's not the only one.</p><p>Everyone has different needs. Therefore the formats might differ. Our manager at work also came up with a way more straightforward structure with only four questions to answer. It was only for our team, while the engineering department had the RFC process for a wider audience.</p><p>The RFCs have another effect on the organization. The process seeks a <strong>consent-based </strong>environment,<strong> not a consensus-based </strong>one. If some people care about a topic a lot and come up with a written document that explains many things in detail, everyone can (and should) trust them. The authors shouldn't wait for everyone's confirmation of their proposal. When they get enough feedback, they should be able to continue further with or abandon the idea. It's their decision. Since they prepared the doc and collected many comments on it, they can have a better judgment.</p><p>The process brings <strong>accountability</strong>, as well. Whoever writes the proposal should be kept accountable. When people know that they will be accountable, they tend to approach more carefully and consider different aspects seriously. Holding someone accountable doesn't mean that there will be a blame in case of failure. It only means that they have to follow up on their proposals, make sure it results in some way, and answer questions on the way. Also, most of the time, the RFC process is separated from the implementation process. While the author is accountable for the RFC itself, the implementation can be done by different people, and the RFC author might not be involved in it at all.</p><p>These hidden gems of writing the idea in a structured way and asking people for comments afterward prevents many endless debates. The culture changes with it as well. Instead of endless debates, we create discussions and solutions based on facts. The process prevents people from talking and doing nothing. Even though the RFC process might not be perfect itself, writing is enough to halt the endless and meaningless discussions. It also helps build trust in the community. So, if you are new to the RFC system, start with writing down your proposal. I'm pretty sure that the result will be way better than expected.</p><hr><p>Check out the comments on <a href="https://news.ycombinator.com/item?id=25622149">HackerNews</a>.</p><hr><p><em>Cover Photo by <a href="https://unsplash.com/@30daysreplay">30daysreplay Marketingberatung</a> on <a href="https://unsplash.com/">Unsplash</a></em></p>
            </div></div>]]>
            </description>
            <link>https://candost.blog/how-to-stop-endless-discussions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622149</guid>
            <pubDate>Sun, 03 Jan 2021 15:07:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Diagrams 2.0 for Mac – Beta Testers Wanted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25622134">thread link</a>) | @lukaskubanek
<br/>
January 3, 2021 | https://diagrams.app/blog/announcing-diagrams-2 | <a href="https://web.archive.org/web/*/https://diagrams.app/blog/announcing-diagrams-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-fb5b0f28bd71f240bdf3"><p>For the past few months, we’ve been working hard on the next big update for <em>Diagrams</em>, and today we’re announcing <em>Diagrams 2.0 Macaw!</em> Read on to learn more about the upcoming changes.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1608210356524_22353"><p><em>Diagrams 2.0</em> is a new milestone for the app in terms of functionality. The update takes its name from the macaw, a beautiful parrot with vibrant, colorful feathers. Just as macaws come in a variety of colors, you’ll be able to apply an extended pool of colors to your diagrams. And in addition to the introduction of new color variations and text formatting options, we rethought the customization workflow from the ground up.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1608210356524_71943"><p>With <em>Diagrams 2.0</em>, you’ll be able to use different palettes. When creating a diagram, you can start with one of the preset palettes or create your own palette from scratch. Each document will have its own set of types in the palette, which can be edited, allowing you to create as many different element and relationship combinations as you need. You’ll no longer be limited to four colors of each shape!</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1608210356524_75334"><div><p>Whether you want to do some simple brainstorming with just a few boxes, or create complex technical diagrams with dozens of different shapes, colors, and arrows, the new document palettes offer the flexibility you need!</p><p>Lastly, <em>Diagrams 2.0</em> will be ready for the next generation of the Mac ecosystem. In addition to a shiny new app icon and an overhauled UI specifically tailored for macOS Big Sur, it will include support for the Apple M1 chip.</p><p>This update is free for all existing users, and we can’t wait to share more details with you! Follow us on <a href="https://twitter.com/diagramsapp" target="_blank">Twitter</a> and <a href="https://diagrams.app/newsletter">subscribe to our newsletter</a> to be notified as soon as the update goes live <em>early next year</em>.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1608213579082_8666"><div><h2>Beta Program</h2><p>But wait, there’s one more thing! We’re starting a new beta program to get your feedback and improve <em>Diagrams</em>. The beta program will be limited to a closed tester group, but we’re happy to provide as many seats as possible. If you’re interested in testing new features during development, feel free to join the beta now!</p></div></div></div>]]>
            </description>
            <link>https://diagrams.app/blog/announcing-diagrams-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622134</guid>
            <pubDate>Sun, 03 Jan 2021 15:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life and death with a no-good, grumpy dog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622091">thread link</a>) | @mooreds
<br/>
January 3, 2021 | https://boulderbeat.news/sydney-obituary/ | <a href="https://web.archive.org/web/*/https://boulderbeat.news/sydney-obituary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content">
	<div role="main">
		<article id="post-5918" class="page">

	

	<section>
		<div>
<p><span><img data-attachment-id="5919" data-permalink="https://boulderbeat.news/sydney-obituary/sydface/" data-orig-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-scaled.jpg" data-orig-size="2560,1440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;XT1254&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.8&quot;,&quot;iso&quot;:&quot;160&quot;,&quot;shutter_speed&quot;:&quot;0.02499&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sydface" data-image-description="" data-medium-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-300x169.jpg" data-large-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1024x576.jpg" loading="lazy" src="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1024x576.jpg" alt="" width="906" height="510" srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1536x864.jpg 1536w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-2048x1152.jpg 2048w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1200x675.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-500x281.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1600x900.jpg 1600w" sizes="(max-width: 906px) 100vw, 906px" data-lazy-srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1536x864.jpg 1536w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-2048x1152.jpg 2048w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1200x675.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-500x281.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1600x900.jpg 1600w" data-lazy-src="https://boulderbeat.news/wp-content/uploads/2021/01/Sydface-1024x576.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p>
<p><span>How many times have I drafted this obituary in my head? Sydney had been dying for years, or so it felt. If you’ve ever seen a dog age, you’ll know: Their death comes too slowly and entirely too fast, all at once.</span></p>
<p><span>The memorials I penned were full of humor and frankness. They captured Sydney’s essence perfectly: her aloofness that later turned to irritability, her tenacity of spirit, her stubborn-yet-sweet refusal to do anything other than what she wanted, to be anything other than what she was.&nbsp;</span></p>
<p><span>They were the words of someone whose dog died a good death, surrounded by loved ones, a hard but correct choice at the end of a gradual decline.&nbsp;</span></p>
<p><span>In writing, I would feel a sense of sadness, yes, but also one of relief. I would be ready and, more importantly, so would Sydney. Ending her life would be the humane choice, the only choice, and I would feel at peace with that decision.</span></p>
<p><span>I know death well. We’ve met before, many times. Both of my biological parents, all my grandparents, a cousin, a friend, a mentor, an editor; once, almost, myself.&nbsp;</span></p>
<p><span>I know death.&nbsp;</span></p>
<p><span>It doesn’t matter.&nbsp;</span></p>
<p><span>None of my familiarity has ever once lessened the pain of death — no matter how much I prepare, how many times I experience it, whether I see it coming or not. It’s as if I’d been watching a giant bird circle closer in the sky, only to have it pluck me right off the ground.</span></p>
<p><span>I have seen so many of life’s cruelties up close, but death remains the most painful, the most absurd, the most mundane and the cruelest thing to ever happen to me. In all my preparing and rationalizing and sincere belief that death is but a part of life, I seem to forget one simple truth: Life </span><i><span>hurts</span></i><span>.</span></p>
<p><strong><img data-attachment-id="5920" data-permalink="https://boulderbeat.news/sydney-obituary/sand-dunes/" data-orig-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes.jpg" data-orig-size="1066,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sand dunes" data-image-description="" data-medium-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-300x169.jpg" data-large-file="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-1024x576.jpg" loading="lazy" src="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes.jpg" alt="" width="1066" height="600" srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes.jpg 1066w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-500x281.jpg 500w" sizes="(max-width: 1066px) 100vw, 1066px" data-lazy-srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes.jpg 1066w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes-500x281.jpg 500w" data-lazy-src="https://boulderbeat.news/wp-content/uploads/2021/01/Sand-dunes.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></strong></p>
<p><strong>I.</strong></p>
<p><span>There are platitudes people always offer when a pet dies. “She was a good dog” is the first.</span></p>
<p><span>Sydney wasn’t, not really. Sure, she was quiet, and a neat eater and drinker. She didn’t jump all over people when they came in the house, which I appreciated. She never chewed anything she shouldn’t or licked my face excessively. She traveled well. She was calm and gracious with children.</span></p>
<p><span>But the things you think of when you conjure the image of a dog? Sydney wasn’t those things.</span></p>
<p><span>Playful? Nope. She didn’t fetch, she wasn’t interested in toys.&nbsp;</span></p>
<p><span>A happy, wagging tail? Not really. It was a beautiful, classic German Shepherd tail, held high in what a trainer once told me was dominance, not joy.&nbsp;</span></p>
<p><span>Constantly by my side? Yes, but not in the puppy-trailing-after-you sort of way. “Stalked” is the most appropriate word for what Sydney did, following me through every room in the house. I always sensed she was plotting a coup, waiting her chance to usurp my authority.</span></p>
<p><span>As for her attitude toward other dogs? </span><span>As L.M. Montgomery wrote (with necessary adjustments), her “paw was against every (dog) and every (dog’s) paw against” her.</span></p>
<p><span>Living with my housemate’s pup taught me how “bitch” evolved its current popular meaning. We went to the vet no fewer than a half dozen times to clean wounds they left on each other. I had to have abscesses drained, punctures patched. They both bore scars of their pitched battles.&nbsp;</span></p>
<p><span>Sydney was the fun police. If ever a fellow canine were enjoying itself too much, she would swoop in and put a stop to it. One of my many nicknames for her was Sydvicious.</span></p>
<p><span>She had a particular hatred for the old and weak, a true four-legged social Darwinian. The last time I ever took Sydney to the dog park, she kept eyes on an old, yellow-white fluffball the entire time she sniffed the perimeter of the park. When she had grown bored of the area’s olfactory offerings, she turned her full attention to this luckless creature, hiding under a picnic table. The dog shifted; that was all the provocation Sydney needed: She pounced. The rest of the dogs at the park circled up, yapping the canine version of that old schoolyard chant “Fight! Fight! Fight!” Fur was flying everywhere; Sydney could not be contained. She’d tasted the flesh of her enemy and gone mad with bloodlust.</span></p>
<p><span>My companion, a bar guest of mine, scooped her up in his arms, where she writhed and frothed. Shocked dog guardians stared at us as we beat a hasty retreat under their withering glare, Sydney struggling for freedom the entire way.</span></p>
<p><span>(The other dog was OK, in case you’re wondering, aside from a few chunks of missing fur.) We never went back.</span></p>
<p><span>Sydney did not reserve her aggression for her fellow canines. She bit numerous humans as well, including my late, elderly mother (who was very much alive at the time of the bite) and, once, a jogger’s prominent left ass cheek, mid-stride.&nbsp;</span></p>
<p><span>“Bite” is a strong word — Sydney was a shepherd; she had a herding instinct. Nothing and no one could move in our house without Sydney attempting to corral it using sharp nips at the heels. She terrorized five successive roommates, all meek and quiet females. (Proving she was no woman-hater, Sydney once barred an HVAC man in my very small laundry room and refused to let him move. I drove home from work to free him.)</span></p>
<p><span>As she grew older, Sydney turned her teeth to other, softer and more accessible parts of the body: hands, arms, calves. She began chomping my housemate, whom she had known for 8 years, and, eventually, me. Truly, she raged against the dying of the light.</span></p>
<p><span>It wasn’t biting in the best sense of the word. She never clamped down — she snapped, her way of letting you know she was displeased with whatever was happening.&nbsp;</span></p>
<p><span>When I took her home this year to my dad’s house, my nephews were deeply disappointed. They love dogs, but Sydney did not want to be pet. She did not want to play. She wanted two things: Your food, and to be left alone.</span></p>
<p><span>This was not a dog, my younger nephew moaned, it was a coyote.</span></p>
<p><span>I respected Sydney for her clear communication and boundary-setting. I never took it personally, as others seemed to. Her affection was hard-won, yes, but not nonexistent. It waned with age, but what can you expect from someone who is mostly deaf, partially blind, barely mobile and losing a slow war to skin cancer?&nbsp;</span></p>
<p><span>Sometimes, you’re just out of fucks to give.</span></p>

<p><strong><img data-attachment-id="5927" data-permalink="https://boulderbeat.news/sydney-obituary/snarl-3/" data-orig-file="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-scaled.jpg" data-orig-size="1440,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;XT1254&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.8&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.02499&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Snarl" data-image-description="" data-medium-file="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-169x300.jpg" data-large-file="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-576x1024.jpg" loading="lazy" src="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-576x1024.jpg" alt="" width="576" height="1024" srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-576x1024.jpg 576w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-169x300.jpg 169w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-768x1365.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-864x1536.jpg 864w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1152x2048.jpg 1152w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1200x2133.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-500x889.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1600x2844.jpg 1600w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-scaled.jpg 1440w" sizes="(max-width: 576px) 100vw, 576px" data-lazy-srcset="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-576x1024.jpg 576w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-169x300.jpg 169w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-768x1365.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-864x1536.jpg 864w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1152x2048.jpg 1152w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1200x2133.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-500x889.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-1600x2844.jpg 1600w, https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-scaled.jpg 1440w" data-lazy-src="https://boulderbeat.news/wp-content/uploads/2021/01/Snarl-2-576x1024.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">II.</strong></p>
<p><span>The other thing people say when a pet dies is, “She had a good life.” But did she?</span></p>
<p><span>I was not a great mom to Sydney. I was in my early 20s when I brought her home, a bartender in a tourist town before the recession. I had money to burn, and I burned it mostly on boozy nights out with friends.&nbsp;</span></p>
<p><span>In my quest to never be lonely, I left her alone far too often, for far too long.&nbsp;</span></p>
<p><span>I hadn’t yet dealt with the trauma of my youth. I was angry, a lot. I yelled too much and pet her too little — particularly after I moved from humid Florida to arid Colorado and developed an allergy to dogs. I couldn’t risk snuggles without hives, red eyes and a runny nose, though I often did.&nbsp;</span></p>
<p><span>I had selected Sydney for two reasons: One, I wanted an older dog and felt that I should therefore take whatever name it came with. I loved Australia during my time there, so Sydney it was.&nbsp;</span></p>
<p><span>What really sealed it is that I saw myself in her. She showed signs of being mistreated, flinching at sudden movements. The shelter staff told me it was likely she was abused. Her kennel card — which I still have — said the couple who turned her in found her wandering on the street. She was surrendered because she jumped fences, they wrote, but I suspect it was because she did not get along with their other dogs: they wanted to spare her the almost certain death attached to a label of aggressive or dangerous.</span></p>
<p><span>When I went to greet her, Sydney was in the cage with a young, lively pit bull. Every time I extended my hand to touch her, it would jump in the way. After a few attempts, she gave up, took a couple steps back and looked at me from the tops of her eyes, almost rolling them, as if to say, “Do you see what I have to deal with here?”</span></p>
<p><span>From that moment, she was mine.&nbsp;</span></p>
<p><span>I was still naive enough to be looking for symbols, signs from the universe that I would be OK, that I could escape my very-much-present past and become a whole person. I convinced myself we could heal together, Sydney and me. That if she could get better, I could, too.</span></p>
<p><span>It took me a few years to figure out I could not wait on anyone to prove to me that I could heal. The only thing I could do was try. Sydney was <a href="https://tv.getyarn.io/yarn-clip/57aa6637-85ef-4c3b-87bd-288a306cfcc1" target="_blank" rel="noopener noreferrer">a dog, not an oracle</a>. She was limited in her capacities.</span></p>
<p><span>I did get better, eventually. Sydney did not, not really, which I will forever believe is my fault. Dogs are intensely in-tune animals, reflecting the personalities of their owners; I can see for myself how my housemate’s pup mirrors his own anxiety.&nbsp;</span></p>
<p><span>So what does it say about me that my dog was, to put it bluntly, kind of a bitch? Never trusting, always on alert, reserving her sweetness for a select few. With another owner, what could she have become? Would they have gotten a proper trainer to overcome her aggression? Would she have stopped cowering at raised hands and voices and started chasing Frisbees in the park? Would she have been that loveable, happy dog that everyone wants, a dog that would have delighted my nephews? </span></p>
<p><span>I can’t help but feel that the answer, at least to some extent, is yes. That far from helping her realize her potential, I prevented her from reaching it.</span></p>
<p><span>Still, her life wasn’t exactly bad. She got three walks a day and two meals. She once rolled in a maggoty shark on the beach and seemed to enjoy it. She took road trips, ate cheeseburgers and ice cream. She got steak on her birthday, turkey on Thanksgiving and a full stocking on Christmas. She stole all sorts of food from my roommates over the years, most recently an entire buttered English muffin and a plate of roasted grapes in sausage grease, having finally figured out at 14 how to climb onto the dining room table.&nbsp;</span></p>
<p><span>She had a warm bed to sleep in every night, patches of sunlight in which to nap. She climbed mountains.&nbsp;</span></p>
<p><span>For a one-time street dog from Orlando, I suppose it could have been worse.</span></p>
<p><strong><img data-attachment-id="5921" data-permalink="https://boulderbeat.news/sydney-obituary/snoots/" data-orig-file="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-scaled.jpg" data-orig-size="2560,1440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snoots" data-image-description="" data-medium-file="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-300x169.jpg" data-large-file="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1024x576.jpg" loading="lazy" src="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1024x576.jpg" alt="" width="906" height="510" srcset="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1536x864.jpg 1536w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-2048x1152.jpg 2048w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1200x675.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-500x281.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1600x900.jpg 1600w" sizes="(max-width: 906px) 100vw, 906px" data-lazy-srcset="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1024x576.jpg 1024w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-300x169.jpg 300w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-768x432.jpg 768w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1536x864.jpg 1536w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-2048x1152.jpg 2048w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1200x675.jpg 1200w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-500x281.jpg 500w, https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1600x900.jpg 1600w" data-lazy-src="https://boulderbeat.news/wp-content/uploads/2021/01/snoots-1024x576.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">III.</strong></p>
<p><span>Old age began years ago for Sydney. She started greying around 8; by 10, I had to sign the senior dog waiver at the groomer’s, …</span></p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boulderbeat.news/sydney-obituary/">https://boulderbeat.news/sydney-obituary/</a></em></p>]]>
            </description>
            <link>https://boulderbeat.news/sydney-obituary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622091</guid>
            <pubDate>Sun, 03 Jan 2021 14:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Made It Through 2020, But What For?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25622038">thread link</a>) | @stanrivers
<br/>
January 3, 2021 | https://newsletter.butwhatfor.com/p/but-what-for-newsletter-2020-highlights | <a href="https://web.archive.org/web/*/https://newsletter.butwhatfor.com/p/but-what-for-newsletter-2020-highlights">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Well, 2020 was quite the year - but 2021 is finally here - so Happy New Year! I hope it is off to a great start for everyone.</p><p>I want to thank all of you for subscribing, reading, and sharing these emails and my writing. The response here has far exceeded any expectations I had when I started writing with some consistency in September last year. Your support means a lot and provides me the motivation to keep writing.</p><p>If you have any suggestions or thoughts on what you like/do not like or new things you would like to see in the Sunday or Tuesday emails, please feel free to comment here or email me. I am always interested in ways that we can create a better end product that is valuable and meaningful over the long term.</p><p>Thank you!</p><p>— EJ</p><p><em>Welcome to all our new subscribers! I write a weekly newsletter, sent out every Sunday, with curated quotes and one-line takeaways from material that I think is worth reading. Occasionally, I share my own thoughts, inspired by others’ writings, on Tuesdays. If you enjoy the newsletter, please share it with a few friends/colleagues or follow me on&nbsp;<a href="https://twitter.com/ButWhatForBlog">Twitter</a>.</em></p><p><em>As always, any suggested materials for our Sunday newsletter can be sent to <a href="https://newsletter.butwhatfor.com/cdn-cgi/l/email-protection" data-cfemail="1a697579737b765a786f6e6d727b6e7c75683479757734">[email&nbsp;protected]</a> Thank you!</em></p><h2><strong>2020 Highlights From But What For?</strong></h2><p><em>(Underlined titles are links to full articles)</em></p><h4><strong>Most Viewed of 2020:  <a href="https://www.butwhatfor.com/on-old-age-with-cicero/">On Old Age with Cicero</a></strong></h4><p><em>~10,000 views with an average time on page of ~6 minutes</em></p><p>But bear well in mind that in this entire discussion&nbsp;I am praising that old age which has its foundation well laid in youth. Hence it follows— as I once said with the approval of all who heard it— that that old age is wretched which needs to defend itself with words! Nor can wrinkles and grey hair suddenly seize upon influence;&nbsp;but when the preceding part of life has been nobly spent, old age gathers the fruits of influence at the last.</p><h4><strong>Longest Average Time on Page of 2020:  </strong><a href="https://www.butwhatfor.com/feynman-technique/">Richard Feynman &amp; The Feynman Technique: How to Learn Anything Well</a></h4><p><em>~6,000 views with an average time on page of ~7 minutes</em></p><p>You asked me if an ordinary person, by studying hard, would get to be able to imagine these things like I imagine.</p><p>Of course! <a href="https://www.butwhatfor.com/richard-feynman/">I was an ordinary person who studied hard</a>. There are no miracle people. It just happens that they got interested in this thing, and they learned all this stuff. They’re just people. There’s no [science] talent – a special miracle ability to understand quantum mechanics or a miracle ability to imagine electromagnetic fields&nbsp;<a href="https://www.butwhatfor.com/perseverance-is-great-but-dont-forget-to-prepare/">that comes without practice and reading and learning and study</a>.</p><h4>My Favorite of 2020: <a href="https://www.butwhatfor.com/a-stoic-philosopher-in-a-hanoi-prison/">A Stoic Philosopher in a Hanoi Prison</a></h4><p><em>~8,000 views with an average time on page of ~5 minutes</em></p><p>Stockdale had no reason to think that the day’s mission was to be anything unique.</p><p>The flight in September 1965 was part of his third combat tour of North Vietnam, serving as Wing Commander of the aircraft carrier Oriskany. Despite his misgivings about the purpose of him being in Vietnam, he was a competent and skilled career fighter pilot. Nothing suggested he shouldn’t expect to make it back home that day – let alone that decade.</p><p>But sometimes life deals you a lousy hand, and it dealt Stockdale quite an unfair one.</p><p>While trying to aid trapped American soldiers on the ground, he was suddenly falling out of the sky and hurtling towards a small Vietnamese village. His plane was on fire, the control system shot out by North Vietnamese who had used the grounded soldiers as bait, and he didn’t have much choice beyond punching out of the plane.</p><h4><strong>Least Viewed of 2020:  </strong><a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">Invert, Always Invert – Avoid Failure to Succeed</a></h4><p><em>~700 views with an average time on page of ~5 minutes</em></p><p>“Suppose I wanted to kill a lot of pilots – what would be the easy way to do it?”&nbsp;</p><p><a href="https://youtu.be/HS8neXkNnhw?t=5962">That might not be what you want to hear from the guy clearing your plane for takeoff</a>, but if your fellow passengers are an elderly billionaire and some Cold War-era Soviet engineers, they might rest easy knowing the right questions are being asked. That is because thinking about how to do the exact opposite of your goal is sometimes the best way to ensure you achieve it.</p><h4>Most Controversial of 2020: <a href="https://www.butwhatfor.com/stand-up-straight-with-your-shoulders-back/">Stand Up Straight with Your Shoulders Back</a></h4><p><em>Most unsubscribes following a post</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png&quot;,&quot;height&quot;:null,&quot;width&quot;:null,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><h4>Most Popular 2020 Tweet</h4><p><em>Maybe I should write about fountain pens?</em></p><h4>Top Twitter Follower (<em>the most important award</em>) - <a href="https://twitter.com/BaldingsWorld">@BaldingsWorld</a></h4><p><em>Brought about the largest 24-hour increase in Twitter followers - - -&gt;</em></p><h2>Favorite Memoirs Read in 2020</h2><p><em>(Underlined titles are links to the books)</em></p><h4><a href="https://amzn.to/2JJrdIk">Survival in the Killing Fields</a> (<a href="https://www.butwhatfor.com/survival-in-the-killing-fields-ngor/">Summary of Book</a>)</h4><p><em>Haing Ngor, with Robert Warner</em></p><p>“Nothing has shaped my life as much as surviving the Pol Pot regime. I am a survivor of the Cambodian holocaust. That's who I am.”</p><p>“I believe what the old monk taught me. And everything he said came true, only in reverse. My family was unhappy, my village was unhappy, and so was the country. And now I look back on it all and think about the connections, and wonder whether I myself was partly to blame.”</p><p>“And when I saw their false pride, I felt I finally understood what war is about. Men fight for glory or ideals, but the result is not glorious or idealistic. The main result, besides the suffering, is that civilization is set back many years.”</p><p>“If I didn’t worry about the Khmer Rouge, it was because I didn’t believe they could be any worse than the Lon Nol regime… It surprises me now, but most of us pretended that life was almost normal. We made ourselves believe that Phnom Penh was a little island of peace and it was going to stay that way.”</p><p>“We had not been in favor of the revolution. We had not been against it. We didn’t even care about politics much. But now that the revolution had come, we had been bulldozed by it, reduced to the same level as the other exiles around us. And there was no new society building. Just the rubble of the old one.”</p><p>“To avoid our own deaths people like me were doing things we knew were wrong. And as we scrambled to protect ourselves, or sought to gain favor with the new powers, the old relationships were torn apart.”</p><p>“What made it worse, what made it more appalling was that somehow it was ordinary. You put one foot in front of the other and you kept on walking. You heard the cries of the weak but you didn’t pay much attention, because you were concentrating on yourself and your own survival. We had all seen death before.”</p><p>“How fast man changes! How fast he sheds his outer humanity and becomes the animal inside! … Children left their parents to die, wives abandoned their husbands and the stronger kept on moving. The Khmer Rouge had taken away everything that held our culture together, and the result was this: a parade of the selfish and the dying, Society was falling apart.”</p><p>“They knew that a small lie can be caught and that a big lie is easier to get away with.”</p><p>“There were no laws under the Khmer Rouge except the law of silence. There were no courts except Angka Leu. Maybe the prisoners hadn’t worked hard enough. Or they stole food. Or a chhlop, a spy, overheard them making remarks about Angka. People disappeared. That is all we knew. And I knew that someday I would be one of them.”</p><h4><a href="https://amzn.to/2KSRnZu">Confessions: An Innocent Life in Communist China</a></h4><p><em>Kang Zhengguo, translated by Susan Wilf</em></p><p>“‘Behavior’ meant putting on a deliberate show of allegiance to the authorities. When the teachers and school leadership evaluated your ‘behavior,’ they were referring to your politics, and you had to play the game right if you wanted a rating of ‘well behaved.’ Behavior ratings were as important as tests and grades since they affected one’s class rank, admission to select groups, and future prospects in general.”</p><p>“As I was browsing the big-character posters on the street on a winter day in 1966, it dawned on me that people everywhere were jumping onto the Cultural Revolution bandwagon to try to better their own lots, and I sensed their pent-up rage spilling out like water roiling over a dam… After paying lip service to Chairman Mao’s revolutionary line, which conveniently proclaimed the right to rebel, the aggrieved parties blamed all their problems indiscriminately on the bourgeois reactionary line. Now that leaders had been pronounced fair game, nobody was afraid to lash out at them anymore.”</p><p>“Instead of telling me why I was being detained or charging me with a specific crime and asking me to confess, he told me to make my deposition first. As if the reason for my arrest were a riddle to which only he knew the answer, he had turned the interrogation into a guessing game.”</p><p>“It was my first experience with such poverty, and I was learning some new lessons about human nature. Apparently, people could coexist only if everyone was equally destitute, and a stroke of good luck could be a nuisance in disguise.”</p><p>“Broaching the forbidden was tantamount to “advocating” or “appreciating” it; that was the prevailing logic.”</p><p>“Even if I had been duped, I had no reason to regret having performed a good deed.”</p><h4><a href="https://amzn.to/3aZ95Fu">Blood Red Sunset: A Memoir of the Chinese Cultural Revolution</a></h4><p><em>Ma Bo, translated by Howard Goldblatt</em></p><p>“It was my background. My mother sealed my fate the day she became a writer. People from literary families were among society’s foulest outcasts… Revolutionary soldiers hate cultured people, writers especially, so they had no use for me.”</p><p>“‘Ma Bo, the masses have complained about your behavior during these denunciation meetings… Just because you weren’t permanently labeled doesn’t mean there isn’t a label with your name on it. Labels are in the hands of the masses, who can stick them on you anytime they want!’”</p><p>“But getting angry wouldn’t do any good… I was a counterrevolutionary mirror that reflected people’s true souls. When they looked into it they discovered they weren’t as attractive as they’d thought. That made them unhappy, so they blamed the mirror.”</p><p>“Experience told me that Jin Gang’s sympathy for me was tied to his own interests. If I were drowning, he would be the last person to come to my rescue. But I also knew that if I made my way back to the shore, his outstretched hand would be there for me.”</p><p>“Skeins of tangled emotion spilled …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsletter.butwhatfor.com/p/but-what-for-newsletter-2020-highlights">https://newsletter.butwhatfor.com/p/but-what-for-newsletter-2020-highlights</a></em></p>]]>
            </description>
            <link>https://newsletter.butwhatfor.com/p/but-what-for-newsletter-2020-highlights</link>
            <guid isPermaLink="false">hacker-news-small-sites-25622038</guid>
            <pubDate>Sun, 03 Jan 2021 14:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powerful Life Skills for the New Decade]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621975">thread link</a>) | @neilkakkar
<br/>
January 3, 2021 | https://neilkakkar.com/powerful-life-skills.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/powerful-life-skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Over the past few years, I’ve noticed certain skills in people I admire, from Paul Graham, Vitalik Buterin, to Ender Wiggin.</p>

<p>Most normal people like me don’t realise these are skills. This makes the skills powerful - not everyone can see them, and very few people have mastered them.</p>

<p>However, I aim to change that. What follows below are 10 skills sourced from admirable people that I want to develop this decade.</p>

<p>Powerful life skills make powerful people.</p>

<h2 id="learn-to-take-compounding-seriously">Learn to take compounding seriously</h2>

<p>It’s not just your wealth that compounds, but life experience and knowledge, too.</p>

<p>So, learn the most basic, most useful skills first. The longer you wait to learn skills like these, the less time there is for compounding magic. That’s what this entire list is about: powerful skills to learn and use for the rest of your life.</p>

<p>And even though you’ve heard about compounding, this item is first on the list, because <a href="https://neilkakkar.com/taking-ideas-seriously.html">taking ideas seriously is hard</a>.</p>

<p>A good way to figure out what compounds is <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">to figure out what’s a platform</a>.</p>

<h2 id="learn-to-develop-taste">Learn to develop taste</h2>

<p>Despite prevalent beliefs, taste isn’t subjective.</p>

<p>While it may seem like it on the outside, when you say “I just love this painting” or “I just love this coffee machine” - all it means is that the defining characteristics are illegible to you. And noticing this is the first step.</p>

<p>Let’s take a specific example. Say you’re designing a high quality clay pot - and you’ve never done this before.</p>

<p>What’s a good way to develop taste for quality here?</p>

<p>If you’ve heard this claypot parable, you know the answer: start by making lots of crap pots.</p>

<blockquote>
  <div><p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A,” forty pounds a “B,” and so on. Those being graded on “quality,” however, needed to produce only one pot—albeit a perfect one—to get an “A.”</p><p>

Well, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work—and learning from their mistakes—the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. - <a href="https://amzn.to/3o9o17A" target="_blank" rel="noopener">Art and Fear</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p></div>
</blockquote>

<p>Let others tell you what you’ve made is crap. Learn why. Notice when they tell you something is great. Figure out why.</p>

<p>This transfers to writing as well: Popular advice to get better is to write a lot of junk, do it a 100 times, and pay particular attention to what is received well. Here’s <a href="http://www.paulgraham.com/taste.html" target="_blank" rel="noopener">another example - developing taste for design</a>.</p>

<p>In effect, you bootstrap good taste by first learning what others consider good. Then, <a href="#learn-to-see-systems">you see the system behind it</a>. Then you break the rules and still manage to awe.</p>

<p>Then you’ve developed taste.</p>

<h2 id="learn-to-sequence-things-well">Learn to sequence things well</h2>

<p>Waking up when others are asleep and getting lots done is a super power. It’s born out of a system of <a href="https://neilkakkar.com/sequencing-things-in-the-right-order.html">learning to sequence things well</a>.</p>

<p>It means choosing the right time for that Netflix binge.</p>

<p>It means being prepared before the meeting, not scrambling to get things done after.</p>

<p>It means reading the coursebook before the lecture, not after.</p>

<h2 id="learn-to-see-what-others-see">Learn to see what others see</h2>

<p>How well can you understand other people? Can you sense their desires, their concerns, and what events lead to those desires and concerns?</p>

<p>If you can do this, you can understand them. But not before.</p>

<blockquote>
  <p>In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it’s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. - <a href="https://amzn.to/2KKe8Px" target="_blank" rel="noopener">Ender’s Game</a><sup id="fnref:1"><a href="#fn:1">2</a></sup></p>
</blockquote>

<p>It’s worth going this far because understanding is powerful. It helps you empathise. It helps you negotiate. It helps you figure out why you don’t have product-market fit. It helps you learn quickly: you can switch through personas and see what will and won’t work.</p>

<p>How do you do learn to see? I know no better way than to practice. Try it a 100 times. <a href="https://neilkakkar.com/subscribe">Come back next year</a>, and maybe I’ll have a better way once I’ve done it a 100 times.</p>

<h2 id="learn-to-make-and-execute-decisions-quickly">Learn to make and execute decisions quickly</h2>

<p>Most people have a bias towards analysis-paralysis versus getting shit done.</p>

<p>When decisions are reversible - and they mostly are - speed is a super power. Cultivating a habit of making decisions quickly, and then executing them is better than just thinking about it.</p>

<p>Training this skill begins as easily as deciding what to eat on a huge menu. It’s a small step, but over time, <a href="#learn-to-take-compounding-seriously">even the smallest steps compound</a>.</p>

<blockquote>
  <p>“Hesitation is always easy, rarely useful” - Prof. Quirrel alterego, <a href="http://www.hpmor.com/" target="_blank" rel="noopener">HPMOR</a></p>
</blockquote>

<p>Here’s an <a href="https://firstround.com/review/speed-as-a-habit/" target="_blank" rel="noopener">example in the context of business</a>. And a <a href="https://twitter.com/sama/status/1345140364995227648" target="_blank" rel="noopener">tweet from Sam Altman</a>.</p>

<h2 id="learn-to-spot-a-convex-or-concave-world">Learn to spot a convex or concave world</h2>

<p>In the world of viral infections, a 50% lockdown is worse than a 0% and a 100% lockdown, both. The virus isn’t contained, and businesses have to shut down, too.</p>

<p>In the world of immigration policies, letting some specific people in is better than letting no one or everyone in. The middle ground is better than the extremes.</p>

<p>When the best of both worlds is great, you’re in a concave disposition.</p>

<p>When the best of both worlds is worse than either, you’re in a convex disposition.</p>

<p>The world is sometimes concave, and sometimes convex. Knowing your topology can help you make better decisions.</p>

<p>I first noted this when <a href="https://vitalik.ca/general/2020/11/08/concave.html" target="_blank" rel="noopener">Vitalik Buterin explained it</a>. Read it for more concrete examples.</p>

<!-- ## Learn to do obvious things -->

<h2 id="learn-to-tell-stories">Learn to tell stories</h2>

<p>People donate more to charity when they know a single victim’s story, versus statistics of a thousand deaths. It’s called the <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a>, but it’s the power of stories over facts. The right framing gets you further than all the facts combined.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.”</p>
</blockquote>

<p>Ideas &amp; facts contextualised by stories are more powerful than either alone.</p>

<p><i></i><b>The Skill of Storytelling</b><br>
There’s lots to unpack here, and this is the first skill I’ve been working on for the past few months. Watch out for a long blogpost in 2 weeks!</p>

<h2 id="learn-to-dive-into-the-source-code-when-documentation-isnt-enough">Learn to dive into the source code when documentation isn’t enough</h2>

<p>Sometimes, there’s no precedent for what you want to do. Or the people who did it before didn’t write a manual.</p>

<p>In cases like these, figuring things out for yourself is powerful. Research papers and obscure books aren’t just for scientists. They’re freely available on the internet* for all of humanity to use. Learn to use it. Learn about resources like <a href="https://sci-hub.do/" target="_blank" rel="noopener">SciHub</a>, <a href="https://libgen.xyz/" target="_blank" rel="noopener">LibGen</a>, and hiring researchers. You’re allowed to hire people (specially graduate students!) to satisfy your research concerns.</p>

<p>… and when you’re done, <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html#writing-code">preserve context for future you</a>.</p>

<p>It’s a lot like trying to use an API that has no documentation. Would’ve been easy if there was documentation, but there isn’t. So you got to do it the hard way: read the source code and figure out what you need to make things work.</p>

<p>It’s also like <a href="https://neilkakkar.com/A-framework-for-First-Principles-Thinking.html">figuring out what you need to build rockets yourself</a> when existing ones are too expensive.</p>

<p><a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" target="_blank" rel="noopener">More resources here</a>.</p>

<h2 id="learn-to-be-specific">Learn to be specific</h2>

<p>Every time I gave an example above, I was training my specificity muscles.</p>

<p>Most of the time, most people don’t know what they’re talking about. Not being specific is a sign of that. The more abstract the word, the harder it is to pin down a meaning.</p>

<p>For example, “negative ramifications” doesn’t tell you what exactly happened, while “the sonic boom from the new supersonic jet destroyed windows in a 100m radius” is a lot more specific.</p>

<p>Learn to be specific, and learn to spot when others aren’t. <a href="https://www.lesswrong.com/posts/NgtYDP3ZtLJaM248W/sotw-be-specific" target="_blank" rel="noopener">Here’s how</a>.</p>

<h2 id="learn-to-see-systems">Learn to see systems</h2>

<p>There’s two kinds of people.</p>

<ul>
  <li>Bob, who will see this list, find some skills very interesting, and then go about honing those skills</li>
  <li>Alice, who will see this list, and wonder how I came up with these
<!-- - The Inspiration-Junkie, who will lurk and move on to the next inspiring post without changing anything -->
</li>
</ul>

<p>Alice would then try to understand the system that generated these ideas. Then, she’ll adopt the system, and come up with skills possibly more relevant to herself.</p>

<p>Having the option to do both is powerful. Since Bob is the default, <a href="https://neilkakkar.com/How-to-see-Systems-in-everyday-life.html">learn to be like Alice</a>. Choose <a href="https://neilkakkar.com/understanding-systems.html">systems when things are important</a> to you. Choose hacks when you need a quickfix.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>



    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/powerful-life-skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621975</guid>
            <pubDate>Sun, 03 Jan 2021 14:34:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container images, multi-architecture, manifests, ids, digests – what’s behind?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621963">thread link</a>) | @based2
<br/>
January 3, 2021 | https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/ | <a href="https://web.archive.org/web/*/https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Many of us use container images from day to day, maybe also in many various architectures. For example on your Raspberry PI (aarch64), do you really know how it works in detail?</p>



<p>I have worked with container images more or less since 2015 but during an <a href="https://www.openshift.com/" target="_blank" rel="noreferrer noopener">OpenShift</a> 4 air-gapped installation and mirroring of images into a registry, I hit the wall quite hard and have to realize I didn’t know all the details very well.&nbsp;</p>



<p>If you are not familiar with OpenShift 4 air-gapped installation, the installation is divided into two parts: first <a rel="noreferrer noopener" href="https://docs.openshift.com/container-platform/4.6/installing/installing_bare_metal/installing-restricted-networks-bare-metal.html" target="_blank">OpenShift 4 Core </a><a rel="noreferrer noopener" href="https://docs.openshift.com/container-platform/4.6/installing/installing_bare_metal/installing-restricted-networks-bare-metal.html" target="_blank">i</a><a rel="noreferrer noopener" href="https://docs.openshift.com/container-platform/4.6/installing/installing_bare_metal/installing-restricted-networks-bare-metal.html" target="_blank">nstallation</a> and second the <a rel="noreferrer noopener" href="https://docs.openshift.com/container-platform/4.6/operators/admin/olm-restricted-networks.html" target="_blank">cluster add-ons via OperatorHub/Operator Lifecycle Manager</a>. The second part is optional but brings a lot of value into OpenShift.&nbsp;</p>



<p>Today I am excited to share my learnings with you.</p>



<p><strong>Let’s start off with some basics around container images</strong></p>



<p>A container image is a static immutable packaging and shipping format. It contains everything you need to start a container, the actual software packages and information on how to start it at your container runtime. A container image is distributed via a container registry like <a href="https://quay.io/" target="_blank" rel="noreferrer noopener">quay.io</a> or <a href="https://hub.docker.com/" target="_blank" rel="noreferrer noopener">Docker Hub</a>.</p>



<p>All the important format definitions for distribution and runtime of a container image are specified in the open container initiative (OCI) – <a href="https://opencontainers.org/" target="_blank" rel="noreferrer noopener">https://opencontainers.org/</a>.</p>



<p>The container workflow from build to run is:</p>



<figure><table><tbody><tr><td>First</td><td>You build your<strong> container image</strong> via OpenShift, <a href="https://podman.io/" target="_blank" rel="noopener noreferrer">podman</a>, <a href="https://buildah.io/" target="_blank" rel="noopener noreferrer">buildah</a> or the container <strong>build</strong> tool of your choice.</td></tr><tr><td colspan="2" data-align="center"><strong>Push</strong> your container image into your container registry.</td></tr><tr><td>Second</td><td>You ship/distribute your container image via&nbsp; quay.io or the <strong>container registry</strong> of your choice.&nbsp;</td></tr><tr><td colspan="2" data-align="center"><strong>Pull</strong> your container image into your container registry.</td></tr><tr><td>Third</td><td>You run your container image at runtime using OpenShift/CRI-O or your runtime of your choice.</td></tr></tbody></table></figure>



<p><strong>Building a container&nbsp;</strong></p>



<p>There are various blog posts and articles about how to build containers. All you have to know for now is that you need a&nbsp; Containerfile (formally known as Dockerfile) and with podman, buildah or docker you build your container from it.&nbsp;</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/www.opensourcerers.org\/2020\/11\/16\/container-images-multi-architecture-manifests-ids-digests-whats-behind\/&quot;}"><figure><img data-attachment-id="2698" data-permalink="https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/opensourcers-container-images-manifests-id-digest-and-multi-arch-1/" data-orig-file="https://www.opensourcerers.org/wp-content/uploads/2020/11/Opensourcers-Container-images-manifests-id-digest-and-multi-arch-1.png" data-orig-size="283,195" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Opensourcers-Container-images-manifests-id-digest-and-multi-arch-1" data-image-description="" data-medium-file="https://www.opensourcerers.org/wp-content/uploads/2020/11/Opensourcers-Container-images-manifests-id-digest-and-multi-arch-1.png" data-large-file="https://www.opensourcerers.org/wp-content/uploads/2020/11/Opensourcers-Container-images-manifests-id-digest-and-multi-arch-1.png" loading="lazy" width="283" height="195" src="https://www.opensourcerers.org/wp-content/uploads/2020/11/Opensourcers-Container-images-manifests-id-digest-and-multi-arch-1.png" alt=""></figure><p>During the build process, it creates a bunch of file system layers including the container configuration (how to run, port, volume details). The file system layers contain all the software components, operating system libraries, of your software – basically all you need to run your software inside the container.</p></div>



<p>Depending on the build environment it also creates a temporary Manifest. The Manifest itself will become important later during the container image distribution.&nbsp;</p>



<p><strong>At this point, we have a container image that is made to run in the architecture it is built for.</strong> For example x86 on an x86 host or aarch64 on aarch64 host. At the end of the build you also get the Image ID of your container image.&nbsp;&nbsp;</p>



<p>Here are the key details taken from the <a href="https://github.com/opencontainers/image-spec/blob/master/config.md#imageid" target="_blank" rel="noreferrer noopener">Image ID specification</a>:<br><em>Each image’s ID is given by the SHA256 hash of its configuration JSON. It is represented as a hexadecimal encoding of 256 bits, e.g., sha256:a9561eb1b190625c9adb5a9513e72c4dedafc1cb2d4c5236c9a6957ec7dfd5a9. Since the configuration JSON that gets hashed references hashes of each layer in the image, this formulation of the ImageID makes images content-addressable.</em></p>



<p>After the build on the build machine, the final container image digest will not be available as the digest. The digests will be created during the push into the container registry.</p>



<p>The container image configuration is specified here:</p>



<ul><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/config.md" target="_blank">application/vnd.oci.image.config.v1+json</a></li></ul>



<p>For FileSystem layers, their are different types / specifications available:</p>



<ul><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md" target="_blank">application/vnd.oci.image.layer.v1.tar</a></li><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md#gzip-media-types" target="_blank">application/vnd.oci.image.layer.v1.tar+gzip</a></li><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md#gzip-media-types" target="_blank">application/vnd.oci.image.layer.v1.tar+zstd</a></li><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md#non-distributable-layers" target="_blank">application/vnd.oci.image.layer.nondistributable.v1.tar</a></li><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md#non-distributable-layers" target="_blank">application/vnd.oci.image.layer.nondistributable.v1.tar+gzip</a></li><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/layer.md#non-distributable-layers" target="_blank">application/vnd.oci.image.layer.nondistributable.v1.tar+zstd</a></li><li><a rel="noreferrer noopener" href="https://github.com/docker/docker/blob/master/image/spec/v1.md#creating-an-image-filesystem-changeset" target="_blank">application/vnd.docker.image.rootfs.diff.tar.gzip</a></li></ul>



<p>In case you miss the first version: <a rel="noreferrer noopener" href="https://github.com/moby/moby/tree/master/image/spec" target="_blank">application/vnd.docker.container.image.v1+json</a>: Docker Image Specification v1 Image JSON has still been widely used and officially adopted in <a rel="noreferrer noopener" href="https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md" target="_blank">V2 manifest</a> and <a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec" target="_blank">OCI Image Format Specification</a>.</p>



<p><strong>Push – image distribution and a little bit of container registry&nbsp;</strong></p>



<p>After an image build, you typically distribute your container image to a container image registry.&nbsp; At this point the manifest comes into play. Container registries can support different manifest types: </p>



<ul><li><a rel="noreferrer noopener" href="https://github.com/opencontainers/image-spec/blob/master/manifest.md" target="_blank">application/vnd.oci.image.manifest.v1+json</a> (oci)</li><li><a rel="noreferrer noopener" href="https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-1.md" target="_blank">application/vnd.docker.distribution.manifest.v1+json </a>– broadly called as schema1 (v2s1)</li><li><a rel="noreferrer noopener" href="https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md" target="_blank">application/vnd.docker.distribution.manifest.v2+json</a> – broadly called as schema2 (v2s2)</li></ul>



<p>All major registries support schema2. If you want to know how quay.io – the first private registry – can grow from v1 to v2.2 (schema2)&nbsp; then I recommend the following video:</p>



<figure><p data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/www.opensourcerers.org\/2020\/11\/16\/container-images-multi-architecture-manifests-ids-digests-whats-behind\/&quot;}">
<iframe title="Community Central: Container Registries: Then and Now" width="580" height="326" src="https://www.youtube.com/embed/M1GWYTJhMos?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Have a look at the following snippet, which shows an example of a schema2 manifest:</p>


<pre aria-describedby="shcb-language-2" data-shcb-language-name="JSON / JSON with Comments" data-shcb-language-slug="json"><p><code>{
  <span>"schemaVersion"</span>: <span>2</span>,
  <span>"mediaType"</span>: <span>"application/vnd.docker.distribution.manifest.v2+json"</span>,
  <span>"config"</span>: {
    <span>"mediaType"</span>: <span>"application/vnd.docker.container.image.v1+json"</span>,
    <span>"size"</span>: <span>2654</span>,
    <span>"digest"</span>: <span>"sha256:85db140f49f9135479330babb875fe46713b7abcaeda290bf36aaf2977688569"</span>
  },
  <span>"layers"</span>: [
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>42050576</span>,
      <span>"digest"</span>: <span>"sha256:7697e6e7be39d9b66c05a4276d8d0674c1b617a4ceec971e2aef37c07240f139"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>1819</span>,
      <span>"digest"</span>: <span>"sha256:b24bc1e6fa6137aa1685aad067db2b22f3c24410f02c3994c8f71d0720f03ba0"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>158</span>,
      <span>"digest"</span>: <span>"sha256:8ba23a6869850ca5c696f5cfd2505ac81c62529315c976736724599bda439704"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>1307298</span>,
      <span>"digest"</span>: <span>"sha256:c0cf0faa3e01881baf1e369ac39b17ef9977aaafe3a18232a5114a5cdec0bef2"</span>
    }
  ]
}</code></p><small id="shcb-language-2"><span>Code language:</span> <span>JSON / JSON with Comments</span> <span>(</span><span>json</span><span>)</span></small></pre>


<p>The container image digest SHA256 hash (not to be confused with the SHA256 hash in the manifest layers) is calculated and created by hashing the manifest output shown above during the push. The container image digest hash will of course change if you change anything in the manifest like schemeVersion(schema1 vs schema2) or mediaType.&nbsp;</p>



<p>IMPORTANT:&nbsp; if you pull, tag, and push an image, the image digest can change in cases where the image layer compression changes and/or the manifest version has been converted. The only secure way is to use skopeo copy!&nbsp;</p>



<p>Usually, images are pushed to a registry via a tag. You can consider a tag as a reference to a specific container image digest, which can be rewritten to another container image (digest).&nbsp; If you want to run a specific version of a container image you can use the container image digest. If something changes on the container image: configuration, filesystem layer the container image digest will change too.</p>



<p>Here an example of the different formats:</p>


<pre><p><code>quay.io/openshift-examples/multi-arch:x86_64
quay.io/openshift-examples/multi-arch:@sha256:6e7f0459dc4c93970c8207f0640ebf0f85a5be180e0981a8a20426dd456f16c7</code></p></pre>


<p>You may discover image tags and digests via curl as outlined in the&nbsp; <a href="https://github.com/opencontainers/distribution-spec/blob/master/spec.md">Open Container Initiative Distribution Specification </a>. Here is an example:</p>



<p>Get the list of tags:</p>


<pre aria-describedby="shcb-language-3" data-shcb-language-name="JavaScript" data-shcb-language-slug="javascript"><p><code>$ curl -s https:
{
  <span>"name"</span>: <span>"openshift-examples/multi-arch"</span>,
  <span>"tags"</span>: [
    <span>"x86_64"</span>,
    <span>"aarch64"</span>
  ]
}</code></p><small id="shcb-language-3"><span>Code language:</span> <span>JavaScript</span> <span>(</span><span>javascript</span><span>)</span></small></pre>


<p>Get the manifest of an tag:</p>


<pre aria-describedby="shcb-language-4" data-shcb-language-name="JavaScript" data-shcb-language-slug="javascript"><p><code>$ curl -s -H <span>'Accept: application/vnd.docker.distribution.manifest.v2+json'</span> \
<span>https</span>:
{
  <span>"schemaVersion"</span>: <span>2</span>,
  <span>"mediaType"</span>: <span>"application/vnd.docker.distribution.manifest.v2+json"</span>,
  <span>"config"</span>: {
    <span>"mediaType"</span>: <span>"application/vnd.docker.container.image.v1+json"</span>,
    <span>"size"</span>: <span>2654</span>,
    <span>"digest"</span>: <span>"sha256:85db140f49f9135479330babb875fe46713b7abcaeda290bf36aaf2977688569"</span>
  },
  <span>"layers"</span>: [
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>42050576</span>,
      <span>"digest"</span>: <span>"sha256:7697e6e7be39d9b66c05a4276d8d0674c1b617a4ceec971e2aef37c07240f139"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>1819</span>,
      <span>"digest"</span>: <span>"sha256:b24bc1e6fa6137aa1685aad067db2b22f3c24410f02c3994c8f71d0720f03ba0"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>158</span>,
      <span>"digest"</span>: <span>"sha256:8ba23a6869850ca5c696f5cfd2505ac81c62529315c976736724599bda439704"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>1307298</span>,
      <span>"digest"</span>: <span>"sha256:c0cf0faa3e01881baf1e369ac39b17ef9977aaafe3a18232a5114a5cdec0bef2"</span>
    }
  ]
}</code></p><small id="shcb-language-4"><span>Code language:</span> <span>JavaScript</span> <span>(</span><span>javascript</span><span>)</span></small></pre>


<p>Get the digest of the manifest:</p>


<pre aria-describedby="shcb-language-5" data-shcb-language-name="JavaScript" data-shcb-language-slug="javascript"><p><code>$ curl -s -H <span>'Accept: application/vnd.docker.distribution.manifest.v2+json'</span> \
 <span>https</span>:
<span>6e7</span>f0459dc4c93970c8207f0640ebf0f85a5be180e0981a8a20426dd456f16c7  -</code></p><small id="shcb-language-5"><span>Code language:</span> <span>JavaScript</span> <span>(</span><span>javascript</span><span>)</span></small></pre>


<p>Get the manifest via sha256:</p>


<pre aria-describedby="shcb-language-6" data-shcb-language-name="JavaScript" data-shcb-language-slug="javascript"><p><code>curl -s -H <span>'Accept: application/vnd.docker.distribution.manifest.v2+json'</span> \
<span>https</span>:
{
  <span>"schemaVersion"</span>: <span>2</span>,
  <span>"mediaType"</span>: <span>"application/vnd.docker.distribution.manifest.v2+json"</span>,
  <span>"config"</span>: {
    <span>"mediaType"</span>: <span>"application/vnd.docker.container.image.v1+json"</span>,
    <span>"size"</span>: <span>2654</span>,
    <span>"digest"</span>: <span>"sha256:85db140f49f9135479330babb875fe46713b7abcaeda290bf36aaf2977688569"</span>
  },
  <span>"layers"</span>: [
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>42050576</span>,
      <span>"digest"</span>: <span>"sha256:7697e6e7be39d9b66c05a4276d8d0674c1b617a4ceec971e2aef37c07240f139"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>1819</span>,
      <span>"digest"</span>: <span>"sha256:b24bc1e6fa6137aa1685aad067db2b22f3c24410f02c3994c8f71d0720f03ba0"</span>
    },
    {
      <span>"mediaType"</span>: <span>"application/vnd.docker.image.rootfs.diff.tar.gzip"</span>,
      <span>"size"</span>: <span>158</span>,
      <span>"digest"</span>: <span>"sha256:8ba23a6869850ca5c696f5cfd2505…</span></code></p></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/">https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/</a></em></p>]]>
            </description>
            <link>https://www.opensourcerers.org/2020/11/16/container-images-multi-architecture-manifests-ids-digests-whats-behind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621963</guid>
            <pubDate>Sun, 03 Jan 2021 14:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developing and Maintaining Gratitude]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621945">thread link</a>) | @Topolomancer
<br/>
January 3, 2021 | https://bastian.rieck.me/blog/posts/2021/gratitude/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2021/gratitude/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>As I reflect back on 2020, a year that was tough on human civilisation
as a whole, I am nevertheless grateful for the many positive experiences
of this year. This post is not a ‘humblebrag’ or a denial of the many
negative things of 2020<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but rather a brief recipe and reminder to
my future self to&nbsp;(further) develop and maintain an attitude of
gratitude. This post is written in the form of questions that I used to
ask myself, as well as the current set of answers I came up with. It is
my hope that readers will find some wisdom here.</p>
<p><strong>Why should I be grateful?</strong> Because, fundamentally, your life is not
about you. At least, it is not <em>just</em> about you. You are interacting<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>
with so many other people and doing a lot of things on a daily basis.
You take all of this for granted—until it is not available any more.
So why not make an effort to be cognisant of their positive impact in
your life?</p>
<p><strong>Can I <em>choose</em> to be grateful?</strong> Yes, you can&nbsp;(see below for more
concrete tips). It is not built into most of us—and as the last year
mercilessly demonstrated, we often take things for granted, until they
are gone, and only <em>then</em> do we start bemoaning their loss.</p>
<p><strong>But is focusing on the positive not a denial of the negative?</strong> Our
brains are—at best—capable of producing medium-fidelity
representations of events in our lives, told from our perspective. While
some parts of our memory are more reliable than others, we are still
plagued by ‘bugs’ such as the <a href="https://en.wikipedia.org/wiki/Misinformation_effect">misinformation effect</a>.
Hence, why not make use of this and deliberately store the positive
things? In my experience, negative events, such as the loss of a loved
on or a severe illness, do not need additional reinforcement to be
remembered. But the small stuff, such as receiving a nice ‘Thank you’
note, will probably fall through the cracks. So, without denying that
bad things happen, why not pay attention to the positive ones?</p>
<p><strong>Will gratitude not stymie my efforts?</strong> This is a though one that
I admittedly wrestled with for a long time. If I am grateful for what
I already <em>have</em>, will I not stop wanting to be <em>more</em>? Setting aside
the question of whether it is useful to want ‘more’, I realised that
gratitude also brings a certain amount of clarity with it. For example,
I realised how grateful I was for the interactions with my colleagues
and students this year. This gave me a good idea of how large I want
my future research group to be—so in this sense, I now know that
I do not necessarily require a larger group, but this does not stifle my
application efforts or my research efforts in the slightest. On the
contrary: it makes me appreciate the time I can spend on these things
even more! I think that it is possible to be grateful for what you have,
and still aspire to improve your skills, your life situation, your
relationships, and so on.</p>
<p><strong>How to be grateful and remain it?</strong> Living on the command-line and in
<a href="https://www.vim.org/"><code>vim</code></a> for many of my working and waking hours,
the easiest solution for me is to have a file in which I can journal
things I am grateful for. This could be anything, from having a nice cup
of coffee while reading a well-written paper in the garden to receiving
a nice e-mail about my research or blog, thus reminding me that this is
not a solipsist adventure<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. Put everything in there whenever you are
moved to do so, and after a few months, you can go back and re-read the
list—I promise you that you will be positively surprised!</p>
<p>As a parting thought, I can also encourage you to be included in other
people’s gratitude files: do not hesitate to express your gratitude to
those that helped you, inspired you, and went out of their way to
support you in any way<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> With that, I wish you a blessed 2021. May of
all you find lots of things to be grateful about. Until next time!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>And for all of us, there were plenty of these! <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Maybe not in person, but certainly through other media… <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>One of my&nbsp;(many) blind spots is not being aware of the impact
that even a short positive e-mail or tweet can have on people. Keeping
track of these things is a powerful reminder. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>I am the first to admit that I do not do this often enough, hence
this post as a reminder. <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2021/gratitude/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621945</guid>
            <pubDate>Sun, 03 Jan 2021 14:29:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Varlink: Interface description format and protocol for humans and machines]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25621936">thread link</a>) | @based2
<br/>
January 3, 2021 | https://varlink.org/FAQ | <a href="https://web.archive.org/web/*/https://varlink.org/FAQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
          
        
        <h2 id="what-does-varlink-provide">What does varlink provide?</h2>

<p>Everybody understands it. Varlink uses a simple human and machine readable <a href="https://varlink.org/#interface">text file</a> to
describe an interface with all its data types, method calls and errors. The text file, in its simplicity,
does not require any specific knowledge to join a discussion about design, development, and
maintenance of an API.</p>

<p>It documents itself, in the sources and on the wire. Varlink interfaces describe themselves readable to
humans and reliably consumable by machines. Varlink services are introspectable at runtime. Varlink
interfaces provide their documentation along with the interface description.</p>

<p>Everything is readable. Varlink uses plain text messages, has no magic numbers, no unnamed values, is
easily debuggable with things like
<a href="https://en.wikipedia.org/wiki/Strace">strace</a>,
<a href="https://en.wikipedia.org/wiki/Netcat">netcat</a>,
<a href="https://stedolan.github.io/jq/">jq</a>.</p>

<p>Varlink itself is simpler than the service that uses it. Varlink uses direct connections, has no
central message handling component, it is easily debugged, secured, isolated, tested.</p>

<h2 id="which-transports-can-be-used-to-speak-varlink">Which transports can be used to speak varlink?</h2>

<p>Varlink can be implemented on any connection-oriented transport.The most common example are streaming
sockets, but it can also be implemented on kernel special files like device nodes or encapsulated in
other protocols, like HTTP, GSS-API or SASL.</p>

<h2 id="how-can-i-monitor-changes-or-subscribe-to-signals">How can I monitor changes or subscribe to signals?</h2>

<p>Varlink connections can be turned into monitor connections, they are soft-negotiated between the
client and the service. The client asks the server to possibly reply with more than one reply, the
server replies and indicates that it might have more replies and the client should wait for them.</p>

<p>To avoid race conditions between the reading of the current state and subscribing to updates, a
typical varlink monitor method call first returns the current state and then sends changes in
subsequent replies to the same request on the same connection.</p>

<h2 id="why-are-there-no-sequence-numbers-in-calls-and-replies">Why are there no sequence numbers in calls and replies?</h2>

<p>Varlink operates on connections, all messages are strictly in order on the same connection and always
received in the order they are sent. Connections support message pipelining, but not multiplexing.
Complex interfaces can use multiple connections at the same time.</p>



<p>The varlink message <a href="https://varlink.org/Method-Call">header</a> can be extended by vendors if needed. Added keys should use
the reverse-domain notation including the vendor’s name. The concept is similar to the X-prefix used for
HTTP headers, but neither they nor naked keywords should be added by vendors, since they may clash with
other vendors or future varlink protocol specifications.</p>

<h2 id="why-are-records-separated-by-a-nul-character-and-do-not-specify-a-length">Why are records separated by a NUL character and do not specify a length?</h2>

<p>The simplest possible transport of varlink messages is a raw streaming socket, which forwards JSON
records separated by a NUL character. Conceptually the NUL character belongs to the transport not to
the varlink message. If varlink messages are encapsulated in HTTP, HTTP will specify the record length
and not use a NUL byte.</p>

<h2 id="why-are-there-no-unsigned-integers-and-why-are-there-no-integer-sizes-specified">Why are there no unsigned integers, and why are there no integer sizes specified?</h2>

<p>Like JSON, varlink is intentionally underspecified in this regard. The implementation should use
integers large enough to carry the signed integer value, and return an error if it cannot handle the
received number.</p>

<h2 id="the-varlink-type-system-specifies-features-which-do-not-directly-map-to-json-how-are-they-serialized">The varlink type system specifies features which do not directly map to JSON, how are they serialized?</h2>

<p><a href="https://varlink.org/Interface-Definition#type">Enums</a> are serialized as a JSON name/value pair, with the enum value as a
string. <a href="https://varlink.org/Interface-Definition#type">Maps</a> are serialized as JSON objects, every map element is
represented as a name/value pair.</p>

<h2 id="can-i-transmit-file-descriptors">Can I transmit file descriptors?</h2>

<p>Varlink intentionally does not support features or side-effects specific to transports. Encapsulating
varlink messages in other protocols, passing them over proxies is a requirement of varlink.</p>

<h2 id="how-can-i-reference-a-file">How can I reference a file?</h2>

<p>Varlink should be remotable, therefore you should not point a remote service to a file, which is local
to the client. Just send the content and an identifier/name of the file.</p>

<h2 id="how-can-i-transfer-larger-amounts-or-foreign-data">How can I transfer larger amounts or foreign data?</h2>

<p>You can either send the data as a string, or use the “upgraded” connection feature, where you opt-out
of the varlink protocol after calling a method with the <code>upgrade</code> <a href="https://varlink.org/Method-Call">header</a> field set
to <code>true</code>. After sending this message the connection is yours for sending whatever you want. To
speak the varlink protocol to the service again, you need to open a new connection. Upgraded varlink
connections are similar to the websocket concept.</p>

<h2 id="when-is-a-oneway-request-useful">When is a <code>oneway</code> request useful?</h2>

<p>Setting <code>oneway</code> in a <a href="https://varlink.org/Method-Call">method call</a> means that the service will not send a reply. This
might be useful when many messages are sent as part of one transaction, and only one single reply is
needed to confirm the transaction. It might also be useful for non-critical data like a debugging
interface, to minimize round-trip handling.</p>

<p>The most important reason to add this feature right from the start is, that it could not be added to
the protocol at a later time, because all implementations need to support it right away to correctly
handle the strict message ordering requirement.</p>

<h2 id="why-are-there-no-error-numbers-or-human-readable-messages-in-errors">Why are there no error numbers or human readable messages in errors?</h2>

<p>Varlink errors are interface-specific and identified by a string. If required, Interfaces could add a
<code>message</code> field to the error parameters which contain human readable text. The primary focus of
varlink errors is machine consumption, in most cases a carefully chosen descriptive CamelCase error
sufficiently describes the error to humans.</p>

<h2 id="how-do-i-find-the-service-which-implements-a-local-interface">How do I find the service which implements a local interface?</h2>

<p>On systems with the <code>org.varlink.resolver</code> interface reachable on a defined varlink URI, the
client can call the <code>method org.varlink.resolver.Resolve(interface: string) -&gt; (address: string)</code>.</p>

<h2 id="how-are-varlink-services-accessed-from-a-remote-machine">How are varlink services accessed from a remote machine?</h2>

<p>The varlink command line tool, as well as some varlink language bindings offer the possibility to
connect to a service via a <code>bridge</code>.</p>


<ul>
  <li>Python:
<a href="https://varlink.org/python/#varlink.Client.new_with_bridge">varlink.Client.new_with_bridge()</a></li>
  <li>Rust:
<a href="https://docs.rs/varlink/4.0.0/varlink/struct.Connection.html#method.with_bridge">Connection::with_bridge()</a></li>
</ul>

<p>The bridge command normally is <code>ssh &lt;host&gt; varlink bridge</code>, calling <code>varlink bridge</code> on the
remote host. The <code>varlink bridge</code> command parses all method calls on stdin, queries the
<code>org.varlink.resolver</code> on the remote system for the interface address, connects to this address
and forwards all method calls matching the interface name to the local service on the remote machine.
It reads the replies and passes them back to stdout. Instead of <code>ssh</code> any other connection command
 could be used. Instead of <code>varlink bridge</code> any other utility, which offers an equal
 functionality, could be used.</p>

<h2 id="how-can-i-get-the-version-number-of-an-interface">How can I get the version number of an interface?</h2>

<p>Varlink interfaces do not have a version number, they only have a feature set described in detail by
the interface definition, which is part of the wire protocol.</p>

<p>If your interface has users, you should not break the interface, only extend it, never remove or
incompatibly change things which might be already in use. Clients can fully introspect a service and
figure out which features the interface supports; this is more expressive than any simple numbering
scheme. If you break the API or remove stuff, just release it with a new name, commonly done by adding
a number to the interface name, like <code>org.example.interface2</code>.</p>

<h2 id="how-do-i-extend-an-interface-in-a-backwards-compatible-way">How do I extend an interface in a backwards compatible way?</h2>

<p>Varlink does not use positional parameters or fixed-size objects in its interface definition or on the
 wire, all parameters are identified by their name and can be extended later.</p>

<p>Things like this are not needed:</p>
<pre><code>typedef struct {
       /* … */
       /*
        * Reserved space to allow possible future extensions without
        * breaking the ABI. You should not touch these, because the
        * names of these variables may change.
        */
       uint32_t reserved_int1;
       uint32_t reserved_int2;
       uint32_t reserved_int3;
       uint32_t reserved_int4;
} my_service_struct_foo;
</code></pre>

<p>Extending existing structures should be done via optional fields (nullable type, maybe). The result of
the methods, when passed parameters without the optional fields should be the same as in older
versions. Method parameters can be extended the same way. The expected behavior for omitted
fields/parameters should be documented. Removing fields, types, errors or methods are not backward
compatible and should be avoided.</p>

<h2 id="how-does-socket-activation-work">How does socket activation work?</h2>

<p>Varlink language bindings commonly implement the systemd socket activation protocol. The environment
of the started service will be augmented with the variables LISTEN_FDS, LISTEN_NAMES, LISTEN_PID.</p>

<p><a href="https://www.freedesktop.org/software/systemd/man/sd_listen_fds.html">Read more</a></p>

<h2 id="how-do-i-implement-exit-on-idle-for-my-service">How do I implement exit-on-idle for my service?</h2>

<p>Services can be started on-demand with socket activation. When there is no background task running and
no clients connected to the service, the service can decide to close the listening socket and exit. A
new connection from a client will activate the service again. Because varlink is strictly
point-to-point, there is no buffering involved and the service activator will queue all incoming
messages, exit-on-idle can be implemented in a race-free manner.</p>

<h2 id="how-can-i-restrict-the-access-to-my-service">How can I restrict the access to my service?</h2>

<p>The most commonly used method is to rely on the permissions of a UNIX socket in the file system.
Services which need a more fine-grained access control can check the connection credentials of a unix
socket and decide per call if they want to act on behalf of the client.
If varlink would be wrapped in GSS-API, e.g. kerberos tickets could be used for more fine grained
access control.</p>

        
      </section></div>]]>
            </description>
            <link>https://varlink.org/FAQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621936</guid>
            <pubDate>Sun, 03 Jan 2021 14:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Linux Backups with Restic and B2 Cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25621893">thread link</a>) | @majormjr
<br/>
January 3, 2021 | https://roote.ca/about/tutorials/restic-backups/ | <a href="https://web.archive.org/web/*/https://roote.ca/about/tutorials/restic-backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h3 id="reliable-backups-on-a-linux-system-with-restic-and-systemd">Reliable Backups on a Linux System with Restic and systemd</h3><p>Backups are a critical part of ensuring your data stays safe. Losing data is not something anyone wants to experience and reliable backups are how to ensure this never happens.</p><p>Backup infrastructure is critical but shouldn’t require large amounts of time to maintain. A program to create backups should work quietly in the background while ensuring data integrity and safety.</p><p>Restic is a great backup tool with powerful features like deduplication and encryption. It supports B2 cloud as a storage backend allowing offsite backups for an inexpensive price. Restic is a CLI tool and doesn’t include any scheduled tasks to run to create backups regularly. This tutorial configures systemd to run daily backups, prune the backup repository and run data integrity checks periodically.</p><h3 id="creating-the-config-file">Creating the config file</h3><p>This file contains the authentication details as well as any settings to provide to the Restic command. Save the file with restrictive permissions only readable by the root user to prevent leaking the credentials.</p><div><pre><code data-lang="bash">❯ sudo cat /etc/restic-backup.conf
BACKUP_PATHS<span>=</span><span>"/etc/restic.includes"</span>
EXCLUDE_PATHS<span>=</span><span>"/etc/restic.excludes"</span>
RETENTION_DAYS<span>=</span><span>7</span>
RETENTION_WEEKS<span>=</span><span>8</span>
RETENTION_MONTHS<span>=</span><span>12</span>
RETENTION_YEARS<span>=</span><span>10</span>
B2_ACCOUNT_ID<span>=</span><span>""</span>
B2_ACCOUNT_KEY<span>=</span><span>""</span>
RESTIC_REPOSITORY<span>=</span><span>"b2:[REPO_NAME]:/"</span>
RESTIC_PASSWORD<span>=</span><span>""</span>
RESTIC_CACHE_DIR<span>=</span>/tmp/restic_cache
</code></pre></div><div><pre><code data-lang="bash">❯ sudo cat /etc/restic.includes
/home/mitch
</code></pre></div><div><pre><code data-lang="bash">❯ sudo cat /etc/restic.excludes
**/node_modules/**
**.local/share/Steam/**
**/.stversions/**
**/.PlayOnLinux/**
**/.local/share/Trash/**
**/downloads/**
</code></pre></div><h3 id="configuring-systemd">Configuring systemd</h3><p>This backup configuration consists of three systemd service units, ‘restic-backup’, ‘restic-prune’, and ‘restic-check’. These three units each run a specific job to maintain the Restic repository. There are separate timer unit files to run the backup tasks periodically. Once the unit files are in place, use the <code>systemctl</code> command to activate and start the timer services.</p><h4 id="restic-backup">restic-backup</h4><p>The <code>restic-backup.service</code> unit handles creating the backup snapshots.</p><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-backup.service
<span>[</span>Unit<span>]</span>
Description<span>=</span>Restic system backup
Conflicts<span>=</span>restic-prune.service restic-check.service
JoinsNamespaceOf<span>=</span>restic-prune.service restic-check.service

<span>[</span>Service<span>]</span>
Type<span>=</span>oneshot
ExecStart<span>=</span>restic backup --verbose --tag auto-backup --iexclude-file $EXCLUDE_PATHS --files-from $BACKUP_PATHS 
EnvironmentFile<span>=</span>/etc/restic-backup.conf
SuccessExitStatus<span>=</span><span>3</span>
</code></pre></div><p>The backup frequency is configured with the <code>restic-backup.timer</code> unit file.</p><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-backup.timer
<span>[</span>Unit<span>]</span>
Description<span>=</span>Backup with restic daily

<span>[</span>Timer<span>]</span>
OnCalendar<span>=</span>daily
RandomizedDelaySec<span>=</span>6hours
Persistent<span>=</span>true

<span>[</span>Install<span>]</span>
WantedBy<span>=</span>timers.target
</code></pre></div><h4 id="restic-prune">restic-prune</h4><p>The <code>restic-prune.service</code> unit runs the prune command on the repo, using the retention periods configured in the <code>restic-backup.conf</code> file. This unit is configured to run after the backup unit.</p><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-prune.service
<span>[</span>Unit<span>]</span>
Description<span>=</span>Restic prune to clean up old backups
After<span>=</span>restic-backup.service
Conflicts<span>=</span>restic-backup.service restic-check.service
JoinsNamespaceOf<span>=</span>restic-backup.service restic-check.service

<span>[</span>Service<span>]</span>
Type<span>=</span>oneshot
ExecStart<span>=</span>restic forget --prune -o b2.connections<span>=</span><span>10</span> --compact --tag auto-backup --cleanup-cache --keep-daily $RETENTION_DAYS --keep-weekly $RETENTION_WEEKS --keep-monthly $RETENTION_MONTHS --keep-yearly $RETENTION_YEARS
EnvironmentFile<span>=</span>/etc/restic-backup.conf
</code></pre></div><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-prune.timer
<span>[</span>Unit<span>]</span>
Description<span>=</span>Prune restic backups daily

<span>[</span>Timer<span>]</span>
OnCalendar<span>=</span>daily
RandomizedDelaySec<span>=</span>6hours
Persistent<span>=</span>true

<span>[</span>Install<span>]</span>
WantedBy<span>=</span>timers.target
</code></pre></div><h4 id="restic-check">restic-check</h4><p>The <code>restic-check.service</code> unit runs the consistency check on the repo to ensure data integrity.</p><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-check.service
<span>[</span>Unit<span>]</span>
Description<span>=</span>Restic system backup repository consitency check
Conflicts<span>=</span>restic-backup.service restic-prune.service
JoinsNamespaceOf<span>=</span>restic-backup.service restic-prune.service
After<span>=</span>restic-prune.service

<span>[</span>Service<span>]</span>
Type<span>=</span>oneshot
ExecStart<span>=</span>restic check
EnvironmentFile<span>=</span>/etc/restic-backup.conf
</code></pre></div><p>This unit is configured to run weekly.</p><div><pre><code data-lang="bash">❯ cat /etc/systemd/system/restic-check.timer
<span>[</span>Unit<span>]</span>
Description<span>=</span>Check restic repository consistency

<span>[</span>Timer<span>]</span>
OnCalendar<span>=</span>weekly
RandomizedDelaySec<span>=</span>1day
Persistent<span>=</span>true

<span>[</span>Install<span>]</span>
WantedBy<span>=</span>timers.target
</code></pre></div><h3 id="activating-systemd-units">Activating systemd units</h3><p>After configuring the unit files the systemctl configuration will need to be reloaded, then the timer units activated and started.</p><div><pre><code data-lang="bash">systemctl daemon-reload
systemctl enable restic-backup.timer restic-prune.timer restic-check.timer
systemctl start restic-backup.timer restic-prune.timer restic-check.timer
</code></pre></div><p>The system should now create daily backups, prune any extra data daily, and check the repository consistency weekly.</p><p>Check the backup timer status with <code>systemctl list-timers</code> and individual units with <code>systemctl status restic-backup</code>.</p></section></div>]]>
            </description>
            <link>https://roote.ca/about/tutorials/restic-backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621893</guid>
            <pubDate>Sun, 03 Jan 2021 14:19:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GTK4 for Graphical User Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25621700">thread link</a>) | @chauhankiran
<br/>
January 3, 2021 | http://ssalewski.de/gtkprogramming.html | <a href="https://web.archive.org/web/*/http://ssalewski.de/gtkprogramming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://ssalewski.de/gtkprogramming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621700</guid>
            <pubDate>Sun, 03 Jan 2021 13:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Auto-labeling Kubernetes resources with Kyverno]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621623">thread link</a>) | @kiyanwang
<br/>
January 3, 2021 | https://nirmata.com/2020/10/30/auto-labeling-kubernetes-resources-with-kyverno/ | <a href="https://web.archive.org/web/*/https://nirmata.com/2020/10/30/auto-labeling-kubernetes-resources-with-kyverno/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
											
									<div>
										<div>	
											
		<article id="post-6967">
			<div>
									<p><span>
						<span>October 30, 2020</span>
					</span>
													<span>
						<span>In</span>
						<span><a href="https://nirmata.com/category/product/" rel="category tag">Product</a></span>
					</span>
													
							</p></div>
			
			<div>
										
								<div>
					<div>
																		<div>
							<h2>Introduction</h2>
<p><span>As Kubernetes has become the foundational building block for enterprises to go cloud-native, the last couple of years have seen many solutions that have simplified the cluster creation process. But the Day-2 operations around Kubernetes still remains a complex endeavor, slowing down adoption and increasing the operational costs. Kubernetes’ complexity and skills gaps still remain the biggest factors that are in the way of Enterprise’s adoption of Kubernetes.</span></p>
<p><span>Many of the Day-2 operations use cases include requirements for the central platform team to deliver secure and compliant environments to developers as efficiently as possible with necessary services and best practices preconfigured. Some examples of such use cases include configuring environments with Kubernetes best practices like resource quotas, network policy and pod security. This requires tools that can assess the environments as they are created and then configure them in compliance with the standard defined by the central platform team.</span></p>
<h2><strong>Kyverno: A Flexible Ops Tool for K8s</strong></h2>
<p><span>Kubernetes provides powerful constructs like admission control webhooks that can be leveraged for the purposes of validating and mutating resources. Nirmata’s </span><a href="https://kyverno.io/"><span>Kyverno</span></a><span> was designed specifically to address these types of use cases using the declarative paradigm. Kyverno is an open-source policy engine that was designed for Kubernetes, It provides users with familiar constructs to write custom rules and easily implement to validate, mutate, and generate new resources as needed.</span></p>
<p><span>Managing Kubernetes at scales requires the following best practices and applying standardization across configurations. One such pattern is to use Kubernetes labels. In Kubernetes, every resource can have one or more labels and Kubernetes makes it easy to find and manage the resources using labels.</span></p>
<p><span>A very common use case for Day-2 operations is managing labels across namespaces and pods so that use cases like certificate updates, self-service logging/monitoring, backups etc. can be easily implemented by other Kubernetes controllers and operators.</span></p>
<h2><strong>Auto-Labeling Namespaces</strong></h2>
<p><span>Below is an example of how to implement namespace labeling upon creation in a Kubernetes cluster using Kyverno.&nbsp;</span></p>
<p><span>Install Kyverno in your cluster:</span></p>
<div>
<pre data-lang="Bash"><code>kubectl create -f https://github.com/kyverno/kyverno/raw/master/definitions/install.yaml</code></pre>
</div>
<p><span>Detailed installation instructions are available </span><a href="https://kyverno.io/docs/installation/"><span>here</span></a><span>.</span></p>
<p><span>Here is a sample Kyverno policy that adds labels to namespaces&nbsp; –&nbsp;</span></p>
<div>
<pre data-lang="YAML"><code>apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata: 
  name: add-labels
spec: 
  background: false
  rules:
  - name: add-ns-label
    match:
      resources:
        kinds: 
        - Namespace
    exclude:
      clusterroles: ["cluster-admin"]
    mutate: 
      patchStrategicMerge:
        metadata:
          labels:
            kyverno/user: "{{ request.userInfo.username }}"
            +(kyverno/network): "default"</code></pre>
</div>
<p><span>The policy inserts a label `</span><span>kyverno/user`</span><span>with the value of the user making the API request to create the namespace. The policy also inserts a label `</span><span>kyverno/network</span><span>`, but only if one is not already specified by the user. This simple policy demonstrates some powerful features in Kyverno like </span><a href="https://kyverno.io/docs/writing-policies/writing-policies-variables/"><span>variable substitution</span></a><span> and </span><a href="https://kyverno.io/docs/writing-policies/writing-policies-validate/"><span>conditional anchors</span></a><span>.</span></p>
<p><span>Once the policy is configured in your cluster, create a new namespace and verify the labels have been added to the namespace automatically.</span></p>
<p>Create a new namespace:</p>

<p>View the namespace:</p>
<div>
<pre data-lang="Bash"><code><span>kubectl get ns test -o yaml</span></code></pre>
</div>
<p>This should show a namespace similar to:</p>
<div>
<pre data-lang="YAML"><code>apiVersion: v1
kind: Namespace
metadata:
  labels:
    kyverno/network: default
    kyverno/user: docker-for-desktop</code></pre>
</div>
<p><span>Now, what if you want to make sure that users cannot update a specific label?</span></p>
<p>Kyverno makes that easy to do as well! <span>Here is a policy that prevents the update of the `</span><span>kyverno/network</span><span>` label:</span></p>
<div>
<pre data-lang="YAML"><code>apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: protect-label
spec:
  validationFailureAction: enforce
  background: false
  rules:
  - name: block-updates-for-label
    match:
      resources:
        kinds:
           - Namespace
  validate:
    message: Updating label `kyverno/network` is not allowed
    deny:
    - key: "{{ request.operation }}"
      operator: "EQUALS"
      value: UPDATE</code></pre>
</div>
<h2><strong>Summary</strong></h2>
<p><span>Managing Kubernetes configurations can be complex, and policy engines provide standardization, automated validation, and the ability to mutate and generate configurations.</span></p>
<p><span>Kyverno is an open-source policy engine designed for Kubernetes. It has a minimal learning curve and provides tremendous flexibility for Kubernetes administrators to solve Day-2 operations challenges using Kubernetes’ powerful declarative management capabilities and native tools.&nbsp;&nbsp;</span></p>
<p><span>Learn what else </span><span>Kyverno</span> can do at <a href="https://kyverno.io/" target="_blank" rel="noopener noreferrer">https://kyverno.io</a>.</p>
							
															
													</div>
					</div>
				</div>
			</div>
			
		</article>										</div>
										
										
 
 
						
								
							


 
									</div>
								</div></div>]]>
            </description>
            <link>https://nirmata.com/2020/10/30/auto-labeling-kubernetes-resources-with-kyverno/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621623</guid>
            <pubDate>Sun, 03 Jan 2021 13:23:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward a Synthetic Benchmark to Assess VM Startup, Warmup, Cold-Code Performance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621616">thread link</a>) | @matt_d
<br/>
January 3, 2021 | https://stefan-marr.de/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/ | <a href="https://web.archive.org/web/*/https://stefan-marr.de/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>One of the hard problems in language implementation research is benchmarking.
Some people argue, we should benchmark only applications that actually matter
to people. Though, this has various issues. Often, such applications are embedded in
larger systems, and it’s hard to isolate the relevant parts. In many cases,
these applications can also not be made available to other researchers.
And, of course, things change over time, which means
maintaining projects like <a href="http://dacapobench.org/">DaCapo</a>, <a href="https://renaissance.dev/">Renaissance</a>,
or <a href="https://browserbench.org/JetStream/">Jet Stream</a> is a huge effort.</p>

<p>Which brought me to the perhaps futile question of how we could have more realistic
synthetic benchmarks. <a href="https://dl.acm.org/doi/10.1145/2491894.2464161">ACDC</a>
and <a href="https://research.google/pubs/pub43216/">ACDC-JS</a> are synthetic garbage collection benchmarks.
While they don’t seem to be widely used, they seemed to have been a useful
tool for specific tasks. Based on observing metrics for a range of relevant
programs, these synthetic benchmarks were constructed to be configurable
and allow us to measure a range of realistic behaviors.</p>

<p>I am currently interested in the startup, warmup, and cold-code performance
of virtual machines, and want to study their performance issues.
To me it seems that I need to look at large programs to get interesting and relevant results. With large, I mean millions of lines of code, because that’s where our systems currently struggle.
So, how could we go about to create a synthetic benchmark for huge code bases?</p>

<h2 id="generating-random-code-that-looks-real">Generating Random Code that Looks Real</h2>

<p>In my last two blog posts [<a href="https://stefan-marr.de/2020/12/shape-of-large-source-code/">1</a>, <a href="https://stefan-marr.de/2020/12/shape-of-large-source-code-ruby/">2</a>],
I looked at the shape of large code bases in Pharo and Ruby to obtain data
for a new kind of synthetic benchmark. I want to try to generate random code
that looks “real”. And by looking real I mean for the moment that it is shaped
in a way that is similar to real code. This means, methods have realistic
length, number of local variables, and arguments. For classes, they should have
a realistic number of methods and instance variables.
In the last two blog posts, I looked at the corresponding static code metrics
to get an idea of how large code bases actually look like.</p>

<p>In this post, I am setting out to use the data to get a random number generator
that can be used to generate “realistic looking” code bases.
Of course, this doesn’t mean that the code does do anything realistic.</p>

<p>Small steps… One at a time… 👨🏼‍🔬</p>

<p>So, let’s get started by looking at how the length of methods looks like in
large code bases.</p>

<p>Before we get started, just one more simplification: I will only consider
methods that have 1 to 30 lines (of code).
Setting an upper bound will make some of the steps here simpler,
and plots more legible.</p>

<p>And a perhaps little silly, but nonetheless an issue, it will avoid me having to change
one of the language implementations I am interested in, which is unfortunately
limited to 128 bytecodes and 128 literals (constants, method names, etc.),
which in practice translates to something like 30 lines of code.
While this could be fixed, let’s assume 30 lines of code per method
ought to be enough for anybody…</p>

<h2 id="length-of-methods">Length of Methods</h2>

<p>When it comes to measuring the length of methods,
there are plenty of possibly ways to go about.
Pharo counts the non-empty lines.
And for Ruby, I counted either all lines, or the lines that are not just empty
and not just comments.</p>

<p>The histogram below shows the results for methods with 1-30 lines.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/loc-per-methods-1.png"><figcaption>Distribution of the length of methods.</figcaption></figure>

<p>Despite difference in languages and metrics, we see a pretty similar shape.
Perhaps with the exception of the methods with 1-3 lines.</p>

<h2 id="generating-realistic-method-length-from-uniform-random-numbers">Generating Realistic Method Length from Uniform Random Numbers</h2>

<p>Before actually generating method length randomly, let’s define the goal a bit
more clearly.</p>

<p>In the end, I do want to be able to generate a code base where
the length of methods has a distribution very similar to what we see
for Ruby and Pharo.</p>

<p>Though, the random number generators we have in most systems generate numbers
in a uniform distribution typically in the range from 0 to 1.
This means, each number between 0 and 1 is going to be equally likely to be
picked.
To get other kinds of distributions,
for instance the normal distribution,
we can use what is called the <em>inverted cumulative distribution function</em>.
When we throw our uniformly distributed numbers into this function,
we should end up with random numbers that are distributed according to the
distribution that we want.</p>

<p>One of the options to do this would be:</p>

<ol>
  <li>determine the cumulative distribution of the method length</li>
  <li>approximate a function to represent the cumulative distribution</li>
  <li>and invert the function</li>
</ol>

<p>I found this <a href="https://blog.demofox.org/2017/08/05/generating-random-numbers-from-a-specific-distribution-by-inverting-the-cdf/">post here helpful</a>.
Though, I struggled defining a good enough function to get results I liked.</p>

<p>So, instead, let’s do it the pedestrian way:</p>

<ol>
  <li>calculate the cumulative sum for the method length (cumulative distribution)</li>
  <li>normalize it to the sum of all lengths</li>
  <li>use the result to look up the desired method length for a uniform random number</li>
</ol>

<h3 id="determining-the-cumulative-distribution">Determining the Cumulative Distribution</h3>

<p>Ok, so, the first step is to determine the cumulative distribution.
Since we have the three different cases for Pharo, Ruby with all lines and lines of code,
this is slightly more interesting.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/cum-dist-method-length-1.png"><figcaption>Percentage of methods with a specific length in lines or LOC.</figcaption></figure>

<p>The plot above shows the percentage of methods that have a length
smaller or equal to a specific size.</p>

<p>So, the next question is, which metrics should I choose?
Since the data is a bit noisy, especially for small methods,
let’s try and see what the different types of means give us.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/cum-dist-means-1.png"><figcaption>Different means applied to the cumulative percentage of methods for a given length.</figcaption></figure>

<p>From the above plot, the geometric mean seems a good option.
Mostly because I don’t want to have a too high and too low number of methods
with a single line.</p>

<p>Using the geometric mean, gives us the following partial cumulative distribution
table:</p>

<table>
 <thead>
  <tr>
   <th> length </th>
   <th> cum.perc </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td> 1 </td>
   <td> 0.0520631 </td>
  </tr>
  <tr>
   <td> 2 </td>
   <td> 0.2647386 </td>
  </tr>
  <tr>
   <td> 3 </td>
   <td> 0.5137505 </td>
  </tr>
  <tr>
   <td> 4 </td>
   <td> 0.6068893 </td>
  </tr>
  <tr>
   <td> 5 </td>
   <td> 0.6851248 </td>
  </tr>
  <tr>
   <td> 6 </td>
   <td> 0.7377313 </td>
  </tr>
  <tr>
   <td> 7 </td>
   <td> 0.7861208 </td>
  </tr>
  <tr>
   <td> 8 </td>
   <td> 0.8200427 </td>
  </tr>
  <tr>
   <td> 9 </td>
   <td> 0.8490800 </td>
  </tr>
</tbody>
</table>

<p>In R, the language I use for these blog posts,
I can then use something like the following to take a uniform random number
from the range of 0-1 to determine the desired method length in the range
of 1-30 lines (<code>u</code> being here the random number):</p>

<div><div><pre><code>loc_from_u &lt;- function (u) {
  Position(function (e) { u &lt; e }, cumulative_distribution_tbl)
}
</code></pre></div></div>

<p>There are probably more efficient ways of going about it.
I suppose a binary search would be a good option, too.</p>

<p>The general idea is that with our random number <code>u</code>,
we find the last position in our array with the cumulative distribution,
where <code>u</code> is smaller than the value in the array at that position.
The position then corresponds to the desired length of a method.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/result-with-test-1.png"><figcaption>Three examples of methods generated, for 100, 1,000, or 100,000 methods.</figcaption></figure>

<p>As a test, the three plots above are generated from 100, 1,000, and 100,000
uniformly distributed random numbers, and it looks pretty good.
Comparing to the very first set of plots in this post, this seems like a workable
and relatively straightforward approach.</p>

<p>To use these results and generate methods of realistic sizes in other languages,
the full cumulative
distribution is as follows: [0.0520631241473676, 0.264738601144803, 0.51375051909561, 0.606889305644881, 0.685124787391578, 0.737731315373305, 0.786120782303596, 0.820042695503066, 0.849080035429476, 0.872949669419948, 0.893437469528804, 0.909716501217452, 0.923766913966731, 0.935357118689879, 0.945074445934092, 0.953001059092301, 0.959743413722937, 0.965457396618992, 0.97072530951053, 0.975142363341172, 0.979105371695575, 0.982654867280203, 0.985723232507825, 0.988399223471247, 0.990960559703172, 0.993172997617124, 0.9951015059492, 0.996855138214434, 0.998541672752458, 1].</p>

<h2 id="method-arguments-and-local-variables">Method Arguments and Local Variables</h2>

<p>With the basics down, we can look at the number of arguments and local variables
of methods. One thing I haven’t really thought about in the previous posts
is that there’s a connection between the various metrics. They are not independent of each other.</p>

<p>Perhaps this is most intuitive for the number of local variables a method has.
We wouldn’t expect a method with a single line of code to have many local
variables, while longer methods may tent to have more local variables, too.</p>

<h3 id="number-of-method-arguments">Number of Method Arguments</h3>

<p>Let’s start out by looking at how method length and number of arguments relate
to each other.</p>

<p>I’ll use the cumulative distribution for these plots, since that’s what I am
looking for in the end.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/cum-dist-num-args-1.png"><figcaption>Percentage of methods with a specific number of arguments.</figcaption></figure>

<p>The two plots above show for each method length from 1-30 a line
(so, this is where limiting the method length becomes actually handy).
Though, because there are many, I highlight only every third length,
including length 1 methods.
The bluest blue is length 1, and the red is length 30.</p>

<p>We can see here differences between the languages.
For instance, for methods with only 1 line in Pharo, only ≈45% of them
have no argument. While for Ruby methods, that’s perhaps around 70%.</p>

<p>The other interesting bit that is clearly visible is that the number
of arguments doesn’t have a simple direct relationship to length.
Indeed, longer methods seem to have more likely fewer arguments.
While medium length methods are more likely to have a few more arguments,
at least for the Ruby data this seems to be the case.</p>

<p>So, from these plots, I conclude that I actually need a different cumulative
distribution table for each method length. Since we saw how they look for
method length, I won’t include the details. Though, of course happy to share
the data if anyone wants it.</p>

<h3 id="number-of-methods-locals">Number of Methods Locals</h3>

<p>Next up, let’s look at the number of locals.</p>

<figure><img src="https://stefan-marr.de/assets/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/cum-dist-num-locals-1.png"><figcaption>Percentage of methods with a specific number of local variables.</figcaption></figure>

<p>For the Pharo data, it’s not super readable, but basically 100% of methods
of length 1 have zero local variables.
Compared to the plot on arguments, we also see a pretty direct relationship
to length, because the blue-to-red gradient comes out nicely in the plot.</p>

<p>In the case of Ruby, this seems to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stefan-marr.de/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/">https://stefan-marr.de/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/</a></em></p>]]>
            </description>
            <link>https://stefan-marr.de/2021/01/towards-a-synthetic-vm-startup-cold-code-benchmark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621616</guid>
            <pubDate>Sun, 03 Jan 2021 13:21:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iterative Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621600">thread link</a>) | @cturner
<br/>
January 3, 2021 | http://songseed.org/post/20210103.aa.iterative.development.html | <a href="https://web.archive.org/web/*/http://songseed.org/post/20210103.aa.iterative.development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://songseed.org/post/20210103.aa.iterative.development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621600</guid>
            <pubDate>Sun, 03 Jan 2021 13:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Age vs. Time to Recall]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25621596">thread link</a>) | @trwhite
<br/>
January 3, 2021 | https://notoriousbfg.com/code-age-vs-time-to-recall | <a href="https://web.archive.org/web/*/https://notoriousbfg.com/code-age-vs-time-to-recall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>A colleague of mine has repeatedly called for some of the controllers in our project to be refactored. He says they're messy, but what I think he means is that they're hard to understand. At first glance they do seem complex yes but upon closer inspection:</p><ul>
<li>There are step-by-step instructions in the comments explaining what's going on.</li>
<li>Variable and method names are descriptive but not overly verbose.</li>
<li>The code is spaced, formatted and indented correctly.</li>
</ul><p>I can see why my colleague might see the code this way; it does have multiple concerns, but it came to be this way iteratively over the course of two years. Everything it does relates to a previously-defined requirement i.e. it does what it's supposed to. We also haven't made any changes to it for several months because it hasn't caused any bugs nor are there any major performance bottlenecks.</p><p>One common developer bias is that old code is bad. You've never heard anyone say the phrase "legacy code" without contempt in their tone. I <i>can</i> appreciate that sometimes old code doesn't conform to newer practices agreed on by a team. For example, legacy PHP code might use the now-deprecated PSR-2 standard, but the tech lead might want everyone to write PSR-12. But is this really a good enough reason to potentially jeopardise a piece of working functionality?</p><p>I think the reason old code is often seen this way is because it takes longer to remember. Developers yearn for clarity but if they're not immediately able to recall <a href="https://notoriousbfg.com/building-software-sharing-knowledge" target="_blank" title="Link: https://notoriousbfg.com/building-software-sharing-knowledge">under what circumstances some code was written</a> (in a few seconds or less), they only see ambiguity.</p><div id="posthaven_gallery[1659795]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/medium_PXL_20210103_124638168_1_.jpg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/medium_PXL_20210103_124638168_1_.jpg" data-medium-width="800" data-medium-height="585" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/large_PXL_20210103_124638168_1_.jpg" data-large-width="1200" data-large-height="878" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/thumb_PXL_20210103_124638168_1_.jpg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/xlarge_PXL_20210103_124638168_1_.jpg" data-xlarge-width="2400" data-xlarge-height="1756" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2557290/CCakts8r6v4JFqwWi7yRSooj8VA/PXL_20210103_124638168_1_.jpg" data-orig-width="3967" data-orig-height="2903" data-posthaven-id="2557290">
        </p>
          
        </div>
<p>Even when we talk about code, when we're able to recall previous conversations/decisions/motivations quickly, we can talk about it confidently and convey to others that we understand it well. Unfortunately saying, "I need five to ten minutes to refresh my memory of this" doesn't convey the same sense of confidence. Always prepare.</p><p>Part of the solution to reducing this "time to recall" is through better internal documentation. We use a tool like <a href="https://www.codestream.com/" target="_blank">Codestream</a> but I'll admit that context is not always captured; sometimes it's the "why" not the "what" that's relevant. In my opinion, good old-fashioned comments work best; I try to write mine like a numbered set of instructions. Of course you can also convey meaning with your git commit message.</p><p>The other part of the solution is to agree as a team under what circumstances code should be refactored. If your team collectively agrees that stable, well-documented code should be refactored, run.<br></p></div>
  </div></div>]]>
            </description>
            <link>https://notoriousbfg.com/code-age-vs-time-to-recall</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621596</guid>
            <pubDate>Sun, 03 Jan 2021 13:15:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wrils: Remote Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621544">thread link</a>) | @nycreatis
<br/>
January 3, 2021 | https://wrils.com/jobs | <a href="https://web.archive.org/web/*/https://wrils.com/jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h4>Associate Inside Sales Representative</h4></p><ul><li>Shippo</li><li>Anywhere 🌎</li><li><span>Full Time</span></li></ul><p>Before you read on, take a look around you. Chances are, pretty much everything you see has been shipped, often multiple times,…</p><div><p> new</p><p><span>Full Time</span></p></div></div></div>]]>
            </description>
            <link>https://wrils.com/jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621544</guid>
            <pubDate>Sun, 03 Jan 2021 13:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Eat the Donut (a dumb game I made)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25621540">thread link</a>) | @gitgud
<br/>
January 3, 2021 | https://benwinding.com/eat-the-donut.html | <a href="https://web.archive.org/web/*/https://benwinding.com/eat-the-donut.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://benwinding.com/eat-the-donut.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621540</guid>
            <pubDate>Sun, 03 Jan 2021 13:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We compress Pub/Sub messages and more, saving a load of money]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25621533">thread link</a>) | @kiyanwang
<br/>
January 3, 2021 | https://blog.lawrencejones.dev/compress-everything/ | <a href="https://web.archive.org/web/*/https://blog.lawrencejones.dev/compress-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
<p>Compression is a trick that can be used to solve a load of problems. Often, your
tools will compress content transparently: most modern browsers ask for gzipped
HTTP payload, and some filesystems can be configured to compress blocks without
the user ever asking.</p>

<p>Outside of well known use cases, there are a variety of opportunities to improve
efficiency or save a load of money by leveraging compression. It’s useful to be
aware of common use cases, so you can take these opportunities when they arise.</p>



<p>As a recent example, my team were migrating logs from one Elasticsearch cluster
to another. While not quite Big Data™, this cluster had 10 billion log entries,
or some 60TB of raw JSON.</p>

<p>Having experience tackling long-running, large-scale migrations like this, you
want to build a process that allows you to ‘save game’ as frequently as
possible. This means you can build and run an export process, handling whatever
issues will occur (they will, I promise!), then move cleanly on-to the import
process. As with exports, your import process will also screw up: so it, too,
should be easily re-runnable.</p>

<p>As it is used across a load of GoCardless systems, <a href="https://cloud.google.com/pubsub">Google
Pub/Sub</a> is a natural fit for this problem.
Google’s marketing tagline even sounds like it was written to describe our
ideal, decoupled process:</p>

<blockquote>
  <p>Pub/Sub is an asynchronous messaging service that decouples services that
produce events from services that process events.</p>
</blockquote>

<p>In Pub/Sub, you <a href="https://cloud.google.com/pubsub/docs/publisher">publish messages to topics</a>. Each topic can
have many subscriptions, which <a href="https://cloud.google.com/pubsub/docs/subscriber">consumers can pull messages
from</a>. In the most simple terms, the migration would:</p>

<ol>
  <li>Export logs from the origin cluster into a (per-index) Pub/Sub topic</li>
  <li>Configure the Pub/Sub subscriptions to retain events (set
<code>retain_acked_messages</code>, see: <a href="https://cloud.google.com/pubsub/docs/replay-overview">Replaying and purging messages</a>)
so that we may replay them, if our import goes wrong</li>
  <li>Import logs by pulling messages from the topic subscriptions</li>
</ol>

<p>So, what’s this got to do with compression? Like most Cloud services, Pub/Sub
charges on usage, which means we’ll incur fees proportional to the data we’ll
push through the service.</p>

<p>These charges are:</p>

<ul>
  <li>$40 per TiB delivered, applied to publish and subscribe</li>
  <li>Google Compute Engine network rates (we’ll ignore these, as they get complicated)</li>
  <li>Seek-related message storage, to retain our messages, at $0.27 per GiB-month</li>
</ul>

<p>In the best case where we import/export successfully on the first attempt (this
won’t, and did not happen), we’ll be charged <strong>2 x $40 x 60TB = $4,800 for
message delivery</strong>, as it will apply to both publish and subscribe. If we retain
our messages for 2 weeks while the migration is on-going, we’ll be charged <strong>0.5
x $0.27 x 60,000GB = $8,100 for message storage</strong>.</p>

<p>This leaves a <strong>lower-bound of $12,900 to perform the migration</strong>.</p>

<p>Now, GoCardless isn’t poor. And as a rule of thumb, you normally want to
optimise for engineering hours over infrastructure cost.</p>

<p>But if you can reduce cost with a minimal amount of effort, you should.</p>



<p>To this end, we made a small change to our migration tool (<code>elastic-toolbox</code>) to
support compression of the messages we published to Pub/Sub.</p>

<p>With error handling removed, this is the publish method, where we apply
compression after serialisation:</p>

<div><div><pre><code><span>// Publish takes a message and publishes it to the Pub/Sub topic. If</span>
<span>// compression is enabled, the message payload is compressed, and the</span>
<span>// message is marked with a compress=true attribute.</span>
<span>func</span> <span>(</span><span>f</span> <span>*</span><span>pubsubExportTarget</span><span>)</span> <span>Publish</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>,</span> <span>msg</span> <span>Message</span><span>)</span> <span>error</span> <span>{</span>
    <span>data</span><span>,</span> <span>_</span> <span>:=</span> <span>json</span><span>.</span><span>Marshal</span><span>(</span><span>msg</span><span>)</span>
    <span>if</span> <span>f</span><span>.</span><span>opt</span><span>.</span><span>Compress</span> <span>{</span>
        <span>data</span><span>,</span> <span>_</span> <span>=</span> <span>f</span><span>.</span><span>compress</span><span>(</span><span>data</span><span>)</span>
    <span>}</span>

    <span>// enqueue marks a message as available to be sent, passing it</span>
    <span>// to the Pub/Sub client</span>
    <span>f</span><span>.</span><span>enqueue</span><span>(</span><span>ctx</span><span>,</span> <span>&amp;</span><span>pubsub</span><span>.</span><span>Message</span><span>{</span>
        <span>Data</span><span>:</span> <span>data</span><span>,</span>
        <span>Attributes</span><span>:</span> <span>map</span><span>[</span><span>string</span><span>]</span><span>string</span><span>{</span>
            <span>"compress"</span><span>:</span> <span>fmt</span><span>.</span><span>Sprintf</span><span>(</span><span>"%v"</span><span>,</span> <span>f</span><span>.</span><span>opt</span><span>.</span><span>Compress</span><span>),</span>
        <span>},</span>
    <span>})</span>

    <span>return</span> <span>nil</span>
<span>}</span>
</code></pre></div></div>

<p>The compression itself is dead simple, and almost entirely observability code:</p>

<div><div><pre><code><span>var</span> <span>(</span>
    <span>exportPubsubWriteCompressionRatio</span> <span>=</span> <span>promauto</span><span>.</span><span>NewHistogram</span><span>(</span>
        <span>prometheus</span><span>.</span><span>HistogramOpts</span><span>{</span>
            <span>Name</span><span>:</span>    <span>"elastic_toolbox_export_pubsub_write_compression_ratio"</span><span>,</span>
            <span>Help</span><span>:</span>    <span>"Distribution of compression ratio"</span><span>,</span>
            <span>Buckets</span><span>:</span> <span>prometheus</span><span>.</span><span>LinearBuckets</span><span>(</span><span>0.1</span><span>,</span> <span>0.1</span><span>,</span> <span>10</span><span>),</span> <span>// 0.0 -&gt; 1.0</span>
        <span>},</span>
    <span>)</span>
    <span>exportPubsubWriteCompressDurationSeconds</span> <span>=</span> <span>promauto</span><span>.</span><span>NewHistogram</span><span>(</span>
        <span>prometheus</span><span>.</span><span>HistogramOpts</span><span>{</span>
            <span>Name</span><span>:</span>    <span>"elastic_toolbox_export_pubsub_write_compress_duration_seconds"</span><span>,</span>
            <span>Help</span><span>:</span>    <span>"Distribution of time taken to compress hits"</span><span>,</span>
            <span>Buckets</span><span>:</span> <span>prometheus</span><span>.</span><span>ExponentialBuckets</span><span>(</span><span>0.0625</span><span>,</span> <span>2</span><span>,</span> <span>8</span><span>),</span> <span>// 0.0625 -&gt; 16s</span>
        <span>},</span>
    <span>)</span>
<span>)</span>

<span>// compress applies gzip compression to the incoming data, and instruments</span>
<span>// compression efficiency.</span>
<span>func</span> <span>(</span><span>f</span> <span>*</span><span>pubsubExportTarget</span><span>)</span> <span>compress</span><span>(</span><span>data</span> <span>[]</span><span>byte</span><span>)</span> <span>([]</span><span>byte</span><span>,</span> <span>error</span><span>)</span> <span>{</span>
    <span>defer</span> <span>prometheus</span><span>.</span><span>NewTimer</span><span>(</span><span>prometheus</span><span>.</span><span>ObserverFunc</span><span>(</span><span>func</span><span>(</span><span>v</span> <span>float64</span><span>)</span> <span>{</span>
        <span>exportPubsubWriteCompressDurationSeconds</span><span>.</span><span>Observe</span><span>(</span><span>v</span><span>)</span>
    <span>}))</span><span>.</span><span>ObserveDuration</span><span>()</span>

    <span>var</span> <span>buffer</span> <span>bytes</span><span>.</span><span>Buffer</span>
    <span>zw</span> <span>:=</span> <span>gzip</span><span>.</span><span>NewWriter</span><span>(</span><span>&amp;</span><span>buffer</span><span>)</span>
    <span>if</span> <span>_</span><span>,</span> <span>err</span> <span>:=</span> <span>zw</span><span>.</span><span>Write</span><span>(</span><span>data</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>if</span> <span>err</span> <span>:=</span> <span>zw</span><span>.</span><span>Close</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>compressed</span> <span>:=</span> <span>buffer</span><span>.</span><span>Bytes</span><span>()</span>
    <span>exportPubsubWriteCompressionRatio</span><span>.</span><span>Observe</span><span>(</span>
        <span>float64</span><span>(</span><span>len</span><span>(</span><span>compressed</span><span>))</span> <span>/</span> <span>float64</span><span>(</span><span>len</span><span>(</span><span>data</span><span>)))</span>

    <span>return</span> <span>compressed</span><span>,</span> <span>nil</span>
<span>}</span>
</code></pre></div></div>



<p>As our savings will be proportional to our compression ratio (compressed /
original bytes), we care a lot about how compressible our data is.</p>

<p>JSON logs are likely to be very compressible as:</p>

<ul>
  <li>Logs share many of the JSON keys, which can be de-duplicated (<code>kubernetes.pod_name</code>)</li>
  <li>Values of common log fields might occur very often (<code>kubernetes.labels.namespace</code>)</li>
</ul>

<p>Using the modified <code>elastic-toolbox</code> to run an concurrent export of three
different indices, we can use the
<code>elastic_toolbox_export_pubsub_write_compression_ratio</code> Prometheus metric (see
the <code>compress</code> method above) to build a heatmap of compression ratios:</p>

<figure>
  <a href="https://snapshot.raintank.io/dashboard/snapshot/gHTtGvZh2hK67q03kIU4uJM3q4Sqek8p?orgId=2" target="_blank">
    <img src="https://blog.lawrencejones.dev/assets/images/compress-everything-ratio-heatmap.png" alt="Compressed bytes divided by original bytes, always less than 30%">
  </a>
  <figcaption>
    Compressed bytes / original bytes, always &lt;30%
  </figcaption>
</figure>

<p>This heatmap shows that all messages compressed to <strong>at most 30% the original
size</strong>. When measured over our entire corpus of logs, we average at a <strong>~12%
compression ratio, meaning 1GiB of logs becomes just 120MiB.</strong></p>

<p>Our original bill of $12,900 has become 12% x $12,900 = $1,548.</p>

<p>This means <strong>we’ve saved about $11,500.</strong></p>

<p>Explore the data for yourself at this <a href="https://snapshot.raintank.io/dashboard/snapshot/gHTtGvZh2hK67q03kIU4uJM3q4Sqek8p?orgId=2" target="_blank">Raintank Snapshot: elastic-toolbox compression</a>.</p>



<p>The most obvious next step was to apply this to our logging pipeline all the
time. Given we ship container logs straight into Pub/Sub, pulling them out of a
subscription into Elasticsearch, we can easily write a
<a href="https://www.fluentd.org/">fluentd</a> filter that applies the same compression
strategy.</p>

<p>My colleague Ben put together an awesome dashboard to track how much we save,
which works out to be <strong>several thousand a month</strong>:</p>

<figure>
  <img src="https://blog.lawrencejones.dev/assets/images/compress-everything-headline-figures.png" alt="Savings from compressing logs as they enter the logging pipeline, several thousand dollars a month">
  <figcaption>
    Savings from compressing logs as they enter the logging pipeline
  </figcaption>
</figure>



<p>If you work in a Cloud environment, there are so many opportunities to save
money by compressing your data.</p>

<p>Beyond logs, another GoCardless example is a tool called
<a href="https://github.com/gocardless/draupnir">draupnir</a>. This service hosts copies of
our production databases for load testing and forensic analysis (query plan
prediction, etc). Google SSD storage costs $187 per TiB/month, which means every
copy of our <strong>5TB Postgres costs $1,000/month</strong>.</p>

<p>Draupnir might host several copies at a time, depending on the use cases. We can
save a load of money by enabling <a href="https://btrfs.wiki.kernel.org/index.php/Compression">btrfs
compression</a> to
transparently compress the filesystem blocks, allowing us to use <strong>~70% less SSD
capacity</strong> than we may otherwise.</p>

<p>And if you thought compression was limited to cost savings, you’d be wrong!
Having suffered from occasional micro-outages when people ran large backfills or
built new database indexes, we solved the problem by enabling Postgres WAL
compression (see <a href="https://www.cybertec-postgresql.com/en/postgresql-underused-features-wal-compression/">Postgres Underused Features: WAL Compression</a>,
or the <a href="https://www.postgresql.org/docs/13/runtime-config-wal.html">Postgres Write Ahead Log docs</a>).</p>

<p>The outages were caused by database operations creating a large amount of WAL
churn, where the replica would stall while writing the WAL to disk. By
compressing the WAL stream, we <strong>significantly reduced the IO spikes, allowing
the replica to handle the stream without issue</strong>.</p>

<p>There are more examples, but I think this paints a good picture.</p>



<p>Compression is a trade-off, a decision we make to trade CPU for another resource
that might be more expensive or less available. The value assigned to CPU,
memory, or network bandwidth continually changes, and you’ll need to make this
calculation on a case-by-case basis.</p>

<p>This post aimed to cover a scenario where the cost of compression, in both
compute resource and time-to-build, was significantly outweighed by the savings
it would make. Not all situations will have the same economics, but it takes a
few minutes of napkin maths to decide either way.</p>

<p>I hope this case study prompts consideration of compression outside of standard,
boring use-cases, and helps to find opportunities where you can apply it to your
own systems.</p>


    
    <p>
      <em>
        Discuss this post on
        <a target="_blank" href="https://news.ycombinator.com/item?id=25573605">Hackernews</a>.
      </em>
    </p>
    
  </section></div>]]>
            </description>
            <link>https://blog.lawrencejones.dev/compress-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621533</guid>
            <pubDate>Sun, 03 Jan 2021 13:04:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand technical leadership and boost your career]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621486">thread link</a>) | @d0ugr0ck
<br/>
January 3, 2021 | https://douglasrocha.me/understand-technical-leadership-and-boost-your-career/ | <a href="https://web.archive.org/web/*/https://douglasrocha.me/understand-technical-leadership-and-boost-your-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-785" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>I will tell you a word, and you think of the first image that comes to your mind. Are you ready? Leader!</p>



<p>If you have thought of a white man, dressed in a perfectly fitting suit, you have thought about what most people think when they hear that word. But is that all there is for this word? Apart from the unconscious bias of race and gender, does it define leaders’ characteristics?</p>



<p>If we check the word ‘leader’ in the dictionary, we find:&nbsp;<em>“a person who guides or directs a group”.&nbsp;</em>That definition is so straightforward and clear that we often don’t question what makes a great technical leader. This article will dive deep into the requirements to become a great technical leader. We will understand the similarities and differences to non-tech leadership, and I hope this can guide you in your career.</p>



<h2>The first pillar: Teamwork</h2>



<figure><img loading="lazy" width="640" height="427" src="https://douglasrocha.me/wp-content/uploads/2021/01/annie-spratt-O-40u5howqw-unsplash.jpg" alt="" srcset="https://douglasrocha.me/wp-content/uploads/2021/01/annie-spratt-O-40u5howqw-unsplash.jpg 640w, https://douglasrocha.me/wp-content/uploads/2021/01/annie-spratt-O-40u5howqw-unsplash-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p><span>Technical leadership doesn’t exist isolated; some other type of leadership always accompanies it.</span></p>



<p>An abundance of developers thinks their managers are obsolete dinosaurs who don’t know how to write a single code line. Yes, they may be right in some cases, but that doesn’t mean their managers cannot execute the tasks at hand. Let me explain!</p>



<p><span>The most important organizational factor for a company is to make sure they never lose sight of strategic decisions.</span> The bigger the company, the more substantial the term ‘strategy’ becomes. Enterprise strategy is the only way companies can guarantee employees are walking in the same direction and working for the same goals. Once the top management team decides which will be their primary goals, they are passed down to every team hierarchically, ensuring it reaches every single soul.</p>



<p>Managers are responsible for making sure their segment of the company is under control strategically, but not tactically, and there is where technical leadership shines. The fundamental responsibility of tech leadership roles is to make sure the manager’s strategic definitions are going in the right direction and that projects are executed correctly without hurting any of the premises defined by the board of directors.&nbsp;</p>



<p><span>The quintessence of technical leadership success is to work with your business partners as if you were a single entity in this universe. If you don’t do that, you will be doomed, I promise.</span></p>



<h2><strong>The second pillar: Knowledge</strong></h2>



<figure><img loading="lazy" width="640" height="427" src="https://douglasrocha.me/wp-content/uploads/2021/01/matthew-feeney-Nwkh-n6l25w-unsplash.jpg" alt="" srcset="https://douglasrocha.me/wp-content/uploads/2021/01/matthew-feeney-Nwkh-n6l25w-unsplash.jpg 640w, https://douglasrocha.me/wp-content/uploads/2021/01/matthew-feeney-Nwkh-n6l25w-unsplash-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>You have become a technical leader. Congratulations! This promotion means you are a ‘knowledge reference’ to your peers. While this may seem counter-intuitive, <span>it means you now have way more pressure to keep yourself updated on computer science’s latest trends.</span></p>



<p>Let’s be sincere and frank here: people become more suspicious of you when you cannot clarify their doubts and help them solve their difficulties. There will be times where you will be challenged by developers both directly and indirectly, as they will try to check your boundaries and understand if you’re ready for that position. If you can answer those provocations politely and with strong fundamentals, you succeed at gaining developers’ trust.&nbsp;</p>



<p>Answer challenges appropriately and remember that if you respond in a non-polite way, you fail. You fail both because you have misbehaved and because you are there to support people. It is OK not to know things, make sure you write it down and be ready for answering the question the next day. Never say phrases such as: “Oh, you don’t know that? What a shame! Let me show you how to do that right”, that is typical of lousy knowledge leadership.</p>



<p><span>Never doubt your authority, but make sure you recognize your ignorance. Keep working on what you don’t know in a planned and organized fashion. Technology evolves fast, and without study planning, you will get obsolete fast too.</span></p>



<p>Another critical point is that <span>technical leadership implies that you will have to coach and help your peers think about problems in new ways.</span> But to delve into how to do that, we need to talk about the next pillar: communication.</p>



<h2><strong>The third pillar: Communication</strong></h2>



<figure><img loading="lazy" width="640" height="427" src="https://douglasrocha.me/wp-content/uploads/2021/01/pavan-trikutam-71CjSSB83Wo-unsplash.jpg" alt="" srcset="https://douglasrocha.me/wp-content/uploads/2021/01/pavan-trikutam-71CjSSB83Wo-unsplash.jpg 640w, https://douglasrocha.me/wp-content/uploads/2021/01/pavan-trikutam-71CjSSB83Wo-unsplash-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>Just like non-technical leaders, you will be responsible for communicating your ideas, and your action plans to execute each one of them. You will receive several invitations to present ideas to various people, such as clients, managers, developers, boards of directors, etc. But what differs from the regular communication of business leads? Well, a lot!</p>



<p>The first thing you have to understand is that the higher you go in your leadership career, the fewer people will understand the words you use. The more you know, the greater your vocabulary and the attention you will give to the definitions you use; hence you can’t talk as you normally would. You have to put a lot of effort to talk using less technical vocabulary.&nbsp;</p>



<p><span>I think this exercise applies well to this case, which helps techies explain challenging concepts in a very accessible format:&nbsp;<em><u>“How would you explain X to five years old with the fewer words possible?”</u></em>.&nbsp;</span></p>



<p>From my personal experience, I can tell you that developers live a very pressuring moment where technology novelties emerge every day. The learning pace they need to maintain in their careers is hard, which gives origin to the famous imposter syndrome.&nbsp;</p>



<p><span>The most important lesson I’ve learnt is that to motivate developers, the most efficient method is to help them learn new concepts and abilities</span>.&nbsp;That stern necessity to continually learn new things is the most significant pain in their lives. When you allow them to ease that pain, you start a genuine mentorship relationship that is exceptional for them and augment their loyalty and desire to work.</p>



<p><span>To create a safe learning environment for developers, you need to want that: genuinely!</span>&nbsp;Otherwise, you will cause questions and ideas to become threats. Developers will start to judge each others’ words, and you will create an oppressive environment.</p>



<p>It is harder for technical leaders to think of people first, but the truth is that no matter where you work, the labour output will always be produced directly or indirectly by people. But how can we excel at guiding a group of people?</p>



<p>First, you have to understand that almost every company oscillates into more relaxed and more challenging moments. The lower you go into the company’s hierarchy, the more difficulty you will find to maintain resiliency.&nbsp;</p>



<p><span>Be positive! The world is a constant duality of good and bad aspects of everything. Always choose to see the positive elements of every situation!</span>&nbsp;You have the choice to look at things as opportunities, no matter how hard they are, it means people will learn new things in the process. Doing that is key to developing an inspirational communication style that motivates your followers and allows them to ease their uncertainties.</p>



<p>Remember that on the other side of all communication media, there are people. Demonstrate consideration and understand that everyone has feelings and personal lives, ambitions and dreams. It never hurts to acknowledge their achievements or ideas to improve work quality. Remember to compliment others when they do outstanding work, and teach them the lessons you’ve learnt to become a technological leader. They might want that too.</p>



<p><span>The most important concept here is: Be real! You are not a technological machine. When you act genuinely, you will perform accordingly: People first, then comes technology.</span></p>



<h2><strong>The fourth pillar: Vision</strong></h2>



<figure><ul><li><figure><img loading="lazy" width="640" height="427" src="https://douglasrocha.me/wp-content/uploads/2021/01/karsten-wurth-rafblRbne3o-unsplash.jpg" alt="An image of a road suggesting long-term vision" data-id="791" data-full-url="https://douglasrocha.me/wp-content/uploads/2021/01/karsten-wurth-rafblRbne3o-unsplash.jpg" data-link="https://douglasrocha.me/?attachment_id=791" srcset="https://douglasrocha.me/wp-content/uploads/2021/01/karsten-wurth-rafblRbne3o-unsplash.jpg 640w, https://douglasrocha.me/wp-content/uploads/2021/01/karsten-wurth-rafblRbne3o-unsplash-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure></li></ul></figure>



<p>The last, but not least important pillar for a great technical leader is vision. It is expected from you to understand the direction that the company is going in the short and long-term (5+ years). This pillar is only possible when you accomplish all the previous steps to become a great technical leader.&nbsp;</p>



<p>If you don’t have excellent&nbsp;communication&nbsp;with the&nbsp;business leads,&nbsp;you will never understand the company’s&nbsp;strategical direction. If you have poor contact with the developers, either because you&nbsp;lack knowledge&nbsp;or&nbsp;treat them poorly, you won’t have support to execute your projects. <span>This paragraph shows how important it is to build the previous steps before you go into this one</span>, so let’s dive into what we mean by vision.</p>



<p>As we said before, the higher you go into the company’s hierarchy, the more critical the word strategy becomes. An understanding of the long-term plan is the only way you can excel in technical leadership roles. To suggest new features and products, you have to communicate with business leaders, and unless you talk the same language as them, you won’t be able to sell your ideas.</p>



<p><span>It doesn’t mean that you cannot criticize the strategical plan of the company!</span>&nbsp;Remember you are a technical person, if business leaders make decisions that go against technology’s core principles, you have to express your opinions, so don’t be afraid to do that.&nbsp;<span>Make sure you are polite and build your arguments with analytically profound details.</span> The larger the amount numbers, graphs, and projections, the easier it will be to explain your criticisms.</p>



<p><span>When you achieve the enlightenment of where the company is going, you become the technical glue.</span> When managers fail to explain the vision, you will be responsible for guaranteeing the tactical execution of projects is going in the right direction, so you must pass on the vision to the technical team.&nbsp;<span>The big picture is essential because it allows us to create a sense of unity and progress</span>, enabling creating a healthy development team culture.</p>



<p><strong>If you want to know more about my work, feel free to check out my LinkedIn profile</strong>: </p>



<p><a href="https://www.linkedin.com/in/rochad/" data-type="URL" data-id="https://www.linkedin.com/in/rochad/" target="_blank" rel="noreferrer noopener">https://www.linkedin.com/in/rochad/</a></p>
<br>
		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://douglasrocha.me/understand-technical-leadership-and-boost-your-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621486</guid>
            <pubDate>Sun, 03 Jan 2021 12:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LIVR: Data Validation Motivation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621482">thread link</a>) | @based2
<br/>
January 3, 2021 | https://livr-spec.org/introduction/motivation.html | <a href="https://web.archive.org/web/*/https://livr-spec.org/introduction/motivation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                    






                    <div tabindex="-1" role="main">
                        <div>
                            
<div id="book-search-results">
    <div>
    
                                <section>
                                
                                <h2 id="motivation">Motivation</h2>
<h4 id="the-main-problems-that-occur-in-data-validation-libraries">The main problems that occur in data validation libraries</h4>
<p><strong>Problem #1.</strong> Many validators check only those data for which the validation rules are described. </p>
<blockquote>
<p>It is important for us that any user input that is not explicitly allowed is ignored. That is, the validator must cut out all data for which the validation rules are not described. This is simply a fundamental requirement.</p>
</blockquote>
<p><strong>Problem #2.</strong> Procedural description of validation rules.</p>
<blockquote>
<p>We do not want to think about the validation algorithm every time, we just want to describe declaratively how the correct data should look. In fact, we want to specify a data schema (<a href="https://livr-spec.org/introduction/core-concepts.html#why-not-json-schema">why not "JSON Schema"</a>).</p>
</blockquote>
<p><strong>Problem #3.</strong> Description of validation rules in the form of code. </p>
<blockquote>
<p>It would seem that this is not so terrible, but this immediately nullifies all attempts to serialize the validation rules and use the same validation rules on the backend and frontend.</p>
</blockquote>
<p><strong>Problem #4.</strong> Validation stops at the first field with an error.</p>
<blockquote>
<p>This approach does not allow you to highlight all the error / required fields in the form.</p>
</blockquote>
<p><strong>Problem #5.</strong> Non-standardized error messages.</p>
<blockquote>
<p>For example, "Field name is required". I can not show such a mistake to the user for a number of reasons:</p>
<ul>
<li>The field in the interface can be called quite differently</li>
<li>interface may not be in English</li>
<li>you need to distinguish between the type of error. For example, show errors on an empty value in a special way</li>
</ul>
<p>That is, you need to return not an error message, but standardized error codes.</p>
</blockquote>
<p><strong>Problem #6.</strong> Numerical error codes.</p>
<blockquote>
<p>It's just inconvenient to use. I want the error codes to be intuitive. Agree that the error code "REQUIRED" is more understandable than the code "27". The logic is similar to working with exception classes.</p>
</blockquote>
<p><strong>Problem #7.</strong> There is no way to check hierarchical data structures.</p>
<blockquote>
<p>Today, in the days of different JSON APIs, this can not be avoided. In addition to the validation of hierarchical data, it is necessary to provide and return error codes for each field.</p>
</blockquote>
<p><strong>Problem #8.</strong> Limited rule set.</p>
<blockquote>
<p>There are always not enough standard rules. The validator must be extensible and allow adding rules of any complexity to it.</p>
</blockquote>
<p><strong>Problem #9.</strong> Too much responsibility.</p>
<blockquote>
<p>The validator should not generate forms, should not generate code, should not do anything other than validation.</p>
</blockquote>
<p><strong>Problem #10.</strong> Inability to perform additional data processing.</p>
<blockquote>
<p>Almost always, where there is validation, there is a need for some additional (often preliminary) data processing: cut out prohibited characters, bring them to lowercase, remove unnecessary spaces. Especially important is the removal of spaces at the beginning and end of the line. In 99% of cases they are not needed there. I know that before that I said that the validator should not do anything except validation.</p>
</blockquote>

                                
                                </section>
                            
    </div>
    
</div>

                        </div>
                    </div>
                
            </div></div>]]>
            </description>
            <link>https://livr-spec.org/introduction/motivation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621482</guid>
            <pubDate>Sun, 03 Jan 2021 12:53:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621480">thread link</a>) | @briggers
<br/>
January 3, 2021 | https://paulbridger.com/posts/tensorrt-object-detection-quantized/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/tensorrt-object-detection-quantized/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h5>December 31, 2020</h5><h2 id="intro">Intro
<a href="#intro">#</a></h2><p>My previous post <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">Object Detection at 1840 FPS</a> made some readers wonder who would need to detect anything at 1840 FPS, but my good friend and “performance geek” <a href="https://tanelpoder.com/">Tanel Põder</a> had a different response:</p><blockquote><p>Nice article, I wonder if you could get to 2000 FPS?</p></blockquote><p>Challenge accepted.</p><p>This article is a deep dive into the techniques needed to get there. We will rewrite Pytorch model code, perform <a href="https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon">ONNX graph surgery</a>, optimize <a href="https://github.com/NVIDIA/TensorRT/tree/master/plugin/batchedNMSPlugin">a TensorRT plugin</a> and finally we’ll quantize the model to bits (to 8 bit precision, that is). We will also keep track of divergence from full-precision accuracy with the COCO2017 validation dataset.</p><p>Code supporting this article can be found here: <a href="https://github.com/pbridger/tensorrt-ssd300-8bit-quantized">github.com/pbridger/tensorrt-ssd300-8bit-quantized</a>.</p><p>A quick preview of the final results:</p><div><p>
<label for="tabs-Preview-0">FP32 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.fp32.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-1">FP16 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.fp16.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-2">INT8 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.int8.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-3">All Results</label></p></div><p>So how do we get to 2000 FPS? My previous post already brought the big guns — a <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">TensorRT-optimized DeepStream pipeline</a> was needed to hit 1840 FPS running on 2x Nvidia 2080Ti cards. This time we will abandon TorchScript and <a href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a>, and we’ll put in the work to fully embrace TensorRT model compilation and execution.</p><h3 id="on-optimizing-arbitrary-numbers">On Optimizing Arbitrary Numbers
<a href="#on-optimizing-arbitrary-numbers">#</a></h3><p>1840 FPS, 2000 FPS, 2530 FPS — there is nothing special about any of these numbers, they are all hardware, resolution and model dependent. These optimization articles are about the practical usage of cutting-edge tools and techniques to achieve ambitious project goals or unlock cost savings.</p><p>Tuning a pipeline for throughput maximizes hardware utilization and efficiency in the datacenter, and it allows us to deploy larger models or more complex systems in compute-limited contexts (think IoT, embedded and mobile). It’s also just fun to explore the limits of powerful tools!</p><p>Let’s get started with a baseline from the <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">previous article</a>.</p><h2 id="stage-0-deepstream-baseline">Stage 0: DeepStream Baseline
<a href="#stage-0-deepstream-baseline">#</a></h2><p>To recap, we got peak throughput with the DeepStream pipeline by using a hybrid model — a TensorRT-optimized SSD300 front-end with postprocessing code running in TorchScript in the libtorch runtime. All processing on GPU, of course. Here’s a reminder of some of the throughput milestones from the last article:</p><p>Why did we need TorchScript? Several common object-detection postprocessing operations — including thresholding and non-max-suppression (NMS) — can’t be seamlessly exported from Pytorch to ONNX and compiled with TensorRT. Leaving these operations in TorchScript allowed us to get great performance without rewriting any model code or creating TensorRT plugins.</p><p>Looking at the performance trace from Nsight Systems, we can see the TorchScript postprocessing comes in just under 10 ms. When we compiled the inference step with TensorRT we saw around 43 ms of TorchScript turn into about 16 ms equivalent processing — so anything executing in TorchScript seems ripe for optimization.</p><p>Here’s what it looked like in Nsight Systems:</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/ds_80pc_tensorrt_hacked_ds_two_batch.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/ds_80pc_tensorrt_hacked_ds_two_batch_hudc758a7e69d7157937e6a1d7caab6946_489589_896x520_fill_box_top_2.png" width="896" height="520"><figcaption><small></small></figcaption></figure></a><p>Let’s eliminate the TorchScript postprocessing and get the entire model running end-to-end in TensorRT.</p><h2 id="stage-1-end-to-end-tensorrt">Stage 1: End-to-End TensorRT
<a href="#stage-1-end-to-end-tensorrt">#</a></h2><p>The baseline Pytorch SSD300 model (including postprocessing) cannot be easily compiled with TensorRT for several reasons, all of which involve missing (or impossible) support for tensor operations:</p><ul><li><p>Subscripted tensor assignment results in <code>ScatterND</code> (indexed assignment) nodes in ONNX.</p></li><li><p>Score thresholding uses a mask operation, which cannot be expressed in the fixed-dimension world of TensorRT.</p></li><li><p>Torchvision’s batched non-max suppression (NMS) operation has no exact equivalent in TensorRT.</p></li></ul><p>We can fix the first by tweaking model code and re-exporting to ONNX, but to fix the other issues we’ll have to modify the ONNX computational graph — replacing these operations with a TensorRT plugin.</p><h3 id="11-rewriting-subscripted-tensor-assignment">1.1 Rewriting Subscripted Tensor Assignment
<a href="#11-rewriting-subscripted-tensor-assignment">#</a></h3><p>The baseline postprocessing contains some bounding-box rescaling code:</p><div><pre><code data-lang="python">        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>self</span><span>.</span><span>scale_xy</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>=</span> <span>self</span><span>.</span><span>scale_wh</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>+</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span><span>.</span><span>exp</span><span>()</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span># transform format to ltrb</span>
        <span>l</span><span>,</span> <span>t</span><span>,</span> <span>r</span><span>,</span> <span>b</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>-</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>-</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>+</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>+</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>]</span>

        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>=</span> <span>l</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>=</span> <span>t</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>]</span> <span>=</span> <span>r</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>]</span> <span>=</span> <span>b</span></code></pre></div><p>This code will export to an ONNX graph without issue, but parsing with TensorRT will result in an error: <code>No importer registered for op: ScatterND</code> or <code>getPluginCreator could not find plugin ScatterND</code>.</p><p>We can rewrite the code to avoid generating <code>ScatterND</code> nodes by not using subscript assignment:</p><div><pre><code data-lang="python">    <span>def</span> <span>rescale_locs</span><span>(</span><span>self</span><span>,</span> <span>locs</span><span>):</span>
        <span>locs</span> <span>*=</span> <span>self</span><span>.</span><span>scale_xyxywhwh</span>

        <span>xy</span> <span>=</span> <span>locs</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>+</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>wh</span> <span>=</span> <span>locs</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span><span>.</span><span>exp</span><span>()</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span>wh_delta</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>([</span><span>wh</span><span>,</span> <span>wh</span><span>],</span> <span>dim</span><span>=-</span><span>1</span><span>)</span> <span>*</span> <span>self</span><span>.</span><span>scale_wh_delta</span>
        <span>cxycxy</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>([</span><span>xy</span><span>,</span> <span>xy</span><span>],</span> <span>dim</span><span>=-</span><span>1</span><span>)</span></code></pre></div><p>Problem solved, this code exports without issue to ONNX and then TensorRT. See <a href="">subscript_assignment.py</a> in the repo for an isolated example:</p><div><p>
<label for="tabs-subscript_assignment-0">Code: subscript_assignment.py</label></p><div><div><pre><code data-lang="python">    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>):</span>
        <span>X</span><span>[:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>0</span>
        <span>return</span> <span>X</span>
</code></pre></div></div><p>
<label for="tabs-subscript_assignment-1">ONNX Graph</label></p><div><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/subscript_assignment.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/subscript_assignment_hu463f7206af736e81218c08508fc927eb_438088_896x800_fill_box_center_2.png" width="896" height="800"><figcaption><small></small></figcaption></figure></a></div><p>
<label for="tabs-subscript_assignment-2">Export Output</label></p><div><div><pre><code data-lang="markdown">[TensorRT] WARNING: /build/TensorRT/parsers/onnx/onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[TensorRT] WARNING: /build/TensorRT/parsers/onnx/onnx2trt_utils.cpp:246: One or more weights outside the range of INT32 was clamped
<span>[TensorRT] ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin ScatterND version 1
</span>exporting SubscriptAssign to models/subscript_assign.onnx
compiling models/subscript_assign.onnx with TensorRT
</code></pre></div></div></div><h3 id="12-tensorrt-and-masking">1.2 TensorRT and Masking
<a href="#12-tensorrt-and-masking">#</a></h3><p>Masking is essential to efficient SSD postprocessing. It needs to be done before calculating NMS because of the large number of possible detection bounding boxes (over 8000 for each of 81 classes for this model). Without first reducing the candidate boxes the NMS calculation would be hugely expensive.</p><p>However, TensorRT compilation depends on tensor dimensions being known at compile time. TensorRT layer output dimensions are allowed to vary based on input dimensions, but not based on the result of the layer calculation itself. Unfortunately, this is exactly what supporting masking in TensorRT would require.</p><p>Masking in Pytorch will result in <code>NonZero</code> ONNX nodes which cannot be expressed as a TensorRT layer or plugin. TensorRT fails with <code>No importer registered for op: NonZero.</code> or <code>getPluginCreator could not find plugin NonZero</code>. See <a href="">masking.py</a> in the repo for an example:</p><div><p>
<label for="tabs-masking-0">Code: masking.py</label></p><div><div><pre><code data-lang="python">    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>):</span>
        <span>X</span> <span>=</span> <span>X</span><span>[</span><span>X</span><span>.</span><span>sum</span><span>(</span><span>dim</span><span>=-</span><span>1</span><span>)</span> <span>&gt;</span> <span>0</span><span>]</span>
        <span>return</span> <span>X</span>
</code></pre></div></div><p>
<label for="tabs-masking-1">ONNX Graph</label></p><div><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/masking.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/masking_hu463f7206af736e81218c08508fc927eb_219236_896x320_fill_box_center_2.png" width="896" height="320"><figcaption><small></small></figcaption></figure></a></div><p>
<label for="tabs-masking-2">Export Output</label></p><div><div><pre><code data-lang="markdown"><span>[TensorRT] ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin NonZero version 1
</span>/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_opset9.py:2329: UserWarning: Exporting aten::index operator with indices of type Byte. Only 1-D indices are supported. In any other case, this will produce an incorrect ONNX graph.
  warnings.warn("Exporting aten::index operator with indices of type Byte. "
/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_opset9.py:591: UserWarning: This model contains a squeeze operation on dimension 1 on an input with unknown shape. Note that if the size of dimension 1 of the input is not 1, the ONNX model will return an error. Opset version 11 supports squeezing on non-singleton dimensions, it is recommended to export this model using opset version 11 or higher.
  "version 11 or higher.")
exporting Masking to models/masking.onnx
compiling models/masking.onnx with TensorRT
</code></pre></div></div></div><p>One solution here would be to replace a probability-threshold mask with a top-k approach, which results in an output with fixed dimensions and can therefore be executed in TensorRT. However because we need both top-k and NMS to complete model postprocessing, there is a better alternative.</p><h3 id="13-replacing-masking-and-nms-with-batchednmsplugin">1.3 Replacing Masking and NMS with <code>batchedNMSPlugin</code>
<a href="#13-replacing-masking-and-nms-with-batchednmsplugin">#</a></h3><p>TensorRT ships with a set of open source plugins that extend the functionality of the core layers. One such layer (<a href="https://github.com/NVIDIA/TensorRT/tree/master/plugin/batchedNMSPlugin">batchedNMSPlugin</a>) does almost exactly what we need: NMS on some top-k detections.</p><p>So how do we use it? We will have to go beyond the simple Pytorch -&gt; ONNX -&gt; TensorRT export pipeline and start modifying the ONNX, inserting a node corresponding to the <code>batchedNMSPlugin</code> plugin and cutting out the redundant parts.</p><p>A library called <a href="https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon">ONNX GraphSurgeon</a> makes manipulating the ONNX graph easy, all we need to do is figure out where to insert the new node. This is the full postprocessing computational graph (not including all the convolutions):</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/full_postprocessing.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/full_postprocessing_hu463f7206af736e81218c08508fc927eb_562695_896x940_fill_box_bottom_2.png" width="896" height="940"><figcaption><small></small></figcaption></figure></a><p>There are two ways to figure out where to insert the <code>batchedNMSPlugin</code>:</p><ul><li><p>The hard way is to stare at the ONNX representation above, map it back to Pytorch code and figure out which tensors are the correct inputs to the plugin. Be my guest.</p></li><li><p>The easy way is to tweak the Pytorch model code to produce exactly the outputs the plugin will need. These are then easily accessible in the ONNX graph as outputs, and can be plugged into a new <code>batchedNMSPlugin</code> node as inputs.</p></li></ul><p>See the <code>build_onnx</code> function to review how I did it (the easy way). The resulting modified ONNX looks like this:</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/nms_plugin_postprocessing.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/nms_plugin_postprocessing_hu463f7206af736e81218c08508fc927eb_474181_896x955_fill_box_bottom_2.png" width="896" height="955"><figcaption><small></small></figcaption></figure></a><p>This looks a lot simpler, but more importantly this ONNX can be compiled and optimized end-to-end with TensorRT. See the <code>build_trt_engine</code> function for details.</p><h3 id="14-results-and-analysis">1.4 Results and Analysis
<a href="#14-results-and-analysis">#</a></h3><p>Compiling the modified ONNX graph and running using 4 CUDA streams gives 275 FPS throughput. With <code>float16</code> optimizations enabled (just like the DeepStream model) we hit 805 FPS.</p><blockquote>Mean average precision (IoU=0.5:0.95) on …</blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/">https://paulbridger.com/posts/tensorrt-object-detection-quantized/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/tensorrt-object-detection-quantized/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621480</guid>
            <pubDate>Sun, 03 Jan 2021 12:53:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: AI-powered landing page builder]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25621407">thread link</a>) | @dannypostma
<br/>
January 3, 2021 | https://headlime.com/features/landing-page | <a href="https://web.archive.org/web/*/https://headlime.com/features/landing-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-7531d82e=""><div data-v-3fe645ca="" data-v-7531d82e=""><div data-v-3fe645ca=""><div data-v-3fe645ca=""><div data-v-3fe645ca=""><div data-v-3fe645ca=""><h2 data-v-3fe645ca=""><span data-v-3fe645ca="">
              Say goodbye to manually creating landing pages and writing copy
            </span></h2> <p data-v-3fe645ca="">
            Our AI-powered landing page builder helps you create custom landing pages for your business in minutes — no writing, designing or coding required.
          </p> </div></div> <p data-v-3fe645ca="">
        There’s no way to describe it. You just have to see it for yourself.
      </p> <p data-v-3fe645ca=""><video autoplay="autoplay" muted="muted" loop="loop" controls="controls" data-v-3fe645ca=""><source src="https://headlime.com/_nuxt/videos/headlime-landing-page.fa451f4.mp4" type="video/mp4" data-v-3fe645ca="">
          Sorry, your browser doesn't support embedded videos.
        </video></p></div></div> <p>
    All pages on this site were created with our AI.
  </p> <div data-v-3fe645ca=""><div><div data-v-ff3b314a="" data-v-3fe645ca=""><p><strong data-v-ff3b314a="">Trusted and used by 862+ companies</strong> <img src="https://headlime.com/_nuxt/img/logo-row.9d69021.png" data-v-ff3b314a=""></p> </div></div></div> <div data-v-3fe645ca=""><div data-v-3fe645ca=""><h2 data-v-3fe645ca="">
        Build a landing page in minutes.
      </h2> <p data-v-3fe645ca="">
        Landing pages are the most important part of your marketing strategy, but they're also one of the hardest to create. We've made it easy for you with our AI-powered tool that creates unique landing pages based on the content you give us.
      </p></div> <div data-v-3fe645ca=""><div data-v-3fe645ca=""> <p data-v-3fe645ca="">
          Explain your product in just twenty words and we'll generate appropriate design templates instantly.
        </p></div> <div data-v-3fe645ca=""> <p data-v-3fe645ca="">
          You can choose from hundreds of templates. Choose your favorite blocks and simply drag-and-drop them to build your page.
        </p></div> <div data-v-3fe645ca=""> <p data-v-3fe645ca="">
          Your fully customizable landing page is ready for download as HTML file — ready to be uploaded to where ever your website is hosted.
        </p></div></div></div> <div data-v-3fe645ca=""><dl data-v-3fe645ca=""><div data-v-3fe645ca=""> <p data-v-3fe645ca=""><dt data-v-3fe645ca="">
            Copy, design &amp; code
          </dt> <dd data-v-3fe645ca="">
            Our AI writes compelling copy and weaves it into an HTML template. Your visitor's experience is as if they were reading original content written by a human writer or designer. Not one line of text is ever copied from other sites either - every word has been created by our algorithm specifically for that page only.
          </dd></p></div> <div data-v-3fe645ca=""> <p data-v-3fe645ca=""><dt data-v-3fe645ca="">
            Professional landing pages
          </dt> <dd data-v-3fe645ca="">
            Professionally designed templates, complete with color schemes and fonts, that you can use for your next campaign. Our templates are mobile responsive so they look great on any device.
          </dd></p></div> <div data-v-3fe645ca=""> <p data-v-3fe645ca=""><dt data-v-3fe645ca="">
            Easy to use editor
          </dt> <dd data-v-3fe645ca="">
            Use our drag-and-drop editor to create unique designs using hundreds of prebuilt templates and elements such as headers, pricing, features, forms and more!
          </dd></p></div> <div data-v-3fe645ca=""> <p data-v-3fe645ca=""><dt data-v-3fe645ca="">
            Conversion optimized
          </dt> <dd data-v-3fe645ca="">
            Every element on the page is built using our conversion-trained AI, meaning we know exactly what works best when it comes to conversions.
          </dd></p></div></dl></div> <div data-v-3fe645ca=""><div data-v-3fe645ca=""><h2 data-v-3fe645ca="">
        There’s no human touch here.
      </h2> <p data-v-3fe645ca="">
        Look at the samples below. They were all generated by our AI, not by hand, no designer input whatsoever — just pure machine learning magic. And we think that is freaking awesome! So check out these samples of what Headlime can do for your business.
      </p></div> <p><a href="https://headlime.com/preview/landing-page/example1" target="_blank" data-v-3fe645ca=""><img src="https://headlime.com/_nuxt/img/lp-example-1.a133dc0.jpg" alt="" draggable="false" data-v-3fe645ca=""></a> <a href="https://headlime.com/preview/landing-page/example2" target="_blank" data-v-3fe645ca=""><img src="https://headlime.com/_nuxt/img/lp-example-2.2569780.jpg" alt="" draggable="false" data-v-3fe645ca=""></a> <a href="https://headlime.com/preview/landing-page/example3" target="_blank" data-v-3fe645ca=""><img src="https://headlime.com/_nuxt/img/lp-example-3.386d0a9.jpg" alt="" draggable="false" data-v-3fe645ca=""></a></p></div></div></div></div>]]>
            </description>
            <link>https://headlime.com/features/landing-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621407</guid>
            <pubDate>Sun, 03 Jan 2021 12:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HyperLSTM Implementation and Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621394">thread link</a>) | @vpj
<br/>
January 3, 2021 | https://lab-ml.com/labml_nn/hypernetworks/hyper_lstm.html | <a href="https://web.archive.org/web/*/https://lab-ml.com/labml_nn/hypernetworks/hyper_lstm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p><code>input_size</code> is the size of the input $x_t$,
<code>hidden_size</code> is the size of the LSTM, and
<code>hyper_size</code> is the size of the smaller LSTM that alters the weights of the larger outer LSTM.
<code>n_z</code> is the size of the feature vectors used to alter the LSTM weights.</p>
<p>We use the output of the smaller LSTM to computer $z_h^{i,f,g,o}$, $z_x^{i,f,g,o}$ and
$z_b^{i,f,g,o}$ using linear transformations.
We calculate $d_h^{i,f,g,o}(z_h^{i,f,g,o})$, $d_x^{i,f,g,o}(z_x^{i,f,g,o})$, and
$d_b^{i,f,g,o}(z_b^{i,f,g,o})$ from these again using linear transformations.
These are then used to scale the rows of weight and bias tensors of the main LSTM.</p>
<p>📝 Since the computation of $z$ and $d$ are two sequential linear transformations
these can be combined into a single linear transformation.
However we’ve implemented this separately so that it matches with the description
in the paper.</p>
            </div></div>]]>
            </description>
            <link>https://lab-ml.com/labml_nn/hypernetworks/hyper_lstm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621394</guid>
            <pubDate>Sun, 03 Jan 2021 12:30:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Attention Works in Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621370">thread link</a>) | @sytelus
<br/>
January 3, 2021 | https://theaisummer.com/attention/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/attention/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>I have always worked on computer vision applications. Honestly, transformers and attention-based methods were always the fancy things that I never spent the time to study. You know, maybe later and etc. Now they managed to reach state-of-the-art performance in ImageNet [3].</p>

<p>In NLP, transformers and attention have been utilized successfully in a plethora of tasks including reading comprehension, abstractive summarization, word completion, and others.</p>

<p>After a lot of reading and searching, I realized that <strong>it is crucial to understand how attention emerged from NLP and machine translation</strong>. This is what this article is all about. After this article, we will inspect the transformer model like a boss. I give you my word.</p>

<p>Let’s start from the beginning: What is attention? Glad you asked!</p>

<blockquote>
  <p>Attention is <strong>memory through time</strong>. ~ Alex Graves 2020 [1]</p>
</blockquote>

<p>Always keep this in the back of your mind.</p>

<p>The attention mechanism emerged naturally from problems that deal with <strong>time-varying data (sequences)</strong>. So, since we are dealing with “sequences”, let’s formulate the problem in terms of machine learning first. Attention became popular in the general task of dealing with sequences.</p>

<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
  <li><a href="#sequence-to-sequence-learning" id="markdown-toc-sequence-to-sequence-learning">Sequence to sequence learning</a></li>
  <li><a href="#a-high-level-view-of-encoder-and-decoder" id="markdown-toc-a-high-level-view-of-encoder-and-decoder">A high-level view of encoder and decoder</a></li>
  <li><a href="#the-limitations-of-rnns" id="markdown-toc-the-limitations-of-rnns">The limitations of RNN’s</a></li>
  <li><a href="#attention-to-the-rescue" id="markdown-toc-attention-to-the-rescue">Attention to the rescue!</a></li>
  <li><a href="#types-of-attention-implicit-vs-explicit" id="markdown-toc-types-of-attention-implicit-vs-explicit">Types of attention: implicit VS explicit</a></li>
  <li><a href="#types-of-attention-hard-vs-soft" id="markdown-toc-types-of-attention-hard-vs-soft">Types of attention: hard VS soft</a></li>
  <li><a href="#attention-in-our-encoder-decoder-example" id="markdown-toc-attention-in-our-encoder-decoder-example">Attention in our encoder-decoder example</a></li>
  <li><a href="#attention-as-a-trainable-weight-mean-for-machine-translation" id="markdown-toc-attention-as-a-trainable-weight-mean-for-machine-translation">Attention as a trainable weight mean for machine translation</a></li>
  <li><a href="#how-do-we-compute-attention" id="markdown-toc-how-do-we-compute-attention">How do we compute attention?</a></li>
  <li><a href="#global-vs-local-attention" id="markdown-toc-global-vs-local-attention">Global vs Local Attention</a></li>
  <li><a href="#self-attention-the-key-component-of-the-transformer-architecture" id="markdown-toc-self-attention-the-key-component-of-the-transformer-architecture">Self-attention: the key component of the Transformer architecture</a></li>
  <li><a href="#advantages-of-attention" id="markdown-toc-advantages-of-attention">Advantages of Attention</a></li>
  <li><a href="#attention-beyond-language-translation" id="markdown-toc-attention-beyond-language-translation">Attention beyond language translation</a></li>
</ul>

<h2 id="sequence-to-sequence-learning">Sequence to sequence learning</h2>

<p>Before attention and transformers, Sequence to Sequence (<strong>Seq2Seq</strong>) worked pretty much like this:</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/seq2seq.png" alt="seq2seq"></p>

<p>The elements of the sequence \(x_1, x_2\), etc. are usually called <strong>tokens</strong>. They can be literally anything. For instance, text representations, pixels, or even images in the case of videos.</p>

<p>OK. So why do we use such models?</p>

<blockquote>
  <p>The goal is to transform an input sequence (source) to a new one (target).</p>
</blockquote>

<p>The two sequences can be of the same or arbitrary length.</p>

<p>In case you are wondering, recurrent neural networks (<strong>RNNs</strong>) dominated this category of tasks. The reason is simple: <strong>we liked to treat sequences sequentially</strong>. Sounds obvious and optimal? <a href="https://click.linksynergy.com/deeplink?id=r24KwW5qbBo&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fattention-models-in-nlp%2Ftransformer-decoder-rDLol" rel="noopener" target="_blank">Transformers</a> proved us it’s not!</p>

<h2 id="a-high-level-view-of-encoder-and-decoder">A high-level view of encoder and decoder</h2>

<p>The <strong>encoder</strong> and <strong>decoder</strong> are nothing more than stacked RNN layers, such as <a href="https://theaisummer.com/understanding-lstm/" target="_blank">LSTM’s</a>. The encoder processes the input and produces one <strong>compact representation</strong>, called <strong>z</strong>, from all the input timesteps. It can be regarded as a compressed format of the input.</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/encoder.png" alt="encoder"></p>

<p>On the other hand, the decoder receives the context vector <strong>z</strong> and generates the output sequence. The most common application of Seq2seq is language translation. We can think of the input sequence as the representation of a sentence in English and the output as the same sentence in French.</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/decoder.png" alt="decoder"></p>

<p>In fact, RNN-based architectures used to work very well especially with <a href="https://theaisummer.com/understanding-lstm/" target="_blank">LSTM</a> and <a href="https://theaisummer.com/gru/" target="_blank">GRU</a> components.</p>

<p>The problem? <strong>Only for small sequences</strong> (&lt;20 timesteps). Visually:</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/scope-per-senquence-length.png" alt="scope-per-senquence-length"></p>

<p>Let’s inspect some of the reasons why this holds true.</p>

<h2 id="the-limitations-of-rnns">The limitations of RNN’s</h2>

<p>The intermediate representation <strong>z</strong> cannot encode information from all the input timesteps. This is commonly known as the <strong>bottleneck problem</strong>. The vector z needs to capture all the information about the source sentence.</p>

<p>In theory, mathematics indicates that this is possible. However in practice, how far we can see in the past (the so-called reference window) is finite. RNN’s tend to <strong>forget information</strong> from timesteps that are far behind.</p>

<p>Let’s see a concrete example. Imagine a sentence of 97 words:</p>

<blockquote>
  <p>“On offering to help the <strong>blind man</strong>, the man who then <strong>stole his car</strong>, had not, at that precise moment, had any evil intention, quite the contrary, what he did was nothing more than obey those feelings of generosity and altruism which, as everyone knows, are the two best traits of human nature and to be found in much more hardened criminals than this one, a simple <strong>car-thief</strong> without any hope of advancing in his profession, exploited by the real owners of this enterprise, for it is they who take advantage of the needs of the <strong>poor</strong>.” ~ Jose Saramago, “Blindness.”</p>
</blockquote>

<p>Notice anything wrong? Hmmm… The bold words that facilitate the understanding are quite far!</p>

<p>In most cases, the vector <strong>z</strong> will be unable to compress the information of the early words as well as the 97th word. Eventually, the system pays more attention to the last parts of the sequence. However, this is not usually the optimal way to approach a sequence task and it is not compatible with the way humans translate or even understand language.</p>

<p>Furthermore, the stacked RNN layer usually create the well-know <strong>vanishing gradient problem</strong>, as perfectly visualized in the <a href="https://distill.pub/2019/memorization-in-rnns/" rel="noopener" target="_blank">distill article</a> on RNN’s:</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/memorization-rnns.png" alt="memorization-rnns">
<em>The stacked layers in RNN’s may result in the vanishing gradient problem. <a href="https://distill.pub/2019/memorization-in-rnns/" rel="noopener" target="_blank">Source</a></em></p>

<p>Thus, let us move beyond the standard encoder-decoder RNN.</p>

<h2 id="attention-to-the-rescue">Attention to the rescue!</h2>

<p>Attention was born in order to address these two things on the Seq2seq model. But how?</p>

<blockquote>
  <p>The core idea is that the context vector \(z\) should have access to all parts of the input sequence instead of just the last one.</p>
</blockquote>

<p>In other words, we need to form a <strong>direct connection</strong> with each timestamp.</p>

<p>This idea was originally proposed for computer vision. Larochelle and Hinton [5] proposed that by looking at different parts of the image (glimpses), we can learn to accumulate information about a shape and classify the image accordingly. The same principle was later extended to sequences.  We can look at all the different words at the same time and learn to “pay attention“ to the correct ones depending on the task at hand.</p>

<p>And behold. This is what we now call <strong>attention</strong>, which is simply a notion of <strong>memory through time</strong>.</p>

<p>It is crucial in my humble opinion to understand the generality of this concept. To this end, we will cover all the different types that one can divide attention mechanisms.</p>

<h2 id="types-of-attention-implicit-vs-explicit">Types of attention: implicit VS explicit</h2>

<p>Before we continue with a concrete example of how attention is used on machine translation, let’s clarify one thing:</p>

<blockquote>
  <p>Very deep neural networks <strong>already</strong> learn a form of <strong>implicit attention</strong> [6].</p>
</blockquote>

<p>Deep networks are very rich function approximators. So, without any further modification, they <strong>tend to ignore parts of the input and focus on others</strong>. For instance, when working on human pose estimation, the network will be more sensitive to the pixels of the human body. Here is an example of <a href="https://theaisummer.com/self-supervised-learning-videos/" target="_blank">self-supervised approaches to videos</a>:</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/activations-focus-in-ssl%20.png" alt="activations-focus-in-ssl ">
<em>Where activations tend to focus when trained in a self-supervised way. Image from Misra et al. ECCV 2016. <a href="https://arxiv.org/abs/1603.08561" rel="noopener" target="_blank">Source</a></em></p>

<p>“Many activation units show a <strong>preference</strong> for human body parts and pose.” ~ <a href="https://arxiv.org/abs/1603.08561" rel="noopener" target="_blank">Misra et al. 2016</a></p>

<p>One way to visualize implicit attention is by looking at the partial derivatives with respect to the input. In math, this is the <a href="https://medium.com/unit8-machine-learning-publication/computing-the-jacobian-matrix-of-a-neural-network-in-python-4f162e5db180" rel="noopener" target="_blank">Jacobian matrix</a>, but it’s out of the scope of this article.</p>

<p>However, we have many reasons to enforce this idea of implicit attention. Attention is quite intuitive and interpretable to the human mind. Thus, by asking the network to <strong>‘weigh’ its sensitivity to the input based on memory from previous inputs,</strong> we introduce <strong>explicit attention</strong>. From now on, we will refer to this as attention.</p>

<h2 id="types-of-attention-hard-vs-soft">Types of attention: hard VS soft</h2>

<p>Another distinction we tend to make is between hard and soft attention. In all the previous cases, we refer to attention that is parametrized by <strong>differentiable functions</strong>. For the record, this is termed as <strong>soft attention</strong> in the literature. Officially:</p>

<blockquote>
  <p><strong>Soft</strong> attention means that the function varies smoothly over its domain and, as a result, it is differentiable.</p>
</blockquote>

<p>Historically, we had another concept called <strong>hard attention</strong>.</p>

<p>An intuitive example: You can imagine a robot in a labyrinth that has to make a <strong>hard</strong> decision on which path to take, as indicated by the red dots.</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/labyrinth-hard-attention.png" alt="labyrinth-hard-attention">
<em>A decision in the labyrinth. <a href="https://i.pinimg.com/736x/99/c7/c4/99c7c42d36b436a553db92ace92a796d.jpg" rel="noopener" target="_blank">Source</a></em></p>

<p>In general, <strong>hard means that it can be described by discrete variables while soft attention is described by continuous variables</strong>. In other words, hard attention replaces a deterministic method with a stochastic sampling model.</p>

<p>In the next example, starting from a random location in the image tries to find the “important pixels” for classification. Roughly, the algorithm has to choose a direction to go inside the image, during training.</p>

<p><img src="https://theaisummer.com/assets/img/posts/attention/hard-attention.png" alt="hard-attention">
<em>An example of hard attention.<a href="https://arxiv.org/pdf/1406.6247v1.pdf" rel="noopener" target="_blank">Source</a></em></p>

<p>Since hard attention is non-differentiable, we can’t use the standard gradient descent. That’s why we need to train them using Reinforcement Learning (<strong>RL</strong>) techniques such as <a href="https://theaisummer.com/Policy-Gradients/" target="_blank">policy gradients and the REINFORCE algorithm</a> [6].</p>

<p>Nevertheless, the major issue with the REINFORCE algorithm and similar RL methods is that they have a high variance. To summarize:</p>

<blockquote>
  <p><strong>Hard attention</strong> can be regarded as a switch mechanism to determine whether to attend to a region or not, which means that the function has many abrupt changes over its domain.</p>
</blockquote>

<p>Ultimately, given that we already have all the sequence tokens available, we can relax the definition of <strong>hard</strong> attention. In this way, we have a smooth differentiable function that we can train end to end with our favorite backpropagation.</p>

<p>Let’s get back to our showcase to see it in action!</p>

<h2 id="attention-in-our-encoder-decoder-example">Attention in our encoder-decoder example</h2>

<p>In the encoder-decoder RNN case, given previous state in the decoder as \(y_{i-1}\) and the the hidden state \(\textbf{h} = {h1,h_2, h_{n} }\), we have something like this:</p><p>

\[\textbf{e}_{i}=\operatorname{attention_{net}}\left(y_{i-1}, \textbf{h} \right) \in R{^n}\]

</p><p>The index i indicates the prediction step. Essentially, we define a score between the hidden state of the decoder and all the hidden states of the encoder.</p>

<p>More specifically, for each hidden state (denoted by j) \(\textbf{h}_1,\textbf{h}_2,\textbf{h}_n\) we will calculate a scalar:</p><p>

\[e_{i …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/attention/">https://theaisummer.com/attention/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/attention/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621370</guid>
            <pubDate>Sun, 03 Jan 2021 12:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The science of why bad words feel so good during painful moments]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621321">thread link</a>) | @pseudolus
<br/>
January 3, 2021 | https://www.cbc.ca/radio/quirks/may-30-swearing-makes-pain-more-tolerable-mt-st-helens-40-years-later-and-more-1.5589125/the-science-of-why-bad-words-feel-so-good-during-painful-moments-1.5589136 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/quirks/may-30-swearing-makes-pain-more-tolerable-mt-st-helens-40-years-later-and-more-1.5589125/the-science-of-why-bad-words-feel-so-good-during-painful-moments-1.5589136">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Fake swear words like ‘fouch’ and ‘twizpipe’ just can’t compete with the f-word when it comes to helping people tolerate pain</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5590696.1590778122!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file.jpg"></p></div><figcaption>New research is looking at why swearing helps us tolerate pain longer.<!-- --> <!-- -->(Shutterstock / ESB Professional)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="The science of why bad words feel so good during painful moments"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/268/235/Quirks-640x360__028333.jpg" alt=""></p><p><span>Quirks and Quarks</span><span>8:25</span><span>The science of why bad words feel so good during painful moments</span></p></div></div></div></span></p><p><span><p><em>Originally published on May 30, 2020.</em></p>  <p>According to a new study&nbsp;investigating how swearing affects our pain tolerance, it really has to be a bad word to do any good.</p>  <p>"There's nothing that can beat a good old swear word," lead researcher Olly Robertson told <a href="https://www.cbc.ca/radio/quirks" target="_blank"><em>Quirks &amp; Quarks</em></a> host Bob McDonald.&nbsp;</p>  <p>Most of us have let the occasional curse word slip when experiencing pain. Previous <a href="https://pubmed.ncbi.nlm.nih.gov/19590391/" target="_blank"><u>scientific studies</u></a> have shown that swearing can actually increase a person's pain tolerance. But in polite company, we may try and substitute those swears with a similar-sounding word.</p>  <p>Robertson and her colleagues at the Swear Lab at Keele University in the U.K. wanted to understand what it was about swear words that has this analgesic effect on our pain, and if those fake swears are convincing substitutes for our brains.</p>  <p>Their research is published in the journal <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.00723/full"><u>Frontiers in Psychology</u></a>.</p>  <h2>'Fouch' and 'twizpipe' just won't cut it</h2>  <p>To find out how swearing affects pain tolerance, Robertson and her colleague, psychologist <a href="https://www.keele.ac.uk/psychology/people/richardstephens/"><u>Richard Stephens</u></a>, invented two fake swear words, 'fouch' and 'twizpipe.'&nbsp;</p>  <p>"We hypothesized that perhaps 'fouch' might help in the same way that swear words help because it sounds very similar, it's got that 'FFF-CHH' sound at the end," said Robertson, a post doctoral research assistant&nbsp;in the department of experimental psychology at the University of Oxford.</p>  <p>She adds that 'twizpipe' was chosen because it represented another hypothesis about why swears work —&nbsp;because they&nbsp;sound&nbsp;funny.</p>  <p>"There was an idea that perhaps swear words help because they're hilarious, and they help distract you in that way."</p>  <p>Robertson and Stephens then had 92 participants immerse their hands in a tub of ice cold water for as long as they could — which is a harmless, but painful experience. These participants were told to randomly repeat one of four words every three seconds - either a conventional swear word (in this case, the familiar 'f-word'), a neutral word (the word 'solid') and the words 'fouch' and 'twizpipe.' Throughout, the participants gave ratings of their pain perception, emotion, humour, and distraction levels, as well as had their hearts monitored.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Swearing gives you that little bit of a jolt, it helps your heart beat faster, it helps your respiration rate increase, and so it gives you that power, that adrenaline to get through a stressful period.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Olly Robertson,&nbsp; Keele University</cite></span></blockquote>    <p>The new 'fake' swear words had the exact same effect on pain threshold and pain tolerance as the neutral word. However, saying the genuine f-word was linked with a 32 percent increase in pain threshold, and a 33 percent increase in pain tolerance.</p>  <p>"When we had people swearing with their&nbsp;hand in the water, they could tolerate the cold water for longer by up to 18 seconds, which doesn't sound like a lot but actually, when you need to get yourself through this horrible experience 18 seconds is a long time," said Robertson.</p>  <h2>Swearing could activate fight-or-flight</h2>  <p>There are two predominant theories as to why swear words have this effect on pain. The first is that by saying something that is typically forbidden, the brain's fight-or-flight response is activated.</p>  <p>"Swearing gives you that little bit of a jolt, it helps your heart beat faster, it helps your respiration rate increase, and so it gives you that power, that adrenaline to get through a stressful period," said Robertson.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>It's completely dependent on what you've grown up with, what you think is acceptable, and what isn't<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Olly Robertson, Keele University</cite></span></blockquote>    <p>A second idea was that swearing triggers the brain's rest and relaxation response, which comes after a heightened period of stress.</p>  <p>"As the research stands we don't really know whether they are exclusive, whether they work together, or what's going on. And that's really exciting for us as researchers in the Swear Lab."</p>  <h2>Not all swears are the same</h2>  <p>In this study, the f-word was the swear of choice. In previous research, Robertson has observed that particular word tends to be a favourite amongst English-speakers and non-English speakers alike.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/2008-01-28-7xd0fk3b-jpg.jpg 300w,https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/2008-01-28-7xd0fk3b-jpg.jpg 460w,https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/2008-01-28-7xd0fk3b-jpg.jpg 620w,https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/2008-01-28-7xd0fk3b-jpg.jpg 780w,https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/2008-01-28-7xd0fk3b-jpg.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4651619.1525719283!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/2008-01-28-7xd0fk3b-jpg.jpg"></p></div><figcaption>Dutch daredevil Wim Hof is celebrated for his tolerance to ice baths. Could swearing be part of his secret?<!-- --> <!-- -->(NY Daily News via Getty Images)</figcaption></figure></span></p>  <p>"There's something about that word, that we love, that's cross-cultural. And I just think that's quite beautiful in its own way," said Robertson.</p>  <p>But when it comes to pain tolerance, the words that work best are the words that are the most taboo, or hold the most power. "It's completely dependent on what you've grown up with, what you think is acceptable, and what isn't," she said.&nbsp;</p>  <p>"There's no point saying the f-word if you actually preferred the b-word or the c-word. You've got to use what's good for you and what you think will work."</p>  <hr>  <p><em>Produced and written by Amanda Buckiewicz</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/quirks/may-30-swearing-makes-pain-more-tolerable-mt-st-helens-40-years-later-and-more-1.5589125/the-science-of-why-bad-words-feel-so-good-during-painful-moments-1.5589136</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621321</guid>
            <pubDate>Sun, 03 Jan 2021 12:10:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit Testing Spark Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621307">thread link</a>) | @ayblbd
<br/>
January 3, 2021 | https://ayoublabiad.me/posts/unit-testing-spark-jobs/ | <a href="https://web.archive.org/web/*/https://ayoublabiad.me/posts/unit-testing-spark-jobs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><time datetime="2021-01-02T13:16:26+0100">Sat, Jan 2, 2021</time></p><p>I recently went down the rabbit hole of Spark unit testing. As it’s uncharted territory, you find a plethora of conflicting opinions. So I decided to hack my way through it.
This article is a summary of my thoughts and findings. I try to go into the process I went through to resolve the problems I faced during my Spark journey.</p>
<p>To escape the theory, I will be using concrete examples throughout the article. The data represent the number of flights <code>count</code>, from <code>origin</code> countries to <code>destination</code> countries. It has the following structure:</p>
<table>
<thead>
<tr>
<th>Destination</th>
<th>Origin</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Morocco</td>
<td>Spain</td>
<td>3</td>
</tr>
<tr>
<td>Morocco</td>
<td>Egypt</td>
<td>5</td>
</tr>
<tr>
<td>France</td>
<td>Germany</td>
<td>10</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>The structure is mindlessly inspired by the <a href="https://github.com/databricks/Spark-The-Definitive-Guide/tree/master/data/flight-data/csv">Spark: The Definitive Guide’s Code Repository</a>. You find my code <a href="https://github.com/AYBLBD/spark-unit-testing">here</a>.</p>
<p>Before going into the testing section, I want to lay down the tools I am using, the basics of my project structure, and those of a testable Spark job. First thing first, this is the structure of my project:</p>
<pre>+-- project
|   +-- build.properties
|   +-- plugins.sbt
+-- src
|   +-- main
|   +-- test
+-- .gitignore
+-- .scalafix.conf
+-- .scalafmt.conf
+-- LICENSE
+-- build.sbt
+-- README.md
</pre>
<h2 id="dependencies">Dependencies</h2>
<p>Let’s start with Spark dependencies:</p>
<div><pre><code data-lang="scala"><span>// build.sbt
</span><span></span>libraryDependencies <span>++=</span> <span>Seq</span><span>(</span>
  <span>"org.apache.spark"</span> <span>%%</span> <span>"spark-core"</span> <span>%</span> sparkVersion<span>,</span>
  <span>"org.apache.spark"</span> <span>%%</span> <span>"spark-sql"</span> <span>%</span> sparkVersion<span>,</span>
  <span>"org.apache.spark"</span> <span>%%</span> <span>"spark-hive"</span> <span>%</span> sparkVersion <span>%</span> provided
<span>)</span>
</code></pre></div><h3 id="loading-configuration">Loading configuration</h3>
<p>For configuration loading, I am using Config. But I am curious about using it along with <a href="https://github.com/codingwell/scala-guice">Guice</a>. But for now:</p>
<div><pre><code data-lang="scala"><span>// build.sbt
</span><span>// https://mvnrepository.com/artifact/com.typesafe/config
</span><span></span>libraryDependencies <span>+=</span> <span>"com.typesafe"</span> <span>%</span> <span>"config"</span> <span>%</span> <span>"1.4.1"</span>
</code></pre></div><p>To add a configuration file inside your project. Create a <code>/src/main/resources/reference.conf</code> with the following:</p>
<div><pre><code data-lang="ini"><span># reference.conf</span>
<span>settings {</span>
  <span>database</span> <span>=</span> <span>"dev"</span>
<span>}</span>
</code></pre></div><p>Or any configuration you need. Then use Config to load it as follows:</p>
<div><pre><code data-lang="scala"><span>val</span> config <span>=</span> <span>ConfigFactory</span><span>.</span>load<span>()</span>
<span>val</span> db<span>:</span> <span>String</span> <span>=</span> config<span>.</span>getString<span>(</span><span>"settings.database"</span><span>)</span>
</code></pre></div><p>And you are ready to go! Check the <a href="https://github.com/lightbend/config">docs</a> to find out more.</p>
<h3 id="testing-tool">Testing tool</h3>
<p>For testing, we will be using:</p>
<div><pre><code data-lang="scala"><span>// build.sbt
</span><span>// https://mvnrepository.com/artifact/me.vican.jorge/dijon
</span><span></span>libraryDependencies <span>+=</span> <span>"me.vican.jorge"</span> <span>%%</span> <span>"dijon"</span> <span>%</span> <span>"0.4.0"</span> <span>%</span> <span>"test"</span>

<span>// https://mvnrepository.com/artifact/org.scalatest/scalatest-flatspec
</span><span></span>libraryDependencies <span>+=</span> <span>"org.scalatest"</span> <span>%%</span> <span>"scalatest-flatspec"</span> <span>%</span> <span>"3.3.0-SNAP3"</span> <span>%</span> <span>"test"</span>

<span>// https://github.com/MrPowers/spark-fast-tests
</span><span></span>libraryDependencies <span>+=</span> <span>"com.github.mrpowers"</span> <span>%%</span> <span>"spark-fast-tests"</span> <span>%</span> <span>"0.21.3"</span> <span>%</span> <span>"test"</span>
</code></pre></div><p>Scalatest for creating unit tests, Spark-fast-tests for comparing DataFrames, and Sijon for creating dynamically typed JSON. Scalatest is a flexible testing tool. It is simple to get up and running. An example from the front page:</p>
<div><pre><code data-lang="scala"><span>import</span> collection.mutable.Stack
<span>import</span> org.scalatest._
<span>import</span> flatspec._
<span>import</span> matchers._

<span>class</span> <span>ExampleSpec</span> <span>extends</span> <span>AnyFlatSpec</span> <span>with</span> should<span>.</span><span>Matchers</span> <span>{</span>

  <span>"A Stack"</span> should <span>"pop values in last-in-first-out order"</span> in <span>{</span>
    <span>val</span> stack <span>=</span> <span>new</span> <span>Stack</span><span>[</span><span>Int</span><span>]</span>
    stack<span>.</span>push<span>(</span><span>1</span><span>)</span>
    stack<span>.</span>push<span>(</span><span>2</span><span>)</span>
    stack<span>.</span>pop<span>()</span> should be <span>(</span><span>2</span><span>)</span>
    stack<span>.</span>pop<span>()</span> should be <span>(</span><span>1</span><span>)</span>
  <span>}</span>

  it should <span>"throw NoSuchElementException if an empty stack is popped"</span> in <span>{</span>
    <span>val</span> emptyStack <span>=</span> <span>new</span> <span>Stack</span><span>[</span><span>Int</span><span>]</span>
    a <span>[</span><span>NoSuchElementException</span><span>]</span> should be thrownBy <span>{</span>
      emptyStack<span>.</span>pop<span>()</span>
    <span>}</span> 
  <span>}</span>
<span>}</span>
</code></pre></div><h3 id="plugins">Plugins</h3>
<p>For the plugins, I am using these two:</p>
<div><pre><code data-lang="scala"><span>// project/plugins.sbt
</span><span></span>
addSbtPlugin<span>(</span><span>"ch.epfl.scala"</span> <span>%</span> <span>"sbt-scalafix"</span> <span>%</span> <span>"0.9.24"</span><span>)</span>
addSbtPlugin<span>(</span><span>"org.scalameta"</span> <span>%</span> <span>"sbt-scalafmt"</span> <span>%</span> <span>"2.4.0"</span><span>)</span>
</code></pre></div><h4 id="scalafmt">Scalafmt</h4>
<p><a href="https://github.com/scalameta/scalafmt">Scalafmt</a> for code formating. You can enable it in your IntelliJ IDEA by going to: <code>CTRL + ALT + S</code> &gt; <code>Editor</code> &gt; <code>Code Style</code> &gt; <code>Scala</code> &gt; <code>Formatter</code> Change it from <code>IntelliJ</code> to <code>Scalafmt</code>. Then add the following configuration to the root directory of your project:</p>
<div><pre><code data-lang="ini"><span># .scalafmt.conf</span>
<span>version</span> <span>=</span> <span>"2.7.5"</span>
<span># Check https://github.com/monix/monix/blob/series/3.x/.scalafmt.conf for full configuration</span>
</code></pre></div><h4 id="scalafix">Scalafix</h4>
<p><a href="https://github.com/scalacenter/scalafix">Scalafix</a> is a linting and refactoring tool. It needs some configuration in the <code>build.sbt</code> file:</p>
<div><pre><code data-lang="scala"><span>// built.sbt
</span><span>// https://scalacenter.github.io/scalafix/docs/users/installation.html
</span><span></span>
inThisBuild<span>(</span>
  <span>List</span><span>(</span>
    scalaVersion <span>:</span><span>=</span> <span>"2.12.12"</span><span>,</span>
    semanticdbEnabled <span>:</span><span>=</span> <span>true</span><span>,</span> <span>// enable SemanticDB
</span><span></span>    semanticdbVersion <span>:</span><span>=</span> scalafixSemanticdb<span>.</span>revision <span>// use Scalafix compatible version
</span><span></span>  <span>)</span>
<span>)</span>

scalacOptions <span>++=</span> <span>List</span><span>(</span>
  <span>"-Ywarn-unused"</span>
<span>)</span>
</code></pre></div><p>Then:</p>
<div><pre><code data-lang="ini"><span># .scalafix.conf</span>
<span># https://spotify.github.io/scio/dev/Style-Guide.html</span>
<span>rules</span> <span>=</span> <span>[
</span><span>  RemoveUnused,
</span><span>  LeakingImplicitClassVal</span>
<span>]</span>
</code></pre></div><p>Now that we know our tools, let’s explore our structure.</p>
<h2 id="project-structure">Project structure</h2>
<p>This is the point of divergence. Each team will have its own structure adapted to its specific needs. Here are my suggestions:</p>
<pre>scala
+-- me.ayoublabiad
|   +-- common
|   |   +-- SparkSessionWrapper.scala
|   +-- io
|   |   +-- Read.scala
|   |   +-- Write.scala
|   +-- job
|   |   +-- flights
|   |   |   +-- FlightsTransformation.scala
|   |   |   +-- FlightsJob.scala
|   |   +-- Job.scala
|   +-- Main.scala
</pre>
<ul>
<li><strong>common</strong>: Package for common classes between jobs. A <code>Utils</code> class with frequently used functions could be added here.</li>
<li><strong>io</strong>: Package for input and output functions. Something like:</li>
</ul>
<div><pre><code data-lang="scala">  <span>def</span> readFromCsvFileWithSchema<span>(</span>location<span>:</span> <span>String</span><span>,</span> schema<span>:</span> <span>String</span><span>)</span><span>:</span> <span>DataFrame</span> <span>=</span>
    spark<span>.</span>read
      <span>.</span>option<span>(</span><span>"header"</span><span>,</span> <span>"true"</span><span>)</span>
      <span>.</span>schema<span>(</span>schema<span>)</span>
      <span>.</span>csv<span>(</span>location<span>)</span>
</code></pre></div><p>with <code>val schema = "destination STRING, origin STRING, count INT"</code>. And the output:</p>
<div><pre><code data-lang="scala">  <span>def</span> writeTohive<span>(</span>spark<span>:</span> <span>SparkSession</span><span>,</span> dataFrame<span>:</span> <span>DataFrame</span><span>,</span> database<span>:</span> <span>String</span><span>,</span> tableName<span>:</span> <span>String</span><span>)</span><span>:</span> <span>Unit</span> <span>=</span> <span>{</span>
    dataFrame<span>.</span>createGlobalTempView<span>(</span><span>s"</span><span>${</span>tableName<span>}</span><span>_view"</span><span>)</span>
    spark<span>.</span>sql<span>(</span><span>s"DROP TABLE IF EXISTS </span><span>$database</span><span>.</span><span>$tableName</span><span>"</span><span>)</span>
    spark<span>.</span>sql<span>(</span><span>s"CREATE TABLE </span><span>$database</span><span>.</span><span>$tableName</span><span> AS SELECT * FROM </span><span>${</span>tableName<span>}</span><span>_view"</span><span>)</span>
  <span>}</span>
</code></pre></div><ul>
<li>
<p><strong>job</strong>: Is where the magic happens. This package contains domain-specific subpackages. Inside each subpackage, we find the transformations and the job of each domain-specific use case. This is a personal preference. But I found that grouping transformations in one package and the jobs in another package is burdensome when dealing the code. Especially when the number of use cases grows.</p>
<ul>
<li>The transformation functions should have one of the following signatures:</li>
</ul>
<div><pre><code data-lang="scala"><span>def</span> function1<span>(</span>dataFrame<span>:</span> <span>DataFrame</span><span>)</span><span>:</span> <span>DataFrame</span>
<span>// or 
</span><span></span><span>def</span> function2<span>(</span>column<span>:</span> <span>Column</span><span>)</span><span>:</span> <span>Column</span>
<span>// or even
</span><span></span><span>def</span> function3<span>(</span>columnName<span>:</span> <span>String</span><span>)</span><span>:</span> <span>Column</span>
</code></pre></div><p>They could be used:</p>
<div><pre><code data-lang="scala"><span>val</span> transformedDf<span>:</span> <span>DataFrame</span> <span>=</span> function1<span>(</span>rawDataFrame<span>)</span>

<span>// or 
</span><span></span>
rawDataFrame
  <span>.</span>withColumn<span>(</span><span>"newColumnName"</span><span>,</span> function2<span>(</span>col<span>(</span><span>"oldColumnName"</span><span>)))</span>

<span>// or even 
</span><span></span>
rawDataFrame
  <span>.</span>withColumn<span>(</span><span>"newColumnName"</span><span>,</span> function3<span>(</span><span>"oldColumnName"</span><span>))</span>
</code></pre></div><ul>
<li>The job is where we group the three phases: reading, transforming, and writing. In its simplest form, it should look something like this:</li>
</ul>
<div><pre><code data-lang="scala"><span>import</span> com.typesafe.config.Config
<span>import</span> me.ayoublabiad.io.Read.readTableFromHive
<span>import</span> me.ayoublabiad.io.Write
<span>import</span> me.ayoublabiad.job.Job
<span>import</span> org.apache.spark.sql.functions.<span>{</span>col<span>,</span> lit<span>}</span>
<span>import</span> org.apache.spark.sql.<span>{</span><span>DataFrame</span><span>,</span> <span>SparkSession</span><span>}</span>

<span>object</span> <span>FlightsJob</span> <span>extends</span> <span>Job</span> <span>{</span>
  <span>override</span> <span>def</span> process<span>(</span>spark<span>:</span> <span>SparkSession</span><span>,</span> config<span>:</span> <span>Config</span><span>)</span><span>:</span> <span>Unit</span> <span>=</span> <span>{</span>
    <span>val</span> db<span>:</span> <span>String</span> <span>=</span> config<span>.</span>getString<span>(</span><span>"settings.database"</span><span>)</span>

    <span>val</span> flights<span>:</span> <span>DataFrame</span> <span>=</span> readTableFromHive<span>(</span>db<span>,</span> <span>"flights"</span><span>)</span>

    <span>val</span> destinationsWithTotalCount <span>=</span> <span>FlightsTransformation</span><span>.</span>getDestinationsWithTotalCount<span>(</span>flights<span>)</span>

    <span>Write</span><span>.</span>writeTohive<span>(</span>spark<span>,</span> filteredDestinations<span>,</span> db<span>,</span> <span>"flights_total_count"</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></li>
<li>
<p><strong>Job.scala</strong>: In a trait to bind the jobs implementations.</p>
</li>
<li>
<p><strong>Main.scala</strong>: The entry point of your job.</p>
</li>
</ul>
<p>Inside the job package is your playground. Now that we’re all on the same page, let’s discuss the ideas behind testing Spark jobs.</p>
<h2 id="a-case-for-testing-spark-jobs">A case for testing Spark jobs</h2>
<p>I like to think about Spark jobs as three simple phases:</p>





<figure>
  <picture>
    <source srcset="https://d33wubrfki0l68.cloudfront.net/aa601f8a92e54a26c3ef41ea85ccb40b5b14c0cb/d87fb/posts/unit-testing-spark-jobs/spark-steps.png" media="(min-width: 1200px)">
    <source srcset="https://d33wubrfki0l68.cloudfront.net/aa601f8a92e54a26c3ef41ea85ccb40b5b14c0cb/d87fb/posts/unit-testing-spark-jobs/spark-steps.png" media="(min-width: 920px)">
    <img src="https://d33wubrfki0l68.cloudfront.net/aa601f8a92e54a26c3ef41ea85ccb40b5b14c0cb/d87fb/posts/unit-testing-spark-jobs/spark-steps.png" alt="">
  </picture>
  <figcaption>The three phases of a Spark job</figcaption>
</figure>
<p>You read your data, build your DAG, then you trigger the whole thing by a powerful almighty action. Now we have to keep in mind that our goal is not to test Spark! You are testing your logic and business logic, which is condensed mainly in the <strong>transformations</strong> step. You are trying to answer the question: Does this code reflect what I am thinking? Proceeding, I don’t find a use for testing the IO of your job, that’s on Spark. So we will stick to finding if we need to test those transformations.</p>
<p>Let’s concretize those ideas: Based on the data that we have, what the total count of flights for each destination?</p>
<div><pre><code data-lang="scala"><span>def</span> getDestinationsWithTotalCount<span>(</span>flights<span>:</span> <span>DataFrame</span><span>)</span><span>:</span> <span>DataFrame</span> <span>=</span>
    flights
      <span>.</span>groupBy<span>(</span><span>"destination"</span><span>)</span>
      <span>.</span>agg<span>(</span>sum<span>(</span><span>"count"</span><span>).</span>alias<span>(</span><span>"total_count"</span><span>))</span>
</code></pre></div><p>That’s simple enough. Let’s assume you need the <code>origin</code> country column to stay, and you are not a big fan of self-joins. The <em>natural</em> solution would be using a <code>Window</code> function:</p>
<div><pre><code data-lang="scala">  <span>def</span> addTotalCountColumn<span>(</span>flights<span>:</span> <span>DataFrame</span><span>)</span><span>:</span> <span>DataFrame</span> <span>=</span> <span>{</span>
    <span>val</span> winExpDestination <span>=</span> <span>Window</span><span>.</span>partitionBy<span>(</span><span>"destination"</span><span>)</span>

    flights
      <span>.</span>withColumn<span>(</span><span>"total_count"</span><span>,</span> count<span>(</span><span>"count"</span><span>).</span>over<span>(</span>winExpDestination<span>))</span>
  <span>}</span>
</code></pre></div><p>Is this function worthy of testing? Probably not if:</p>
<ul>
<li>You remember that the boundaries of <code>Window</code>  by defaut are <code>UnboundedPreceding</code> and <code>UnboundedFollowing</code>;</li>
<li>If you noticed that I am using <code>count</code> instead of using <code>sum</code>!</li>
<li>If you understand why we can’t <code>sum</code> the <code>total_count</code> to get the total of all flights for all destinations.</li>
</ul>
<p>While this is a simple example to illustrate an idea, you can scale it up to more complex use cases. I think that Raymond Hettinger talk about <a href="https://www.youtube.com/watch?v=UANN2Eu6ZnM">The Mental Game of Python</a> is relevant in this context. Unfortunately, we can only hold so much in our 7 slots brain.</p>
<p>Although I lied before to prove a point, the natural solution should be:</p>
<div><pre><code data-lang="scala"><span>def</span> getDestinationsWithTotalCount<span>(</span>flights<span>:</span> <span>DataFrame</span><span>)</span><span>:</span> <span>DataFrame</span> <span>=</span>
    flights
      <span>.</span>groupBy<span>(</span><span>"destination"</span><span>)</span>
      <span>.</span>agg<span>(</span>
        collect_list<span>(</span><span>"origin"</span><span>).</span>alias<span>(</span><span>"origins"</span><span>),</span>
        sum<span>(</span><span>"count"</span><span>).</span>alias<span>(</span><span>"total_count"</span><span>))</span>
</code></pre></div><p>Or is it? But you get the idea.</p>
<p>Another example I want to look at, is having to retrieve a parameter stored in a table. Let’s look at the tests first:</p>
<div><pre><code data-lang="scala">  <span>"getParamFromTable"</span> should <span>"turn the param if it exists"</span> in <span>{</span>
    <span>val</span> input<span>:</span> <span>DataFrame</span> <span>=</span> createDataFrame<span>(</span>
      obj<span>(</span>
       …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ayoublabiad.me/posts/unit-testing-spark-jobs/">https://ayoublabiad.me/posts/unit-testing-spark-jobs/</a></em></p>]]>
            </description>
            <link>https://ayoublabiad.me/posts/unit-testing-spark-jobs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621307</guid>
            <pubDate>Sun, 03 Jan 2021 12:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Technology in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25621278">thread link</a>) | @MarkMc
<br/>
January 3, 2021 | https://elidourado.com/blog/notes-on-technology-2020s/ | <a href="https://web.archive.org/web/*/https://elidourado.com/blog/notes-on-technology-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content"><p>As we start a new decade, it’s a good time to reflect on expectations for the next 10 years. Tyler thinks the Great Stagnation <a href="https://marginalrevolution.com/marginalrevolution/2020/12/why-did-the-great-stagnation-end.html">could be ending</a>. Caleb sees <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">cracks</a>. Noah expresses <a href="https://noahpinion.substack.com/p/techno-optimism-for-the-2020s">techno-optimism</a>. In this post, my aim is not to predict an end or non-end to stagnation. Rather, it is to think through the particulars of how technology could evolve over the next decade. Then we can assess separately whether we should consider it the Roaring 20s or the Boring 20s.</p><p>What would constitute an end to the Great Stagnation? Any precise cutoff will be arbitrary, but for the sake of discussion, let’s say sustained growth in <a href="https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/">utilization-adjusted total factor productivity</a> of 2 percent per year. By comparison, mean utilization-adjusted TFP growth from 1947 through 1972 was 2.1 percent. Since 2005, it has been 0.17 percent. (Note: it is important to use the utilization-adjusted series, as this corrects for the business cycle.)</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a7a8a1d9e4c4d1050c2902966a316436559074f1/cd6b6/img/tfp.png" alt="Total factor productivity in the U.S. since 1947" title="Total factor productivity in the U.S. since 1947"></p><p>Whatever your cutoff for TFP growth, one of my convictions is that scientific breakthroughs alone are not enough to drive an end to the Great Stagnation. TFP only budges when new technologies are adopted at scale, and generally this means products, not just science. Science lays critical groundwork for new technology, but after all the science is done, much work remains. Someone must shepherd the breakthrough to the product stage, where it can actually affect TFP. This means building businesses, surmounting regulatory obstacles, and scaling production.</p><p>With that caveat firmly in mind, what will the next decade bring in terms of meaningful technological change? Here’s what I’m watching.</p><h2 id="biotech-and-health">Biotech and health</h2><p>We are coming off a huge win: two new mRNA COVID vaccines, conceived and brought to market in less than a year. The ability to encode and deploy arbitrary mRNA in our bodies sure seems like a game changer—it allows us to essentially program our cells to make whatever proteins we want. In the case of the COVID vaccines, the vaccine payload instructs our cells to make the coronavirus spike protein, which our immune system then learns to attack. Bert Hubert has a <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">fascinating write-up</a> of the “code” in the vaccine.</p><p>Bringing a brand new vaccine to market in less than a year—using a never-before-applied-in-humans-at-scale technology no less—is a world record, but it could have been even faster. As David Wallace-Wells <a href="https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html">emphasizes</a>, Moderna’s vaccine was designed by January 13. We had it the whole time. Some delay was necessary to determine effective dosing. Some further regulatory delay may have been warranted to ensure the vaccine was safe and to ascertain its efficacy. But as Wallace-Wells indicates, the regulatory outcome was never really in doubt. “None of the scientists I spoke to for this story were at all surprised by either outcome,” he writes. “All said they expected the vaccines were safe and effective all along.”</p><p>What should we make of the fact that all of the scientists knew all along that Moderna’s vaccine would work? The question in my mind is: what other mRNA treatments do we have the whole time? What if I told you Moderna has an <a href="https://www.poz.com/article/experimental-hiv-vaccine-stimulates-production-neutralizing-antibodies">HIV vaccine candidate</a>? HIV lacks SARS-CoV-2’s telltale spike protein and thus may prove a more challenging foe—but don’t you wonder, if we treated the problem with real urgency, whether new mRNA technology could wipe out the AIDS epidemic this decade? I do.</p><p>And mRNA technology can be deployed against more than just viruses. Both Moderna and BioNTech have personalized vaccine candidates targeting cancer. Although called a “cancer vaccine,” the treatment is only administered once the subject has cancer—it isn’t preventative. The companies use an algorithm to analyze the genetic sequences of the tumor and the patient’s healthy cells and predict which molecules could be used to generate a strong immune response against the cancer. “I was actually witnessing the cancer cells shrinking before my eyes,” <a href="https://www.nature.com/articles/d41586-019-03072-8">said</a> Brad Kremer, a melanoma patient who received the BioNTech treatment. So let’s milk mRNA technology for all it’s worth this decade. It can save us from more than just a pandemic.</p><p>What about CRISPR? It is a great example of a technology that has not yet made a meaningful economic contribution. Although the technique for editing DNA was discovered in 2012—and a Nobel Prize was awarded to its two discoverers this year—no treatment using CRISPR has been approved outside of clinical trials. So far, its impact has been limited to making researchers more productive—not a bad thing, to be sure, but not close to CRISPR’s full potential. As trials progress, however, I do think some CRISPR treatments will come online in the next few years, especially those targeting genetic disorders that we have very limited means of otherwise treating.</p><p>DeepMind’s <a href="https://medium.com/cgo-benchmark/deepminds-protein-folding-solution-what-just-happened-279d32e8d0f">protein-folding breakthrough</a> signals a promising decade for the science of proteomics. Most directly, being able to predict protein shapes will enable us to discover drugs more rapidly. Buuuut, because drug trials take many years, we might expect this technology not to really be felt by the general public until the 2030s.</p><p>What DeepMind’s achievement indicates to me the most is that machine learning is actually useful. This might seem obvious, but consider: most applications of machine learning so far—excluding autonomous vehicles, which have themselves not really arrived yet—are toys. I love watching AlphaZero crush Stockfish on YouTube, but chess is literally a game. GPT-3 produced some fun demos. AlphaFold heralds something different—non-toy superhuman performance is now here, and I am interested to see what else it can do. Aside from the aforementioned AVs, I expect it to be applied widely in other areas of biology. Again, it will take a long time for the breakthroughs to trickle down into products, but at least the 2030s should be sick. I mean, not sick. Healthy.</p><p>Let’s talk about life extension, one of my favorite biotech topics. 2020 was a big year for the Conboy Lab at Berkeley, which proved that all the weird past findings about “<a href="https://en.wikipedia.org/wiki/Parabiosis">young blood</a>” extending life were not actually due to any elixir in the blood of children (thank goodness). Rather, the rejuvenating aspects of young blood experiments were due to the dilution of harmful factors in old blood. By mechanically removing plasma and replacing it with saline and enough albumin to replace what was taken out, they diluted aged blood factors in both mice and humans and were able to <a href="https://www.aging-us.com/article/103418/text#fulltext">rejuvenate germ layer tissues</a> and <a href="https://link.springer.com/article/10.1007/s11357-020-00297-8">improve cognition by reducing neuroinflammation</a>.</p><p>These findings are exciting not only because they represent a scientific advance in understanding aging, but also because they herald the first real anti-aging product that could come to market. Therapeutic plasma exchange is FDA-approved (not for aging, but for a bunch of other conditions). I imagine there remain prohibitions on advertising that it can add years to your life, but it is safe, and a doctor can prescribe it off label. It’s also cheap. An automated plasmapheresis machine—which lets you do treatment after treatment—can be bought online for under $3,000. That is less than the cost of a single transfusion of young blood sold by the startup <a href="https://www.ambrosiaplasma.com/">Ambrosia</a>. How long until someone opens a clinic offering plasma dilution? I bet someone tries it in 2021. If it works, people will get over the weirdness, and it could be commonplace by 2030.</p><p>Another longevity product that is about to get hot: aging clocks based on DNA methylation or proteomics. Do you want to know how biologically old you are? Today, for a few hundred dollars, you can get a test that will tell you. As these tests become better and cheaper, self-experimenters are going to have a field day. Doing before-and-after aging tests, anyone who can get their hands on human growth hormone could replicate the protocol used by <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/acel.13028">Fahy et al.</a> to rejuvenate the thymus. As the thymus is a critical element of the immune system, decline of which is a critical factor in aging, this is non-trivial rejuvenation. The Fahy study found that 12 months of treatment created about 2.5 years of epigenetic rejuvenation, with results accelerating in the last quarter of the trial.</p><p>There is a lot more in the <a href="https://www.lifespan.io/road-maps/the-rejuvenation-roadmap/">Rejuvenation Roadmap</a>—dozens of possible life-extending treatments are at various stages of development. There’s a good chance a few senolytic drugs will be approved by the end of the decade. As I noted <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">yesterday at Fortune</a>, we spend less than 1% of the NIH budget on aging biology—we should raise that by a lot.</p><p>Unlike others, I am not-so-bullish on metformin. It does seem to reduce all-cause mortality in Americans, but it may do so because <a href="https://www.liebertpub.com/doi/10.1089/met.2018.0105">88% of Americans are metabolically unhealthy</a>. If you are one of the 12%, and you should strive to be, I don’t think metformin will do much for you.</p><p>One final biotech observation: every year, the Apple Watch gets a new health-related sensor. This year it was blood oxygen, pretty good for detecting if you might have COVID! Fast forward to 2030 and wearables will have at least 10 more health-related sensors than they do today. Some no-brainers are body temperature, blood pressure, and blood glucose sensors. What will the other 7 be? At some point, it becomes possible to replace a lot of primary care with continuous monitoring. A few smart algorithms to provide simple medical advice could improve population-level health without much cost. More data could also yield faster, more accurate, and of course more remote diagnoses when you do have to see a doctor.</p><p>There is a lot in biotech that is promising right now, but in more than any other field, it is important not to be seduced by the sexy headlines showing rapid scientific progress. Don’t get complacent. Biology is proceeding faster than medical productivity because a lot of the wonderful discoveries are not being translated into approved treatments and products at a decent rate. Let’s salute and cheer for the discoveries, but spare many thoughts for the entrepreneurs trying to bring treatments to market.</p><h2 id="energy">Energy</h2><p>The 2010s were the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elidourado.com/blog/notes-on-technology-2020s/">https://elidourado.com/blog/notes-on-technology-2020s/</a></em></p>]]>
            </description>
            <link>https://elidourado.com/blog/notes-on-technology-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621278</guid>
            <pubDate>Sun, 03 Jan 2021 11:58:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expressing Problems in Their Natural Language [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25621217">thread link</a>) | @phoe-krk
<br/>
January 3, 2021 | http://watrophy.com/files/language.pdf | <a href="https://web.archive.org/web/*/http://watrophy.com/files/language.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://watrophy.com/files/language.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621217</guid>
            <pubDate>Sun, 03 Jan 2021 11:39:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My stack will outlive yours]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25621169">thread link</a>) | @headalgorithm
<br/>
January 3, 2021 | https://blog.steren.fr/2020/my-stack-will-outlive-yours/ | <a href="https://web.archive.org/web/*/https://blog.steren.fr/2020/my-stack-will-outlive-yours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
	<header>
		
		<time date="2020-12-22">December 2020</time>
	</header>

		<p>
		My stack requires no maintenance, has perfect Lighthouse scores, will never have any security vulnerability, is based on open standards, is portable, has an instant dev loop, has no build step and… will outlive any other stack.
		</p>
		<p>
		It’s not LAMP, Wordpress, Rails, MEAN, Jamstack... I don’t do CSR (Client-side rendering), SSR (Server Side Rendering), SSG (Static Site Generation)...
		</p>
		<p>
		My stack is <b>HTML+CSS</b>.
		</p>
		<p>
		And because my sources are in git, pushed to GitHub, <a href="https://pages.github.com/">GitHub Pages</a> is my host.
		</p>
		<p>
		Of course, I’m being a bit provocative here. I should rather say that, for some specific use cases, I concluded that to get top performances and to guatantee long term support, HTML+CSS was the best choice, instead on relying on technologies currently more popular. Because I’m done rewriting my site every couple of years.
		</p>

		<h3>Why HTML+CSS?</h3>
		<p>
		It all started with <a href="https://labs.steren.fr/">a blog</a>, that I was hosting on Wordpress.com (which is "Wordpress-as-a-Service", because the last thing I want to do is administer a Wordpress installation on my own server). I <strong>paid</strong> Wordpress.com to do one job: host my blog. And one day I looked at its sources and Lighthouse scores:
		</p>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-sources.png" alt="Sources of my Wordpress.com blog, showing a lot of inlined unreadable scripts">
			<figcaption>Sources of my Wordpress.com blog, what is all this?</figcaption>
		</figure>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-lighthouse.png" alt="Lighthouse scores of my Wordpress.com blog, showing 19/100 for Performance">
			<figcaption>Lighthouse score of my blog hosted on Wordpress.com</figcaption>
		</figure>
		<p>
		What have we done?
		</p>
		<p>
		Sure, these are the problems of one specific blogging platform. I’m pretty sure others are better, at least in terms of performance. But isn’t there something fundamentally wrong if displaying a short text with images takes seconds, loads countless render-blocking scripts, and has unreadable sources?
		</p>
		<p>
		My requirements were:
		</p>
		<ol>
			<li>performance</li>
			<li>simplicity</li>
			<li>long long term support</li>
		</ol>
		<p>
		It was time to say goodbye to Wordpress. I didn’t need 99% of its features anyway. Other blogging platforms didn’t meet expectations either (I seriously have no idea why so many people publish on Medium… behind a login wall). I looked at static site generators like Jekyll, Hugo, 11ty, but all of these require tooling installed, have a build step and will ultimately need some updates or be abandonned by their maintainer. What if we also get rid of these?
		</p>
		<p>
		The best tool is no tool, the best build step is no build step, the best update is no update. HTML gives us all that, and more.
		</p>

		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/lighthouse-score-pure-html-css.svg" alt="Lighthouse score of 100">
			<figcaption>Lighthouse score of this page</figcaption>
		</figure>

		<h3>What is the HTML+CSS stack good for?</h3>
		<p>
		Let’s first differentiate between what I call a web <em>page</em> and a web <em>app</em>: The goal of a web <em>page</em> is to serve content, on the other hand, the goal of a web <em>app</em> is to enable the user to perform interactive tasks. Of course, there are in-betweens, often in the form of content that might need customization depending on the logged in user and content that might allow some interactions.
		</p>
		<p>
		HTML+CSS fits the web <em>page</em> use case. Wow, what a revelation! It might seem obvious, but it seems we’ve all forgotten this these days. HTML+CSS does not fit the web <em>app </em>use case, or any in between.
		</p>
		<p>
		We said a web <em>page</em> serves content, but let’s dive into more concrete use cases:
		</p>
		<ul>
			<li>Product / Company / Business landing page and marketing sites</li>
			<li>Personal portfolio / bio</li>
			<li>Blog</li>
			<li>Documentation</li>
		</ul>

		<h3>How to develop for HTML+CSS?</h3>
		<p>
		Authoring a pure HTML+CSS site can be done in any text editor, in any environment (any desktop OS, any smartphone, or even directly using GitHub’s single file editor) and previewed by simply opening the file in any browser.
		</p>
		<p>
		Keep the HTML of every page minimal and semantic. First, because there is no need for countless of &lt;div&gt;, but then because it makes sources more readable and easier to edit. See for example the <a href="https://github.com/steren/blog/blob/master/2020/my-stack-will-outlive-yours/index.html">HTML sources of this page</a>: a total of 150 lines, 100 lines are for the content, the rest is metadata and page structure, nothing extra. 
		</p>
		<p>
		For consistency, all pages that need to share the same style can point to the same CSS file. This avoids  duplication when it comes to styling (but note that loading this file creates an extra HTTP request, which could be avoided if style was inlined).
		</p>
		<p>
		When not cluttered with unnecessary scripts, divs or classes, I have no issue writing HTML directly. Yes, the paragraph tags are a bit annoying and distracting, but proper indentation and syntax highlighting mitigate this.
		<br>
		Sometimes, for drafting long blog articles, I’m working in Google Docs, and when I’m happy, export the content to clean HTML using an add-on. Google Docs is awesome for collaboration, with powerful suggestions and commenting system. That’s ideal for the “draft” phase. 
		<br>
		Because all content is in git, final review and approval can be done via GitHub pull requests.
		</p>
		<p>
		When I publish a new page, I need to link to it manually from the index page. I’m OK with that. It’s done in one line. It also allows me to have more control over when I want the page to be “published”.
		</p>
		<p>
		I don't need to pay for custom themes, I have complete freedom in the style and layout of my site.
		I can embed anything I want without being restricted by the choice of the hosting platform: SVG images, 3D models, interactive JS experiences. 
		</p>
		<p>
		Creating a new page requires to clone an existing one.
		So... if I don’t use any templating system, how do I update my header, footer or nav? Well, simply by using the ”Replace in files” feature of any good text editor. They don’t need frequent updates anyway. The benefits of using a templating system is not worth the cost of introducing the tooling it requires.
		</p>
		
		<h3>In conclusion</h3>
		<p>
		You don’t need  Wordpress, or Hugo to put a blog online, or Angular, React or Next.js to put a web page online. Raw HTML and CSS do the job.
		</p>
		<p>
		That being said, you’ll need to pick up some tooling or framework if you want to build a web app or add more interactivity or customization to your web pages. And for that, I’m very glad to see that frameworks now seem to be prioritizing performance, notably by prioritizing serving the content first and leveraging caching whenever possible. The era of “download 5MB of JS first and then download content from athe REST API” seems to be over for content web pages. (I personally think it’s still OK to do so for web apps, as the user’s intent and expectations are different).
		</p>
		<p>
		Is the “HTML+CSS only” approach a bit extreme? A bit, it’s basically saying “all software is terrible, how can I minimize my dependencies on software”. Web standards are a model of backward compatibility. I’m pretty confident that my web pages written in raw HTML+CSS will have no issue being accessed and authored 10 years from now, without me having to do anything.
		</p>  
	</article>
</div></div>]]>
            </description>
            <link>https://blog.steren.fr/2020/my-stack-will-outlive-yours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621169</guid>
            <pubDate>Sun, 03 Jan 2021 11:28:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Equal Pay for Equal Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25621162">thread link</a>) | @dustinmoris
<br/>
January 3, 2021 | https://dusted.codes/equal-pay-for-equal-work | <a href="https://web.archive.org/web/*/https://dusted.codes/equal-pay-for-equal-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Remote work is on the rise, the economy is on a decline and businesses are re-structuring themselves around what many consider the new normal. Increasingly more organisations are opening themselves up to the possibility of working remotely beyond just the temporary measure in the fight against COVID-19. Many begin to see remote work as not only a necessary consequence, but rather as a new opportunity to diversify their workforce, increase employee productivity and cut some cost. The biggest cost saving obviously comes from office space, and not just in terms of raw square footage but also in location. When previously companies had to boast huge HQs in expensive areas, now they can spread themselves thinner across more affordable cities. Another big cost saving can come from employee salaries. A more distributed workforce and more work from home opportunities will inevitably mean a bigger talent pool competing for the same open positions, effectively giving employers a bigger choice.</p>
<p>However, when it comes to existing employees' salaries the direction taken by big tech companies couldn't be of starker contrast. Companies like <a href="https://www.cnbc.com/2020/05/21/zuckerberg-50percent-of-facebook-employees-could-be-working-remotely.html">Facebook or Twitter</a> have made it clear that employees who choose to relocate to more affordable cities can expect big cuts to their existing salary whereas companies like <a href="https://redditblog.com/2020/10/27/evolving-reddits-workforce/">Reddit announced that they won't reduce the salary of any of their 600 US workers</a> regardless of where they live.</p>
<p>These recent announcements have revived a <a href="https://www.helpscout.com/blog/remote-employee-compensation/">long standing debate</a> around the topic of <a href="https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">equal pay for equal work</a>. Before COVID-19 <a href="https://about.gitlab.com/blog/2019/02/28/why-we-pay-local-rates/">GitLab has already sparked a lot of controversy</a> around the concept of "cost of living" adjusted salaries. At GitLab two engineers who perform the exact same work could get vastly differently compensated based on where they live. It doesn't require a lot of imagination to understand that such policies can alienate a lot of good people and further contribute to the perception of an ever growing inequality gap. Personally I find cost of living adjusted salaries very problematic as they deflect from the real market forces which come into play. Those should be a decent minimum living wage and the forces of demand &amp; supply. If someone is a professional in a niche market, a rare specialist in a scientific field or an exceptionally sought after engineer then cost of living should have no say in determining their pay. Those so called knowledge workers are often higher in demand than there is supply. A good indicator for the scarcity of one's profession is when their employer recruits talent from all across the world and advertises unique perks such as relocation bonuses, dental care or exceptional holiday packages. These benefits would not exist if there wasn't a fierce competition for a particular skill.</p>
<p>Regardless of the real economics at play, it still comes down to a good old negotiation where each person has to stand up for their own beliefs and reach an agreement on their pay. If you find yourself in a situation where your current salary might be at risk due to recent relocation then hopefully the following write-up can help you to negotiate equal pay for equal work. It is a curated list of relevant points to formulate a strong argument why one should receive the same or perhaps an even better pay for the same work carried out from a remote position.</p>
<h2 id="same-duties-same-pay">Same duties, same pay</h2>
<p>If you're reading this blog post then you're most likely not being paid for your time or place of work. You are being paid for your knowledge, your skills, your duties, the challenges which come with your work and most importantly the responsibilities of your role. Your professionalism and your personal commitment which you bring to your every day job will not diminish when you move into a new place. Whether you work remotely or not, you will still contemplate over that tough work problem in your spare time. You will still lose sleep over that big presentation the next day. You will still stay up late to meet an important deadline by the end of the month. You do it because you take pride in your work. You do it because of a sense of personal accountability to your team. It is those qualities which have earned you the trust of your manager over the years. It is those qualities which earned you a pay rise long ago. Changing postcodes doesn't take away your accomplishments from the past. Changing postcodes shouldn't take away the things which you have already earned before.</p>
<h2 id="same-value-same-pay">Same value, same pay</h2>
<p>The value of your contributions hasn't been compromised by moving house. Customers still pay the same price for the products which you have helped to build. Sales figures didn't drop when you went remote. Why should your employer reduce your pay when they are not passing that cost saving onto their customers by cutting their own price? Based on the same principle why your employer won't reduce their prices when downsizing office, you also shouldn't accept a lower salary after moving place. The concept is the same and you shouldn't accept one principle for them, but another for yourself. As you continue to deliver the same value and quality as before, you equally deserve the same compensation in return.</p>
<h2 id="your-savings-their-savings">Your savings, their savings</h2>
<p>Let's be clear, when you transitioned from office to home it's not like you're the only one who benefited from a lower cost of living as a result. Whatever savings you might have made on your rent, your employer does now too. Every person in an office requires an extra desk. Every additional person requires a fraction more of bathroom space. More people mean bigger kitchens, bigger break out areas, more meeting rooms, larger hallways, bigger stairways and more facilities to comply with fire safety regulations. There is more pressure on lifts to avoid bottle necks during peak times. There is more building maintenance work to be done and more frequent cleaning intervals required. A bigger workforce automatically means more individual needs. Extra bicycle storage rooms, canteens, car parks, private offices, outdoor spaces, a bigger selection of refreshments and a larger variety of office perks are just a few to name. Unless your employer is prepared to share their own operational saving directly with you, why should you share your personal operational saving with them? Fundamentally their savings are theirs, and your savings are yours.</p>
<h2 id="their-profit-your-profit">Their profit, your profit</h2>
<p>Have you ever received a pay rise when your employer re-structured themselves to benefit from lower tax? Have you ever received a pay rise when your employer opened up a new factory in a less regulated place? Have you ever received a pay rise when your employer outsourced a call centre into a country without minimum wage? Probably not, because it was your employer and not you who took the risk. Guess what, when you are courageous enough to relocate to a different country, city or state, then any financial gains from your move are also only yours to claim. This shouldn't be a huge surprise as nothing comes without its own significant risk. Economic security, social safety nets, unemployment benefits, retirement support, access to public health services, cost of qualitative education or medical treatment are often some of the compromises which have to be taken into account. Simple things such as free playgrounds for children, access to public recreational grounds, well maintained parks, a good public transport system funded by tax or basic luxuries such as political stability or the ability to safely park a new car on a public road are many other cost calculations not to be dismissed. Of course this is not always the case, but those considerations are for you to make. Nobody else, particularly not your employer, who has a financial interest of dismissing or downplaying those issues should be making those calculations on your behalf. This is such a basic principle that it's almost offensive to suggest the opposite. Your employer should not decide what sort of lifestyle you deserve.</p>
<h2 id="higher-cost-higher-pay">Higher cost, higher pay</h2>
<p>Contrary to common belief, working from home is not cheap. First of all, working permanently from home requires an entire additional room. If your family lived in a three bedroom house before, now you need four.
Thanks to COVID-19 most will agree that working from a sofa is neither practical, nor sustainable or realistic by any means. A proper office desk and a good ergonomic chair are a necessity at the least. Those requirements alone make a legitimate home office significantly more expensive than many would like to admit. Throw in a couple of monitors, a qualitative web cam, microphone, printer, shredder, peripheral devices, a whiteboard, noise cancelling headphones, a mesh router and a backup laptop (assuming you'll get a work laptop provided) then the true cost of a home office begins to reach eye watering levels.</p>
<p>Some employers will try to provide you those supplies, but any seasoned remote worker will tell you to decline such an offer. After all you're still equipping your own personal home. You shouldn't have to pick from a selection of office desks which don't match your walls. You shouldn't have to settle on a chair which doesn't appeal to your eye. You shouldn't have to accept a black bezelled screen when all your other equipment is in space grey. Most importantly though, you want to treat those things as your own. You don't want to change your monitors when you change your job. You don't want to have to go through your employer to make a warranty claim. You don't want to ask for permission to replace a worn out chair. Instead you want to get a pay rise which allows you to set up your home office in the most productive way. If your employer is smart enough then they will not want to manage all of that inventory (which they never get to see) either.</p>
<p>Speaking of inventory, the true cost of working from home does not stop there yet. When working remotely nothing disrupts productivity more than a low bandwidth internet connection. One cannot …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dusted.codes/equal-pay-for-equal-work">https://dusted.codes/equal-pay-for-equal-work</a></em></p>]]>
            </description>
            <link>https://dusted.codes/equal-pay-for-equal-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621162</guid>
            <pubDate>Sun, 03 Jan 2021 11:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8,760 Hours: How to get the most out of next year]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25621018">thread link</a>) | @whikhngbu359
<br/>
January 3, 2021 | https://alexvermeer.com/8760hours/ | <a href="https://web.archive.org/web/*/https://alexvermeer.com/8760hours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_area">
<div class="page">
	<div id="content_box">
		<div id="content">

			<div id="post-2291">
				
				<div>
<p><img src="https://alexvermeer.com/wp-content/uploads/8760-post-cover-v2.jpg" width="900" height="375" alt="Post image for 8,760 Hours: How to get the most out of next year"></p><p><strong>Update (December 2016):&nbsp;Version 2 of this guide is now available! Announcement post <a href="https://alexvermeer.com/8760hours-v2-update-announce/">here</a>. Links in this post are updated to send you to the latest and greatest version.</strong></p>
<h3><a href="http://alexvermeer.com/download/8760-hours-v2.pdf"><!--<a href="https://drive.google.com/file/d/0B2PaeRjVqAN7MngxTXFPQkpLVjg/view">-->Click here to download <em>8,760 Hours v2</em></a><br>&nbsp;</h3>
<p>The end of a year is the perfect time to review one’s life, goals, plans, and projects, as well as plan for the upcoming year. I’ve been fine-tuning my own review process for several years and thought others might be interested to know what I do and how.</p>
<p>So, I wrote up my general year review process in a short PDF guide titled “8,760 Hours”—a reference to the number of hours in a year. This is essentially the review process I use, minus a few details like <a href="http://alexvermeer.com/my-inbox-zero-system/">clearing out my inbox</a>.</p>
<h2 id="outline">Outline</h2>
<p>The guide has six sections:</p>
<ol>
<li><strong>Introduction.</strong> Why plan at all? To get more out of life, to take responsibility for your time.</li>
<li><strong>Tools.</strong> All you really need is pen, paper, and some time. There’s also a very quick introduction to mind mapping and mind mapping software. I then present my fourteen life categories that I use for breaking down my life into its constituent parts and analyzing them.</li>
<li><strong>A snapshot of the past year.</strong> Using the fourteen categories, how are things going? What went well or poorly in the past year? What is the status of your goals and projects?</li>
<li><strong>The next 8,760 hours.</strong> First off, what is your “ideal you”? What do you want each area of your life to look like in an ideal world? Which areas need the most work? What are your major projects or goals to focus on in the upcoming year? Set some priorities.</li>
<li><strong>Optimize for success.</strong> Setting goals is necessary but not sufficient. Using what’s known about <a href="http://alexvermeer.com/getmotivated/">procrastination and motivation</a> we can optimize our chances of success. If you address uncertainties before they creep up, you’ll be better prepared for them. If you schedule regular reviews you’re more likely to stay on track.&nbsp;Squeeze it all into a one-page calendar to keep yourself motivated and remember the big picture.</li>
<li><strong>Additional Resources.</strong> A small collection of additional resources to help you implement the rest of the guide and for further reading.</li>
</ol>
<h2 id="download">Download</h2>
<p>If you’re interested, grab the 22-page PDF guide here:</p>
<h3><a href="http://alexvermeer.com/download/8760-hours-v2.pdf"><!--<a href="https://drive.google.com/file/d/0B2PaeRjVqAN7MngxTXFPQkpLVjg/view">-->Click here to download <em>8,760 Hours v2</em></a><br>&nbsp;</h3>
<p>The guide is completely free, so take it, share it, use it as you see fit. <a href="http://alexvermeer.com/connect/">Let me know</a>&nbsp;if you have any comments, suggestions, or feedback so I can improve it in the next update.</p>
<p>All the best in the new year.</p>
<p>///</p>

					<p>Tagged as:
						<a href="https://alexvermeer.com/tag/guide/" rel="tag nofollow">guide</a>, 
						<a href="https://alexvermeer.com/tag/planning/" rel="tag nofollow">planning</a>, 
						<a href="https://alexvermeer.com/tag/review/" rel="tag nofollow">review</a>
					</p>
				</div>
			</div>

		</div>

		
	</div>
</div>
</div></div>]]>
            </description>
            <link>https://alexvermeer.com/8760hours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25621018</guid>
            <pubDate>Sun, 03 Jan 2021 10:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Data Science with R 2nd edition]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620989">thread link</a>) | @hkhn
<br/>
January 3, 2021 | https://mdsr-book.github.io/mdsr2e/ | <a href="https://web.archive.org/web/*/https://mdsr-book.github.io/mdsr2e/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">

<div id="welcome">

<p>This is the <a href="http://mdsr-book.github.io/mdsr2e">online version</a> of the 2nd edition of <em>Modern Data Science with R</em>.
You can purchase the book from <a href="https://www.routledge.com/Modern-Data-Science-with-R/Baumer-Kaplan-Horton/p/book/9780367191498">CRC Press</a> or from <a href="https://www.amazon.com/Modern-Science-Chapman-Texts-Statistical/dp/0367191490">Amazon</a>.
The <a href="https://www.routledge.com/Modern-Data-Science-with-R/Baumer-Kaplan-Horton/p/book/9781498724487">1st edition</a> is also still available for purchase. Although we won’t recommend buying it, you may find some of <a href="https://www.amazon.com/Modern-Science-Chapman-Texts-Statistical/dp/1498724485/#customerReviews">the reviews</a> helpful.</p>
<p>At the <a href="http://mdsr-book.github.io/">main website for the book</a>, you will find other reviews, instructor resources, errata, and other information.
To submit corrections, please visit our <a href="https://github.com/mdsr-book/mdsr2e/issues">GitHub repository</a> and file an issue.
<img src="https://mdsr-book.github.io/mdsr2e/gfx/mdsr2e_cover.png" width="100%"></p>
<p>© 2021 by <a href="https://taylorandfrancis.com/">Taylor &amp; Francis Group, LLC</a>. Except as permitted under U.S. copyright law, no part of this book may be reprinted, reproduced, transmitted, or utilized in any form by an electronic, mechanical, or other means, now known or hereafter invented, including photocopying, microfilming, and recording, or in any information storage or retrieval system, without written permission from the publishers.</p>

</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://mdsr-book.github.io/mdsr2e/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620989</guid>
            <pubDate>Sun, 03 Jan 2021 10:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimated transmissibility and severity of novel SARS-CoV-2 Variant]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620927">thread link</a>) | @doener
<br/>
January 3, 2021 | https://cmmid.github.io/topics/covid19/uk-novel-variant.html | <a href="https://web.archive.org/web/*/https://cmmid.github.io/topics/covid19/uk-novel-variant.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
  
    
  

  <p><span>Status: Paper under peer review</span> | <span>First online: 23-12-2020</span>  | <span>Last update: 31-12-2020</span></p>


  <p><span><span>Authors: </span><a href="mailto:nicholas.davies@lshtm.ac.uk" title="Email Nicholas Davies">Nicholas Davies</a>*,&nbsp;Rosanna C Barnard<sup>1</sup>,&nbsp;Christopher I Jarvis<sup>1</sup>,&nbsp;Adam J Kucharski<sup>1</sup>,&nbsp;James D Munday<sup>1</sup>,&nbsp;Carl A.B. Pearson<sup>1</sup>,&nbsp;Timothy W Russell<sup>1</sup>,&nbsp;Damien C Tully<sup>1</sup>,&nbsp;Sam Abbott,&nbsp;Amy Gimma,&nbsp;William Waites,&nbsp;Kerry LM Wong,&nbsp;Kevin van Zandvoort,&nbsp;<a href="https://cmmid.github.io/groups/ncov-group" title="CMMID COVID-19 working group" target="_blank">CMMID COVID-19 working group</a>,&nbsp;Rosalind M Eggo,&nbsp;Sebastian Funk,&nbsp;Mark Jit,&nbsp;Katherine E Atkins&nbsp;&amp;&nbsp;W John Edmunds.</span><span>1 contributed equally</span></p>




  
    
      
        
          <p><b>This study has not yet been peer reviewed.</b></p>
        
      
    
  


<p><strong><a href="https://cmmid.github.io/topics/covid19/reports/uk-novel-variant/2020_12_31_Transmissibility_and_severity_of_VOC_202012_01_in_England_update_1.pdf">We have updated our analysis on 31 December 2020 with a brief report here.</a></strong></p>

<p>A novel SARS-CoV-2 variant, VOC 202012/01, emerged in southeast England in November 2020 and appears to be rapidly spreading towards fixation. We fitted a two-strain mathematical model of SARS-CoV-2 transmission to observed COVID-19 hospital admissions, hospital and ICU bed occupancy, and deaths; SARS-CoV-2 PCR prevalence and seroprevalence; and the relative frequency of VOC 202012/01 in the three most heavily affected NHS England regions (South East, East of England, and London). We estimate that VOC 202012/01 is 56% more transmissible (95% credible interval across three regions 50-74%) than preexisting variants of SARS-CoV-2. We were unable to find clear evidence that VOC 202012/01 results in greater or lesser severity of disease than preexisting variants. Nevertheless, the increase in transmissibility is likely to lead to a large increase in incidence, with COVID-19 hospitalisations and deaths projected to reach higher levels in 2021 than were observed in 2020, even if regional tiered restrictions implemented before 19 December are maintained. Our estimates suggest that control measures of a similar stringency to the national lockdown implemented in England in November 2020 are unlikely to reduce the effective reproduction number Rt to less than 1, unless primary schools, secondary schools, and universities are also closed. We project that large resurgences of the virus are likely to occur following easing of control measures. It may be necessary to greatly accelerate vaccine roll-out to have an appreciable impact in suppressing the resulting disease burden.</p>

<p><strong><a href="https://cmmid.github.io/topics/covid19/reports/uk-novel-variant/2020_12_23_Transmissibility_and_severity_of_VOC_202012_01_in_England.pdf">Read the full preprint here.</a></strong></p>

<p><img src="https://cmmid.github.io/topics/covid19/figures/uk_novel_variant_Figure1.png" width="80%"></p>

<p><strong>Fig. 1.</strong> (A) Proportion of VOC 202012/01 in South East, East of England, and London NHS England regions versus the rest of England from 28 September – 1 December 2020 (mean and 95% CI). Grey shaded areas (panels A, C, D) reflect the period of time when England was in a second national lockdown. We cut off the data after 1 December 2020 due to a substantial decrease in representativeness after this time (Fig. S4). (B) Proportion of S gene drop-outs (5 – 11 December) versus mean reproduction number (27 November – 4 December) by local authority in England. The one-week lag accounts for delays from infection to test. (C) Percentage change (95% CI) in Google Mobility indices relative to baseline over time and (D) setting-specific mean contacts (95% CI) from the CoMix study (9) over time and by age for local authorities that went into Tier 4 compared to the rest of England. Educ = education setting. Some local authorities that were within the South East, East of England, and London NHS England regions did not go into Tier 4 and were therefore included in the rest of England for panels C and D. (E) Estimates of R0 (50% and 95% CI) from CoMix social contact survey compared to Rt estimates from REACT-1 SARS-CoV-2 prevalence survey for England. R estimates based on single and aggregated REACT-1 survey rounds are shown.</p>


</div>

      </div>
    </section></div>]]>
            </description>
            <link>https://cmmid.github.io/topics/covid19/uk-novel-variant.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620927</guid>
            <pubDate>Sun, 03 Jan 2021 10:28:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of some Shell goodies for OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620913">thread link</a>) | @todsacerdoti
<br/>
January 3, 2021 | https://www.vincentdelft.be/post/post_20210102 | <a href="https://web.archive.org/web/*/https://www.vincentdelft.be/post/post_20210102">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>I'll list some of my tips and tricks around OpenBSD. <br>
I'm using OpenBSD as daily machine since +10 years now and I'm still amazed how simple and powerful this system is. </p>
<p>So most of the elements listed here under will match <a href="http://man.openbsd.org/ksh">KSH</a> on OpenBSD. I'm using Openbox as window manager, xterm as terminal and neovim as editor. </p>
<p>If you want to re-use some of those ideas, you will have to adapt it to your own config. </p>

<p>On OpenBSD folder's organization is :</p>
<pre><code>- Base applications in /
- Packages in /usr/local
</code></pre>
<p>So I push all my own application is ~/.local</p>
<p>So, one of my first line in ~/.profile is the following</p>
<pre><code>PATH=$HOME/.local/bin:$PATH
</code></pre>
<p>An other important element for Windows Manager and xdg's tool (pkg_add xdg-utils)  is to find .desktop files in :</p>
<pre><code>~/.local/share/applications
</code></pre>

<p>I often have lot of xterm windows open. Generally they are split between the Openbox virtual desktops depending on the scope/activity. </p>
<p>But even that, I have lot of windows. So, I like to change their window title, in order to retrieve them more easily when doing a Alt-TAB or by checking the task bar. </p>
<p>To modify the window's title of xterm, here after a simple command I've added in my .profile:</p>
<pre><code>set_title()
{
    echo -n "\033]0;$1\007"
}
</code></pre>
<p>When you want to change the window's title, you just have to type in the window where you want a new title:</p>
<pre><code>set_title "dev branch xxx"
</code></pre>

<p>To avoid the quazy monochrome of xterm, I'm using colorls (pkg_add colorls). </p>
<p>Then in .profile, I put:</p>
<pre><code>export LSCOLORS=gxfxcxdxbxegedabagacad
alias ls='colorls -GF'
</code></pre>
<p>The first line defines the color to use in the different situation. With colorls we have 11 different situations (directory, link, socket, pipe, exe, ...). For each of those 11, you must provide the foreground color and the background color. <br>
The second line is just to over-write the standard /bin/ls command. The -G is to use the defined colors, with -F colorls adds some visual characters to differentiate folders, executable, ... </p>

<p>As daily machine, I have a laptops, which travel a lot. So I need to know the exact state of the battery. This information is displayed on my status bar. But I do not look it so frequently. So, I prefer to have this information in my preferred shell. </p>
<p>I'm using the following script from my .profile file:</p>
<pre><code>battery()
{
    local bat=""
    local level=""
    local charg=""
    bat=$(apm -b 2&gt;/dev/null)
    if [ -n "$bat" -a "$bat" -lt "4" ]; then
        level=$(apm -l 2&gt;/dev/null)
        charg=$(apm -a 2&gt;/dev/null)
        if [ -n "$charg" -a "$charg" -eq "1" ]; then
            #charging
            print -- "\033[01;32m$level%\033[00m"
        else
            if [ "$level" -lt "20" ]; then
                #print red
                print -- "\033[01;31m$level%\033[00m"
            else 
                #print blue
                print -- "\033[01;34m$level%\033[00m"
            fi
        fi
    else
        #no battery
        print -- ""
    fi
}
</code></pre>
<p>It does report the battery status, if there is one, with 3 colors: green when the power cable is connected, blue when the battery is in good state, red when the battery is bellow 20%. </p>
<p>To have such information directly in my shell, I'm using it in PS1:</p>
<pre><code>export PS1='$(battery)\h:\w\$ '
</code></pre>
<p>By doing this, battery's usage is refreshed each time I press "enter". </p>
<p>The other parameters of PS1 does not provide colors, they display hostname "\h", folder "\w" and default prompt "\$". </p>
<p>Here after a print screen with colorls showing different type of files. Note that I've changed the window's title ;-)</p>
<p><img src="https://www.vincentdelft.be/static/post/post_20210102/color.png"></p>

<p>It's frustrating to type keywords completely, so I'm a big fan of the completion feature of KSH. </p>
<p>It's really easy to configure: just create an array with the elements you have to select. Then you just have to type TAB to have the relevant choice displayed in front of you. </p>
<p>I group them by command. </p>
<pre><code># ssh, scp
set -A SSH_KNOWN_HOSTS ~/.ssh/known_hosts
if [ -f /etc/ssh/ssh_known_hosts ]; then
 SSH_KNOWN_HOSTS="${SSH_KNOWN_HOSTS[@]} /etc/ssh/ssh_known_hosts"
fi
HOST_LIST=$(awk '{split($1,a,","); gsub("].*", "", a[1]); gsub("\[", "", a[1]); print a[1] " root@" a[1]}' $SSH_KNOWN_HOSTS | sort | uniq)
set -A complete_ssh -- $HOST_LIST
set -A complete_scp -- $HOST_LIST

set -A complete_ifconfig_1 -- $(ifconfig | grep ^[a-z] | cut -d: -f1)

set -A complete_signify_1 -- -C -G -S -V
set -A complete_signify_2 -- -q -p -x -c -m -t -z
set -A complete_signify_3 -- -p -x -c -m -t -z

set -A complete_sndioctl_1 -- $(sndioctl | cut -d= -f 1)

set -A complete_chown_1 -- $(users)

alias drcctl="doas rcctl"
set -A complete_drcctl_1 -- get getdef set check reload restart stop start disable enable order ls
set -A complete_drcctl_2 -- $(/bin/ls /etc/rc.d)
</code></pre>
<p>The first lines allow me to list all known hosts from known_hosts files. </p>
<p>The next group display possible interfaces on my machine for the <a href="http://man.openbsd.org/ifconfig">ifconfig</a> command. </p>
<p>The next group is to simplify the usage of signify, per type of command. </p>
<p>For sndioctl it display the possible parameters we can change. </p>
<p>for chwon's command, completion display the known users on my machine. </p>
<p>The last group of command concerns <a href="http://man.openbsd.org/rcctl">rcctl</a>. Since I'm never using "root", I've created a drcctl command in order to have the usual commands as 1st parameter, then the list of possible daemon available on my machine. </p>
<p>With such completion, I'm no more forced to type the full list of parameters. </p>
<p>For example, if I type:</p>
<pre><code>ifc "TAB" i "TAB" scan, I will execute the command
ifconfig iwm0 scan

drc "TAB" sta "TAB" pos "TAB", will become
doas rcctl start postgresql
</code></pre>

<p>Very simple tricks with facilitate the usage of a system like OpenBSD and KSH</p>
<p>In the same "laziness" I'm also a big fan if <a href="https://github.com/junegunn/fzf">fzf</a>. I'll describe how I'm using is in a next blog's post. </p>
      </div></div>]]>
            </description>
            <link>https://www.vincentdelft.be/post/post_20210102</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620913</guid>
            <pubDate>Sun, 03 Jan 2021 10:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a static side generator vs. pure HTML/CSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25620849">thread link</a>) | @dr_melon
<br/>
January 3, 2021 | https://sschoebinger.github.io/posts/2021-01-02-static-site-generator/ | <a href="https://web.archive.org/web/*/https://sschoebinger.github.io/posts/2021-01-02-static-site-generator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="home">
        <!-- HOME -->
        
<article>
    

    <img src="https://sschoebinger.github.io/img/2020-01-02-html-css-vs-11ty.png" alt="html/css vs 11ty" loading="lazy">

<p>Today lets have a look what are the pros and cons of using a static site generator versus building a site with <a href="https://sschoebinger.github.io/posts/2020-12-24-pure-html-css">plain HTML and CSS</a>. As written in my previous blog post I wanted to try a static site generator due to the limitations of the plain HTML and CSS approach. I tried <a href="https://www.11ty.dev/">11ty</a> due to its simplicity and because I'm familiar with the nodejs ecosystem.</p>
<p>The migration of my (simple) site from single page HTML to a static site (generated by 11ty) took me about 2h. I used the following <a href="https://www.filamentgroup.com/lab/build-a-blog/">tutorial</a>.</p>
<p>The 11ty structure of my site looks like this:</p>
<img src="https://sschoebinger.github.io/img/2021-01-02-structure.png" alt="structure of my site with 11ty" loading="lazy">

<p>I write my blog posts in markdown and put each blog post into one separate file.
Due to the fact that the final website need to be generated I was forces to add a build step. With github pages you can specify a branch that contains the content that should be published (previously that was the <em>main</em> branch, now I created a <em>gh-pages</em> branch for that). To avoid the manual effort of generating the website and copying it to the <em>gh-pages</em> branch, I used <a href="https://travis-ci.com/">travis-ci</a> to do that. If I push a change to the <em>main</em> branch of my repository, travis-ci will generate the website with 11ty and push the result to the <em>gh-pages</em> branch of my repository which will then be published with github pages. See <a href="https://github.com/sschoebinger/sschoebinger.github.io">that repo</a> for all details.</p>
<p>And yes, this is the cost that comes with the usage of a static site generator - <strong>the build step</strong>.</p>
<h2>The pros of building your site with plain HTML and CSS:</h2>
<p><strong>You learn and train the basics</strong></p>
<p>As there is no framework you have to do each and every detail on your own (style, navigation, content structuring, ...).
You, the maintainer of your site, knows how your site is build and you can change everything you want. Put content on your site on a regular basis and you will be familiar with changing HTML and CSS files by hand at any time.</p>
<p><strong>Deployment is as easy as possible</strong></p>
<p>As there is no build step you can deploy all the files from your project right to your webserver.
With <a href="https://pages.github.com/">github pages</a> that is zero effort, the only thing you have to do is activate it in your github repo.</p>
<p><strong>No dependency updates</strong></p>
<p>There is no dependency, there is no need for updates, there is no risk of breaking builds.</p>
<h2>The cons of building your site with plain HTML and CSS:</h2>
<p><strong>Content structuring</strong></p>
<p>If you want to structure your code in more than one file you need a templating mechanism or you have to copy the same HTML skeleton into each file.
Now if you want to change your layout you have to change it in each file which is error-prone.</p>
<p><strong>No support for other formats</strong></p>
<p>Writing blog posts in markdown is very comfortable, but of course there is no support for markdown or other formats if you only use plain HTML and CSS.</p>
<h2>The pros of building your site with a static site generator:</h2>
<p><strong>Content structuring</strong></p>
<p>As you can use templates, it is easy to structure your content. At build time you can do whatever you want. For example you can loop over all your blog posts and build a list of it (or only the previous 3 posts below each blog post).</p>
<p><strong>Templates</strong></p>
<p>You can clone a template (from someone else) and only change the configuration and the content to make it yours. You don't need deep knowledge of HTML and CSS.</p>
<h2>The cons of building your site with a static site generator:</h2>
<p><strong>You need a build step</strong></p>
<p>Deployment of your site gets a bit more complicated as you need a build step. If you automate it, the effort is reduced but there is the risk that due to incompatible dependencies the build will break and you have to fix it.</p>
<h2>Conclusion</h2>
<p>From my point of view the advanced content structuring and support of markdown for writing my content is absolutely worth the cost of having a build step required to deploy my website. I'll go with the static site generator setup!</p>
<p>I'm curious to see how often my build will break, I set everything to lts tags/versions 🤞.</p>

</article>
      </section>
    </div></div>]]>
            </description>
            <link>https://sschoebinger.github.io/posts/2021-01-02-static-site-generator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620849</guid>
            <pubDate>Sun, 03 Jan 2021 10:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ and Passing by Value]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620798">thread link</a>) | @ingve
<br/>
January 3, 2021 | https://xania.org/202101/cpp-by-value-args | <a href="https://web.archive.org/web/*/https://xania.org/202101/cpp-by-value-args">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        

        <p>I was recently responding to some <a href="https://github.com/mattgodbolt/xania/pull/252#discussion_r550894493">code review feedback</a>
 and it occurred to me I could write it up for this blog. Which also means I start 2021 with a blog post, not something
 I’ve done in ages.</p>
<p>The question was around why I passed an non-trivial object by value to a function. The recipient function was
 going to copy the object, and the short version is “clang tidy complains if you don’t pass by value and move”.</p>
<p>For the longer version, consider this super simple example:</p>
<div><pre><span></span><code><span>#include</span> <span>&lt;string&gt;</span><span></span>

<span>struct</span> <span>Thing</span> <span>{</span>
  <span>std</span><span>:</span><span>string</span> <span>s_</span><span>;</span>
  <span>void</span> <span>set_s</span><span>(</span><span>std</span><span>::</span><span>string</span> <span>s</span><span>)</span> <span>{</span> <span>s_</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>s</span><span>);</span> <span>}</span>
<span>};</span>
</code></pre></div>

<p>Now consider what happens when we do something like <code>set_s("moo");</code>:</p>
<ul>
<li>The <code>const char*</code> gets converted into a temporary <code>string</code> via the <code>string</code> constructor that takes a <code>const char*</code>.
  That does allocations<sup id="fnref:sso"><a href="#fn:sso">1</a></sup> etc and copies the <code>"moo"</code> into the new temporary <code>string</code> object.</li>
<li>That temporary is used to construct the parameter value <code>s</code> in the <code>set_s</code>. 
  The argument to the constructor of this <code>s</code> is a temporary – so it’s of type <code>string &amp;&amp;</code>. 
  The <code>string&amp;&amp;</code> constructor can “steal” the contents of the temporary string&amp;&amp; which makes it super cheap (no allocations, just swapping pointers).</li>
<li>The <code>s_ = std::move()</code> runs. The <code>s_</code>‘s <code>operator=(string &amp;&amp;)</code> is called (as the move turns the <code>string</code> into an r-value). This also does the steal-the-innards trick.</li>
<li>All the destructors for the temporaries run – the original <code>"moo"</code> temporary object and the pass-by-copy param <code>s</code>. They have no work to do as they’ve been “stolen” from.</li>
</ul>
<p>Short version: exactly one “real” string construction is done, and then there’s a bit of pointer movement, but nothing more expensive.</p>
<p>If, however, we change the parameter to a <code>const string &amp;</code> in <code>set_s</code>, and remove the <code>move</code> in <code>set_s()</code>:</p>
<ul>
<li>The <code>const char *</code> gets converted into a temporary string as before.</li>
<li>It is passed by reference (very cheaply) to <code>set_s()</code> - no work done here at all.</li>
<li>In the <code>s_ = s;</code> we copy the <code>string</code> object. This is another allocation and copy, as we can’t “steal” anything from anyone.</li>
<li>We then destroy the temporary <code>string</code>.</li>
</ul>
<p>This means we do the allocation twice, copy the string data twice, and do a deallocation once. This is more expensive!</p>
<p>You can see in <a href="https://godbolt.org/z/xr1bno">Compiler Explorer</a> that the <code>string::_M_create</code> method is called twice in
the second case, whereas for this small string it’s all inlined in the first case.</p>

    </div>
</div></div>]]>
            </description>
            <link>https://xania.org/202101/cpp-by-value-args</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620798</guid>
            <pubDate>Sun, 03 Jan 2021 09:55:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Opensource your abandonware (2010)]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25620785">thread link</a>) | @app4soft
<br/>
January 3, 2021 | http://pulkomandy.tk/_/_Development/_Opensource%20your%20abandonware | <a href="https://web.archive.org/web/*/http://pulkomandy.tk/_/_Development/_Opensource%20your%20abandonware">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>As you may know, back in 2007 I ressurected the development of <a href="http://grafx2.googlecode.com/">GrafX2</a>.
this old pixelart program, made only for DOS, was left out 6 years earlier by the authors, that had moved on to more modern computers.
Today, graFX2 is amongst the best tool for pixelling, particularly on Linux or other alternative operating systems.
Many people are using it daily to draw really nice pictures. The newer versions added a lot of features such as layers, and there's more to come.</p>

<p>This was possible only because the authors decided to release the source when the project stopped. The code wasn't perfectly clean; it was tied to ms-dos
with some optimized parts written directly in assembly language and accessing the video card hardware directly. Of course, getting an SDL-based version out of it
was not easy. But still, it took considerably less time than rewriting everything from scratch. Also, part of the userbase for the old GrafX2 upgraded to
the new one. For some of them it felt like getting back home after years of using suboptimal tools.</p>

<p>During the revival of GrafX2, I had to develop my web searching skills a lot. First, the original GrafX2 website was offline, and the sourcecode was
gone with it. Thanks to <a href="http://www.filewatcher.com/">filewatcher</a>, an ftpsearch engine, and <a href="http://www.archive.org/">the web archive</a>,
I was able to locate a copy on some russian FTP. Then, I wanted to get in touch with the authors to let them know their software finally found some use.</p>

<p>But grafX2 isn't the main purpose of this article. Last month, I downloaded APlayer, a music player for BeOS. After some hacking to get it working on Haiku
(which eventually led to uncovering and fixing a compatibility bug), I noticed that most musics from Burned Sounds, my preferred chiptune collection, didn't load.
The strange thing is that most of them were in formats supposed to be recognized by APlayer. But looking closer, it turned out they are packed using the Shrink
algorithm. This is a packing system from Amiga days, which can be unpacked only on amiga for lack of any sourcecode or format information. Well, that was until yesterday.
Using my high web searching skills, I found the author of Shrink and kindly asked him by mail if he was willing to release the sourcecode for hissoftware, the last version being from
1996.</p>

<p>He was a bit surprised to see there was some files using Shrink still around, but he had a linux version of the archiver. This version is now released as GPL sourcecode
at <a href="http://sourceforge.net/projects/ashrink/">sourceforge</a>. This is an important step for me in getting more open source software available ; but also in preserving
old files packed in this format. I hope some other people will find it useful too.</p>

<p>I forgot to mention I also made possible the release of a whole lot of other BeOS software made by Arvid and Jonas Norberg. This include the sawteeth sound synthetizer, as
well as the backslash n demo, and also some other unfinished code.</p>

<p>The overall message is, for developpers : think about opensourcing your old projects. Even if the source is not as clean as it could be ; even if they are of no use for you ;
even if they only work on a dead since 10 years operating system : someone, somewhere, may find it useful. You can visit the <a href="http://www.unmaintained-free-software.org/wiki/Main_Page">
Unamintained Free Software</a> page to get some examples of how passing on a project to someone else may work. But not everything goes through this website.</p>

<p>For non-developpers, don't hesitate to get in touch with the devs, even for unmaintained apps, and ask for an open source release. If the software is dead, the author isn't going to get
anymoney for it, so why not release it so other people can improve it ? This is the fastest way to get more open source software. And don't be shy, developpers are, above all, normal people, and they
do like hearing from users.</p>
				</div></div>]]>
            </description>
            <link>http://pulkomandy.tk/_/_Development/_Opensource%20your%20abandonware</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620785</guid>
            <pubDate>Sun, 03 Jan 2021 09:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using checksums to verify syncing 100M database records]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620761">thread link</a>) | @todsacerdoti
<br/>
January 3, 2021 | https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    <p>
        This is an edition of the <a href="https://sirupsen.com/napkin/">Napkin Math newsletter</a>,
        a newsletter about using napkin math and first-principle thinking to
        estimate the performance of systems.
        You can <a href="https://sirupsen.com/napkin">subscribe through email.</a>
    </p>

    <p>A common problem you’ve almost certainly faced is to sync two datastores. This problem comes up in numerous shapes and forms: Receiving webhooks and writing them into your datastore, maintaining a materialized view, making sure a cache reflects reality, ensure documents make it from your source of truth to a search index, or your data from your transactional store to your data lake or column store.</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/8b99afab-9ae3-47cf-8703-f465aaec1473.png" alt=""></p>
<p>If you’ve built such a system, you’ve almost certainly seen B drift out of sync. Building a completely reliable syncing mechanism is difficult, but perhaps we can build a checksumming mechanism to check if the two datastores are equal in a few seconds?</p>
<p>In this issue of napkin math, we look at implementing a solution to <strong>check whether A and B are in sync for 100M records in a few seconds</strong>. The key idea is to checksum an indexed <code>updated_at</code> column and use a binary search to drill down to the mismatching records. All of this will be explained in great detail, read on!</p>
<h2 id="why-are-syncing-mechanisms-unreliable">Why are syncing mechanisms unreliable?</h2>
<p>If you are firing the events for your syncing mechanism after a transaction occurs, such as enqueuing a job, sending a webhook, or emit a Kafka event, you can’t guarantee that it <em>actually</em> gets sent after the transaction is committed. Almost certainly part of pipeline into database B is leaky due to bugs: perhaps there’s an exception you don’t handle, you drop events on the floor above a certain size, some early return, or deploys lose an event in a rare edge case.</p>
<p>But <em>even</em> if you’re doing something that’s theoretically bullet-proof, like using the database replication logs through <a href="https://debezium.io/">Debezium</a>, there’s still a good chance a bug somewhere in your syncing pipeline is causing you to lose occasional events. If theoretical guarantees were adequate, <a href="https://jepsen.io/">Jepsen</a> wouldn’t uncover much, would it? A team I worked with even wrote a TLA+ proof, but still found bugs with a solution like the one I describe here! In my experience, a checksumming system should be part of <em>any</em> syncing system.</p>
<p>It would seem to me that building reliable syncing mechanisms would be easier if databases had a standard, fast mechanism to answer the question: <em>“Does database A and B have all the same data? If not, what’s different?"</em> Over time, as you fix your bugs, it will of course happen more rarely, but being able to guarantee that they are in sync is a huge step forward.</p>
<p>Unfortunately, this doesn’t exist as a user API in modern databases, but perhaps we can design such a mechanism <em>without</em> modifying the database?</p>
<p>This exploration will be fairly long. If you just want to see the final solution, scroll down to the end. This issue shows how to use napkin math to incrementally justify increasing complexity. While I’ve been thinking about this problem for a while, this is a fairly accurate representation of how I thought about the problem a few months ago when I started working on it. It’s also worth noting that when doing napkin math usually, I don’t write prototypes like this if I’m fairly confident in my understanding of the system underneath. I’m doing it here to make it more entertaining to read!</p>
<h2 id="assumptions">Assumptions</h2>
<p>Let’s start with some assumptions to plan out our ‘syncing checksum process’:</p>
<ul>
<li>100M records</li>
<li>1KiB per record (~100 GiB total)</li>
</ul>
<p>We’ll assume both ends are SQL-flavoured relational databases, but will address other datastores later, e.g. ElasticSearch.</p>
<h2 id="iteration-1-check-in-batches">Iteration 1: Check in Batches</h2>
<p>As usual, we will start by considering the simplest possible solution for checking whether two databases are in sync: a script that iterates through all records in batches to check if they’re the same. It’ll execute the SQL query below in a loop, iterating through the whole collection on both sides and report mismatches:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>@</span><span>limit</span> <span>OFFSET</span> <span>@</span><span>offset</span>
</code></pre></div><p>Let’s try to figure out how long this would take: Let’s assume each loop is querying the two databases in parallel and our batches are 10,000 records (10 MiB total) large:</p>
<ul>
<li>In MySQL, reading 10 MiB off SSD at <a href="https://github.com/sirupsen/napkin-math#numbers">200 us/MiB</a> will take ~2ms. We assume   this to be sequential-ish, <a href="http://yoshinorimatsunobu.blogspot.com/2013/10/making-full-table-scan-10x-faster-in.html">but this is not entirely true</a>.</li>
<li>Serializing and deserializing the MySQL protocol at <a href="https://github.com/sirupsen/napkin-math#numbers">5 ms/MiB</a>, for a total   of ~2* 50ms = 100ms.</li>
<li>Network transfer at <a href="https://github.com/sirupsen/napkin-math#numbers">10 ms/MiB</a>, for a total of ~100ms.</li>
</ul>
<p>We’d then expect each batch to take roughly ~200ms.  This would bring our theoretical grand total for this approach to <code>200 ms/batch * (100M / 10_000) batches ~= 30min</code>.</p>
<p>To test our hypothesis against reality, I implemented this to <a href="https://github.com/sirupsen/napkin-math/blob/master/newsletter/14-syncing/check.rb">run locally for the first 100 of the 10,000 batches</a>. In this local implementation, we won’t incur the network transfer overhead (we could’ve done this with <a href="https://github.com/shopify/toxiproxy">Toxiproxy</a>). Without the network overhead, we expect a query time in the 100ms ballpark. Running <a href="https://github.com/sirupsen/napkin-math/blob/master/newsletter/14-syncing/check.rb">the script</a>, I get the following plot:</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/dfef5830-f658-4268-b655-ec23e64ce90c.png" alt=""></p>
<p>Ugh. The real performance is pretty far from our napkin math lower bound estimate. What’s going on here?</p>
<p>There’s a fundamental problem with our napkin math. Only the <em>very</em> first batch will read only <code>~10 MB</code> off of the SSD in MySQL. <code>OFFSET</code> queries will read through the data <em>before</em> the offset, even if it only returns the data after the offset! Each batch takes 3-5ms more than the last, which lines up well with reading another 10 MiB per batch from the increasing offset.</p>
<p>This is the reason why OFFSET-based pagination causes so much trouble in production systems. If we take the area under the graph here and extend to the 10,000 batches we’d need for our 100M records, we get a <strong>~3 day runtime</strong>.</p>
<h2 id="iteration-2-outsmarting-the-optimizer">Iteration 2: Outsmarting the optimizer</h2>
<p>As <code>OFFSET</code> will scan through all these 1 KiB records, what if we scanned an index instead? It’ll be much smaller to skip 100,000s of records on an index where each record only occupies perhaps 64 bit. It’ll still grow linearly with the offset, but passing the previous batch’s 10,000 records is only 10 KiB which would only take a few hundred microseconds to read.</p>
<p>You’d think the optimizer would make this optimization itself, but it doesn’t. So we have to do it ourselves:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>WHERE</span> id <span>&gt;</span> (<span>SELECT</span> id <span>FROM</span> <span>table</span> <span>LIMIT</span> <span>1</span> <span>OFFSET</span> <span>@</span><span>offset</span>)
<span>ORDER</span> <span>BY</span> id <span>ASC</span> 
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/47a71e04-2c3d-48e6-a7de-c2240d1ac26f.png" alt=""></p>
<p>It’s better, but just not by enough. It just delays the inevitable scanning of lots of data to find these limits. If we interpolate how long this’d take for 10,000 batches to process our 100M records, we’re still talking on the <strong>order of 14 hours</strong>. The 128x speedup doesn’t carry through, because it only applies to the MySQL part. Network transfer is still a large portion of the total time!</p>
<p>Either way, if you have some OFFSET queries lying around in your codebase, you might want to consider this optimization.</p>
<h2 id="iteration-3-parallelization">Iteration 3: Parallelization</h2>
<p>This seems like an embarrassingly parallel problem: Can’t we just run 100 batches of 10,000 records in parallel? Can the database support that? Since we can pre-compute <em>all</em> the LIMITs and OFFSETs up front, let’s abuse that?</p>
<p>This seems kind of difficult to do the napkin math on. Typically when that’s the case, I try to solve the problem backwards: Fundamentally, the machine can <a href="https://github.com/sirupsen/napkin-math#numbers">read sequential SSD at 4 GiB/s</a>, which would be an absolute lower bound for how fast the database can work. The dataset is 100 GiB, as we established in the beginning.</p>
<p>If we’re using our optimization from iteration 2, then our queries are on average processing <code>50M * 64 bit</code> for the sub-query, and the <code>10 MiB</code> of returned data on top. That’s a total of ~400 MiB. So for our 10,000 batches, that’s 4.2 TB of data we will need to munch through with this query. We can read 1 GiB from SSD in 200ms, so that’s 14 minutes in total. That would be the <em>absolute</em> lowest bound, assuming essentially zero overhead from MySQL and not taking into consideration serialization, network, etc.</p>
<p>This also assumes the MySQL instance is doing <em>nothing</em> but serving our query, which is unrealistic. In reality, we’d dedicate <em>maybe</em> 10% of capacity to these queries, which puts us at 2 hours. Still faster, but a far cry from our hope of seconds or minutes. Buuh.</p>
<h2 id="iteration-4-dropping-offset">Iteration 4: Dropping OFFSET</h2>
<p>It’s starting to seem like trouble to use these OFFSET queries, even as sub-queries. We held on to it for a while, because it’s nice and easy to reason about, and means the queries can be fired off in parallel. We also held on to it for a while to truly show how awful these types of queries are, so hopefully you think twice about using it in a production query again!</p>
<p>If we change our approach to maintain <code>max(id)</code> from the last batch, we can simply change our loop’s query to:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>`</span><span>table</span><span>`</span>
<span>WHERE</span> id <span>&gt;</span> <span>@</span>max_id_from_last_batch
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p>This curbed the linear growth!</p>
<p><img src="https://buttondown.s3.us-west-2.amazonaws.com/images/6b0263d5-c59f-4127-a573-6b06d615c195.png" alt=""></p>
<p>Now MySQL can use its efficient primary key index to do <a href="https://www.wolframalpha.com/input/?i=log%28100*10%5E6%29%2Flog%281024%2F3*2%2F%288%2B4%29%29+%2B+1++*https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F8.0%2Fen%2Festimating-performance.html*">~6 SSD seeks</a> on <code>id</code> and then scan forward. This means we only process and serialize 10 MiB, putting our napkin math consistently around 100ms per batch as in the original estimate in iteration 1. That means this solution should <strong>finish in about half an hour!</strong> However, we learned in the previous iteration that we are constrained by only taking 10% of the database’s capacity, so as calculated from iteration 3, we’re back at 2 hours..</p>
<p>We fundamentally need an approach that handles less data, as the serialization and network time is the primary reason why the integrity checking is now slow.</p>
<h2 id="iteration-5-checksumming">Iteration 5: Checksumming</h2>
<p>If we want to handle less data, we need to have some way to fingerprint or checksum each record. We could change our query to something along the lines of:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> MD5(<span>*</span>) <span>FROM</span> <span>table</span>
<span>WHERE</span> id <span>&gt;</span> <span>@</span>max_id_from_last_batch
<span>ORDER</span> <span>BY</span> id <span>ASC</span>
<span>LIMIT</span> <span>10000</span>;
</code></pre></div><p>If there’s a mismatch, we simply revert to iteration 4 and find the rows that mismatch, but we have to scan far less data as we can assume the majority of it lines up.</p>
<p>Before moving on, let’s see whether the napkin math works out:</p>
<ul>
<li>Reading 10 MiB off SSD at <a href="https://github.com/sirupsen/napkin-math#numbers">200 us/MiB</a> will take ~2ms.</li>
<li>Has…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/">https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/</a></em></p>]]>
            </description>
            <link>https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620761</guid>
            <pubDate>Sun, 03 Jan 2021 09:45:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving the 1973 Unix text to voice translator]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25620635">thread link</a>) | @ingve
<br/>
January 3, 2021 | https://www.spinellis.gr/blog/20210102/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20210102/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>The early Research Edition Unix versions featured a program that would turn a stream of ASCII text into utterances that could be played by a voice synthesizer. The source code of this program was lost for years. Here's the story of how I brought it back to life.</p>
<h3 id="finding-the-lost-code">Finding the lost code</h3>
<p>The (early 1973) Third Research Edition of Unix <a href="https://dspinellis.github.io/unix-v3man/v3man.pdf#page=130">documented</a> a program that would receive as input ASCII text and convert it into phonemes that could then be played by a <a href="https://en.wikipedia.org/wiki/Votrax">Votrax</a> voice synthesizer made by the Vocal Interface Division of Federal Screw Works. The program was written by <a href="https://en.wikipedia.org/wiki/Douglas_McIlroy">M. D. McIlroy</a>, who documented its operation in a detailed <a href="https://www.cs.dartmouth.edu/~doug/speak.tar">technical report</a>.</p>
<p>Although the program appeared in the Unix manual pages up to the 1975 <a href="https://ia800600.us.archive.org/19/items/v6-manual/v6-manual.pdf#page=251">Sixth Research Edition</a>, its source code was missing from the archives that had survived. Even its author lacked a copy.</p>
<p>Fortunately, in 2011, Jonathan Gevaryahu <a href="https://web.archive.org/web/20140620170452/https://minnie.tuhs.org/pipermail/tuhs/2011-December/002538.html">found</a> most parts of the program's source code in unallocated space of a Sixth Research Edition disk dump. (This means that the code was once stored on disk, but was later deleted, and the parts where it resided were never allocated to other uses.) Even better, he could reconstruct a single block that was missing from the program's compiled version, which was also available. Based on these findings, I added the <a href="https://github.com/dspinellis/unix-history-repo/blob/Research-V6-Snapshot-Development/usr/source/s2/speak.c">speak source code</a> and the <a href="https://github.com/dspinellis/unix-history-repo/blob/Research-V6-Snapshot-Development/usr/source/s2/speak.v">speech rules</a> to the <a href="https://github.com/dspinellis/unix-history-repo">GiHub repository of Unix history</a> I am maintaining.</p>
<h3 id="reviving-the-code">Reviving the code</h3>
<p>To see how the program was working, I experimented with making it run and compile. As the program was written in an ancient dialect of C and was also unlikely to be portable, I first tried to make it work on a Sixth Edition Unix running on a <a href="https://en.wikipedia.org/wiki/SIMH">SIMH</a> PDP-11 emulator. This attempt quickly failed, because the console wasn't reliable enough to allow me to transfer the code via copy-paste.</p>
<p>I then run the PDP-11 2.11 BSD Unix on the same emulator, which offers rudimentary internet connection capabilities. After configuring a <code>.rhosts</code> file to allow remote copying (to obtain remote access, you simply add your remote host and user name), I was able to move the code to that machine.</p>
<p>However, compiling the code wasn't immediately possible. To make it compile I</p>
<ul>
<li>changed the old <code>=+</code>, <code>=^</code> to the modern <code>+=</code>, <code>^=</code> operators,</li>
<li>added forward declarations for functions returning pointers,</li>
<li>inserted an assignment operator in initialized constants (<code>int tflag 0;</code> became <code>int tflag = 0;</code> — I didn't even know this form ever existed),</li>
<li>changed calls from <code>seek</code> to <code>lseek</code>, and</li>
<li>added a proper exit code to <code>exit</code>.</li>
</ul>
<p>At that stage the program could compile, but was crashing when I tried to run it. Given that 2.11 BSD lacked <em>gdb</em> and was generally slow and difficult to use, I decided to port the program to modern Unix/Linux. I also added more declarations, including full function prototypes to find other problems. (In early versions of C you didn't need to declare a function before using it.) I then methodically removed all compiler warnings, which allowed me to pinpoint a variable that was declared as a pointer but used as an integer. By correcting its declaration I fixed the initial crash.</p>
<p>Now I had a program that compiled and run, but was still crashing in some cases, and also wasn't producing correct output. For this further changes were needed.</p>
<ul>
<li>I replaced writing to a string with a write to a <code>char</code> array.</li>
<li>I corrected the size of a structure that was assumed to be 4.</li>
<li>I documented some functions to be able to follow the program logic.</li>
<li>I fixed the assumption that integers occupied two bytes.</li>
<li>I replaced integers initialized as pairs of characters (e.g. <code>'u1'</code>) with a macro that initialized the value in an endian-neutral manner.</li>
</ul>
<p>After these changes the program was able to compile the rules file and produce <a href="https://www.tuhs.org/Archive/Distributions/Research/Dennis_v5/v5man.pdf#page=285">Votrax phoneme codes</a>.</p>
<h3 id="getting-voice-output">Getting voice output</h3>
<p>Votrax voice synthesizers and their descendant chips (which appear to use similar phoneme codes) <a href="http://www.redcedar.com/sc01.htm">are not longer marketed</a>. In order to listen to the generated voice I needed a workaround. My first attempt was to use samples from the <a href="https://github.com/sealj553/votrax-speak">votrax-speak GitHub repository</a>. Converting the phoneme Votrax codes into their mnemonic names, and passing the corresponding sample files as arguments to <a href="https://en.wikipedia.org/wiki/SoX">SoX</a>, allowed me to create a sound file consisting of the phonemes played together. However, the generated sound file was almost unintelligible. As I read later, a great advantage of Votrax synthesizers was how they merged together the phonemes into continuous speech, which was not the case with my approach.</p>
<p>My second attempt involved using the phoneme output functionality of the <a href="https://github.com/espeak-ng/espeak-ng">espeak-ng</a> program. For this I created <a href="https://github.com/dspinellis/speak/blob/master/votrax-espeak.md">a map</a> between the Votrax phoneme codes and the corresponding <a href="http://espeak.sourceforge.net/phonemes.html">espeak phonemes</a>, which I then coded into a <em>sed</em> script that would feed <em>espeak</em> with the output of Unix <em>speak</em>. Through this method I was finally able to produce somewhat intelligible speech with a pipeline, such as the following.</p>
<div><pre><code><span>echo</span> Hello world <span>|</span>
<span>speak</span> speak.m <span>|</span>
<span>LC_ALL=</span>C <span>./votrax-espeak.sed</span> <span>|</span>
<span>espeak</span></code></pre></div>
<h3 id="code-availability">Code availability</h3>
<p>The revived source code is available in <a href="https://github.com/dspinellis/speak">this GiHub repository</a>.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20210102#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20210102/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620635</guid>
            <pubDate>Sun, 03 Jan 2021 09:12:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LoggedFS – Filesystem Monitoring with FUSE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620613">thread link</a>) | @pabs3
<br/>
January 3, 2021 | https://rflament.github.io/loggedfs/ | <a href="https://web.archive.org/web/*/https://rflament.github.io/loggedfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<h2>
  
  Donation</h2>

  <p>Donate Ethereum: 0x83FBC94FBca4e2f10Bede63e16C5b0Bb31a1Fed1 </p>
  <h2>
Description</h2>

<p>LoggedFS is a fuse-based filesystem which can log every operations that happens in it. </p>

<p>How does it work ?</p>

<p>Fuse does almost everything. LoggedFS only sends a message to syslog when called by fuse and then let the real filesystem do the rest of the job.</p>

<h2>
Installation</h2>

<p>If loggedfs is included in your distribution you can just install with your package manager.</p>

<h2>
Installation from source</h2>

<p>First you have to make sure that fuse is installed on your computer. 
If you have a recent distribution it should be. Fuse can be downloaded here : <a href="https://github.com/libfuse/libfuse">https://github.com/libfuse/libfuse</a>.
Then you should download the loggedfs archive and install it with the make command :</p>

<pre><code>
wget https://github.com/rflament/loggedfs/archive/loggedfs-0.9.tar.gz
tar xfz loggedfs-0.9.tar.gz
cd loggedfs-loggedfs-0.9
make
make install
</code></pre>

<p>LoggedFS has the following dependencies :</p>

<pre><code>fuse
pcre
libxml2
</code></pre>

<h2>
Configuration</h2>

<p>LoggedFS can use an XML configuration file if you want it to log operations only for certain files, for certain users, or for certain operations.</p>

<p>Here is a sample configuration file :</p>

<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;loggedFS logEnabled="true" printProcessName="true"&gt;
  &lt;includes&gt;
    &lt;include extension=".*" uid="*" action=".*" retname=".*"/&gt;
  &lt;/includes&gt;
  &lt;excludes&gt;
    &lt;exclude extension=".*\.bak$" uid="*" action=".*" retname="SUCCESS"/&gt;
    &lt;exclude extension=".*" uid="1000" action=".*" retname="FAILURE"/&gt;
    &lt;exclude extension=".*" uid="*" action="getattr" retname=".*"/&gt;
  &lt;/excludes&gt;
&lt;/loggedFS&gt;
</code></pre>

<p>This configuration can be used to log everything except it if concerns a *.bak file, or if the uid is 1000, or if the operation is getattr.</p>

<h2>
Launching LoggedFS</h2>

<p>If you just want to test LoggedFS you don't need any configuration file.</p>

<p>Just use that command :</p>

<pre><code>loggedfs -f -p /var
</code></pre>

<p>You should see logs like these :</p>

<pre><code>tail -f /var/log/syslog
17:29:34 (src/loggedfs.cpp:552) LoggedFS running as a public filesystem
17:29:34 (src/loggedfs.cpp:547) LoggedFS not running as a daemon
17:29:34 (src/loggedfs.cpp:666) LoggedFS starting at /var.
17:29:34 (src/loggedfs.cpp:691) chdir to /var
17:29:35 (src/loggedfs.cpp:136) getattr /var/ {SUCCESS} [ pid = 8700 kded [kdeinit] uid = 1000 ]
17:29:41 (src/loggedfs.cpp:136) getattr /var/ {SUCCESS} [ pid = 10923 ls uid = 1000 ]
17:29:41 (src/loggedfs.cpp:136) getattr /var/run {SUCCESS} [ pid = 10923 ls uid = 1000 ]
17:29:41 (src/loggedfs.cpp:136) getattr /var/run/nscd {FAILURE} [ pid = 10923 ls uid = 1000 ]
17:29:41 (src/loggedfs.cpp:136) readdir /var/ {SUCCESS} [ pid = 10923 ls uid = 1000 ]
17:29:41 (src/loggedfs.cpp:136) getattr /var/pouak {SUCCESS} [ pid = 10923 ls uid = 1000 ]
</code></pre>

<p>If you have a configuration file to use you should use this command :</p>

<pre><code>./loggedfs -c loggedfs.xml -p /var
</code></pre>

<p>If you want to log what other users do on your filesystem, you should use the -p option to allow them to see your mounted files. For a complete documentation see the manual page</p>

<p>Rémi Flament - remipouak at gmail.com</p>

      

    </section></div>]]>
            </description>
            <link>https://rflament.github.io/loggedfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620613</guid>
            <pubDate>Sun, 03 Jan 2021 09:07:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lock It In]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620612">thread link</a>) | @imartin2k
<br/>
January 3, 2021 | https://blairbellecurve.com/lock-it-in/ | <a href="https://web.archive.org/web/*/https://blairbellecurve.com/lock-it-in/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">

			 <!-- end header -->
			
			<div id="content">

				<div id="inner-content">

					

					<div id="main" role="main">

						<div>

							
								<article id="post-3398" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

									<!-- <div class="header-ad">
									</div>  -->

									<header>


										

										

									</header> <!-- end article header -->

									<section itemprop="articleBody">
										<div>
<p>I might take a lot of heat for writing this, but I’m going to write it anyway. If you’ve made life changing money in one or more of the high flying stocks this year, it’s time to lock in some gains.</p>
<p>When I read about investors making <a href="https://www.wsj.com/articles/investors-double-down-on-stocks-pushing-margin-debt-to-record-11609077600">millions on Tesla</a> in the Wall Street Journal, I get nervous. I am also insanely happy for their good fortune. There is no greater luck than winning the lottery. It is not supposed to be this easy to make money in the stock market. Preserve and grow capital yes, but outright make a fortune? No. Money made this easily can be lost in the blink of an eye.</p>
<p>Morgan Housel wrote this in his best selling book, <a href="https://amzn.to/3o0Aevd"><em>The Psychology of Money</em></a>:</p>
<blockquote><p>There are a million ways to get wealthy, and plenty of books on how to do so.</p>
<p>But there’s only one way to stay wealthy: some combination of frugality and paranoia.</p>
<p>And that’s a topic we don’t discuss enough.</p></blockquote>
<p>Morgan goes on to describe how Jesse Livermore, known as the greatest trader on Earth in the early 20th century, made and lost several billion dollar fortunes in his lifetime. He never locked in his gains, never diversified, never took money off the gambling table. Although he was once the wealthiest man in the world, Livermore eventually took his own life. He died in debt, worthless.</p>
<p>Whatever you think you know, that the rest of the world doesn’t know, about Tesla, Etsy, Nvidia, Paypal, or any of the other winners this year, it doesn’t matter. You’ve made the kind of return most investors will only dream about. Take some money off the table. It doesn’t matter if the stock keeps going up from here. You can still participate with less of your money at risk.&nbsp; Lock it in. Secure the win.</p>
<p>You may be worried about the regret you will feel watching the stock go higher after you sell. Believe me, the pain of watching your gains disappear is worse. You don’t need to top tick this winner because you’ve already won. Don’t get greedy, get nervous. You can still participate in the upside by keeping a smaller position. There’s no need to bet the house.</p>
<p>Now, let’s talk about what comes next. Like an addict chasing that first high, you are going to be underwhelmed by all of your future investments. You will, most likely, never repeat the success you’ve had this year. Gambling is fun when you win. Investing is boring all the time. The good news is that you can keep the fun alive in a small trading account. The trick is to keep your trading account small enough that a complete loss won’t change your lifestyle and large enough to keep you entertained.</p>
<p>Congratulations, you have beat the odds and made a fortune trading stocks. My greatest wish for you is that you will have the humility to realize how lucky you are and lock in those gains.</p>


<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-pdf-button.png" alt="Print Friendly, PDF &amp; Email"></a></p></div>									</section> <!-- end article section -->

									 <!-- end article footer -->

									

									
									
									
									
								</article> <!-- end article -->

							
							
						</div>

					</div> <!-- end #main -->

									


				</div> <!-- end #inner-content -->

			</div> <!-- end #content -->

			 <!-- end footer -->

		</div></div>]]>
            </description>
            <link>https://blairbellecurve.com/lock-it-in/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620612</guid>
            <pubDate>Sun, 03 Jan 2021 09:07:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Quick intro to testing PHP code with PHPUnit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620522">thread link</a>) | @zooboole
<br/>
January 3, 2021 | https://lancecourse.com/howto/a-quick-intro-to-testing-php-code-with-phpunit | <a href="https://web.archive.org/web/*/https://lancecourse.com/howto/a-quick-intro-to-testing-php-code-with-phpunit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
						<p>If you started out writing one page, simple scripts in PHP like I did. You probably were not thinking about testing your code before you lumped it onto the server.</p>
<p>I mean, it worked right? You were probably pretty confident about it, as I was.</p>
<p>As you have progressed in your development journey and moved towards more complex structurings of your code, such as with frameworks and multiple folder systems, I’m sure the default level of confidence in your codebase, when untested, that you started with, has begun to go down a peg.</p>
<p>It sure did for me.</p>
<p>As I improved as a developer, I wanted my code to do the same, so I began to look for the ways that I could be sure that my code was ‘good code’ or at least, it behaved as I expect it to.</p>
<p>The most important and reliable way I found that this could be done was by testing it.</p>
<h2>Why Testing Code Is Important?</h2>
<p>As you develop your code, what you are doing is creating a complex structure. If you imagine that this structure is real, like a building for example. You would want to make sure that the integrity of the structure is good (ie. that there are no bugs) so that it would not surprise you at any point, such as by collapsing.</p>
<p>In the real-world building process, you ensure this by engaging in various checks, tests, and surveys of structural integrity, done throughout the building process. When coding, you test. Specifically, you <code>unit test</code>.</p>
<h3>What is ‘Unit Testing’?</h3>
<p>The word ‘unit’, within the context of code testing, refers to a block of code that will be tested.</p>
<p>Usually, this block is in the form of a class method, a function, or some other highly relevant, segmented block of code. Essentially it is a segment of code whose integrity and expected output we want to ensure.</p>
<p>As stated on the <a href="https://en.wikipedia.org/wiki/PHPUnit" target="_blank" rel="nofollow">PHPUnit Wikipedia</a>,</p>
<blockquote>
<p>The goal of unit testing is to isolate each part of the program and show that the individual parts are correct. A unit test provides a strict, written contract that the piece of code must satisfy. As a result, unit tests find problems early in the development cycle.</p>
</blockquote>
<h3>What Does ‘Testing Code’ Mean?</h3>
<p>Testing code in general is the process of identifying, breaking down, and then specifying the units of our code that we would like to test. We do this by outlining our expected outcome. And then once we’ve done that, running those units through tests, using testing software tools to see if our expected outcomes are what we get.</p>
<p>All programming languages, in their ecosystem, dispose of some kind of toolings used to unit test source codes. PHP is not of an exception. And we have tools like <strong>PHPUnit</strong>, <strong>Codeception</strong>, <strong>Behat</strong>, <strong>PHPSpec</strong>, <strong>Storyplayer</strong>, <strong>Peridot</strong>, and much more out there.</p>
<p>In this post, we will focus on how you can get started with PHPUnit.</p>
<h2>PHPUnit</h2>
<p>If you’ve been involved in the PHP community for some time now, you’ve most likely heard of PHPUnit. It’s not only one of the most popular unit testing frameworks in PHP but is also one of the easiest to use.</p>
<p>Testing our code with PHPUnit is simply a matter of placing and applying our units of code within tests. These units are tested by writing a unique ‘test cases’.</p>
<h3>How To Use PHPUnit - Step By Step</h3>
<p>The typical testing flow goes like this:</p>
<ul>
<li>Import the class method, function, or segment of code to test. The <code>unit</code> you want to test.</li>
<li>Give input to the function, method, or unit.</li>
<li>Define what to expect as the output of the unit.</li>
<li>Check if the function/method/unit produces the expected output.</li>
</ul>
<h3>Installing and using PHPUnit</h3>
<p>To get started testing with PHPUnit, we first need to start by installing it.
There are two ways of using PHPUnit.</p>
<p>1- As a local development-time dependency: Basically you will add PHPUnit with <a href="https://lancecourse.com/tutorials/back-end/composer-your-first-class/52">composer</a> as a development dependency. The advantage of using it that way is that you can easily migrate from one version to another, and you can use a different version for two distinct projects.</p>
<p>2- As an installed tool in your development machine. This allows you to have a globally installed tool that can be used throughout your machine regardless of the project.</p>
<p>You can refer to the official installation guide for more details on these two ways of installation. For the brevity of this post, we will focus only on the first method.</p>
<p>To do so, first, navigate to or create the folder within which our project will sit(<code>Example</code> in my case), and then we can download(add to our dependencies) PHPUnit with the following command:</p>
<pre><code>composer require --dev phpunit/phpunit</code></pre>
<h3>Creating Our Class (Which We Will Then Test)</h3>
<p>Once we’ve downloaded PHPUnit into our folder, we can now begin our testing process by first writing the class that we will be testing. Let’s create a simple ‘User’ class that sets a <code>$first_name</code> and a <code>$last_name</code> property. And then has a function that returns the combination of these two properties as a <code>full name</code>.</p>
<p>You can see an example of this below(<strong>User.php</strong>):</p>
<pre><code>&lt;?php

final class User
{

    public $first_name;
    public $last_name;

    public function getFullName(): string
    {
        return $this-&gt;first_name . " " . $this-&gt;last_name;
    }

}</code></pre>
<h3>Creating The Test Folder &amp; phpunit.xml</h3>
<p>Once we have set up our ‘User’ class, let us now set up our ‘tests’ folder, where we will hold our tests.</p>
<p>We will also create our <code>phpunit.xml</code> file at the root of our project. We will reference the folder where our tests are held inside that file. We do this by placing the name of the folder in the directory element within our XML file.</p>
<p>Here is a minimal content one could have on your phpunit.xml file:</p>
<pre><code>&lt;phpunit bootstrap="vendor/autoload.php" colors="true"&gt;
    &lt;testsuites&gt;
        &lt;testsuite name="IntroPHPUnitTest"&gt;
            &lt;directory&gt;tests&lt;/directory&gt;
        &lt;/testsuite&gt;
    &lt;/testsuites&gt;
&lt;/phpunit&gt;</code></pre>
<h3>Writing Our First Test</h3>
<p>Now that we have created our tests/ folder, we may now move onto creating our first test. In this, we will be simply checking if our <code>getFullName()</code> class method above returns a string of <code>$first_nam</code>e and <code>$last_name</code> as we expect.</p>
<p>Our test will look like this(<strong>UserTest.php</strong>):</p>
<pre><code>&lt;?php

declare(strict_types=1);

use PHPUnit\Framework\TestCase;

final class UserTest extends TestCase
{
    /* 
    Our first test method: testing if our 
    User class can return a full name 
     */
    public function testReturnsUserFullName()
    {

        // We need to bring in our User class
        // so that we can access its methods
        require_once './User.php';

        // Get an instance of the User class
        $user = new User;

        // Set the properties
        $user-&gt;first_name = 'Femy';
        $user-&gt;last_name = 'Babatunde';

        // Assert if the getFullName() can return the full name 'Femy Babatunde'
        $this-&gt;assertEquals('Femy Babatunde', $user-&gt;getFullName());
    }
}</code></pre>
<p>Here we are including the ‘TestCase’ class from PHPUnit, which gives us the functionality that we need to run the test.</p>
<p>Then we creating our test class <code>UserTest</code> which extends the <code>TestCase</code> class from PHPUnit.</p>
<p>Bear in mind that the name of the file and should ideally have the name of the class that we are testing, ending with the ‘Test’.</p>
<p>The name of the test class should also be the same as the name of the class being tested, but should also end with <code>Test</code> Such as the above specified <code>UserTest</code> class definition.</p>
<p>The name of the method that we use to wrap our actual unit test should be as much as possible, a description of the test that we are attempting to run. In the above case, it is <code>testReturnsUserFullName</code>, which is what our test checks for.</p>
<p>Inside this method, we then load in and instantiate our original class, our data, and then attempt to run our test using the <code>assertEquals($expected, $actual)</code> method from PHPUnit. The method checks if its two arguments match. That is to set the full name, using our <code>$first_name</code> and <code>$last_name</code> properties that we defined within our constructor.</p>
<p>Once we have set up our test assertion, we are now ready to run our test.</p>
<h3>Running Our First Test</h3>
<h4>Overview of our project</h4>
<p>Once we have created our test, it is now time for us to run it. But, before we move on to testing our setup, let's have a look at how our project looks like.</p>
<p><img src="https://phpocean.com/assets/images/forum-uploads/f1ae214da762d1d534a0daf83d053af7.png" alt="Project Structure"></p>
<p>PHPUnit's framework in actually inside a subfolder named <code>bin</code> located in the <code>vendor</code> folder.</p>
<p>If you installed PHPUnit using our second method of installation above, you may do this by simply running the command <code>phpunit</code> in our command line, while within the folder directory where we have installed PHPUnit. But, in our case, we used the first method to install PHPUnit as a project-level dependency. So, to run your test type the following command while being in the root folder, <code>Example</code>:</p>
<pre><code>.\vendor\bin\phpunit</code></pre>
<p>The expected output of the above test case within the command line should let you know that the test passed. This is how it looks like in my case:</p>
<p><img src="https://phpocean.com/assets/images/forum-uploads/aed65b79e698104d84e11a12a70a22af.png" alt="Test Result"></p>
<p>With a “Passed” statement and no “Failed” statements, this means that our tests have passed and that our assumption for the test (or test cases) is validated.</p>
<h2>Wrapping It All Up</h2>
<p>This is what testing in PHP using PHPUnit looks like. This example used here is a very basic use case. You push further with more complex code. Please, refer to the official PHPUnit website for more on the subject.</p>
<p>In other languages, the general idea is also the same. Ultimately, all tests of code follow the same structure that we’ve outlined above.</p>
<p>I hope that this tutorial has given you enough information to get you started with unit testing in PHP and unit testing in general.</p>
<p>If you have anything to add to this article, please let me know in the comments section.</p>
					</section></div>]]>
            </description>
            <link>https://lancecourse.com/howto/a-quick-intro-to-testing-php-code-with-phpunit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620522</guid>
            <pubDate>Sun, 03 Jan 2021 08:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Want other to talk? Be a listener]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620297">thread link</a>) | @docuru
<br/>
January 2, 2021 | https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener | <a href="https://web.archive.org/web/*/https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>Sometimes ago, I saw a manager complain about how hard it is to talk to his staffs. While there can be many reasons, but one I’ve seen more often. That’s the manager isn’t a listener, even though he/she is listening.</p><p>The different about listening and a listener is that, a listener had a reputation for listening</p><p>Let’s say a manager asked his staff to discus about work performance issue, try to understand and improve it. Though, the manager doesn’t feel the discussion was open enough.</p><p>In the past, the manager often don’t take his staff words serious, dismiss their ideas. Eventually, his staffs will assume him won’t take serious.</p><p>Often, when you often listen to people, you train them to talk. Otherwise, taking people words lightly, you accidentally train them to ignore.</p></div></div>]]>
            </description>
            <link>https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620297</guid>
            <pubDate>Sun, 03 Jan 2021 07:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Repl-Driven Programming]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 127 (<a href="https://news.ycombinator.com/item?id=25620256">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | http://mikelevins.github.io/posts/2020-12-18-repl-driven/ | <a href="https://web.archive.org/web/*/http://mikelevins.github.io/posts/2020-12-18-repl-driven/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			
			<div>

				<div>

					

					<p>Once upon a time, someone with the handle “entha_saava” posted this question on <a href="https://news.ycombinator.com/item?id=23791152">Hacker News</a>:</p>
<blockquote>
<p>Can someone knowledgeable explain how are lisp REPLs different from
Python / Ruby REPLs? What is the differentiating point of REPL
driven development?</p>
</blockquote>
<p>The answer is that there is a <a href="http://mikelevins.github.io/2020/02/03/programming-as-teaching.html">particular kind of programming</a>
in which you build a program by <em>interacting</em> with it as it runs, and
there are certain languages and runtimes that are designed from the
ground up to support that kind of programming.</p>
<p>Python and Ruby are not examples of such languages.</p>
<p>Why not? That’s the crux of entha_saava’s question, right? What are
these <strong>repl-driven</strong> programming systems, and what makes them
different from Python and Ruby and every other language that offers a
repl?</p>
<p>For that matter, what’s a repl?</p>
<p>The word <strong>repl</strong> is an acronym that stands for <strong>read-eval-print
loop</strong>. The term comes from the history of Lisp. From the start, sixty
years ago, the standard way of working with a Lisp has been to start a
language processor, type expressions at its prompt, and wait for it to
evaluate the expressions and print their results, before prompting for
another expression. Read, eval, print. Loop.</p>
<p>Nowadays, repls are all the rage. Every language and its brother
offers a repl. There’s a website, <a href="https://repl.it/">repl.it</a>, whose
entire purpose is to provide all the repls.</p>
<p>It doesn’t actually provide <em>all</em> the repls, of course. What’s
particularly ironic is that it doesn’t provide either of the canonical
repl-driven development environments: Common Lisp and Smalltalk.</p>
<p>That brings us back to entha_saava’s question: if Common Lisp and
Smalltalk are repl-driven environments, and Python and Ruby are not,
what’s the difference? What do Lisp and Smalltalk have that Python and
Ruby don’t?</p>
<p>What they have is a language and runtime system that are designed from
the ground up with the assumption that you’re going to develop
programs by starting the language engine and talking to it, teaching
it how to be your program <em>interactively</em>, by changing it <em>while it
runs</em>.</p>
<p>I can hear the objections formulating already. I’ve seen them
before. Yes, every language with a repl can do some things in the
repl. Obviously that’s true; if it weren’t, then the repl would be
entirely useless.</p>
<p>Being able to do <em>some</em> things in the repl does not make an engine
into a repl-driven programming environment. What distinguishes
old-fashioned Lisp and Smalltalk environments is that you can do
<em>everything</em> in the repl. They place no gratuitous limitations on what
you can do; if the language and runtime can do it, then the repl can
do it.</p>
<p>For example, you can ask the current version of Clozure Common Lisp to
rebuild itself from scratch by evaluating the following expression at
the repl prompt:</p>
<pre><code>(rebuild-ccl :full t)
</code></pre>
<p>CCL responds by completely rebuilding itself from source.</p>
<p>The point is not that you would want to rebuild CCL this way all the
time. The point is that there are no artificial limitations on what
the repl can do. The full range of the development system’s
capabilities is accessible from the repl.</p>
<p>That’s one of the first things I notice when using newer, lesser
repls: I’m always running into things I can’t do from the repl.</p>
<p>It’s not just about freedom from restrictions, though. Proper support
for interactive programming means that the language and its runtime
have positive features that support changing your program <em>while it
runs</em>.</p>
<p>Try this in your favorite repl:</p>
<p>Define a function, <code>foo</code>, that calls some other function, <code>bar</code>, that
is not yet defined. Now call <code>foo</code>. What happens?</p>
<p>Obviously, the call to <code>foo</code> breaks, because <code>bar</code> is not defined. But
what happens when it breaks? What happens next?</p>
<p>If your favorite repl is Python’s or Ruby’s or any of a few dozen
other modern repls, the answer is most likely that it prints an error
message and returns to its prompt. In some cases, perhaps it crashes.</p>
<p>So what’s my point, right? What else could it do?</p>
<p>The answer to that question is the “differentiating point” of
repl-driven programming. In an old-fashioned Lisp or Smalltalk
environment, the break in <code>foo</code> drops you into a <strong>breakloop</strong>.</p>
<p>A <strong>breakloop</strong> is a full-featured repl, complete with all of the
tools of the main repl, but it exists inside the dynamic environment
of the broken function. From the breakloop you can roam up and down
the suspended call stack, examining all variables that are lexically
visible from each stack frame. In fact, you can inspect all live data
in the running program.</p>
<p>What’s more, you can <em>edit</em> all live data in the program. If you think
that a break was caused by a wrong value in some particular variable
or field, you can interactively change it and resume the suspended
function. If it now works correctly, then congratulations; you found
the problem!</p>
<p>Moreover, because the entire language and development system are
available, unrestricted, in the repl, you can define the missing
function <code>bar</code>, resume <code>foo</code>, and get a sensible result.</p>
<p>In fact, there’s a style of programming, well known in Lisp and
Smalltalk circles, in which you define a toplevel function with calls
to other functions that don’t yet exist, and then define those
functions as you go in the resulting breakloops. It’s a fast way to
implement a procedure when you already know how it should work.</p>
<p>If you’re a user of old-fashioned Lisp or Smalltalk systems then this
all sounds obvious to you, but that reaction is not common. Surprise
is much more common, or even suspicion: what’s the catch?</p>
<p>The catch is that the designers of your language system had to think
that facility through in the planning stages. You don’t get a decent
implementation of it by bolting it on after the fact. Breakloops need
<em>full</em> access to the <em>entire</em> development system, interactively, with
a computation and its call stack suspended in the breakloop’s
environment.</p>
<p>Let’s take another example of a facility designed to support
interactive programming. Once again, try this in your favorite repl:</p>
<p>Define a datatype. I mean a class, a struct, a record type–whatever
user-defined type your favorite language supports. Make some instances
of it. Write some functions (or methods, or procedures, or whatever)
to operate on them.</p>
<p>Now change the definition of the type. What happens?</p>
<p>Does your language runtime notice that the definition of the type has
changed? Does it realize that the existing instances have a new
definition? When something touches one of them, does it automatically
reinitialize it to conform to the new definition, or, if it doesn’t
know how to do that, does it start a breakloop and ask you what to do
about it?</p>
<p>If the answer is “yes,” then you’re probably using a Lisp or Smalltalk
system. If the answer is “no,” then you’re missing a crucial element
of repl-driven development.</p>
<p>Remember: the point is to support programming <em>interactively</em>. You
don’t want to have to kill your program and rebuild it from scratch
just because you changed a definition. That’s silly; adding and
changing definitions is most of what you do! If your development
environment is going to support interactive development, then it had
better know how to keep your program running when you change some
definitions.</p>
<p>Old-fashioned Lisp and Smalltalk system know how to do that. There are
also a few other kinds of systems, mostly older ones, that know how to
do it.</p>
<p>These are not eccentric new ideas out of left field. They’ve been
around for half a century. They contribute materially to productivity
in interactive development.</p>
<p>They’re what sets <strong>repl-driven development</strong> apart from mere
development with a repl.</p>
<p>Now, not every programmer prefers that kind of development. Some
programmers prefer to think of development as a process of designing,
planning, making blueprints, and assembling parts on a
workbench. There’s nothing wrong with that. Indeed, a
multibillion-dollar international industry has been built upon it.</p>
<p>But if you prefer interactive development, if it’s more natural to
you, then it can make you enormously more productive, not to mention
happier in your work.</p>
<p>Interactive development with a proper repl-driven environment is the
exception. Most programming is done in other ways.</p>
<p>As a consequence, there are a lot of programmers out there who’ve
never even heard of it, who have no idea that it exists. My intuition
is that some fraction of those programmers would prefer well-supported
interactive programming, and would benefit from it, if they just knew
what it was.</p>
<p>Maybe if enough programmers are exposed to that style of programming
then we’ll begin to see new tools that embrace it.</p>


				</div>

			</div>
			
		</div>
	</div></div>]]>
            </description>
            <link>http://mikelevins.github.io/posts/2020-12-18-repl-driven/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620256</guid>
            <pubDate>Sun, 03 Jan 2021 07:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Superhuman is Sublime Text for Email]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25620176">thread link</a>) | @mastermojo
<br/>
January 2, 2021 | http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/ | <a href="https://web.archive.org/web/*/http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        




<article>
  <!-- date:       2021-02-01 -->
<!-- Why does the date cause the post to not render? -->

<center>
<small>
Note: The author has never paid for, is not affiliated with, and is not endorsing Superhuman as a product.
</small>
</center>

<h3 id="superhuman">Superhuman</h3>

<p>Superhuman is an invite-only $30/month email client.<sup id="fnref:pricing" role="doc-noteref"><a href="#fn:pricing">1</a></sup> People like it for its sleek design, responsive speed, and suite of keyboard shortcuts to improve a user’s email efficiency. People justify this purchase over free alternatives by the fact that they spend hours on email everyday. Part of Superhuman’s feature offering includes read statuses, which is useful for executives and sales people who like to keep a pulse on their conversations.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/superhuman.png" alt="Superhuman Product Screenshot"></p>

<p>Users love Superhuman. Take a quick peak on Twitter<sup id="fnref:twitter" role="doc-noteref"><a href="#fn:twitter">2</a></sup> at the effusive praise the company gets. Andreessen Horowitz led the latest investment round in the company with a valuation of roughly $260 million.</p>

<p>Following in the tailwind of this prosumer email client that has taken Silicon Valley and Twitter by storm are a suite of companies claiming to be “Superhuman for x”.<sup id="fnref:superhumanofx" role="doc-noteref"><a href="#fn:superhumanofx">3</a></sup></p>

<p>As identified by Todd Goldberg, the “Superhuman of X” has the following traits:</p>
<ul>
  <li>Designed for speed.</li>
  <li>Built as an opinionated product experience for a specific use case and/or target audience.</li>
  <li>Driven primarily by keyboard shortcuts.</li>
  <li>Beautiful and thoughtfully designed.</li>
  <li><em>Optional</em>: Built as a modern alternative to a product that has legacy distribution effects</li>
  <li><em>Optional</em>: Positioned as a premium product vs. free alternatives.</li>
</ul>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/commands_superhuman.png" alt="Superhuman Commands Screenshot"><br>
<small>
  Superhuman Command bar: short-cut triggered command search bar
</small></p>

<hr>

<center>
<small>
Note: The author has never paid for, is not affiliated with, but likes using Sublime Text as a product.
</small>
</center>

<h3 id="sublime-text">Sublime Text</h3>

<p>I present Sublime Text: a piece of software more than a decade older than Superhuman, that shares the above attributes. Sublime can be driven primarily by keyboard shortcuts. It’s as thoughtfully designed as I have been shamefully unwilling to purchase the non-trial version for 80 USD. The similarities lie much deeper than that. Sublime has two close-to-instant-speed search-bars: one for opening a file in your project [goto] and one for executing commands.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/commands_sublime.png" alt="Sublime Commands Screenshot"><br>
<small>
  Sublime Text Command Palette: short-cut triggered command search bar
</small><br></p>

<p>Sublime Text is also simultaneously opinionated but also configurable. It is simple enough for a programmer to install, open, and “hit the ground running” on a big project with a combination of GOTO (⌘+P) and project search (⌘+Shift+F).</p>

<hr>

<h3 id="the-sublime-text-of-x">The “Sublime Text of X”</h3>

<p>Without futhur ado, I present a case study sampling of “Sublime Texts of X”.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/sublime.png" alt="Sublime Text Screenshot"><br>
<small>The (Eponymous) Sublime Text of Text Editors: <a href="https://www.sublimetext.com/">https://www.sublimetext.com/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/fman.png" alt="Fman Product Screenshot"><br>
<small>The Sublime Text of Finder/File Explorer: <a href="https://fman.io/">https://fman.io/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/linear.png" alt="Linear Product Screenshot"><br>
<small>The Sublime Text of Task/Bug Tracking: <a href="https://linear.app/">https://linear.app/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/cron.png" alt="Cron Product Screenshot"><br>
<small>The Sublime Text of Calendars: <a href="https://cron.app/">https://cron.app/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/merge.png" alt="Sublime Merge Product Screenshot"><br>
<small>The Sublime Text of Git GUI Clients: <a href="https://www.sublimemerge.com/">https://www.sublimemerge.com/</a>
</small></p>

<p>The “Sublime Text of X” is software having the following traits:</p>
<ul>
  <li>Designed for speed.</li>
  <li>Built as an opinionated product experience for a specific use case and/or target audience.</li>
  <li>Driven primarily by keyboard shortcuts.</li>
  <li>Beautiful and thoughtfully designed.</li>
  <li><span><em>Not Optional</em>: &nbsp;Dark mode&nbsp;</span></li>
</ul>

<p>I look forward to a <del>bright</del> dark future where everything can be done fast and efficiently through keyboard shortcuts. If there are other startups or products that give you Sublime Text vibes I would love to know!</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/terminal.png" alt="Terminal Product Screenshot"><br></p>

<hr>



</article>





<br>
<hr>






      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620176</guid>
            <pubDate>Sun, 03 Jan 2021 07:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ordered Key-Value Stores]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25620137">thread link</a>) | @timhigins
<br/>
January 2, 2021 | https://hyper.dev/ordered-key-value-stores.html | <a href="https://web.archive.org/web/*/https://hyper.dev/ordered-key-value-stores.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hyper.dev/ordered-key-value-stores.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620137</guid>
            <pubDate>Sun, 03 Jan 2021 07:06:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Design Patterns as a Book]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25620110">thread link</a>) | @WnZ39p0Dgydaz1
<br/>
January 2, 2021 | https://rust-unofficial.github.io/patterns/ | <a href="https://web.archive.org/web/*/https://rust-unofficial.github.io/patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<h2><a href="#participation" id="participation">Participation</a></h2>
<p>If you are interested in contributing to the Patterns catalogue, check out the <a href="https://rust-unofficial.github.io/patterns/CONTRIBUTING.html">contribution guidelines</a>.</p>
<h2><a href="#design-patterns" id="design-patterns">Design patterns</a></h2>
<p>When developing programs, we have to solve many problems. A program can be viewed as a solution to a problem. It can also be viewed as a collection of solutions to many different problems. All of these solutions work together to solve a bigger problem.</p>
<h2><a href="#design-patterns-in-rust" id="design-patterns-in-rust">Design patterns in Rust</a></h2>
<p>There are many problems that share the same form. Due to the fact that Rust is not object-oriented design patterns vary with respect to other object-oriented programming languages. While the details are different, since they have the same form they can be solved using the same fundamental methods.</p>
<p><a href="https://rust-unofficial.github.io/patterns/patterns/index.html">Design patterns</a> are methods to solve common problems when writing software.</p>
<p><a href="https://rust-unofficial.github.io/patterns/anti_patterns/index.html">Anti-patterns</a> are methods to solve these same common problems.</p>
<p>However, while design patterns give us benefits, anti-patterns create more problems.</p>
<p><a href="https://rust-unofficial.github.io/patterns/idioms/index.html">Idioms</a> are guidelines to follow when coding. They are social norms of the community.
You can break them, but if you do you should have a good reason for it.</p>
<p>TODO: Mention why Rust is a bit special - functional elements, type system, borrow checker</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://rust-unofficial.github.io/patterns/CONTRIBUTING.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://rust-unofficial.github.io/patterns/CONTRIBUTING.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://rust-unofficial.github.io/patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620110</guid>
            <pubDate>Sun, 03 Jan 2021 06:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Envelope Budgeting with Prudent (and Ledger)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619916">thread link</a>) | @vitoc
<br/>
January 2, 2021 | https://docs.prudent.me/docs/addons/envelope | <a href="https://web.archive.org/web/*/https://docs.prudent.me/docs/addons/envelope">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><p>Envelope is an analytics extension that provides contextual visualization of your expenses vs your budget.</p>
<h2>Defining a budget</h2>
<p>Here's an example monthly budget of $800 for groceries and $320 for petrol.</p>
<pre><code>~ Monthly
    Expenses:Groceries  $<span>800</span>
    Expenses:Petrol  $<span>320</span>
    Assets
</code></pre>
<h2>Expense transactions</h2>
<p>Here's a bunch of example expense transactions that leads to the first 3 charts in the Detailed View section of this document:</p>
<pre><code><span>2021</span>/<span>01</span>/<span>03</span>
  Assets:Savings  -$<span>110</span>
  Expenses:Groceries  
  
<span>2021</span>/<span>01</span>/<span>10</span>
  Assets:Savings  -$<span>125</span>
  Expenses:Groceries    
  
<span>2021</span>/<span>01</span>/<span>17</span>
  Assets:Savings  -$<span>180</span>
  Expenses:Groceries      
  
<span>2021</span>/<span>01</span>/<span>24</span>
  Assets:Savings  -$<span>160</span>
  Expenses:Groceries
  
<span>2021</span>/<span>01</span>/<span>31</span>
  Assets:Savings  -$<span>75</span>
  Expenses:Groceries  

<span>2021</span>/<span>01</span>/<span>03</span>
  Assets:Savings  -$<span>90</span>
  Expenses:Petrol  
  
<span>2021</span>/<span>01</span>/<span>10</span>
  Assets:Savings  -$<span>85</span>
  Expenses:Petrol    
  
<span>2021</span>/<span>01</span>/<span>17</span>
  Assets:Savings  -$<span>80</span>
  Expenses:Petrol      
  
<span>2021</span>/<span>01</span>/<span>24</span>
  Assets:Savings  -$<span>95</span>
  Expenses:Petrol
  
<span>2021</span>/<span>01</span>/<span>31</span>
  Assets:Savings  -$<span>75</span>
  Expenses:Petrol  
</code></pre>
<h2>Detailed view</h2>
<p>There are four charts in the Expenses vs Envelope budgeting detailed view.</p>
<p>The first one shows you the percentage of expenses for the particular month:</p>
<div><p><img src="https://docs.prudent.me/img/ExpensesDistribution.PNG"></p></div>
<p>The second chart shows the sub-total of each expense: <br></p>
<div><p><img src="https://docs.prudent.me/img/ExpensesSubtotal.PNG"></p></div>
<p>The third chart shows the amount that is left in each envelop (budget) that you'd defined:</p>
<div><p><img src="https://docs.prudent.me/img/Envelope.PNG"></p></div>
<p>The above chart is based on the budget we defined in the example earlier. The budget we set for groceries was $800 and $770 was spent for groceries within the month, giving a balance in the envelope of $30 in the Groceries envelope. Petrol expenses exceeded the budget by $105 and is marked in red because of that.</p>
<p>The last chart shows the expense transactions that had occured for the month:</p>
<div><p><img src="https://docs.prudent.me/img/MonthlyExpenses.PNG"></p></div>
<p>This chart is useful when setting budget, when viewed on a Year time scope (click on the Year button near the top-right):</p>
<div><p><img src="https://docs.prudent.me/img/YearToDateExpenses.PNG"></p></div>
<p>In the above chart, we see that expenses hovers around $700 for groceries and $480 for petrol. We can set our budget based on the average that we see here or any other trend (down or up) that the chart might show.</p>
<h2>Additional transaction examples</h2>
<p>The last expenses chart above can be reproduced with these additional transactions (on top of the other transactions shown above):</p>
<pre><code><span>2021</span>/<span>02</span>/<span>10</span>
  Assets:Savings  -$<span>700</span>
  Expenses:Groceries     
  
<span>2021</span>/<span>02</span>/<span>10</span>
  Assets:Savings  -$<span>380</span>
  Expenses:Petrol      
  
<span>2021</span>/<span>03</span>/<span>10</span>
  Assets:Savings  -$<span>850</span>
  Expenses:Groceries     
  
<span>2021</span>/<span>03</span>/<span>10</span>
  Assets:Savings  -$<span>350</span>
  Expenses:Petrol        
</code></pre>
<h2>Sample journal</h2>
<p>The detailed charts above can be reproduced in your Prudent client locally with this <a href="https://docs.prudent.me/samples/Budget.journal">sample journal</a>.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://docs.prudent.me/docs/addons/envelope</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619916</guid>
            <pubDate>Sun, 03 Jan 2021 06:10:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design flaws of password managers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25619451">thread link</a>) | @_wldu
<br/>
January 2, 2021 | https://www.go350.com/posts/the-design-flaws-of-password-managers/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/the-design-flaws-of-password-managers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I once worked in highly regulated environments and needed a way to recall dozens of complex passwords that changed frequently. I tried to use a password manager, but could not due to the burdens and insecurity of some common design flaws. I wrote a Deterministic Password Generator <a href="https://github.com/62726164/dpg">DPG</a> to address this.</p><p>If after reading this you still wish to use a traditional password manager, I suggest that you put your passwords into a plain text file and symmetrically encrypt it with <a href="https://gnupg.org/">GnuPG</a> or use <a href="https://www.pwsafe.org/">Password Safe</a>. I have no relation with either.</p><p>Here are three common design flaws in password managers:</p><ol><li>Password storage</li><li>Reliance on remote systems</li><li>Web browser integration</li></ol><h2 id="password-storage">Password storage</h2><p>When passwords are stored, they must be encrypted and then retrieved later when needed. Storage, of any type, is a burden. Users are required to backup stored passwords, synchronize them across devices and implement measures to protect them.</p><p>Users must also devise a master password to unlock the encrypted passwords stored by the password manager. This is similar to a <a href="https://en.wikipedia.org/wiki/Master_keying">master key</a>. It is generally accepted that master keyed locks are less secure than non-master keyed locks. If the master password is exposed, then confidence (in all the passwords that it unlocks) is lost.</p><p>And, are we certain that the encryption used to store the passwords is implemented correctly? Has the encryption been externally validated? Some password managers are closed-source and proprietary and cannot be examined.</p><p>Encryption is hard. Even respected, expert developers with many years of experience (who seldom make mistakes) <a href="http://www.daemonology.net/blog/2011-01-18-tarsnap-critical-security-bug.html">do make mistakes</a> that render encryption weak or in some cases almost useless.</p><h2 id="reliance-on-remote-systems">Reliance on remote systems</h2><p>Ironically, password managers rely on remote systems largely because they store passwords. The first design flaw causes the second.</p><p>Remote systems are outside the user’s control. They are opaque and cannot be examined and should not be trusted with password management. These systems may not be available when needed. They may not be storing or transmitting passwords correctly.</p><p>Externally, the systems may seem correct (strong HTTPS, reasonable CSP) but behind the scenes, no one really knows what’s going on. How are the passwords being transmitted, generated and stored internally? Who has access to them?</p><p>Several popular cloud-based password managers have reported security breaches: <a href="https://www.darkreading.com/attacks-breaches/onelogin-breach-reignites-concerns-over-password-managers/d/d-id/1329034">1</a>, <a href="https://arstechnica.com/information-technology/2017/03/potent-lastpass-exploit-underscores-the-dark-side-of-password-managers/">2</a>, <a href="https://www.wired.com/2015/06/hack-brief-password-manager-lastpass-got-breached-hard/">3</a>.</p><h2 id="web-browser-integration">Web browser integration</h2><p>Web browsers today have “everything but the kitchen sink” capabilities built-in and are becoming more and more complex each year. They are turning into whole platforms that have browser plug-ins and extensions for every possible need known to humankind.</p><p>While many of these add-ons are handy and useful, we should not trust them with password management. Browsers are just too complex and have far too much going on.</p><h2 id="dpg">DPG</h2><p>I wrote DPG (The Deterministic Password Generator) around 2010 to address the design flaws described above. Here are its key concepts.</p><ol><li>Never store passwords. Rather, generate them as needed based on user input. The need to backup, synchronize and properly encrypt passwords is removed. There is no master password that immediately unlocks all of the other passwords. There is nothing to become lost, stolen or corrupt.</li><li>Only run locally on end-use devices. No reliance on remote systems or web browsers.</li><li><a href="https://github.com/62726164/dpg">DPG is open-source</a> and has several implementations. The passwords it generates can be verified and validated by external implementations in multiple programming languages.</li></ol><h2 id="conclusion">Conclusion</h2><p>DPG removes many of the flaws that I have experienced with traditional password managers over the years. Try it. You may like it. I hope you find it as useful as I have.</p><ul><li><a href="https://www.go350.com/tags/passwords">passwords</a></li><li><a href="https://www.go350.com/tags/compliance">compliance</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/the-design-flaws-of-password-managers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619451</guid>
            <pubDate>Sun, 03 Jan 2021 04:27:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stanford University Supplementary Essays]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619387">thread link</a>) | @crazypython
<br/>
January 2, 2021 | https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/ | <a href="https://web.archive.org/web/*/https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">



<!-- Sect: Hero
================================================== -->	
<header>
 <div>
 	<div>
	  <p><span>September 20, 2019</span></p>
			<h4>Stanford University</h4>
  </div>
 </div>
</header>

<!-- Article: Content
================================================== -->
<section>
	<div>
	<p>Please write a short essay in response to each of the three essay topics below. There is a 100-word minimum and a 250-word maximum for each essay.
</p>		<p>First, let’s briefly get a sense of what 250 words means. It’s two average paragraphs, or three lean paragraphs. Also known as: not a ton of space! The burden is on you to think about the meatiest point you need to make, and then to build your surrounding elements strategically, so that they help you deliver that point with maximum impact, concisely. It’s not as easy as it may sound. For our analysis, we’re mostly going to dig into the “meat” aspect.</p>
<h3>Essay 1: The Stanford community is deeply curious and driven to learn in and out of the classroom. Reflect on an idea or experience that makes you genuinely excited about learning.</h3>
<p>Strangely, this one rides or dies on the PROOF that you’re actually, truly, genuinely excited about learning. What serves as proof? Action. The stuff YOU DO in response to the stuff you’re inspired by… that demonstrates it, and makes it real. Anyone can CLAIM to be super inspired by X Y and Z and talk about it. But if all they do is talk, does it really matter? Not exactly the world’s sexiest Zen koan, but you get the idea.</p>
<p>Something to consider here – something common to folks who are genuinely excited about learning – is an unusual comfort level with being WRONG. A thirst for learning is predicated on (1) acknowledging that you don’t know everything already, and (2) that the stuff you may THINK you know, is wrong or incomplete. Why mention this? Cuz it can help your case to give EVIDENCE of that. Have you ever been wrong about something, and were THRILLED to discover what ended up being a BETTER WAY OF LOOKING AT SOMETHING? Walk us through what it felt like, why it might have felt bad at some point, but why it felt GOOD eventually to have developed, improved, evolved. We need to really PROVE that you’re turned on by learning, and admitting that you’ve been wrong (and loved it), is an excellent way to do so.</p>
<p>Another way, alluded to earlier, is purely through action. Is there evidence of “tirelessness” when you’re attempting to learn something? We need to see ways in which you pursue this thing, especially when it’s INCONVENIENT to do so. In other words, if your pursuit is compelling, but kinda expected, it won’t weigh as much. If you decided you wanted to get some cereal, and then went out and bought yourself some cereal… um, okay? But if on the way, it started to rain, and a hurricane arrived, and the store closed, so you hitchhiked to another location, and that store was closed too, so you decided to call your friend you know who happened to have an extra box, but he wasn’t home, so you decided to……. [yada yada]…. You ended up with your box of Crispix. Now THAT GUY’s interest in “cereal” seems unimpeachable, no? Show us how, when pursuing something for the sake of learning, you’ve done it (1) when no one else was looking, or (2) when it became inconvenient to do so, but you still did it, or (3) when the risk of continuing to do it started to outweigh the benefits, or… you get the idea.</p>
<p>Most students will focus on THE THING they’re excited about, rather than proving their excitement through action. It’s that second group that ultimately wins, because we now have reason to believe that they have that forward-leaning trait which will carry them through college and beyond. (And that’s whole point of this question – to make sure you won’t drop out in freshman year when you take a class that’s harder than any class you’ve ever taken before.)</p>
<h3>Essay 2: Virtually all of Stanford’s undergraduates live on campus. Write a note to your future roommate that reveals something about you or that will help your roommate—and us—know you better.</h3>
<p>Classic Stanford undergrad question. The mistake we see 95% of the time on first drafts is the impulse to try to “slip in” resume highlights. As if this is a veiled attempt by Stanford to get those highlights, instead of, you know, just asking for them. The way to impress Stanford here is through honesty and charm. But mostly honesty.</p>
<p>Indulge us here and take two swings at this. On the first attempt, get it out of your system, whatever letter you want to write, just take a crack and then file it away for the time being.</p>
<p>On your second attempt, go with us on a little journey. Start by <strong>creating a roommate</strong>, leaving everything to chance (the same way it’ll more or less work out when you’re actually assigned a roommate in your freshman dorm). For starters, your roommate will almost certainly be the same gender. Now, generate a bunch of parameters, like ethnicity, height, weight, athletic/ musical/etc., liberal/conservative, east coast/southern/west-coast/etc., affable/surly, cool/not-so-cool, American/foreign-born/etc.…. Don’t spend too much time, because it doesn’t really matter much. Give this guy or gal a name. Again, don’t get stuck on this, the idea is to paint a vague picture. But once you have this picture, commit to it for a second. Imagine a real person on the other end.</p>
<p>Now, you’re gonna address a fresh new letter to this person. If the open-ended-ness of the Stanford prompt leaves you stuck, consider some of the following ideas. Write the letter using one of the following:</p>
<ul>
<li>What if your roommate just confided in you, and told you an incredible secret. Something that leaves your roommate in an extremely vulnerable emotional state having just put him/herself on the line. What might you reveal about YOURSELF in response? “Hey, so here’s something most people don’t know about ME…” (What might follow that up?)</li>
<li>Treat it as though it were a dating profile. What kinds of preferences would you reveal about yourself that might give the BEST clues about what you’re all about? Think about quirks and specificity here. If you were to say “I like Chinese food” it doesn’t say all that much since so many different types of people would fall under that same category. If, however, you were to say you absolutely HATE the HBO show “Game of Thrones” that would have the opposite effect since “most people are obsessed with that show (INCLUDING ALL OF US AT ADMISSIONADO, SO WATCH YOUR STEP!).” Can you stack up a few such preferences that, when summed, may help someone get a sense for what you’re all about, and even better, become more curious to get to know you better?</li>
<li>You know that classic question “if you were stuck on a desert island forever, what album would you bring?” … You can put a twist on it here. Name a few KEY possessions you’re gonna bring that’ll be essential to your comfort. Forget bland necessities like “a toothbrush” (since everyone will be packing one of those). More like, the “sounds of the rainforest” you use to lull yourself to sleep every night. Stuff like that. And possibly even suggest a few things you DON’T have that your roommate may bring to complete the set for total roommate symbiosis. You don’t need to follow this conceit exactly, but maybe this gives you an idea from which you can springboard to help show us something about who you are exactly, and what makes you … you.</li>
</ul>
<h3>Essay 3: Tell us about something that is meaningful to you, and why?</h3>
<p>Ha, in 250 words… you’re asked to grapple with one of life’s more challenging questions. A fitting test for a place like Stanford. Let’s start with what NOT to do.</p>
<p>Extinguish the desire to imagine what Stanford wants to hear. If you pen a response that you <strong>BELIEVE</strong> will put you in good stead because you think it shows maturity, or emotional intelligence, or whatever else… you are in for a crash landing. Or, tell you what, let’s a make a deal. Write that version, and keep it handy. Now write <strong>ANOTHER</strong> version that may never ever see the light of day. Think of this as a private diary entry. An exercise that may lead to something. But take the pressure away that someone might read it, so be more honest than you might want to be otherwise.</p>
<p>For this version, imagine you’re addressing a &nbsp;huge crowd (as if you are the Pope, or MLK), and it’s a crowd of people who… aren’t really contributing all that positively to society. Maybe they’re lazy. Maybe they’re irresponsible. Maybe they’re disaffected. Maybe they’re dangerous. Let’s just call them the folks who aren’t model citizens of the world.</p>
<p>What might you say to inspire these folks? Think about it. If you were to say something obvious, wouldn’t it run the risk of not having much of an impact? Make it less about you (just for a second), and instead think about what you might say to inspire this crowd. If you were to say “say no to drugs” or “do unto others…” or “cherish each day as though it were your last” … hasn’t everyone heard it already? If they haven’t internalized those ideas, they’re certainly not gonna do so just because <strong>YOU</strong> said it, right? But they might if they hear something <strong>NEW</strong>, something fresh about what matters, in a way that may cause them to re-evaluate things or see things through a new lens.</p>
<p>Obviously, you won’t want to write about something trivial, like “driving a nice car matters because the value of a smooth ride is more pleasing than a bumpy one.” Unless it’s a cracking metaphor, something like that might make your message seem like you didn’t give it a whole lot of thought, or, worse, you’re someone who’s so privileged that that type of material comfort is truly something that matters more than deeper, cooler things. So, it probably will have to do with human interaction, or a way of approaching things, or a state of being, or the like. Think about where others are going wrong. What are others <strong>MISSING</strong>, in a way that leads to irresponsible behavior, actions, attitudes, etc.? What matters to <strong>YOU</strong> that makes you feel like your compass is pointed in a better direction?</p>
<p>This conceit (of addressing a crowd) is meant to unlock ideas, not for you to embrace the idea too literally. You’re not proselytizing. So, if it helps, use your imagination of …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/">https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/</a></em></p>]]>
            </description>
            <link>https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619387</guid>
            <pubDate>Sun, 03 Jan 2021 04:18:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More Simple Tips to Boost Your Productivity X2 (2021 Guide)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619289">thread link</a>) | @mcsee
<br/>
January 2, 2021 | https://maximilianocontieri.com/10-more-simple-tips-to-boost-your-productivity-x2-2021-guide | <a href="https://web.archive.org/web/*/https://maximilianocontieri.com/10-more-simple-tips-to-boost-your-productivity-x2-2021-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1609423230375/G2lMeCoy4.gif?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format,compress&amp;gif-q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><em>The previous article on lifehacks was a huge success. Let's start the year with more productivity tips!</em></p>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/Wikipedia:Too_long;_didn%27t_read">TL;DR</a> Just Read the Headlines. </p>



<ul>
<li>Goals and objectives are important. But without tracking they are useless.</li>
<li>Progress metrics, and goal replanning, are keys.</li>
<li>It's never all-or-nothing!</li>
<li>Don't plan and abandon!</li>
</ul>

<ul>
<li>Surgeon Maxwell Maltz found out <a target="_blank" href="https://jamesclear.com/new-habit">it takes about 21 days</a> to create a new habit.</li>
<li>It takes at least about 21 days for an old mental image to dissolve and a new one to harden.</li>
<li>Creating (or removing) a habit is straightforward.</li>
<li>Repeat 21 days (streak).</li>
<li>Fake it till you make it.</li>
</ul>

<ul>
<li>If the product is free, <strong>you</strong> are the product</li>
<li>Attention is <em>your</em> asset</li>
<li>When you use website/application/soft and try to do A, there will be a lot of alerts, banners, messages and clickbaits prompting you to do B/C/D, etc.</li>
<li>Be like Ulysses, don't listen to Mermaids!</li>
</ul>

<ul>
<li>Notifications are our enemy.</li>
<li>But notification prompts are also a Foe.</li>
<li>Disable <em>Notifications Requests</em> at all, on mobile or web. </li>
</ul>
<p><a target="_blank" href="https://support.google.com/chrome/answer/3220216?co=GENIE.Platform%3DDesktop">Chrome</a>/<a target="_blank" href="https://sendpulse.com/knowledge-base/push-notifications/enable-disable-push-notifications-mozilla-firefox">Firefox</a></p>

<ul>
<li>Have clear goals but manage goals. </li>
<li>Revisit them often.</li>
<li>Don't stick to the plan. </li>
<li>There's no plan</li>
<li>Set aims and change direction if necessary</li>
</ul>

<p>To avoid Procrastination set daily goals with artificial hard deadlines.</p>
<p><em>I try to write daily articles even though they are very far from perfect. 
Fake deadline: today.</em></p>

<p>(web hack)</p>
<ol>
<li>Go to “Explore” under “Home”</li>
<li>Click the wheel at the right of the “Search Twitter” box.</li>
<li>Click “Explore Locations”.</li>
<li>Pick a country (like <a target="_blank" href="https://en.wikipedia.org/wiki/Saint_Kitts_and_Nevis">St Kitts</a>).</li>
<li>Now the “What’s Happening” will only display content for the location (empty).</li>
<li>You will only see your timeline.</li>
</ol>

<ul>
<li>Use <em>time limits</em> to your advantage. Even if you don’t have a real deadline on a task, set one for yourself. </li>
<li>Knowing that you only have four hours left, will help ensure you don’t waste an hour of it on social media.</li>
</ul>

<ul>
<li><strong>S</strong>pecific</li>
<li><strong>M</strong>easurable</li>
<li><strong>A</strong>ttainable</li>
<li><strong>R</strong>elevant</li>
<li><strong>T</strong>ime-bound</li>
</ul>
<p>Write your goals as <em>SMART</em> Sentences:</p>
<p>Example:</p>
<blockquote>
<p>“Write one <a target="_blank" href="https://hashnode.com/series/code-smells-ckh0jrbfm07pu20s1bc0yaae1">Code Smell</a> article every week until 2022."</p>
</blockquote>

<ul>
<li>Auto-block some distraction websites.</li>
<li>Use <a target="_blank" href="https://chrome.google.com/webstore/detail/blocksite-stay-focused-co/eiimnmioipafcokbfikbljfdeojpcgbh">BlockSite</a> or similar to keep you off social media or news</li>
<li>Block site IPs on hosts.txt or similar.</li>
<li>Cut off internet using router rules.</li>
<li>Go to an internet void zone in the wild.</li>
<li>Engage on a goal-based group to be accountable.</li>
</ul>
<hr>
<p>This list is far from finished. But my autodeadline was today.</p>
<p>Hopefully, draft tips will be out next week!</p>
<p>What do you think?</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://maximilianocontieri.com/10-more-simple-tips-to-boost-your-productivity-x2-2021-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619289</guid>
            <pubDate>Sun, 03 Jan 2021 04:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Response to Critique of Dream Investigation Results [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619247">thread link</a>) | @Tomte
<br/>
January 2, 2021 | https://mcspeedrun.com/dream/rebuttal.pdf | <a href="https://web.archive.org/web/*/https://mcspeedrun.com/dream/rebuttal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcspeedrun.com/dream/rebuttal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619247</guid>
            <pubDate>Sun, 03 Jan 2021 03:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Complete Their Thought]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619124">thread link</a>) | @ny2ko
<br/>
January 2, 2021 | https://nngorok.com/don-t-complete-their-thought | <a href="https://web.archive.org/web/*/https://nngorok.com/don-t-complete-their-thought">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <p><a href="https://nngorok.com/don-t-complete-their-thought">January 3, 2021</a></p>
<p>I’ve recently been thinking about why listening can be very difficult. One aspect that always comes to mind, a practice that is exceptionally difficult to give up, is the tendency to finish other’s thoughts. Here’s some similar scenarios to illustrate:</p>
<p>Meet Alice, a senior engineer on a team and Bob a recent addition on the team.</p>
<blockquote>
<p>Bob: Hey Alice. Got a sec?<br> Alice: Sure Bob. What’s up?<br> Bob: I was trying to use system X and I run into problem Y. I …<br> Alice: Oh, must be issue Z? That concurrency bug surfaces from time to time.</p>
</blockquote>
<p>This can go one of 2 ways. Either, Alice is on the money and has helped Bob figure it quickly.</p>
<blockquote>
<p>Bob: Oh! Right! I hadn’t thought about that. Why is that?<br> Alice: My pleasure.<br> etc.</p>
</blockquote>
<p>Or alternatively, Alice is off the mark:</p>
<blockquote>
<p>Bob: I don’t think so. I’m seeing more of issue A.<br> Alice: I see. Must be the installation ordering!<br> etc.</p>
</blockquote>
<p>In both these cases, Alice quickly concludes what issue Bob might be facing. With her wealth of experience on the team and deep knowledge of the systems, she is able to usually have a good idea what the issue is. However, in both cases, Alice unintentionally doesn’t allow Bob to complete his thoughts. What else could Bob have said about the issue? He, for instance, could have elaborated on the steps he had taken so far, and how he went about trying to figure out the issue. All this information could have given Alice more context and a better opportunity to coach Bob as he ramps up on the team even better. It also could have fostered more relationship building between them. Unfortunately, this doesn’t happen.</p>
<p>Cases such as this are very common. Let’s look at Juan a manager and Neda, an engineer that reports to him:</p>
<blockquote>
<p>Juan: Hey Neda! How’s the project going?<br> Neda: The project is coming along well. I do have some reservations on it’s value to the company. It…<br> Juan: What aspects are giving you reservations?<br> Neda: The project will take Y months and at best generate Z in revenue. <span>I…</span><br> Juan: That sounds pretty decent to me. This project has been a long time coming and will have impact around the company beyond revenue. It will…</p>
</blockquote>
<p>Juan does a good job trying to understand the problem a bit better at the start asking a clarifying question. However, when he gets a whiff of what he thinks the issue is, he quickly jumps to address it, attempting to complete Neda’s thoughts.</p>
<p>Unfortunately, it isn’t possible to truly know what another’s thoughts are. We simply cannot <strong>(yet)</strong> read each other’s minds. If we don’t let others finish their thought, we risk souring the conversation and/or relationship: whether that means the other person has to correct us and redirect the conversation or that the other person resorts to not voicing their opinions.</p>
<p>We all have busy schedules and want to be efficient in our conversations. As leaders, we often are having similar conversations with many different people. So much so, that we usually know what the person is<span></span> <span>“</span>getting at”; it is very tempting to make the connections! The crux though, is that when we guess wrong, it can be disastrous.</p>
<p>So the next time you have the urge, pressing as it may be, to complete someone’s thoughts, hold your tongue. Let them go over what they think even if you’ve heard it all before. Before you respond, ask yourself, have they finished their thought? Are you about to complete their thought because you think you know what they are getting at? Don’t respond until they finish. With all the context they give you, give them that great response! They will appreciate you for it. If you really must, and can’t fight the urge, count down for 5 seconds of silence or try asking a clarifying question instead.</p>
          

          



          

          <hr>

          <a href="https://nngorok.com/managers-should-code-but-not-at-work">
            <h5>Previous post</h5>
            <span>Managers should code, but not at work</span>
            <span>Should managers code? This question doesn’t seem to have a clear answer. There are proponents and opponents to the debate, each having valid points</span>
          </a>

        </div>

      </div>
    </div></div>]]>
            </description>
            <link>https://nngorok.com/don-t-complete-their-thought</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619124</guid>
            <pubDate>Sun, 03 Jan 2021 03:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Concepts of Legibility]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619052">thread link</a>) | @jashkenas
<br/>
January 2, 2021 | https://ideolalia.com/essays/two-concepts-of-legibility.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/two-concepts-of-legibility.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>In <a href="https://en.wikipedia.org/wiki/Seeing_Like_a_State"><em>Seeing Like a State</em></a>, James C. Scott defines “legibility” as something a state imposes on its people and resources.  It is a coercive abstraction, not only treating different people, places, and ways of life as if they were the same<sup id="fnref:abstraction"><a href="#fn:abstraction">1</a></sup>, but creating an environment which encourages people to forget those differences ever existed.</p>

<p>One of Scott’s first examples is land ownership in pre-modern rural villages, each of which had its own peculiar practices built over generations, describing the obligations between neighbors, the obligations between relatives, and the use of common pastures and forests.  These practices were perfectly legible within a given village, but a cacophonous mess to state officials trying to understand all of them at once.</p>

<p>And so the states sent in surveyors, who drew sharp boundaries on their maps.  A year later came the tax collectors, maps in hand.  If a family paid taxes on what was once common property, they had little motivation to let their neighbors continue to use it.  Instead, the villagers reshaped their lives to fit the maps.</p>

<p>In <a href="https://en.wikipedia.org/wiki/The_Image_of_the_City"><em>The Image of the City</em></a>, Kevin Lynch defines “legibility” as something that a complex environment offers to its inhabitants, allowing them to easily navigate it.  It is a clarifying abstraction, making the world more than an endless deluge of minute details.</p>

<p>Lynch interviewed long-time residents of various cities, and asked them to describe how they’d navigate from one part of the city to another.  He created reference maps of shared elements from these journeys, representing how each city was understood by its people.</p>

<p>Some cities, such as Boston, were highly legible; its map was full of reference points, and its residents were confident in each step of their imagined journey.  Other cities were less so:</p>

<blockquote>
  <p>[A]lmost anyone can, if attentive, learn to navigate in Jersey City, but only at the cost of some effort and uncertainty.  Moreover, the positive values of legible surroundings are missing: the emotional satisfaction, the framework for communication or conceptual organization, the new depths that it may bring to everyday experience.</p>
</blockquote>

<p>The moral hazard described in <em>Seeing Like a State</em> exists in any field of design.  In software, for instance, anywhere one implementation cannot be easily exchanged for another, users are forced to bend themselves to the needs of their software.  This is trivially true of enterprise software, since the users are not the buyers, but given the increasingly <a href="https://en.wikipedia.org/wiki/Zero_to_One">monopolistic bent</a> of all software companies, it can be also true in the consumer space.</p>

<p>This is worrisome, not least because of the tech industry’s continuous attempts to resurrect <a href="https://en.wikipedia.org/wiki/Logical_positivism">logical positivism</a>.  Someone who claims their design was conceived from first principles has almost always injected their own biases and incuriosity into those principles.  As coercive abstractions, these designs will preserve whatever is familiar to a small, homogeneous group, and allow everything else to wither away.</p>

<p>Scott offers prescriptions for avoiding the problems he describes, but they’re mostly process-oriented (“take small steps”, “favor reversibility”) and entirely focused on harm reduction.  For Scott, abstraction is always something done to people, never for people.</p>

<p>But this is just one side of the coin; to apply the insights in either book we must understand both kinds of legibility, and what separates them.  To get there, though, we must first explore two works of fiction.</p>

<hr>

<p>The Gnostics were a collection of early Christian sects which fused the gospels with Platonic dualism.<sup id="fnref:gnostics"><a href="#fn:gnostics">2</a></sup>  A true Creator was responsible for the world of ideal forms, while a lesser being, a <strong>demiurge</strong>, was responsible for the pale shadow of our physical world.  For the Gnostics, the work of the demiurge was a veil over our eyes, created out of malice or ineptitude, and their goal was to pierce that veil, to achieve <strong>gnosis</strong>.</p>

<p>Philip K. Dick had a lifelong fascination with the Gnostics, and their ideas appear constantly throughout his novels.  Nowhere is this more evident than in <a href="https://en.wikipedia.org/wiki/The_Three_Stigmata_of_Palmer_Eldritch"><em>The Three Stigmata of Palmer Eldritch</em></a>.</p>

<p>In the novel, the Earth has become uninhabitably hot, forcing everyone to take shelter in buildings or subterranean structures during the day.  People are being forcibly migrated to even more hardscrabble lives on nearby planets, which can only be escaped via Perky Pat layouts, effectively Barbie Dream Houses they can temporarily inhabit using Can-D, a drug illicitly distributed by the creators of Perky Pat.</p>

<p>Using the drug, users are transported to a single, perfect day in San Francisco, before the Earth became too hot, in the bodies of a wealthy, beautiful couple.  They can accessorize their escapism by purchasing “minned” items, which will appear full-size and functional within Perky Pat’s world.</p>

<p>This is a false gnosis, layering something simple and idealized atop the messiness of the physical world, rather than peeling it back.  False gnosis is a central theme in all of Dick’s writing, which makes him perhaps the only science-fiction author who truly anticipated our present day.  Like everyone else, he failed to predict the smartphone, but he alone seemed to understand how completely technology could intermediate our understanding of the world.<sup id="fnref:cyberspace"><a href="#fn:cyberspace">3</a></sup></p>

<p><em>Three Stigmata</em> begins with the return of Palmer Eldritch, an industrialist who had travelled to Proxima Centauri in search of new business opportunities.  He has brought with him a new drug, Chew-Z, which promises the same escape as Can-D without the need to buy any accessories.</p>

<p>Anyone taking Chew-Z can create their own world to inhabit, but every person in that world takes on aspects of Eldritch himself, sharing his prosthetic hand, eyes, and mouth.  Even as the drug seems to subside, Eldritch remains, making it impossible to know what’s real.</p>

<p>In time, it’s revealed that the returned Eldritch is not the businessman, but rather a dying demiurge who has assumed his form.  He toys with anyone who takes Chew-Z, creating escapist fantasies that prove to be every bit as flawed as their real lives.  By the end, Eldritch has begun to merge with humanity, even infecting people who never touched the drug.</p>

<p>Eldritch doesn’t offer gnosis, but neither does he offer pure escapism like Perky Pat.  He gives humanity an understanding of <em>himself</em>, of the nature of the veil over our eyes.  Even if it tells us nothing of what lays beyond, Dick seems to suggest it’s the most we can hope for.<sup id="fnref:exegesis"><a href="#fn:exegesis">4</a></sup></p>

<p>A different sort of demiurge is portrayed in Italo Calvino’s <a href="https://en.wikipedia.org/wiki/Invisible_Cities"><em>Invisible Cities</em></a>, in which Marco Polo tells Kublai Khan of all the cities he’s seen in his travels.  They sit in the Khan’s palace, at the center of an empire which has exceeded his grasp:</p>

<blockquote>
  <p>It is the desperate moment when we discover that this empire, which had seemed to us the sum of all wonders, is an endless, formless ruin, that corruption’s gangrene has spread too far to be healed by our scepter, that the triumph over enemy sovereigns has made us the heirs of their long undoing.  Only in Marco Polo’s accounts was Kublai Khan able to discern, through the walls and towers destined to crumble, the tracery of a pattern so subtle it could escape the termites’ gnawing.</p>
</blockquote>

<p>His descriptions of the cities, however, are narrow.  In one, he only describes a memory it evokes.  In another, he only describes the relationship between the city and its reflection in the surrounding water.  Sometimes the cities themselves are narrow; one such city has been reduced to freestanding pipes, with attached bathtubs and fountains, populated by nymphs and naiads.</p>

<p>These are pieces of cities, mixed and distilled from everything Polo has seen in his travels.  But at their core, they are facets of a city he never describes, the city he knows best, his birthplace:</p>

<blockquote>
  <p>And Polo said: “Every time I describe a city I am saying something about Venice.”</p>
</blockquote>

<blockquote>
  <p>“When I ask you about other cities, I want to hear about them.  And about Venice, when I ask you about Venice.”</p>
</blockquote>

<blockquote>
  <p>“To distinguish the other cities’ qualities, I must speak of a first city that remains implicit.  For me it is Venice.”</p>
</blockquote>

<p>Marco Polo is a worldly man, but he is not of the world; he is Venetian, and everything is understood and remembered through that lens.  What he has discovered, in the course of his travels, is that certain pieces of Venice are timeless.  These are what will survive the collapse of the Khan’s empire, what will constantly reoccur throughout time; always different in detail, but unmistakably the same.</p>

<p>And yet Polo, just like Eldritch, does not offer true gnosis.  Each city hides all but a tiny piece of Venice through omission and fantastic obfuscations like the nymphs and naiads.  Unlike Eldritch, however, he offers choice.  The set of cities he describes is neither minimal nor exhaustive; each can be considered or ignored in isolation.</p>

<p>These cities may obscure their underlying reality, but they don’t attempt to replace it.  Instead, they simply reveal a resonance, a commonality of experience we might otherwise have missed.</p>

<hr>

<p>The legibility described in <em>Seeing Like a State</em>, and imposed by Palmer Eldritch, is <strong>singular</strong>; It overrides our own experience, forcing us to live within the mind of its creator.  The legibility described in <em>Image of the City</em>, and offered by Marco Polo, is <strong>faceted</strong>; it complements our own experience, allowing us to apply it where we see fit.</p>

<p>Creating singular legibility is simple: find something that’s easy for you to understand, and force people to use it.  What’s hard is using it responsibly; to predict its full effect, you’d need to first have an exhaustive understanding of the environments in which it will be used.</p>

<p>Faceted legibility is more forgiving, allowing us to understand the world incrementally and collaboratively.  It’s not, however, something we can simply create on our own.  Instead, we can only lay the groundwork and hope it flourishes.</p>

<p>How do we lay the proper groundwork?  It depends on what you’re …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/two-concepts-of-legibility.html">https://ideolalia.com/essays/two-concepts-of-legibility.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/two-concepts-of-legibility.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619052</guid>
            <pubDate>Sun, 03 Jan 2021 03:18:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Comfortably in Thick Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25618959">thread link</a>) | @AceyMan
<br/>
January 2, 2021 | https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html | <a href="https://web.archive.org/web/*/https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<p>Writing in a thick notebook can be troublesome when you get close to the end of a page. If you're like most people you will encounter a zone where the palm, fingernails or wrist (which I will refer to collectively as "palm") of your writing hand have nowhere to rest, and you may find yourself trying to "float" your hand over the page. As a result, control of the pen-tip becomes enough of an effort to hamper the free-flow of thoughts from the brain through the nervous system to their final conversion to written word.</p>

<p>At best, you get your point across, but usually not without some effort, frustration, and sloppy penmanship.</p>

<p>I suppose one could simply turn to a fresh page before this becomes an issue. That would probably be ok with cheap notebooks, but if you are reading this, yours is probably not cheap, and you intend to wring out all of its value by using every bit of its space.</p>

<p>Thus, as your palm starts to drift off the bottom edge of the page, it needs somewhere to rest...two possible solutions come to mind...one is free, the other cheap:</p>

<p>1. The Smart Phone Trick (free)</p>
<p>2. The Writing Mat (cheap)</p>


<p><strong>The Smart Phone Trick</strong></p>

<p>Placing your smartphone at the bottom of the book at the right point serves as a rest for your palm. It feels like instant relief, at least compared to the alternative of doing nothing at all. It's as if your hand lost its balance at the edge of the page, and the phone is there to catch it.</p>

<p>A smart phone is also a very good thickness (about 10mm) for this purpose. At some point it will be lower than the page you are writing in, and at other points higher, but the differential will never be very great because you won't always need it.</p>

<p>A thin paperback also works well for this purpose, but it can't be too wide or long because it will use up a lot of desk space and may even dig into your forearm. And you'll have to always remember to have it on hand. So, a smartphone is nearly the perfect size....and it is very handy for many of us most of the time. It may take some trial-and-error to figure out exactly when and where you need to deploy the device, but once you do, you will once again find your thoughts freely flowing to any point on the page.</p>

<p>And, as a pen-and-paper person, you may gain some satisfaction from knowing that technology doesn't always exist just for its own sake.</p>


<p><strong>The Writing Mat</strong></p>

<p>Writing mats (sold on this site) are great for enhancing the pen-to-paper connection, and if while writing you press hard with fine points it will protect the lower pages from impressions.</p>

<p>They are also great as a lower extension of the page you are writing on. For that purpose the thin plastic mats seem to work better than the soft mats because they are stiffer and give more support to the palm. But the soft ones work fine too. As you get to that troublesome point on the page, you just keep moving the mat down as long as you need to, and it provides a gentle slope on which your palm can rest.</p>

<p>The mat should be at least the same size as the paper. It can be larger, but larger doesn't have any real advantage other than being able to work with more notebook sizes. They are also harder to carry around. But even if you have the perfect size mat, you have to remember to have it with you, so you may prefer the smart phone trick anyway.</p>


<p><strong>Conclusion</strong></p>

<p>There are many folks that don't write in notebooks because of this very issue, but given these simple solutions it doesn't have to be hard at all. There is also a certain feeling of satisfaction, security and abundance when writing in a thick notebook, and anyone can deploy these or similar tactics in order to get the full experience.</p>


<p><img title="img-1731.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1731.jpg?t=1398725710" alt="img-1731.jpg" width="600" height="600"></p>

<p><img title="img-1732.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1732.jpg?t=1398725710" alt="img-1732.jpg" width="600" height="600"></p>



<p><img title="img-1734.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1734.jpg?t=1398725710" alt="img-1734.jpg" width="600" height="600"></p>


<p><img title="img-1762.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1762.jpg?t=1398725710" alt="img-1762.jpg" width="600" height="600"></p>

<p><img title="img-1763.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1763.jpg?t=1398725710" alt="img-1763.jpg" width="600" height="600"></p>
	
	</div></div>]]>
            </description>
            <link>https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618959</guid>
            <pubDate>Sun, 03 Jan 2021 03:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[After APIs, Webhooks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25618908">thread link</a>) | @vitoc
<br/>
January 2, 2021 | https://docs.prudent.me/blog/2020/12/6/webhooks | <a href="https://web.archive.org/web/*/https://docs.prudent.me/blog/2020/12/6/webhooks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We hear a lot about APIs as financial institutions open up their services for public access, but webhooks can be just as useful for user experience in personal finance management.</p>
<p>APIs are more passive whereas webhooks are more pro-active.</p>
<p>This makes a difference from a programmatic point of view, which then affects user experience.</p>
<p>You can imagine this difference with e-mail for example.</p>
<p>Imagine a time before push notifications. Without push notification, the manifest practice is to "Check mail". Remember those quaint days when we used to push that Send/Receive button? That's API call for you.</p>
<p>While we can code applications in such a way as to check an API very often, it's not very bandwidth-compute-energy efficient.</p>
<p>Webhooks are much better. Like push notification, applications gets notified when a transaction happens and changes its state accordingly.</p>
<p>Along with the change of state, any other triggers or reactive components can then come alive, a much better pattern :)</p>
<p><a href="https://docs.prudent.me/blog/2020/12/6/ideal-experience">More on what webhooks can do for Prudent UX here...</a></p>
<p><a href="https://stripe.com/docs/webhooks">Stripe's excellent webhooks</a></p>
<p><a href="https://en.wikipedia.org/wiki/Push_technology">Wikipedia entry on Push technology in general (with examples of how it is implemented, including long polling, which I think is not ideal)</a></p>
</span></p></div></div></div>]]>
            </description>
            <link>https://docs.prudent.me/blog/2020/12/6/webhooks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618908</guid>
            <pubDate>Sun, 03 Jan 2021 02:53:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's Snowing in My CPU – A Snowflake Catalogue]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618902">thread link</a>) | @sytelus
<br/>
January 2, 2021 | http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">






<!-- elapsed slogan/addthis 0.001823 -->
<hr>


<!-- elapsed masthead 0.000477 -->






 <!-- header -->

<!-- elapsed header 0.001905 -->




<!-- elapsed masthead/badge/about 0.0004 -->


<p><span>
Scientific graphical abstracts — design guidelines
<a href="http://mkweb.bcgsc.ca/graphical.abstract.design"><img src="http://mkweb.bcgsc.ca/gfx/arrow-right-news.png"></a>
</span>














</p>
<hr>
<!-- elapsed news 0.002352 -->



<hr>
<!-- elapsed on the side 0.003213 -->





<div id="projects">




<div>










<p>
Art is science in love.
<br>
<span>— E.F. Weisslitz</span>
</p>






<p>Somewhere in the world, it's snowing. But you don't need to go far—it's always snowing on this page. Explore <a href="http://mkweb.bcgsc.ca/snowflakes/random.mhtml">light flurries</a>, <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml">snowflake families</a> and <a href="http://mkweb.bcgsc.ca/snowflakes/flake.mhtml?flake=autqzcws">individual flakes</a>. There are many <a href="http://mkweb.bcgsc.ca/snowflakes/oddities.mhtml">unusual snowflakes</a> and snowflake <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml?family=12">family 12</a> and <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml?family=46">family 46</a> are very interesting. 

</p><p>But don't settle for only pixel snowflakes—<a href="http://mkweb.bcgsc.ca/snowflakes/snowflake.3dprint.mhtml?name=morptel">make an STL file and 3D print your own flakes</a>!

</p><p>Ad blockers may interfere with some flake images—the names of flakes can trigger ad filters.













<a id="l0home"></a>
</p>








<h2>In silico flurries: computing a world of snowflakes</h2>

<p>High-resolution images from our Scientific American article <a href="https://blogs.scientificamerican.com/sa-visual/in-silico-flurries/">In Silico Flurries: computing a world of snowflakes</a>.





</p><div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/1.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/1.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 1.</b> An example of a snowflake grown using the Gravner-Griffeath model. Various amounts of ice (encoded by the blue tone) at different parts of the snowflake make up the six-fold radially symmetric shape.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/1.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/2.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/2.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 2.</b> The Gravner-Griffeath model is a type of reaction-diffusion system, with three kinds of “morphogens”: ice, quasi-liquid and vapor. The model is deterministic—given a set of parameters the output is always the same. Optionally the model can include randomness by perturbing the amount of vapor mass in every site at each step.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/2.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/3.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/3.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 3.</b> The evolution of the snowflake from Figure 1 to full size at 15,353 growth steps.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/3.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/4.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/4.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 4.</b> The effect of varying each of the model parameters on the shape of the snowflake in Figure 1, whose parameter value is shown as a red dot. The images sample the parameter values shown by small black ticks. The distribution of snowflakes in our collection by parameter value is shown as a gray histogram. The median is the long black line among the bins.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/4.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/5.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/5.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 5.</b> Our collection of snowflakes clustered based on structural similarity. Clusters are projected onto two dimensions using t-SNE. The snowflakes are themselves arranged on a hex grid to allow tighter packing.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/5.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/6.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/6.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 6.</b> A collection of paths in the two-dimensional t-SNE space of the snowflakes, affectionately named “The Flube.”


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/6.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/7.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/7.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 7.</b> A sample of the snowflakes found at the t-SNE hex grid of each station in The Flube, showing the variation in shape within and between clusters.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/7.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/8.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/8.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 8.</b> The relationship between parameter values and t-SNE clustering. Each snowflake is drawn as a circle colored by the relative difference of the snowflake’s parameter with the median value. The lines of The Flube are superimposed to help interpret the variation in shape in Figure 7.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/8.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/9.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/9.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 9.</b> A hand-drawn interpretation of the t-SNE map in Figure 5. Geographical features encode parameter values: woods (low ρ), grassland (low β), marsh (low μ) and desert (high θ). The speed at which the snowflake grew (steps to reach full size, n) is encoded by mountains (high n) and ice cliffs (low n). All names are generated using an RNN trained on 257 names of countries. The Flube network is drawn as thin lines with stations as loops with cities (medium size text) placed at the location of station positions in Figure 6.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/9.png">zoom</a>)
</p>
</div></div>



















</div>
</div>


<!-- elapsed page content 1.146593 -->



<!-- elapsed thoughts 0.000431 -->



<hr>


<!-- elapsed value 0.000185 -->


<!-- elapsed keywords 0.000165 -->

 <!-- footer -->
<!-- elapsed footer 0.000452 -->

</div></div>]]>
            </description>
            <link>http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618902</guid>
            <pubDate>Sun, 03 Jan 2021 02:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Indifference Engine: An Ecological Characterization of Bitcoin [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618883">thread link</a>) | @sp332
<br/>
January 2, 2021 | https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Wassim+Alsindi">Wassim Alsindi</a>

</p>


<!-- %h3 About -->
<p>"As Bitcoin surpasses previous price records and re-enters mainstream consciousness following several wilderness years, the twelve-year-old cryptocurrency appears to have “arrived” in the eyes of the market. The value proposition of an ungoverned, uncensorable digital means of value transfer is clear for all to see…but can humanity and Earth afford the thermodynamic price tag? </p>

<p>To maintain the integrity of the transaction record, the Bitcoin network creates a hard boundary to the outside through exacting validation requirements. However it does not possess any feedback mechanism or capacity to respond to the consequences of the thermoeconomic challenges it issues. This insensitivity of ‘mined’ cryptocurrencies to the energy sources used to secure them has led to criticism as to their inability to mitigate their ecological externalities."</p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618883</guid>
            <pubDate>Sun, 03 Jan 2021 02:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Survey Chicken]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618712">thread link</a>) | @exolymph
<br/>
January 2, 2021 | https://carcinisation.com/2020/12/11/survey-chicken/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/12/11/survey-chicken/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-738">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>



<p>As a banana who lives among humans, I am naturally interested in humans, and in the social sciences they use to study themselves. This essay is my current response to the Thiel question: “What important truth do very few people agree with you on?” And my answer is that surveys are bullshit.</p>



<p>In the abstract, I think a lot of people would agree with me that surveys are bullshit. What I don’t think is widely known is how much “knowledge” is based on survey evidence, and what poor evidence it makes in the contexts in which it is used. The nutrition study that claims that eating hot chili peppers makes you live longer is based on surveys. The twin study about the heritability of joining a gang or carrying a gun is based on surveys of young people. The economics study claiming that long commutes reduce happiness is based on surveys, as are all studies of happiness, like the one that claims that people without a college degree are much less happy than they were in the 1970s. The study that claims that pornography is a substitute for marriage is based on surveys. That criminology statistic about domestic violence or sexual assault or drug use or the association of crime with personality factors is almost certainly based on surveys. (Violent crime studies and statistics are particularly likely to be based on extremely cursed instruments, especially the Conflict Tactics Scale, the Sexual Experiences Survey, and their descendants.) Medical studies of pain and fatigue rely on surveys. Almost every study of a psychiatric condition is based on surveys, even if an expert interviewer is taking the survey on the subject’s behalf (e.g. the Hamilton Depression Rating Scale). Many studies that purport to be about suicide are actually based on surveys of suicidal thoughts or behaviors. In the field of political science, election polls and elections themselves are surveys.&nbsp;</p>



<p>What I mean by “surveys” is standard written (or spoken) instruments, composed mostly of language, that are administered to subjects, who give responses, and whose responses are treated as quantitative information, which may then be subjected to statistical analysis. It is not the case that knowledge can never be obtained in this manner. But the idea that there exists some survey, and some survey conditions, that might plausibly produce the knowledge claimed, tends to lead to a mental process of filling in the blanks, of giving the benefit of the doubt to surveys in the ordinary case. But, I think, the ordinary survey, in its ordinary conditions, is of no evidentiary value for any important claim. Just because there exist rare conditions where survey responses tightly map to some condition measurable in other ways does not mean that the vast majority of surveys have any value.&nbsp;</p>



<p>Survey evidence seems to be a new phenomenon. Robert Groves (2011) argues that it is a 20th century phenomenon, arising in the 1930s, achieving a golden age from the 1960s to the 1990s, and then falling off in prestige and reliability after that.&nbsp;</p>



<p>Why is it important that surveys are new? I think it is important to remember that there is no ancestral practice equivalent to surveys. That is to say, there is no ancient human practice or context in which people anonymously tell the pure, innocent truth with language, in response to questioning, with no thought for the motives of the questioner or the effect of their answers. However, in the new, wholly invented ethnomethod of [doing a survey], it is imagined that subjects do tell the innocent truth, comprehending the underlying sense of the question but not answering with any motive or particularity of context. The anonymity of survey takers is given as proof that they feel free to tell the truth, rather than being perceived as a bar to asking them what they might have meant by their responses.</p>



<p>To get at the philosophical weirdness of the survey, it is necessary to dissect the phenomenon of survey-taking in detail. First I will consider the legal perspective, since that is an ancient domain of getting at truth through language in particular contexts.&nbsp;</p>



<p><strong>Surveys and Legal Evidence</strong></p>



<p>The vast majority of evidence in the legal context is and has always been testimonial. That is, a witness testifies in language to communicate some fact to the judge or jury, and the judge or jury then decides how much to believe it. This is true even for modern DNA evidence: the expert witness testifies about the alleged meaning of the laboratory findings, even if documents (also testimony of the writer or preparer) are also given to the trier of fact to examine. Good evidence and garbage evidence are both usually testimony.&nbsp;</p>



<p>In the English common law tradition, the biggest rule about testimonial evidence is hearsay. To put it colloquially, the hearsay rule says that testimony has to come from the horse’s mouth. If you saw someone run a red light and crash into a fire truck, you could undergo the ritual of being put under oath (agreeing that negative legal consequences could befall you for untrue speech), and testify about what you saw in court. Then you would be subject to the further ritual of cross-examination, in which all the aspects of your testimony could be questioned: your vision, whether you had your glasses on, where you were positioned, what specifically you mean by “crashed,” your relationship with the driver, and perhaps even whether you had a past conviction for forgery, which might make you seem like a liar in general. Those responsible for deciding whether to believe your testimony would have the chance to look at your face and mannerisms while testifying, to look at your clothes and hair and grooming, to see whether your eyes are bloodshot, in order to judge your responses to questioning. This may seem superficial and unfortunate, but in conversation we make these judgments all the time. And a witness may lose credibility for appearing too slick as often as for appearing too tattered, as in ordinary life.</p>



<p>However, if you wanted to testify about what you heard <em>someone else</em> say, someone who isn’t present for ritual oath-taking and questioning, that would be hearsay, admissible only under a list of exceptions. The exceptions to the hearsay rule are generally contexts in which language evidence is considered particularly likely to be accurate and truthful, such as a record kept in the ordinary course of business, or an emotional shout just after the crash (the idea being that you wouldn’t have time to think up a lie).&nbsp;</p>



<p>Survey evidence, then, is plainly hearsay, since when we hear claims based on survey evidence, we get no opportunity to judge the credibility of the statements as we might in conversation (much less under oath). However, survey evidence is often admissible in legal proceedings, particularly under the much-abused “state of mind” exception. But I think the more common reasoning underlying admission of survey evidence is as stated by a legal scholar at the beginning of the golden age of surveys (Zeisel 1959): “[S]ince surveys provide the best, <strong>if not the only</strong>, evidence on certain issues, and since expert knowledge in the field has advanced sufficiently to protect the trier of the facts from error, the law may well lower its heavy guard” (bolded emphasis mine). In other words, survey evidence is admissible because there’s no other way to get at the underlying facts. Consider trademark confusion: how would one measure whether consumers confuse one mark with another except by asking them in some clever way? The phenomenon of confusion is hidden in the minds of consumers, and can’t be measured with calipers or rulers.&nbsp;</p>



<p>Even when surveys are the only way to get at some particular knowledge, they may be done well or poorly. Zeisel (1959), citing <em>Coca-Cola v. Nehi Corp.</em>, 27 Del. Ch. 318, 326, 36 A.2d 156 (1944), says:</p>



<blockquote><p>Other aspects of an interview can also become grounds for criticism. Word association tests given to students in a classroom were rejected because their reactions were “bound to differ from that of the buyer in the market place when confronted with the.., beverage …. ” As another court remarked, “the issue is not whether the goods would be confused by a casual observer, but [rather] .. .by a prospective purchaser at the time he considered making the purchase. If the interviewee is not in a buying mood but is just in a friendly mood answering a pollster, his degree of attention is quite different.”</p></blockquote>



<p>That is to say, even though a survey might be the only way to judge the phenomenon of confusion, a college classroom was judged to be sufficiently different from shopping in a store (e.g.) to render the survey meaningless. I find this standard touchingly exacting compared to the present lax standard for taking survey evidence seriously. The present standard seems to be that the more math you do to survey data, the more reliable it is.</p>



<p>The meaning of my title is from a joke told at the end of <em>Annie Hall</em>:</p>



<blockquote><p>I thought of that old joke—you know, this guy goes to a psychiatrist and say doc, my brother’s crazy! He thinks he’s a chicken. And the doc says, why don’t you turn him in? Then the guy says, I would, but I need the eggs. I guess that’s pretty much now how I feel about relationships. They’re totally crazy, irrational, and absurd, but I guess we keep going through it because most of us need the eggs.</p></blockquote>



<p>Surveys are perhaps the only way to get certain information, information about the most important and pressing phenomena, about happiness and suffering in all its forms. These are eggs that most of us need. So even though surveys are bullshit, they are not “turned in” like the unfortunate brother in Woody Allen’s joke, but embraced in a plausibility structure whose maintenance is widespread and in which we are all complicit.</p>



<p><strong>The Phenomenon of the Survey</strong></p>



<p>To understand what’s wrong with surveys, we must alternate between critically examining survey …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/12/11/survey-chicken/">https://carcinisation.com/2020/12/11/survey-chicken/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/12/11/survey-chicken/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618712</guid>
            <pubDate>Sun, 03 Jan 2021 02:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Technology in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25618655">thread link</a>) | @telltruth
<br/>
January 2, 2021 | https://elidourado.com/blog/notes-on-technology-2020s/ | <a href="https://web.archive.org/web/*/https://elidourado.com/blog/notes-on-technology-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content"><p>As we start a new decade, it’s a good time to reflect on expectations for the next 10 years. Tyler thinks the Great Stagnation <a href="https://marginalrevolution.com/marginalrevolution/2020/12/why-did-the-great-stagnation-end.html">could be ending</a>. Caleb sees <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">cracks</a>. Noah expresses <a href="https://noahpinion.substack.com/p/techno-optimism-for-the-2020s">techno-optimism</a>. In this post, my aim is not to predict an end or non-end to stagnation. Rather, it is to think through the particulars of how technology could evolve over the next decade. Then we can assess separately whether we should consider it the Roaring 20s or the Boring 20s.</p><p>What would constitute an end to the Great Stagnation? Any precise cutoff will be arbitrary, but for the sake of discussion, let’s say sustained growth in <a href="https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/">utilization-adjusted total factor productivity</a> of 2 percent per year. By comparison, mean utilization-adjusted TFP growth from 1947 through 1972 was 2.1 percent. Since 2005, it has been 0.17 percent. (Note: it is important to use the utilization-adjusted series, as this corrects for the business cycle.)</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a7a8a1d9e4c4d1050c2902966a316436559074f1/cd6b6/img/tfp.png" alt="Total factor productivity in the U.S. since 1947" title="Total factor productivity in the U.S. since 1947"></p><p>Whatever your cutoff for TFP growth, one of my convictions is that scientific breakthroughs alone are not enough to drive an end to the Great Stagnation. TFP only budges when new technologies are adopted at scale, and generally this means products, not just science. Science lays critical groundwork for new technology, but after all the science is done, much work remains. Someone must shepherd the breakthrough to the product stage, where it can actually affect TFP. This means building businesses, surmounting regulatory obstacles, and scaling production.</p><p>With that caveat firmly in mind, what will the next decade bring in terms of meaningful technological change? Here’s what I’m watching.</p><h2 id="biotech-and-health">Biotech and health</h2><p>We are coming off a huge win: two new mRNA COVID vaccines, conceived and brought to market in less than a year. The ability to encode and deploy arbitrary mRNA in our bodies sure seems like a game changer—it allows us to essentially program our cells to make whatever proteins we want. In the case of the COVID vaccines, the vaccine payload instructs our cells to make the coronavirus spike protein, which our immune system then learns to attack. Bert Hubert has a <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">fascinating write-up</a> of the “code” in the vaccine.</p><p>Bringing a brand new vaccine to market in less than a year—using a never-before-applied-in-humans-at-scale technology no less—is a world record, but it could have been even faster. As David Wallace-Wells <a href="https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html">emphasizes</a>, Moderna’s vaccine was designed by January 13. We had it the whole time. Some delay was necessary to determine effective dosing. Some further regulatory delay may have been warranted to ensure the vaccine was safe and to ascertain its efficacy. But as Wallace-Wells indicates, the regulatory outcome was never really in doubt. “None of the scientists I spoke to for this story were at all surprised by either outcome,” he writes. “All said they expected the vaccines were safe and effective all along.”</p><p>What should we make of the fact that all of the scientists knew all along that Moderna’s vaccine would work? The question in my mind is: what other mRNA treatments do we have the whole time? What if I told you Moderna has an <a href="https://www.poz.com/article/experimental-hiv-vaccine-stimulates-production-neutralizing-antibodies">HIV vaccine candidate</a>? HIV lacks SARS-CoV-2’s telltale spike protein and thus may prove a more challenging foe—but don’t you wonder, if we treated the problem with real urgency, whether new mRNA technology could wipe out the AIDS epidemic this decade? I do.</p><p>And mRNA technology can be deployed against more than just viruses. Both Moderna and BioNTech have personalized vaccine candidates targeting cancer. Although called a “cancer vaccine,” the treatment is only administered once the subject has cancer—it isn’t preventative. The companies use an algorithm to analyze the genetic sequences of the tumor and the patient’s healthy cells and predict which molecules could be used to generate a strong immune response against the cancer. “I was actually witnessing the cancer cells shrinking before my eyes,” <a href="https://www.nature.com/articles/d41586-019-03072-8">said</a> Brad Kremer, a melanoma patient who received the BioNTech treatment. So let’s milk mRNA technology for all it’s worth this decade. It can save us from more than just a pandemic.</p><p>What about CRISPR? It is a great example of a technology that has not yet made a meaningful economic contribution. Although the technique for editing DNA was discovered in 2012—and a Nobel Prize was awarded to its two discoverers this year—no treatment using CRISPR has been approved outside of clinical trials. So far, its impact has been limited to making researchers more productive—not a bad thing, to be sure, but not close to CRISPR’s full potential. As trials progress, however, I do think some CRISPR treatments will come online in the next few years, especially those targeting genetic disorders that we have very limited means of otherwise treating.</p><p>DeepMind’s <a href="https://medium.com/cgo-benchmark/deepminds-protein-folding-solution-what-just-happened-279d32e8d0f">protein-folding breakthrough</a> signals a promising decade for the science of proteomics. Most directly, being able to predict protein shapes will enable us to discover drugs more rapidly. Buuuut, because drug trials take many years, we might expect this technology not to really be felt by the general public until the 2030s.</p><p>What DeepMind’s achievement indicates to me the most is that machine learning is actually useful. This might seem obvious, but consider: most applications of machine learning so far—excluding autonomous vehicles, which have themselves not really arrived yet—are toys. I love watching AlphaZero crush Stockfish on YouTube, but chess is literally a game. GPT-3 produced some fun demos. AlphaFold heralds something different—non-toy superhuman performance is now here, and I am interested to see what else it can do. Aside from the aforementioned AVs, I expect it to be applied widely in other areas of biology. Again, it will take a long time for the breakthroughs to trickle down into products, but at least the 2030s should be sick. I mean, not sick. Healthy.</p><p>Let’s talk about life extension, one of my favorite biotech topics. 2020 was a big year for the Conboy Lab at Berkeley, which proved that all the weird past findings about “<a href="https://en.wikipedia.org/wiki/Parabiosis">young blood</a>” extending life were not actually due to any elixir in the blood of children (thank goodness). Rather, the rejuvenating aspects of young blood experiments were due to the dilution of harmful factors in old blood. By mechanically removing plasma and replacing it with saline and enough albumin to replace what was taken out, they diluted aged blood factors in both mice and humans and were able to <a href="https://www.aging-us.com/article/103418/text#fulltext">rejuvenate germ layer tissues</a> and <a href="https://link.springer.com/article/10.1007/s11357-020-00297-8">improve cognition by reducing neuroinflammation</a>.</p><p>These findings are exciting not only because they represent a scientific advance in understanding aging, but also because they herald the first real anti-aging product that could come to market. Therapeutic plasma exchange is FDA-approved (not for aging, but for a bunch of other conditions). I imagine there remain prohibitions on advertising that it can add years to your life, but it is safe, and a doctor can prescribe it off label. It’s also cheap. An automated plasmapheresis machine—which lets you do treatment after treatment—can be bought online for under $3,000. That is less than the cost of a single transfusion of young blood sold by the startup <a href="https://www.ambrosiaplasma.com/">Ambrosia</a>. How long until someone opens a clinic offering plasma dilution? I bet someone tries it in 2021. If it works, people will get over the weirdness, and it could be commonplace by 2030.</p><p>Another longevity product that is about to get hot: aging clocks based on DNA methylation or proteomics. Do you want to know how biologically old you are? Today, for a few hundred dollars, you can get a test that will tell you. As these tests become better and cheaper, self-experimenters are going to have a field day. Doing before-and-after aging tests, anyone who can get their hands on human growth hormone could replicate the protocol used by <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/acel.13028">Fahy et al.</a> to rejuvenate the thymus. As the thymus is a critical element of the immune system, decline of which is a critical factor in aging, this is non-trivial rejuvenation. The Fahy study found that 12 months of treatment created about 2.5 years of epigenetic rejuvenation, with results accelerating in the last quarter of the trial.</p><p>There is a lot more in the <a href="https://www.lifespan.io/road-maps/the-rejuvenation-roadmap/">Rejuvenation Roadmap</a>—dozens of possible life-extending treatments are at various stages of development. There’s a good chance a few senolytic drugs will be approved by the end of the decade. As I noted <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">yesterday at Fortune</a>, we spend less than 1% of the NIH budget on aging biology—we should raise that by a lot.</p><p>Unlike others, I am not-so-bullish on metformin. It does seem to reduce all-cause mortality in Americans, but it may do so because <a href="https://www.liebertpub.com/doi/10.1089/met.2018.0105">88% of Americans are metabolically unhealthy</a>. If you are one of the 12%, and you should strive to be, I don’t think metformin will do much for you.</p><p>One final biotech observation: every year, the Apple Watch gets a new health-related sensor. This year it was blood oxygen, pretty good for detecting if you might have COVID! Fast forward to 2030 and wearables will have at least 10 more health-related sensors than they do today. Some no-brainers are body temperature, blood pressure, and blood glucose sensors. What will the other 7 be? At some point, it becomes possible to replace a lot of primary care with continuous monitoring. A few smart algorithms to provide simple medical advice could improve population-level health without much cost. More data could also yield faster, more accurate, and of course more remote diagnoses when you do have to see a doctor.</p><p>There is a lot in biotech that is promising right now, but in more than any other field, it is important not to be seduced by the sexy headlines showing rapid scientific progress. Don’t get complacent. Biology is proceeding faster than medical productivity because a lot of the wonderful discoveries are not being translated into approved treatments and products at a decent rate. Let’s salute and cheer for the discoveries, but spare many thoughts for the entrepreneurs trying to bring treatments to market.</p><h2 id="energy">Energy</h2><p>The 2010s were the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elidourado.com/blog/notes-on-technology-2020s/">https://elidourado.com/blog/notes-on-technology-2020s/</a></em></p>]]>
            </description>
            <link>https://elidourado.com/blog/notes-on-technology-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618655</guid>
            <pubDate>Sun, 03 Jan 2021 02:02:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tritris]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25618535">thread link</a>) | @beefman
<br/>
January 2, 2021 | https://goel25.github.io/tritris/ | <a href="https://web.archive.org/web/*/https://goel25.github.io/tritris/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="title">
            
            <div><p>
                Welcome to Tritris!
                <br>
                Use the pieces to fill as many lines as possible before the game
                gets too fast and you top out!
                </p><p>
                
                Click the <b>"How to Play"</b> button for controls and
                strategies. </p><p>
                
                <a href="https://youtu.be/HMkfj1OJ08Q">
                    <b>Watch the video!</b>
                    <img width="30" src="https://goel25.github.io/tritris/assets/youtubeLogo.png">
                </a></p><p>
                
                <label>Sound</label>
                </p></div>
        </div><div id="tutorial">
            
            <hr>
            <h3>Controls</h3>
            <p>
                Use the arrow keys to move left and right. Press down to soft
                drop. Use Z and X to rotate. Press enter to pause/unpause. Press
                escape to quick reset.
            </p>
            <hr>
            <h3>Pieces</h3>
            <p>
                There are 7 pieces total. There are 6 pieces made out of every
                possible configuration of 3 triangles, and 1 piece made out of a
                single triangle, which will always spawn in groups of 3.
                <img src="https://goel25.github.io/tritris/assets/allPieces.png">
            </p>
            <hr>
            <h3>Mechanics</h3>
            <p>
                The mechanics are very similar to NES Tetris. It uses the same
                DAS, entry delay, and level speed timings.<br>
                All of the pieces are made out of 3 connected right triangles.
                There is also a white, single triangle piece which can be used
                to fix holes in your stack. It will always come out 3 at a time.
                The single triangle is also special, lines will only be cleared
                once they have all been placed. This allows you to fill 3 lines
                to score a Tritris!
            </p>
            <hr>
            <h3>Phasing</h3>
            <p>
                <b>IMPORTANT - Since the release of the Youtube video, phasing
                    has become easier. There are no longer any frame-perfect
                    tricks. Instead, all phases can be performed by holding each
                    key (rotate can now be held to become "charged").</b>
                <br>
                One of the most unique mechanics of Tritris is phasing. A piece
                will always move to the next location as long as the next
                location is valid (no intersecting triangles). By moving a piece
                in multiple ways at the same time, pieces are able to do many
                types of tucks and spins. Below are a few examples.
            </p>
            <div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/down.gif"></p><p>
                        The pieces are able to easily move down into an empty
                        space.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/downRotate.gif"></p><p>
                        For the bottom right triangle, X (rotate) is held once
                        above the desired position.
                        <b>Due to the phasing update, down does not need to be pressed.</b>
                        Once all 3 triangles are placed, the line clears.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/downMove.gif"></p><p>
                        Left or right are held when the piece is above the
                        desired position, and when the piece moves down, it also
                        moves horizontally.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/multiple.gif"></p><p>Here are a few examples of some phases!</p>
                </div>
            </div>
            <br>
            <hr>

            <h3>Scoring</h3>
            <div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/tritris.gif"></p><p>A Tritris is scored!</p>
                </div>
                <p>
                    In Tritris, clearing 4 lines at a time is not possible, so
                    the highest score value is obtained from 3 lines at a time,
                    a Tritris. This can only be achieved by settings up 3 rows,
                    each missing only one triangle, then placing a single
                    triangle in each row. Once all triangles are placed, the
                    rows clear and a Tritris is scored!
                    <br>
                    A triple is equivalent to a Tetris in NES Tetris, a double
                    is equivalent to a triple, and a single is equivalent to a
                    double.
                </p>
            </div>

            <hr>
            <br>
            </div></div>]]>
            </description>
            <link>https://goel25.github.io/tritris/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618535</guid>
            <pubDate>Sun, 03 Jan 2021 01:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Repl-Driven Programming]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25618457">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://mikelevins.github.io/2020/12/18/repl-driven.html | <a href="https://web.archive.org/web/*/https://mikelevins.github.io/2020/12/18/repl-driven.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mikelevins.github.io/2020/12/18/repl-driven.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618457</guid>
            <pubDate>Sun, 03 Jan 2021 01:25:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Software Engineering with Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618391">thread link</a>) | @kawera
<br/>
January 2, 2021 | https://merely-useful.github.io/py-rse/index.html | <a href="https://web.archive.org/web/*/https://merely-useful.github.io/py-rse/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">

<div id="welcome">

<blockquote>
<p>It’s still magic even if you know how it’s done.</p>
<p>— Terry Pratchett</p>
</blockquote>
<p>Software is now as essential to research as telescopes, test tubes, and reference libraries.
This means that researchers <em>need</em> to know how to build, check, use, and share programs.
However,
most introductions to programming focus on developing commercial applications,
not on exploring problems whose answers aren’t yet known.
Our goal is to show you how to do that,
both on your own and as part of a team.</p>
<p>We believe every researcher should know
how to write short programs that clean and analyze data in a reproducible way
and how to use version control to keep track of what they have done.
But just as some astronomers spend their careers designing telescopes,
some researchers focus on building the software that makes research possible.
People who do this are called <a href="https://merely-useful.github.io/py-rse/glossary.html#rse">research software engineers</a>;
the aim of this book is to get you ready for this role by helping you go from
writing code for yourself to creating tools that help your entire field advance.</p>
<div id="intro-big-picture">
<h2> The Big Picture</h2>
<p>Our approach to research software engineering is based on three related concepts:</p>
<ul>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#open_science">Open science</a>: Making data, methods, and results
freely available to all by publishing them under <a href="https://merely-useful.github.io/py-rse/glossary.html#open_license">open
licenses</a>.</p></li>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#reproducible_research">Reproducible research</a>: Ensuring that anyone
with access to the data and software can feasibly reproduce results, both to
check them and to build on them.</p></li>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#sustainable_software">Sustainable software</a>: The ease with which to
maintain and extend it rather than to replace it. Sustainability isn’t
just a property of the software: it also depends on the skills and culture
of its users.</p></li>
</ul>
<p>People often conflate these three ideas,
but they are distinct.
For example,
if you share your data and the programs that analyze it,
but don’t document what steps to take in what order,
your work is open but not reproducible.
Conversely,
if you completely automate your analysis,
but your data is only available to people in your lab,
your work is reproducible but not open.
Finally,
if a software package is being maintained by a couple of post-docs
who are being paid a fraction of what they could earn in industry
and have no realistic hope of promotion because their field doesn’t value tool building,
then sooner or later it will become <a href="https://merely-useful.github.io/py-rse/glossary.html#abandonware">abandonware</a>,
at which point openness and reproducibility become less relevant.</p>
<p>Nobody argues that research should be irreproducible or unsustainable,
but “not against it” and actively supporting it are very different things.
Academia doesn’t yet know how to reward people for writing useful software,
so while you may be thanked,
the effort you put in may not translate into academic job security or decent pay.</p>
<p>Some people worry that if they make their data and code publicly available,
someone else will use it and publish a result they could have come up with themselves.
This is almost unheard of in practice,
but that doesn’t stop it being used as a scare tactic.
Other people are afraid of looking foolish or incompetent by sharing code that might contain bugs.
This isn’t just <a href="https://merely-useful.github.io/py-rse/glossary.html#impostor_syndrome">impostor syndrome</a>:
members of marginalized groups are frequently judged more harshly than others,
so being wrong in public is much riskier for them.</p>
<p>With this course, we hope to give researchers the tools and knowledge to be
better research software developers, to be more efficient in their work, make
less mistakes, and work more openly and reproducibly.
We hope that by having more researchers with these skills and knowledge,
research culture can improve to address the issues raised above.</p>
</div>
<div id="intro-personas">
<h2> Intended Audience</h2>
<p>This book is written for researchers who are already using Python for their data analysis,
but who want to take their coding and software development to the next level.
You don’t have to be highly proficient with Python,
but you should already be comfortable doing things like reading data from files
and writing loops, conditionals, and functions.
The following personas are examples of the types of people
that are our target audience.</p>
<dl>
<dt>Amira Khan</dt>
<dd>completed a master’s in library science five years ago
and has since worked for a small aid organization.
She did some statistics during her degree,
and has learned some R and Python by doing data science courses online,
but has no formal training in programming.
Amira would like to tidy up the scripts, data sets, and reports she has created
in order to share them with her colleagues.
These lessons will show her how to do this.
</dd>
<dt>Jun Hsu</dt>
<dd>completed an <a href="https://www.insightdatascience.com/">Insight Data Science</a> fellowship last year after doing a PhD in Geology
and now works for a company that does forensic audits.
He uses a variety of machine learning and visualization packages,
and would now like to turn some of his own work into an open source project.
This book will show him how such a project should be organized
and how to encourage people to contribute to it.
</dd>
<dt>Sami Virtanen</dt>
<dd>became a competent programmer during a bachelor’s degree in applied math
and was then hired by the university’s research computing center.
The kinds of applications they are being asked to support
have shifted from fluid dynamics to data analysis;
this guide will teach them how to build and run data pipelines
so that they can pass those skills on to their users.
</dd>
</dl>
</div>
<div id="intro-syllabus">
<h2> What You Will Learn</h2>
<p>Rather than simply providing reference material about good coding practices,
the book follows Amira and Sami as they work together to write an actual software package
to address a real research question.
The data analysis task that we focus on
relates to a fascinating result in the field of quantitative linguistics.
<a href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s Law</a> states that the second most common word in a body of text
appears half as often as the most common,
the third most common appears a third as often, and so on.
To test whether Zipf’s Law holds for a collection of classic novels
that are freely available from <a href="https://www.gutenberg.org/">Project Gutenberg</a>,
we write a software package that counts and analyzes the word frequency distribution
in any arbitrary body of text.</p>
<p>In the process of writing and publishing a Python package to verify Zipf’s Law,
we will show you how to:</p>
<ul>
<li>Organize small and medium-sized data science projects.</li>
<li>Use the Unix shell to efficiently manage your data and code.</li>
<li>Write Python programs that can be used on the command line.</li>
<li>Use Git and GitHub to track and share your work.</li>
<li>Work productively in a small team where everyone is welcome.</li>
<li>Use Make to automate complex workflows.</li>
<li>Enable users to configure your software without modifying it directly.</li>
<li>Test your software and know which parts have not yet been tested.</li>
<li>Find, handle, and fix errors in your code.</li>
<li>Publish your code and research in open and reproducible ways.</li>
<li>Create Python packages that can be installed in standard ways.</li>
</ul>
</div>
<div id="intro-using">
<h2> Using this Book</h2>
<p>This book was written to be used as the material for a (potentially) semester
long course at the university level,
although it can also be used for independent self-study.
Participatory live-coding is the anticipated style for teaching the material,
rather than lectures simply talking about the code presented <span>(Brown and Wilson <a href="https://merely-useful.github.io/py-rse/references.html#ref-Brow2018" role="doc-biblioref">2018</a>; Wilson <a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2018" role="doc-biblioref">2019</a><a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2018" role="doc-biblioref">a</a>)</span>.
The chapters and their content are generally designed to be used in the order
given.</p>
<p>Chapters are structured with the introduction at the start, content in the middle,
and exercises at the end. Callout boxes are interspersed throughout the content
to be used as a supplement to the main text,
but not a requirement for the course overall.
Early chapters have many small exercises;
later chapters have fewer but larger exercises.
In order to break up long periods of live-coding while teaching,
it may be preferable to stop and complete some of the exercises
at key points throughout the chapter,
rather than waiting until the end.
Possible exercise solutions are provided (Appendix&nbsp;<a href="https://merely-useful.github.io/py-rse/solutions.html#solutions">A</a>),
in addition to learning objectives (Appendix <a href="https://merely-useful.github.io/py-rse/objectives.html#objectives">B</a>)
and key points (Appendix <a href="https://merely-useful.github.io/py-rse/keypoints.html#keypoints">C</a>) for each chapter.</p>
</div>

<div id="intro-ack">
<h2> Acknowledgments</h2>
<p>This book owes its existence to
everyone we met through <a href="https://carpentries.org/">The Carpentries</a>.
We are also grateful to <a href="https://www.insightdatascience.com/">Insight Data Science</a> for sponsoring the early stages of this work,
to the authors of <span>Noble (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Nobl2009" role="doc-biblioref">2009</a>)</span>, <span>Haddock and Dunn (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Hadd2010" role="doc-biblioref">2010</a>)</span>, <span>Wilson et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2014" role="doc-biblioref">2014</a>)</span>, <span>Scopatz and Huff (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Scop2015" role="doc-biblioref">2015</a>)</span>, <span>Taschuk and Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Tasc2017" role="doc-biblioref">2017</a>)</span>, <span>Wilson et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2017" role="doc-biblioref">2017</a>)</span>, <span>Brown and Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Brow2018" role="doc-biblioref">2018</a>)</span>, <span>Devenyi et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Deve2018" role="doc-biblioref">2018</a>)</span>, <span>Sholler et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Shol2019" role="doc-biblioref">2019</a>)</span>, <span>Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2019" role="doc-biblioref">2019</a><a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2019" role="doc-biblioref">b</a>)</span>
and to everyone who has contributed, including Madeleine Bonsma-Fisher,
Jonathan Dursi,
Christina Koch,
Sara Mahallati,
Brandeis Marshall,
and Elizabeth Wickes.</p>
<ul>
<li><p>Many of the explanations and exercises in Chapters&nbsp;<a href="https://merely-useful.github.io/py-rse/bash-basics.html#bash-basics">2</a>–<a href="https://merely-useful.github.io/py-rse/bash-advanced.html#bash-advanced">4</a>
have been adapted from Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/shell-novice/"><em>The Unix Shell</em></a>.</p></li>
<li><p>Many of explanations and exercises in Chapters&nbsp;<a href="https://merely-useful.github.io/py-rse/git-cmdline.html#git-cmdline">6</a> and&nbsp;<a href="https://merely-useful.github.io/py-rse/git-advanced.html#git-advanced">7</a>
have been adapted from Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/git-novice/"><em>Version Control with Git</em></a> and an
<a href="https://uw-madison-datascience.github.io/git-novice-custom/">adaptation/extension of that lesson</a> maintained by
the University of Wisconsin-Madison Data Science Hub.</p></li>
<li><p>Chapter&nbsp;<a href="https://merely-useful.github.io/py-rse/automate.html#automate">9</a> is based on Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/make-novice/"><em>Automation and Make</em></a>
and on Jonathan Dursi’s
<a href="https://github.com/ljdursi/make_pattern_rules"><em>Introduction to Pattern Rules</em></a>.</p></li>
<li><p>Chapter&nbsp;<a href="https://merely-useful.github.io/py-rse/packaging.html#packaging">14</a> is based in part on <a href="https://python-102.readthedocs.io/"><em>Python 102</em></a>
by Ashwin Srinath.</p></li>
</ul>
</div>
<div id="dedications">
<h2> Dedications</h2>
<div><p>To David Flanders<br>
who taught me so much about growing and sustaining coding communities.<br>
— Damien</p><p>
&nbsp;
To the UofT Coders Group<br>
who taught us much more than we taught them.<br>
— Luke and Joel</p><p>
&nbsp;
To my parents Judy and John<br>
who taught me to love books and everything I can learn from them.<br>
— Kate</p><p>
&nbsp;
To Joshua.<br>
— Charlotte</p><p>
&nbsp;
To Brent Gorda<br>
without whom none of this would have happened.<br>
— Greg</p><p>
&nbsp;
All royalties from this book are being donated to The Carpentries,<br>
an organization that teaches foundational coding and data science
skills<br>
to researchers worldwide.</p></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://merely-useful.github.io/py-rse/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618391</guid>
            <pubDate>Sun, 03 Jan 2021 01:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encrypted Backup Shootout]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25618346">thread link</a>) | @andrewchambers
<br/>
January 2, 2021 | https://acha.ninja/blog/encrypted_backup_shootout/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/encrypted_backup_shootout/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Recently I have been spending time on improving the performance of <a href="https://github.com/andrewchambers/bupstash">bupstash</a> (my encrypted backup tool), and wanted to compare it to some existing tools to try and find its relative performance in the backup tool landscape.</p>
<p>This post compares <a href="https://github.com/andrewchambers/bupstash">bupstash</a>, <a href="https://restic.net/">restic</a>, <a href="https://www.borgbackup.org/">borg backup</a> and plain old tar + gzip + GPG across a series of simple benchmarks.</p>
<p>What do all these tools have in common?</p>
<ul>
<li>They encrypt data at rest.</li>
<li>They compress data.</li>
<li>They have some form of incremental and/or deduplicated snapshotting.</li>
<li>They are all pretty great backup systems.</li>
</ul>
<p>Feel free to checkout the project websites to learn more, let’s get to the benchmarks.</p>
<h2 id="benchmarks">Benchmarks</h2>
<p>For these tests we are using the following versions of the given software:</p>
<ul>
<li>GNU tar 1.32 + gzip 1.10 + GPG 2.2.23</li>
<li>Bupstash 0.6.1</li>
<li>Borg 1.1.14</li>
<li>Restic 0.11.0</li>
</ul>
<p>The test machine has an AMD Ryzen Threadripper 1950X 16-Core Processor with 16 GB of ram, and an NVMe SSD hard drive. It is probably best to simply compare results relatively, as reproducing my test environment exactly would be difficult.</p>
<p>The scripts I used for my benchmarking can be found <a href="https://github.com/andrewchambers/EncryptedBackupShootout">here</a>, though they will definitely need tweaking for your environment.</p>
<h3 id="deduplication-and-compression">Deduplication and compression</h3>
<p>For this benchmark we take 20 different consecutive versions of the linux kernel source code and add them all to the same directory, we then create a snapshot and measure the size of the resulting tarball/repository.</p>
<p>The linux kernel versions chosen for this test are all the consecutive git commits preceeding version 5.9, with the resulting directory containing 21 GB of uncompressed files.</p>
<p><img src="https://acha.ninja/img/Test_Snapshot_Size.svg" alt="plot"></p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Size</th>
<th>Compression Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash</td>
<td>0.378 GB</td>
<td>55x</td>
</tr>
<tr>
<td>borg</td>
<td>0.476 GB</td>
<td>49x</td>
</tr>
<tr>
<td>restic</td>
<td>1.5 GB</td>
<td>14x</td>
</tr>
<tr>
<td>tar + gzip + gpg</td>
<td>3.6 GB</td>
<td>5.8x</td>
</tr>
</tbody>
</table>
<p>This benchmark shows the advantage the more sophisticated tools have over plain tarballs, they all have extremely good compression ratios when similar data is added multiple times to
a backup repository.</p>
<h3 id="creating-a-fresh-directory-snapshot">Creating a fresh directory snapshot</h3>
<p>For this benchmark we are snapshotting a copy of the linux
5.9.8 source code.</p>
<p>The directory we are snapshotting is 1.1 GB comprised of 74725 files and directories.</p>
<p>The snapshots are all made to tmpfs so hopefully does not measure delays introduced by the network or disk activity.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash put</td>
<td>3.939 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.026 s</td>
</tr>
<tr>
<td>borg create</td>
<td>13.831 s</td>
</tr>
<tr>
<td>tar | gzip | gpg</td>
<td>24.505 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the clear winner here for raw snapshotting speed.</p>
<h3 id="sending-a-fresh-snapshot-to-a-remote-server">Sending a fresh snapshot to a remote server</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh. This benchmark should only be considered an approximation of the effect latency has on the tool performance as it is so dependent on network speeds.</p>
<p>At the time of benchmarking my connection to the remote server can be summarized as follows:</p>
<ul>
<li>server -&gt; client 10MiB/s</li>
<li>client -&gt; client 2.5MiB/s</li>
<li>ping 32 milliseconds</li>
</ul>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Remote_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar | gzip | gpg | ssh</td>
<td>72.640 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>121.817 s</td>
</tr>
<tr>
<td>borg create</td>
<td>143.942 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>414.859 s</td>
</tr>
</tbody>
</table>
</details>
<p>Plain tar takes the win, Restic performs poorly here, it has a far more latency-sensitive upload protocol.</p>
<h3 id="creating-an-incremental-directory-snapshot">Creating an incremental directory snapshot</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark, except now we measure the time for an incremental snapshot using the builtin caching mechanism of the tools. What this means is each tool keeps a record of what files it has already sent, and is able to
skip doing that work again.</p>
<p><img src="https://acha.ninja/img/Time_for_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg</td>
<td>0.209 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.394 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>3.916 s</td>
</tr>
<tr>
<td>borg create</td>
<td>7.724 s</td>
</tr>
</tbody>
</table>
</details>
<p>Incremental tar is the clear winner here, but why are the other tools slower? I think this is mainly because the other tools present each snapshot to the user as a full backup and thus do extra work to spare the end user from managing incremental backups manually.</p>
<p>It is also interesting to me that <code>bupstash put</code> is an order of magnitude faster than the other similar tools, though I currently can not explain clearly why that may be the case.</p>
<h3 id="sending-an-incremental-snapshot-to-a-remote-server">Sending an incremental snapshot to a remote server</h3>
<p>This benchmark is the same as the incremental local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh.</p>
<p>Benchmark conditions are the same as the fresh remote snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg | ssh</td>
<td>0.779 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.999 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.140 s</td>
</tr>
<tr>
<td>borg create</td>
<td>10.772 s</td>
</tr>
</tbody>
</table>
</details>
<p>These results match closely with the local incremental snapshots.</p>
<h3 id="restoring-a-snapshot">Restoring a snapshot</h3>
<p>In this benchmark we will restore the snapshot made in the fresh local snapshot benchmark to tmpfs. This is what measuring what happens when you need to do a bulk disaster recovery from your backup repository.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash get | tar -x</td>
<td>2.712 s</td>
</tr>
<tr>
<td>gpg -d | gzip -d | tar -x</td>
<td>4.449 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>4.890 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>9.694 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the winner for restoring backups.</p>
<h3 id="restoring-a-snapshot-from-a-remote-server">Restoring a snapshot from a remote server</h3>
<p>In this benchmark we will restore the snapshot made in the fresh remote snapshot benchmark to tmpfs. The main difference from the previous benchmark is the introduction of
an internet connection between the backup repository and restore point.</p>
<p>Network conditions are the same as the fresh network snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>ssh | gpg -d | gzip -d | tar -x</td>
<td>28.082 s</td>
</tr>
<tr>
<td>bupstash get | tar -x</td>
<td>48.893 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>52.931 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>146.098 s</td>
</tr>
</tbody>
</table>
</details>
<p>Interestingly, the introduction of the network pushed tar ahead of bupstash for backup restoration - this is something I am very interested in investigating further.</p>
<h3 id="pruning-an-old-backup">Pruning an old backup</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository on the same computer. For this test we generate a backup repository with 50 different snapshots of different versions of the linux kernel source code and then time how long it takes to remove one of the snapshots. This benchmark simulates
cycling old backups out of your backup repository when you no longer need them.</p>
<p>Tar with incremental backups does not easily support pruning of old backups, so does not participate in this benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>0.0386 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>0.497 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>2.030 s</td>
</tr>
</tbody>
</table>
</details>
<p>The bupstash garbage collector is an order of magnitue faster than both restic and borg at pruning the backup repository.</p>
<h3 id="pruning-an-old-backup-on-a-remote-server">Pruning an old backup on a remote server</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository stored on a remote server. The remote server is the same as the one used in fresh remote snapshot benchmark, and the test data is the same as the local prune bench mark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>2.137 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>3.111 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>145.540 s</td>
</tr>
</tbody>
</table>
</details>
<p>Once again restic suffers the worst from introduced network latency of all the tools.</p>
<h3 id="approximate-peak-client-side-ram-usage">Approximate peak client side ram usage</h3>
<p>For this benchmark we repeat the fresh snapshot benchmark, but measure the peak client ram usage (RSS) as reported by the ‘time’ command. For tar we approximate this by summing the peak memory usage across tar, gpg and gzip.</p>
<p><img src="https://acha.ninja/img/Test_Peak_Memory_Usage.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Peak Memory Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar + gzip + GPG</td>
<td>10.312 MB</td>
</tr>
<tr>
<td>bupstash</td>
<td>18.192 MB</td>
</tr>
<tr>
<td>borg</td>
<td>96.696 MB</td>
</tr>
<tr>
<td>restic</td>
<td>191.252 MB</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is very memory-efficient compared to restic and borg, but ultimately loses out to the simplicity of tar + gzip + GPG.</p>
<h2 id="conclusions-and-discussion">Conclusions and discussion</h2>
<p>GNU Tar + gzip + gpg is an excellent encrypted backup option and performed better than I expected. I think tar and gpg is still a great choice for users who prefer to DIY their own backup scripts. With this in mind, we must ask what are the problems with tar that the other tools address? My opinion is that managing
incremental backups, deduplication, pruning, and searching backups are far more difficult when using incremental tar compared to borg/restic/bupstash. With incremental tar, it quickly becomes quite hard to track which incremental
tarballs depend on eachother and you often need to periodically do full snapshots - losing most of the speed benefits.</p>
<p>As the biased author of bupstash, I am also pleased with how it has performed and hope I can push it further in the future. Restic, while fast at local operation, seems to trail the other tools when network latency is thrown into the mix. Borg is an all-around great tool and performed very well.</p>
<p>I can see both strengths and room for improvement in each of the tools tested, and encourage everyone to give them a try for yourself if you haven’t already.</p>
<p>As always, thank you for your time and see you next time :).</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/encrypted_backup_shootout/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618346</guid>
            <pubDate>Sun, 03 Jan 2021 01:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychopathy and the Origins of Totalitarianism]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618333">thread link</a>) | @haivri
<br/>
January 2, 2021 | https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		
		

				
		
		
		<div>

			
			<div>

				
				<div id="content">

					
	<div id="primary">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-3890">

					
					<div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p>Many of the greatest horrors of the history of humanity owe their occurrence solely to the establishment and social enforcement of a false reality. With gratitude to the Catholic philosopher Josef Pieper and his important 1970 essay “Abuse of Language, Abuse of Power” for the term and idea, we can refer to these alternative realities as ideological <em>pseudo-realities</em>.</p>
<p>Pseudo-realities, being false and unreal, will always generate tragedy and evil on a scale that is at least proportional to the reach of their grip on power—which is their chief interest—whether social, cultural, economic, political, or (particularly) a combination of several or all of these. So important to the development and tragedies of societies are these pseudo-realities when they arise and take root that it is worth outlining their basic properties and structure so that they can be identified and properly resisted before they result in sociopolitical calamities—up to and including war, genocide, and even civilizational collapse, all of which can take many millions of lives and can ruin many millions more in the vain pursuit of a fiction whose believers are, or are made, sufficiently intolerant.</p>
<h3 id="the-nature-of-pseudo-realities">The Nature of Pseudo-realities</h3>
<p>Pseudo-realities are, simply put, false constructions of reality. It is hopefully obvious that among the features of pseudo-realities is that they must present a plausible but deliberately wrong understanding of reality. They are cult “realities” in the sense that they are the way that members of cults experience and interpret the world—both social and material—around them. We should immediately recognize that these deliberately incorrect interpretations of reality serve two related functions. First, they are meant to mold the world to accommodate small proportions of people who suffer pathological limitations on their abilities to cope with reality as it is. Second, they are designed to replace all other analyses and motivations with power, which these essentially or functionally psychopathic individuals will contort and deform to their permanent advantage so long as their pseudo-real regime can last.</p>
<p>Pseudo-realities are always social fictions, which, in light of the above, means political fictions. That is, they are maintained not because they are true, in the sense that they correspond to reality, either material or human, but because a sufficient quantity of people in the society they attack either believe them or refuse to challenge them. This implies that pseudo-realities are<em> linguistic phenomena</em> above all else, and where power-granting linguistic distortions are present, it is likely that they are there to create and prop up some pseudo-reality. This also means that they require power, coercion, manipulation, and eventually force to keep them in place. Thus, they are the natural playground of psychopaths, and they are enabled by cowards and rationalizers. Most importantly, pseudo-realities do not attempt to describe reality as it is but rather as it “should be,” as determined by the relatively small fraction of the population who cannot bear living in reality unless it is bent to enable their own psychopathologies, which will be projected upon their enemies, which means all normal people.</p>
<p>Normal people do not accept pseudo-reality and interpret reality more or less accurately, granting the usual biases and limitations of human perspective. Their common heuristic is called<em> common sense</em>, though much more refined forms exist in the uncorrupted sciences. In reality, both of these are handmaidens of power, but in pseudo-realities, this is inverted. In pseudo-reality, common sense is denigrated as bias or some kind of false consciousness, and science is replaced by a scientism that is a tool of power itself. For all his faults and the faults of his philosophy (which enable much ideological pseudo-reality), Michel Foucault warned us about this abuse quite cogently, especially under the labels “biopower” and “biopolitics.” These accusations of bias and false consciousness are, of course, projections of the ideological pseudo-realist, who, by sheer force of rhetoric, transforms limitations on power into applications of power and thus his own applications of power into liberation from it. Foucault, for any insight he provided, is also guilty of this charge.</p>
<p>It must be observed that people who accept pseudo-realities as though they are “real” are no longer normal people. They perceive pseudo-reality in place of reality, and the more thoroughly they take on this delusional position, the more functional psychopathy they necessarily exhibit and thus the less normal they become. Importantly, normal people consistently and consequentially fail to realize this about their reprogrammed neighbors. Perceiving them as normal people when they are not, normal people will reliably misunderstand the motivations of ideological pseudo-realists—power and the universal installation of their own ideology so that everyone lives in a pseudo-reality that enables their pathologies—usually until it is far too late.</p>
<p>As a result of this failure of perspective, many particularly epistemically and morally open normal people will reinterpret the claims of pseudo-reality into something that is plausible in reality under the usual logic and morals that guide our thinking, and this reinterpretation will work to the benefit of the pseudo-realists who have ensnared them. This sort of person, who stands between the real world and the pseudo-real are useful idiots to the ideology, and their role is to generate copious amounts of epistemic and ethical camouflage for the pseudo-realists. This phenomenon is key to the success, spread, and acceptance of pseudo-realities because without it very few people outside of small psychologically, emotionally, or spiritually unwell people would accept a pseudo-reality as if it is a superior characterization of the genuine article. Clearly, the more plausible the account of pseudo-reality on offer, the stronger this effect will be, and the more power the ideologues who believe in it will be able to accrue.</p>
<p>Pseudo-realities may have any degree of plausibility in their distorted descriptions of reality, and thus may recruit different numbers of adherents. They are often said to be accessible only by applying a “theoretical lens,” awakening a specialized “consciousness,” or by means of some pathological form of faith. Whether by “lens,” “consciousness,” or “faith,” these intellectual constructs exist to make the pseudo-reality seem more plausible, to drag people into participating in it against their will, and to distinguish those who “can see,” “are awake,” or “believe” from those who cannot or, as it always eventually goes, <em>will not</em>. That is, they are the pretext to tell people who inhabit reality instead of pseudo-reality that they’re not looking at “reality” correctly, which means as pseudo-reality. This will typically be characterized as a kind of<em> willful ignorance</em> of the pseudo-reality, which will subsequently be described paradoxically as unconsciously maintained. Notice that this puts the burden of epistemic and moral responsibility on the person inhabiting reality, not the person positing its replacement with an absurd pseudo-reality. This is a key functional manipulation of pseudo-realists that must be understood. The ability to recognize this phenomenon when it occurs and to resist it is, at scale, the life and death of civilizations.</p>
<p>Adoption of a pseudo-reality tends to hinge upon a lack of ability or will to question, doubt, and reject them and their fundamental presuppositions and premises of the pseudo-reality. Therefore, the “logical” and “moral” systems that operate within the pseudo-reality will always seek to manufacture this failure wherever they can, and successful pseudo-realist attacks will evolve these features like a social virus until their effectiveness is very high. This deficiency is often the direct result of mental illness, usually paranoia, schizoidia, anxiety, or psychopathy, however, so maintaining and manufacturing these states in themselves and normal people is strongly incentivized by the false “logic” and false “morality” of the ideological pseudo-reality. That is, the methods and means applied in service to a pseudo-reality will create and manipulate psychological weaknesses in people to get them to carry water for a destructive lie. The nicer, more tolerant, and more charitable a community is, supposing it lacks the capacity to spot these counterfeits early on, the more susceptible its members will tend to be to these manipulations.</p>
<h3 id="pseudo-realities-and-power">Pseudo-realities and Power</h3>
<p>The ultimate purpose of creating a pseudo-reality is power, which the constructed pseudo-reality grants in many ways. Though these means are many, we should name a few. First, the pseudo-reality is always constructed such that it structurally advantages those who accept it over those who do not, frequently by overt double standards and through moral-linguistic traps. Double standards in this regard will always favor those who accept pseudo-reality as reality and will always disfavor those who seek the truth. An ideological pseudo-reality must displace reality in a sufficient population to grant itself power to succeed in its goals. Linguistic traps will often employ strategic double meanings of words, often by strategic redefinition (creating a <em>motte and bailey</em>), will beg the question in ways that forces people to participate in the pseudo-reality to respond (often by <em>Aufhebung</em>-style, i.e., Hegelian, dialectical traps), or will begin with an assumption of guilt and demand proof of innocence such that denial or resistance is taken as proof of guilt of some moral crime against the moral system that serves the pseudo-reality (a <em>kafkatrap</em>). Demands will be made with sufficient …</p></section></div></div></article></main></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</a></em></p>]]>
            </description>
            <link>https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618333</guid>
            <pubDate>Sun, 03 Jan 2021 01:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Golang for You]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618264">thread link</a>) | @gurjeet
<br/>
January 2, 2021 | https://gurjeet.singh.im/blog/no-golang-for-you | <a href="https://web.archive.org/web/*/https://gurjeet.singh.im/blog/no-golang-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The blog post <a href="https://fasterthanli.me/articles/i-want-off-mr-golangs-wild-ride">“I want off Mr. Golang’s Wild Ride”</a> by Amos incited
me to write a comment on its <a href="https://news.ycombinator.com/item?id=25616593">HN</a> submission page. But as the comment ran 5
paragraphs long, I have turned it into this blog post.</p>

<p>It is a well written and in-depth look at the rot inside the Golang ecosystem.
Make sure to read to the end and notice that the rot started at the core
contributors level.</p>

<p>Golang’s tagline, from their <a href="https://github.com/golang/go">repository</a>, is “Go is an open source
programming language that makes it easy to build simple, reliable, and efficient
software.”</p>

<p>Reading this post by Amos should make it clear to you that Golang has succeeded
ONLY in the “simple” part of the claim; unless written with extreme care,
programs written in Golang are neither reliable, nor efficient.</p>

<p>Amos presents some examples of why I have disliked Golang since the beginning.
After having used Golang for a few years seriously, I disliked it enough to
start a fork of the language named <a href="https://github.com/gurjeet/gofy/tree/gofy">GoFY</a>. I named the language as such
because, since the beginning when I saw some of initial presentations by Rob
Pike specifically, and some others’ presentations and blog posts generally, they
had an air of ego when dismissing others’ opinions and concerns, and appeared to
say “these are our decisions, that is how it is, and if you don’t like it, Go
F*** Yourself”. So the project name was a GoFY to them back, from me.</p>

<p>I’m sure it looks a great language from afar, and for newcomers. But as a
seasoned developer who has seen a few other languages in thier lifetime, you
will quickly begin to see the problems with the language and the ecosystem
around it.  The astute among you may notice that in my <a href="https://gurjeet.singh.im/blog/persistence-perseverance">post yesterday</a> I
did not claim to be an expert in Golang; it’s hard to be an expert in something
that’s fragile, flaky and full of special cases. For the same reason I
never took up using MySQL; I have heard enough stories of its flakiness and
special cases that it never looked like a solid technology to me. I openly and
whole-heartedly recommend learning and using <a href="https://www.postgresql.org/">Postgres</a> to anyone who would
listen.</p>

<p>Fortunately I did not invest any more time in it other than to document a few
times in section <a href="https://github.com/gurjeet/gofy/tree/gofy#gofy-desired-differences">“GoFY Desired Differences”</a> as to what I would
like to see different in the GoFY language, which in turn would make it better
than Golang, at least for long-time systems developers like myself. I am glad I
didn’t burn any oil on it because creating a new language, even a fork, is
neither easy nor quick.</p>


  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gurjeet.singh.im/blog/no-golang-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618264</guid>
            <pubDate>Sun, 03 Jan 2021 00:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Work, a Pictorial Essay]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618219">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://joinmarket.me/blog/blog/pow-a-pictorial-essay/ | <a href="https://web.archive.org/web/*/https://joinmarket.me/blog/blog/pow-a-pictorial-essay/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>In the modern nation state, courts ("justice") operate with the threat of violence. The exact way a dispute is settled varies (jury, single judge, etc.), but the "finality" of the resolution they provide is based on the fact that the state asserts the final say, and if you don't agree, it doesn't matter, because they have men with guns. Importantly, they don't just have <em>some</em> men with guns (that's something <em>you</em> might have, too), they have an overwhelming number of men and increasingly large guns depending on how much you don't want to accept their say.</p>
<p>If you are thinking "that's a stupidly over-simplified way of thinking about modern justice systems", then that's fine; a lot of what follows is precisely about the <em>finesse</em> around this simplified view of the world.</p>
<h3>The threat is stronger than its execution</h3>
<p>This aphorism comes from the world of chess (as far as I gather); it's somehow both obvious but also subtle at the same time.
Forgive the sidetrack, but it reminds me of the possible originator of this phrase, a controversial figure in the history of chess - Aron Nimzowitsch. One (apocryphal?) <a href="http://www.caissa.com/ext/bulletin/ms/tlda0000/fms1221935698008892000004-%22Why-must-I-lose-to-this-IDIOT-%22">story</a> of him features him pointing at his grandmaster opponent and loudly proclaiming "Why must I lose to this idiot?!". But to the matter in hand - Nimzowitsch wrote one of the most famous early-ish treatises on chess strategy called "My System".</p>
<p><img src="https://joinmarket.me/images/aronsystem.jpeg" width="436" height="436"></p>
<p>in this book he popularised (amongst many other less controversial things) the idea of <strong>overprotection</strong> - so for example, you have a pawn on square e5, and he considered it good strategy to protect it with a knight on f3, a rook on e1 and a bishop on g3 etc. etc. Many players - indeed top grandmasters - today find this idea faintly ridiculous. What interests me is that when they deride the idea they essentially never give credence to the element of truth it surely contains, which is this: if N &gt; 1 pieces protect a key square, it means that <em>any</em> of them can move without losing protection of that square. In other words the <em>potential</em> for <em>any</em> piece to move is preserved (contrasted with a single protector, which is therefore bound and cannot move away from protection).</p>
<p><img src="https://joinmarket.me/images/overprotection.png" width="436" height="436"></p>
<p>The idea behind the phrase "the threat is stronger than its execution" - which sounds paradoxical at first - is similar. Potentiality is more difficult for the adversary to handle than actuality, mostly because the adversary may have to handle many potential actions, rather than the one that is actualised.</p>
<p>This can manifest psychologically - inducing <em>fear</em> in an enemy is often a very excellent strategy, rather than directly attacking them. But it's important to understand that it's not just mind games. It's a matter of economy, and a matter of abstraction. Just like in the development of quantitative disciplines (all the way from early mathematics to modern computer programming, and much modern science), the development of abstractions allows for economy, which maximally leverages resources, and even open up whole new dimensions that were previously inaccessible.</p>
<h3>The virtualization of violence</h3>
<p>This line of thinking naturally leads us to how violence as a concrete actualization of will tends to get abstracted away. This is seen across nature, <em>not</em> only in human societies. It's well understood how access to mating in social animals (various types of mammals) is "arbitrated" through combat, and importantly, the combat is rarely to-the-death. Even more strikingly, the "combat" is reduced to competition over attributes <em>which might allow for better success in combat</em>. The obvious example is the stag's antlers:</p>
<p><img src="https://joinmarket.me/images/antlers1.jpeg" width="436" height="436"></p>
<p>That's a lot of physical raw material, requiring a lot of nutrition, and with unclear direct utility (very inefficient!). These are only a quasi-abstraction from real horns designed to kill - they <em>can</em> kill other stags, but apparently it's very rare, but they have evolved to be very visually assessable by other stags, and their complex geometry allows for battles ("horns locked") which are more of an assessment of the ability to kill, than an attempt to do so. There are of course many further examples that are more obviously abstractions. Further, displays may not be of attributes designed to inflict violence, but attributes that display high levels of general fitness, which itself is an abstraction from "ability to gather a lot of resources". The peacock being the most famous visually striking example, albeit the exact mechanisms involved may not be a matter of settled science.</p>
<p>i<img src="https://joinmarket.me/images/peacock.jpg" width="436" height="436"></p>
<p>I will leave the biologists to extend this list further with more obscure examples...</p>
<p>A rather interesting summary of one perspective on these phenomena is <a href="https://en.wikipedia.org/wiki/Handicap_principle">the handicap principle</a> (which somehow I had not read before writing most of this document, and as you will understand from reading it, I now rather wish I had!).</p>
<p>Also, the two examples we've seen so far show how there are two sides to this phenomenon: show dominance by showing the <em>ability</em> to win a fight without fighting; show superior suitability by showing the <em>ability</em> to gather resources without actually gathering resources. They are clearly not <em>completely</em> distinct.</p>
<h3>The same in modern human society</h3>
<p>We can see both types of 'abstraction' very clearly even in modern society. The violence-competition is virtualized in sport, most obviously:</p>
<p><img src="https://joinmarket.me/images/gridiron.jpeg" width="436" height="436"></p>
<p>(It's probably not an accident that in many places, sportsmen are pretty much at the top of the mating hierarchy, at least to some females!). But lest we get <em>too</em> abstract, let's not forget that just generally, displays of violence <em>capability</em> are also a big part of human society, even at the nation-state level:</p>
<p><img src="https://joinmarket.me/images/militaryparadewithtanks.jpeg" width="436" height="436"></p>
<p>Once we start thinking about human behaviour this way, we can see it everywhere. Consider the engagement ring and ask yourself where this tradition might come from:</p>
<p><img src="https://joinmarket.me/images/engagementring.jpeg" width="436" height="436"></p>
<p>We are not so different from peacocks here ... and it's not of course "irrational" in any but the most inane sense. Look at the analogy between the peacock's display and the engagement ring more closely, both:</p>
<ul>
<li>are costly in resources to create</li>
<li>are visually appealing</li>
<li>are (visually) very distinct from the normal "stuff" in the environment</li>
<li>are very immediately and easily recognized <em>by any viewer, on their own</em></li>
<li>signal that the creator is part of a group (genetic, or cultural)</li>
</ul>
<p>Much less obvious I think is that the <em>permanence</em> of these displays is not central. Sometimes they are very delicate and fragile (think: flowers, think: sports displays with substantial risk of injury that would cause permanent inability to repeat them), and this is <em>almost</em> the point - to the receiver of the signal, what matters is that the signal was unambiguously difficult to create. What matters much less is the "substrate", i.e. what the signal is "made of". This is part of the insight in the "handicap principle":</p>
<blockquote>
<p><strong>what matters is what you <em>couldn't</em> do, because you did this.</strong></p>
</blockquote>
<p><img src="https://joinmarket.me/images/smallbirdinjungle.jpeg" width="436" height="436"></p>
<p>Further, imagine yourself as a small bird in the jungle - to find mating partners in this <strong>extremely</strong> noisy environment, you are looking for a small signal - a patch of bright colour - in this high noise environment. You want the signal to be unambiguous - blue where everything is green, yellow, brown, red - and costly. You don't want to have to compare it to something else to check it's correct (is it the same color as something else on the other side of the jungle? sheesh!). You really don't care about semantics - you don't care what the signal "means", except specifically that it's in some sense pre-agreed (perhaps genetically? see the last bullet point); to an outsider the signal could be outlandish or ridiculous, and that doesn't matter.</p>
<h3>The court, the bank, and the abstraction of money</h3>
<p><img src="https://joinmarket.me/images/bankofmontreal.jpeg" width="436" height="436"></p>
<p>You can see it in architecture; there is of course a very good reason why historically banks were built of extremely sturdy materials, at considerable cost. They were originally actually vaults for high concentrations of physical wealth, and had to protect well from direct frontal assault.</p>
<p><img src="https://joinmarket.me/images/hongkong.jpeg" width="436" height="436"></p>
<p>Nowadays this is another abstraction of the type already mentioned; if an organization put <em>that</em> much money into building such an imposing building or flashy skyscraper, they're hardly likely to steal my pathetic little stash! Court buildings likewise represent an abstraction of the state's power, and so do government offices (this is particularly obvious in more authoritarian states like China, where the government buildings in smaller towns look almost absurd (this example is very typical, in Luxian):</p>
<p><img src="https://joinmarket.me/images/luxian.jpeg" width="436" height="436"></p>
<p>The whole "virtualization" paradigm, taking concrete physical force and replacing it with "threats, stronger than executions" has entirely entered the realm of money too. Not to dip my toe into the various debates about the origin of money, I'll just talk about recent history: we moved from bearer instruments and certificates for bearer instruments, through to certificates representing pure "fiat" in the literal sense - fiat meaning the will of the governing power, essentially. So "fiat is backed by men with guns", the famous <a href="https://www.youtube.com/watch?v=MJWi8VUHUzk">Krugman</a> quote,</p>
<p><img src="https://joinmarket.me/images/krugman.jpeg" width="436" height="436"></p>
<p>... is certainly right <em>in essence</em> even if you quibble over various details. In the same way that courts are "backed by men with guns".</p>
<p>But I think it's important to step back and consider what role money takes in a society - its purpose is always exactly abstraction. It solves the "double coincidence of wants" problem by creating an entirely new class of good that no one originally wanted (this is the counter intuitive about much mathematics - to solve a problem involving 2 or 3 things you add another thing, superficially making everything more complicated, but suddenly everything 'falls into place', creating a new structure with more symmetry. For example, if the general solution of polynomials is tortuous and even insoluble (see: <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Galois</a>) for real numbers, by adding an apparent complexity: a new made-up solution to x^2=-1, you suddenly find that everything cleans itself up (see: <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra">the fundamental theorem of algebra</a>). Money does something similar, because we replace an O(N^2) pricing problem with an O(N) problem - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joinmarket.me/blog/blog/pow-a-pictorial-essay/">https://joinmarket.me/blog/blog/pow-a-pictorial-essay/</a></em></p>]]>
            </description>
            <link>https://joinmarket.me/blog/blog/pow-a-pictorial-essay/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618219</guid>
            <pubDate>Sun, 03 Jan 2021 00:45:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for UI Checkboxes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618218">thread link</a>) | @efortis
<br/>
January 2, 2021 | https://blog.uidrafter.com/usability-tips/guidelines-for-checkboxes | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/usability-tips/guidelines-for-checkboxes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
As checkboxes are one of the most confusing UI elements, here
are a few tips for drafting them clear and unambiguously.
</p>
<section>
<h2>Labels</h2>
<p>
Let's start with a classic tip: verbs clarify the intent.
</p>
<p><label> Billing Address </label>
<label> Ship to Billing Address</label>
</p>
<p>
Headings help too and avoid repetitive verbs.
</p>
<div>
<p><span>Time Settings:</span></p>
<p><label> 24-Hour Format</label>
</p></div>
<p>
Don't break the mood, keep the mindset polarity. e.g., in Sign Up:
</p>
<p><label> Opt out of Newsletter</label>
<label> Subscribe to Newsletter</label>
</p>
</section>
<section>
<h2>Maybe it's a Selector</h2>
<p>
Mitigate misreads by consolidating pairs like:
</p>
<p><label> Painted?</label>
<label>
Color

</label>
<br>
<label>
Color

</label>
</p>
<div>
<p>
Be aware the alternative might be unexpected to the user:
</p>
<p><label> 240 Volts?</label>
</p>
<div>
<div>
<p><span>Operating Voltage:</span></p>
<p><label> 240V</label>
<label> 480V</label>
</p></div>
</div>
</div>
</section>
<section>
<h2>Maybe it's a Button</h2>
<p>
Checkboxes imply options, Buttons actions. If toggling
requires confirmation, it's closer to an action.
</p>

</section>
</article>
<article>
<hr>
<h2>More</h2>
<ul>
<li><a rel="noopener" href="https://docs.uidrafter.com/checkboxes">How to draft UI Checkboxes?</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/usability-tips/radio-buttons-vs-dropdowns">Radio Buttons vs. Dropdowns</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/usability-tips/guidelines-for-checkboxes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618218</guid>
            <pubDate>Sun, 03 Jan 2021 00:45:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Android Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618065">thread link</a>) | @xearl
<br/>
January 2, 2021 | https://madaidans-insecurities.github.io/android.html | <a href="https://web.archive.org/web/*/https://madaidans-insecurities.github.io/android.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  

  <p><i><time datetime="2020-12-30">Last edited: December 30, 2020</time></i></p>

  <p>
    By default, Android has a strong security model and incorporates <a href="https://source.android.com/security/selinux/">
    full system SELinux policies</a>, <a href="https://source.android.com/security/app-sandbox">strong app sandboxing</a>,
    <a href="https://source.android.com/security/verifiedboot">full verified boot</a>, modern exploit mitigations like
    <a href="https://source.android.com/devices/tech/debug/cfi">fine-grained forward-edge Control-Flow Integrity</a> and
    <a href="https://source.android.com/devices/tech/debug/shadow-call-stack">ShadowCallStack</a>, widespread use of
    memory-safe languages (Java / Kotlin) and more. As such, this article explains common ways in which people worsen the
    security model rather than criticisms of the security model itself.
  </p>

  <h2 id="unlocking-the-bootloader"><a href="#unlocking-the-bootloader">Unlocking the bootloader</a></h2>

  <div><p>
    Unlocking the bootloader in Android is a large security risk. It disables <a href="https://source.android.com/security/verifiedboot/">verified boot</a>, a fundamental part of the security
    model. Verified boot ensures the integrity of the base system and boot chain to prevent <a href="https://en.wikipedia.org/wiki/Evil_maid_attack">
    evil maid attacks</a> and malware persistence. </p><p>
    
    Contrary to common assumptions, verified boot is not just important for physical security — it prevents the persistence
    of <b>any</b> tampering with your system, be it from a physical attacker or a malicious application that has managed to
    hook itself into the operating system. For example, if a remote attacker has managed to exploit the system and gain high
    privileges, verified boot would revert their changes upon reboot and ensure that they cannot persist.
  </p></div>

  <h2 id="rooting"><a href="#rooting">Rooting your device</a></h2>

  <div><p>
    Rooting your device allows an attacker to easily gain extremely high privileges. Android's architecture is built
    upon <a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege">principle of least privilege</a>. By default,
    unrestricted root is found nowhere in the system due to the <a href="https://source.android.com/security/selinux">
    full system SELinux policy</a>. Even the init system does not have unrestricted root access. Exposing privileges far
    greater than any other part of the OS to the application layer is not a good idea. </p><p>
    
    It does not matter if you have to whitelist apps that have root. An attacker can fake user input by for example,
    <a href="https://en.wikipedia.org/wiki/Clickjacking">clickjacking</a> or they can exploit vulnerabilities in apps that
    you have granted root to. By rooting your device, you are breaking Android's security model and adding further layers
    of trust where it is inappropriate. </p><p>
    
    A common argument for rooting is that Linux allows root but this does not account for the fact that the average
    desktop Linux system does not have a security model like Android does. On the usual Linux system, <a href="https://madaidans-insecurities.github.io/linux.html#root">gaining root is extremely easy</a>. This is why Linux hardening procedures often involve
    restricting access to the root account.
  </p></div>

  <h2 id="custom-roms"><a href="#custom-roms">Custom ROMs</a></h2>

  <p>
    The majority of custom ROMs severely weaken the security model by disabling verified boot, using userdebug builds,
    disabling SELinux, and various other issues. Furthermore, you are also usually at the mercy of the maintainer to
    apply security updates properly. Certain ROMs often apply security patches late or sometimes not apply them at all,
    especially when it comes to firmware patches.
  </p>

  <h3 id="lineageos"><a href="#lineageos">LineageOS</a></h3>

  <p>
    A common ROM that has many of these issues is <a href="https://lineageos.org/">LineageOS</a>:
  </p>

  <ul>
    <li>
      LineageOS <a href="https://github.com/LineageOS/hudson/blob/master/lineage-build-targets">uses
      userdebug builds by default</a>. This <a href="https://source.android.com/setup/build/building#choose-a-target">
      adds many debugging features as additional attack surface</a>. It also weakens various SELinux polices and exposes
      root access via adb which <a href="#root">as discussed above</a>, is not a good idea.
    </li>

    <li>
      LineageOS requires an unlocked bootloader, therefore disabling verified boot which <a href="#unlocking-the-bootloader">
      is essential to verify the integrity of the operating system</a>.
    </li>

    <li>
      It does not implement <a href="https://source.android.com/security/verifiedboot/verified-boot#rollback-protection">
      rollback protection</a>. This allows an attacker to downgrade the system to an older version and then exploit already
      patched vulnerabilities. The default updater even allows you to downgrade versions yourself.
    </li>

    <li>
      Most LineageOS builds also do not include firmware updates which prevents users from getting new patches to fix
      vulnerabilities. Instead, it gives a pop-up advising users to flash updates manually that most people will simply
      ignore.
    </li>
  </ul>

  <p>
    This is a non-exhaustive list. There are more issues than just those listed above. LineageOS (and most other custom
    ROMs) are focused on customizing the device and not privacy or security. Of course, you could build LineageOS yourself
    to fix many of these issues but most users will not be capable of doing so.
  </p>

  <h2 id="microg-signature-spoofing"><a href="#microg-signature-spoofing">MicroG / Signature Spoofing</a></h2>

  <div>
    <p><a href="https://microg.org/">MicroG</a> is a common alternative to Google Play Services. It is often used to get rid
    of Google's tracking but most people do not realise that this can potentially worsen security as it
    <a href="https://github.com/microg/android_packages_apps_GmsCore/wiki/Signature-Spoofing">requires signature spoofing
    support</a> which allows apps to request to bypass signature verification. </p><p>
    
    Although, some signature spoofing implementations restrict it to make it less bad such as <a href="https://gitlab.com/calyxos/platform_frameworks_base/commit/dccce9d969f11c1739d19855ade9ccfbacf8ef76">CalyxOS'
    implementation</a> which allows only microG to spoof the Play Services signature and nothing else.
  </p></div>

  <h2 id="firewalls"><a href="#firewalls">Firewalls</a></h2>

  <div><p>
    Firewalls such as <a href="https://github.com/ukanth/afwall/">AFWall+</a> or <a href="https://www.netguard.me/">
    Netguard</a> are regularly used on Android to attempt to block network access from a specific app but these
    do not reliably work — apps can use IPC to bypass the restrictions. If you cut off network access to an app, it
    will not prevent the app from sending an <a href="https://developer.android.com/reference/android/content/Intent">
    intent</a> to another app (such as the browser) to make it make the same connection. </p><p>
    
    Many apps already do this unintentionally whilst using APIs such as the <a href="https://developer.android.com/reference/android/app/DownloadManager">download manager</a>. </p><p>
    
    The most effective way to block network access is to revoke the <code>INTERNET</code> permission from the app
    like <a href="https://github.com/GrapheneOS/platform_frameworks_base/commit/5e2898e9d21dd6802bb0b0139e7e496c41e1cd80">
    GrapheneOS allows you to do</a>. This prevents abusing OS APIs to initiate network connections as they contain checks
    for that permission, one example of which is the aforementioned download manager. You should also run the app in its
    own user or work profile to ensure that it cannot abuse third party apps either.
  </p></div>

  <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>

  

  <p>
    <a href="https://madaidans-insecurities.github.io/index.html">Go back</a>
  </p>

  
  


</div>]]>
            </description>
            <link>https://madaidans-insecurities.github.io/android.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618065</guid>
            <pubDate>Sun, 03 Jan 2021 00:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25618048">thread link</a>) | @barry-cotter
<br/>
January 2, 2021 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618048</guid>
            <pubDate>Sun, 03 Jan 2021 00:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dug, A global DNS propagation checker on your CLI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25618012">thread link</a>) | @monkaiju
<br/>
January 2, 2021 | https://git.kaijucode.com/matt/dug | <a href="https://web.archive.org/web/*/https://git.kaijucode.com/matt/dug">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="count_prompt">You can not select more than 25 topics</span>
			<span id="format_prompt">Topics must start with a letter or number, can include dashes ('-') and can be up to 35 characters long.</span>
		</p><div>
	
	<div>
		<div>
			
				
<p><a href="https://drone.kaijucode.com/matt/dug" rel="nofollow"><img src="https://drone.kaijucode.com/api/badges/matt/dug/status.svg" alt="Build Status"></a></p>
<p>The <strong>real</strong> repository is located <a href="https://git.kaijucode.com/matt/dug" rel="nofollow">here</a></p>
<p>The GitHub repository <a href="https://github.com/unfrl/dug" rel="nofollow">here</a> is used for issues and stars <span aria-label="glowing star">🌟</span></p>
<p>A powerful global DNS progagation checker that can output in a variety of formats.</p>
<p>The goal of dug is to make it easy to check the propagation of DNS records. It is also capable of providing templated output that can be used in scripts for things like monitoring.</p>
<h2 id="user-content-usage">Usage</h2>
<p>Until theres a wiki for this, the easiest way to explore dug is through the help.</p>
<ul>
<li><code>dug help</code> -&gt; Get top level help explaining the different verbs</li>
<li><code>dug help run</code> or <code>dug run --help</code> -&gt; Get details about a specific verb (run, which is the default)</li>
<li><code>dug help update</code> or <code>dug update --help</code> -&gt; Get details about the update verb</li>
</ul>
<p>The simplest way to get started is to just run a query against the domain whose DNS records you’re updating.
For example: <code>dug git.kaijucode.com</code>:
<a href="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif1.gif" rel="nofollow"><img src="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif1.gif" alt=""></a></p>
<p>You can also do complicated things like ask for specific record types, get the output as json, and pipe it into other applications: <code>dug git.kaijucode.com -q A --output-format JSON --output-template Ipaddress,city,value,responsetime | jq</code>:
<a href="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif2.gif" rel="nofollow"><img src="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif2.gif" alt=""></a></p>
<h2 id="user-content-installation">Installation</h2>
<h3 id="user-content-linux-deb-debian-ubuntu-mint-pop-os">Linux Deb (Debian, Ubuntu, Mint, Pop!_os)</h3>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .deb package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.linux-x64.deb</code></li>
</ul>
</li>
<li>On most distros double clicking the .deb package will allow you to install via a UI, alternatively it can be installed by running <code>sudo dpkg -i ./dug.&lt;version&gt;.linux-x64.deb</code></li>
</ol>
<h3 id="user-content-linux-rpm-rhel-centos-fedora">Linux RPM (RHEL, CentOS, Fedora)</h3>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .rpm package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.linux-x64.rpm</code></li>
</ul>
</li>
<li>On most distros double clicking the .deb package will allow you to install via a UI, alternatively it can be installed by running <code>rpm -i ./dug.&lt;version&gt;.linux-x64.deb</code></li>
</ol>
<h3 id="user-content-arch">Arch</h3>
<ol>
<li>A friend put dug in the AUR! <a href="https://aur.archlinux.org/packages/dug-git/" rel="nofollow">here</a></li>
</ol>
<h3 id="user-content-osx">OSX</h3>
<blockquote>
<p>Not Officially Supported Yet</p>
</blockquote>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the osx binary.
<ul>
<li>It should look like <code>dug-osx-x64</code></li>
</ul>
</li>
<li>You should be able to download that, make is executable, and run it from the terminal. Then you can put it somewhere and update your path so you can execute it from anywhere.</li>
</ol>
<h3 id="user-content-windows">Windows</h3>
<h4 id="user-content-chocolatey-choco-cli">Chocolatey (choco cli)</h4>
<blockquote>
<p>Waiting on chocolatey to approve my package, then I can publish there so this wont require a manual download. <a href="https://chocolatey.org/packages/dug" rel="nofollow">here</a></p>
</blockquote>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .nupkg package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.nupkg</code></li>
</ul>
</li>
<li>Install by running <code>choco install dug.&lt;version&gt;.nupkg</code></li>
</ol>
<h4 id="user-content-executable">Executable</h4>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .exe binary.
<ul>
<li>It should look like <code>dug.exe</code></li>
</ul>
</li>
<li>You should be able to download that and run it from the terminal. Then you can put it somewhere and update your path so you can execute it from anywhere.</li>
</ol>
<h3 id="user-content-npm">NPM</h3>
<blockquote>
<p>EXPERIMENTAL! (Currently only supports linux-x64)</p>
</blockquote>
<ol>
<li>Run: <code>npm -g @unfrl/dug</code></li>
</ol>
<p>Idk why I wanted to publish it on npm as well, its really not a good way to distribute a binary...</p>
<h2 id="user-content-development">Development</h2>
<p>This is a .net 5 project, so as long as you have the dotnet cli, available <a href="https://dotnet.microsoft.com/download/dotnet/5.0" rel="nofollow">here</a> you should be able to do the following: <code>dotnet build ./cli</code></p>
<p>The project was developed in VSCode so the debugger profiles that I have used are available if you’re also using VSCode.</p>
<h2 id="user-content-license">License</h2>
<p>The license used by dug, <a href="https://git.kaijucode.com/matt/dug/src/branch/main/cli/LICENSE" rel="nofollow">here</a>, is very explicitly designed to try to keep capitalists from benefiting from this tool. This is not a traditional license but it is very simple, please read it.</p>
<p>Made with <span aria-label="red heart">❤️</span> by <a href="https://unfrl.com/" rel="nofollow">Unfrl</a></p>

			
		</div>
	</div>
</div></div>]]>
            </description>
            <link>https://git.kaijucode.com/matt/dug</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618012</guid>
            <pubDate>Sun, 03 Jan 2021 00:12:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why You Shouldn’t Teach Recursion (Yet)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25617947">thread link</a>) | @amichlin
<br/>
January 2, 2021 | https://blog.ceos.io/2021/01/02/why-you-shouldnt-teach-recursion-yet/ | <a href="https://web.archive.org/web/*/https://blog.ceos.io/2021/01/02/why-you-shouldnt-teach-recursion-yet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-187">

	

	
			<figure>
				<img width="556" height="367" src="https://blogceosio.files.wordpress.com/2021/01/recursion.png?w=556" alt="" loading="lazy" srcset="https://blogceosio.files.wordpress.com/2021/01/recursion.png 556w, https://blogceosio.files.wordpress.com/2021/01/recursion.png?w=150 150w, https://blogceosio.files.wordpress.com/2021/01/recursion.png?w=300 300w" sizes="(max-width: 556px) 100vw, 556px" data-attachment-id="192" data-permalink="https://blog.ceos.io/2021/01/02/why-you-shouldnt-teach-recursion-yet/recursion/" data-orig-file="https://blogceosio.files.wordpress.com/2021/01/recursion.png" data-orig-size="556,367" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="recursion" data-image-description="" data-medium-file="https://blogceosio.files.wordpress.com/2021/01/recursion.png?w=300" data-large-file="https://blogceosio.files.wordpress.com/2021/01/recursion.png?w=556">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p><em>Picture taken from <a href="https://s3-us-west-2.amazonaws.com/www-cse-public/k12outreach/apcs/slides/java-recursive-tracing.pdf">this presentation</a></em></p>



<p>My esteemed colleague Shriram Krishnamurthi has written an interesting draft blog post on <a href="https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/">How Not to Teach Recursion</a> that details some of the common, perhaps misguided, ways computer science teachers teach recursion.</p>



<p>Let me start by saying that I agree with much of his criticism. Fibonacci is a contrived example and ignores the horrible computational complexity of the recursive solution compared to the iterative solution.  Euclid’s Algorithm, best left for a dedicated course in Cryptography, becomes an out of context example and I truly do not understand why anyone would care about Towers of Hanoi. My own education in recursion began by being required to implement the <a href="https://en.wikipedia.org/wiki/Knight%27s_tour">Knight’s Tour</a> Problem on a chess board in Pascal and I still bear the unseen scars to this day. </p>



<p>Regarding recursion versus cyclicity, which is a very valid criticism, I make a point of always teaching stacks before teaching recursion. When students understand stacks, it is much easier to explain why unbounded recursion is different than cyclicity.  It also helps them to understand a computer security term like “smashing the stack” or why Stack Overflow is called Stack Overflow (they never use that website… ahem). With a proper understanding of stacks, the “dumb” jokes become not so dumb and do serve to elucidate learning. </p>



<p>Now let’s talk recursion in context of AP CS A, where things are much worse </p>



<div><p>In AP CS A, recursion is only tested on the multiple choice portion of the test. Let that sink in. As bad as any of the above examples, not a single one will appear on test. And what will appear on the test will likely look something like <a href="https://s3-us-west-2.amazonaws.com/www-cse-public/k12outreach/apcs/slides/java-recursive-tracing.pdf">this</a>.</p><p>But it gets worse. The multiple choice test is timed and the students have to do a certain amount of problems in a relatively small amount of time. Correctly tracing mystery recursion problems takes time and doing that in a time crunch, is quite frankly, a good way to get students to absolutely abhor recursion for life. Frankly, Towers of Hanoi and Euclid would be an improvement.</p></div>



<div><p>My preference would be to wait to teach recursion until the students have significant experience in data structures, at least stacks, queues, lists, and trees. The beauty that is the recursive algorithm for <a href="https://en.wikipedia.org/wiki/Tree_traversal">walking a tree</a> is where I would want recursion to be introduced. Moving recursion out of AP CS A and collegiate CS1 into data structures is not likely to happen any time soon, so I have come up with a compromise in my own teaching.</p><p>While I no longer teach AP CS A at the high school level for this and many other reasons. I do use the Fibonacci example, although I quickly explain all the limitations in context of the computational complexity I like to first teach (that is not part of the AP CS A curriculum). Students do first know stacks and lists (not so much trees) and I do a bit of hand waving explaining recursion and walking trees. I would prefer to leave recursion out entirely, but know all too well what waits them in college.</p><p>I tell them that, done properly, recursion is a beautiful thing. Which, I hope, will help them weather the storm to come in college that is Towers of Hanoi, Knight’s Tour, and Euclid.</p></div>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.ceos.io/2021/01/02/why-you-shouldnt-teach-recursion-yet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25617947</guid>
            <pubDate>Sun, 03 Jan 2021 00:04:30 GMT</pubDate>
        </item>
    </channel>
</rss>
