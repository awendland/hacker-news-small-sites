<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 30 Oct 2020 12:22:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 30 Oct 2020 12:22:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Hiten Shah on choosing the right value proposition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917128">thread link</a>) | @gresquare
<br/>
October 28, 2020 | https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/ | <a href="https://web.archive.org/web/*/https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>Louis:</b><span> Bonjour, bonjour and welcome to another episode of Everyone Hates Marketers.com. The no fluff, actionable marketing podcast, for people sick of shady, aggressive marketing.</span></p>
<p><span>I’m your host, Louis Grenier. In today’s episode, you learn how to test different value propositions for whatever you’re offering your product or service, and pick which one you’d like to resonate the most with your audience.</span></p>
<p><span>My guest today you probably know him. He’s the co-founder and the CEO of FYI, a solution to have all of your documents in one place, and is the co-owner of Crazy Egg as well. He’s a serial entrepreneur, founded multiple software companies over the last 20 years or so. And I’m super happy to have him on board because.. obviously I believe that customer feedback and truly understanding your customer is the first step towards success, towards building something that people would care about. So that’s why I’m super happy to have you Hitan Shah onboard. Welcome.</span></p>
<p><b>Hiten:</b><span>Thanks for having me</span></p>
<p><b>Louis:</b><span> Let’s get started straight away. How do you define what a value proposition is, you have extensive experience launching products, dating them side projects, et cetera. But how do you define what a value proposition is?</span></p>
<p><b>Hiten:</b><span> Yeah. In short, I think it’s what, one sort of entity, if you want to call it, that can do for another.</span></p>
<p><span>And that it’s very simple. and the reason I would put it that way is because a value proposition can exist between any, basically two entities. So it could be an individual and an organization. It could be an organization or an organization. It could be an individual and an individual.</span></p>
<p><span>And it’s basically the value that one entity delivers to another. And the value proposition is how that sort of quantified, communicated, realized, et cetera. And the typical way people think about this is your business has a value proposition for its customers. The way I think about it is that.</span></p>
<p><span>Your value proposition for a business, a service, one human to another is what they’re getting from you, that is of value to them. And when you think about it that way, I think it really defines, it defines what this means and what it means is that it’s not up to you. Who’s giving the value, whether it’s an organization or individual to the other person to be like, Oh, here’s my value proposition for you.</span></p>
<p><span>It actually more works the other way around where that person or that company organization, group of individuals is like, this is what that other entity, organization, person does for me. And this is why it’s valuable. And I think that’s the basis of the value proposition is this idea that it’s in someone else’s mind. It’s not in your mind. The one who’s delivering the value. It’s the other party’s mind.</span></p>
<p><span>So it’s generous, it’s a way to think about it. Generously thinking about your people first, what do they want? And you provide that to them. You don’t start with your, with you being self centered and then think of your product.</span></p>
<p><b>Louis:</b><span> And now, what is our value proposition? Then let’s find people who would care about it. It’s really the opposite. You think of those people first, what they care about because it’s, that’s what they care about is themselves, right?</span></p>
<p><b>Hiten:</b><span> Yeah. if you don’t do that, then whatever value proposition you come up with, you’re throwing darts against the wall and hoping something just sticks and it’s probably not going to hit the bullseye for sure.</span></p>
<p><span>So you, you think of it the other way, and you think about these people and what their needs are and, I don’t know, I’ve seen that in every single, basically business I’ve started or business I’ve talked to somebody about it. It doesn’t even matter what it is. It’s that there’s this sort of effect where no matter what I say I’m doing for you, if you don’t agree, I don’t get to have your business.</span></p>
<p><span>I don’t get to be in that relationship with you. And you could go all the way to dating. You could go to marriage, you could go to any type of business. This will work. Because the value, the whole idea of a value proposition is it’s for somebody else. It’s not for the person who’s delivering the value.</span></p>
<p><span>And what I mean by that is like my understanding of it as a person, delivering value is only valuable if it relates to how I’m delivering value to somebody else. Or some other organization or whatever, and this is why this method works. No matter what industry you’re in. Like I said, it boils down to even relationships.</span></p>
<p><span>I think relationships are a set of value propositions to each other, And like when they fall apart, it’s usually because value is not met. Some expectation of that value is not delivered on and that’s it.</span></p>
<p><b>Louis:</b><span> Yeah. That’s when you’re diving very deep into a topic when you see it everywhere, when you go back to first principles, fundamental truth. Which is the way I like to think. So it’s great to hear. So before we actually go through a step by step on how to actually test value propositions, if you have a few in mind and how maybe how to come up with them in the first place. Based on your experience, you said you have funded multiple, very successful companies, you’ve probably advised a lot as well, being in touch with a lot of people. What do you think are the top two other mistakes folks are doing when it comes to value proposition? Besides the main one you described there?</span></p>
<p><b>Hiten:</b><span> Yeah. Let me even give you an example from right now, if I may. So you said, I said, certain things about the businesses I started. In reality, you said it, I didn’t say it. So in a way, it’s really like what people get wrong is they don’t pay attention to basically this idea that, look you said it, not me. And if you said it’s in your mind. So for example, you said that the businesses I’ve started have been successful.</span></p>
<p><span>I didn’t say that. You didn’t even ask me if they have been, right? Because if you would’ve asked me, I would have said successful? I don’t really know what that means. I think I tried my best, the teams did, and we got where we got, and here we are. Like whether that big thing is over or the thing is still going, that eye of the beholder is not me. The eye of the beholder is you, so thank you for saying that. I think there’s some level of credibility, maybe I have as a result of what’s in other people’s minds, but in my mind, I don’t know. Cause it doesn’t matter. So I think what people get wrong is they try to make up the value propositions, in their own heads about what they’re doing.</span></p>
<p><span>Oftentimes, because what they’re doing is something that they want to see exist in the world. And they haven’t really thought about whether it should exist to other people. I know this might sound like what I just said, you know what we’ve been talking about, but it is a second point. The second point is it doesn’t matter what you think.</span></p>
<p><span>Like it just doesn’t. so a lot of times people will come up with things and it’s just wrong because their whole idea of a value proposition is based on what they think about it. So if you asked me about my businesses, I would go into a lot of detail, about them and what happened, but I would never use the word successful, but you did.</span></p>
<p><span>So that means that I’m not saying I should, but it’s just information for me, regardless of what I think. And I think that there’s a resistance oftentimes to what other people think about something of yours and that resistance. Yeah.</span></p>
<p><b>Louis:</b><span> Let’s, sorry to cut through there, but I think you’re about to touch on it.</span></p>
<p><span>Let’s talk about this resistance. Where do you think it’s mainly coming from?</span></p>
<p><b>Hiten:</b><span> A lot of places. I think it usually comes from some form of a reaction that you have to what you just heard and whether that reaction is positive or negative. That’s really what sort of shapes your own ability to deal with what you’re hearing, this is one of the biggest problems with value propositions, which is when you don’t personally agree with what you’re hearing.</span></p>
<p><span>And then you bias yourself towards what you actually want something to be when it won’t be that, because nobody’s saying it. So I don’t think if I said my businesses have been successful, that would be as powerful or accurate as someone else saying it, because my definition of it, because it’s mine is going to be different than yours.</span></p>
<p><span>But what I really care about is your definition of it, not mine. And I think there’s a lot of aversion there to being able to see the truth about yourself or the truth about what you’re doing. And the main reason is you get invested in it. So the reason this happens is usually a really strong, emotional investment in what you’re doing and what you want it to be versus the ability to I like to call it, you go where the wind blows.</span></p>
<p><span>So the wind is blowing a certain way, you go there. So a good example of this is like a lawyer who’s really good at, let’s say like trademark law, and yet they want to do, I don’t know, some kind of M&amp;A, yeah. They want to be an M&amp;A lawyer. That’s very different from trademarks, but they happen to be really good at trademarks.</span></p>
<p><span>And everybody knows them as a lawyer. That’s all about trademarks. But they want to do M&amp;A. So think about how much effort they’re going to have to put in to become known and good at being an M&amp;A lawyer and known for it compared to the thing that’s the path of least resistance where the wind is already blowing, which is other people consider them a great trademark lawyer.</span></p>
<p><span>And it’s not to say that they shouldn’t be an M&amp;A lawyer or anything like that. It’s just to say that, like you have a position in people’s minds. And I don’t think you can talk about value propositions without thinking about positioning and positioning to me, is really like when a good service person, human being, whatever has carved out a place in your brain, and that positioning is what I’m really trying to figure out constantly what, when I’m presented with a problem where we need to like, figure out the value proposition.</span></p>
<p><b>Louis:</b><span> They are always though too, when you have 10, like tens of …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/">https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/</a></em></p>]]>
            </description>
            <link>https://www.everyonehatesmarketers.com/hiten-shah-on-choosing-the-right-value-proposition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917128</guid>
            <pubDate>Wed, 28 Oct 2020 10:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Markov Chain Monte Carlo (MCMC) Sampling, Part 1: The Basics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24917011">thread link</a>) | @vonadz
<br/>
October 28, 2020 | https://www.tweag.io/blog/2019-10-25-mcmc-intro1/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2019-10-25-mcmc-intro1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>This is part 1 of a series of blog posts about MCMC techniques:</p>
<ul>
<li><a href="https://www.tweag.io/posts/2020-01-09-mcmc-intro2.html">Part II: Gibbs sampling</a></li>
<li><a href="https://www.tweag.io/blog/2020-08-06-mcmc-intro3/">Part III: Hamiltonian Monte Carlo</a></li>
<li><a href="https://www.tweag.io/blog/2020-10-28-mcmc-intro-4/">Part IV: Replica Exchange</a></li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo</a> (MCMC) is a powerful class of methods to sample from probability distributions known only up to an (unknown) normalization constant. But before we dive into MCMC, let’s consider why you might want to do sampling in the first place.</p>
<p>The answer to that is: whenever you’re either interested in the samples themselves (for example, inferring unknown parameters in Bayesian inference) or you need them to approximate expected values of functions w.r.t. to a probability distribution (for example, calculating thermodynamic quantities from the distribution of microstates in statistical physics).
Sometimes, only the mode of a probability distribution is of primary interest. In this case, it’s obtained by numerical optimization so full sampling is not necessary.</p>
<p>It turns out that sampling from any but the most basic probability distributions is a difficult task.
<a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">Inverse transform sampling</a> is an elementary method to sample from probability distributions, but requires the cumulative distribution function, which in turn requires knowledge of the, generally unknown, normalization constant.
Now in principle, you could just obtain the normalization constant by numerical integration, but this quickly gets infeasible with an increasing number of dimensions.
<a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection sampling</a> does not require a normalized distribution, but efficiently implementing it requires a good deal of knowledge about the distribution of interest, and it suffers strongly from the curse of dimension, meaning that its efficiency decreases rapidly with an increasing number of variables.
That’s when you need a smart way to obtain representative samples from your distribution which doesn’t require knowledge of the normalization constant.</p>
<p>MCMC algorithms are a class of methods which do exactly that.
These methods date back to a <a href="https://pdfs.semanticscholar.org/7b3d/c9438227f747e770a6fb6d7d7c01d98725d6.pdf">seminal paper by Metropolis et al.</a>, who developed the first MCMC algorithm, correspondingly called <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis algorithm</a>, to calculate the equation of state of a two-dimensional system of hard spheres. In reality, they were looking for a general method to calculate expected values occurring in statistical physics.</p>
<p>In this blog post, I introduce the basics of MCMC sampling; in subsequent posts I’ll cover several important, increasingly complex and powerful MCMC algorithms, which all address different difficulties one frequently faces when using the Metropolis-Hastings algorithm. Along the way, you will gain a solid understanding of these challenges and how to address them.
Also, this serves as a reference for MCMC methods in the context of the <a href="https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html">monad-bayes</a> series.
Furthermore, I hope the provided notebooks will not only spark your interest in exploring the behavior of MCMC algorithms for various parameters/probability distributions, but also serve as a basis for implementing and understanding useful extensions of the basic versions of the algorithms I present.</p>
<h2>Markov chains</h2>
<p>Now that we know why we want to sample, let’s get to the heart of MCMC: Markov chains.
What is a Markov chain? Without all the technical details, a Markov chain is a random sequence of states in some state space in which the probability of picking a certain state next depends only on the current state in the chain and not on the previous history: it is memory-less.
Under certain conditions, a Markov chain has a unique stationary distribution of states to which it converges after a certain number of states. From that number on, states in the Markov chain are distributed according to the invariant distribution.</p>
<p>In order to sample from a distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>, a MCMC algorithm constructs and simulates a Markov chain whose stationary distribution is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>, meaning that, after an initial “burn-in” phase, the states of that Markov chain are distributed according to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>.
We thus just have to store the states to obtain samples from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x)</annotation></semantics></math></span></span>.</p>
<p>For didactic purposes, let’s for now consider both a discrete state space and discrete “time”.
The key quantity characterizing a Markov chain is the transition operator <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> which gives you the probability of being in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> at time <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i+1</annotation></semantics></math></span></span> given that the chain is in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span> at time <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span>.</p>
<p>Now just for fun (and for illustration), let’s quickly whip up a Markov chain which has a unique stationary distribution.
We’ll start with some imports and settings for the plots:</p>
<div data-language="python"><pre><code><span>%</span>matplotlib notebook
<span>%</span>matplotlib inline
<span>import</span> numpy <span>as</span> np
<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
plt<span>.</span>rcParams<span>[</span><span>'figure.figsize'</span><span>]</span> <span>=</span> <span>[</span><span>10</span><span>,</span> <span>6</span><span>]</span>
np<span>.</span>random<span>.</span>seed<span>(</span><span>42</span><span>)</span></code></pre></div>
<p>The Markov chain will hop around on a discrete state space which is made up from three weather states:</p>
<div data-language="python"><pre><code>state_space <span>=</span> <span>(</span><span>"sunny"</span><span>,</span> <span>"cloudy"</span><span>,</span> <span>"rainy"</span><span>)</span></code></pre></div>
<p>In a discrete state space, the transition operator is just a matrix.
Columns and rows correspond, in our case, to sunny, cloudy, and rainy weather.
We pick more or less sensible values for all transition probabilities:</p>
<div data-language="python"><pre><code>transition_matrix <span>=</span> np<span>.</span>array<span>(</span><span>(</span><span>(</span><span>0.6</span><span>,</span> <span>0.3</span><span>,</span> <span>0.1</span><span>)</span><span>,</span>
                              <span>(</span><span>0.3</span><span>,</span> <span>0.4</span><span>,</span> <span>0.3</span><span>)</span><span>,</span>
                              <span>(</span><span>0.2</span><span>,</span> <span>0.3</span><span>,</span> <span>0.5</span><span>)</span><span>)</span><span>)</span></code></pre></div>
<p>The rows indicate the states the chain might currently be in and the columns the states the chains might transition to.
If we take one “time” step of the Markov chain as one hour, then, if it’s sunny, there’s a 60% chance it stays sunny in the next hour, a 30% chance that in the next hour we will have cloudy weather, and only a 10% chance of rain immediately after it had been sunny before.
This also means that each row has to sum up to one.</p>
<p>Let’s run our Markov chain for a while:</p>
<div data-language="python"><pre><code>n_steps <span>=</span> <span>20000</span>
states <span>=</span> <span>[</span><span>0</span><span>]</span>
<span>for</span> i <span>in</span> <span>range</span><span>(</span>n_steps<span>)</span><span>:</span>
    states<span>.</span>append<span>(</span>np<span>.</span>random<span>.</span>choice<span>(</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>)</span><span>,</span> p<span>=</span>transition_matrix<span>[</span>states<span>[</span><span>-</span><span>1</span><span>]</span><span>]</span><span>)</span><span>)</span>
states <span>=</span> np<span>.</span>array<span>(</span>states<span>)</span></code></pre></div>
<p>We can monitor the convergence of our Markov chain to its stationary distribution by calculating the empirical probability for each of the states as a function of chain length:</p>
<div data-language="python"><pre><code><span>def</span> <span>despine</span><span>(</span>ax<span>,</span> spines<span>=</span><span>(</span><span>'top'</span><span>,</span> <span>'left'</span><span>,</span> <span>'right'</span><span>)</span><span>)</span><span>:</span>
    <span>for</span> spine <span>in</span> spines<span>:</span>
        ax<span>.</span>spines<span>[</span>spine<span>]</span><span>.</span>set_visible<span>(</span><span>False</span><span>)</span>

fig<span>,</span> ax <span>=</span> plt<span>.</span>subplots<span>(</span><span>)</span>
width <span>=</span> <span>1000</span>
offsets <span>=</span> <span>range</span><span>(</span><span>1</span><span>,</span> n_steps<span>,</span> <span>5</span><span>)</span>
<span>for</span> i<span>,</span> label <span>in</span> <span>enumerate</span><span>(</span>state_space<span>)</span><span>:</span>
    ax<span>.</span>plot<span>(</span>offsets<span>,</span> <span>[</span>np<span>.</span><span>sum</span><span>(</span>states<span>[</span><span>:</span>offset<span>]</span> <span>==</span> i<span>)</span> <span>/</span> offset
            <span>for</span> offset <span>in</span> offsets<span>]</span><span>,</span> label<span>=</span>label<span>)</span>
ax<span>.</span>set_xlabel<span>(</span><span>"number of steps"</span><span>)</span>
ax<span>.</span>set_ylabel<span>(</span><span>"likelihood"</span><span>)</span>
ax<span>.</span>legend<span>(</span>frameon<span>=</span><span>False</span><span>)</span>
despine<span>(</span>ax<span>,</span> <span>(</span><span>'top'</span><span>,</span> <span>'right'</span><span>)</span><span>)</span>
plt<span>.</span>show<span>(</span><span>)</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/d0d8c/mcmc-intro1-weatherchain.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="png" title="png" src="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/fcda8/mcmc-intro1-weatherchain.png" srcset="https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/12f09/mcmc-intro1-weatherchain.png 148w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/e4a3f/mcmc-intro1-weatherchain.png 295w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/fcda8/mcmc-intro1-weatherchain.png 590w,
https://www.tweag.io/static/970ffb50b65a63406121b8ed07f5e4b1/d0d8c/mcmc-intro1-weatherchain.png 609w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>The mother of all MCMC algorithms: Metropolis-Hastings</h2>
<p>So that’s lots of fun, but back to sampling an arbitrary probability distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>.
It could either be discrete, in which case we would keep talking about a transition matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span>, or be continuous, in which case <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span> would be a transition <em>kernel</em>.
From now on, we’re considering continuous distributions, but all concepts presented here transfer to the discrete case.</p>
<p>If we could design the transition kernel in such a way that the next state is already drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>, we would be done, as our Markov chain would… well… immediately sample from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>.
Unfortunately, to do this, we need to be able to sample from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span>, which we can’t.
Otherwise you wouldn’t be reading this, right?</p>
<p>A way around this is to split the transition kernel <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> into two parts:
a proposal step and an acceptance/rejection step.
The proposal step features a proposal distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_{i+1}|x_i)</annotation></semantics></math></span></span>, from which we can sample possible next states of the chain.
In addition to being able to sample from it, we can choose this distribution arbitrarily. But, one should strive to design it such that samples from it are both as little correlated with the current state as possible and have a good chance of being accepted in the acceptance step.
Said acceptance/rejection step is the second part of the transition kernel and corrects for the error introduced by proposal states drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo mathvariant="normal">≠</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">q \neq \pi</annotation></semantics></math></span></span>.
It involves calculating an acceptance probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i)</annotation></semantics></math></span></span> and accepting the proposal <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> with that probability as the next state in the chain.
Drawing the next state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)</annotation></semantics></math></span></span> is then done as follows:
first, a proposal state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> is drawn from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_{i+1}|x_i)</annotation></semantics></math></span></span>.
It is then accepted as the next state with probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i)</annotation></semantics></math></span></span> or rejected with probability <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">1-p_\mathrm{acc}(x\_{i+1}|x_i)</annotation></semantics></math></span></span>, in which case the current state is copied as the next state.</p>
<p>We thus have</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i)=q(x_{i+1} | x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) \ \text .</annotation></semantics></math></span></span></span></p><p>A sufficient condition for a Markov chain to have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span> as its stationary distribution is the transition kernel obeying <em>detailed balance</em> or, in the physics literature, <em>microscopic reversibility</em>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(x_i) T(x_{i+1}|x_i) = \pi(x_{i+1}) T(x_i|x_{i+1})</annotation></semantics></math></span></span></span></p><p>This means that the probability of being in a state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span> and transitioning to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> must be equal to the probability of the reverse process, namely, being in state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">x\_{i+1}</annotation></semantics></math></span></span> and transitioning to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.
Transition kernels of most MCMC algorithms satisfy this condition.</p>
<p>For the two-part transition kernel to obey detailed balance, we need to choose <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span> correctly, meaning that is has to correct for any asymmetries in probability flow from / to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i+1}</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.
Metropolis-Hastings uses the Metropolis acceptance criterion:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mrow><mo fence="true">{</mo><mn>1</mn><mo separator="true">,</mo><mfrac><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>×</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">}</mo></mrow><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i) = \mathrm{min} \left\{1, \frac{\pi(x_{i+1}) \times q(x_i|x_{i+1})}{\pi(x_i) \times q(x_{i+1}|x_i)} \right\} \ \text .</annotation></semantics></math></span></span></span></p><p>Now here’s where the magic happens:
we know <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span></span> only up to a constant, but it doesn’t matter, because that unknown constant cancels out in the expression for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span>!
It is this property of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}</annotation></semantics></math></span></span> which makes algorithms based on Metropolis-Hastings work for unnormalized distributions.
Often, symmetric proposal distributions with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(x_i|x_{i+1})=q(x\_{i+1}|x_i)</annotation></semantics></math></span></span> are used, in which case the Metropolis-Hastings algorithm reduces to the original, but less general Metropolis algorithm developed in 1953 and for which</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mrow><mo fence="true">{</mo><mn>1</mn><mo separator="true">,</mo><mfrac><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>π</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">}</mo></mrow><mtext>&nbsp;.</mtext></mrow><annotation encoding="application/x-tex">p_\mathrm{acc}(x_{i+1}|x_i) = \mathrm{min} \left\{1, \frac{\pi(x_{i+1})}{\pi(x_i)} \right\} \ \text .</annotation></semantics></math></span></span></span></p><p>We can then write the complete Metropolis-Hastings transition kernel as</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>:</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo mathvariant="normal">≠</mo><msub><mi>x</mi><mi>i</mi></msub><mtext>;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>−</mo><mo>∫</mo><mi mathvariant="normal">d</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mtext>&nbsp;</mtext><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>:</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mtext>.</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">T(x_{i+1}|x_i) = \begin{cases}
                   q(x_{i+1}|x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) &amp;: x_{i+1} \neq x_i \text ; \\\\
                   1 - \int \mathrm{d}x_{i+1} \ q(x_{i+1}|x_i) \times p_\mathrm{acc}(x_{i+1}|x_i) &amp;: x_{i+1} = x_i\text .
                 \end{cases}</annotation></semantics></math></span></span></span></p><h2>Implementing the Metropolis-Hastings algorithm in Python</h2>
<p>All right, now that we know how Metropolis-Hastings works, let’s go ahead and implement it.
First, we set the log-probability of the distribution we want to sample from—without normalization constants, as we pretend we don’t know them. Let’s work for now with a standard normal distribution:</p>
<div data-language="python"><pre><code><span>def</span> <span>log_prob</span><span>(</span>x<span>)</span><span>:</span>
     <span>return</span> <span>-</span><span>0.5</span> <span>*</span> np<span>.</span><span>sum</span><span>(</span>x <span>**</span> <span>2</span><span>)</span></code></pre></div>
<p>Next, we choose a symmetric proposal distribution. Generally, including information you have about the distribution …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2019-10-25-mcmc-intro1/">https://www.tweag.io/blog/2019-10-25-mcmc-intro1/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2019-10-25-mcmc-intro1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24917011</guid>
            <pubDate>Wed, 28 Oct 2020 09:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Malcontents]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916924">thread link</a>) | @bschne
<br/>
October 28, 2020 | https://boz.com/articles/malcontents | <a href="https://web.archive.org/web/*/https://boz.com/articles/malcontents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>There is an important, under appreciated group at every company who are never content no matter how much success they or the company has had. There is a set of people who care so deeply about the company and its products that they take any shortcomings personally. They are offended by bad products and angered by cultural deficiencies. They write passionate notes that nobody asked for and rally people on comment threads in groups they aren’t required to be a part of. They speak truth to power because they are righteous and speak for those who might otherwise have no voice. They aren’t afraid to rock the boat no matter how much the people around them value stability and they can’t be bothered to do it politely. Adam Grant calls these people “<a href="https://www.ted.com/talks/adam_grant_are_you_a_giver_or_a_taker#t-113064">Disagreeable Givers</a>.” I call these people malcontents. And I am one of them.</p>
<p>We malcontents are often confused with <a href="http://boz.com/articles/ownership-and-entitlement.html">entitled whiners</a> but that’s a mistake. Whiners and Malcontents may share the same disagreeable tactics when it comes to complaining, but whiners have poor motivation whereas we malcontents have the best intentions. Whiners want to change the establishment for their own benefit. We malcontents want the establishment to change for its own benefit. Unlike whiners, we malcontents often make personal sacrifices to effect positive change (even if we would rather not be forced to). We often do valuable, unsexy, and sometimes underappreciated work like fixing bugs, improving tools or processes, and helping others. When you see large shifts in culture, organizations, or technology not driven by extrinsic or top down forces there is usually a malcontent behind the scenes or leading the charge.</p>
<p>The fate of malcontents is proof that good intentions and good work simply aren’t enough. Evaluating them exclusively on the impact of their work they are invariably promoted more slowly than their more polite peers. They get feedback constantly that they are doing good work but need to figure out how to do it without frustrating so many people. They are told they need to learn how to influence more effectively. To them it just feels like oppressive politics slowing them and the whole company down. I watched at Facebook as my peer group was consistently promoted a year or two ahead of me. I recall telling my manager at one point after a disappointing review that “this company is going to nice itself to death.” But niceness wasn’t hurting the company. I was. For every person who made me feel good about myself by clicking like on something inflammatory that I wrote there were ten people who quietly wrote me off. Not only did that erode my <a href="http://boz.com/articles/influence-over-authority.html">influence</a> over time it also didn’t help me advance my agenda on whatever issue I was raising.</p>
<p>For the malcontents out there: my advice is to stop and listen to the feedback you are getting. Your team needs you to highlight the opportunities around them and I don’t want you to stop advocating for change but I can tell you from personal experience that your impact is being diluted by your approach. You’re loudly trying to make a change but the tactics you use are costly and only marginally effective. If people think are you are emotional or biased, they will dismiss you. If they think your mind is closed, they will close their own. If they think you are attacking them, they will defend. If you take too much of their time or energy relative to the size of the issue, they will avoid you in the future. Do not fall for the Golden Rule — “Treat others as you wish to be treated” — because nobody else wants to be treated as bluntly as you do. If you do that, you will end up frustrated and marginalized. Instead go for the Platinum Rule: <em>Treat others as they wish to be treated</em>. It is only in expressing your passion through openness, empathy, and relationship building that you can really start to create change at scale.</p>
<p>Instead of just fighting the establishment, you must co-opt it. Find things the people involved care about and frame your concerns in those terms. You can change what the organization cares about by degrees over time, not dramatically overnight. As Richard Hamming said : “By realizing you have to use the system and studying how to get the system to do your work, you learn how to adapt the system to your desires. Or you can fight it steadily, as a small undeclared war, for the whole of your life.”</p>
<p>For those interacting with malcontents: embrace them. Nobody will care more or work harder on behalf of the people who use your product. Make space for them to raise all the concerns they have in an environment where it can be productive and recognize them for the value they bring in doing so when others are too polite to ask hard questions. And when necessary, try to make the cost of their clumsy communication as tangible a possible. Remind them of what their goal is in communicating and then show them how their approach was ineffective and coach them on a more effective approach.</p>
<p>I’m no less personally offended today by bad products or bad practices as I was years ago, but I’m much more effective at turning those emotions into impact. I’m not perfect at it and it isn’t hard to find examples where I’ve missed the mark, but now that I see how effective it can be to communicate more respectfully I find it much easier to do most of the time. I will always be grateful to Facebook for all the critical feedback and patience that got me to where I am. So today I try to pay it forward by identifying malcontents and giving them a little extra space and a lot of extra help.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/malcontents</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916924</guid>
            <pubDate>Wed, 28 Oct 2020 09:41:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defining Data Intuition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916868">thread link</a>) | @headalgorithm
<br/>
October 28, 2020 | https://blog.harterrt.com/data_intuition.html | <a href="https://web.archive.org/web/*/https://blog.harterrt.com/data_intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Last week, one of my peers asked me to explain what I meant by "Data Intuition",
and I realized I really didn't have a good definition.
That's a problem! I refer to data intuition all the time!</p>
<p>Data intuition is one of the three skills I interview new data scientists for
(along with statistics and technical skills).
In fact, I just spent the first nine months of 2020
building Mozilla's data intuition.
I'm really surprised to realize I can't point to
a good explanation of what I'm trying to cultivate.</p>
<p>So - I'll make one up. I propose the following definition for Data Intuition:</p>
<blockquote>
<p><strong>Data Intuition is a resilience to misleading data and analyses.</strong></p>
</blockquote>
<p>In other words, it's harder to mislead someone with data
if they have strong data intuition.
Think of this as <strong>a defense against the dark data arts</strong>.</p>
<p>So what does that look like in practice?</p>
<h2>Data Stink</h2>
<p>Someone with strong data intuition can quickly spot "data-stink"
(a close cousin to "<a href="https://en.wikipedia.org/wiki/Code_smell">code smell</a>").
These are data issues that don't necessarily invalidate an analysis,
but certainly draw suspicion on the results.
For example:</p>
<ul>
<li>An analysis prominently reports a seemingly <strong>arbitrary metric</strong> -
  4-day retention increased by 0.5%!
  Where did 4-day retention come from? Don't we usually track 7-day retention?
  This needs more attention before I trust the results.</li>
<li>An analysis reports <strong>extraordinary results</strong> where nominal results are expected -
  this feature increased retention by 10%!
  But, past efforts were trying to increase retention by 0.5% - 
  and isn't retention already 90%? How'd we get and increase of 10%?</li>
</ul>
<p>These are extreme examples. 
Usually the problems are more subtle
and result in a general sense of uneasiness with the results
(that's why it's called "intuition").</p>
<p>It's clear to me that data intuition is <em>related</em> to product intuition,
though these <em>are</em> different skills.
Product intuition can contextualize our results
and make it easier to identify extraordinary claims in analyses.
To know a 10% gain in retention is ridiculous
we need to know that users retain pretty well already.</p>
<h2>Methods issues</h2>
<p>Strong data intuition can also help you 
spot issues with how the analysis was designed.
Things like: how did the author collect data? Is it a representative sample?
Do they need to have an experiment to establish causation?</p>
<p>Here's an example -
say an analysis reports that Firefox users who create a Firefox account
retain 10% higher than users who don't.
By default, a lot of folks interpret this to mean that
if we invest some time in helping users open accounts
we'll see an increase in retention.
Folks with stronger data intuition will instead 
recognize these results are just correlational (not causational).</p>
<p>Users who use the product a lot tend to stick around longer.
Users who open an account are more active users, thus they retain better.
Users who <em>crash</em> Firefox are more active users, and also retain <em>better</em>.</p>
<p>I think this intuition is more than just understanding statistics well.
A strong stats background can help me identify issues
when reading the <em>methods section of a white paper</em>.
Strong data intuition helps me determine how much I trust
results I hear about in a <em>news headline</em>.
Data intuition helps me establish whether results are
<a href="https://blog.harterrt.com/pub-true.html">true-enough</a>.</p>
<h2>More than Skepticism</h2>
<p>I almost defined data intuition as a type of skepticism,
but I think this is a bad characterization.
Skepticism over-focuses on disregarding results.</p>
<p>Intuition is more than being skeptical.
It's <strong>incorporating new data as part of a body of existing knowledge</strong>.
A lot of times, that means deciding new incoming data are inconsistent
and need more investigating before we can trust them.
But other times, it means changing our opinions in the face of new data
that are more authoritative than our existing body of knowledge.</p>
<h2>What do you think?</h2>
<p>I want to hear your thoughts on this.
I'm posting this definition publicly in part because I want to invoke
<a href="https://meta.wikimedia.org/wiki/Cunningham%27s_Law">Cunningham's Law</a>.
The best way to get to the right answer is to post the wrong answer!</p>
<p>Does this definition for data intuition resonate with you?
Am I missing something important? Let me know! 
My email is at the bottom of this page.</p>
<p>I'm spending the next few month building some self-service trainings
to help non-data people at Mozilla build data intuition.
I'd rather be wrong now than next year!</p>
  </div><p>
        Feel free to share any feedback via email!
        You can reach me at <code>harterrt</code> on gmail.
        Look forward to hearing from you!
    </p></div>]]>
            </description>
            <link>https://blog.harterrt.com/data_intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916868</guid>
            <pubDate>Wed, 28 Oct 2020 09:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudden Changes in UI: Why It's a Bad Move]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916574">thread link</a>) | @yllow
<br/>
October 28, 2020 | https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>There’s a reason why change aversion in users is so often spoken about in the world of digital consumerism <span>— </span>human beings love their comfort zones. In the grand scheme of things, we seek out what is familiar to us for a sense of security.</p>
<!--more-->
<p>Keeping your software product updated is important, but it’s also important to make sure the perfective changes you make are within the bounds of what your users are familiar and comfortable with.</p>
<p>Now, what kinds of changes might we be referring to?&nbsp;</p>
<p>The types of changes that can be introduced in a software product are changes in infrastructure, functionality, and interface. Among them, interface changes incite the biggest reactions from users. That’s because it’s the most forefront part of a product that they see and interact with <span>— layout, tabs, fonts, colors, buttons, animation, etc</span>.</p>
<p><span>When introducing changes in this aspect of your product, both psychology and history say you should take it slow.</span></p>
<h2><strong>What Psychology Tells Us&nbsp;</strong></h2>
<p>To discuss why sudden and major UI changes backfire from a psychological point of view, we have to address change aversion.&nbsp;</p>
<p>There have been many cases where consumers refused to adapt to a new product, even if it was objectively “better”. One good example would be the introduction of the <a href="https://www.dvorak-keyboard.com/"><span>Dvorak keyboard</span></a> in the 1930s.</p>
<p>Even&nbsp;though the Dvorak keyboard promoted objectively better physical ergonomics, people refused to move from the QWERTY keyboard <span>—</span> simply because they were used to it.&nbsp;</p>
<p>Why is that?</p>
<h3><strong>Users Want to Feel Smart</strong></h3>
<p>It’s widely taught by UIUX experts like Rohan Puri and Robert Youmans, that users are aversive to change because “change makes them feel dumb”. When using your product, users want to feel in control, like they know what they’re doing.&nbsp;</p>
<p>Especially for neurodivergent users, big and sudden changes in UI can be disorienting. When you change things around all at once, you’re also making your users relearn what they’d previously mastered before <span>— and that takes time and energy. In other words, you’re giving them work to do.</span></p>
<p>If you’re an app or web developer, always remember that your users aren’t sitting next to you, watching you iterate and develop from scratch. Your interface may seem simple to you because you’ve familiarized with it as you worked on it, but that’s not the case for them.</p>
<h3><strong>Value is Invisible</strong></h3>
<p>Confirming many real-life cases, a study by Rosman et al on <a href="https://www.researchgate.net/publication/262411663_On_user_behaviour_adaptation_under_interface_change"><span>user behaviour adaptation under interface change</span></a> found that it takes many tries for a user to feel comfortable enough with an interface that was initially unfamiliar to them, before they “conﬁdently choose it and realise the potential beneﬁts”.</p>
<p>Because the bulk of your revamp’s value is neither visible nor instantly detectable, more impatient users might poorly estimate the efﬁciency of your improved UI and “prematurely abandon it” in that particular time frame.</p>
<p>After all, if they don’t see an increase in value, why would they like that you changed what was already working for them?</p>
<h2><strong>What History Tells Us</strong></h2>
<p>Negative feedback from a large number of users can spread like wildfire on social media. Needless to say, that can be really detrimental to your brand and product.</p>
<p>If you’re a startup just starting out with a small user base, you have more leeway for major UI redesigns while you figure out your brand and voice. As your product grows, however, so does the need to prioritize your users’ preferences.&nbsp;</p>
<p>Some companies with really big user bases learned the hard way so we don’t have to.&nbsp;</p>
<h3><strong>What Happened with Digg</strong></h3>
<p>In 2010, Digg, a news aggregate site very much like reddit, launched a redesign that caused them to lose 35% of their users nearly instantly.</p>
<p>In the Digg v4 update, the site was heavily revamped visually and functionally. Among many of the sudden changes, the downvote button was removed, users could no longer save posts to favorites or posts videos,&nbsp; their Upcoming page was gone, and the overall focus was shifted from user-submitted content to publisher-submitted content.&nbsp;</p>
<p>This major change didn’t just disorient their users. It took control away from them. With the new system, posts by publishers and sponsors flooded the front page, while posts by regular users were practically invisible.&nbsp;</p>
<p>The result of this? A mass exodus. Users either flooded the site with protest links (many of which were links to Reddit, their biggest competitor) or immediately migrated to Reddit.&nbsp;</p>
<h3><strong>What Happened with eBay</strong></h3>
<p>Once, eBay decided to change the background color of many of their site’s pages from bright yellow to white. Even though this change may seem like an obvious aesthetic choice today, it caused a ruckus on the internet (and in the team’s mailbox) when it first happened, forcing them to revert to yellow.</p>
<p>eBay didn’t give up on their vision, though. They came up with a strategy to go subtle, and designed an algorithm that faded the background from yellow to white, one shade at a time, over a few months. This time, the internet was still. The change was taking place so gradually that their users didn’t notice it was happening.</p>
<h2><strong>How Do You Safely Revamp?</strong></h2>
<p>Now that storytime is over, let’s talk about what we can learn from them. How can you revamp your product while being wary of change aversion?&nbsp;</p>
<p>Obviously, getting complaints from users doesn’t mean you should stop updating your app or website. <span>M</span>aintenance is necessary for your product to thrive and continue thriving.<span> The secret lies in </span><em><span>how</span></em><span> you execute it.</span></p>
<h3><strong>Change Little and Often</strong></h3>
<p>Instead of giving your users a whole new interface to relearn at one go, introduce a little change at a time. Habits take time to unlearn. Giving users one small redirection at a time is a lot less disorienting and burdensome for them.</p>
<h3><strong>Give Users a Heads-up&nbsp;</strong></h3>
<p>Before you launch your redesign, give users time to prepare for it. This will dampen the impact of the launch and reduce the risk of shocking them into frustration with your product.&nbsp;</p>
<h3><strong>Spell Out the Values</strong></h3>
<p>As mentioned before, values are invisible. Users don’t always immediately see the benefits of your new interface when they first try it. Instead of waiting for them to figure the maze out on their own, give them the lowdown on how the changes you’ve implemented are designed to solve the problems they face.</p>
<h3><strong>Provide Guidance</strong></h3>
<p>Part of spelling out the values of your redesign is by easing your users’ transition to your new interface. When you provide tutorials and demonstratives, you’re also teaching them how the new design improves their experience on your app or website.</p>
<h3><strong>Provide Options</strong></h3>
<p>It’s always good to give your users the option to switch back to the old interface. Provide them a toggle switch or button to revert to the old version, and place it somewhere easily accessible.</p>
<h3><strong>Welcome Feedback</strong></h3>
<p>Give your users an outlet or channel through which they can directly communicate with your team. Whether it’s a form on your website, or simply an email address they can write to specifically for complaints and feedback, it’s always good to let your users know that you’re listening.</p>
<h2><strong>We’re Here to Help</strong></h2>
<p>Snappymob is equipped with software developers and designers who understand user behavior. Our team has helped clients from startups to large corporations, within and beyond Malaysia, launch successful revamps and redesigns.</p>
<p>With our help, you can rest assured that your redesigns launch safely. Click <a href="https://www.snappymob.com/contact"><span>here</span></a> to reach out to us!</p>
</span></p><p><label>app design</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/sudden-changes-in-ui-why-its-a-bad-move</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916574</guid>
            <pubDate>Wed, 28 Oct 2020 08:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon Launches in Sweden]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916410">thread link</a>) | @kouzant
<br/>
October 28, 2020 | https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden | <a href="https://web.archive.org/web/*/https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
    
        <div><p><b>Stockholm - October 28, 2020</b> – Starting today, customers across Sweden can visit Amazon.se to shop from a selection of over 150m products, with the benefit of everyday low prices and reliable free delivery for eligible orders above SEK 229. Amazon.se features a vast selection of products across more than 30 categories, such as Books, Consumer Electronics, Sports and Outdoor, Tools and Home Improvement, Toys and Baby, including products from thousands of European and local Swedish businesses.</p><p>“We are thrilled to launch Amazon.se and to be able to offer Swedish customers a selection of more than 150 million products, including tens of thousands of products from local Swedish businesses,” said Alex Ootes, Vice President, European Expansion for Amazon. “Today is only the start of Amazon.se. We will continue to work hard to earn the trust of Swedish customers by growing our product range, ensuring low prices, and providing a convenient and trusted shopping experience.”</p><p>Swedish customers can conveniently shop from anywhere, any time with no-hassle returns and Swedish customer service through the Amazon Shopping app and desktop and mobile browsers. All customers shopping on Amazon.se enjoy free delivery for millions of items on eligible orders over SEK 229. Customers can easily browse the growing selection, read customer reviews, view personalized recommendations, create wish lists and track their orders.</p><p>Amazon is offering a wide variety of products from local Swedish brands, as well as big brand favorites. Customers can find great prices on products offered by Swedish brands like Electrolux, Lagerhaus, OBH Nordica, Ellos, BRIO, Bonnierförlagen and Ifö, as well as international brands like ASUS, Mattel, Hasbro, LEGO and Bosch.</p><p><b><em>Amazon.se offers growth opportunities for Swedish businesses – big and small</em></b><br>With the launch of Amazon.se, it will be easier for Swedish businesses to sell their products on Amazon, reach more customers and expand. Amazon has invested billions of dollars in infrastructure and technical services that help small and medium-sized businesses reach new customers across Sweden and around the world, including simple listing tools that support all seven European Amazon stores, enabling easy expansion within Europe, as well as 24/7 online Selling Partner support, open and transparent selling conditions and pricing, and reports and analytics tools to help them grow. As a result of this investment there are now 1.7 million small and medium-sized businesses around the world selling in Amazon’s stores, with more than 200,000 entrepreneurs worldwide who surpassed $100,000 in sales on Amazon in 2019.</p><p>“Today, thousands of European and local selling partners are offering their products on Amazon.se and on our other Amazon stores across the EU as well as in the US. We are excited for our international customers to experience and enjoy this Swedish selection and help grow these businesses with every purchase they make”, says Alex Ootes. “Small and medium sized companies selling in Amazon stores created an estimate 1.6 million jobs worldwide and we hope to see Swedish companies prosper in the same way.”</p><p>Pierre Magnusson, Head of E-commerce at N!CK’S, the Swedish healthy snack business, said: “The opportunities on Amazon are enormous. Amazon has grown to become our most important channel for exports, and within the first months of working with Amazon we were cash flow positive. N!CK'S continues to grow and has become one of the best-selling brands within our category, and we are still seeing 50% year-on-year growth in the EU Amazon stores alone. I would definitely recommend more Swedish companies start selling on Amazon.”</p><p>Elisabet Sandström, CEO of Miss Mary of Sweden AB, a manufacturer of high quality lingerie, said: “Amazon is an important channel for our expansion in Europe and the US, and we now look forward to selling through the Swedish Store when Amazon opens in our home country. Our sales on Amazon have increased steadily by over 50% per year, and Amazon is our fastest growing channel. Germany is currently Miss Mary’s largest customer base, and when we entered Amazon.de we noticed an immediate sales increase. We now appreciate the opportunity to reach new Swedish customers and make them happy.”</p><p><b><em>Investment in Sweden for a Sustainable Future</em></b><br>The launch of Amazon.se comes weeks after Amazon announced its largest investment in renewable energy outside of the US, with the launch (10/15) of the 91-megawatt Bäckhammar project in Western Sweden. It will support Amazon Web Services (AWS) data centers in the country, as well as the expanding Amazon retail business, and is expected to deliver 280,000-megawatt hours of clean energy annually into the Swedish grid - the equivalent of powering 29,000 average homes in Sweden. The Bäckhammar project is<em> </em>the first of two Amazon renewable energy projects to come online in Sweden. The second, a 122-megawatt onshore windfarm in Västernorrland, currently in construction, is expected to commence operations in 2022. In total, these projects will add 213 megawatts of new clean energy to the Swedish grid.</p><p>These launches takes Amazon one step closer to meeting its <span><span><a href="https://sustainability.aboutamazon.com/about/the-climate-pledge#section-nav-id-1" target="_blank" data-cms-ai="0">Climate Pledge commitments</a></span></span> of achieving net zero carbon emissions by 2040, ten years ahead of the Paris Agreement. This will be achieved through powering its operations with 100% renewable energy by 2025, making all Amazon shipments net zero carbon through Shipment Zero, with 50% of all shipments net zero carbon by 2030; ordering over 100,000 electric delivery vehicles; and investing $2 billion to support the development of technologies and services that reduce carbon emissions and help preserve the natural world.</p><p><b><em>About Amazon</em></b><br>Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. Customer reviews, 1-Click shopping, personalized recommendations, Prime, Fulfillment by Amazon, AWS, Kindle Direct Publishing, Kindle, Fire tablets, Fire TV, Amazon Echo, and Alexa are some of the products and services pioneered by Amazon. For more information, visit <span><span><a href="https://www.aboutamazon.eu/" data-amzn-id="00000162-a79c-d62f-ab6e-ef9d38f30000" data-cms-ai="0">aboutamazon.eu</a></span></span> and follow <span><span><a href="https://twitter.com/AmazonNewsEU" target="_blank" data-cms-ai="0">@AmazonNewsEU</a></span></span>.<br></p></div>
    
</div></div></div>]]>
            </description>
            <link>https://www.aboutamazon.eu/press-release/amazon-se-launches-in-sweden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916410</guid>
            <pubDate>Wed, 28 Oct 2020 08:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qt 6 will provide additional libraries via Conan package manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916321">thread link</a>) | @alaenix
<br/>
October 28, 2020 | https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday October 27, 2020 by <a href="https://www.qt.io/blog/author/iikka-eklund">Iikka Eklund</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span data-contrast="auto">With Qt 6 we want to provide more flexibility via </span><span data-contrast="auto">leveraging</span><span data-contrast="auto"> a package manager in addition to Qt </span><span data-contrast="auto">Online </span><span data-contrast="auto">Installer. The new package manager functionality, based on conan.io (</span><a href="https://conan.io/"><span data-contrast="none">https://conan.io</span></a><span data-contrast="auto">), allows provi</span><span data-contrast="auto">ding more </span><span data-contrast="auto">packages </span><span data-contrast="auto">to the users without increasing the complexity of the baseline Qt. In addition to the </span><span data-contrast="auto">packages </span><span data-contrast="auto">provided by Qt, the package manager can be used for getting content from other sources.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<!--more-->
<p><span data-contrast="auto">Initially</span><span>,</span><span data-contrast="auto"> we have three </span><span data-contrast="auto">Additional Li</span><span data-contrast="auto">b</span><span data-contrast="auto">raries </span><span data-contrast="auto">provided via the package manager: Qt Network Authorization, Qt Image Formats</span><span>,</span><span data-contrast="auto"> and Qt 3D. More </span><span data-contrast="auto">Additional Libraries </span><span data-contrast="auto">will be available </span><span data-contrast="auto">in forthcoming</span><span data-contrast="auto"> Qt 6 releases. We are currently leveraging the exis</span><span data-contrast="auto">ting Qt delivery system as</span><span data-contrast="auto"> the</span> <span data-contrast="auto">backend for the </span><span data-contrast="auto">Additional Libraries</span><span data-contrast="auto"> available via the package manager.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>How the packages are managed?&nbsp;</strong></p>
<p><span data-contrast="auto">The required </span><span data-contrast="auto">tools, Conan, </span><span data-contrast="auto">CMake</span><span>,</span><span data-contrast="auto"> and Ninja, can be easily installed u</span><span data-contrast="auto">sing</span><span data-contrast="auto"> the</span> <span><strong>Qt </strong></span><strong><span data-contrast="auto">O</span></strong><strong><span data-contrast="auto">nline installer </span></strong><strong><span data-contrast="auto">4.0</span></strong><span data-contrast="auto">, which is going to be released </span><span data-contrast="auto">soon.</span> <span data-contrast="auto">The</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> build </span><span data-contrast="auto">recipes</span> <span data-contrast="auto">for </span><span data-contrast="auto">Additional Libraries</span><span data-contrast="auto"> require </span><span data-contrast="auto">CMake</span><span data-contrast="auto"> and Ninja to build the module</span><span data-contrast="auto">.</span> <span data-contrast="auto">The project linking to the module</span> <span data-contrast="auto">can be </span><span data-contrast="auto">qmake</span><span data-contrast="auto">-</span><span data-contrast="auto">based as well.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Once installed</span><span data-contrast="auto">, </span><span data-contrast="auto">the selected </span><span data-contrast="auto">Add</span><span data-contrast="auto">itional Libraries</span> <span data-contrast="auto">can be built </span><span data-contrast="auto">once </span><span data-contrast="auto">by </span><span data-contrast="auto">using</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> per selected target configuration</span><span data-contrast="auto">. After the build</span><span data-contrast="auto">,</span><span data-contrast="auto"> the binary package is available in </span><span data-contrast="auto">user’s</span><span data-contrast="auto"> local</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> cache</span><span data-contrast="auto">, and can be </span><span data-contrast="auto">linked to any other project</span><span data-contrast="auto">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;<br></span><span></span></p>
<p><span><strong>How to get and build the packages?&nbsp;</strong><br></span><span data-contrast="auto"></span></p>
<p><span data-contrast="auto">An example build call</span> <span data-contrast="auto">look</span><span data-contrast="auto">s</span><span data-contrast="auto"> like this:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<pre>$conan.exe install qtnetworkauth/6.0.0@qt/beta --build=missing <br>--profile=&lt;QtSdk&gt;/Tools/Conan/profiles/qt-6.0.0-msvc2019_64 -s <br>build_type=Release -g cmake_paths -g=cmake -g deploy&nbsp;</pre>

<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">Now, let's look what that contains:</span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">qtnetworkauth</span><span data-contrast="auto">/6.0.0@qt/beta</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">This is the</span><span data-contrast="auto"> Conan</span><span data-contrast="auto"> reference for the package</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">You can search available packages in your </span><span data-contrast="auto">C</span><span data-contrast="auto">onan cache by:</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;&nbsp;</span><span data-contrast="auto">$conan</span><span data-contrast="auto">.exe </span><span data-contrast="auto">search</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">--profile</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">This file is installed by the Qt installer. Each </span><span data-contrast="none">Qt 6 E</span><span data-contrast="none">ssential package installed by the Qt </span><span data-contrast="none">I</span><span data-contrast="none">nstaller</span><span data-contrast="none"> installs also a matching profile file. This tells</span><span data-contrast="none"> Conan</span><span data-contrast="none"> the target build configuration.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">The user needs to select</span><span data-contrast="none"> a </span><span data-contrast="none">suitable profile</span><span data-contrast="none">, that is </span><span data-contrast="none">the target build configuration.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">-g</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">If your consuming project is a </span><span data-contrast="none">CMake</span> <span data-contrast="none">project</span><span data-contrast="none"> the</span><span data-contrast="none">n</span><span data-contrast="none"> use the</span> <span data-contrast="none">CMake</span><span data-contrast="none"> generators</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">If your consuming project is</span><span data-contrast="none"> a</span> <span data-contrast="none">qmake</span> <span data-contrast="none">project</span><span data-contrast="none"> then you can pass: -g </span><span data-contrast="none">qmake</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="none">The “deploy” generator deploys the buil</span><span data-contrast="none">t</span><span data-contrast="none"> A</span><span data-contrast="none">dditional Library</span><span data-contrast="none"> from </span><span data-contrast="none">the</span><span data-contrast="none"> Conan</span><span data-contrast="none"> cache to your working environment</span><span data-contrast="none">. This is useful if you </span><span data-contrast="none">want to bundle your application files together.</span><span data-ccp-props="{&quot;134233279&quot;:true,&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ul>
</li>
</ul>
<p><span data-contrast="none">For detailed steps see the <a data-insert="true" href="https://wiki.qt.io/Qt6_Add-on_src_package_build_using_Conan_package_manager" rel="noopener">instructions</a>.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="none">Currently</span><span data-contrast="none">,</span><span data-contrast="none"> Qt </span><span data-contrast="none">Online </span><span data-contrast="none">Installer exports the A</span><span data-contrast="none">dditional Library packages (sources and build recipes)</span><span data-contrast="none"> into the</span><span data-contrast="none"> Conan</span><span data-contrast="none"> cache. There is no </span><span data-contrast="none">C</span><span data-contrast="none">onan remote that hosts the Add</span><span data-contrast="none">itional Library</span> <span data-contrast="none">C</span><span data-contrast="none">onan packages</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p aria-level="2"><strong>Next steps&nbsp;</strong></p>
<p><span data-contrast="none">Like Qt 6.0, the current work is still in beta phase and </span><span data-contrast="none">all </span><span data-contrast="none">feedback is welcome</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;Note that currently the Conan profile files and build recipies for&nbsp;</span><span data-contrast="none">Android and iOS targets are being worked on</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;Also, t</span><span data-contrast="none">he build recipes of the </span><span data-contrast="none">Additional Libraries</span><span data-contrast="none"> are not part of the repositories yet. </span><span>&nbsp;</span><span data-contrast="none">Once the build recipes</span><span data-contrast="none"> are mature</span><span data-contrast="none"> the plan is to move those into module repositories.</span><span>&nbsp;</span></p>
<p><span></span><span data-contrast="none">If you want to have a look already now</span><span data-contrast="none">,</span><span data-contrast="none"> how</span><span data-contrast="none"> the conanfile.py recipes </span><span data-contrast="none">look like</span><span data-contrast="none">,</span> <span data-contrast="none">those </span><span data-contrast="none">can be found </span><span data-contrast="none">in</span> <span data-contrast="none">the </span><span data-contrast="none">Qt installation, under each module in “</span><span data-contrast="none">AdditionalLibraries</span><span data-contrast="none">/Qt</span><span data-contrast="none">/”</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
&nbsp;</span></p>
                            
                            
                                <hr>
                          
                                <h6>Blog Topics:</h6>        
                                
                            


                        </div></div>]]>
            </description>
            <link>https://www.qt.io/blog/qt-6-additional-libraries-via-package-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916321</guid>
            <pubDate>Wed, 28 Oct 2020 07:55:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sjgar Stack]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24916319">thread link</a>) | @vijairamcharan
<br/>
October 28, 2020 | https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack | <a href="https://web.archive.org/web/*/https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><em>Published October 28th, 2020 – 20 min read</em></p>
<p><strong>In this article I will introduce you to a new software stack that can be thought of as a spiritual successor to the MEAN or MERN stack. The technologies in the SJGAR stack were carefully combined to create something where the whole is greater than the sum of its parts. Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</strong></p>
<p><strong>If you want to find out why the mix of Serverless, JavaScript, GraphQL, AWS and React could be interesting to you please read on.</strong></p>
<p><em>Disclaimer: This is <strong>not</strong> a sponsored post. All views expressed in this article are mine and may or may not be shared by my employer.</em></p>
<p><span>
      <a target="_blank" rel="noopener" href="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg">
    <span></span>
  <img alt="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" title="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" src="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg" srcset="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/e6c22/pexels-archie-binamira-672358.jpg 205w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/0d3fb/pexels-archie-binamira-672358.jpg 410w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg 820w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/4f4d6/pexels-archie-binamira-672358.jpg 1230w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/b68c0/pexels-archie-binamira-672358.jpg 1640w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg 6000w" sizes="(max-width: 820px) 100vw, 820px" loading="lazy">
  </a>
    </span></p>

<p>I remember writing software in the period roughly between 2005 and 2015 where sometimes it could feel like every week something new was thrown at us. We were transitioning from desktop to the web and then cloud and mobile. We were just getting good at Object-oriented programming when a shift towards Functional Programming required us to rethink our mental models around our code. Cloud scale computing brought us from solely using SQL databases to study and use NoSQL databases. We went from embracing XML and SOAP to transitioning to JSON.</p>
<div><p><h3>Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</h3></p></div>

<p>Looking at JavaScript alone there was also a lot of turmoil. The language started almost as a toy language to glue together simple elements on a web page. Then it slowly but steadily grew into becoming the most widely used programming language on the web. It even moved on beyond the browser and started to conquer the server with Node.js. A realm where Java and .NET were dominant before, now had to create some room for people starting to use JavaScript on the server.</p>
<p>On the web, framework after framework was becoming popular. Much to the point where they are still being refactored away ten years later. I remember moving from jQuery to Backbone or Knockout. I used Ember a bit and then also Angular. All of these seemed to offer some improvements over what was previously there. There were still enough rough edges however. It was clear we were not there yet.</p>
<div id="enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time"><h3><a href="#enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time" target="_blank" rel="noopener noreferrer" aria-label="enter the calm and how we used the sjgar stack for the first time permalink"></a>Enter the Calm and how we used the SJGAR stack for the first time.</h3></div>
<p>In 2015, I got the chance to work on a corporate startup project that was completely greenfield. We set out to create a platform with web and mobile apps with state-of-the-art user experience, and we wanted to fail or succeed fast. This meant we had to ensure a short time to market. We had to focus on developer experience and productivity. After having tried some pieces of technology on smaller projects, this was the perfect chance to put them together and figure out if they would play nicely together. In theory, it should all work, but previous experience had shown that you really need to start using them for a decent amount of time to figure out if the new advantages will really outweigh the drawbacks.</p>
<div><p><h3>It worked. It really worked.</h3></p></div>
<p>We built a web application using React and an accompanying mobile app using React Native. The backend was built using AWS Serverless technologies. We used DynamoDB as the single source of truth for data. The built-in event triggering system was used to run some Node.js code in a Lambda to stream this data to a managed Elasticsearch cluster, so we could support the search and query capabilities we needed. We created a GraphQL API using the reference server implementation graphql-js (Apollo Server and Client weren't a thing back then). Again this was run in Lambda. To make sure the web application was performant enough for our end users we used a Lambda to implement Server Side Rendering (Gatsby and Next.js also weren't a thing back then). We also used the Serverless framework, a bit shaky at that time, to write our infra as code.</p>
<p>With a handful of full stack engineers we were able to deliver this project successfully to production. We could deliver new versions of our microservices independently, and we would do this multiple times a day.</p>
<p>It worked. It really worked.</p>
<p>We started with almost zero costs for infrastructure. The most expensive service was the Elasticsearch service. The other services would easily service our first customers on the free tier. I think we never spent over 100 euros a month. Without Elasticsearch it would probably not have been higher than 10 euros a month. We launched and started running ad campaigns to lure customers to our new offering. For these ad campaigns we were spending over a thousand euros per month. It was clear that we now could go to the business and tell them we could do innovation projects with IT running costs of close to zero.</p>
<p>I remember we were able to move some logic from the web app to the authentication provider (we used Auth0 back then since Cognito was still a bit too new) by just copying some JavaScript code. Similarly, we were able to move code from frontend to backend. More generally we were able to take what we learned in a certain context, and apply it to a different one. JavaScript allowed us to learn a single programming language and write code for the Web, Mobile and Cloud. React allowed us to use a single framework to structure applications and do the state management for both Web and Mobile. Using Flexbox we could even apply the same UI layout system in these apps. With the complex and time-consuming nature of layout work, it was great that we were able to reuse our knowledge and tools to enjoy a great productivity boost.</p>
<p>Going Serverless meant we did not have to spend time on managing servers. The code and the system would just work. No disks filling up, no security patches to be applied, no certificates to be updated. AWS had given us a platform with great performance and stability. Everything would just run.</p>
<p>After running this project in 2015 and 2016, in the end it was shuttered because it did not align with our business goals. Only later I came to realize this set of technologies would stand the test of time, and would do so pretty well.</p>
<div id="okay-this-thing-needs-a-name"><h3><a href="#okay-this-thing-needs-a-name" target="_blank" rel="noopener noreferrer" aria-label="okay this thing needs a name permalink"></a>Okay. This Thing Needs A Name.</h3></div>
<p>Fast-forward a bit to when I joined my current team and company early 2019. We formed a new innovation department and dreamed of a future where we helped turn our 175-year-old financial company into a fintech. Teaming up with the department that was our business counterpart, in the first year we built and delivered a total of fourteen projects with a relatively common two pizza team. In the previous nineteen years of my career I had never witnessed anything like this. We built smaller projects like landing pages, but also large ones like a new platform to sell houses using data and AI. We also built a fairly complex API to serve as the backend for an IoT driven car insurance. We even managed to surprise ourselves and win a hackathon in our first year with a mobile app for planting trees.</p>
<div><p><h3>Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</h3></p></div>
<p>Many things fell into place to make this a success. For one, it were the amazing people we joined. I consider myself lucky to this day that we met them and were able to make all of these things happen. It was almost as if we started in a performing phase as a team, skipping the forming, norming and storming phases altogether.</p>
<p>Besides the people the technology played an important role here. Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</p>
<p>What was really cool was that we were able to deliver all these different types of applications using basically the same architecture. For the IoT insurance, the API we delivered we implemented a lightweight event sourced system using mainly DynamoDB and Lambda. We later added a future event system where we combined DynamoTTL and Step Functions to combine high and low resolution timers, all of which were inspired by a set of blog posts and a tweet we found on the web.</p>
<p>For the housing platform we combined Cognito, Azure AD, DynamoDB, Lambda, AppSync, S3 and CloudFront to deliver a platform that was highly performant. Gatsby helped us leverage React’s power to build statically rendered, SEO-friendly pages, hosted on S3 and made available to the wide internet using CloudFront and Route53. On the backend we created a GraphQL API to, on the one hand, power the build-time data requirements. On the other hand it also powered the real-time admin panel we needed for providing customers support.</p>
<p>There were many more projects that used very similar architectures. Five years after first having used these technologies we were still able to use them to build modern applications. In our hiring process I remember seeing the smiles on the faces of the engineers when we would mention our tech stack.</p>
<div><p><h3>Which parts are going to be successful for at least the next five years?</h3></p></div>
<p>There was this one thing I noticed though. Whenever I wanted to explain our technology stack, I was summing up this combination of technologies one by one. Time after time saying things like “Our stack is JavaScript based, uses the React ecosystem and runs on AWS Serverless... And oh yeah we use GraphQL as a BFF for our apps.” A couple of days later I would say something like “We build apps using React and use JavaScript/TypeScript. Our APIs are running on AWS Lambda using NodeJS.”. And then many more variations of these sentences.</p>
<p>Okay. This thing needs a name.</p>
<p>Back in the days we had the LAMP stack, and some time after that there was the MEAN stack. Acronyms that became part of our vocabulary to help explain the stack we were using, or even inspired greenfield projects to combine these technologies. People would think, hey, I recently have been hearing a lot of buzz around the MEAN …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</a></em></p>]]>
            </description>
            <link>https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916319</guid>
            <pubDate>Wed, 28 Oct 2020 07:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using an AWS ECR Image as a GitHub Action Container]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24916221">thread link</a>) | @mbitard
<br/>
October 28, 2020 | https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/ | <a href="https://web.archive.org/web/*/https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <h2 id="moving-from-docker-hub-to-ecr">Moving from Docker Hub to ECR</h2>

<p><a href="https://pubstack.io/">Pubstack</a>, my current client decided to migrate all its docker images to <a href="https://aws.amazon.com/ecr/">ECR</a>.</p>

<p>With the recent <a href="https://www.docker.com/pricing/resource-consumption-updates">announcement</a> about rate limiting on Docker Hub, maybe we will not be the only ones moving away.</p>

<p>For our <strong>CI/CD</strong> pipelines we use both <a href="https://circleci.com/">CircleCI</a> and <a href="https://github.com/features/actions">GitHub Actions</a>.</p>

<p>Using an <strong>ECR</strong> image is a really simple task in <strong>CircleCI</strong>, it consists of adding the <code>aws_auth</code> to the image configuration.</p>

<div><div><pre><code>  <span>docker</span><span>:</span>
    <span>-</span> <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>aws_auth</span><span>:</span>
        <span>aws_access_key_id</span><span>:</span> <span>$AWS_ACCESS_KEY_ID</span>
        <span>aws_secret_access_key</span><span>:</span> <span>$AWS_SECRET_ACCESS_KEY</span>
</code></pre></div></div>

<p>On the other hand, using <strong>ECR</strong> images in <strong>GitHub Actions</strong> was a bit more tricky.</p>

<p>The problem is, you could only use images from private registries in job and service containers since <a href="https://github.blog/changelog/2020-09-24-github-actions-private-registry-support-for-job-and-service-containers/">late september</a>, and they only did the “credentials” implementation.
It means something like this is expected:</p>

<div><div><pre><code><span>jobs</span><span>:</span>
  <span>test</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>credentials</span><span>:</span>
        <span>username</span><span>:</span> <span>AWS</span>
        <span>password</span><span>:</span> <span>${{ secrets.ECR_PASSWORD }}</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>run</span><span>:</span> <span>echo "inside an ecr container"</span>
</code></pre></div></div>

<p>With aws, you can get a password with <code>aws ecr get-login-password</code>, and it is valid 12 hours.</p>

<p>You can manually set the GitGub secret “ECR_PASSWORD” every 12 hours, but that’s not really convenient.</p>

<p>After a little digging, I found an <a href="https://github.community/t/github-actions-new-pulling-from-private-docker-repositories/16089/28">answer</a> on a GitHub community thread explaining what seems like a good solution.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>Basically what we will do is:</p>

<ol>
  <li>Retrieve <strong>ECR</strong> password from aws</li>
  <li>Store it as a <strong>GitHub</strong> secret name <code>ECR_PASSWORD</code></li>
</ol>

<p>All that inside a <strong>GitHub</strong> action scheduled to run every 6 hours.</p>

<p>It was not really as simple as I first thought, so here is all I had to do.
I hope it can help you.</p>

<p>First, I created some aws credentials (ie. a couple <code>aws_access_key_id</code> and <code>aws_secret_access_key</code> with enough right to pull from ECR)
I put them as secrets inside the <strong>GitHub</strong> project, let’s call them <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>.
Then I generated a personal access token (the “provided by default” <code>GITHUB_TOKEN</code> doest not have sufficient rights), let’s call it <code>GH_API_ACCESS_TOKEN</code>.</p>

<p>The complete <strong>GitHub</strong> workflow:</p>

<div><div><pre><code><span>name</span><span>:</span> <span>ecr-login</span>
<span>on</span><span>:</span>
  <span># Every 6 hours, the password validity is 12 hours</span>
  <span>schedule</span><span>:</span>
    <span>-</span> <span>cron</span><span>:</span>  <span>'</span><span>0</span><span> </span><span>*/6</span><span> </span><span>*</span><span> </span><span>*</span><span> </span><span>*'</span>
<span>jobs</span><span>:</span>
  <span>login</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>Checkout</span>
        <span>uses</span><span>:</span> <span>actions/checkout@v2</span>
      <span>-</span> <span>name</span><span>:</span> <span>AWS cli install action</span>
        <span>uses</span><span>:</span> <span>chrislennon/action-aws-cli@1.1</span>
      <span>-</span> <span>name</span><span>:</span> <span>retrieve ecr password and store as secret</span>
        <span>run</span><span>:</span> <span>|</span>
          <span>pip3 install -r .github/requirements.txt</span>
          <span>python3 .github/ecr_password_updater.py</span>
        <span>env</span><span>:</span>
          <span>AWS_ACCESS_KEY_ID</span><span>:</span> <span>${{ secrets.AWS_ACCESS_KEY_ID }}</span>
          <span>AWS_SECRET_ACCESS_KEY</span><span>:</span> <span>${{ secrets.AWS_SECRET_ACCESS_KEY }}</span>
          <span>AWS_DEFAULT_REGION</span><span>:</span> <span>AWS_REGION</span>
          <span>GH_API_ACCESS_TOKEN</span><span>:</span> <span>${{ secrets.GH_API_ACCESS_TOKEN }}</span>
  <span># This 'test' job is usefull for fast debugging</span>
  <span>test</span><span>:</span>
    <span>needs</span><span>:</span> <span>login</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> <span>ACCOUNT.dkr.ecr.REGION.amazonaws.com/IMAGE:VERSION</span>
      <span>credentials</span><span>:</span>
        <span>username</span><span>:</span> <span>AWS</span>
        <span># Here is the password retrieved as a secret that is set by the `login` job</span>
        <span>password</span><span>:</span> <span>${{ secrets.ECR_PASSWORD }}</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>run</span><span>:</span> <span>echo "Inside a container pulled from ECR \o/"</span>
</code></pre></div></div>

<p>The python file <code>ecr_password_updater.py</code>:</p>

<div><div><pre><code><span>from</span> <span>base64</span> <span>import</span> <span>b64encode</span>
<span>from</span> <span>nacl</span> <span>import</span> <span>encoding</span><span>,</span> <span>public</span>
<span>import</span> <span>requests</span>
<span>import</span> <span>os</span>
<span>import</span> <span>subprocess</span>
<span>import</span> <span>json</span>


<span>def</span> <span>encrypt</span><span>(</span><span>raw_public_key</span><span>:</span> <span>str</span><span>,</span> <span>secret_value</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>"""Encrypt a Unicode string using the public key."""</span>
    <span>public_key</span> <span>=</span> <span>public</span><span>.</span><span>PublicKey</span><span>(</span><span>raw_public_key</span><span>.</span><span>encode</span><span>(</span><span>"utf-8"</span><span>),</span> <span>encoding</span><span>.</span><span>Base64Encoder</span><span>())</span>
    <span>sealed_box</span> <span>=</span> <span>public</span><span>.</span><span>SealedBox</span><span>(</span><span>public_key</span><span>)</span>
    <span>encrypted</span> <span>=</span> <span>sealed_box</span><span>.</span><span>encrypt</span><span>(</span><span>secret_value</span><span>.</span><span>encode</span><span>(</span><span>"utf-8"</span><span>))</span>
    <span>return</span> <span>b64encode</span><span>(</span><span>encrypted</span><span>).</span><span>decode</span><span>(</span><span>"utf-8"</span><span>)</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>

    <span>get_public_key</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>f'https://api.github.com/repos/ORG/REPOSITORY/actions/secrets/public-key'</span><span>,</span>
                                  <span>headers</span><span>=</span><span>{</span><span>'Accept'</span><span>:</span> <span>'application/vnd.github.v3+json'</span><span>,</span>
                                           <span>'Authorization'</span><span>:</span> <span>'token '</span> <span>+</span> <span>os</span><span>.</span><span>environ</span><span>[</span><span>'GH_API_ACCESS_TOKEN'</span><span>]})</span>
    <span>if</span> <span>get_public_key</span><span>.</span><span>ok</span> <span>is</span> <span>False</span><span>:</span>
        <span>print</span><span>(</span><span>'could not retrieve public key'</span><span>)</span>
        <span>print</span><span>(</span><span>get_public_key</span><span>.</span><span>text</span><span>)</span>
        <span>exit</span><span>(</span><span>1</span><span>)</span>
    <span>get_public_key_response</span> <span>=</span> <span>get_public_key</span><span>.</span><span>json</span><span>()</span>
    <span>public_key_value</span> <span>=</span> <span>get_public_key_response</span><span>[</span><span>'key'</span><span>]</span>
    <span>public_key_id</span> <span>=</span> <span>get_public_key_response</span><span>[</span><span>'key_id'</span><span>]</span>

    <span>password</span> <span>=</span> <span>subprocess</span><span>.</span><span>run</span><span>([</span><span>'aws'</span><span>,</span> <span>'ecr'</span><span>,</span> <span>'get-login-password'</span><span>],</span> <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>PIPE</span><span>).</span><span>stdout</span><span>.</span><span>decode</span><span>(</span><span>'utf-8'</span><span>)</span>
    <span>encrypted_password</span> <span>=</span> <span>encrypt</span><span>(</span><span>public_key_value</span><span>,</span> <span>password</span><span>)</span>
    <span>update_password</span> <span>=</span> <span>requests</span><span>.</span><span>put</span><span>(</span><span>'https://api.github.com/repos/ORG/REPOSITORY/actions/secrets/ECR_PASSWORD'</span><span>,</span>
                                   <span>headers</span><span>=</span><span>{</span><span>'Accept'</span><span>:</span> <span>'application/vnd.github.v3+json'</span><span>,</span>
                                            <span>'Authorization'</span><span>:</span> <span>'token '</span> <span>+</span> <span>os</span><span>.</span><span>environ</span><span>[</span><span>'GH_API_ACCESS_TOKEN'</span><span>]},</span>
                                   <span>data</span><span>=</span><span>json</span><span>.</span><span>dumps</span><span>({</span><span>'encrypted_value'</span><span>:</span> <span>encrypted_password</span><span>,</span> <span>'key_id'</span><span>:</span> <span>public_key_id</span><span>}))</span>
    <span>if</span> <span>update_password</span><span>.</span><span>ok</span> <span>is</span> <span>False</span><span>:</span>
        <span>print</span><span>(</span><span>'could not update password'</span><span>)</span>
        <span>print</span><span>(</span><span>update_password</span><span>.</span><span>text</span><span>)</span>
        <span>exit</span><span>(</span><span>1</span><span>)</span>

</code></pre></div></div>

<p>The dependencies used by the python code:</p>
<div><div><pre><code>pynacl==1.4.0
requests==2.24.0
</code></pre></div></div>

<p>I first started with a simple bash script, but it became quite complex<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, so I switched to python.</p>

<p>Enjoy!</p>



    </div></div>]]>
            </description>
            <link>https://agileek.github.io/software/aws/2020/10/28/using-an-ecr-image-in-github-actions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916221</guid>
            <pubDate>Wed, 28 Oct 2020 07:37:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing Kernel Functions: FBT stack() and arg]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915942">thread link</a>) | @moks
<br/>
October 27, 2020 | https://zinascii.com/2020/fbt-args-and-stack.html | <a href="https://web.archive.org/web/*/https://zinascii.com/2020/fbt-args-and-stack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
      <p>Oct 27, 2020</p>

      <p>
	In my <a href="https://zinascii.com/2020/the-amd64-fbt-handler.html">previous
	post</a> I described how FBT intercepts function calls and
	vectors them into the DTrace framework. That laid the
	foundation for what I want to dicuss in this post: the
	implementation of the <code>stack()</code> action and
	built-in <code>arg</code> variables. These features rely on
	the precise layout of the stack, the details of which I
	touched on previously. In this post I hope to illuminate those
	details a bit more with the help of some visuals, and then
	guide you through the implentation of these two DTrace
	features as they relate to the FBT provider.
      </p>

      <h2>A Correction</h2>

      <p>
	But first I must make a correction to my last post. It turns
	out the FBT handler <b>does not</b> execute on the IST stack.
	It runs on either the thread’s stack or the CPU’s high-level
	interrupt stack depending on the context of the kernel
	function call, but never on the IST.
	Rather, <a href="https://en.wikipedia.org/wiki/Kernel_page-table_isolation">KPTI</a>
	uses the IST stack as a scratch space to perform its
	trampoline into the real handler. This little detail is
	important. Functions like <code>dtrace_getpcstack()</code>
	have zero chance of working if run with the IST stack, for
	reasons which become obvious later. This also explains why the
	AMD64 handler pulls down the stack
	during <code>pushq&nbsp;%RBP</code> emulation: if it’s working
	on the same stack as the thread/interrupt, then it must make
	room for <code>RBP</code>. I can explain better with a visual.
	First, the diagram from the last post.
      </p>

      <figure>
	  
	  <figcaption><a name="fig1-int3-pre-handler">Figure 1. INT3 thread/interrupt state pre-handler</a></figcaption>
      </figure>

      <p>
	On the left we have a kernel thread, interrupt thread, or
	high-level interrupt running on CPU. On the right we have the
	“interrupt context” of the breakpoint exception, using the
	IST. The image is correct in that there are two different
	stacks in play, but what’s running on the right-hand side is
	not the <code>brktrap</code> handler. The right-hand side is
	running the KPTI trampoline, ensuring a CR3 switch when moving
	between the user/kernel boundary. The trampoline also provides
	a facsimile of the processor frame to the interrupted thread’s
	stack, making it none the wiser that KPTI was ever on the
	scene. So all the action happens on the left side, but what
	does the stack look like as we transition through the #BP
	handler on our way to <code>dtrace_invop()</code>?
      </p>

      <figure>
	  
	  <figcaption><a name="fig2-pre-fbt-stack">Figure 2. stack state from #BP to pre dtrace_invop()</a></figcaption>
      </figure>

      <p>
	In phase ① <code>mac_provider_tx()</code> is
	calling <code>mac_ring_tx()</code> while it is under FBT entry
	instrumentation. The last thing on the thread’s stack is the
	return address, and the CPU is about to execute
	the <code>int3</code> instruction.
      </p>

      <p>
	Phase ② is immediately after the CPU has finished execution of
	the <code>int3</code> instruction. The processor (via the
	spectre of the KPTI trampoline) has pushed a 16-byte aligned
	processor frame on the stack and has vectored into
	the <code>brktrap()</code> handler.
      </p>

      <p>
	Phase ③ is after some amount of execution of
	the <code>brktrp()</code> and <code>invoptrap()</code>
	handlers—remember, the #BP handler for DTrace mimics a #UD.
	This last phase shows the state just before the call
	to <code>dtrace_invop()</code>. At this point we’ve grown an
	entire <code>regs</code> structure on the stack and stashed a
	copy of the return address on top of this. The later used to
	populate <code>cpu_dtrace_caller</code>, a variable which
	becomes important later.
      </p>

      <h2>The stack() Action</h2>

      <p>
	The separation of probes and actions is a vital aspect of
	DTrace’s architecture. A firm boundary between these two makes
	DTrace more powerful than it ever could be if they were
	tightly coupled. Think about it, I can ask for the call stack
	in any probe, not just the probes that deem that information
	useful. The probes give you access to a context, and the
	actions give you access to data in that context. To limit the
	execution of actions to specific probes would limit the
	questions you can ask about the system. With this design the
	number of questions you can ask is virtually endless. And it
	turns out one of the more useful questions to ask is: “what
	the hell is running on my CPU”?
      </p>

      <p>
	The <code>stack()</code> action allows you to record the call
	stack that lead to the probe site. In the context of FBT this
	will record the call stack of the kernel thread or interrupt
	executing an entry or return from this kernel function. You
	can also access the userland stack of a thread
	via <code>ustack()</code>, but I don’t cover that here.
      </p>

      <p>
	The <code>stack()</code> action is implemented by
	the <code>dtrace_getpcstack()</code> function. To get there
	from <code>dtrace_invop()</code> requires a couple of more
	calls in the DTrace framework. Ultimately, the call stack to
	get there looks like this.
      </p>

      <figure>
	<div>
	  <pre><code>dtrace_getpcstack()
dtrace_probe()
fbt_invop()
dtrace_invop()
dtrace_invop_callsite() &lt;aka invoptrap&gt;
&lt;rest of call stack that lead here&gt;</code></pre>
	</div>
	<figcaption>call stack between dtrace_getpcstack() and dtrace_invop()</figcaption>
      </figure>

      <p>
	The implementation of <code>stack()</code> really starts
	with <code>DTRACEACT_STACK</code> inside
	of <code>dtrace_probe()</code>.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/common/dtrace/dtrace.c#L7184-L7191">usr/src/uts/common/dtrace/dtrace.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>			case DTRACEACT_STACK:</code></span>
<span><span></span><code>				if (!dtrace_priv_kernel(state))</code></span>
<span><span></span><code>					continue;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>				dtrace_getpcstack((pc_t *)(tomax + valoffs),</code></span>
<span><span></span><code>				    size / sizeof (pc_t), probe-&gt;dtpr_aframes,</code></span>
<span><span></span><code>				    DTRACE_ANCHORED(probe) ? NULL :</code></span>
<span><span></span><code>				    (uint32_t *)arg0);</code></span></pre>
	  </div>
	  <figcaption>stack() action implementation found in dtrace_probe()</figcaption>
	</figure>
      </figure>

      <p>
	The first argument is the address of the array used to store
	program counter values (aka function pointers). This array
	starts at some offset into the current DTrace buffer. The
	second argument if the size of that array. The third argument
	is the number of “artificial frames” on the stack, more on
	this later. The fourth argument is used to determine if the
	first (topmost) program counter in the call stack is the value
	passed in <code>arg0</code> to <code>dtrace_probe()</code>. An
	“anchored” probe is one that has a function name specified
	when calling <code>dtrace_probe_create()</code>. For example,
	the FBT provider uses the name of the kernel function as the
	probe’s function name, thus it is anchored on the kernel
	function. The profile provider, however, specifies no probe
	function name; it is not anchored and is a bit of a special
	case. I address this at the end of the post.
      </p>

      <p>
	This brings us to the <code>dtrace_getpcstack()</code>
	function. But first I’ll expand
	on <a href="#fig2-pre-fbt-stack">figure 2</a> to show our
	stack state as of source line 60 of the function.
      </p>

      <figure>
	
	<figcaption>
	  <a name="fig3-start-of-dtrace_getpcstack">Figure 3. start of dtrace_getpcstack()</a>
	</figcaption>
      </figure>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L43-L60">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>void</code></span>
<span><span></span><code>dtrace_getpcstack(pc_t *pcstack, int pcstack_limit, int aframes,</code></span>
<span><span></span><code>    uint32_t *intrpc)</code></span>
<span><span></span><code>{</code></span>
<span><span></span><code>	struct frame *fp = (struct frame *)dtrace_getfp();</code></span>
<span><span></span><code>	struct frame *nextfp, *minfp, *stacktop;</code></span>
<span><span></span><code>	int depth = 0;</code></span>
<span><span></span><code>	int on_intr, last = 0;</code></span>
<span><span></span><code>	uintptr_t pc;</code></span>
<span><span></span><code>	uintptr_t caller = CPU-&gt;cpu_dtrace_caller;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>	if ((on_intr = CPU_ON_INTR(CPU)) != 0)</code></span>
<span><span></span><code>		stacktop = (struct frame *)(CPU-&gt;cpu_intr_stack + SA(MINFRAME));</code></span>
<span><span></span><code>	else</code></span>
<span><span></span><code>		stacktop = (struct frame *)curthread-&gt;t_stk;</code></span>
<span><span></span><code>	minfp = fp;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>	aframes++;</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	To build the call stack we first need to be able to walk the
	stack. Luckily, illumos keeps frame pointers in the kernel,
	making this easy. But in this particular situation there is
	more to consider. First, we might have two stacks in play: the
	high-level interrupt’s stack as well as the stack of the
	thread it interrupted. Second, the DTrace framework and FBT
	provider have put their own frames between this code and the
	function that tripped this probe; we must exclude these
	“artificial” frames from the result. Finally, we need to make
	sure not to walk off the stack and into space, both for
	correctness and safety. Speaking of the stack,
	the <code>stacktop</code> variable is pointing to the “top” of
	the stack in terms of memory (on x86 stacks grow downwards).
	Logically speaking, <code>stacktop</code> is the bottom of the
	stack and the <code>dtrace_getpcstack()</code> frame is the
	top.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L62-L63">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>	if (intrpc != NULL &amp;&amp; depth &lt; pcstack_limit)</code></span>
<span><span></span><code>		pcstack[depth++] = (pc_t)intrpc;</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	If <code>intrpc</code> is set, then that’s our first program counter.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L65-L85">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>	while (depth &lt; pcstack_limit) {</code></span>
<span><span></span><code>		nextfp = (struct frame *)fp-&gt;fr_savfp;</code></span>
<span><span></span><code>		pc = fp-&gt;fr_savpc;</code></span>
<span><span></span><code></code></span>
<span><span></span><code>		if (nextfp &lt;= minfp || nextfp &gt;= stacktop) {</code></span>
<span><span></span><code>			if (on_intr) {</code></span>
<span><span></span><code>				/*</code></span>
<span><span></span><code>				 * Hop from interrupt stack to thread stack.</code></span>
<span><span></span><code>				 */</code></span>
<span><span></span><code>				stacktop = (struct frame *)curthread-&gt;t_stk;</code></span>
<span><span></span><code>				minfp = (struct frame *)curthread-&gt;t_stkbase;</code></span>
<span><span></span><code>				on_intr = 0;</code></span>
<span><span></span><code>				continue;</code></span>
<span><span></span><code>			}</code></span>
<span><span></span><code></code></span>
<span><span></span><code>			/*</code></span>
<span><span></span><code>			 * This is the last frame we can process; indicate</code></span>
<span><span></span><code>			 * that we should return after processing this frame.</code></span>
<span><span></span><code>			 */</code></span>
<span><span></span><code>			last = 1;</code></span>
<span><span></span><code>		}</code></span></pre>

	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	The main loop walks the call stack and fills in program
	counters as long as there are slots remaining in
	<code>pcstack</code>. If we were in the context of a
	high-level interrupt and we’ve walked off its stack, then hop
	to the thread stack. Otherwise, we’ve walked off the thread
	stack, leaving just this last frame to record.
      </p>

      <figure>
	<figcaption><a href="https://github.com/illumos/illumos-gate/blob/007ca33219ffdc49281657f5f8a9ee1bbfc367ab/usr/src/uts/intel/dtrace/dtrace_isa.c#L87-L98">usr/src/uts/intel/dtrace/dtrace_isa.c</a></figcaption>
	<figure>
	  <div>
<pre><span><span></span><code>		if (aframes &gt; 0) {</code></span>
<span><span></span><code>			if (--aframes == 0 &amp;&amp; caller != 0) {</code></span>
<span><span></span><code>				/*</code></span>
<span><span></span><code>				 * We've just run out of artificial frames,</code></span>
<span><span></span><code>				 * and we have a valid caller -- fill it in</code></span>
<span><span></span><code>				 * now.</code></span>
<span><span></span><code>				 */</code></span>
<span><span></span><code>				ASSERT(depth &lt; pcstack_limit);</code></span>
<span><span></span><code>				pcstack[depth++] = (pc_t)caller;</code></span>
<span><span></span><code>				caller = 0;</code></span>
<span><span></span><code>			}</code></span>
<span><span></span><code>		} else {</code></span></pre>
	  </div>
	  <figcaption>dtrace_getpcstack()</figcaption>
	</figure>
      </figure>

      <p>
	Make sure to skip over any artificial frames.
	The <code>aframes</code> value is based on information given
	by the provider at probe creation time
	(<code>dtrace_probe_create()</code>/<code>dtpr_aframes</code>)
	as well as knowledge inherent to the DTrace framework. These
	two know how many frames they have each injected between
	the <code>stack()</code> action and the first real frame; we
	sum the values to know how many total frames to skip.
      </p>

      <p>
	The <code>caller</code> variable is a bit more subtle; and
	this is another thing I got wrong in
	my <a href="https://zinascii.com/2020/the-amd64-fbt-handler.html">last post</a> while
	discussing the return probe. The <code>caller</code> value
	…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zinascii.com/2020/fbt-args-and-stack.html">https://zinascii.com/2020/fbt-args-and-stack.html</a></em></p>]]>
            </description>
            <link>https://zinascii.com/2020/fbt-args-and-stack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915942</guid>
            <pubDate>Wed, 28 Oct 2020 06:39:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub should stand up to the RIAA over YouTube-dl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915885">thread link</a>) | @pabs3
<br/>
October 27, 2020 | https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/ | <a href="https://web.archive.org/web/*/https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this week, <a href="https://www.zdnet.com/article/riaa-blitz-takes-down-18-github-projects-used-for-downloading-youtube-videos/">GitHub took down the repository</a> for the youtube-dl project. This came in response to a request from the RIAA—the recording industry’s lobbying and harassment body. youtube-dl is a tool for downloading videos. The RIAA argued that this violates the anticircumvention protections of the Digital Millennium Copyright Act (DMCA). While GitHub taking down the repository and its forks is true to the principle of minimizing corporate risk, it’s the wrong choice.</p>



<p> Microsoft—currently the world’s second-most valuable company with a market capitalization of $1.64 trillion—owns GitHub. If anyone is in a position to fight back on this, it’s Microsoft. Microsoft’s lawyers should have a one word answer to the RIAA’s request: “no”. <em>(full disclosure: I own a small number of shares of Microsoft)</em></p>



<h2>The procedural argument</h2>



<p>The first reason to tell the RIAA where to stick it is procedural. The RIAA isn’t arguing that youtube-dl is infringing its copyrights or circumventing its protections. It is arguing that youtube-dl infringes YouTube’s protections. So even if it is, that’s YouTube’s problem, not the RIAA’s.</p>



<h2>The factual argument</h2>



<p>I have some sympathy for the anticircumvention argument. I’m not familiar with the specifics of how youtube-dl works, but it’s at least possible that youtube-dl circumvents YouTube’s copy protection. This would be a reasonable basis for YouTube to take action. Again, YouTube, not the RIAA.</p>



<p>I have less sympathy for the infringement argument. youtube-dl doesn’t induce infringement more than a web browser or screen recorder does. There are a variety of uses for youtube-dl that are not infringing. Foremost is the fact that some YouTube videos are under a license that explicitly allows sharing and remixing. Archivers use it to archive content. Some people who have time-variable Internet billing use it to download videos overnight.</p>



<p>So, yes, youtube-dl can be used to infringe the RIAA’s copyrights. It can also be used for non-infringing purposes. The code itself does not infringe. There’s nothing about it that gives the RIAA a justification to take it down.</p>



<h2>youtube-dl isn’t the whole story</h2>



<p>youtube-dl provides a focal point, but there’s more to it. Copyright law is now used to suppress instead of promote creative works. The DMCA, in particular, favors the large rightsholders over smaller developers and creators. It essentially forces sites to act on a “guilty until proven innocent” model. Companies in a position to push back have an obligation to do so. Microsoft has become a supporter of open source, now it’s time to show they mean it.</p>



<p>We should also consider the risks of consolidation. git is a decentralized system. GitHub has essentially centralized it. Sure, many competitors exist, but GitHub has become the default place to host open source code projects. The fact that GitHub’s code is proprietary is immaterial to this point. A FOSS service would pose the same risk if it became the centralized service.</p>



<p>I saw a quote on this discussion (which I can’t find now) that said “code is free, infrastructure is not.” And while projects self-hosting their code repository, issue tracker, etc may be philosophically appealing, that’s not realistic. Software-as-a-Service has lowered the barrier for starting projects, which is a good thing. But it doesn’t come without risk, which we are now seeing.</p>



<p>I don’t know what the right answer is for this. I know the answer won’t be easy. But both this specific case and the general issues they highlight are important for us to think about.</p>
			</div></div>]]>
            </description>
            <link>https://funnelfiasco.com/blog/2020/10/25/youtube-dl-github-riaa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915885</guid>
            <pubDate>Wed, 28 Oct 2020 06:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fraudster Startup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915876">thread link</a>) | @ninja-z
<br/>
October 27, 2020 | https://www.eloquicity.com/2020/10/28/the-fraudster-startup/ | <a href="https://web.archive.org/web/*/https://www.eloquicity.com/2020/10/28/the-fraudster-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.eloquicity.com/2020/10/28/the-fraudster-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915876</guid>
            <pubDate>Wed, 28 Oct 2020 06:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pants v2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915737">thread link</a>) | @gilad
<br/>
October 27, 2020 | https://blog.pantsbuild.org/introducing-pants-v2/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/introducing-pants-v2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h3 id="pants-2-0-0-the-first-stable-release-of-the-pants-v2-open-source-build-system-is-out-now-">Pants 2.0.0, the first stable release of the Pants v2 open-source build system, is out now!</h3><p>There are so many tools in the Python development ecosystem. You might use <a href="https://pip.pypa.io/en/stable/">pip</a> to resolve dependencies, <a href="https://docs.pytest.org/en/stable/">pytest</a> to run tests, <a href="https://flake8.pycqa.org/en/latest/">flake8</a> and <a href="https://www.pylint.org/">pylint</a> for lint checks, <a href="https://black.readthedocs.io/en/stable/">black</a> and <a href="https://pycqa.github.io/isort/">isort</a> for auto-formatting, <a href="http://mypy-lang.org/">mypy</a> for type checking, <a href="https://ipython.org/">IPython</a> or <a href="https://jupyter.org/">Jupyter</a> for interactive sessions, <a href="https://setuptools.readthedocs.io/en/latest/">setuptools</a>, <a href="https://pex.readthedocs.io/en/latest/">pex</a> or <a href="https://www.docker.com/">docker</a> for packaging, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a> for code generation, and many more. Not to mention any custom tooling you've built for your repo. </p><p>Installing, configuring and orchestrating the invocation of these tools<strong>—</strong>all while not re-executing work unnecessarily<strong>—</strong>is a hard problem, especially as your codebase grows. The lack of a robust, scalable build system for Python has been a problem for a long time, and this has become even more acute in recent years, with Python codebases increasing in size and complexity. </p><p>Fortunately, there is now a tailor-made (pun intended) solution: <strong>Pants v2</strong>!</p><p><a href="https://www.pantsbuild.org/">Pants v2</a> is designed from the ground-up for fast, consistent builds. Some noteworthy features include:</p><ul><li>Minimal metadata and boilerplate</li><li>Fine-grained workflow</li><li>Shared result caching</li><li>Concurrent execution</li><li>A responsive, scalable UI</li><li>Unified interface for multiple tools and languages</li><li>Extensibility and customizability via a plugin API</li></ul><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/render1603750306032.gif" alt=""><figcaption>Pants running multiple linters in parallel</figcaption></figure><p>Read on to learn more about Pants v2, and what it means for your Python codebase.</p><hr><h2 id="a-little-history">A little history</h2><p>We started the original open-source Pants project back in 2011. At the time, we were frustrated by slow, flaky Scala builds. The leading strategy for scaling was to hand each developer a RAM stick and a screwdriver... Surely this was a problem we could tackle with software! Thus Pants v1 was born. </p><p>Pants v1 was quite successful, and was adopted at cutting-edge tech companies such as Twitter, Foursquare, Square and others. But we still weren't satisfied: The APIs were clunkier than we would have liked, the UI was overly chatty, caching was hard to get right, and concurrent execution had to be special-cased. We knew there were plenty of performance and stability improvements to be had, if we could only unlock them. </p><p>We learned a lot from our years of work on Pants v1, and knew that we could design something new and better, leaning on our experience with v1 while addressing the drawbacks of that system. Luckily, at the same time as we began thinking about this hypothetical next system, a new motivating problem emerged: Python builds.</p><h2 id="python-builds-today">Python builds today</h2><p>As you probably know, Python has skyrocketed in popularity in recent years. Not only is it used to build a wide variety of server applications, via frameworks such as <a href="https://www.djangoproject.com/">Django</a> and <a href="https://flask.palletsprojects.com/en/1.1.x/">Flask</a>, but it's also the language of choice for data scientists, thanks to powerful libraries and tools such as <a href="https://numpy.org/">NumPy</a>, <a href="https://www.scipy.org/">SciPy</a>, <a href="https://pandas.pydata.org/">Pandas</a> and <a href="https://jupyter.org/">Jupyter</a>. </p><p>Python hits a sweet spot of simplicity and power, but there is a big problem - there is no truly great scalable build tool for Python, and this is becoming a real pain point as Python repos grow like never before. &nbsp;</p><p>Python builds today involve manually invoking a wide variety of tools. Each tool has to be installed, configured and invoked in just the right way, often while sequencing the output of one tool into input of another. Knowing how to use each tool in a given scenario is complicated and burdensome. </p><p>Sure, you can hack around the problem for a while with some combination of shell scripts, <a href="https://www.gnu.org/software/make/manual/make.html">Makefiles</a>, <a href="https://tox.readthedocs.io/en/latest/">tox</a>, and <a href="https://python-poetry.org/">poetry</a>. But even a small code change might require you to run a huge amount of sequential build work. Re-executing the same processes with the same inputs over and over again is a frustrating waste of time and resources. &nbsp;And these solutions start to break down as your codebase grows.</p><p>Perhaps you experimented with more complex build systems, such as <a href="https://bazel.build/">Bazel</a> or <a href="https://v1.pantsbuild.org/">Pants v1</a>. &nbsp;But it's laborious to maintain all that BUILD metadata, all for a sub-par experience not optimized for Python. Not to mention the difficulty of implementing your own custom build logic. </p><p>Alternatively, maybe you've been tempted to split up your codebase into multiple interdependent repos, each with their own "smaller" builds. But that creates an even thornier problem, namely how to manage those interdependencies. Having to propagate changes across codebase boundaries can slow development down to a crawl, and leave you with the worst of both worlds - slower processes and a fragmented, unmanageable codebase.</p><p>A great build system for repos - of all sizes - that include Python code would support fine-grained invalidation and caching, so that it only executes the build work actually affected by a change. It would support concurrent local and even remote execution, to greatly speed up work by using all available CPU. It would be easy to adopt in a small repo, but would scale up as your codebase grows. It wouldn't require huge amounts of boilerplate metadata, and it would be easy to extend with custom build logic. </p><p>Well, Pants v2 is that system! </p><h2 id="introducing-pants-v2">Introducing Pants v2</h2><p><a href="https://www.pantsbuild.org/">Pants v2</a> is a completely new open-source build system, inspired by our work on Pants v1. &nbsp;We've been developing and testing it for the last couple of years, and it's finally ready for prime time!</p><p>A key factor in the design of Pants v2 was a set of lessons we learned from Pants v1 and other existing systems, such as Bazel. Among them: that ease of use and performance matter, boilerplate is annoying, concurrency and caching require hard design work, and most people will need custom logic at some point.</p><h3 id="lesson-1-ease-of-use-and-performance-both-matter">Lesson #1: Ease of use and performance both matter</h3><p>When designing software you often find yourself making tradeoffs between ease of use and performance. But in a build system, both are vital. The Pants v2 execution engine - which is the performance-critical heart of the system - is written in <a href="https://www.rust-lang.org/">Rust</a>, for raw speed. And the domain-specific build logic is written in familiar, easy to work with, type-annotated Python 3. This helps make Pants v2 easy to extend, without compromising performance. </p><p>Pants v2 also runs a daemon that memoizes fine-grained build state in memory, for even faster performance. This daemon watches for changes to your source files and precisely invalidates its state on the fly to ensure that the minimum amount of work happens the next time you build.</p><h3 id="lesson-2-writing-build-metadata-is-a-real-drag">Lesson #2: Writing build metadata is a real drag</h3><p>Some build tools are slow because they don't have enough information about the structure of your code to intelligently perform incremental work. Others have gone too far in the other direction, requiring a huge amount of metadata and boilerplate in BUILD files, especially relating to your code's dependencies. </p><p>Pants v2 offers the best of both worlds - intelligent, fine-grained incremental work, without the boilerplate. It does so by assuming sensible, magic-free defaults, inferring dependencies from the import statements in your code, and supporting plugins for custom inference logic. Stay tuned for an upcoming post on exactly how Pants achieves this!</p><h3 id="lesson-3-design-for-caching-concurrency-and-remoting">Lesson #3: Design for caching, concurrency and remoting </h3><p>Writing build logic that can be cached and executed concurrently and remotely is very hard. You have to be very careful about not producing or consuming side-effects, and it's extremely difficult to tack that on later. And unless you design your APIs with care, supporting these kinds of features often places severe restrictions on what your build logic may safely do. </p><p>In Pants v2, build logic is composed of <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> Python 3 <a href="https://docs.python.org/3/library/asyncio-task.html">async coroutines</a>. So a build rule can depend not only on its inputs, but can also await on new data at runtime - all of which is precisely tracked for invalidation and caching. This gives us the best of both worlds: logic that is properly isolated from side-effects, and is therefore amenable to caching, concurrent execution and remoting, while still allowing the use of natural control flow.</p><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/caching.gif" alt=""><figcaption>We run both tests, then add a syntax error to one test and rerun; the unmodified test uses the cache and is isolated from the syntax error.</figcaption></figure><h3 id="lesson-4-almost-everyone-needs-to-customize-their-builds">Lesson #4: Almost everyone needs to customize their builds</h3><p>Most teams have custom build steps, so extensibility is a key feature in any build system. Pants v2 is built around a <a href="https://www.pantsbuild.org/docs/plugins-overview">plugin architecture</a>. You can write your own rules using the same API as the built-in functionality. So your custom build logic will enjoy the same fine-grained invalidation, caching, concurrency and remote execution abilities as the core Pants code.</p><h2 id="pants-2-0-0-is-out-now-">Pants 2.0.0 is out now!</h2><p>All this leads me to the happy announcement that <a href="https://pypi.org/project/pantsbuild.pants/2.0.0/">Pants 2.0.0</a>, the first stable release of Pants v2, is out now! 2.0.0 is the culmination of years of design and development work, and many months of beta testing at several organizations. So we're really happy, proud (and relieved…) to finally have it ready for general use. </p><p>You can see what Python tools Pants currently supports <a href="https://www.pantsbuild.org/docs/python">here</a>. There are also commands for querying and understanding your dependency graph, and a robust help system. &nbsp;We're adding support for additional tools and features all the time, and it's straightforward to implement your own. Beta users have already written their own logic for Cython and docker, for example. </p><p>Now is a great time to adopt Pants 2.0.0! The team that developed Pants v2 is <a href="https://www.pantsbuild.org/docs/community">ready to help you</a> onboard, answer any questions, and even pair with you to help you write any custom build logic. We're also eager to get feedback, bug reports and suggestions for what features we should focus on in the next weeks and months of development.</p><p>Pants v2 is developed by a helpful open source community, is funded by a 501(c)6 non-profit, and has excellent support available. If you have a growing Python codebase, and want to take Pants 2.0.0 for a spin, <a href="https://www.pantsbuild.org/docs/community">let us know</a>. We'd love to fit you with some new Pants today!</p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/introducing-pants-v2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915737</guid>
            <pubDate>Wed, 28 Oct 2020 06:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Grand Unified Theory of Software Architecture]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24915497">thread link</a>) | @nreece
<br/>
October 27, 2020 | https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html | <a href="https://web.archive.org/web/*/https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                <p>Take <strong>Uncle Bob's</strong> Clean Architecture and map its correspondences with <strong>Gary Bernhardt's</strong> thin imperative shell around a functional core, and you get an understanding of how to cheaply maintain and scale software!</p>
<p>This is what <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a> did. It's not every day that I find such clear insight.</p>
<p>I am honored to have found his <a href="https://rhodesmill.org/brandon/talks/#clean-architecture-python">presentation</a> and <a href="https://rhodesmill.org/brandon/slides/2014-07-pyohio/clean-architecture/">slides</a> explaining  <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture</a> and Gary Bernhardt's PyCon talks of <a href="https://archive.org/details/pyvideo_422___units-need-testing-too">2011</a>, <a href="https://pycon-2012-notes.readthedocs.io/en/latest/fast_tests_slow_tests.html">2012</a>, and <a href="https://www.destroyallsoftware.com/talks/boundaries">2013</a>.</p>
<p>Mr. Rhodes offers such a distilled view, that he can show you these crucial concepts in 3 slides of code. I will go ahead and summarize what he said and add a tiny bit of my insight.</p>
<p>Copyright of all Python code on this page belongs to <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a>, and copyright of the diagram belongs to <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Robert C. Martin (Uncle Bob)</a>. I use these under (hopefully) fair use (nonprofit and educational).</p>


<p>First of all, we need to be on the same page, in order to be able to understand each other. Here are the words I'll use:</p>
<ul>
<li>Function: I use "function" or "pure function" to refer to a Python "function" that only uses its parameters for input, returns a result as output, and does not cause any other side-effects (such as I/O). <ul>
<li>A pure function returns the same output given the same inputs.</li>
<li>A pure function may be called any number of times without changing the system state - it should have no influence on DB, UI, other functions or classes.</li>
<li>This is very similar to a mathematical function: takes you from <em>x</em> to <em>y</em> and nothing else happens.</li>
<li>Sadly we can't have only pure functions; software has a <strong>purpose</strong> of causing side-effects.</li>
</ul>
</li>
<li>Procedure, Routine, or Subroutine: A piece of code that executes, that may or may not have side effects. This is a "function" in Python, but might not be a "pure function".</li>
<li>Tests: automated unit tests. By "unit" I mean not necessarily just a class, but a behavior. If you want, see more details in <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a>.</li>
</ul>

<div><pre><span></span><code><span>import</span> <span>requests</span>                      <span># Listing 1</span>
<span>from</span> <span>urllib</span> <span>import</span> <span>urlencode</span>

<span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, we have a piece of code that prepares a URL, then gets some data over the network (I/O), then validates the result (a word definition) and returns it.</p>
<p>This is a bit much: a procedure should ideally do one thing only. While this small-ish procedure is quite readable still, it is a metaphor for a more developed system - where it could be arbitrarily long.</p>
<p>The current knee-jerk reaction is to <em>hide</em> the I/O operations somewhere far away. Here is the same code after extracting the I/O lines:</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 2</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>data</span> <span>=</span> <span>call_json_api</span><span>(</span><span>url</span><span>)</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>

<span>def</span> <span>call_json_api</span><span>(</span><span>url</span><span>):</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>return</span> <span>data</span>
</code></pre></div>
<p>In Listing #2, the I/O is extracted from the top-level procedure. </p>
<p>The problem is, the code is still <strong>coupled</strong> - <code>call_json_api</code> is called whenever you want to test anything - even the building of the URL or the parsing of the result.</p>
<p><strong>Coupling kills software.</strong></p>
<p>A good rule of thumb to spot coupling is this: Can you test a piece of code without having to mock or dependency inject like Frankenstein?</p>
<p>Here, we can't test <code>find_definition</code> without somehow replacing <code>call_json_api</code> from inside it, in order to avoid making HTTP requests.</p>
<p>Let's find out what a better solution looks like.</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 3</span>
    <span>url</span> <span>=</span> <span>build_url</span><span>(</span><span>word</span><span>)</span>
    <span>data</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span><span>.</span><span>json</span><span>()</span>  <span># I/O</span>
    <span>return</span> <span>pluck_definition</span><span>(</span><span>data</span><span>)</span>

<span>def</span> <span>build_url</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>return</span> <span>url</span>

<span>def</span> <span>pluck_definition</span><span>(</span><span>data</span><span>):</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, the procedure at the top (aka. the <span><strong>imperative shell</strong></span> of the program) is handling the I/O, and everything else is moved to <span><strong>pure functions</strong></span> (<code>build_url</code>, <code>pluck_definition</code>). The <span><strong>pure functions</strong></span> are easily testable by just calling them on made-up data structures; no Frankenstein needed.</p>
<p>This separation into an <span><strong>imperative shell</strong></span> and <span><strong>functional core</strong></span> is an encouraged idea by Functional Programming.</p>
<p>Ideally, though, in a real system, you wouldn't test elements as small as these routines, but integrate more of the system. See <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a> to understand the trade-offs.</p>

<p>Look at <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture chart</a> (Copyright Robert C. Martin aka. Uncle Bob) :
<img alt="The Clean Architecture" src="https://danuker.go.ro/images/CleanArchitecture.jpg"></p>
<p>Uncle Bob's <span><strong>Use Cases</strong></span> and <span><strong>Entities</strong></span> (red and yellow circles of the chart) map to the <span><strong>pure functions</strong></span> we saw earlier - <code>build_url</code> and <code>pluck_definition</code> from Listing 3, and the <span><strong>plain objects</strong></span> they receive as parameters and send as outputs. <em>(updated 2020-10-28)</em></p>
<p>Uncle Bob's <span><strong>Interface Adapters</strong></span> (green circle) map to the top-level <span><strong>imperative shell</strong></span>  from earlier - <code>find_definition</code> from Listing 3, handling only I/O to the outside (Web, DB, UI, other frameworks).</p>
<p><a href="https://www.reddit.com/r/programming/comments/jj7ave/the_grand_unified_theory_of_software_architecture/gabst6z/?context=3">Update 2020-10-28</a>: A "Model" object in today's MVC frameworks is a poisoned apple: it is not a <a href="https://khanlou.com/2014/12/pure-objects/">"pure" object</a> or <a href="http://xunitpatterns.com/Humble%20Object.html">"humble" object</a>, but one that can produce side effects like saving or loading from the database. Their "save" and "read" methods litter your code with untestable side-effects all over. Avoid them, or confine them to the periphery of your system and reduce their influence accordingly (they are actually a hidden <span><strong>Interface Adapter</strong></span>) due to interacting with the DB.</p>
<p>Notice the arrows on the left side of the circles, pointing inwards to more and more abstract parts. These are procedure or function calls. Our code is called by the outside. <strong>This has some exceptions. Whatever you do, the database won't call your app. But the web can, a user can through a UI, the OS can through STDIN, and a timer can, at regular intervals (such as in a game).</strong> <em>(updated 2020-10-28)</em></p>
<p>The top-level procedure:</p>
<ol>
<li>gets the input, </li>
<li>adapts it to simple objects acceptable to the system,</li>
<li>pushes it through the functional core,</li>
<li>gets the returned value from the functional core,</li>
<li>adapts it for the output device,</li>
<li>and pushes it out to the output device.</li>
</ol>
<p>This lets us easily test the functional core. Ideally, most of a production system should be pure-functional.</p>

<p>If you reduce the <span><strong>imperative shell</strong></span> and move code into the <span><strong>functional core</strong></span>, each test can verify almost the entire (now-functional) stack, but stopping short of actually performing external actions.</p>
<p>You can then test the imperative shell using <strong>fewer integration tests</strong>: you only need to check that it is <strong>correctly connected</strong> to the functional core.</p>
<p>Having two users for the system - the real user and the unit tests - and listening to both, lets you guide your architecture so as to <strong>minimize coupling</strong> and build a more <strong>flexible system</strong>.</p>
<p>Having a flexible system lets you implement new features and change existing ones <strong>quickly and cheaply</strong>, in order to <strong>stay competitive as a business</strong>.</p>
<p>Comments are much appreciated. I am yet to apply these insights, and I may be missing something!</p>
<p><strong>Edit 2020-10-28:</strong> I have tried out this methodology in some small TDD Katas, and together with TDD, it works great. But I am not employed right now, so I can't say I've <em>really</em> tried it.</p>
            </div>
            <!-- /.entry-content -->


        </article>
    </section>

        </div>
        
    </div>
</div></div>]]>
            </description>
            <link>https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915497</guid>
            <pubDate>Wed, 28 Oct 2020 05:19:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDoS attack against TinyCert announced]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915478">thread link</a>) | @shdon
<br/>
October 27, 2020 | https://www.tinycert.org/ddos | <a href="https://web.archive.org/web/*/https://www.tinycert.org/ddos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Posted by admin on 28 October 2020 at 06:15 CET. Latest update on 28 October 2020 at 17:02 CET.</p>
<p>A greedy bunch of bastards calling themselves "Voodoo Bear" sent an <a href="#mail">email</a> to my private email address announcing a DDoS attack aimed at TinyCert to take place, starting Monday 2 November 2020. They seem to be under the impression that there is a large company with deep pockets behind TinyCert, which I suppose is flattering. TinyCert is just a pet project of mine, that I find useful for myself and figured others might find it useful too.</p>
<h3>Ransom demands</h3>
<p>As you can see from the <a href="#mail">email below</a>, they are demanding a "small" $1000 ransom to call off the attack, increasing their demands by $1000 per day they are not met. TinyCert has been up for 6 years now and costs me about $200 per year to run ($1200 thusfar) and the total amount of <a href="https://www.tinycert.org/donate">donations</a> in that time has been $75, as I guess not enough people found it useful enough to consider donating. Thus, even if I <i>could</i> pay the ransom, I would not want to. If the site goes down, so be it, the version I use privately will be unaffected anyway.</p>
<h3>What can I do about it?</h3>
<p>Realistically, nothing. I could change the IP address by moving to another host or hosting provider, so that the attack goes to the wrong place. That would probably not be effective, at least not for very long. Besides, I would much rather the moronic dipshits waste their time and effort by attacking my little pet project rather than going after somebody who might actually pay them. Heck, if anything, they're saving me money if I have to shut down the site.</p>
<h4>Cloudflare?</h4>
<p>Using Cloudflare or similar services is not an option. The dumb idiots indicate they will attack the network directly (most likely the IP address of the server TinyCert is running on, rather than the actual network of my hosting provider). Since it is a very lightweight server, as TinyCert requires very little in terms of server resources, it won't hold up against a proper DDoS attack for any significant length of time. If anything, it will be interesting to see how well it holds up. For Cloudflare's protection to be effective, the IP address would first have to be changed (which in itself is easily done - I guess the criminals overestimate how much work it is to migrate a small website), but the Cloudflare SSL proxy is not suitable in the free tier. This is because the free tier does not allow the use of a custom certificate and TinyCert uses <abbr title="HTTP Public Key Pinning">HPKP</abbr>. There is also no way I could afford the higher tier that allows that.</p>
<p><strong>Update:</strong> Cloudflare CEO Matthew Prince has <a href="https://twitter.com/eastdakota/status/1321320999678136325">offered Cloudflare's assistance</a> at no cost if needed. I hope it will not be necessary, but kudos to him and Cloudflare for their work and the kind offer.</p><h4>Open source?</h4>
<p>It has been suggested that I open-source the TinyCert codebase and allow people to have their own local versions, which of course wouldn't be affected. This too is not an option. Parts of the codebase are licensed to me personally and providing the source to them would be a breach of that license. Swapping that out for open source code would be possible, but time consuming and labour intensive and not something I am willing to do.</p>
<h3 id="mail">The actual email received</h3>
<p>Here is a copy of the email, for anybody who is interested.</p>
<div>
	<p>
		From: Robert Clark &lt;robertclark@coronaxy.com&gt;<br>
		Subject: If www.tinycert.org is important to you, you must read this<br>
		Date: Wed, 28 Oct 2020 02:13:37 +0000
	</p>
	<div><p>
		PLEASE FORWARD THIS EMAIL TO SOMEONE IN YOUR COMPANY WHO IS ALLOWED TO MAKE IMPORTANT DECISIONS!</p><p>
		==========================================</p><p>
		We are the Voodoo Bear and we have chosen www.tinycert.org as target for our next DDoS attack.<br>
		Please perform a google search for "Voodoo Bear" to have a look at some of our previous work.</p><p>
		Your network will be subject to a DDoS attack starting at 2020 November 2nd (Monday).</p><p>
		THIS IS NOT A HOAX, and to prove it right now we will start a small attack on www.tinycert.org that will last for 30 minutes.<br>
		It will not be heavy attack, and will not cause you any damage so don't worry, at this moment.</p><p>
		This means that your website, e-mail and other connected services will be unavailable for everyone.</p><p>
		We will refrain from attacking your servers for a small fee.<br>
		The current fee is $1000(USD) in bitcoins (BTC). The fee will increase by 1000 USD for each day after deadline that passed without payment.</p><p>
		Please send Bitcoin to the following Bitcoin address (cAsE-SeNsitIve):</p><p>
		[address removed]</p><p>
		You can easily buy bitcoins via several websites or even offline from a Bitcoin-ATM. We suggest you coinmama.com or https://buy.coingate.com/ for buying bitcoins.</p><p>
		Once you have paid we will automatically get informed that it was your payment. Please note that you have to make payment before the deadline or the attack WILL start!</p><p>
		If you decide not to pay, we will start the attack on the indicated date and uphold it until you do, there's no counter measure to this, you will only end up wasting more money trying to find a solution (Cloudflare, Sucuri, Imperva and similar services are useless, because we will hit your network directly).</p><p>
		We will completely destroy your reputation and make sure your services will remain offline until you pay.<br>
		We will also download your database and do as much damage as possible.</p><p>
		Do not reply to this email, don't try to reason or negotiate, we will not read any replies.</p><p>
		Once you have paid we won't start the attack and you will never hear from us again.</p><p>
		Please note that Bitcoin is anonymous and no one will find out that you have complied.</p><p>
		-- Voodoo Bear team
	</p></div>
</div>
<p>I literally laughed out loud at the first sentence, as it indicates how clueless these numbskulls are. Maybe I'll forward the email to my budgerigars, as they are the only other living beings in here, though I'm not sure they're qualified to make any decisions.</p>
<p><strong>Update:</strong> some users have reported receiving similar emails. On the one hand, that is a good thing, as it reduces the likelihood of (persistent) follow-through on the part of these scumbags. On the other hand, the more widespread this is, the more likely it is that somebody will give in and pay up. If you receive a threat like this, do not comply. It will only encourage them that their actions are successful and marks you as being susceptible to caving in to pressure.</p>
<p>So, Mr. "Clark" or "Voodoo Bear", whatever you hilariously pitiable imbeciles call yourselves, you can just fuck off. I have not for a nanosecond considered giving in to your demands, even if I could. You wanna waste your time to take down my pet project? Be my guest. My taking the time and effort to Write this page is the only thing you have "achieved" as you're not getting a penny from me. And thank you for thinking TinyCert something worthy of extortion - that means I must've done something right in creating it.</p>
<p>Well, there you go. It's been fun while it lasted. This is why we can't have nice things.</p>
				</div></div>]]>
            </description>
            <link>https://www.tinycert.org/ddos</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915478</guid>
            <pubDate>Wed, 28 Oct 2020 05:15:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[X266 Open Source Video Codec for Versatile Video Coding (VVC) Update]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24915382">thread link</a>) | @ponderingfish
<br/>
October 27, 2020 | https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/ | <a href="https://web.archive.org/web/*/https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/x266-featured-image.png?resize=678%2C381&amp;ssl=1" alt="x266 multicoreware vvc" title="x266-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/x266-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>MulticoreWare is a software development company that works on video compression, ML, heterogeneous computing, and championed the open-source x265 encoder in the past. They are now driving the x266 project to create an open-source VVC (Versatile Video Coding) encoder and use their experience from their UHDKit product to make it the premier open-source VVC encoder.</strong></p>




<h2><span id="Who_is_MulticoreWare"></span><strong>Who is MulticoreWare?</strong><span></span></h2>



<p><a href="https://multicorewareinc.com/" target="_blank" aria-label="MulticoreWare (opens in a new tab)" rel="noreferrer noopener">MulticoreWare</a> is a multi-faceted company with expertise in different verticals such as high-performance Video Compression, AI &amp; Video Analytics, ADAS (Automated Driver Assistance), etc. A common thread through these verticals is their ability to design and write high-performance code for various computing platforms. MulticoreWare’s background and experience are cool, in my opinion, and how they’ve nurtured and built a strong team in a very complex niche is admirable.</p>



<p>With teams in the US, India, China, and Germany, MulticoreWare is well-placed to don the role of a thought-leader in the open-source video codec world.</p>



<p>Let’s see why and what their plans are!</p>



<h2><span id="The_Road_To_x266_%E2%80%93_An_Open_Source_VVC_Encoder"></span><strong>The Road To x266 – An Open Source VVC Encoder</strong><span></span></h2>



<p>MPEG announced three new video codecs – VVC (Versatile Video Coding), EVC (Essential Video Coding), and LCEVC (Low Complexity Enhancement Video Coding). Of these three, VVC or H.266 is touted as the successor to H.265 (HEVC) and promises 50% more compression efficiency over HEVC but comes at a much higher complexity. Here’s a <a href="https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">brief explanation of all three</a> on OTTVerse.</p>



<p>But, first, let’s take a look at HEVC and the x265 encoder.</p>



<h3><span id="x265_and_HEVC"></span><strong>x265 and HEVC</strong><span></span></h3>



<p>MulticoreWare announced the <a href="https://x265.com/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">x265 project</a> back in 2013, and it was a success. x265 allowed video compression teams worldwide to get their hands on an efficient, standards-compliant HEVC encoder. x265 was made available under the open-source <a href="http://www.gnu.org/licenses/old-licenses/gpl-2.0.html" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">GNU GPL v2 license</a> and also offered by MulticoreWare under Commercial License Agreements.</p>



<p>But, having a good encoder clearly wasn’t enough. Because, fast-forward 7 years, and unfortunately, HEVC is still embroiled in patent-wars that seem destined to give it a “death by a thousand cuts.”&nbsp;</p>



<p>HEVC’s situation is rather unfortunate considering that HEVC had interesting features such as the use of quadtree-decomposition, large block sizes, the concept of TU, PU, and CUs, the Sample Adaptive Offset filter, new picture types, and several innovations which made it possible to compress 4K videos quite efficiently (in comparison to H.264/AVC).</p>



<h3><span id="The_x266_Project"></span><strong>The x266 Project</strong><span></span></h3>



<p>Riding on the back of their x265 success, MulticoreWare has decided to pioneer the x266 project along the x265 project lines they worked on earlier. x266 will be an open-source project with the MulticoreWare video compression team’s full attention and the backing of an industry-consortium.</p>



<p>As with any new codec, there are always early adopters (both programmers and companies) willing to give it a try, evaluate, file tickets, and contribute code. But, to get the ball rolling, you need a reliable encoder that is not only standards-compliant but also reasonably fast and with enough presets and knobs to make the early-adoption both valuable and exciting (in a geeky-sense!)</p>



<p>I spoke to <a href="https://www.linkedin.com/in/shivakumarasu/" target="_blank" aria-label="Shivakumar Narayanan (opens in a new tab)" rel="noreferrer noopener">Shivakumar Narayanan</a>, Senior Director – Marketing and Product Management at MulticoreWare, about the consortium, and this is what he had to say –</p>



<blockquote><p><em>Similar to when we did this for x265 consortium, to get key consortium members on board and invest in the development of this codec. These members will be founding partners with benefits when the codec (rather encoder is ready to release for the open-source world). Consortium members being strategic, will also play an important role in the shaping of this codec as well as prioritization of functionalities as it would pertain to their and their customers’ interests.</em></p></blockquote>



<p>Industry involvement bodes well for the open-source community because <strong>video encoder implementation is both an art and a science.</strong></p>



<p>It helps to have a proficient team that understands and implements concepts such as wavefront parallelism, multi-threading, intrinsics, etc. to make codec implementations practical and useful. And, of course, people with “golden eyes” to spot issues with video quality as they occur.&nbsp;</p>



<p>MulticoreWare has such a team, and I feel they’ll bring their experience from x265 to the x266 development.</p>



<h3><span id="Expertise_from_UHDKit"></span><strong>Expertise from UHDKit</strong><span></span></h3>



<p>Another product in MulticoreWare’s portfolio is <a href="https://x265.com/uhdkit/" target="_blank" rel="noopener">UHDKit</a>. It is an extended encoding library built on top of the x264 (AVC) encoder and x265 (HEVC) encoder libraries. It has a better performance and feature-set than the vanilla x264, x265, and svt-av1 encoders. UHDKit comes in-built with powerful features such as a “control system for video compression” that dynamically adjusts settings to achieve better video quality based on the computing platform’s spec. </p>



<p>Additional features include fast ABR encoding (to get the bitrate ladder faster!) and high-performance live encoding, all this on software, without any requirement for additional hardware accelerators. It can be used as a standalone encoding library or can be invoked via the FFmpeg framework, which makes it seamlessly integrate into any software encoding/ transcoding pipeline.</p>



<p>I am sure some of this expertise from building UHDKit will rub off on the x266 encoder development.</p>



<h2><span id="How_Do_I_Get_my_hands_on_x266"></span><strong>How Do I Get my hands on x266?</strong><span></span></h2>



<p>Currently, MulticoreWare is working closely with x266 Consortium members and after a few months, it will be available to them.</p>



<p>Upon enquiring about the open-source implementation, here’s what MCW had to say –</p>



<blockquote><p><em>For the larger open source community, it will be made available when we have reached critical mass required for its first release. As we near readiness, we will update here on how you can get hold of it.</em></p></blockquote>



<p>If you have any questions for the MulticoreWare team, please get in touch with Shivakumar Narayanan at <a aria-label="x266@multicorewareinc.com (opens in a new tab)" href="mailto:x266@multicorewareinc.com" target="_blank" rel="noreferrer noopener">x266@multicorewareinc.com</a>.</p>



<p>Also, many thanks to <a aria-label="Praveen Kumar Karadugattu (opens in a new tab)" href="https://www.linkedin.com/in/praveenkpk/" target="_blank" rel="noreferrer noopener">Praveen Kumar Karadugattu</a>, Video Architect at MulticoreWare for kicking off this discussion between MulticoreWare and OTTVerse.com. </p>




		
		
		
	</div></div>]]>
            </description>
            <link>https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915382</guid>
            <pubDate>Wed, 28 Oct 2020 04:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a Yarn Workspace Is, and the Problem It Solves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914835">thread link</a>) | @taphangum
<br/>
October 27, 2020 | https://planflow.dev/blog/what-is-a-yarn-workspace | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/what-is-a-yarn-workspace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>What Is A Yarn Workspace?</h2><p>Before I start to use a new technology, I first try to make sure that I really understand what it is. </p><p>This means getting the definition of what it is to be as crystal clear as possible for me, in all areas that compose the technology.</p><p>This is what we will first do with Yarn Workspaces before we dive into the way we can use them for our projects.</p><p><strong>We can briefly state that a Yarn Workspace is a method of combining multiple project NPM dependencies into a single workspace, so that all projects share the same dependencies. This is commonly referred to as a ‘</strong><a target="_blank" title="monorepo" href="https://www.perforce.com/blog/vcs/what-monorepo"><strong>monorepo</strong></a><strong>’.</strong></p><p>To get an even better understanding of what a Yarn Workspace is, it's best to take a look at the broader picture of the problem it solves and why that problem exists in the first place.</p><h2>The Multi-Megabyte Problem that a Yarn Workspace solves</h2><p>While the emergence of open source packages within the NPM ecosystem has lead to <a target="_blank" title="https://flaviocopes.com/node-modules-size/" href="https://flaviocopes.com/node-modules-size/">tremendous benefits</a> and time-saved on project code, the fact that so many node modules are now needed for even the simplest of projects has led to a lot of bloat in overall project size. </p><p>The average node js project, specifically the dependencies located within it, <a target="_blank" title="https://forum.freecodecamp.org/t/node-modules-is-huge-is-this-normal/137282/12" href="https://forum.freecodecamp.org/t/node-modules-is-huge-is-this-normal/137282/12">have a total estimated size of 76MB</a>.</p><p>For a single, web based project for example, this is huge.</p><p>When working on more complex projects, with dependencies from a variety of frameworks, this size can swell even more. I’m sure we’re all familiar with the infamous Godzilla 500+ MB /node_modules folder.</p><p>Imagine now, with these large individual file sizes on each project, that we had a multi-project setup with each project that needed to have its own dependencies, such as what you might find in a standard MERN or MEVN stack. With a separate /client and /server folder structure, each with their own package.json and subsequent package dependencies.</p><p>Each of these projects would have to be loading in their own dependencies, and sometimes, as shown in the drawing above, having the same duplicate dependencies loaded in for each folder, causing massive unnecessary bloat. Not to mention the issues that would arise from dealing with out-of-date code and the potential conflicts in the overall codebase.</p><p>These issues are what are commonly referred to as ‘<a target="_blank" title="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html" href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">dependency hell’</a>. </p><p><strong>And it’s not a new issue. Infact, its been around for a long time. </strong></p><p>Fortunately, there are now solutions to this problem. That solution as we have stated above is the monorepo. </p><p>One of the most prominent (within the NPM ecosystem) of which is the <em><strong>Yarn Workspace</strong></em>.</p><p><strong>Whose benefits alongside the obvious bloat reduction mentioned above, include:</strong></p><p>-	Better code-quality and optimization due to packages being linked together. Leading to more up to date code in general. </p><p>-	All your dependencies installed together at one time, leading to better ability for Yarn to optimize them.</p><p>-	Yarn gets to make a single lock file rather than multiple, giving you fewer conflicts and making code review easier.</p><p>So now that we have a clearer overall picture of what a Yarn Workspace is in general. Let’s now take a look at what it actually looks like and how we can go about setting it up within a project.</p><h2><strong>How Do You Set Up A Yarn Workspace? And What Does It Looks Like?</strong></h2><p>Setting up a Yarn Workspace is as easy as running a few commands and making some edits to a few simple pages.</p><h3><strong>The general steps are:</strong></h3><p><strong>1. Create your main project directory with a command like this:</strong></p><p>$ mkdir my-monorepo-workspace</p><p><strong>2. Navigate to the newly created project directory root and create your package.json.</strong></p><p>$ cd my-monorepo-workspace</p><p>$ touch package.json</p><p><strong>3. Replace the contents of your package.json with the following:</strong></p><p>{</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [],</p><p>   "scripts": {}</p><p>}</p><p>This makes the workspace project that we have created private, as we don’t want to upload it to NPM. It also creates the spaces where we will set our workspace project names and our scripts.</p><p><strong>4. Create two project directories within your main directory root, like this:</strong></p><p>$ mkdir project-1 project-2</p><p>Feel free to name these however you want.</p><p><strong>5. Add your project names to the workspace package.json that lives within your root directory:</strong></p><p> {</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [“project-1”, “project-2”],</p><p>   "scripts": {}</p><p>}</p><p>Once set up, these two of our projects will be able to share the same installed NPM packages. </p><p>The above steps have now given us our basic Workspace structure. </p><p>Now we can get started with fully activating our Workspace. Let’s add some real code to it before we do that, to demonstrate how it all works.</p><p>We’ll do this by creating a front end in project-1 and a backend in project-2.</p><p><strong>6. For our front-end in project-1, we’ll use React, which we can install with the following command:</strong></p><p>$ yarn create react-app project-1</p><p><strong>7. For our backend in project-2, we’ll use an </strong><a target="_blank" title="https://expressjs.com/" href="https://expressjs.com/"><strong>Express.js</strong></a><strong> server package. Which we can install by first adding Express Generator to our global package.json like so:</strong></p><p>$ yarn global add express-generator --prefix /usr/local</p><p><strong>Note</strong><strong>:</strong> Notice here that we use ‘yarn global add’ instead of the usual ‘yarn add’, now that we have multiple projects, we need to specify the scope of our installed packages for clarity.</p><p><strong>8. Generate and install the Express package for our server in ‘project 2’ like this:</strong></p><p>$ express --view=pug project-2</p><p>Now that we have set up our react app frontend and our express app backend we can now install all of our dependencies.</p><p><strong>9. Install all of the dependencies like so:</strong></p><p>$ yarn install</p><p>This command generates a yarn.lock file, which contains a note of all of your dependencies. This is generated automatically and should not be deleted.</p><p>Our packages our now installed and should be available to both of our projects within the workspace. </p><p>As a final step, let us now set up some scripts that can run our projects for us concurrently, which is wise to do within a shared workspace, as the core concept is about bringing these two together.</p><p><strong>10. We can set up the two projects to run concurrently by first setting the command within our root package.json like this:</strong></p><p>$ yarn add -W concurrently</p><p>This adds the ‘concurrently’ start script that you’ll see below that runs the two project start scripts concurrently. </p><p>To tell our package.json how we want those scripts to run, add the following:</p><p>{</p><p>   "private": true,</p><p>   "name": "my-monorepo-workspace",</p><p>   "workspaces": [“project-1”, “project-2”],</p><p>   "scripts": {</p><p>   	"project-1": "yarn workspace project-1 start",</p><p>   	"project-2": "yarn workspace project-2 start",</p><p>   	"start": "concurrently --kill-others-on-fail \"yarn project-2\"  \"yarn project-1\"</p><p>   }</p><p>}</p><p>The actual scripts that are necessary to run the projects are within the installations within the project directories.</p><p>Last but not least, change the port name within our project-2 express app directory to port 4000, just to ensure that we don’t get conflicts by running the same port 3000 when we run our two app projects.</p><p><strong>11. We can do that like this, within our server/bin/www on line 15:</strong></p><p>var port = normalizePort(process.env.PORT || '4000');</p><p>Now to run our project, all we need to do is go to our root directory and run:</p><p>$ yarn start</p><p><strong>That’s it, we’re done. </strong></p><p>This has fully set up our Yarn Workspace, and has it running!</p><p><em><strong>If you’d like to read some more on the topic of Yarn Workspaces, as well as monorepo's in general. Here are some good resources:</strong></em></p><p>Creating Yarn Workspaces with GatsbyJS - <a target="_blank" title="https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/" href="https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/">https://www.gatsbyjs.com/blog/2019-05-22-setting-up-yarn-workspaces-for-theme-development/</a></p><p>Yarn Workspaces: Organize Your Project’s Codebase Like A Pro - <a target="_blank" title="https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/" href="https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/">https://www.smashingmagazine.com/2019/07/yarn-workspaces-organize-project-codebase-pro/</a></p><p>Ride Down Into JavaScript Dependency Hell - <a target="_blank" title="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html" href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html</a></p><p>What Is a Monorepo? - <a target="_blank" title="https://www.perforce.com/blog/vcs/what-monorepo" href="https://www.perforce.com/blog/vcs/what-monorepo">https://www.perforce.com/blog/vcs/what-monorepo</a></p><p><strong>Bonus: </strong><a target="_blank" title="https://stackoverflow.com/questions/64110406/how-could-i-change-the-name-of-my-yarn-workspace-package" href="https://stackoverflow.com/questions/64110406/how-could-i-change-the-name-of-my-yarn-workspace-package"><strong>How Do You Modify A Yarn Workspace?</strong></a></p><p>This is a post on StackOverflow that will help in modifying a Yarn workspace that has already been setup when that is necessary for you to do.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/what-is-a-yarn-workspace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914835</guid>
            <pubDate>Wed, 28 Oct 2020 03:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Note on Branching Within a Shader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914672">thread link</a>) | @underanalyzer
<br/>
October 27, 2020 | https://www.peterstefek.me/shader-branch.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/shader-branch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>26 October 2020</strong></label></p><p>An <a href="https://www.google.com/search?q=three+weeks&amp;oq=three+weeks">eternity</a> ago, I published a <a href="https://www.peterstefek.me/focused-render.html">blog post</a> about a shader I wrote. In that post, I casually repeated a piece of gpu folklore I picked up as a wee opengl enthusiast almost a decade ago,   </p>
<p>
"Using if statements inside a shader will cause performance degradation."  
</p>

<p>People on the internet seemed a little skeptical about this statement, and I realized my advice might be outdated. So this post is a quick follow up about the cost of branching on more modern gpus.  </p>
<p>Before we talk about branching, what is a gpu? A GPU or graphics processing unit, is a special piece of hardware initially developed to crunch numbers for graphics calculations. It accomplishes this goal quickly through a large amount of parallelization.   </p>
<p>GPUs can run many threads at the same time in parallel. These threads are generally executed in groups called warps (CUDA), invocations (Vulkan) and waves (I will use the term warp, but they are all interchangeable). On recent Nvidia hardware (Ampere/ Volta / Pascal) these warps contain 32 threads. Pascal for example can theoretically run up to four independent instructions per warp over 56 warps of 32 threads which comes out to a mind blowing 7168 instructions per cycle. </p>
<p>Each warp can only execute one instruction at a time. However that instruction can be executed for each of the threads in the warp. This means the GPU can execute 32 copies of the same instruction in parallel for each thread in the warp at once.   </p>
<p>However, taking both sides of a branch will cause the threads inside a warp to "diverge". This means some threads will need to execute one side of the branch and some will need to execute the other. Unfortunately, both instructions can not be executed simultaneously for threads in the same warp. So these divergent instructions must be executed sequentially.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.  </p>
<p>Consider the <a href="https://www.shadertoy.com/view/WdyyWV">following fragment shader</a>:<br>
<code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{  <br>
  </code></p><p><code>
  // TUNE THIS AMOUNT TO YOUR GPU STRENGTH<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (mod(fragCoord.x, 2.) &lt; 1. &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
      </p></div>
  } else {
    <div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>In fragment shaders like the one above, each warp is composed of a set of spatially close pixels. Each warp in this shader should diverge because each horizontally adjacent pixel takes a different side of the branch. Let's say the cost of each inner loop is n cycles. Since each side of the branch is executed in series, each warp must take at least 2n cycles, even though each thread uses only one side of the branch. These effects scale with the number of threads in the distinct divergent paths taken (up to 32x in Nvidia hardware). Here's another shader which should have roughly four branches per warp. <a href="https://www.shadertoy.com/view/wsVyzG">This shader</a> will take at least 4n cycles.  </p>
<p>However, let's look a <a href="https://www.shadertoy.com/view/tsVyzG">second shader</a>:   </p>
<p><code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
  </code></p><p><code>
  // USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (fragCoord.x &lt; iResolution.x / 2.0 &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
    </p></div>
  } else {
    <div><p>
        for (int i = 0; i &lt; workAmount; i++) {
          </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>This shader should run roughly twice as fast as the other shader even though roughly the same number of pixels take each branch. This is because most of the warps do not diverge (with the exception of a few around half way across the screen).   </p>
<p><strong>Nvidia Specifics</strong><br>
As far as I can tell, there are roughly two different ways of nvidia graphics cards handle divergence with in a warp.</p>
<p><strong>Thread Masking (Pre Volta)</strong><br>
On pre volta Nvidia card, divergence was handled by something called thread masking.   </p>
<p>Basically when a conditional is hit, a thread mask is generated.  We can think of this mask as a 32 entry array. Each entry specifies whether the corresponding thread takes the first side of the branch or not. The first side is then executed for each of those threads. After the first side of the branch is then executed, the mask is reversed and the other side of the branch is executed.   </p>
<p>This thread mask strategy exists in part because there is only one program counter per warp on pre volta gpus. So essential every thread in the warp must be at the same place in the program. The only way we know which threads to execute, is by using the mask.</p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>It's worth noting that only the threads which need to execute the branch actually are assigned to computational cores. So if no threads execute one side of the branch, no work is done.</p>
<p><strong>Independent Thread Scheduling (Volta and Beyond)</strong><br>
One big change in the Volta architecture and beyond is the introduction of "Independent Thread Scheduling".   </p>
<p>In Independent thread scheduling, each thread has its own program counter. This allows each warp to track the execution of every thread at a fine grain level. However, we can still only execute only one instruction at a time. So the actual runtime of a branch does not change.  </p>
<p>So if Independent Thread Scheduling does not speed up branching, what does it do? Independent Thread Scheduling enables both sides of a branch to execute concurrently but not in parallel.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/volta-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>The reason for this shift is because before Volta, branches were places where deceptive deadlocks could occur. <br>
<code>
leader_id = 0<br>
If (threadIdx.x == leader_id) {<br>
  </code></p><p><code>
    // Do some inital work
  </code></p><p><code>
} else {
  <p>
    // Wait for leader to finish it's work<br>
    // then do my work
  </p>
}<br>
</code></p>
<p>In the above compute shader pseudo code, we have 31 "follower" threads waiting for the "leader thread" to finish (using in-warp shared local memory) before executing their own instructions. </p>
<p>On a Pascal GPU or below, if the else side of the branch is executed first, a deadlock will occur. The leader will never get a chance to start it's work because its followers will be waiting for it. </p>
<p>Independent Thread Scheduling gets around these locking problems by interlacing the two diverging paths. </p>
<p><strong>Article TLDR</strong><br>
Branch divergence in warp makes all parts of the branch execute in sequence which slows down the shader. Branching divergence between warps does not affect runtime.  </p>
<p><strong>Further Reading</strong><br>
Branch execution on gpus is surprisingly deep, and there are many edge cases I didn't address and I also didn't touch gpu vendors other than Nvidia. Here are some good sources if you want to learn more:  </p>
<p><a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">The Volta Whitepaper</a> (Most of this post can be found between figures 20 and 22)<br>
<a href="http://taylorlloyd.ca/gpu,/pascal,/cuda/2017/01/07/gpu-pipelines.html">Understanding the Pascal GPU Instruction Pipeline</a><br>
<a href="https://aschrein.github.io/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html#figure-8-divergent-threads-execution-time">What's up with My Branch on GPU</a> (this post covers some diabolical edge cases, including some around texture sampling)  </p>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/shader-branch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914672</guid>
            <pubDate>Wed, 28 Oct 2020 03:10:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a Real-Time NYC Subway Map with Real Weird NYC Subway Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914667">thread link</a>) | @underanalyzer
<br/>
October 27, 2020 | https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/ | <a href="https://web.archive.org/web/*/https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <h3>
        <a href="">
            Making a Real-Time NYC Subway Map with Real Weird NYC Subway Data
        </a>
      </h3>
      
            
      <p>Earlier this week the NYC MTA released a new <a href="https://map.mta.info/">digital-first map</a>. The <a href="https://www.curbed.com/2020/10/first-look-new-yorks-digital-subway-map-comes-alive-today.html">Curbed exclusive</a> that announced its release accurately portrays it as a strange child of both the 1972 map design by Massimo Vignelli and the current <a href="https://new.mta.info/map/5256">“paper” map</a>. One feature of the new map (though it's harder than it should be to notice at first) is real-time visualizations of each train in the system.</p>
<p>I've been working on a similar concept, starting in February 2020, on which progress stalled once I stopped riding the subway regularly in March. But, when I started my batch at <a href="https://www.recurse.com/">Recurse Center</a> I decided to pick up the project again. My inspiration for the map was the large TV screens that the MTA has installed in stations over the last few years, which frustratingly display the “paper” version of the map.</p>
<figure>
<p><img src="https://www.patrickweaver.net/images/blog/nyc-subway/tv-screen-map.jpg" alt="A photograph of a TV in a subway station with the “paper” map displayed.">
</p>
<figcaption>Subway station TV (This is not a good photo, but it’s hard to take a picture of a screen underground)</figcaption>
</figure>
<p>Over the past few weeks at RC the subway map has been my main focus, which is longer than I expected the project to take (and though I have a prototype, I wouldn’t say I’m close to “done”). A big factor in the time the project has taken is some of the quirks in working with MTA data, which based on some of the bugs I've seen in the "official" version I'd say the team working on that version had to grapple with as well.  I'm not sure I will ever finish this project to a state that would look great on a subway station tv, or be useful, but I do want to point out <a href="https://www.theweekendest.com/trains">The Weekendest</a> by <a href="https://sunny.ng/">Sunny Ng</a> (who also made <a href="https://www.goodservice.io/">goodservice.io</a>), which is a great take on the concept, and handles some of the challenges of this kind of project much better than the MTA map does.</p>
<p>For a long time the NYC Subway was almost <a href="https://www.theatlantic.com/technology/archive/2015/11/why-dont-we-know-where-all-the-trains-are/415152/">completely lacking in real-time data</a>. For many years the only line that had even countdown clocks in stations was the L, which seems to be the line the MTA tries out new technology on, likely because it never shares tracks with any other line. Over the last 5 years the MTA has slowly installed countdown clocks in every station, and made the data that powers the countdown clocks available on their website, in apps, and as data online.</p>
<p>Inspired and frustrated by the “paper” maps on the tv screens, I first became interested in working with MTA data in 2018, but I initially started working with bus data, I think for two reasons: the first was because at the time the API key for working with bus data was easier to obtain than for subway data, the second because my morning commute at the time usually started with the bus (The MTA, earlier this year, has fortunately updated the system for obtaining an API key for subway data). I made a small prototype of an iPhone app that would show real-time bus data, but got distracted by learning the Swift programming language and abandoned the project without building functionality beyond what the MTA already provided <a href="https://bustime.mta.info/">on their bustime website</a>.</p>
<p>That MTA Bustime website was the other inspiration for what became my map idea. Though you could only view one route at a time (and the functionality is not available on phone-size devices), the Bustime website showed, in addition to countdowns for each stop, the physical location of each bus on a map. This leads us to the first weird thing about working with NYC Subway data, unlike real-time bus data, the subway data does not contain the latitude and longitude data for each train that would make it easy to show them on a map.</p>
<h3>Real-Time Transit Data</h3>
<p>Transit data for most transit systems is available in formats called <a href="https://developers.google.com/transit/gtfs">GTFS</a> (General Transit Feed Specification) and <a href="https://developers.google.com/transit/gtfs-realtime">GTFS Realtime</a>, which were developed by Google (makes you wonder what the “G” originally stood for), but are now widely used. A GTFS file is, “a collection of at least six, and up to 13 CSV files (with extension .txt) contained within a .zip file.” and “The GTFS Realtime data exchange format is based on Protocol Buffers” (which are <a href="https://developers.google.com/protocol-buffers">“Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data”</a>).</p>
<p>The GTFS Realtime feeds are available through 9 different API endpoints from the MTA. These 9 endpoints roughly correspond to the line colors, with Shuttles combined with trains they share tracks or stations with, and the 1/2/3 and 4/5/6 sharing one endpoint. This list of separate endpoints is another challenge with working with the entirety of the MTA data.</p>
<p>I have exclusively worked with the NYC MTA’s GTFS Realtime feeds through the <a href="https://www.npmjs.com/package/gtfs-realtime-bindings">npm module</a> maintained by Google. It is very possible that some of the challenges I’ve encountered are due to trying to squeeze the “extensible mechanism for serializing structured data” into JSON. Each API response is mostly composed of an array of "Feed Entity" objects like <a href="https://www.patrickweaver.net/notes/nyc-subway-feed-entity/">these</a>, but there are a few quirks to working with this data (some maybe because of the JSON conversion).</p>
<ul>
<li>Each item in the array has an <code>id</code> property, but unfortunately these ids do not consistently refer to the same train between each update, it's best to ignore it.</li>
<li>The array consists of pairs of objects that either have a <code>tripUpdate</code> property or a <code>vehicle</code> property. Each of these have a sub-property called <code>tripId</code> that allows you to unite the pairs, but there are also some that don't have a corresponding item (usually these represent trips that recently ended or haven't yet begun).</li>
<li>The data mixes together HH:MM:SS timestamps for data about when a train's trip started, and <a href="https://en.wikipedia.org/wiki/Unix_time">Unix timestamps</a> for data about the current time (according to the API) and when a train will arrive at a station (the API provides both arrival and departure times but as far as I have seen they are always identical).</li>
<li><code>tripUpdate</code> items show information about the stops a train will make in the future (stopTimeUpdates) and vehicle items show information about the current status of the train, but the first <code>stopTimeUpdate</code> is usually in the past.</li>
</ul>
<p>I had never heard of Protocol Buffers before starting this project, so I was excited to learn more about them while reading through <a href="https://dataintensive.net/">Designing Data Intensive Applications</a> with fellow Recursers.  In the book Martin Kleppmann notes that a, "curious detail of Protocol Buffers is that it does not have a list or array datatype, but instead has a repeated marker for fields (which is a third option alongside required and optional)." This could be the reason for the strange organization of the <code>tripUpdate</code> and <code>vehicle</code> properties.</p>
<h3>Calculating Train Locations</h3>
<p>The subway real-time API doesn’t have latitude and longitude data because it is designed to feed data to countdown clock style applications that show when the train will be at a specific station. One of the earliest features that I built into the real-time map was a way to translate these station-by-station countdown clocks into an approximation of the location of each train. My first attempt at this was to just show a list of stations and display an icon for a train between the names of the station it had been at previously and the station it was approaching.</p>
<figure>
<p><img src="https://www.patrickweaver.net/images/blog/nyc-subway/prototype-diagram.png" alt="An early prototype diagram of G train positions.">
</p>
<figcaption>A first prototype, still available at: <a href="https://nyc-subway-g.glitch.me/">nyc-subway-g.glitch.me</a></figcaption>
</figure>
<p>The next step was plotting the stations on a map. To start off, as with the diagram version, I just placed each train at the midpoint between the station it was travelling from and the station it was travelling towards.</p>
<p>A goal I had for the project was not just to show real-time train locations, but to animate them as they moved around the map. To determine how long I should expect a train to take to travel between each station I logged updates from the MTA API for a few hours and noted both the average time for a pair of stations, and the longest time I had seen for the pair. I'm still experimenting a little bit with what values to use as the baseline, but from looking at the logged numbers there does seem to be an expected amount of time for most stations.</p>
<figure>
<div>
<pre><code>G: {
   G22: { N: { avg: 60, max: 71 }, S: null },
   G24: { N: { avg: 123, max: 180 }, S: { avg: 60, max: 106 } },
   G26: { N: { avg: 75, max: 90 }, S: { avg: 108, max: 180 } },
   G28: { N: { avg: 128, max: 180 }, S: { avg: 78, max: 90 } },
   G29: { N: { avg: 60, max: 76 }, S: { avg: 139, max: 180 } },
   G30: { N: { avg: 51, max: 74 }, S: { avg: 70, max: 90 } },
   G31: { N: { avg: 60, max: 90 }, S: { avg: 58, max: 69 } },
   G32: { N: { avg: 66, max: 87 }, S: { avg: 53, max: 84 } },
   G33: { N: { avg: 50, max: 66 }, S: { avg: 67, max: 84 } },
   G34: { N: { avg: 58, max: 90 }, S: { avg: 54, max: 66 } },
   G35: { N: { avg: 68, max: 86 }, S: { avg: 50, max: 81 } },
   G36: { N: { avg: 81, max: 161 }, S: { avg: 59, max: 71 } },
   A42: { N: { avg: 70, max: 177 }, S: { avg: 87, max: 157 } },
   F20: { N: { avg: 68, max: 90 }, S: { avg: 86, max: 165 } },
   F21: { N: { avg: 72, max: 120 }, S: { avg: 76, max: 120 } },
   F22: { N: { avg: 62, max: 90 }, S: { avg: 84, max: 120 } },
   F23: { N: { avg: 90, max: 120 }, S: { avg: 88, max: 150 } },
   F24: { N: { avg: 101, max: 120 }, S: { avg: 67, max: 84 } },
   F25: { N: { avg: 139, max: 180 }, S: { avg: 71, max: 90 } },
   F26: { N: { avg: 120, max: 120 }, S: { avg: 109, max: 150 } },
   F27: { N: null, S: { avg: 81, max: 120 } },
 }
</code></pre>
</div>
<figcaption>Average and max wait times in seconds for stops on the G line.</figcaption>
</figure>
<figure>
<table>
<thead>
<tr>
<th>Trip Id</th>
<th>Trip Start Time</th>
<th>Trip Date</th>
<th>Route</th>
<th>Stop1 Arrival</th>
<th>Stop1 Id</th>
<th>Stop2 Arrival</th>
<th>Stop2 Id</th>
<th>Seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>073476_G..N</td>
<td>12:14:46</td>
<td>20200818</td>
<td>G</td>
<td>1597768631</td>
<td>G33N</td>
<td>1597768692</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>074600_G..N</td>
<td>12:26:00</td>
<td>20200818</td>
<td>G</td>
<td>1597769103</td>
<td>G33N</td>
<td>1597769172</td>
<td>G32N</td>
<td>69</td>
</tr>
<tr>
<td>075000_G..N</td>
<td>12:30:00</td>
<td>20200818</td>
<td>G</td>
<td>1597769531</td>
<td>G33N</td>
<td>1597769596</td>
<td>G32N</td>
<td>65</td>
</tr>
<tr>
<td>076501_G..N</td>
<td>12:45:01</td>
<td>20200818</td>
<td>G</td>
<td>1597770333</td>
<td>G33N</td>
<td>1597770396</td>
<td>G32N</td>
<td>63</td>
</tr>
<tr>
<td>077700_G..N</td>
<td>12:57:00</td>
<td>20200818</td>
<td>G</td>
<td>1597771043</td>
<td>G33N</td>
<td>1597771104</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>078403_G..N</td>
<td>13:04:02</td>
<td>20200818</td>
<td>G</td>
<td>1597771443</td>
<td>G33N</td>
<td>1597771524</td>
<td>G32N</td>
<td>81</td>
</tr>
<tr>
<td>079600_G..N</td>
<td>13:16:00</td>
<td>20200818</td>
<td>G</td>
<td>1597772051</td>
<td>G33N</td>
<td>1597772112</td>
<td>G32N</td>
<td>61</td>
</tr>
<tr>
<td>080550_G..N</td>
<td>13:25:30</td>
<td>20200818</td>
<td>G</td>
<td>1597772711</td>
<td>G33N</td>
<td>1597772776</td>
<td>G32N</td>
<td>65</td>
</tr>
</tbody>
</table>
<figcaption>Logged travel Times between the Bedford - Nostrand stop and the Myrtle - Willoughby stop on the G train</figcaption>
</figure>
<h3>Secret Stations</h3>
<p>One thing I discovered while …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/">https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/</a></em></p>]]>
            </description>
            <link>https://www.patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914667</guid>
            <pubDate>Wed, 28 Oct 2020 03:09:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Dual-Boot Ubuntu 20.04 and Windows 10 with Encryption]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24914573">thread link</a>) | @Fiveplus
<br/>
October 27, 2020 | https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html | <a href="https://web.archive.org/web/*/https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><img src="https://www.mikekasberg.com/images/posts/dual-boot-encryption-full.jpg" alt="Image for "></p>
  <p><span>08 Apr 2020</span></p><p>When you run the Ubuntu installer, there’s an option to dual-boot Ubuntu with an
existing Windows installation. There’s also an option to encrypt your Ubuntu
installation, but <em>only if you erase everything and install ubuntu</em>. There’s no
automatic way to install Ubuntu alongside Windows 10 with encryption. And while
there are plenty of tutorials for dual-booting Ubuntu and Windows, many of them
are outdated – often referencing an MBR partition table – and almost none of
them seem to address encrypting your Ubuntu partition.</p>

<blockquote>
  <p>Dual-booting with encrypted storage should not be this hard in 2020.</p>

  <p>–Me, while figuring out how to do this.</p>
</blockquote>

<p>In reality, once you figure it out, it’s not that hard. The tricky thing is that
this isn’t well-documented <strong>anywhere</strong>! So I’m hoping to fix that with this
tutorial blog post. Honestly, if you know enough about Ubuntu to set up a
dual-boot with Windows, it’s only a little bit harder to do it with encryption.
I prepared this tutorial on a Dell Latitude e7450, and I fine-tuned it when I
tested it on my Dell Precision 5510. So it should work with almost no
modification on most Dell systems, and with only minor modifications
(particularly around BIOS setup) on most other types of computers.</p>

<h2 id="references">References</h2>

<p>To write this guide, I compiled information from several sources. Here are some
of the most useful references I found:</p>

<ul>
  <li><a href="https://gist.github.com/luispabon/db2c9e5f6cc73bb37812a19a40e137bc">XPS 15 9560 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/luispabon">luispabon</a>. I followed these notes pretty
closely, but modified some partition sizes and names based on other guides.</li>
  <li><a href="https://gist.github.com/mdziekon/221bdb597cf32b46c50ffab96dbec08a">XPS 15 9570 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/mdziekon">mdziekon</a>, upon which the above is based.</li>
  <li><a href="https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019">Full Disk Encryption HowTo 2019</a>,
from the Ubuntu Community Wiki. This is a great resource, but deals with
encryption without dual-booting.</li>
  <li><a href="https://help.ubuntu.com/community/ManualFullSystemEncryption">Manual Full System Encryption</a>,
from the Ubuntu Community Wiki. This is longer, and isn’t focused on
dual-booting, but provides great details on the way certain things work.</li>
</ul>

<p>It is worth noting that this method doesn’t encrypt <code>/boot</code>. While there are
valid reasons for encrypting /boot, the graphical installer does not encrypt it
when you do a graphical install with LUKS. As such, I’m matching that precedent,
and keeping the simplicity of an unencrypted /boot partition. Thus, the guide
I’ve compiled below is just about the <strong>simplest way to have a LUKS encryption
with dual-boot.</strong></p>

<h2 id="why-encryption-is-important">Why encryption is important</h2>

<p>I began using encrypted storage on all my personal computers 5 or 6 years ago
after noticing that all the companies I’d worked for required it, and had good
reason to. Laptops get lost and stolen all the time. They’re high-value items
that are small and easy to carry. And when a thief gets your laptop, there’s
tons of valuable information on it that they can use or sell. Even if you use a
password to log in, it’s easy for an attacker to gain access to your data if
your disk isn’t encrypted – for example, by using a live USB stick. And once
they have that data, they might get access to online accounts, bank statements,
emails, and tons of other data. For me, an encrypted hard disk isn’t optional
anymore – its a necessity.</p>

<h2 id="an-overview">An Overview</h2>

<p>So what are we going to do? This tutorial will help you set up a system to
<strong>dual-boot Ubuntu 20.04 and Windows 10</strong>. (I haven’t tested it, but it should
work with most other modern versions (~16.04+) of Ubuntu or Windows.) The system
will use a GPT hard disk with UEFI (your BIOS must support UEFI). The Ubuntu
partition will be encrypted with LUKS.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The Windows partition can optionally
be encrypted with BitLocker. I’m going to keep the Ubuntu installation as close
to a “default” installation as possible – no fancy tricks like a separate
<code>/home</code> partition, but it should be somewhat easy to add that yourself if you
really want to.</p>

<p>I’m going to start with a blank hard disk, installing both Windows 10 and Ubuntu
from scratch. If you already have Windows installed and you want to keep it, you
should be able to shrink your windows partition and join us in phase 3 (though
you might want to skim phases 1 and 2 to understand what we did).</p>

<p>To give you a broad overview of where we’re headed, here’s what we’re going to
do:</p>

<ol>
  <li>Prepare the installation media and computer</li>
  <li>Install Windows 10</li>
  <li>Create an encrypted partition for Ubuntu</li>
  <li>Install Ubuntu</li>
</ol>

<p>Of course, as with any new OS installation, you should back up any important
data before proceeding. <strong>The instructions below will erase all the data on your
hard disk.</strong> Proceed at your own risk; I’m not responsible for any damage or
data loss.</p>



<p>Since we’re installing both Windows 10 and Ubuntu from scratch, we’ll need a USB
stick for each. If you don’t already have a computer running Ubuntu or Windows,
making the installation media will be a little harder – but there are tutorials
for that and I’ll let you figure it out on your own.</p>

<ol>
  <li>Create a Windows Installer USB stick.  The easiest way is to use the <a href="https://www.microsoft.com/software-download/">Windows
10 Media Creation Tool</a> from a
computer that’s already running Windows.</li>
  <li>Create an Ubuntu 20.04 USB stick. The easiest way is to <a href="https://ubuntu.com/download/desktop">download the
ISO</a> and use the Startup Disk Creator on a
computer that’s already running Ubuntu.</li>
</ol>

<p>Great! We’ve got our USB sticks ready to go! One final thing before we get
started – we need to make sure our BIOS is set up correctly. In particular, we
want to make sure we’re using UEFI to boot our OS.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/dell-bios.jpg" alt="The Dell BIOS"></p>

<ol start="3">
  <li>Ensure your computer is running the latest BIOS available. This is important
because an out-of-date BIOS can have bugs, and those bugs sometimes affect
things like UEFI, non-Windows operating systems, or other components we’ll be
touching.</li>
  <li>Edit your BIOS settings. The following names are probably specific to Dell
BIOS, but other manufacturers will have similar settings.
    <ol>
      <li>Under <code>General</code> and <code>Boot Sequence</code>, make sure your <code>Boot
List Option</code> is set to <code>UEFI</code>.</li>
      <li>Under <code>General</code> and <code>Advanced Boot Options</code>, I disabled
<code>Legacy Option ROMs</code>. It’s important that both OSes install in UEFI mode.
(You can probably enable this when installation is complete if you care).</li>
      <li>Under <code>Security</code>, <code>TPM Security</code> must be enabled if you
want to easily set up BitLocker in Windows.</li>
      <li>I disabled <code>Secure Boot</code>. I’m not sure if this is absolutely required, and
you can try leaving it on or re-enabling it when you’re done if you want.</li>
    </ol>
  </li>
</ol>

<p>Now that our BIOS is configured for UEFI, we’re going to set up our hard disk.</p>

<div>
<p><b>For this tutorial, your BIOS must support UEFI!</b></p>
<p>Most modern computers support this, but if yours doesn't this tutorial won't
work for you. You should consider:</p>

<ul>
  <li>Installing only Linux with encryption using the graphical installer.</li>
  <li>OR Installing only Windows with encryption.</li>
  <li>OR Dual-booting Linux and Windows without encryption using Ubuntu's graphical installer.</li>
  <li>OR Finding another tutorial or figuring out how to do this with an MBR disk.</li>
</ul>
</div>

<ol start="5">
  <li><strong>Completely erase</strong> your hard disk and set it up for UEFI by doing the
following.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>
    <ol>
      <li>Boot your Ubuntu USB stick and use <code>Try without installing</code>.</li>
      <li>Open a terminal. Make it fullscreen while you’re at it.</li>
      <li>Figure out what your primary hard disk is called. It will probably be
either <code>/dev/sda</code> or <code>/dev/nvme0n1</code>. Importantly, it’s <strong>not</strong> <code>/dev/sda1</code> or
<code>/dev/nvme0n1p1</code> – those are partitions of the disk. One way to figure out what
yours is called is to run <code>lsblk</code> and look at the disk size. Throughout the rest
of this guide, I’m going to refer to <code>/dev/sda</code>. <strong>If yours is not
<code>/dev/sda</code>, replace <code>/dev/sda</code> with your own (perhaps <code>/dev/sdb</code> or
<code>/dev/nvme0n1</code>) for the rest of this guide.</strong></li>
      <li>
        <p>Run the following commands. This will initialize the drive as a GPT drive
and create a 550M EFI system partition formatted as FAT32.</p>

        <div><div><pre><code>$ sudo su
# sgdisk --zap-all /dev/sda
# sgdisk --new=1:0:+550M /dev/sda
# sgdisk --change-name=1:EFI /dev/sda
# sgdisk --typecode=1:ef00 /dev/sda
# mkfs.fat -F 32 /dev/sda1
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ol>

<p>OK, phase 1’s complete. We have our installation media ready to go and the
computer’s BIOS and hard drive is set up correctly. Next, we’ll install Windows.</p>

<h2 id="phase-2-install-windows">Phase 2: Install Windows</h2>

<p>In this phase, we’re going to install Windows. Note that when we do this, we’re
going to leave some unallocated space to install Linux later. This is a good
approach because the Windows installer will mess with our partitions a little
bit, and its easier to let it do so before finalizing our Linux partitions.</p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/windows-installer.jpg" alt="The Windows installer"></p>

<ol>
  <li>Boot from your Windows Installer USB stick.</li>
  <li>Choose a <code>Custom (advanced)</code> install to get to the Windows partitioning tool.</li>
  <li>Create a new partition. The size of this partition should be the amount of
disk space you want to use for Windows. In this example, I did 80G since the SSD
on my computer is relatively small. If unsure, do about half of your hard
disk.</li>
  <li>Windows will warn you that it is going to create an extra system partition.
This is good.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
  <li>Install Windows onto the partition you just made. There’s no need to format
any partitions – the Windows installer will take care of that for you.</li>
  <li>When the Windows installation is finished, log in and enable BitLocker on
drive <code>C:</code>. This will automatically create yet another partition on your disk
(a Windows recovery partition) - which is why we’re doing it before
partitioning for Ubuntu.</li>
</ol>

<p>At this point, you can start using Windows. But I’d avoid doing too much setup
or personalization yet so you don’t have to do it again if something goes wrong
below. If you want to double check your partitions, this is what you’ll be left
with after installing Windows and enabling BitLocker:</p>

<div><div><pre><code>ubuntu@ubuntu:~$ sudo sgdisk --print /dev/sda
Disk /dev/sda: 500118192 sectors, 238.5 GiB

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048         1128447   550.0 MiB   EF00  EFI
   2         1128448         1161215   16.0 MiB    0C01  Microsoft reserved ...
   3         1161216       167825076   79.5 GiB    0700  Basic data partition
   4       167825408       168900607   525.0 MiB   2700
</code></pre></div></div>

<h2 id="phase-3-partition-the-drive-for-ubuntu">Phase 3: Partition the drive for Ubuntu</h2>

<p>This is the trickiest phase since this is where we need to manually set up our
encrypted disks for Ubuntu. We’re going to make it work very similar to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</a></em></p>]]>
            </description>
            <link>https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914573</guid>
            <pubDate>Wed, 28 Oct 2020 02:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Do Great Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914528">thread link</a>) | @StokoeKeagan
<br/>
October 27, 2020 | https://www.keaganstokoe.com/post/how-to-do-great-work | <a href="https://web.archive.org/web/*/https://www.keaganstokoe.com/post/how-to-do-great-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><p id="viewer-foo"><span>Nobody sets out to be average. Nobody wants to reach the end of the road feeling that they haven’t fulfilled their potential. We all want to do great work. </span></p><p id="viewer-4evni"><span>Great work is a form of wizardry. People who do great work are wizards. <strong>The path to wizardry can be summed up in one sentence: surround yourself with wizards. </strong></span></p><p id="viewer-7mio7"><span>It seems naively simple, but when you get to the end of this essay you’ll understand why on the quest to do great work, the only thing that matters is whether you’ve been surrounded by wizards or not. </span></p><p id="viewer-84pdq"><span>Great work doesn’t come from moments of magic. It comes from making incremental improvements over a long enough time for them to compound. Steph Smith wrote an </span><a href="https://blog.stephsmith.io/how-to-be-great/" target="_blank" rel="noopener"><span><u>essay</u></span></a><span> about this where she arrives at the conclusion that great is just good, but repeatable. The image below summarises the argument. <strong> </strong></span></p><div id="viewer-s8ii"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_37e47edcee264562b335c6763c11b58d~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_37e47edcee264562b335c6763c11b58d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-749s7"><span>If great work is just good work done repeatedly, two questions need to be answered: </span></p><ol><li id="viewer-f1qj8"><p><span>How do you do good work? </span></p></li><li id="viewer-e2eh6"><p><span>How do you do it consistently? </span></p></li></ol><p id="viewer-64o4s"><span><strong>The answer to both is simple: surround yourself with wizards. </strong></span></p><h3 id="viewer-id1h"><strong>THE GOOD WORK PART</strong></h3><p id="viewer-5isde"><span>When I was 13 years old I made the challenging jump from junior to senior cricket. The players were physically and mentally stronger, and far more mature. The coaching was more intense, the fitness requirements whizzed up a notch, and everything seemed to shift from 0 to 60 extremely quickly.</span></p><p id="viewer-7skt"><span>One of the players on the team was phenomenal. In my first game for the side, he walked in to bat and hit 5 fours off his first 5 balls. He was retired and he walked off the field as if nothing had happened. It was magic. That was my first encounter with a wizard. </span></p><p id="viewer-3gk1g"><span>Wizards do work that is not only brilliant in its own right but work that makes everyone around them better. Our team was filled with an unrivalled sense of confidence. It's what makes wizards valuable. It's why we want to be wizards. </span></p><p id="viewer-c3is3"><span>That season was a phenomenal experience. Even though we were on the same team, and logically we were playing at the same level, it seemed like the skills required were completely different. You couldn’t compare my abilities with his. I improved more in that season than in any other.</span></p><p id="viewer-aao0e"><span>It leads me to wonder how one person on one team helped me produce good work for years to come. <strong>The best explanation I’ve come across is tacit knowledge.</strong> Tacit knowledge is the knowledge and skills we pick up from the people around us and i<!-- -->t plays a disproportionately large role in doing good work. </span></p><p id="viewer-1ugo0"><span>Tacit knowledge is challenging to wrap your head around. This anecdote from an </span><a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank" rel="noopener"><span><u>essay series</u></span></a><span> on the topic provides context:</span></p><blockquote id="viewer-1mt6r"><span>“Gallwey (a tennis coach) relays the story of teaching a student without explicit instruction: “I was going to skip entirely my usual explanations to beginning players about the proper grip, stroke and footwork for the basic forehand. Instead, I was going to hit ten forehands myself, and I wanted him to watch carefully, not thinking about what I was doing, but simply trying to grasp a visual image of the forehand. He was to repeat the image in his mind several times and then just let his body imitate.” 

It worked. Gallwey concluded: “I was beginning to learn what all good pros and students of tennis must learn: <strong>that images are better than words, showing better than telling, too much instruction worse than none, and that trying often produces negative results.”</strong></span></blockquote><p id="viewer-7j54h"><span>Tacit knowledge is knowledge that cannot be captured through words alone. It’s what’s on display when you ask someone how they did something and they tell you that "it just felt right.” </span></p><p id="viewer-2rjc9"><span><strong>Tacit knowledge is a catalyst that transforms average people with average skills into people with the intuition and know-how to produce good work. It’s not to say that you can’t do good work without it, but you’re far more likely to succeed with it and as a result of it. </strong></span></p><p id="viewer-6i9ji"><span>When learning a new skill, your tacit knowledge resources start at zero. Over time they increase and the quality of your work increases with them. Time spent with wizards reduces the effort required to develop tacit knowledge and produce good work. Why? Because when learning, images are better than words, showing better than telling, and too much instruction worse than none. When you question and imitate wizards, you learn extremely quickly. You place yourself on the shortest path to doing good work. </span></p><p id="viewer-c09e3"><span>It happens because stress elicits growth. Place your body under stress and it’ll overshoot and overprepare in response. It’s how you get stronger and more capable. Do it often enough and good work becomes your default. </span></p><p id="viewer-81jj0"><span>In theory, it’s simple: place yourself under sufficient stress to elicit desired growth. In practice, it’s more complicated. Imagine I went to the gym every day and pushed myself as hard as I could. I’d see growth, but would it be the most growth I’m capable of? Probably not. My biological and nutritional knowledge would let me down, and it would be far tougher to remain motivated when in pursuit of this goal by myself. </span></p><p id="viewer-2rdj8"><span>Intellectual and career growth works in the same way. I can push myself to read more books and learn new skills. I’ll grow, but will I reach the levels I’m capable of without the right environment? Probably not. <!-- -->To get a more accurate picture of the type of growth you’re capable of, you need to be in an environment that fosters and values growth. </span></p><p id="viewer-5dmef"><span>Tobi Lutke, CEO of Shopify, began an apprenticeship at the age of 16. In </span><a href="https://tobi.lutke.com/blogs/news/11280301-the-apprentice-programmer" target="_blank" rel="noopener"><span><u>an essay</u></span></a><span> he wrote about the experience, he says the following: </span></p><div id="viewer-2bd6n"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_00186cf1173d477c92d7e2e3f6bca549~mv2.png/v1/fit/w_1000%2Ch_628%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_00186cf1173d477c92d7e2e3f6bca549~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-5n3p7"><span>That is an enormous statement. It comes from someone the CEO of a $120 billion-dollar company. For him to attribute a move to the basement as the most important thing to happen in professional life shows the importance of environment.</span></p><p id="viewer-f4mn5"><span><strong>Let’s recap: </strong></span></p><ul><li id="viewer-3rsa1"><p><span>Great work is just good work, done repeatably. </span></p></li><li id="viewer-5dhso"><p><span>Tacit knowledge is the catalyst that transforms average work into good work. </span></p></li><li id="viewer-28srk"><p><span>You acquire tacit knowledge by placing yourself in an environment where the people around you are better than you. Stress leads to growth. Growth leads to good work. </span></p></li></ul><h3 id="viewer-97c3t"><strong>CONSISTENCY, CONSISTENCY, CONSISTENCY</strong></h3><p id="viewer-2kgkg"><span>Environment plays an important role in doing good work, but it’s unlikely that it’s the only way to produce good work.<!-- --> It’s simply one that is effective for most people. </span></p><p id="viewer-2sqvq"><span>It’s not uncommon for people to produce good work, but it is uncommon for them to sustain it over a long period of time. To maintain consistency, environment is non-negotiable. </span></p><p id="viewer-fn7ld"><span>There’s a part of Paul Graham’s </span><a href="http://www.paulgraham.com/cities.html" target="_blank" rel="noopener"><span><u>Cities and Ambition</u></span></a><span> that reads:</span></p><div id="viewer-4lk0i"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.keaganstokoe.com/post/how-to-do-great-work" data-pin-media="https://static.wixstatic.com/media/6a534b_4eacac09732c4246b4dedb7368117a59~mv2.png/v1/fit/w_1000%2Ch_566%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/6a534b_4eacac09732c4246b4dedb7368117a59~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-5dpv9"><span>I thought about this for days. If I am trying to do good work on a consistent basis and my environment isn’t suitable, I don’t stand much of a chance. I’m gritty and stubborn, but if 15th century Milanese Leonardo couldn’t do it, I don’t fancy my odds. </span></p><p id="viewer-34jca"><span>Even if I did manage to win the battle against my environment, it would require plenty of energy and determination which would be better spent on trying to improve the quality of my work. If environment is so powerful, using it as a tailwind seems a more effective strategy.</span></p><p id="viewer-7tjq4"><span>People are the critical component of any good environment, for two reasons: </span></p><ol><li id="viewer-eo2p1"><p><span><strong>Your habits and behaviour align with theirs.</strong></span></p></li><li id="viewer-4e80f"><p><span><strong>Your interests and motivation </strong></span><strong>fluctuate</strong><span><strong> with theirs.</strong></span></p></li></ol><p id="viewer-1s5qb"><span>I suspect that in pursuit of greatness, motivation and passion are two ingredients you’re likely to need. Not because you can’t produce great work in areas that you’re not passionate about -  I doubt that people in the portable toilet industry are passionate about shit, yet successful companies continue to emerge from the near </span><a href="https://www.prnewswire.com/news-releases/portable-toilet-rental-market-worth-24-70-billion-by-2025--cagr-7-30-grand-view-research-inc-300914775.html" target="_blank" rel="noopener"><span><u>$25 billion market</u></span></a><span> - but that doing great work requires time. </span></p><p id="viewer-doqc5"><span>The correct environment for you is the one where the people around you care about the things that you do. When the people around you care about the things you wish to care about, it becomes easy to do the same. </span></p><p id="viewer-9sqco"><span>In neuroscience, long-term potentiation is the persistent strengthening of synapses based on recent patterns of activity. In the context of your environment, the people you’re surrounded by determine the behaviours and beliefs that get strengthened. </span></p><p id="viewer-64dpg"><span>Put a lot of cynical people in one place and they become more cynical. Put a lot of ambitious people in one place and they become more ambitious. Put a lot of wizards in one place and they become more wizardly. <strong>If you want to learn to produce magic, surround yourself with wizards. By spending time around them, you can’t help but develop the same traits. </strong></span></p><p id="viewer-ejfpo"><span>The pursuit of greatness is an uphill battle. Being surrounded by people that motivate and inspire you reduces the friction associated with getting to the top.  </span></p><h3 id="viewer-f3m6d"><span><strong>GET OUT OF YOUR OWN WAY</strong></span></h3><p id="viewer-5devi"><a href="https://en.wikipedia.org/wiki/Joseph_Tussman" target="_blank" rel="noopener"><span><u>Joseph Tussman</u></span></a><span> has a fantastic saying: </span></p><blockquote id="viewer-897kv"><span>“What the pupil must learn, if he learns anything at all, is that the world will do most of the work for you, provided you cooperate with it by identifying how it really works and aligning with those realities. If we do not let the world teach us, it teaches us a lesson.”</span></blockquote><p id="viewer-611ii"><span>Placing yourself in the correct environment is like finding yourself in a riptide - you can’t help but get pulled along with it. <!-- -->The riptide represents a leverage point: a place where little effort produces large output. </span></p><p id="viewer-emsei"><span>Most of us understand this or at least have an intuition about it, but we struggle to identify leverage points. Developing tacit knowledge will help you navigate the sea you’re in and find the riptides heading in the direction you want to go. Your effort will </span>compound<span> to the point where it becomes near impossible to not do great work. </span></p><p id="viewer-2p84u"><span>This is an essay about how to become a wizard. It's about doing work that isn't only great in </span>its<span> own right, but work that inspires the people around you to be as good as they can be.</span></p><p id="viewer-3fdej"><span>Surrounding yourself with wizards is the first step of this </span>journe<span>y. The time you spend around them will transform you from an average person with average skills, into someone with the intuition and know-how to produce good work on a consistent basis. Great work is just good work, but repeatable. </span></p><p id="viewer-590bb"><span>You won’t get your wizard hat straight away, but each day that you spend surrounded by wizards and the magic that they produce will take you closer than you were before.</span></p><p id="viewer-6ltik"><em>Thank …</em></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keaganstokoe.com/post/how-to-do-great-work">https://www.keaganstokoe.com/post/how-to-do-great-work</a></em></p>]]>
            </description>
            <link>https://www.keaganstokoe.com/post/how-to-do-great-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914528</guid>
            <pubDate>Wed, 28 Oct 2020 02:50:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When is no-code useful?]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24914062">thread link</a>) | @thesephist
<br/>
October 27, 2020 | https://linus.coffee/note/no-code/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/no-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>To talk about what no-code is good for, we need to first take a digression on what makes no-code fundamentally different from “yes-code” software.</p>
<h2 id="the-grain-of-abstractions">The grain of abstractions</h2>
<p>Software – yes-code software – has been around for a while. One of the things we’ve learned as an industry is how to write software <em>that gracefully evolves</em>. We’re not perfect – sad, legacy systems still proliferate – but we as a technical industry have learned how to build and evolve software systems against changing requirements and constraints that span years and decades.</p>
<p>When we first solve a problem with software, we write some code against the constraints of that particular day. We don’t necessarily know how the problem is going to change. Maybe there will be different customers or stakeholders tomorrow, or maybe the product will expand to serve a related, but different, problem space. We need to be able to change software to accommodate changing circumstances without rewriting it, and that is fundamentally what <em>software engineering</em> is: how to change software systems. <em>Change</em> is the name of the game.</p>
<p>We’ve gotten decent at change. We’ve built tools like Git and patterns like continuous integration and code autoformatting to make it easier to change code and remain stable. We’ve learned how to operate large software teams, especially in open source. We’ve also learned to use better abstractions. Abstractions are conceptual wrappers that isolate different parts of a codebase – say, a data source from a user interface – so that one part may change while another doesn’t. In general we have started to figure out how to make the DNA of software systems resilient against the changing tides of time.</p>
<p>No-code seems to reject a lot of those learnings, for better or worse. I haven’t seen any no-code company or product that allows source control (and I’ve seen many no-code companies, but you’re welcome to prove me wrong.) I have yet to find no-code products that allow for natural construction of abstraction between layers of a no-code workflow. No-code software is also scarily ill-prepared for large scale development: we have software systems being worked on by tens of thousands of engineers – what does it look like for a team of 1000 engineers to be working on a set of thousands of no-code workflows? Chaos.</p>
<blockquote>
<p>Traditional software has learned the abstractions and patterns that make software resilient and adaptable to change and scale. No-code software is not ready for changing constraints nor development scale.</p>
</blockquote>
<p>Despite these limitations, I think no-code has a few niches where making tradeoffs in adaptability and scale allows no-code tools to be much, much better. So, given this, <em>when is no-code useful?</em></p>
<h2 id="1-transitionary-ephemeral-software">1. Transitionary, ephemeral software</h2>
<p>The obvious answer, and one I had before our conversation, was <em>transitionary</em> software, software with <em>a defined lifetime</em>. If your software system has a finite, pre-defined lifetime and team, it doesn’t need to worry about changing constraints or team growth. It just needs to worry about solving a problem well, now.</p>
<p>Lots of software has predictably finite lifetime: a product prototype for an early-stage company, a game or app used as a part of an interactive online ad, a quick sketch or solution to patch a particularly urgent problem in a product, an app built for an event or a conference or a recruiting cycle or a quarterly goal tracker… all of these are projects with a pre-defined, maximum lifetime. They don’t need to last or grow or change – they just need to work now, and by giving up some of the adaptability of software abstractions of code, no-code software benefits from way faster prototyping speed. This is a plus.</p>
<p>I think we see lots of finite-time software in transitions. Transitions from having no product to having a product, in a prototype. Transitions in the process of brainstorming a solution and trying multiple designs. Software with a finite shelf life is a good fit for no-code tools.</p>
<h2 id="2-high-churn-code">2. High-churn code</h2>
<p>There’s another category of software for which long-term maintainability matters little – code with high churn.</p>
<p>By high churn, I mean that requirements are changing almost daily, and very little of the code written today will exist in a month or a quarter’s time. If the code you write today doesn’t have to last and evolve, because something new is going to take its place tomorrow, what matters is the speed to build, not resilience to change.</p>
<p>There’s lots of high-churn code in businesses. Marketing websites and landing pages, data pipelines for analytics, e-commerce storefronts, marketing campaigns, payment portals – requirements for these kinds of solutions change quickly enough that code is constantly being rewritten, and if code needs to <em>be replaced</em> more than it needs to <em>last</em>, no-code tools are a great fit.</p>
<h2 id="avoiding-the-same-mistakes">Avoiding the same mistakes</h2>
<p>I think “no-code” is a misnomer. It leads us to think that no-code software is the start of a trend in which general software will involve less coding, and software engineering will become easier. This is not the case. Software engineering is not about building solutions, it’s about evolving them. But change resiliency over time is not the focus of no-code tools, and I think that’s ok.</p>
<p>I think no-code tools are instead an extension of a different trend: <a href="https://thesephist.com/posts/text/">reifying workflows</a>. Business processes and workflows used to be documented in Word docs strewn about the office or on a shared folder, or even just passed down by oral tradition in companies. Now, we have tools that allow us to build these workflows, talk about them, edit them, and share them more concretely. This is a huge boon for more repeatable business processes and for getting things done quickly! I think this is the true win of no-code tools: concretizing workflows.</p>
<p>If no-code wants to be a serious competitor against “traditional” software – though I don’t think it should try – no-code needs to learn from the mistakes of early software. No-code tools need to understand that products and software systems need to live on for decades against changing teams and requirements, and against products and companies and standards that die out and get replaced. This requires a cultural shift, a tooling shift, and a new class of abstractions in our toolbelt as no-code engineers. Anytime we try to introduce more tooling and abstraction to no-code, I think no-code gets just a little more “code” in it. And perhaps that’ll bring us right back to where we started, discovering that code is good.</p>
<p>After all, the world is complex. And when we build software against the complexity of the world, that <a href="https://thesephist.com/posts/complexity-conservation/">complexity needs to go somewhere</a>. Software is complex, but only as much as the world it attempts to make sense of.</p>
<p>It feels like we’re getting off the edge of a discovery phase of no-code, and into a time when we’re starting to understand what problems no-code tools are great for. I think it’s important that no-code tool builders focus on those strengths, or risk falling into the trap of repeating the software industry’s mistakes from the ground up.</p>

        <hr>
        <p>
            
            Next:
            <a href="https://linus.coffee/note/scannability/"><em>Scannability is king</em></a>
            
        </p>
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/no-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914062</guid>
            <pubDate>Wed, 28 Oct 2020 01:36:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ench – a minimalistic editor x3 faster than Medium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24914041">thread link</a>) | @hewmax
<br/>
October 27, 2020 | https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH | <a href="https://web.archive.org/web/*/https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ench.app/ench/the-internet-today-is-it-really-a-genius-product-of-humanity-TfHQUH</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914041</guid>
            <pubDate>Wed, 28 Oct 2020 01:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Audio Visualizations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24914012">thread link</a>) | @parisianka
<br/>
October 27, 2020 | https://www.hiteshsahu.com/AudioAnalysis | <a href="https://web.archive.org/web/*/https://www.hiteshsahu.com/AudioAnalysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div id="outer"><div></div><p>Hold on, it's loading!</p></div></div></div>]]>
            </description>
            <link>https://www.hiteshsahu.com/AudioAnalysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914012</guid>
            <pubDate>Wed, 28 Oct 2020 01:28:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OfferMarket launched today on Product Hunt, and we failed miserably]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24913859">thread link</a>) | @dwshorowitz
<br/>
October 27, 2020 | https://www.offermarket.us/blog/try-to-find-us-on-product-hunt | <a href="https://web.archive.org/web/*/https://www.offermarket.us/blog/try-to-find-us-on-product-hunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post-838853946992034243">
	
	  <p><a href="https://www.offermarket.us/blog/try-to-find-us-on-product-hunt" data-back-to-blog-link="">Back to Blog</a></p>
	
	  
	
	  <div>
	    	

<h2>OfferMarket launched today on Product Hunt, and we failed miserably.</h2>

<div><p>
We tried launching on Product Hunt today, if that's what you'll call it. We half-assed it. We put together our launch post and asked a few friends to upvote.&nbsp;<span>6 hours in and we have 3 referrals to our site from Product Hunt.</span></p><p>

One person we asked for an upvote replied "I just like sold my soul to give you an upvote", here's what they were referring to in the sign up with Twitter authentication flow:
</p></div>

<div>
<div>
<p><a><img src="https://www.offermarket.us/uploads/1/3/1/0/131040874/published/twitter-authorize-an-application-copy.jpg?1603845762" alt="Picture"></a></p>
</div>
</div>



<p>
Then we tried to have some people find us on Product Hunt, but they couldn't because their search doesn't work...<br>
</p>

<div>
<div>
<p><a><img src="https://www.offermarket.us/uploads/1/3/1/0/131040874/published/producthunt-offermarket-search-no-results.png?1603845954" alt="Picture"></a></p>
</div>
</div>



<div><p>
So that's when we realized we probably were not going to be raising much awareness on Product Hunt this time around. It also made it clear that Product Hunt either has some bugs or performance issues, or the only people whose product launches percolate to the top of the daily rankings do one or both of the following:</p><ul>
<li>know a lot of people already on Product Hunt and build a following on Product Hunt before launch</li>

<li>coerce a lot of friends, family and others for upvotes</li>
</ul><p>
Which doesn't lend much credibility to the platform as a utility for finding valuable tools.</p><p>

Moving on then. We'll try again next time. We hope you enjoyed our post-mortem and how not to launch on Product Hunt.
</p></div>




	  </div>
	
	
	  	

	
	  
	
	  
	
	  <p><a href="https://www.offermarket.us/blog/try-to-find-us-on-product-hunt">
	    <span>read more</span>
	  </a>
	</p></div></div>]]>
            </description>
            <link>https://www.offermarket.us/blog/try-to-find-us-on-product-hunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913859</guid>
            <pubDate>Wed, 28 Oct 2020 01:05:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Actions for ML in R]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913691">thread link</a>) | @ishcheklein
<br/>
October 27, 2020 | https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/ | <a href="https://web.archive.org/web/*/https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I had a few goals in my first few days of vacation:</p>
<ol type="1">
<li>Figure out GitHub Actions.</li>
<li>Try out <a href="https://tidymodels.org/"><code>tidymodels</code></a> , after being inspired by a R in Pharma talk on the <code>stacks</code> package.</li>
<li>Investigate this whole MLOps thing, and by investigate I meant <em>try it</em>, I did NOT go on vacation to read more Gartner Garbage ™️ .</li>
</ol>
<p>As luck would have it, <a href="https://twitter.com/DrElleOBrien">@DrElleOBrien</a> happened to reach out about trying <a href="https://twitter.com/DrElleOBrien">DVC</a> with R. DVC is a framework for MLOps that can use GitHub actions, so I had the perfect excuse to knock out all three goals with one sample project.</p>
<p>If you don’t want the rambling story, here is the project: <a href="https://github.com/slopp/tidydvc">https://github.com/slopp/tidydvc</a>.</p>
<h2 id="background">Background</h2>
<h3 id="dvc">DVC</h3>
<p><a href="https://dvc.org/">DVC</a>, and its close companion <a href="https://cml.dev/">CML</a>, provide tools for model management - think Git for data and models. The core idea is that a DVC pipeline tracks the input (files, data, hyper-parameters) to an experiment and the output of an experiment (model, metrics, etc). DVC can be used locally, but the real magic is that DVC can be combined with something like GitHub and GitHub actions to automate the experiment management. Just like a software engineer could create a PR to propose a change to code, a data scientist could create a PR to propose a change to a model. But, unlike in software engineering where the goal of a PR is to review and automatically test code changes, in ModelOps the goal of the PR would be to train a model and explain the outcome!</p>
<p>DVC is primarily built around Python, but I wanted to see if it could be used with R. In many ways it shares some of the principles of the <code>drake</code> (now <code>targets</code>) package, but with some added Git ✨.</p>
<h3 id="tidymodels">Tidymodels</h3>
<p><a href="https://tidymodels.org/">Tidymodels</a> is an opinionated workflow for model construction in R<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>. It is kind of like scikit learn in the sense that many different algorithms are presented with a consistent interface.</p>
<p>A few interesting bits about tidymodels:</p>
<ol type="1">
<li>There is a concept of a <code>workflow</code> that allows you to track a model’s pre-processing steps and the model itself in one easy-to-use object. This turns out to be super helpful, though a bit at odds with DVC (or drake)’s concept of a pipeline… more to come.</li>
<li>There are easy ways to <code>tune</code> hyper-parameters. Again, very helpful, but potentially at odds with external ModelOps-y things that want to control those elements.</li>
<li>There is experimental support for <a href="https://github.com/tidymodels/stacks">ensembles</a>, which is what I wanted to try!</li>
</ol>
<p><img src="https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/images/paste-5761E6A6.png" title="The Delightful stacks Logo" alt="The Delightful stacks Logo"><br>
</p>
<h3 id="mashup">Mashup</h3>
<p>Aside from learning the individual pieces, I wanted to see if it was possible to glue these different ecosystems together. As I hinted at above, however, there were some surface level concerns. It wasn’t clear to me if I could define clean boundaries between the concepts <code>tidymodels</code> wanted to control and what DVC expected to own. But the goal of PRs with beautiful <code>ggplots</code>was enticing. (Famous last words).</p>
<p>Final note, I also enjoy using R Markdown as a framework for data exploration and model creation. I find R Markdown encourages “thinking while coding”. I definitely wanted R Markdown to play a role.</p>
<p>If you are interested in this type of mashup but want to play mostly in R, I highly recommend this article by David Neuzerling: <a href="https://mdneuzerling.com/post/machine-learning-pipelines-with-tidymodels-and-targets/">Machine Learning Pipelines with Tidymodels and Targets</a>.</p>
<h2 id="unstacking-stacks">Unstacking Stacks</h2>
<div><p>I began by creating an R Markdown document that roughly followed the outline of this <a href="https://stacks.tidymodels.org/articles/basics.html">stacks tutorial</a>. To spice things up, I decided to use the Ames Housing data, so my goal was to create an ensemble that predicted housing prices. You can follow the <a href="https://github.com/slopp/tidydvc/blob/main/fit_model.Rmd">code here</a>. Because one of my goals was to try tidymodels, here are some notes for future me on what I learned.</p></div>
<h3 id="dont-skip-eda">Don’t skip EDA</h3>
<p>I didn’t want to just copy code from Max’s <a href="https://www.tidymodels.org/learn/models/parsnip-ranger-glmnet/">parsnip regression tutorial</a> so instead I opted to write my own formula regressing on different predictors<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>. I thought I could do this without any EDA. MISTAKE. I lost at least 2 hours fighting models that wouldn’t converge because my data was either incomplete or my pre-processing was non-sensical. I still am not happy with the results, but I did learn a valuable tactic. <em>When defining a recipe that will be used further down the line in a workflow, it is still a good idea (though not required) to prep and juice the recipe.</em> Essentially, this optional juicing allows you to SEE how the recipe is applied to your training dataset and troubleshoot any errors in a friendly space, as opposed to an unfriendly space (which is what I call a stack trace from the middle of a cross validation optimization routine that has failed because of a <code>NA</code>).</p>
<div data-layout="l-body">
<pre><code>
# First define the recipe
housing_rec &lt;- recipe(SalePrice ~ ...) %&gt;% 
  update_role(PID, new_role = "ID") %&gt;% 
  step_dummy(all_nominal()) %&gt;%  
  step_meanimpute(all_numeric()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_nzv(all_predictors())

# Check it!
housing_rec %&gt;% 
  prep() %&gt;% 
  juice()

# Then do the rest of your workflow magic
housing_wflow &lt;- 
  workflow() %&gt;% 
  add_recipe(housing_rec)</code></pre>
</div>
<p><em>Tune</em></p>
<p>Tuning is easy. Getting the model out of the tune to actually use… a little less intuitive. As with all things, I should have started by reading <a href="https://juliasilge.com/blog/sf-trees-random-tuning/">Julia Silge’s advice</a>. Essentially there are a couple things you (future me) need to know:</p>
<ol type="1">
<li>You create a model spec and stick it in a workflow:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# PS - for those who learned penalized regression through glmnet
# penalty = lambda 
# mixture = alpha
model_spec &lt;- linear_reg(penalty = tune("penalty"), mixture = tune("mixture"))

# the workflow ties your model to your pre-processing
model_wflow &lt;- 
  workflow() %&gt;% 
  add_recipe(preprocess_data) %&gt;% 
  add_model(model_spec)</code></pre>
</div>
<ol start="2" type="1">
<li>You can tune the model<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> using a grid:</li>
</ol>
<div data-layout="l-body">
<pre><code>
tune_results &lt;- 
  tune_grid(
    model_wflow,
    resamples = folds,  
    metrics = metric,  # think rmse
    control = control_grid() # controls what metadata is saved 
  )</code></pre>
</div>
<ol start="3" type="1">
<li>You can look at the tuned results:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# hint use the n function argument to see more. This is where you can find the actual tune parameters
show_best(tune_results)</code></pre>
</div>
<ol start="4" type="1">
<li>BUT, at this point, <em>you have to finalize the actual best model</em>. Or in the case of an ensemble, you have to finalize <em>many</em> models. Finalize means take the tuned parameters and fit the model on ALL the training data. (The parameters come from a model fit on a cross validation fold). To do this:</li>
</ol>
<div data-layout="l-body">
<pre><code>
# select_best was counterintuitive to me... I found it hard to pull the data
# for all models; and it doesn't give you the best model, just the best
# tune parameters 
tuned_params &lt;- select_best(tune_results)

# use this object for future predictions
model_wflow_fit &lt;- finalize_workflow(model_wflow, tuned_params)

# final tip: to inspect the actual model 
model_wflow_fit %&gt;% 
  pull_workflow_fit() %&gt;% 
  broom::tidy() # linear models OR
  vip::vip() # trees</code></pre>
</div>
<p>At different points of this process it can be easy to forget what is trained and what is still a placeholder. The print methods are really good, use them.</p>
<h3 id="stacks">Stacks</h3>
<p>My final goal was to fit an ensemble model. Unfortunately, I hit an error using the <code>stacks</code> package. I suspect this error was due to the fact that the package is experimental and I had some stale dependencies. This left me between a rock and, well, another rock. I could have tried to nuke my environment and fight with <code>remotes</code> to install a bunch of development tidymodels packages. (This was made harder by the WIP change to <code>main</code> from <code>master</code> 👏). Or I could try to push forward by working around the error with my own ensemble code. I went for the latter path, and refreshed a lot of my statistical thinking along the way. (Recall <code>%*%</code> is how to do matrix multiplication in R). But I also killed 5 hours of vacation. 🤷 I will spare you and my future self the details in the hope that the error is fixed, but a few conceptual tips:</p>
<ol type="1">
<li>The <code>stacks()</code> object starts with candidate models (from <code>tune_grid</code>) or a single model but with multiple fits (from <code>fit_resamples</code>). The magic this function does is align the different models based on the resample they used. In other words, if one candidate was fit on resample 1, it is matched with another candidate fit on resample 1. The same matching occurs within tuning configurations from a single model.<br>
</li>
<li>Under the hood, the ensemble is fit with glmnet, but buried in quite a few layers of tidymodels abstraction. <code>cv.glmnet</code> works as an alternative, but with a nasty side affect. You have to do all the work manually to get a final fitted object that glues all the prior models, workflows, and the ensemble together.<br>
</li>
<li>When those nice print methods I mentioned earlier fail, try <code>attributes</code> to see “all the stuff” tidymodels is carrying around.</li>
</ol>
<h2 id="the-mashup">The Mashup</h2>
<h3 id="adding-dvc">Adding DVC</h3>
<p><br>
Once I had a functional R Markdown document that was fitting models, it was time to try this ModelOps thing. Now ModelOps can consist of a lot of things, but in this case I was interested in trying out the training side of model operations - tracking experiments and enabling collaboration. I’ll save the monitoring side - deploying models to production and watching them overtime - for another vacation.</p>
<div><p>DVC is oriented around pipelines. Unfortunately, this appeared to clash a bit with my R Markdown workflow. For one, the R Markdown document “drove” all the modeling code, and this code was not amenable to being managed by an external pipeline. Another problem was that the tidymodels packages, especially <code>tune</code> and <code>stacks,</code> handled the parameters and “experiments” that DVC wanted to control.</p><p>

I decided to mostly ignore the first challenge. If my data was large, or the pre-processing intense, I think I would have benefited from breaking the R Markdown document into child documents that could each be a stage in a pipeline. In this case, I didn’t care for the extra overhead in saving intermediate results, and things were fast enough that I didn’t mind re-running steps from scratch. As I mentioned, I am advocate for using R Markdown instead of .R files even in the multi-stage approach. You an see an example of this <a href="https://github.com/sol-eng/bike_predict">“split it up” approach here</a>.</p></div>
<p>For the second problem, I decided to go with a hyper-hyper-parameter strategy. Essentially, I allowed <code>tune</code> and tidymodels to handle the hyper-parameter optimization within a model, but I used DVC to handle “parameters” that would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/">https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/</a></em></p>]]>
            </description>
            <link>https://loppsided.blog/posts/2020-10-26-tidymodels-dvc-mashup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913691</guid>
            <pubDate>Wed, 28 Oct 2020 00:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Saturn Homebrew with Game Basic]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913598">thread link</a>) | @lostgame
<br/>
October 27, 2020 | https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/ | <a href="https://web.archive.org/web/*/https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6">
		<!-- .entry-header -->

	
	<div>
		
	
<figure><img data-attachment-id="123" data-permalink="https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/game-basic-for-sega-saturn-2/" data-orig-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn.jpg" data-orig-size="2560,1920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1602104707&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Game BASIC for Sega Saturn" data-image-description="" data-medium-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg" data-large-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" loading="lazy" width="1024" height="768" src="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" alt="Sega Saturn for Game BASIC - Complete in Box" srcset="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg 1024w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg 300w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-768x576.jpg 768w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1536x1152.jpg 1536w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-2048x1536.jpg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Game BASIC for Sega Saturn – Complete in Box</figcaption></figure>



<h2>Part 1: Introduction</h2>



<h3>Summary</h3>



<p>Game BASIC for Sega Saturn is a homebrew development kit that allows you to program games for the Sega Saturn using the BASIC programming language.&nbsp; If you’re familiar with the PlayStation’s Net Yaroze platform, think of this as the Saturn’s answer to it – just cheaper and easier to get started with.</p>



<p>Game BASIC’s use of the BASIC language makes for a very low barrier to entry in terms of programming skill.&nbsp; Though the Saturn is notoriously difficult to program for, Game BASIC makes it easy to get started and is surprisingly powerful, allowing very easy sprite manipulation and straightforward 3D polygon implementation.&nbsp; It even includes an adapter cable that allows you to communicate with the Saturn from your PC to transfer or save programs and streamline development.  For example, here’s a Pilotwings-esque demo, but in Game BASIC:</p>



<figure><p>
<iframe title="Game Basic for Sega Saturn - GBSS CD - Jump Multi Controller" width="525" height="394" src="https://www.youtube.com/embed/jMPksluhvlE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>“Jump” demo, provided with Game BASIC (video courtesy <a href="https://www.satakore.com/sega-saturn-game-basic,,GBSSCD_G_JUMP_A,,GBSS-CD-Jump-Multi-Controller-Version-Bits-Laboratory.html" target="_blank" rel="noreferrer noopener">Satakore.com</a>)</figcaption></figure>



<p>The caveat?&nbsp; Game BASIC was released only in Japan, so this means a complete setup can be difficult to obtain and all documentation is in Japanese!&nbsp; Moreover, the supporting software that allows you to use your PC for streamlined development was intended for the Windows 95 era and flat out does not install on modern systems. Oh, and the adapter cable that allows you to connect your Saturn to your PC is a 25-pin serial connection!</p>



<p>Who in the world still has both Game BASIC and a Windows 95 PC with a physical serial port? Nobody!&nbsp; (Well, unless you’re <a href="https://www.youtube.com/watch?v=O_QU8eaMymo" target="_blank" rel="noreferrer noopener">Modern Vintage Gamer</a>) But if you’re a brave experimenter who’s not afraid to tinker a bit, there are still multiple options to get everything working, even today!&nbsp; You can even do a lot just via emulation.&nbsp; So, let’s head to the Lab and get started…</p>



<h3>What You’ll Need</h3>



<p>There are several options for working with Game BASIC, ranging from quite simple but clunky to work with, to quite powerful and streamlined.&nbsp; Here are the three options:</p>



<h4>The Simple Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>A copy of the <a href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank" rel="noreferrer noopener">Game BASIC for Sega Saturn disc</a></li><li>The ability to play Japanese Saturn games (A Japanese or modded console, a Pro Action Replay/<a href="https://ppcenter.webou.net/pskai/" target="_blank" rel="noreferrer noopener">Pseudo Saturn Kai</a> cartridge, or a Saturn emulator)</li><li>Any Saturn controller</li><li>Plenty of room in the Saturn’s internal memory (if you want to save your programs)</li></ul>



<p>For this option, you’ll run Game BASIC on the Saturn with no PC connection, using only standard Saturn accessories.&nbsp; This is a reasonable choice if you just want to write “Hello, World!”-style programs or play around with the neat games and demos that come with the kit.&nbsp; Theoretically, you can write even the most complex programs this way, but you’ll run into limitations on the size of games you can save to the Saturn’s internal memory.&nbsp; Plus, programming with a virtual keyboard is an absolute pain.&nbsp; Start here if you don’t have the necessary hardware for the other options, or if you just want to poke around a bit and see what this is all about.</p>



<h4>The Enhanced Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>All of the tools from Option 1, PLUS</li><li>Some kind of external expanded memory, such as:<ul><li>A direct-save memory cartridge (e.g., the official Saturn Backup Memory)</li></ul><ul><li>A Sega Saturn Floppy Disk Drive and some 3.5″ floppy disks</li></ul></li><li>A Sega Saturn keyboard OR the NetLink keyboard adapter with a PS/2 keyboard</li><li>Fun peripherals, like the Stunner light gun, 3D Control Pad, multi-tap, and Shuttle Mouse</li></ul>



<p>One of the great things about Game BASIC is how easy it makes it to access the Saturn’s peripherals, including the internal backup RAM, external memory cartridges, and even the Saturn Floppy Disk Drive.&nbsp; With a setup like this, you’ll have plenty of space to save your programs and you can use a real keyboard for text entry.&nbsp; You can even start experimenting with different forms of input, like analog controls and light guns!&nbsp; But without access to the tools a PC provides, it will be difficult to make nice-looking sprites, textures, and 3D models.&nbsp; So, this will still limit what you’re capable of.&nbsp; Regardless, this is a great option for the sheer fun factor of “Hey look! I’m programming with my Saturn!” or if you have no ability to connect your Saturn to a PC.</p>



<p>You can even go this route with a Saturn emulator, giving you easy access to improved keyboard, mouse, and storage options.&nbsp; I’ve confirmed that Mednafen successfully emulates Game BASIC and allows for keyboard and mouse pass-through input, meaning you can do a whole lot of Saturn development with very little barrier to entry.</p>



<h4>The Full Saturn plus PC Setup</h4>



<h5>Required Tools</h5>



<ul><li>A complete Game BASIC for Sega Saturn kit, including:<ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Game BASIC for Sega Saturn disc</a></li></ul><ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Windows 95 Tools disc</a></li></ul><ul><li>The special Saturn-to-PC serial cable adapter</li></ul></li><li>A modern PC with a USB port, capable of running a Virtual Machine (I use VirtualBox)</li><li>A copy of Windows XP SP3 32-bit to install on a VM</li><li>A <a href="https://www.amazon.com/USB-Serial-Adapter-Prolific-PL-2303/dp/B003WOWBBW" target="_blank" rel="noreferrer noopener">USB-to-Serial adapter</a> (Must support RS232 with a DB25 connector)</li><li>The ability to play Japanese Saturn games on original hardware (Japanese or modded console, or a Pro Action Replay/Pseudo Saturn Kai cartridge)</li><li>A Saturn controller</li><li>Optionally, any fun Saturn accessories you may want to experiment with (I especially recommend a keyboard or keyboard adapter)</li></ul>



<p>This is the Cadillac option!&nbsp; This is the setup I use, is how Game BASIC was really intended to be used (well, except nobody expected it to be run on a VM, I suppose), and is what the rest of this guide will focus on.&nbsp; With this setup, writing a game is as simple as writing BASIC in a text editor and hitting a couple of buttons to send it to your Saturn, where it immediately shows up on your TV and responds to controller and keyboard input!&nbsp; Seriously, it’s super cool once you get it working…</p>



<p>The Simple and Enhanced Saturn-only setups are extremely straightforward.&nbsp; You just boot Game BASIC like any other Saturn game and get started, so there’s not much configuration to discuss.&nbsp; Regardless of the setup you choose, continue on to Part 2 for a few test programs.&nbsp; But if you want the Full setup, it’s quite a project to get going, so read on to Part 3 for the complete How-To!</p>


<nav role="navigation"><!-- .nav-links --></nav><!-- .mpp-post-navigation -->	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913598</guid>
            <pubDate>Wed, 28 Oct 2020 00:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Shoot Yourself in the Foot with Python. Part 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913355">thread link</a>) | @rbanffy
<br/>
October 27, 2020 | https://miguendes.me/how-to-shoot-yourself-in-the-foot-with-python-part-1 | <a href="https://web.archive.org/web/*/https://miguendes.me/how-to-shoot-yourself-in-the-foot-with-python-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Have you ever had a bug that took ages to fix and made no sense at all? </p>
<p>If the answer is yes, then keep reading. Chances are that if you program in Python, you will probably fall into one of these silly behaviors.</p>
<p>In the part 1 of this series I’m going to show you 5 things that have a great potential drive you mad in Python. Some of them are very subtle and others are not obvious at all. By learning about them in advanced, you can save hours of debugging time. So brace yourself and let’s go!</p>
<p><img src="https://media.giphy.com/media/UkaZpqcieR38c/giphy.gif" alt=""></p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#implicit-string-concatenation">Implicit String Concatenation</a></li>
<li><a href="#walrus-wat">Walrus WAT!?</a></li>
<li><a href="#be-careful-when-using-with-lists">Be Careful When Using += With Lists</a></li>
<li><a href="#mutable-defaults">Mutable Defaults</a></li>
<li><a href="#chained-operations-gone-wrong">Chained Operations Gone Wrong</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="implicit-string-concatenation">Implicit String Concatenation</h2>
<p><img src="https://media.giphy.com/media/L7Nnb9j5NU48g/giphy.gif" alt="A dog falling into a pit"></p>
<p>I confess that this one has costed me several hours of my life. When used correctly it is very nice but when you don’t, it’s a headache.</p>
<p>In Python you can concatenate strings using not only using the <code>+</code> operator but also implicitly. The following snippet illustrates a very common bug in Python.</p>
<pre><code>In [<span>2</span>]: <span>"french "</span> + <span>"bulldog"</span>
Out[<span>2</span>]: <span>'french bulldog'</span>
</code></pre>
<p>That's fine, <code>&lt;string&gt; + &lt;string&gt;</code> generates a new <code>&lt;string&gt;</code>. But what you may not know is that you can leave <code>+</code> out and Python will still concatenate the string.</p>
<pre><code>In [<span>3</span>]: <span>"french "</span> <span>"bulldog"</span>
Out[<span>3</span>]: <span>'french bulldog'</span>
</code></pre>
<p>When is this a problem, then? It'll be an issue when you want a list of strings and forget a comma.</p>
<pre><code>In [<span>4</span>]: dogs = [<span>"poodle"</span> <span>"french bulldog"</span>, <span>"pit bull"</span>, <span>"american bully"</span>]
In [<span>6</span>]: dogs
Out[<span>6</span>]: [<span>'poodlefrench bulldog'</span>, <span>'pit bull'</span>, <span>'american bully'</span>]
</code></pre>
<p>Oh, it can get worse. Imagine you have a function that accepts two strings, but the second one is optional.</p>
<pre><code>In [<span>11</span>]: <span><span>def</span> <span>print_pair</span>(<span>a: str, b: Optional[str] = None</span>):</span>
    ...:     print(<span>"a: "</span>, a, <span>"b: "</span>, b)
In [<span>13</span>]: print_pair(
    ...: <span>"First string"</span>
    ...: <span>"Second string"</span>
    ...: )
a:  First stringSecond string b:  <span>None</span>
</code></pre>
<p>You see? The function runs just fine, so that’s not great! Situations like these can hide nasty bugs. The lesson here is clear: be careful when passing strings to functions or using them as list of items.</p>
<h2 id="walrus-wat">Walrus WAT!?</h2>
<p><img src="https://media.giphy.com/media/cv4aHA3NS4YxO/giphy.gif" alt="A dog playing goes #fail"></p>
<p>In 2019, Python 3.8 introduced the walrus operator. This new feature generated a lot of controversies. Some people loved whereas other actually hated it. The goal of this post is not to debate that, so I’ll dive right into what makes walrus confusing.</p>
<p>Before Python 3.8, you could not assign a value to a variable and test if it was “truthy” in the same statement.  For example, see the following example, of reading data from a socket until an empty string is read. This examples is inspired by  <a target="_blank" href="https://www.python.org/dev/peps/pep-0572/#capturing-condition-values">one</a>  described in the PEP.</p>
<p>Without <code>walrus</code>:</p>
<pre><code>data = sock.recv(<span>4096</span>)
<span>while</span> data:
    clean_data = clean(data)
    print(<span>"Received data:"</span>, data)
    data = sock.recv(<span>4096</span>)
</code></pre>
<p>With <code>walrus</code>:</p>
<pre><code><span>while</span> data := sock.recv(<span>4096</span>):
    clean_data = clean(data)
    print(<span>"Received data:"</span>, data)
</code></pre>
<p>That is, you do both the assignment and the checking in the same line by using <code>:=</code>.</p>
<p>In Python we can use tuples to assign values to more than one variable in the same line.</p>
<pre><code>In [<span>1</span>]: a, b = <span>2</span>, <span>3</span>

In [<span>2</span>]: a
Out[<span>2</span>]: <span>2</span>

In [<span>3</span>]: b
Out[<span>3</span>]: <span>3</span>
</code></pre>
<blockquote>
<p>Hum... we probably can do the same using walrus, right?</p>
</blockquote>
<pre><code>In [<span>4</span>]: (a, b := <span>16</span>, <span>19</span>)
Out[<span>4</span>]: (<span>2</span>, <span>16</span>, <span>19</span>)
</code></pre>
<blockquote>
<p>WAT!</p>
</blockquote>
<p>Yeah, a 3-tuple is returned!</p>
<p> ̶T̶h̶e̶ ̶r̶e̶a̶s̶o̶n̶ ̶f̶o̶r̶ ̶t̶h̶a̶t̶ ̶i̶s̶ ̶t̶h̶a̶t̶ ̶t̶h̶e̶ ̶<code>̶b̶</code>̶ ̶t̶a̶k̶e̶s̶ ̶p̶r̶e̶c̶e̶d̶e̶n̶c̶e̶ ̶a̶n̶d̶ ̶g̶e̶t̶s̶ ̶a̶s̶s̶i̶g̶n̶e̶d̶ ̶t̶o̶ ̶i̶t̶ ̶t̶h̶e̶ ̶t̶u̶p̶l̶e̶ ̶<code>̶1̶6̶,̶ ̶1̶9̶</code>̶.̶ ̶I̶n̶ ̶o̶t̶h̶e̶r̶ ̶w̶o̶r̶d̶s̶,̶ ̶i̶t̶’̶s̶ ̶t̶h̶e̶ ̶s̶a̶m̶e̶ ̶a̶s̶ ̶<code>̶(̶a̶,̶ ̶(̶b̶ ̶:̶=̶ ̶1̶6̶,̶ ̶1̶9̶)̶)̶</code>̶.̶ ̶A̶n̶d̶ ̶s̶i̶n̶c̶e̶ ̶<code>̶a̶</code>̶ ̶h̶a̶d̶ ̶a̶l̶r̶e̶a̶d̶y̶ ̶b̶e̶e̶n̶ ̶b̶o̶u̶n̶d̶ ̶t̶o̶ ̶<code>̶2̶</code>̶,̶ ̶s̶o̶ ̶t̶h̶e̶ ̶r̶e̶t̶u̶r̶n̶ ̶i̶s̶ ̶t̶h̶e̶ ̶t̶u̶p̶l̶e̶ ̶<code>̶(̶a̶,̶ ̶b̶ ̶:̶=̶ ̶1̶6̶,̶ ̶1̶9̶)̶ ̶=̶&gt;̶ ̶(̶2̶,̶ ̶(̶1̶6̶,̶ ̶1̶9̶)̶)̶</code>̶.̶</p>
<p>Thanks to  <a target="_blank" href="https://www.reddit.com/user/ForceBru/">@ForceBru</a> who kindly  <a target="_blank" href="https://www.reddit.com/r/Python/comments/jh66bh/how_to_shoot_yourself_in_the_foot_with_python/g9wfoi9/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">corrected me</a>, what gets assigned to <code>b</code> is not a tuple, but only the first element after <code>:=</code>.
As a result, <code>(a, b := 16, 19)</code> is the same as <code>(a, (b := 16), 19)</code>. And that explains why a 3-tuple is returned.</p>
<p>You can verify that by <a target="_blank" href="https://tio.run/##K6gsycjPM7YoKPr/PzO3IL@oRCGxuISLq6AoM69EA8jUSynNLQAzChKLilM1lDQSdRSSrGwVDM10FAwtNZU0NTX//wcA">printing the AST</a> .</p>
<pre><code><span>import</span> ast

print(ast.dump(ast.parse(<span>"(a, b:= 16, 19)"</span>)))
</code></pre>
<p>Which produces the following output:</p>
<pre><code>Module(
    body=[
        Expr(
            value=Tuple(
                elts=[
                    Name(id=<span>"a"</span>, ctx=Load()),
                    NamedExpr(
                        target=Name(id=<span>"b"</span>, ctx=Store()),
                        value=Constant(value=<span>16</span>, kind=<span>None</span>),
                    ),
                    Constant(value=<span>19</span>, kind=<span>None</span>),
                ],
                ctx=Load(),
            )
        )
    ],
    type_ignores=[],
)
</code></pre>
<p>As you can see, the thing is confusing!</p>
<blockquote>
<p>What if <code>a</code> is not defined?</p>
</blockquote>
<pre><code>In [<span>14</span>]: (a, b := <span>16</span>, <span>19</span>)
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input<span>-14</span>-bd6265d8ca84&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> (a, b := <span>16</span>, <span>19</span>)

NameError: name <span>'a'</span> <span>is</span> <span>not</span> defined
</code></pre>
<p>When the first variable is not defined, a <code>NameError</code> will be raised. Now you know how to avoid that!</p>
<h2 id="be-careful-when-using-with-lists">Be Careful When Using <code>+=</code> With Lists</h2>
<p><img src="https://media.giphy.com/media/GEObzG7vNeRUs/giphy.gif" alt="A dog falling down the stairs"></p>
<p>Lists in Python are incredibly nice. You can perform all sorts of stuff like:</p>
<ul>
<li>concatenating multiple lists using <code>+</code> operator</li>
<li>generating a repeated list by using the <code>*</code> operator</li>
<li>concatenate and assign lists using <code>+=</code></li>
</ul>
<p>Let’s look at an example on how <code>+</code> operator works with the <code>list</code> object. I know you may be tired of such toy examples, but please, bear with me.</p>
<pre><code>In [<span>20</span>]: lst = [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>]

In [<span>21</span>]: lst_copy = lst

In [<span>22</span>]: lst = lst + [<span>8</span>, <span>9</span>]

In [<span>23</span>]: lst
Out[<span>23</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]

In [<span>24</span>]: lst_copy
Out[<span>24</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>]
</code></pre>
<p>Cool, we created a list called <code>lst</code> then we built a new one named <code>lst_copy</code> by pointing it to <code>lst</code>. Then we changed <code>lst</code> by appending <code>[8, 9]</code> to it. As expected, the <code>+</code> operator expanded <code>lst</code> whereas <code>lst_copy</code> remained the same.</p>
<p>In Python one can shorten expressions like <code>a = a + 1</code> as <code>a += 1</code>. As I mentioned in the beginning, you can also use the <code>+=</code> operator with lists. So, let’s give it a shot and re-write our example.</p>
<pre><code>In [<span>25</span>]: lst = [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>]

In [<span>26</span>]: lst_copy = lst

In [<span>27</span>]: lst += [<span>8</span>, <span>9</span>]

In [<span>28</span>]: lst
Out[<span>28</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]

In [<span>29</span>]: lst_copy
Out[<span>29</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<blockquote>
<p>WAAATTT!? What happened here?</p>
</blockquote>
<p>The reason for this behavior is that, like other Python operators, the implementation of <code>+=</code> is defined by the class that implements it. That is, to define <code>+=</code> the <code>list</code> class has defined a <code>object.__iadd__(self, other)</code> magic method. And the way it works is the same as <code>list.extends</code>. </p>
<p>So why has <code>lst_copy</code> been modified? </p>
<p>Because it is not an actual copy of <code>lst</code> but it points to the in memory.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603005116647/dEuGgiAqj.png?auto=format&amp;q=60" alt="Screenshot_2020-10-18_08-11-01.png"></p>
<pre><code>In [<span>28</span>]: lst
Out[<span>28</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]

In [<span>29</span>]: lst_copy
Out[<span>29</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]

In [<span>30</span>]: lst = [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>]

In [<span>31</span>]: lst_copy = lst

In [<span>32</span>]: lst.extend([<span>8</span>, <span>9</span>])

In [<span>33</span>]: lst
Out[<span>33</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]

In [<span>34</span>]: lst_copy
Out[<span>34</span>]: [<span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>The key takeaway is, don't blindly assume operators will have the same semantics across different classes. </p>
<h2 id="mutable-defaults">Mutable Defaults</h2>
<p><img src="https://media.giphy.com/media/13cbZDgXa23UeQ/giphy.gif" alt="A dog jumping sofas #fail"></p>
<p>I understand that this one might not be new to you. However, it’s unquestionably one of the most dangerous. The case I’m talking about is the usage of mutable default arguments on functions. If you don’t know what this is all about, take a look at the following example.</p>
<pre><code>In [<span>35</span>]: <span><span>def</span> <span>add_fruit</span>(<span>fruit: str, basket: list = []</span>) -&gt; list:</span>
    ...:     basket.append(fruit)
    ...:     <span>return</span> basket
    ...: 

In [<span>36</span>]: b = add_fruit(<span>"banana"</span>)

In [<span>37</span>]: b
Out[<span>37</span>]: [<span>'banana'</span>]

In [<span>38</span>]: c = add_fruit(<span>"apple"</span>)

In [<span>39</span>]: c
Out[<span>39</span>]: [<span>'banana'</span>, <span>'apple'</span>]
</code></pre>
<blockquote>
<p>WAAATT!?</p>
</blockquote>
<p>As you can see, we call the function twice without passing a list to it. The ultimate result is a list with two items, how did that happen?</p>
<p>The reason for this behavior is that when the interpreter defines the function, it also creates the default argument. Then, it binds the object created to the function argument. </p>
<p>In our problem, Python allocated an empty list and bound it to the argument <code>basket</code>. To make things simpler to follow, let’s look at a visual example made with <a target="_blank" href="http://www.pythontutor.com/">python tutor</a>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603048050068/v39uSktN5.png?auto=format&amp;q=60" alt="mutable-1.png"></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603048076920/D_qYippaU.png?auto=format&amp;q=60" alt="mutable-2.png"></p>
<p>As you can see, the argument <code>basket</code> is created once and the function points to it during its entire lifetime. The only exception is when you pass another list to it but that won’t change the default. Whenever you call the function again without passing a list to it, it will use the one created when the function was defined.</p>
<blockquote>
<p>How can we avoid this, then?</p>
</blockquote>
<p>To avoid this, you must set the argument to <code>None</code> and create a list if none is passed.</p>
<pre><code>In [<span>44</span>]: <span><span>def</span> <span>add_fruit</span>(<span>fruit: str, basket: Optional[list] = None</span>):</span>
    ...:     <span>if</span> basket <span>is</span> <span>None</span>:
    ...:         basket = []
    ...:     basket.append(fruit)
    ...:     <span>return</span> basket

In [<span>45</span>]: b = add_fruit(<span>"banana"</span>)

In [<span>46</span>]: b
Out[<span>46</span>]: [<span>'banana'</span>]

In [<span>47</span>]: c = add_fruit(<span>"apple"</span>)

In [<span>48</span>]: c
Out[<span>48</span>]: [<span>'apple'</span>]
</code></pre>
<p>Great! Now we create a list whenever no argument is passed to the function, which fixes the bug.</p>
<h2 id="chained-operations-gone-wrong">Chained Operations Gone Wrong</h2>
<p><img src="https://media.giphy.com/media/3oEduU8I0dHP38CdLW/giphy.gif" alt="A dog playing on grass and failing"></p>
<p>Chained operations are an exceptional feature. It makes the code terse without sacrificing readability. I discuss it in more detail in another blog <a target="_blank" href="https://miguendes.me/5-hidden-python-features-you-probably-never-heard-of">post</a> but to provide you a bit of context let’s see it in action.</p>
<pre><code><span>&gt;&gt;&gt; </span>x = <span>10</span>
<span>&gt;&gt;&gt; </span><span>20</span> == x == <span>0</span>
<span>False</span>
<span>&gt;&gt;&gt; </span><span>25</span> &gt; x &lt;= <span>15</span>
<span>True</span>
</code></pre>
<p>Let's pay close attention to the first example. If Python didn't have this feature, that statement could be re-written as:</p>
<pre><code>In [<span>53</span>]: <span>20</span> == x <span>and</span> x == <span>0</span>
Out[<span>53</span>]: <span>False</span>
</code></pre>
<p>Now, what happens if we add parentheses to enforce some kind of precedence?</p>
<pre><code>In [<span>51</span>]: <span>20</span> == x == <span>0</span>
Out[<span>51</span>]: <span>False</span>

In [<span>52</span>]: (<span>20</span> == x) == <span>0</span>
Out[<span>52</span>]: <span>True</span>
</code></pre>
<blockquote>
<p>Wait? What on earth has just happened?</p>
</blockquote>
<p>When we added the parentheses, <code>(20 == x)</code> was evaluated to <code>False</code>. However, the problem is that <code>False</code> is then compared to <code>0</code>.  ̶S̶i̶n̶c̶e̶ ̶<code>̶0̶</code>̶ ̶i̶s̶ ̶c̶o̶n̶s̶i̶d̶e̶r̶e̶d̶ ̶a̶ ̶"̶F̶a̶l̶s̶y̶"̶ ̶v̶a̶l̶u̶e̶,̶ ̶t̶h̶e̶n̶ ̶t̶h̶e̶ ̶c̶o̶m̶p̶a̶r̶i̶s̶o̶n̶ ̶r̶e̶t̶u̶r̶n̶s̶ ̶'̶T̶r̶u̶e̶`̶.̶</p>
<p>As pointed out by <a href="https://hashnode.com/@alexmojaki" target="_blank" rel="noopener noreferrer">@alexmojaki</a>, <code>False == 0</code> is <code>True</code> because <code>bool</code> is a subclass of <code>int</code>. For instance, other "Falsy" values such as <code>[]</code> or <code>""</code> are not equal to <code>False</code>.</p>
<pre><code>In [<span>54</span>]: <span>False</span> …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/how-to-shoot-yourself-in-the-foot-with-python-part-1">https://miguendes.me/how-to-shoot-yourself-in-the-foot-with-python-part-1</a></em></p>]]>
            </description>
            <link>https://miguendes.me/how-to-shoot-yourself-in-the-foot-with-python-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913355</guid>
            <pubDate>Tue, 27 Oct 2020 23:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where to Start with AWS as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913319">thread link</a>) | @samjulien
<br/>
October 27, 2020 | https://www.samjulien.com/where-to-start-with-aws-as-a-developer | <a href="https://web.archive.org/web/*/https://www.samjulien.com/where-to-start-with-aws-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>AWS (Amazon Web Services) is <strong>massive</strong>. At the time I'm writing this, there are 175 different services on AWS! This surface area is bigger than most things you might try to learn as a developer. So where do you get started? How do you start chipping away at this complex elephant, but do it in a way that's practical?</p><p>I'm a few months in to my AWS journey and I wanted to share what concepts and resources I've found helpful so far. I resisted getting into AWS for a while because of its complexity. Any time I would log into AWS, my eyes would glaze over and my head would spin.</p><p>I realized, though, that ignoring AWS for much longer will be to my detriment. <a href="https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/">AWS is dominating</a> the hundred billion dollar cloud infrastructure and computing market:</p><p><span>
      <span></span>
  <img alt="AWS Public Cloud Share graph by Statista" title="AWS Public Cloud Share graph by Statista" src="https://www.samjulien.com/static/e8c62fe995e7cef80f609d9a70ac50a0/af659/aws-cloud-share.jpg" srcset="https://www.samjulien.com/static/e8c62fe995e7cef80f609d9a70ac50a0/8356d/aws-cloud-share.jpg 259w,https://www.samjulien.com/static/e8c62fe995e7cef80f609d9a70ac50a0/bc760/aws-cloud-share.jpg 518w,https://www.samjulien.com/static/e8c62fe995e7cef80f609d9a70ac50a0/af659/aws-cloud-share.jpg 1035w,https://www.samjulien.com/static/e8c62fe995e7cef80f609d9a70ac50a0/e5166/aws-cloud-share.jpg 1200w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy">
    </span>
<a href="https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/">Source</a></p><p>Because of this, AWS certifications are in very high demand. I decided a few months ago that it's time for me to step up and at least get the <a href="https://aws.amazon.com/certification/certified-cloud-practitioner/">Cloud Practitioner certification</a>, and probably others like the <a href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">Solutions Architect Associate</a>.</p><h2>Big AWS Concepts for Developers</h2><p>Let's lay down a couple of definitions to help you as you progress in your AWS education.</p><p>First, what are <strong>cloud computing</strong> and <strong>cloud infrastructure</strong>? In short, this means that instead of you having to physically set up servers and networks in your garage or at your company, you "rent" these from Amazon. Everything you might want to do to run a website <!-- -->—<!-- --> the hardware that runs the server, the database, the storage that holds the frontend and static files, and the domain name configuration <!-- -->—<!-- --> can be done using AWS's networking and computing resources.</p><p>Why does this matter? The main reason is <strong>scalability</strong>: the ability to grow based on demand. AWS alleviates both the cost and logistics of scaling a service or business. Imagine you're running an online store for dog toys on a single server in your garage (you probably bought it on eBay). Suddenly, <a href="https://twitter.com/dog_feelings">Thoughts of Dog</a> tweets about your store and your traffic spikes by twenty times as millions of people try to buy your bespoke artisan chew toys. What's going to happen? Most likely your server will crash due to that much demand. You're frantically searching eBay for another server and some networking equipment, but it will likely cost you a couple thousand bucks and several days to upgrade your server or add additional servers to your network. Ouch! (Incidentally, a show that demonstrates this dilemma perfectly is <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a>, which is about startups in the 80s.)</p><p>Services like AWS, Azure, and Google Cloud Platform came along and revolutionized the industry. Now instead of needing to buy a brand new server, you can click a button and immediately grow your infrastructure. Even better, you can automatically grow and shrink your infrastructure as demand for your site or service fluctuates. This helps keeps costs more predictable and spreads them out over time instead of all at once with big hardware purchases.</p><h2>Key AWS Services for Developers</h2><p>When approaching AWS as a developer, there are a few of the core services that you'll likely encounter right away, so here's a quick overview of those:</p><ul><li><strong>Lambda</strong>: Serverless functions are kind of a gateway for developers into AWS and cloud infrastructure. In AWS, Lambda is the service that runs these functions. Serverless functions let you perform calculations or access databases without having a physical server.</li><li><strong>S3</strong>: S3 stands for Simple Storage Service. This is where you host static files such as HTML, images, or videos.</li><li><strong>Route 53</strong>: Route 53 is where you set up DNS for domain names. "Route" is a reference to US Route 66 and "53" is a reference to TCP or UDP port 53, where DNS server requests are addressed.</li><li><strong>EC2</strong>: Elastic Compute Cloud (EC2) is where you run servers. If you're looking to run an API or a traditional web app using something like Node or Nest, this is what you want. EC2 costs can add up quick, so be careful experimenting with these.</li><li><strong>RDS</strong>: RDS stands for Relational Database Service so this is where you'll set up databases such as MySQL, PostgreSQL, and Microsoft SQL Server.</li><li><strong>DynamoDB</strong>: DynamoDB is Amazon's No SQL solution similar to MongoDB.</li><li><strong>Amplify</strong>: Amplify is a platform for building full stack apps quickly. The Amplify Framework consists of 3 components including libraries, UI components, and a CLI toolchain, while the Amplify Console is a static web hosting service.</li></ul><p>These are the core services I would focus on as a developer getting started with AWS. There are many, many more services relevant to developers, but getting a handle on the basics of these will get you quite a long way.</p><h2>AWS Pitfalls for Developers</h2><p>The two main pitfalls you might run into as you learn AWS (other than its sheer complexity) are <strong>billing</strong> and <strong>identity and access management (IAM)</strong>.</p><p>AWS is not free to use, though there is a free tier and some services are free. Usually these costs are minor for short periods of time, but beware: if you run through a tutorial and then forget to clean up after yourself, you might face a big bill at the end of the month! Be sure to know what costs you're incurring as you do tutorials and try to shut down and delete anything you don't need when you're finished. AWS also lets you create billing alerts that will email you when you've hit a threshold. Here's a great <a href="https://egghead.io/playlists/use-aws-billing-cost-management-dashboard-to-keep-your-aws-bill-to-minimum-ff0f">egghead collection on AWS cost management</a> that will help a lot.</p><p>The other really sticky area in AWS is security. Identity and Access Management (IAM) in AWS is extremely complex. There are many layers of permissions for each service, user, and group. Most tutorials will help you navigate the basic set up that you will need to get things done. Be careful that you're not leaving yourself open to big vulnerabilities as you learn. Not only does that open the door to data theft, but it could also result in huge bills if someone gets a hold of your root account. This doc is kind of scary, but you're going to want to get familiar with <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">security best practices in AWS</a> little by little. At the very least, secure your root account and enable MFA.</p><p>For the sake of both billing and IAM, you will likely want to avoid using your employer's AWS account to learn. If your job is the motivation for learning AWS, work with your company on creating a sandboxed account with a given budget.</p><h2>Overview of AWS Certifications</h2><p>While not all certifications in tech are created equal, AWS certifications are extremely valuable. They're designed to minimize false positives and fairly rigorous, so employers know they can use them as a solid benchmark of knowledge. This means they can add some zeroes to your paycheck and set you apart from the average developer.</p><p>There are many different AWS certifications, so let's break down what the options are.</p><p>The <a href="https://aws.amazon.com/certification/certified-cloud-practitioner/">Cloud Practicioner exam</a> is considered a <strong>Foundational</strong> exam recommended for people with 6 months of fundamental AWS knowledge. It's high-level and not super technical, but gets your feet with AWS.</p><p>From there, there are three <strong>Associate</strong> level exams, recommended for people with 1 year of experience solving problems and implementing solutions using AWS. These exams have broad scope but shallow depth and break into three paths: Architect, Operations, and Developer. The three exams are:</p><ul><li><a href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">Solutions Architect Associate</a></li><li><a href="https://aws.amazon.com/certification/certified-sysops-admin-associate/">SysOps Administrator Associate</a></li><li><a href="https://aws.amazon.com/certification/certified-developer-associate/">Developer Associate</a></li></ul><p>From there, there are two <strong>Professional</strong> certifications, recommended for people with 2 years of comprehensive experience designing, operating, and troubleshooting solutions using AWS. These exams have broader scope and are quite deep. The Architect path remains, but Developer and Operations combine into DevOps. The two exams are:</p><ul><li><a href="https://aws.amazon.com/certification/certified-solutions-architect-professional/">Solutions Architect Professional</a></li><li><a href="https://aws.amazon.com/certification/certified-devops-engineer-professional/">DevOps Engineer Professional</a></li></ul><p>There are also six <strong>Specialty</strong> exams, which are very narrow in scope but very deep:</p><ul><li><a href="https://aws.amazon.com/certification/certified-advanced-networking-specialty/">Advanced Networking Specialty</a></li><li><a href="https://aws.amazon.com/certification/certified-security-specialty/">Security Specialty</a></li><li><a href="https://aws.amazon.com/certification/certified-machine-learning-specialty/">Machine Learning Specialty</a></li><li><a href="https://aws.amazon.com/certification/certified-alexa-skill-builder-specialty/">Alex Skill Builder Specialty</a></li><li><a href="https://aws.amazon.com/certification/certified-data-analytics-specialty/">Data Analytics Specialty</a></li><li><a href="https://aws.amazon.com/certification/certified-database-specialty/">Database Specialty</a></li></ul><p>I decided to get some of these certifications as a way to guarantee that I will actually set aside the time to learn some AWS and have something to show for it. My plan is to get the Cloud Practicioner and then the Solutions Architect Associate. Why not the Developer Associate first? Well, my understanding is that the Solutions Architect Associate is more comphrensive than the Developer Associate, and thus it's easier to get the Developer Associate after getting the Solutions Architect Associate. It also sets you up to get the Solutions Architect Professional, which is extremely difficult and highly coveted (and thus should come with a big pay raise!). The SA-P requires the SA-A, so it makes sense to go that route. I'll update this article when I've got some results.</p><h2>AWS Resources for Developers</h2><p>There are boatloads of resources for learning AWS out there. Some are geared towards infrastructure and networking folks, some are geared towards database admins, some for security teams, and others towards developers. Here are the key resources I've been using and a variety of others I've found useful.</p><h3>My Essential AWS Resources</h3><p>I've found myself relying pretty heavily on these resources in my own AWS journey:</p><ul><li><a href="https://acloud.guru/">A Cloud Guru</a>: A Cloud Guru is hands down the single best resources out there for learning AWS and just about any other cloud technology. I am honestly blown away. Just the <a href="https://acloud.guru/learn/aws-certification-preparation?_ga=2.170270560.1574418745.1603210089-860129520.1602887034">AWS Certification Preparation Guide</a> is worth the cost of admission. I'm working my way through the Developer Learning Path and about halfway through the <a href="https://acloud.guru/learn/aws-certified-cloud-practitioner?_ga=2.124181706.1574418745.1603210089-860129520.1602887034">Cloud Practitioner 2020 course</a>. I've also used A Cloud Guru a <em>ton</em> for work whenever I've needed to look up terms or concepts I don't understand. I had a big annoying run-in with VPCs and private networks and A Cloud Guru seriously came to my rescue.</li><li><a href="https://cloudnewbies.com/">Cloud Newbies Discord</a>: This is a Discord server founded by <a href="https://twitter.com/hirokonishimura">Hiroko Nishimura</a>, creator of <a href="https://awsnewbies.com/">AWS Newbies</a> (which is another great site full of articles, books, and exam tips). It is immensely helpful to have a welcoming and friendly community of people with whom to learn. The server has different channels for different cloud technologies and certifications, and the …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.samjulien.com/where-to-start-with-aws-as-a-developer">https://www.samjulien.com/where-to-start-with-aws-as-a-developer</a></em></p>]]>
            </description>
            <link>https://www.samjulien.com/where-to-start-with-aws-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913319</guid>
            <pubDate>Tue, 27 Oct 2020 23:37:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a circuitikz GUI editor for latex]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24913055">thread link</a>) | @grex99
<br/>
October 27, 2020 | https://grex99.gitlab.io/circuitgui/ | <a href="https://web.archive.org/web/*/https://grex99.gitlab.io/circuitgui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://grex99.gitlab.io/circuitgui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913055</guid>
            <pubDate>Tue, 27 Oct 2020 22:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beam Marches Forward]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912808">thread link</a>) | @zdw
<br/>
October 27, 2020 | https://underjord.io/the-beam-marches-forward.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-beam-marches-forward.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-10-26</small>
        <p>The BEAM is the virtual machine that Erlang and Elixir runs on. It is widely cited as a battle-tested piece of software though I don’t know in which wars it has seen action. It has definitely paid its dues in the telecom space as well as globally scaled projects such as Whatsapp and Discord. It is well suited to tackle soft-realtime distributed systems with heavy concurrency. It has been a good platform chugging along. And with a small team at Ericsson responsible for much of its continuing development it has been managed in a deeply pragmatic way. Erlang has always been a bit of a secret and silent success. Almost no-one uses it if you look at market shares. But among the ones that use it there seems to be a very positive consensus. And then Elixir came and caused a bit of a boom. I think the BEAM has benefited from Elixir and Elixir wouldn’t exist without the BEAM. With that bit of background I’d like to shine a light on some cool developments that I think makes the BEAM more interesting or even uniquely interesting in the future.</p>
<h2 id="the-jit-is-here-soon-otp-24">The JIT is here (soon, OTP 24)</h2>
<p>With OTP 24 landing sometime next year we are going to get the a JIT for the BEAM. Based on the project <a href="https://github.com/asmjit/asmjit">AsmJit</a> this will mean that some BEAM code will be translated to native instructions. It will not be the kind of warm-up-for-performance-gains JIT that I’ve heard of in PyPy but rather significantly simpler. The goal of the project was to introduce a JIT that could give performance gains for some cases but would not cause any performance regressions. A pragmatic and laudable approach. Considering this made the Jason JSON-library (written in Elixir) beat the Jiffy JSON-library (written as a C NIF) in <strong>some</strong> tests I think this has the potential to obviate the need for some NIF implementations. Avoiding reaching out to the lower level code that is more capable but more dangerous is a good win.</p>
<p>Anyone running RabbitMQ should look forward to the update as measurements indicate 30-50% increased message throughput. Which is a nice thing to get for no code changes at all.</p>
<p>Pushing the performance of the BEAM closer to native is magnificent. To be clear the BEAM is already quite a good performer. I would put Erlang and Elixir at the abstraction level of languages like Python/Ruby/Node.js. Python and Ruby are poor performers. The Python ML stuff all goes into C++ or similar for performance. I’ve worked a bunch with Python and the things I hear from the Ruby world makes them sound quite equivalent in performance. They are a bit slow and can only <a href="https://underjord.io/more-than-one-thing-at-a-time.html">do one thing at a time</a>. Node.js is a bit different. It can do multiple things at a time, if you append asterisks and squint. It does it largely the same way Python + Gevent does it. This approach is incredibly susceptible to CPU-bound work causing head-of-line blocking. It becomes the single most important consideration for building a performant application “get to IO, don’t compute”. V8 that Node.js runs on is heavily optimized and fast for such a dynamic language. I think the BEAM provides a better approach that can deliver comparable results without as many footguns (opportunities for shooting yourself in the foot). But getting better at the raw crunching is a big gain with this JIT implementation and I look forward to the release.</p>
<h2 id="lumen---static-compilation--wasm">Lumen - Static compilation &amp; WASM</h2>
<p>The <a href="https://getlumen.org/">Lumen project</a> is a huge effort by a gang of open source developers and DockYard to implement a compiler (and more) that can take Elixir and Erlang into the browser. By solving that they end up solving static compilation for Erlang and Elixir as well. So this isn’t compiling and shipping the BEAM to the browser. This is a faithful reimplementation of the BEAM functionality in a way that allows it to be compiled statically. It uses LLVM and requires quite a bit of effort both in development and in wrangling the Web Assembly work group process stuff to make sure that the standard is not entirely run by Object-Oriented Programming needs.</p>
<p>I don’t think Lumen will replace the BEAM. The BEAM has a brilliant track record for long-running services and distributed computing that the Lumen project do not even attempt to achieve right now. Instead the Lumen project will allow Elixir and Erlang to move into spaces where the BEAM might be a bit too heavy and still provide the same guarantees. Typically I see it being good for command line tools, web frontends (super interesting to consider the Actor model going there), serverless/edge computing and potentially with WASM competing with Docker as a delivery mechanism for code in Kubernetes, using something like <a href="https://github.com/deislabs/krustlet">Krustlet</a> (<a href="https://player.fm/series/software-sessions/webassembly-on-the-server-with-krustlet">good podcast episode on WASM/Krustlet</a>). It’s probably Cloud Native or something. Who knows.</p>
<p>What gives Lumen the potential to be a better fit in these circumstances is that it can optimize for filesize (by cutting out hot code updates) and it is likely able to start much faster. Lumen is written in Rust. Which seems to be the popular choice around Web Assembly from what I’ve seen. Lumen is still an early release project and not fit for production. But it is beeing actively pushed forward.</p>
<h2 id="nerves---an-iot-platform-with-minimal-suck">Nerves - An IoT platform with minimal suck</h2>
<p>The <a href="https://www.nerves-project.org/">Nerves project</a> is fantastic. I’m a hardware hobbyist, not an IoT dev but I’ve worked a fair bit with Nerves and it is so, so good. What Nerves gives you when working with a Raspberry Pi for example is a way to let your code run all of the device. The BEAM is basically your operating system on top of a minimal Linux installation. The Linux you have is based on the solid foundation of Buildroot so it is quite feasible to modify it as you see fit. The big idea is that if you are running a Linux-level SBC already you might as well build on something that gives you the guarantees of the BEAM.</p>
<p>Beyond that the default setup encodes a lot of good embedded practices by default so that you avoid bricking devices with firmware updates, you get easy support for pushing firmware over the network or USB and much, much more.</p>
<p>There are a ton of good libraries for sensors and assorted hardware, as well as the common protocols like GPIO/SPI/I2C/UART. Networking support is well considered and has been reworked since I first started using Nerves a few years back (and it worked well then too). BLE is getting more and more good support recently.</p>
<p>The project also created <a href="https://www.nerves-project.org/nerveshub">NervesHub</a> which is a solution for managing a fleet of devices by securely providing firmware updates, allowing the switching on of a remote console on devices if that’s a need on your product. I think the most recent stuff is a UI revamp and some serious work on binary diffed patches to minimize firmware update sizes for data-constrained deployments.</p>
<p>This is very much a production project and people are shipping hardware with Nerves. It keeps marching forward.</p>
<h2 id="the-beam-can-be-your-entire-application">The BEAM can be your entire application</h2>
<p>Saša Jurić, author of the much-acclaimed Elixir in Action book has produced a library called <a href="https://github.com/sasa1977/site_encrypt">site_encrypt</a>. It allows you to handle LetsEncrypt configuration without a separate webserver or actually using certbot.</p>
<p>Now this library is good and meaningful in its own right but the underlying idea is why I bring it up. The BEAM can be your entire application. This is something I’ve realized over time. Where in Python you would reach for Gunicorn to run you Django app and Nginx to protect Gunicorn from the big bad world.. The BEAM is made for this. Introducing an intermediate layer of Nginx (or another HTTP server) might actually be detrimental in that you now have two things you need to configure correctly and two pools of multi-core processing workers that care about this request/response cycle and can independently screw it up.</p>
<p>The BEAM was always built for this. OTP has a lot weird corners where you find interesting libraries such as <code>wx</code> for WxWidgets (window management) and <code>ssh</code> for both SSH client and server work I believe. Because it is meant to be delivered as a full solution. It can run and manage multiple different types of work inside of it. Gracefully. It doesn’t replace Kubernetes for the large deployment or polyglot environments. But it might very well mean you don’t actually need to go there early. Or you can reduce how much Ops you need in your Dev. If your entire stack is Elixir or Erlang front to back I think you have empowered your developers significantly.</p>
<p>There is already a move towards this where tools are converging that give us a lot of things out of the box that we’d otherwise need to move outside our application for. These are pragmatic 80-90% solutions. The normal solutions are still all there if you need to reach for them. But maybe you don’t. I see these as moves in the same vein:</p>
<ul>
<li>LiveView - We can reduce the amount of frontend we need to build that isn’t BEAM code (Elixir or Erlang), in some cases get rid of it entirely.</li>
<li>Live Dashboard - Application insights right in your application stack instead of pushing them out to another solution.</li>
<li>Phoenix PubSub - Distributed PubSub without requiring coordination via something like Redis.</li>
<li>Phoenix Channels - Distributed PubSub over WebSockets using the above PubSub to coordinate delivery.</li>
<li>Phoenix Presence - Distribute Presence. A CRDT-powered thing for maintaining information about if someone is connected to a channel or not, like chatrooms and online/offline. Using Channels.</li>
</ul>
<p>Lowering complexity by keeping the solutions in a system you understand well is potentially very powerful. At some point many projects will need to pick up external dependencies such as Nginx, Redis or whatever. But I think there is something compelling about building your application inside a system that can do all of it quite well. Elixir and Phoenix already have significant mind-share in the startup world. I wouldn’t be surprised if this ends up being a very popular solution for startups. No frontend-specific code for the MVP, no New Relic or Mixpanel bill we make do with the Live Dashboard. Distribution is Erlang distribution + Swarm/Horde/Libcluster or something …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/the-beam-marches-forward.html">https://underjord.io/the-beam-marches-forward.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/the-beam-marches-forward.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912808</guid>
            <pubDate>Tue, 27 Oct 2020 22:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[End of Notebag]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912613">thread link</a>) | @sixhobbits
<br/>
October 27, 2020 | https://pretzelhands.com/posts/end-of-notebag | <a href="https://web.archive.org/web/*/https://pretzelhands.com/posts/end-of-notebag">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>27th October 2020</p>


<p><strong>TL;DR: I am stopping work on Notebag.</strong> It is causing me lots of stress and guilt and I currently
have neither the capacity nor the will to update it right now and for the foreseeable future.
It is available free and open-source <a href="https://github.com/pretzelhands/notebag">on GitHub.</a> You can extend it!
If you bought your license in the past 30 days, send me an email with your order number and I'll refund it.</p>

<hr>

<p>So. Here we are. The irony of my last two blog posts being about the start and end of something is not lost
on me. I know that a few of you are probably confused, angry and perhaps even a bit sad right now, and I
apologize in advance. And some critical voices that have been haunting me around the internet have finally
been proven right.</p>
<p>Now let me tell you why exactly I am stopping work on Notebag, what will happen to it and where I will
be going from here.</p>
<h2>The Why</h2>
<p>One or two of you reading this might perhaps know what it's like when you start a new project. You come
up with a concept! Ideas burst through your head! You are itching to tear the world apart and make
things come alive exactly the way you imagined them. This is an absolute high of productivity and you
hack away until late at night, only to get up early next morning and get right back into it.</p>
<p>That was me. </p>
<p>That's how Notebag started, doubly fueled by the fact that the world in 2020 is .. something else
and I was shit-out-of-luck in terms of freelancing contracts. So I clung to the one thing I had and put
all of my energy into it and I worked to make it into something I thought was nice.</p>
<p>I pushed and pushed each day. Bigger! Better! More features!</p>
<p>And this worked well for a while, until the inevitable tiredness came creeping in. So I put Notebag on the
backburner. New freelancing contracts finally started trickling in and I found myself busy with two kinds of
work: The one paying my bills and the one I did on Notebag.</p>
<p>It was a struggle. Every day after work I tried to pour some of my remaining energy into Notebag, but nothing
happened. I failed to implement the most basic things and bit by bit, this intense feeling of guilt set in.</p>
<p>In time, I started avoiding Twitter. Because everytime I tweeted, I felt like someone out there would be
judging me. Why wasn't I reporting progress on Notebag? What was I even up to? And so I withdrew to the confines
of Telegram and ignored Twitter. DMs came in asking and I was too scared to reply.</p>
<p>Worst of all, I was and am building this subconscious pressure on myself that I am not really allowed to work on anything
else. Why would I work on <code>Project X</code> when Notebag fans are clamoring for updates? That makes me a bad person, no? This
has led me to a state where I was afraid to program outside of my contracts. Not a great spot to be in.</p>
<p>When you are not happy with things, you should change them. I am not happy with how Notebag is currently holding
a soft stranglehold on my life and so I am changing it.</p>
<h2>The What</h2>
<p>What does all of this mean for Notebag's future? First of all, I have <a href="https://github.com/pretzelhands/notebag">published the source code.</a>
It's MIT-licensed and on GitHub, free for everyone to download, build and play with. In my wildest dreams of course there
would be a shining community hero that rises up and picks up where I left off. But that is unlikely to happen.</p>
<p>So at least as a consolation, Notebag in its entirety is available for everyone, for all time, for free. If someone is
seriously willing to make pull requests and improve the code, I am happy to release signed builds with those changes
included. If anyone has specific questions about the architecture and why my code is so bad, I will gladly answer them.</p>
<p>This is, I think, the most elegant solution. It at least guarantees that the code doesn't just gather dust on my machine,
forever unreachable for any interested person. </p>
<p>And since there is still the occasional sale of a license, I offer anybody who bought their license in the past 30 days
(after September 27) a full refund, no questions asked. To avail this, just <a href="https://pretzelhands.com/cdn-cgi/l/email-protection#7018151c1c1f30000215040a151c18111e14035e131f1d4f0305121a1513044d3e1f04151211175542402215041902151d151e04554240221516051e14">send me an email</a>
or send me a Twitter DM.</p>
<h2>The Future</h2>
<p>Notebags future probably does not hold many further improvements. I still use it as my personal preferred
note-taking app, because that was its purpose. It works for me and my workflow and I hope that other people will keep
on using it or maybe learn a thing or two from the source code.</p>
<p>Personally I only have one or two side projects, but I'll probably put them on indefinite hold. Clean slate.
There's a few other hobbies I've been meaning to get around to and I think right now is a good time to do that. And
perhaps, somewhere down the line an idea will strike me and I'll give in to the itch to build again. But the time for
that is not right now.</p>
<h2>Final words</h2>
<p>I would again like to apologize to anyone who put high hopes into this app. Turns out that the detractors who pointed out
my legacy of abandoned apps were onto something! It sucks to be known for this, but maybe one day that will change. Or
maybe it won't.</p>
<p>As it is, Notebag will keep working in its usual state for the foreseeable future. But maybe <code>Au revoir</code>, doesn't have
to mean goodbye forever. Not that I have any hopes of picking it back up, but if 2020 has taught the world anything,
it's that life is unpredictable.</p>
<p>For my final point I'd like to give a special shout-out to <a href="https://twitter.com/Clo__S">@Clo__S</a>, who aside from being
an early adopter and wonderful source of feedback was probably Notebag's most vocal fan. Thanks for all the support along
the way.</p>
</div></div>]]>
            </description>
            <link>https://pretzelhands.com/posts/end-of-notebag</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912613</guid>
            <pubDate>Tue, 27 Oct 2020 22:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moore’s Law Is Dead for DRAM and That Is Great for SemiCap – SemiAnalysis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912591">thread link</a>) | @rbanffy
<br/>
October 27, 2020 | https://semianalysis.com/moores-law-is-dead-for-dram-and-that-is-great-for-semicap/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/moores-law-is-dead-for-dram-and-that-is-great-for-semicap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
				
<article id="post-493">
	
   
   
   <div>

   
   
      

   	
   	<div>
   		
<p>Moore’s law has been the driver of semiconductor capabilities and cost for decades. This phenomenon is still being pushed by the likes of TSMC, Intel, and Samsung in logic, but in DRAM, it is dead. DRAM scaling slowed significantly nearly a decade ago and it is moving at a snail’s pace now. New DRAM nodes are now a tiny fraction of a shrink. Going from 20nm to sub 10nm is going to take at least 5 different incremental node shrinks.</p>



<figure><amp-img width="678" height="389" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?resize=678%2C389&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?w=678&amp;ssl=1 678w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?resize=300%2C172&amp;ssl=1 300w" sizes="(max-width: 678px) 100vw, 678px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="678" height="389" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?resize=678%2C389&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?w=678&amp;ssl=1 678w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/0.png?resize=300%2C172&amp;ssl=1 300w" sizes="(max-width: 678px) 100vw, 678px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM4OScgd2lkdGg9JzY3OCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure>



<p>Density has not doubled over even the last 5 years. Despite this, DRAM demand has continued to grow at an incredible pace. This is not a shocker to anyone who follows the semiconductor field.</p>



<figure><amp-img width="1365" height="624" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?fit=800%2C366&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?w=1365&amp;ssl=1 1365w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=300%2C137&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=1024%2C468&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=768%2C351&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=1200%2C549&amp;ssl=1 1200w" sizes="(max-width: 1140px) 100vw, 1140px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1365" height="624" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?fit=800%2C366&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?w=1365&amp;ssl=1 1365w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=300%2C137&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=1024%2C468&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=768%2C351&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/1.png?resize=1200%2C549&amp;ssl=1 1200w" sizes="(max-width: 1140px) 100vw, 1140px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzYyNCcgd2lkdGg9JzEzNjUnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>The death of this scaling is what caused previous price spikes. As technology scaling slows, the only way to produce DRAM is with more wafers. It became a very capital-intensive task to increase DRAM bit output when this became true.</p>



<figure><ul><li><figure><amp-img width="596" height="413" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=596%2C413&amp;ssl=1" alt="" data-id="496" data-full-url="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?fit=596%2C413&amp;ssl=1" data-link="https://semianalysis.com/?attachment_id=496" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?w=596&amp;ssl=1 596w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=300%2C208&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=392%2C272&amp;ssl=1 392w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=130%2C90&amp;ssl=1 130w" sizes="(max-width: 596px) 100vw, 596px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="596" height="413" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=596%2C413&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?w=596&amp;ssl=1 596w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=300%2C208&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=392%2C272&amp;ssl=1 392w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.1.png?resize=130%2C90&amp;ssl=1 130w" sizes="(max-width: 596px) 100vw, 596px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQxMycgd2lkdGg9JzU5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure></li><li><figure><amp-img width="625" height="424" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?resize=625%2C424&amp;ssl=1" alt="" data-id="497" data-full-url="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?fit=625%2C424&amp;ssl=1" data-link="https://semianalysis.com/?attachment_id=497" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?w=625&amp;ssl=1 625w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?resize=300%2C204&amp;ssl=1 300w" sizes="(max-width: 625px) 100vw, 625px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="625" height="424" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?resize=625%2C424&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?w=625&amp;ssl=1 625w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/05/2.2.png?resize=300%2C204&amp;ssl=1 300w" sizes="(max-width: 625px) 100vw, 625px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQyNCcgd2lkdGg9JzYyNScgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure></li></ul></figure>



<p>Most of the wafer output increases will be coming from new fabs, as existing clean room space is bursting at the seams. This contrasts from Logic which requires much more clean room space and fab area for node shrinks, despite relatively stable wafer output on the leading edge.</p>



<figure><amp-img width="762" height="516" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?resize=762%2C516&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?w=762&amp;ssl=1 762w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 762px) 100vw, 762px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="762" height="516" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?resize=762%2C516&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?w=762&amp;ssl=1 762w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/3-1.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 762px) 100vw, 762px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzUxNicgd2lkdGg9Jzc2MicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure>



<p>More wafers require additional clean room space and semiconductor capital equipment. This spells great news for the likes of Applied Materials, ASML, Lam Reaseach, KLA-Tencor, and Tokyo Electron. Not all of these companies stand to gain the same and investors should keep this in mind when targeting the DRAM semi capital equipment market.</p>



<figure><amp-img width="638" height="413" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?resize=638%2C413&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?w=638&amp;ssl=1 638w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 638px) 100vw, 638px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="638" height="413" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?resize=638%2C413&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?w=638&amp;ssl=1 638w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/05/4-1.png?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 638px) 100vw, 638px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQxMycgd2lkdGg9JzYzOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure>
   	</div>

   </div>

	</article>

			
		</div></div>]]>
            </description>
            <link>https://semianalysis.com/moores-law-is-dead-for-dram-and-that-is-great-for-semicap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912591</guid>
            <pubDate>Tue, 27 Oct 2020 22:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five practices for serverless and distributed systems productivity]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912370">thread link</a>) | @wfaler
<br/>
October 27, 2020 | https://chaordic.io/blog/serverless-distributed-system-productivity/ | <a href="https://web.archive.org/web/*/https://chaordic.io/blog/serverless-distributed-system-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
                  <p><img src="https://chaordic-public.s3.eu-central-1.amazonaws.com/images/productivity-1995786_960_720.jpg" alt=""></p>
<p>To productively build serverless &amp; distributed systems, we need to adopt new practices, some which may seem counterintuitive at first. This post will suggest five concrete practices to up your game.</p>
<p>Let’s jump in, roughly in order of importance:</p>
<h4 id="1-prefer-running-your-system-in-the-cloud-over-local-emulation">1. Prefer running your system in the cloud over local emulation</h4>
<p>Local development is sacred cow for many developers, being able to deploy, run and test an application or system on your laptop. But the reality of modern distributed systems is that some things cannot easily be emulated locally, if at all.</p>
<p>It is not for a lack of trying: systems running on Kubernetes are often emulated with Docker Compose or Minikube, with varying levels of success. For AWS Serverless, we have AWS SAM and LocalStack.</p>
<p>There are however a few issues with this type of emulation:</p>
<ul>
<li>The cost of maintaining emulation is high, since you effectively maintain two stacks - one for local development, and one for “real” deployment.</li>
<li>Emulation isn’t the real thing: you will find configuration drift, small or large differences in the behaviour of your stack.</li>
</ul>
<p>In summary, our experience of trying to maintain emulation is that the costs far outweigh the benefits. That effort should instead be put towards the ability to deploy local code quickly to the cloud environment, or where possible, connect a locally running process to a real environment in the cloud.</p>
<p>One of the great benefits of Serverless in particular, is that the cost of creating and provisioning <em>Feature Environments</em> is approaching zero. Moving local development to the cloud is a low-cost proposition.</p>
<h4 id="2-cicd-pipelines-are-not-enough-local-deployment-automation-is-crucial">2. CI/CD Pipelines are not enough, local deployment automation is crucial</h4>
<p>Given our stance on local emulation, the next instinct to suppress is that of relying on CI/CD to manage deployments to feature environments. If we rely entirely on CI pipelines for our ongoing development work, we end up wasting large amounts of time waiting for CI pipelines to build and deploy.</p>
<p>If instead, CI &amp; local development workflows can share as much as possible of deployment infrastructure, we should be able to reduce/remove this bottleneck on development, while also minimizing the duplicated effort of maintaining two types of automation.</p>
<p>In summary, any developer should trivially be able to:</p>
<ul>
<li>Deploy or connect locally built resources to their own feature environment in seconds with a single command from their laptop.</li>
<li>Deploy only the unit of deployment which has changed.</li>
<li>Have a development experience that is practically indistinguishable from “local development”.</li>
</ul>
<h4 id="3-for-aws-serverless--function-as-a-service---monolithic-functions-are-ok">3. For AWS Serverless &amp; “Function-as-a-Service” - monolithic functions are OK</h4>
<p>The first thing many teams do when they first start using AWS Lambda, is that they create separate deployable functions for every type of function invocation. For instance, a REST API gets a function for every single endpoint on the API. However, if you think in terms of <em>Domain Driven Design</em>, this might mean you end up with a number of functions that logically make up a single <em>Bounded Context</em>.</p>
<p>There are also practical considerations: as an example, AWS CloudFormation has a default limit of maximum 200 resources per stack. When you start adding up the multiplicative effect of the resources required for a Serverless application, you quickly realise that this is a limit that can be easily reached. Sticking to a service per Bounded Context, that acts as the target for multiple types of Lambda invocations is a sensible thing to do. Doing this will also reduce the automation and coordination overhead.</p>
<h4 id="4-consider-adopting-a-monorepo-with-tooling-appropriate-for-monorepos">4. Consider adopting a monorepo, with tooling appropriate for monorepos</h4>
<p>Let us start with a caveat emptor: monorepos without using appropriate tooling can be a disaster of slow CI pipelines &amp; low productivity. The upside is that some amazing and battle-tested tooling for monorepos exist these days (a personal favourite is <a href="https://bazel.build/">Bazel</a>, which originated from Google).</p>
<p>Without a monorepo, building distributed systems can be painful.</p>
<p>With dozens of repositories, code navigation for larger changes spanning multiple services become painful. Another thing that quickly becomes painful is dependency management, code sharing &amp; reuse. It is not uncommon to find that different components have different, mutually incompatible dependencies, which become painful to upgrade.</p>
<p>A monorepo negates these pains, while also making things such as security audits easier to conduct and address.</p>
<p>However, to avoid the “rebuild the universe” problem with monorepos, you need tooling that solves three problems:</p>
<ul>
<li>Change detection &amp; dependency-graph tracking.</li>
<li>Dependency-graph based rebuilds (rebuild only what has changed and what is invalidated by the change).</li>
<li>Build caching.</li>
</ul>
<h4 id="5-implement-all-three-pillars-of-observability">5. Implement all three pillars of observability</h4>
<p>Observability in control theory is defined as the ability to infer the internal state of a system by from knowledge about its external outputs. In practice, this is the triumvirate of event logs (log aggregation &amp; analytics), metrics (for alerting) &amp; tracing (driving visualization). Most organizations today skew heavily towards event logs only, with maybe some metrics, but very few do all three well.</p>
<p>In a distributed systems world, doing all three pillars of observability well means that the time to detect, find and address bugs and other issues can be cut down to a fraction of what it would otherwise be. Furthermore, great observability will also improve developer productivity, since we can better understand the state of our entire system.</p>
<p>This is perhaps an area where AWS Serverless stands out as a leader. While the Kubernetes eco-system is filled with many options of various complexity and quality, AWS gives us an easy way to achieve a high level of observability at low effort and cost. <em>CloudWatch Logs, CloudWatch Metrics</em> and <em>AWS X-Ray</em> can provide observability to a Serverless architecture at a relatively low threshold of effort and learning.</p>
<h4 id="conclusion">Conclusion</h4>
<p>It should be obvious by now that Serverless &amp; distributed systems require great discipline in deployment automation. It is unfortunate that many still make the distinction between deployment being an “ops” concern, separate from development.</p>
<p>Dev &amp; Ops in modern systems are intertwined, the level and quality of automation has a great impact on DevEx (Developer Experience), and thus developer productivity. It is not a concern that can be postponed or thought about after the fact: it requires effort initially, and disciplined refinement throughout. If this is done well, you will be able to develop with a speed, reliability and level of productivity that will run rings around the competition.</p>
<p>We will return to this subject in the future to show what a practical Serverless toolchain and reference architecture could look like. Feel free to sign up to our email list below to get notified when we do!</p>
                  
                  </div></div>]]>
            </description>
            <link>https://chaordic.io/blog/serverless-distributed-system-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912370</guid>
            <pubDate>Tue, 27 Oct 2020 21:52:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A tool to understand and compare tech company compensation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24912218">thread link</a>) | @pmckee11
<br/>
October 27, 2020 | https://aeqium.com/offer_analysis?s=120000&sb=50000&ab=25000&sc=6000&st=option&sp=0.99&pp=6 | <a href="https://web.archive.org/web/*/https://aeqium.com/offer_analysis?s=120000&sb=50000&ab=25000&sc=6000&st=option&sp=0.99&pp=6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aeqium.com/offer_analysis?s=120000&amp;sb=50000&amp;ab=25000&amp;sc=6000&amp;st=option&amp;sp=0.99&amp;pp=6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912218</guid>
            <pubDate>Tue, 27 Oct 2020 21:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product Path Dependence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24912163">thread link</a>) | @sperand_io
<br/>
October 27, 2020 | https://n2parko.com/blog/product-path-dependence | <a href="https://web.archive.org/web/*/https://n2parko.com/blog/product-path-dependence">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><hr><p>Why the future of your product depends on its past.</p><a href="#httypo" id="httypo"><h2>HTTyPo</h2></a><p>There's a typo that runs the Internet. </p><p>In 1996, the Computer Scientist Phillip Hamam Barker and Roy Fieldings released <a href="https://tools.ietf.org/html/rfc1945#section-10.13" rel="noopener" target="_blank">RFC1945</a>, which proposed a new header field in the HTTP Protocol. The new field called <code>referer</code> — a misspelling of the word <i>referrer</i> — allowed "the client to specify, for the server's benefit, the address (URI) of the resource from which the Request-URI was obtained". A great addition to the protocol, but ter-ible spelling 😛</p><p>75 years later, on every website request that is made, there is now a <code>referer</code> header. Barker later <a href="https://groups.google.com/forum/?hl=en#!original/alt.folklore.computers/7X75In21_54/JgV9Rw04f-EJ" rel="noopener" target="_blank">joke</a>d that he was trying to get the Oxford English dictionary to adjust their spelling..."since my spelling is used several billion times a minute more than theirs" </p><p>SQL queries have been written, databases have been designed, bugs have been introduced...because of how Barker and Fieldings spelled this word. </p><a href="#&quot;in-this-great-future,-you-can't-forget-your-past&quot;" id="&quot;in-this-great-future,-you-can't-forget-your-past&quot;"><h2>"In this great future, you can't forget your past"</h2></a><p>Developing products is inherently path dependent. History matters. Every product decision you've made determines every product decision you're going to make in the future.</p><p><img src="https://n2parko.com/api/asset?assetUrl=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F147e9b25-92c3-4534-bfef-510315be9d39%2FUntitled.png&amp;blockId=cb6c5a83-5484-4e3d-8049-e7c40cb03e23" alt="An image from Notion"></p><p>Product-Market Fit is where that initial path is set. It is Decision A. At that point, you could've head in any direction. You could turn around quickly, and head in another direction. But the further you go down a particular trail, the further you have to backtrack. The more people you convince to join you on the trail, the more you have to explain why <i>everyone</i> needs to turn around. </p><p>I've found that thinking about your product path dependency is a helpful framework for understanding why your product is the way it is, and how to shape its future. It helps clarify why parts of your product — the product you are building! — stink and are so hard to fix. It clarifies which decisions matter and which do not. </p><p>And it helps you understand how and when you can change that path.</p><a href="#exploring-some-paths" id="exploring-some-paths"><h2>Exploring Some Paths</h2></a><p>Let's explore a few examples of Product Path Dependency at play...</p><a href="#smtp-protocol" id="smtp-protocol"><h3>SMTP Protocol</h3></a><p>Most email clients don't let you retract an email once it's been sent. You also can't edit a sent email. Most email clients — from Superhuman to HEY to Gmail — are built on the assumption that a sent email is a sent email. </p><p>Products have gotten creative to work around this assumption. Superhuman adds a 10 second wait period to allow you to unsend. If both sender and recipient are using Microsoft Exchange, an email can be "recalled". </p><p>But an <a href="https://tools.ietf.org/html/rfc821" rel="noopener" target="_blank">early decision in 1982</a> is largely still dictating how much of the world digitally communicates.  </p><p><img src="https://n2parko.com/api/asset?assetUrl=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F902fe272-6f32-4432-8a0f-718df674cc53%2FUntitled.png&amp;blockId=96299059-f253-4b65-8d7c-138bfc19f900" alt="An image from Notion"></p><p>Slack is a great example of what can happen when new entrants aren't burdened by past decisions. Rather than using SMTP, slack uses Websockets. When you send a message, the recipients see the message almost immediately. And you can edit, delete, pin and share the messages you're sending. </p><p>Once you've used Slack, you wonder why email was so static and immutable. It revisited an assumption, and made it painfully visible. </p><a href="#instagram" id="instagram"><h3>Instagram</h3></a><p>There's been a lot of <a href="https://www.vox.com/recode/2020/8/5/21354975/tiktok-clone-instagram-reels-facebook-copycat" rel="noopener" target="_blank">shade</a> thrown at Instagram for attempting to clone hit features like Stories (Snapchat) and Reels (TikTok). Occasionally these clones will work, in the case of Stories, but most of the time they flop. From NYTimes Tech Reporter <a href="https://www.nytimes.com/2020/08/12/technology/personaltech/tested-facebook-reels-tiktok-clone-dud.html" rel="noopener" target="_blank">Taylor Lorenz:</a></p><p><img src="https://n2parko.com/api/asset?assetUrl=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F94b14ca1-c890-47f0-8bc3-261ee6e5a82d%2FUntitled.png&amp;blockId=8748479f-7b04-4422-b70c-71ecf734c65b" alt="An image from Notion"></p><p>Instagram started as a simple photo sharing app. Snap photo, add filter, share with friends. Now put yourself in the shoes of the PM responsible for shipping Reels. You're trying to figure out how to fit Reels in alongside Stories, IGTV, Shop, Well-Being Guides, DMs for Brands, Influencers, Advertisers, and a user base in every country around the world. </p><p><img src="https://n2parko.com/api/asset?assetUrl=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9c67aef4-e50a-47b7-baf6-cceddeef5173%2FUntitled.png&amp;blockId=85d7f892-4c3b-4a23-8c45-c33b213177cf" alt="An image from Notion"></p><a href="#what-to-do-about-product-path-dependence" id="what-to-do-about-product-path-dependence"><h2>What to do about product path dependence?</h2></a><p>Path dependency is inherent to product development. It is a badge of successfully building something that people want, and an organization that can support it. So if we can't avoid it, what can we do about it? </p><a href="#early-decisions-are-disproportionately-important" id="early-decisions-are-disproportionately-important"><h3>Early Decisions are <i>Disproportionately Important</i></h3></a><p>There is a paradox of early product decision-making. Early decisions are disproportionately important in that all future decisions will rely on it. Yet they are also the ones that need to be made the fastest and given the least consideration. "Try it out and see what sticks." Until it sticks, and then you are left with that decision for a very long time. </p><p>I think there's a way to resolve this tension by making decisions that <i>preserve future optionality</i>. It's somewhat of a hack to avoid making a decision that you will have to unwind in the future.  </p><p>Let's take a user data model as a simple example. When you have no users, designing your data model is easy. You can change on the fly. As you build more features — like your sign up flow — they are built around the assumptions you made in designing your user model. Are you going to collect birthday? Are you going to ask them to use a company email address? Can they invite friends? As you build upon these early product assumptions, they become harder and riskier to change. </p><p>Designing for optionality may take slightly more time, but thinking through some potential options you might want down the line can reduce your path dependence. </p><ul><li>Will Users be part of an Account?</li><li>Will Users need to be Linked via a social graph?</li><li>Will Users need to have multiple Plans?</li></ul><p><img src="https://n2parko.com/api/asset?assetUrl=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa558f675-6d7e-45a3-ade1-174780e3bb29%2FUntitled.png&amp;blockId=38c88d0c-697e-4319-ab5e-a7fd6f9d6881" alt="An image from Notion"></p><p>An option-preserving decision early on can save you months or years of migration work down the line. </p><a href="#competitors-are-forging-their-own-paths" id="competitors-are-forging-their-own-paths"><h3>Competitors are forging their own paths</h3></a><p>Competitors are on a path as well, but it's different from yours. By understanding your competitors path, you can understand what they might do in the future, and what they aren't able to do given their prior decisions. A company geared at large enterprises has likely built a sales team that will be reluctant  to lower prices to sell to startups. A company designed to run on-prem will have quarters/years to migrate to the cloud. </p><p>New entrants are unburdened by decisions of the the past and can move much faster in many more directions. Every so often, revisit the assumptions and "path" that you are on. If you were to start all over again, how might your product and the org look different? Migrations and re-writes can be painful, but better to do so early than to continue to building on a crumbling foundation. </p><a href="#pms-are-the-&quot;product-historians&quot;" id="pms-are-the-&quot;product-historians&quot;"><h3>PMs are the "Product Historians"</h3></a><p>PMs can play an important role in understanding the market, organizational, and technology constraints that of the past, that led to the product today. In doing so, you'll be able to revisit past assumptions, avoid making the same mistakes, and build the trust of your team and customers. It's easy to fall into the trap that those who came before made bad decisions. Rarely is that the case. They made the best decision they could with the data and assumptions they were working off of. </p><p>By putting yourself in the shoes of those that came before — and really understanding the context — you can make even better decisions going forward. </p></div></div></div>]]>
            </description>
            <link>https://n2parko.com/blog/product-path-dependence</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912163</guid>
            <pubDate>Tue, 27 Oct 2020 21:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FusionAuth 1.20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912149">thread link</a>) | @mooreds
<br/>
October 27, 2020 | https://fusionauth.io/blog/2020/10/27/announcing-fusionauth-1-20/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/10/27/announcing-fusionauth-1-20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>We’re excited to announce the release of version 1.20. The 1.20 release shipped on Oct 26, 2020. This version delivers new features as well as resolving issues for users on version 1.19 and older.</p>

<!--more-->

<h2 id="highlights">Highlights</h2>

<p>In addition to bug fixes and user interface improvements, there are a couple of new features and improvements which deserve a spotlight.</p>

<h3 id="saml-saml-saml">SAML, SAML, SAML</h3>

<p>With this release, FusionAuth implements additional parts of the SAML 2.0 standard.</p>

<p>FusionAuth now has support for SAML POST bindings when it is acting as either the SP or the IdP. This allows FusionAuth to integrate with a number of popular commercial off-the-shelf applications and websites, including <a href="https://developers.login.gov/saml/">login.gov</a> and <a href="https://docs.alfresco.com/saml/concepts/saml-overview.html">Alfresco</a>.</p>

<p>FusionAuth also supports the <code>SessionIndex</code> attribute, which is optional, but required by some software applications, notably Artifactory.</p>

<p>Finally FusionAuth now honors the <code>AssertionConsumerServiceURL</code> in a SAML request. Multiple redirect URLs can be configured in the application SAML settings as well.</p>

<h3 id="docker-changes">Docker changes</h3>

<p>In this release, we updated the base image for Docker from <code>alpine</code> to <code>ubuntu:focal</code>. This should not impact functionality, but it’s worth paying attention to if you are building Docker images based on our image.</p>

<p>We made this change because in order to run on <code>alpine</code> without including the GNU C Library (<code>glibc</code>) we had to use a custom build of OpenJDK compiled using the <code>musl</code> C library. Due to some possible performance concerns with this option, we have moved to an official build of JDK provided by AdoptOpenJDK. This build is compiled using <code>glibc</code>. Unfortunately, using the <code>ubuntu:focal</code> image increased the docker image size by approximately 30 MB over the <code>alpine</code> based image. However, until we can obtain official builds from AdoptOpenJDK based upon the <code>musl</code> C library, we are not planning to ship an official FusionAuth image on <code>alpine</code> due to the performance concerns.</p>

<h3 id="additional-admin-user-management-forms">Additional admin user management forms</h3>

<p>In version 1.18, FusionAuth added <a href="https://fusionauth.io/features/advanced-registration-forms/">custom registration forms</a> for users with a paid edition.</p>

<p>In this release, we’ve added a few new forms. These customizations are also only available to customers with a paid edition. (Learn more about <a href="https://fusionauth.io/pricing/">purchasing a paid edition</a>.)</p>

<p>This new feature allows you to customize the form used to add or edit a user from the FusionAuth admin UI. These forms can be configured on a per tenant basis. For instance, you can now require a mobile phone number or require one or many custom fields when a FusionAuth admin is creating a user.</p>

<p>You can also modify the registration creation and update form in the FusionAuth admin UI, including capturing custom data, removing unused fields and adding validation to the custom fields. This form is configurable on an application by application basis.</p>

<p>For instance, if your business logic needs to know a user’s favorite color (or anything else), FusionAuth has you covered:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/release-1-20/custom-edit-registration-form.png" alt="A customized registration editing form."></p>

<p>When combined with FusionAuth’s granular roles, which allow you to create users with limited privileges, you can expose these forms to customer service reps or other users whom you might not want to access the entire FusionAuth admin UI.</p>

<h2 id="bugs-squashed">Bugs squashed</h2>

<p>In addition to these features, there were over ten other bugs squashed and GitHub issues resolved as well. These fixes include changes to JWT contents in certain situations, dashboard user counts, and superfluous log messages. Please see the <a href="https://fusionauth.io/docs/v1/tech/release-notes/">release notes</a> for the full breakdown of the changes between 1.19 and 1.20.</p>

<p>If you’d like to upgrade your self-hosted FusionAuth instance, see our <a href="https://fusionauth.io/docs/v1/tech/installation-guide/upgrade/">upgrade guide</a>. If you have a FusionAuth Cloud deployment, open a <a href="https://account.fusionauth.io/" target="_blank">support request from your account dashboard</a> or <a href="https://fusionauth.io/contact" target="_blank">use our contact form</a> and we’ll get your servers upgraded! Or, if you’d like to download and use FusionAuth, <a href="https://fusionauth.io/pricing/">check out your options</a>.</p>

            
          </div></div>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/10/27/announcing-fusionauth-1-20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912149</guid>
            <pubDate>Tue, 27 Oct 2020 21:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reddit will pay U.S. employees the same wherever they work from]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912106">thread link</a>) | @cwwc
<br/>
October 27, 2020 | https://www.bnnbloomberg.ca/reddit-will-pay-u-s-employees-the-same-wherever-they-work-from-1.1513853 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/reddit-will-pay-u-s-employees-the-same-wherever-they-work-from-1.1513853">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>      
      
      <section>
        
        <div>
            		    
                  
    
  
    
  
    
    
        
            
    

      
    
    
        










        

    



<section data-obj-id="axisCollectionObj_7_596965_1528215697" ng-controller="AxisCollection" ng-init="init()">

                        
        
			
                        
        
	        

    

    <p>The information you requested is not available at this time, please check back again soon.</p>

			    	
</section>

	

      
  
        		      			      				    
                  
    
  
    
  
    
    
            


      
  
        			    		          </div>
        <div>
                                          
        
            
            
    
        
    
    
                        
                        
                    

                

                                        <article>
            
            <div>

                                <header>
                                            		                                                    
                    
        	    
                        
                    
                                                            
                    
                </header>

                                                <div>
                                                            <p><img title="Reddit, Photographer: Gabby Jones/Bloomberg" height="349" alt="Reddit" width="620" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1513854.1603832140!/fileimage/httpImage/image.jpg_gen/derivatives/landscape_620/reddit.jpg">                                            </p>

                    <p>                            Reddit
                        , Photographer: Gabby Jones/Bloomberg</p>

                                    </div>
    
                                                                
                                <div><p>Reddit will give employees, with some exceptions, the flexibility to work outside of offices going forward, the company said Tuesday in&nbsp;a blog post.</p>

<p>U.S. employees will now be paid the same, based on high-cost locations like NY or San Francisco, whether they work from those places or not.</p>

<p>â€œMoving forward, teams and team members will have flexibility to explore where they work: in the office, remotely, or a combination of the two,â€� the post said.</p>

<p>For those who do come into the office, the spaces will be look different: Reddit said itâ€™s â€œreimaginingâ€� its office space, without fixed desks and with â€œneighborhoodsâ€� for teams to work together. The newly flexible approach will help Reddit bring in top talent without concerns about relocations, increase workersâ€™ engagement and make their office space more efficient.</p>

<p>Several&nbsp;tech firms, including Facebook and Slack, have said during the pandemic that their workers are free to relocate and work remotely going forward, but they will be paid based on where they live. Stripe Inc. said that it would pay employees who relocate from the Bay Area or New York a one-time bonus of $20,000 â€“ but theyâ€™d also get a pay cut of as much as 10%. Brex, a fintech company based in San Francisco, has also outlined salary reductions for employees who move out of the Bay Area and New York to places like Austin, Texas or Utah.</p>

<p>â€œWe will not be afraid to continuously adapt and evolve our workforce philosophies, programs, and processes,â€� Redditâ€™s post stated.</p>
</div>

            </div>

        </article>



                
    
        
    
    


                                  
                  
    
  
    
  
    
    
        

      
  
              </div>
      </section>
    </div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/reddit-will-pay-u-s-employees-the-same-wherever-they-work-from-1.1513853</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912106</guid>
            <pubDate>Tue, 27 Oct 2020 21:25:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Create personalized promotions and pricing with 5 lines of code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24912104">thread link</a>) | @jegan_hb
<br/>
October 27, 2020 | https://stack.promo/personalization.html?src=hn | <a href="https://web.archive.org/web/*/https://stack.promo/personalization.html?src=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <!-- Header -->
    
    <!-- end: Header -->

    <section>
        <div>
            <div>
                <div>
                    <h2><span>Create personalized promotions with ease</span></h2>
                    <p>Delivering personalized content at the right time, to the right person can significantly boost customer engagement and increase revenue.
                    </p>
                </div>  
            </div>
        </div>
    </section>

    <section>
        <div>

            <div>
                <div>
                    <div>
                        
                        <h4>API api.stack.promo/v1/website/skus/personalize</h4>
                        <p><span>This API accepts a simple list of SKUs(stockkeeping unit) as a request and transforms it into alist SKUs with the promotions.
                        </span></p>
                    </div>
                </div>
            </div>
            <div>
                
                <div data-animate="fadeInRight">
                    <p>
                        <h4>Your website with stack.promo</h4>
                    </p>
                    
                </div>
            </div>
        </div>
   </section>
   <section>
        <div>

            <div>
                <div>
                    <div>
                        
                        <h4>API api.stack.promo/v1/shopping-carts/personalize</h4>
                        <p><span>This API accepts a simple shopping cart as a request and transforms it into personalizedshopping cart with promotions.
                        </span></p>
                    </div>
                </div>
            </div>

            <div>
                <div data-animate="fadeInLeft">
                    <div>
                        <p>
                            <h4>Your cart</h4>
                        </p>
                        <div>
                            <div>
                                <div>
                                    <table>
                                        <thead>
                                            <tr>
                                                <th></th>
                                                <th>Product</th>
                                                <th>Description</th>
                                                <th>Unit Price</th>
                                                <th>Total</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td>
                                                </td>
                                                <td>
                                                    <p>Bolt Sweatshirt</p>
                                                </td>
                                                <td>
                                                    <p><span>Bolt Sweatshirt</span>
                                                        <span>Size: M</span>
                                                        <span>Color: Blue</span>
                                                        <span>Gender: Women</span>
                                                    </p>
                                                </td>
                                                <td>
                                                    <span>$20.00</span>
                                                </td>
                                                <td>
                                                    <span>$20.00</span>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                </td>
                                                <td>
                                                    <p>Consume Tshirt</p>
                                                </td>
                                                <td>
                                                    <p><span>Consume Tshirt</span>
                                                        <span>Size: S</span>
                                                        <span>Color: Blue</span>
                                                        <span>Gender: Women</span>
                                                    </p>
                                                </td>
                                                <td>
                                                    <span>$18.99</span>
                                                </td>
                                                <td>
                                                    <span>$18.99</span>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                </td>
                                                <td>
                                                    <p>Logo Tshirt</p>
                                                </td>
                                                <td>
                                                    <p><span>Logo Tshirt</span>
                                                        <span>Size: L</span>
                                                        <span>Color: Grey</span>
                                                        <span>Gender: Man</span>
                                                    </p>
                                                </td>
                                                <td>
                                                    <span>$9.00</span>
                                                </td>
                                                <td>
                                                    <span>$18.00</span>
                                                </td>
                                            </tr>
                                            <tr>
                                                <td>
                                                </td>
                                                <td>
                                                    <p>Grey Sweatshirt</p>
                                                </td>
                                                <td>
                                                    <p><span>Grey Sweatshirt</span>
                                                        <span>Size: L</span>
                                                        <span>Color: Grey</span>
                                                        <span>Gender: Man</span>
                                                    </p>
                                                </td>
                                                <td>
                                                    <span>$22.99</span>
                                                </td>
                                                <td>
                                                    <span>$68.97</span>
                                                </td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div data-animate="fadeInRight">
                    <p>
                        <h4>Your cart with stack.promo</h4>
                    </p>
                    <div>
                        <div>
                            <div>
                                <table>
                                    <thead>
                                        <tr>
                                            <th></th>
                                            <th>Product</th>
                                            <th>Description</th>
                                            <th>Unit Price</th>
                                            <th>Total</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>
                                            </td>
                                            <td>
                                                <p>Bolt Sweatshirt</p>
                                            </td>
                                            <td>
                                                <p><span>Bolt Sweatshirt</span>
                                                    <span>Size: M</span>
                                                    <span>Color: Blue</span>
                                                    <span>Gender: Women</span>
                                                </p>
                                            </td>
                                            <td>
                                                <p><span>$10.00</span></p>
                                                <p><span><del>$20.00</del></span></p>
                                                <h4><span>Applied - Get $10</span></h4>
                                            </td>
                                            <td>
                                                <span>$10.00</span>
                                            </td>
                                        </tr>
                                        <tr>
                                            <td>
                                            </td>
                                            <td>
                                                <p>Consume Tshirt</p>
                                            </td>
                                            <td>
                                                <p><span>Consume Tshirt</span>
                                                    <span>Size: S</span>
                                                    <span>Color: Blue</span>
                                                    <span>Gender: Women</span>
                                                </p>
                                            </td>
                                            <td>
                                                <span>$18.99</span>
                                            </td>
                                            <td>
                                                <span>$18.99</span>
                                            </td>
                                        </tr>
                                        <tr>
                                            <td>
                                            </td>
                                            <td>
                                                <p>Logo Tshirt</p>
                                            </td>
                                            <td>
                                                <p><span>Logo Tshirt</span>
                                                    <span>Size: L</span>
                                                    <span>Color: Grey</span>
                                                    <span>Gender: Man</span>
                                                </p>
                                            </td>
                                            <td>
                                                <span>$9.00</span>
                                            </td>
                                            <td>
                                                <span>$9.00</span>
                                            </td>
                                        </tr>
                                        <tr>
                                            <td>
                                            </td>
                                            <td>
                                                <p>Grey Sweatshirt</p>
                                            </td>
                                            <td>
                                                <p><span>Grey Sweatshirt</span>
                                                    <span>Size: L</span>
                                                    <span>Color: Grey</span>
                                                    <span>Gender: Man</span>
                                                </p>
                                            </td>
                                            <td>
                                                <span>$22.99</span>
                                                <h4><span>Applied - Earn 500
                                                        points</span></h4>
                                            </td>
                                            <td>
                                                <span>$22.99</span>
                                            </td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section>
        <div>
            <div>
                <div>
                    <div>
                        
                        <h4>API api.stack.promo/v1/customers/promotions</h4>
                        <p><span>This API returns all the promotions available to a customer. The API response can be used to create a new section within the website to delight customers with the current and upcoming promotions.
                        </span></p>
                    </div>
                </div>
            </div>
            <div>
                <div data-animate="fadeInLeft">
                    <p>
                        <h4>Your rewards</h4>
                    </p>

                    <div>
                        <div>
                            <h4>Hi David,<br>
                                Save big and earn big when you shop with us.
                            </h4>
                            
                            
                            
                        </div>
                    </div>
                </div>
                <div data-animate="fadeInRight">
                    <p>
                        <h4>Your rewards with stack.promo</h4>
                    </p>
                    <div>
                        <div>
                            <h4>Hi David,<br>
                                Save big and earn big when you shop with us.
                            </h4>
                            <div>
                                <div data-percent="100" data-delay="0" data-type="%">
                                    <p>Discount - $15 <span>(2/2)</span></p>
                                    <p><span>%</span><span>100</span>
                                </p></div>
                            </div>
                            
                            <div>
                                <div data-percent="25" data-delay="0" data-type="%">
                                    <p>Loyalty Points - 5000 <span>(1/4)</span>
                                    </p>
                                    <p><span>%</span><span>25</span>
                                </p></div>
                            </div>

                            
                        </div>

                    </div>
                </div>
            </div>
      …</div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stack.promo/personalization.html?src=hn">https://stack.promo/personalization.html?src=hn</a></em></p>]]>
            </description>
            <link>https://stack.promo/personalization.html?src=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912104</guid>
            <pubDate>Tue, 27 Oct 2020 21:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Learned to Enjoy Networking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912059">thread link</a>) | @shsachdev
<br/>
October 27, 2020 | https://www.careerfair.io/reviews/enjoy-networking | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/enjoy-networking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
I used to hate the term “networking”.
</p>
<p>
I remember walking home one day when I saw one of my friends rushing towards our career center. When I asked why he was in such a hurry, he mentioned there was a networking event going on. 
</p>
<p>
He carefully explained that your network is your net worth. I puked a bit in my mouth and continued home. 
</p>
<p>
It always seemed really artificial to me - you go to a place with the intention of meeting someone who’ll benefit your career, irrespective of your actual interest in getting to know them as a person. 
</p>
<p>
That doesn’t sit right with me. It leads to artificial and short sighted conversations. 
</p>
<p>
After thinking about it more, I realized that the reason I don’t like networking events is because the agenda is very unclear. 
</p>
<p>
And no, an opportunity to potentially meet someone who will help advance your career is not a clear agenda. I guess what I don’t like is that these events are trying really hard to manufacture serendipity. And no one likes a try-hard. 
</p>
<p>
But then you have something like developer meetups which I think are much better, mainly because the agenda is clear: you’re learning about something new. And you’re doing it together. 
</p>
<p>
Now, in the process of learning, you might indeed meet like minded people who help you advance in your career. But the point is that, this is not the primary purpose of the meetup - it’s just a byproduct. 
</p>
<h2>The best networking is learning</h2>


<p>
This got me thinking and then I realized that the best form of networking is learning. You either offer value by sharing your knowledge or by asking someone else a specific question about something they have experience with.
</p>
<p>
That’s why the best way to network is to write blog posts, reach out to people you admire with specific requests, and to use platforms like Twitter to find interesting content. 
</p>
<p>
This is the opposite of exchanging business cards and sending random Linkedin requests. 
</p>
<p>
This is networking done right - you have a clear agenda in mind and the focus is on giving value. Not like vague entrepreneurship conferences where the supposed goal is to end up with as many business cards as humanly possible. 
</p>
<p>
And to be clear, I don’t think the above has anything to do with being an extrovert or an introvert. 
</p>
<p>
Those two are just attitude types, not interpersonal skills, and more importantly, everyone has both sides. 
</p>
<p>
I consider myself an introvert but when I’m interested in a topic and I read something insightful about it, I’ve made it a habit to reach out to the author. 
</p>
<p>
Here are a few examples I’ve seen that embody the “best way of networking is learning” approach. 
</p>
<h2>Example #1: Learning in public</h2>

<p>
I follow <a href="https://twitter.com/stopachka/status/1318361464831442949">Stepan</a> on Twitter. He’s constantly posting his learnings and asking questions. Here’s an example:
</p>
  <center>
    <img src="https://www.careerfair.io/assets_enjoy_networking/stopa_tweet_1.png" alt="">
  </center>
<p>
Most of his tweets won’t get engagement, but sometimes people will comment and discuss topics he’s thinking about. 
</p>
  <center>
    <img src="https://www.careerfair.io/assets_enjoy_networking/stopa_tweet_2.png" alt="">
  </center>
<p>
Over time, when someone visits his profile, they can basically scroll through his timeline and discover what kind of topics he’s interested in. This is a fantastic way to meet like-minded people and develop a high quality network. 
</p>
<h2>Example #2: Blogging </h2>


<p>
I wanted to have a coffee chat with a founder. I reached out to him and he agreed. Instead of just speaking to him in private, I decided to make the <a href="https://www.careerfair.io/reviews/interview-with-ceo-of-appsumo">interview public</a> and wrote it up on my blog (with his permission, of course). 
</p>
  <center>
    <img src="https://www.careerfair.io/assets_enjoy_networking/ayman_screengrab.png" alt="">
  </center>
<p>
People who like the interview can now email me about it and we can talk about something that was discussed. A further benefit is that people can also reach out to Ayman (the CEO I spoke with). 
</p>
<p>
Extending this - people often email me about multiple topics I’ve discussed. All because I decided to publish online and share my thoughts. I’m still at the very early stages of this, but the benefits are already trickling in. 
</p>
<h2>Example #3: Publishing book notes </h2>


<p>
Nat Eliason publishes <a href="https://www.nateliason.com/notes">book notes</a> for almost everything he reads. Talking about books you both like is a great conversation starter. 
</p>
  <center>
    <img src="https://www.careerfair.io/assets_enjoy_networking/eliason_notes.png" alt="">
  </center>
<p>
Again, just like the Twitter example, people can get an overview of the kind of topics that Nat is interested in and reach out to him if they want to talk about something specific.
</p>
<p>
Reaching out to someone you admire or even just a peer works way better when you narrow the focus of conversation. For instance, instead of sending a 500 word email where you ramble your thoughts all over the place, you send 150 words directed at something you want to talk to about.
</p>
<p>
All of the above examples make it really easy to do this. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/enjoy-networking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912059</guid>
            <pubDate>Tue, 27 Oct 2020 21:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Members-Only Blog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24911984">thread link</a>) | @mmarcelline
<br/>
October 27, 2020 | https://blog.cotter.app/how-to-start-a-members-only-blog-with-webflow/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/how-to-start-a-members-only-blog-with-webflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/kEsj5dBURWQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption><a href="https://alberts-initial-project-a368bc.webflow.io/blog">Try it!</a></figcaption></figure><p>In this tutorial we're going to guide you on how to restrict your blog readers to only signed in users.</p><h2 id="part-1-cotter-setup">Part 1: Cotter Setup</h2><p>Go to <a href="https://dev.cotter.app/">https://dev.cotter.app</a> to create an account. Once you have created an account, make sure to create a new project and grab the API Key ID. We will be using your API Key ID later in part 2.</p><h2 id="part-2-webflow-setup">Part 2: Webflow Setup</h2><p>For this tutorial, we have created 3 pages: Blog Homepage, Sign In Page, and Blog Content Page. We will be using Webflow CMS to do this. Please <a href="https://www.youtube.com/watch?v=NBtF_XuimCo&amp;t=3720s">refer to this YouTube tutorial to create a simple blog</a>.</p><h3 id="blog-homepage-setup">Blog Homepage Setup </h3><p>The Blog Homepage contains a list of your blogs and an overview of each blog. If a reader wants to read the full article, he/she will be redirected to the Sign In Page where we will show the embedded Cotter login form for your users to type in their email before getting access to the full blog post. If the reader is already signed in, then he/she will be redirected to the full article page.</p><p>After finishing the page setup, we can start with adding custom code to the Blog Homepage. Copy paste the code below to the custom code tab on the Blog Homepage Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/09/Screen-Shot-2020-09-06-at-7.47.23-PM-1.png"><figcaption>Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/09/Screen-Shot-2020-09-06-at-7.49.28-PM-1.png"><figcaption>Scroll down to "Custom Code" section</figcaption></figure><p>Add the code below to the body of the Blog Homepage</p><pre><code>&lt;script&gt;
// 1. We check if a user has already logged in
var cotterOAuthToken = localStorage.getItem("user_session");

// 2. Fetch the user data
let token = JSON.parse(cotterOAuthToken);

// 3. Change the "Sign In" Button to "Sign Out"
let authButton = document.getElementById("auth-button")

if(!!cotterOAuthToken) authButton.innerHTML = "Sign Out"

authButton.addEventListener("click", () =&gt; {
	window.localStorage.setItem("redirect_url_after_login", window.location.href);
	window.localStorage.removeItem("user_session");
});
&lt;/script&gt;</code></pre><h3 id="sign-in-page-setup-where-the-sign-in-form-will-show-up-">Sign In Page Setup (where the sign in form will show up)</h3><p>We need to include a section element to load Cotter's login form. Moreover, we need to set that section ID to "cotter-form-container". This enables Cotter's JS SDK to load the login form to the section element that we just added.</p><p>After finishing the page setup, we can start with adding custom code to the Sign In Page. Copy and paste the code below to the custom code tab on the Sign In Page settings.</p><ol><li>Get Cotter JS SDK</li></ol><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
    src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="385b574c4c5d4a7808160b16090e">[email&nbsp;protected]</a>/dist/cotter.min.js"
    type="text/javascript"
&gt;&lt;/script&gt;</code></pre><p><br>2. Initialize Cotter</p><p>Add the code below to the body of Sign In Page.</p><pre><code>&lt;!-- 2. Initialize Cotter --&gt;
&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID here
  const redirectURL = localStorage.getItem("redirect_url_after_login")
  cotter
  	// Choose what method of login do you want
    // Sign In with Magic Link
    .signInWithLink()
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
	  // save OAuth token
      localStorage.setItem("user_session", JSON.stringify(payload));
      
      // redirect to location before login page
      const redirectURL = localStorage.getItem("redirect_url_after_login")
      if(!!redirectURL) window.location.href = redirectURL
      else window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h3 id="blog-content-page-setup-full-article-page-">Blog Content Page Setup (full article page)</h3><p>Now let's move on to the Blog Content page. The Blog Content Page refers to the page that contains your full blog article in which you only want signed in users to access this page. </p><p>We'll be adding custom code to the header to:</p><ol><li>Check if a user is logged in </li><li>Set the location for redirection after the user is logged in (so that the user will be redirected to the page he/she was trying to access before being redirected to the Sign In Page)</li><li>Fetch the user's OAuth token. </li></ol><p>Add the code below to the header</p><pre><code>&lt;script&gt;
// 1. We check if a user has already logged in
var cotterOAuthToken = localStorage.getItem("user_session");

// 1a. Set the location for redirection after the user is logged in.
localStorage.setItem("redirect_url_after_login", window.location.href);

// 2. If user is not logged in then we redirect to the login page
if (!cotterOAuthToken || cotterOAuthToken.length &lt;= 0) window.location.href = "/";

// 3. If user is logged in then we fetch the user data
let url = "https://cotterapp.herokuapp.com/login"
fetch(url, {
    method: 'POST',
    cache: 'no-cache',
    headers: {
      'Content-Type': 'application/json'
      // TODO: add API key ID to allow different audience
    },
    body: cotterOAuthToken
  })
  .then(resp =&gt; resp.json())
  .then(data =&gt; {
  	if(!data.success) { window.location.href = "/" }
  });

&lt;/script&gt;</code></pre><h2 id="part-3-publish-and-test">Part 3: Publish and Test</h2><p>We've arrived at the last part of this tutorial and all that you need to do is to click publish and test Cotter's magic link authentication for your Webflow blog!</p><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="cdb9a8aca08daea2b9b9a8bfe3acbdbde3">[email&nbsp;protected]</a></p><hr><p><a href="https://www.youtube.com/watch?v=NBtF_XuimCo&amp;t=3720s">Build a Simple Blog with #Webflow</a> tutorial by Brian Haferkamp.</p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/how-to-start-a-members-only-blog-with-webflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911984</guid>
            <pubDate>Tue, 27 Oct 2020 21:14:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app that fixed my depression]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24911903">thread link</a>) | @zoozla
<br/>
October 27, 2020 | https://blog.elifiner.com/i-built-an-app-to-fix-my-depression-stats/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/i-built-an-app-to-fix-my-depression-stats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. I tried different meds for a few years and every time life took a bad turn the doc recommended I up the dosage. I could see this how  would eventually lead me to a straitjacket and started looking for other ways.</p>



<p>Over the years I tried various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and managing covid anxiety. My longest bout of depression now lasts a couple of hours at most, and even that is pretty rare. Others have used the app to deal with loneliness, social media and porn addiction and a general sense of being stuck in a rut.</p>



<p>I can’t make any bold claims yet, but the <a href="https://twitter.com/finereli/status/1314784540703899648?s=20">stats I have from close to 1,000 people</a> show that a single use of the app causes apathy, tension and fear to drop by about 70% and anger by almost 90%.</p>



<p>You can try it too: <a href="https://wuju.app/">wuju.app</a></p>



<hr>



<p>You can try the app for free but full use is subscription based. If you need it but can’t afford it please ping me and we’ll figure something out.</p>



<p>Your mental health is your responsibility and this is an experimental tool that may or may not work for you.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://blog.elifiner.com/i-built-an-app-to-fix-my-depression-stats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911903</guid>
            <pubDate>Tue, 27 Oct 2020 21:06:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years, 8 months and 12 days]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24911784">thread link</a>) | @app4soft
<br/>
October 27, 2020 | https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/ | <a href="https://web.archive.org/web/*/https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="lesanimals-page-wrapper" role="main">
        <section id="template-post-single" data-view-name="template-post-single" data-id="2969">

        <canvas data-text="News"></canvas>

        <span></span>

        

        <div>

            
            <div>
                <p>This article could have been entitled&nbsp;337,737,600 seconds, but hiding the fact that Prototypo started more than 10 years ago would have been a missed opportunity to show the dedication the team and I, as a founder, put in this project over the years.</p>
<p>Prototypo started as a student project when I studied Graphic Design at H.E.A.R Strasbourg in France. As a non-savvy Type Designer I was frustrated to not be able to complete the typeface projects I had in mind. Typefaces are made of rules and systems, right? Catcha! We can code something that follows rules, so we should succeed in coding fonts. That was the starting point of the next 10 years, and the beginning of the Roller Coaster, a.k.a creating a startup company.</p>
<p>Prototypo is a startup like many others: before having a stable and reliable business model, we put a lot of energy into developing innovative and useful technologies for our users.</p>
<p>But before being a startup, Prototypo is a company. Today we have reached the end of our resources without having found the expected Product Market Fit, and so the Break-even.</p>
<p>After several years of a strong dedication and passion for what we’ve built, we decided to shutdown the company.</p>
<p>Since the first second, I knew that it would be a hard journey with many obstacles on the path. But I regret nothing. The next 337,737,599 seconds were full of great experiences, shared with amazing people.</p>
<p>Thank you for those who supported us along the road, it was a great adventure.</p>
<p><a href="https://www.linkedin.com/in/yannick-mathey/">Yannick,</a> (former) CEO</p>

            </div>

            

        </div>

                    
        
    </section>
</section></div>]]>
            </description>
            <link>https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911784</guid>
            <pubDate>Tue, 27 Oct 2020 20:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring Myths Common in Hacker News Discussions]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24911758">thread link</a>) | @Ozzie_osman
<br/>
October 27, 2020 | https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-222">

	

	
	<div>
		
<p>Another day, another HackerNews discussion about hiring being broken. The most recent one I saw was triggered by <a href="https://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">a blog post</a> by the formidable Aline Lerner (disclaimer: Aline is a friend and we collaborated on a <a href="https://www.holloway.com/g/technical-recruiting-hiring/about">hiring book</a> last year). Now, I 100% agree that hiring is broken, and Aline’s post is really thoughtful. In fact, a lot of “hiring is broken” articles are thoughtful.</p>



<p>But the discussion threads are something else—they miss the point of the article. The discussion threads are even more broken than hiring. And they’re really repetitive. They always do contain grains of truth, but inevitably have us reaching conclusions that are simplistic, and in my opinion, create a pretty bad attitude in the tech industry.</p>



<p><strong>Conclusion #1: “Hiring sucks for candidates, but hiring managers can do what they want</strong>“</p>



<p>The truth is that hiring is hard for everyone. There’s no question about it. It’s hard for both candidates and for hiring managers. Sure, FAANGs and the startup-du-jour might have a leg up, but most people who are hiring are trying to hire at a non-FAANG, non-sexy company. If you’ve never done it, you should try it at some point in your career. It’s an <em>incredibly </em>humbling experience. Or, at the very least, find a friend who’s spent time on hiring, and ask them for their favorite battle story. They’ve been ghosted by candidates. They’ve spent hours trying to convince people to talk to them. They’ve spent even more time getting candidates to the offer stage, only to lose out to the FAANG / startup-du-jour.</p>



<p>And yes, on the balance, power and information asymmetry work out in favor of the companies hiring. And that asymmetry is much larger with FAANGs. But even FAANGs have to invest a tremendous amount of time and energy into hiring. It’s not really easy for anyone. </p>



<p>Especially if you want to do it <em>well</em>. Ask any successful leader (entrepreneur, manager) what they spend most of their time on, and it’ll either involve a large chunk spent on hiring (if they appreciate the problem and give it the attention it deserves) or dealing with the consequences of bad hiring (if they don’t).</p>



<p><strong>Conclusion #2: “Hiring is a crap-shoot—it’s a roll of the dice</strong>“</p>



<p>I strongly disagree with this one. When writing the <a href="https://www.holloway.com/g/technical-recruiting-hiring">Holloway Guide to Technical Hiring and Recruiting</a>, I got to interview dozens of really thoughtful hiring managers and recruiters. They were really good at their jobs. And there were some common themes. They were thoughtful about every step of their process. They kept their process balanced and fair, holding a high bar but respecting candidates and their time. They didn’t chase the same pool of candidates everyone else was chasing—instead, they found non-traditional ways to discover really talented and motivated people who weren’t in the pool of usual suspects. They were thoughtful about what signals they were looking for and how best to assess them. And, they deeply understood their team’s needs, and candidates’ needs, and were really good at deciding when there was or wasn’t a fit. But most of all, they were effective: they built really talented teams.</p>



<p>There are a handful of companies that have built amazing hiring engines, and the proof is that they’ve been able to put together really strong teams. You can generally tell that if a person worked at a certain company at a certain time, that person is probably incredibly intelligent and incredibly motivated (some examples are Google, Facebook, Stripe, Dropbox at different points in time). There will always be noise. Even the best hiring managers will sometimes make hiring mistakes. And of course, even the best engineers may not be a fit for every role or every company. </p>



<p>Again, hiring is hard. But there is not a shred of doubt in my mind that if you are thoughtful about it, you can hire well. And really, you don’t need to be perfect at it. You just need to be better than the rest.</p>



<p><strong>Conclusion #3: “FAANGs suck at hiring”</strong></p>



<p>This one has some truth to it, but it’s a lot more subtle than “FAANGs suck at hiring”. Because let’s face it, they do hire really smart people. Some of the smartest people I know are at FAANGs right now. So let’s decouple that statement a little more.</p>



<p>FAANGs <em>do </em>suck at parts of hiring, like their candidate experience. They can be really slow at making hiring decisions. Their hiring process might be tedious and seem arbitrary. But <em>they usually can get away with it</em>, <em>and you probably can’t!</em> They’ve got a strong brand, interesting technical challenges (interesting for some people, at least), and a lot of money. In fact, one FAANG VP of Engineering told me: “our process is what we can get away with”. To the point that they can even play it off as a positive: “our process is slow and long because we are <em>very</em> selective”.</p>



<p>And look, I’m sure FAANGs lose some talented candidates who get turned off by their “you’d-be-blessed-to-work-with-us” attitude. They definitely have a lot of room for improvement. But at the end of the day, they’re operating a process that’s delivering large quantities of really smart people at scale. In fact, I’d argue their internal processes around strategy, performance management / promotions, etc cause incredibly <em>more</em> damage to them than broken hiring—if you lose out on hiring one talented person when you have thousands applying to work for you, that’s one story, but if you hire someone really talented and driven, and they work for you for 6 to 12 months but don’t meet their potential and leave in bitter frustration… well, that’s a subject for another post)</p>



<p>“But”, people go on, “FAANGs <em>also</em> don’t know how to interview!” Which brings me to trope #4.</p>



<p><strong>Conclusion #4: “Whiteboard</strong> <strong>and algo/coding interviews suck”</strong></p>



<p>Again, this one has some truth to it, but if you just stop at the above statement, you miss the point.</p>



<p>Algo/coding interviews are one of the primary hiring mechanisms used by FAANG companies. And they are incredibly unpopular—at least in discussion threads. But big companies have spent years looking at their hiring data and feeding that back into their hiring process (coining the term “<a href="https://rework.withgoogle.com/subjects/people-analytics/">people analytics</a>” along the way).</p>



<p>The argument against them is usually a combination of:</p>



<ul><li>they really only assess pattern-matching skills (map a problem to something you’ve seen before)</li><li>they only assess willingness to spend time preparing for these types of interviews</li></ul>



<p>These are fair criticisms, but that doesn’t mean these interviews are actually terrible. I mean, they might be terrible for you if you’re interviewing and you don’t get the job. You’re probably a brilliant engineer, and I agree, these interviews certainly don’t fully assess your ability (or maybe you’re a shit engineer, I don’t know you personally). In any case, the leap from “this interview sucked for me” to “this interview sucks” is still pretty big.</p>



<p>If you’re a large tech co with a big brand and a salary scale that ranks at the top of&nbsp;<a href="https://www.levels.fyi/">Levels.fyi</a>, you probably get a lot of applications. So a good interview process is one that weeds out people who wouldn’t do well at your company. To do well at a large tech company, you need to (and I’m painting with a really broad brush, but this is true for 90% of roles at these companies):</p>



<ol><li>Some sort of problem-solving skill that’s a mix of raw intelligence and/or ability to solve problems by pattern-matching to things you’ve seen before.</li><li>Ability/commitment to work on something that may not&nbsp;<em>always&nbsp;</em>be that intrinsically motivating, in the context of getting/maintaining a well-paying job at a large, known company.</li></ol>



<p>Hopefully you can see where I’m going with this. Basically, the very criticisms thrown at these types of interviews are the reason they work well for these companies. They’re a good proxy for the work you’d be doing there and how willing you are to do it. If you’re good at pattern matching, and are willing to invest effort into practicing to get one of these jobs, you’ll probably do well at the job.</p>



<p>Not that there’s anything wrong with that type of work. I spent several years at big tech co’s, and the work was intellectually stimulating most of the time. But a lot of times it wasn’t. It was a lot of pattern-matching. Looking at how someone else had solved a problem in a different part of the code-base, and adapting that to my use-case.</p>



<p>On the other hand, if you’re an engineer (no matter how brilliant) who struggles with being told what to do or doing work that you can’t immediately connect to something intrinsically motivating to you, that FAANG interview just did both you and the company a favor by weeding you out of the process.</p>



<p>So the truth is, there is no single “best interview technique”. In our book, we wrote several chapters about different interviewing techniques and their pros and cons. In-person algo/coding interviews on a whiteboard, in-person interviews where you work in an existing code base, <a href="https://www.holloway.com/g/technical-recruiting-hiring/sections/take-homes">take-home interviews</a>, pairing together, having a trial period, etc all have pros and cons. The trick is finding a technique that works for both the company and the candidate. </p>



<p>And that can really differ from company to company and candidate to candidate. A VP at Netflix told me about how they had a really strong candidate come in, but when asked to do a whiteboard-type interview, informed them (politely) that they might as well just reject him then. He was no good at whiteboard interviews… But if they allowed him to go home and write some code, he’d be happy to talk through it. And since then, many Netflix teams have offered candidates the choice of doing a take home.</p>



<p>And really, any interview format can suck. It can fail to assess a candidate for the things a company needs and it can be a negative candidate experience. Which would you rather have:</p>



<ul><li>A whiteboard interview with heavy algorithms for a role where that knowledge (or ability to develop that knowledge) isn’t critical, delivered by an apathetic engineer who doesn’t care about their job.</li><li>A …</li></ul></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</a></em></p>]]>
            </description>
            <link>https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911758</guid>
            <pubDate>Tue, 27 Oct 2020 20:53:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get started with 2-minute rule]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24911312">thread link</a>) | @hoanhan101
<br/>
October 27, 2020 | https://hoanhan.co/2-minute-rule | <a href="https://web.archive.org/web/*/https://hoanhan.co/2-minute-rule">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Scale any task down into a 2-minute version to make it easier to get started.</p><time datetime="2020-10-27T00:00:00-04:00"> October 27, 2020 · 1 min read · <a href="https://hoanhan.co/category/Motion">Motion</a><hr> </time><p>Whenever you find it hard to get started on a task, consider scaling it down into a 2-minute version. For example,</p><ul><li>Read a book → Read one page</li><li>Write an essay → Write one sentence</li><li>Run 10 miles → Wear my running shoes</li><li>Do 100 push-ups → Do 1 push up</li><li>Eat more vegetables → Eat an apple</li><li>Study for interview → Skim through my notes</li><li>Build a program → Code a function</li></ul><p>The idea is to make it super easy to get started. Once you pass the starting point, which is arguably the hardest step, you start to gain momentum to keep doing the task itself:</p><ul><li>Read one page → Read 10 pages → Finish the first chapter</li><li>Write one sentence → Write an opening paragraph → Write the body</li><li>Wear my running shoes → Walk for 5 minutes → Run for 5 minutes</li></ul><p>As you can see, once you start, it is much easier to continue doing it. Sometimes, you’ll find yourself completing the task even before you even notice it.</p><blockquote><p>For more insights on system planning and goal setting, feel free to check out <a href="https://hoanhan.co/motion">this guide</a>. If you’re curious about how I apply it on a daily basis, <a href="https://motion.hoanhan.co/goals/hoanhan/">check this out →</a></p></blockquote><hr><p><strong>References:</strong></p><ul><li><a href="https://jamesclear.com/how-to-stop-procrastinating">https://jamesclear.com/how-to-stop-procrastinating</a></li><li><a href="https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html">https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html</a></li></ul><hr><hr><p> Tagged: <a href="https://hoanhan.co/tag/motion.hoanhan.co">#motion.hoanhan.co</a>, <a href="https://hoanhan.co/tag/consistency">#consistency</a>, <a href="https://hoanhan.co/tag/start">#start</a></p><br> </article></div></div>]]>
            </description>
            <link>https://hoanhan.co/2-minute-rule</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911312</guid>
            <pubDate>Tue, 27 Oct 2020 20:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pants 2.0.0 released – Concurrently cache and orchestrate modern Python builds]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24911148">thread link</a>) | @stuhood
<br/>
October 27, 2020 | https://blog.pantsbuild.org/introducing-pants-v2/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/introducing-pants-v2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h3 id="pants-2-0-0-the-first-stable-release-of-the-pants-v2-open-source-build-system-is-out-now-">Pants 2.0.0, the first stable release of the Pants v2 open-source build system, is out now!</h3><p>There are so many tools in the Python development ecosystem. You might use <a href="https://pip.pypa.io/en/stable/">pip</a> to resolve dependencies, <a href="https://docs.pytest.org/en/stable/">pytest</a> to run tests, <a href="https://flake8.pycqa.org/en/latest/">flake8</a> and <a href="https://www.pylint.org/">pylint</a> for lint checks, <a href="https://black.readthedocs.io/en/stable/">black</a> and <a href="https://pycqa.github.io/isort/">isort</a> for auto-formatting, <a href="http://mypy-lang.org/">mypy</a> for type checking, <a href="https://ipython.org/">IPython</a> or <a href="https://jupyter.org/">Jupyter</a> for interactive sessions, <a href="https://setuptools.readthedocs.io/en/latest/">setuptools</a>, <a href="https://pex.readthedocs.io/en/latest/">pex</a> or <a href="https://www.docker.com/">docker</a> for packaging, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a> for code generation, and many more. Not to mention any custom tooling you've built for your repo. </p><p>Installing, configuring and orchestrating the invocation of these tools<strong>—</strong>all while not re-executing work unnecessarily<strong>—</strong>is a hard problem, especially as your codebase grows. The lack of a robust, scalable build system for Python has been a problem for a long time, and this has become even more acute in recent years, with Python codebases increasing in size and complexity. </p><p>Fortunately, there is now a tailor-made (pun intended) solution: <strong>Pants v2</strong>!</p><p><a href="https://www.pantsbuild.org/">Pants v2</a> is designed from the ground-up for fast, consistent builds. Some noteworthy features include:</p><ul><li>Minimal metadata and boilerplate</li><li>Fine-grained workflow</li><li>Shared result caching</li><li>Concurrent execution</li><li>A responsive, scalable UI</li><li>Unified interface for multiple tools and languages</li><li>Extensibility and customizability via a plugin API</li></ul><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/render1603750306032.gif" alt=""><figcaption>Pants running multiple linters in parallel</figcaption></figure><p>Read on to learn more about Pants v2, and what it means for your Python codebase.</p><hr><h2 id="a-little-history">A little history</h2><p>We started the original open-source Pants project back in 2011. At the time, we were frustrated by slow, flaky Scala builds. The leading strategy for scaling was to hand each developer a RAM stick and a screwdriver... Surely this was a problem we could tackle with software! Thus Pants v1 was born. </p><p>Pants v1 was quite successful, and was adopted at cutting-edge tech companies such as Twitter, Foursquare, Square and others. But we still weren't satisfied: The APIs were clunkier than we would have liked, the UI was overly chatty, caching was hard to get right, and concurrent execution had to be special-cased. We knew there were plenty of performance and stability improvements to be had, if we could only unlock them. </p><p>We learned a lot from our years of work on Pants v1, and knew that we could design something new and better, leaning on our experience with v1 while addressing the drawbacks of that system. Luckily, at the same time as we began thinking about this hypothetical next system, a new motivating problem emerged: Python builds.</p><h2 id="python-builds-today">Python builds today</h2><p>As you probably know, Python has skyrocketed in popularity in recent years. Not only is it used to build a wide variety of server applications, via frameworks such as <a href="https://www.djangoproject.com/">Django</a> and <a href="https://flask.palletsprojects.com/en/1.1.x/">Flask</a>, but it's also the language of choice for data scientists, thanks to powerful libraries and tools such as <a href="https://numpy.org/">NumPy</a>, <a href="https://www.scipy.org/">SciPy</a>, <a href="https://pandas.pydata.org/">Pandas</a> and <a href="https://jupyter.org/">Jupyter</a>. </p><p>Python hits a sweet spot of simplicity and power, but there is a big problem - there is no truly great scalable build tool for Python, and this is becoming a real pain point as Python repos grow like never before. &nbsp;</p><p>Python builds today involve manually invoking a wide variety of tools. Each tool has to be installed, configured and invoked in just the right way, often while sequencing the output of one tool into input of another. Knowing how to use each tool in a given scenario is complicated and burdensome. </p><p>Sure, you can hack around the problem for a while with some combination of shell scripts, <a href="https://www.gnu.org/software/make/manual/make.html">Makefiles</a>, <a href="https://tox.readthedocs.io/en/latest/">tox</a>, and <a href="https://python-poetry.org/">poetry</a>. But even a small code change might require you to run a huge amount of sequential build work. Re-executing the same processes with the same inputs over and over again is a frustrating waste of time and resources. &nbsp;And these solutions start to break down as your codebase grows.</p><p>Perhaps you experimented with more complex build systems, such as <a href="https://bazel.build/">Bazel</a> or <a href="https://v1.pantsbuild.org/">Pants v1</a>. &nbsp;But it's laborious to maintain all that BUILD metadata, all for a sub-par experience not optimized for Python. Not to mention the difficulty of implementing your own custom build logic. </p><p>Alternatively, maybe you've been tempted to split up your codebase into multiple interdependent repos, each with their own "smaller" builds. But that creates an even thornier problem, namely how to manage those interdependencies. Having to propagate changes across codebase boundaries can slow development down to a crawl, and leave you with the worst of both worlds - slower processes and a fragmented, unmanageable codebase.</p><p>A great build system for repos - of all sizes - that include Python code would support fine-grained invalidation and caching, so that it only executes the build work actually affected by a change. It would support concurrent local and even remote execution, to greatly speed up work by using all available CPU. It would be easy to adopt in a small repo, but would scale up as your codebase grows. It wouldn't require huge amounts of boilerplate metadata, and it would be easy to extend with custom build logic. </p><p>Well, Pants v2 is that system! </p><h2 id="introducing-pants-v2">Introducing Pants v2</h2><p><a href="https://www.pantsbuild.org/">Pants v2</a> is a completely new open-source build system, inspired by our work on Pants v1. &nbsp;We've been developing and testing it for the last couple of years, and it's finally ready for prime time!</p><p>A key factor in the design of Pants v2 was a set of lessons we learned from Pants v1 and other existing systems, such as Bazel. Among them: that ease of use and performance matter, boilerplate is annoying, concurrency and caching require hard design work, and most people will need custom logic at some point.</p><h3 id="lesson-1-ease-of-use-and-performance-both-matter">Lesson #1: Ease of use and performance both matter</h3><p>When designing software you often find yourself making tradeoffs between ease of use and performance. But in a build system, both are vital. The Pants v2 execution engine - which is the performance-critical heart of the system - is written in <a href="https://www.rust-lang.org/">Rust</a>, for raw speed. And the domain-specific build logic is written in familiar, easy to work with, type-annotated Python 3. This helps make Pants v2 easy to extend, without compromising performance. </p><p>Pants v2 also runs a daemon that memoizes fine-grained build state in memory, for even faster performance. This daemon watches for changes to your source files and precisely invalidates its state on the fly to ensure that the minimum amount of work happens the next time you build.</p><h3 id="lesson-2-writing-build-metadata-is-a-real-drag">Lesson #2: Writing build metadata is a real drag</h3><p>Some build tools are slow because they don't have enough information about the structure of your code to intelligently perform incremental work. Others have gone too far in the other direction, requiring a huge amount of metadata and boilerplate in BUILD files, especially relating to your code's dependencies. </p><p>Pants v2 offers the best of both worlds - intelligent, fine-grained incremental work, without the boilerplate. It does so by assuming sensible, magic-free defaults, inferring dependencies from the import statements in your code, and supporting plugins for custom inference logic. Stay tuned for an upcoming post on exactly how Pants achieves this!</p><h3 id="lesson-3-design-for-caching-concurrency-and-remoting">Lesson #3: Design for caching, concurrency and remoting </h3><p>Writing build logic that can be cached and executed concurrently and remotely is very hard. You have to be very careful about not producing or consuming side-effects, and it's extremely difficult to tack that on later. And unless you design your APIs with care, supporting these kinds of features often places severe restrictions on what your build logic may safely do. </p><p>In Pants v2, build logic is composed of <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> Python 3 <a href="https://docs.python.org/3/library/asyncio-task.html">async coroutines</a>. So a build rule can depend not only on its inputs, but can also await on new data at runtime - all of which is precisely tracked for invalidation and caching. This gives us the best of both worlds: logic that is properly isolated from side-effects, and is therefore amenable to caching, concurrent execution and remoting, while still allowing the use of natural control flow.</p><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/caching.gif" alt=""><figcaption>We run both tests, then add a syntax error to one test and rerun; the unmodified test uses the cache and is isolated from the syntax error.</figcaption></figure><h3 id="lesson-4-almost-everyone-needs-to-customize-their-builds">Lesson #4: Almost everyone needs to customize their builds</h3><p>Most teams have custom build steps, so extensibility is a key feature in any build system. Pants v2 is built around a <a href="https://www.pantsbuild.org/docs/plugins-overview">plugin architecture</a>. You can write your own rules using the same API as the built-in functionality. So your custom build logic will enjoy the same fine-grained invalidation, caching, concurrency and remote execution abilities as the core Pants code.</p><h2 id="pants-2-0-0-is-out-now-">Pants 2.0.0 is out now!</h2><p>All this leads me to the happy announcement that <a href="https://pypi.org/project/pantsbuild.pants/2.0.0/">Pants 2.0.0</a>, the first stable release of Pants v2, is out now! 2.0.0 is the culmination of years of design and development work, and many months of beta testing at several organizations. So we're really happy, proud (and relieved…) to finally have it ready for general use. </p><p>You can see what Python tools Pants currently supports <a href="https://www.pantsbuild.org/docs/python">here</a>. There are also commands for querying and understanding your dependency graph, and a robust help system. &nbsp;We're adding support for additional tools and features all the time, and it's straightforward to implement your own. Beta users have already written their own logic for Cython and docker, for example. </p><p>Now is a great time to adopt Pants 2.0.0! The team that developed Pants v2 is <a href="https://www.pantsbuild.org/docs/community">ready to help you</a> onboard, answer any questions, and even pair with you to help you write any custom build logic. We're also eager to get feedback, bug reports and suggestions for what features we should focus on in the next weeks and months of development.</p><p>Pants v2 is developed by a helpful open source community, is funded by a 501(c)6 non-profit, and has excellent support available. If you have a growing Python codebase, and want to take Pants 2.0.0 for a spin, <a href="https://www.pantsbuild.org/docs/community">let us know</a>. We'd love to fit you with some new Pants today!</p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/introducing-pants-v2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911148</guid>
            <pubDate>Tue, 27 Oct 2020 19:58:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring Interns––Choose interest over experience]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910953">thread link</a>) | @ilestkempo
<br/>
October 27, 2020 | https://adchen.co/interest-over-experience | <a href="https://web.archive.org/web/*/https://adchen.co/interest-over-experience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>October 2020</p><p>Aaron Chen</p><p>The vast majority of software-related internships should weigh meaningful interest over technical experience.</p><p>If an applicant can effectively display <strong>qualified interest</strong> through a well-thought and value-aligned argument, then they deserve that spot over those who don’t display that initiative. <em><strong>Even</strong> if there are others that seem more technically qualified</em>. </p><p>In a world of hiring, meritocracy reigns supreme <!-- -->[1]<!-- -->. And for good reason. The most effective individuals are the most skilled. A for-profit company’s essential and primary goal is to make money. To do that, a company needs to provide a product or service at a certain level of quality and form. At the base level, it’s simple: to create the best product, hire the best engineers. But these open positions inherently have a certain expectation of performance granted upon them. Internships on the other hand are fundamentally different.</p><p>One primary difference is that they’re learning-focused <!-- -->[2]<!-- -->. Companies hire full-time engineers with the expectation that they’ll be able to produce, and not primarily to learn <!-- -->[3]<!-- -->. On the other hand, interns are hired so they’ll learn the product and company. At its center internships are used to test candidates in a real world environment <!-- -->[4]<!-- -->. Hiring full-time engineers are based on the presumption that these individuals know how to perform in or at least navigate a real company environment already <!-- -->[5]<!-- -->. And for that reason, they should be treated differently. <strong>Meritocracy need not be the highest measure for hiring an intern</strong>. When present, well-intentioned and meaningful interest should be given precedence over experience. </p><p>I say this acknowledging that there should still be some minimum standard of technicality that the candidate has. They should be interested in programming after all! Deciding that minimum standard is a little up in the air though. What if the standards are <em>too</em> low? How do we differentiate between applicants at scale? First, well that’s already a problem with recruiting. Scaling to large numbers is incredibly difficult, and being able to do so currently, like your Google’s and Amazon’s often entail an already very frustrating and hated interviewing process. Second, your technical standards work in tandem with the entire application itself––I almost want to <strong>guarantee</strong> you that the amount of individuals who are willing to put in that effort to write a thoughtful, and cohesive letter are few to none in comparison to the bulk of applications <!-- -->[6]<!-- -->.</p><p>So I think those standards shouldn’t be set high.</p><p>Say you’re hiring for a frontend internship position. This position entails working on a server-side web framework––let’s use Ruby on Rails. As a hiring manager (lead talent guy or whatnot), you have to pick between two people: an individual who’s just submitted a resume that has 1 - 2 years of experience in Ruby on Rails, passes whatever technical examination you give him/her with high marks, and seems to be a smart and amiable individual on phone. And then there’s the applicant who’s had experience in Java for two years, a bit of JS/CSS/HTML for personal sites, and does a little below average on the technical portion <!-- -->[7]<!-- -->. But they also submit an extensive 1.5 page cover letter, detailing why they wanted to work at Company X, and also describes why they believe they’ll be a right fit <!-- -->[8]<!-- -->. This applicant, like the other, appears to be a good person, and displays similar levels of enthusiasm as in the letter on phone <!-- -->[9]<!-- -->.</p><p>If I were in that position of making the choice, I’d pick the latter. </p><p>I’d do so <em>knowing</em> that this applicant isn’t as technically qualified as the former. But, I’d also make this decision knowing this candidate displayed genuine interest, logically and persuasively argued his/her case in a manner that showed critical thinking and enthusiasm, and had the baselines for a programmer to adequately navigate the dynamics of software. The other candidate’s application was <em>just</em> a resume. And while they were technically qualified and adequately amalgable with the company, they just didn’t have the initiative or <em>spark</em> in their application. I think those sparks can make or break a company culture.</p><p>You want people that <strong>want to work at your company</strong>. The other candidate may have been a fine full-time too. But I think that spark goes a long way: you can rest assured knowing they have that demonstrated interest in learning the technology, product, and company. With that demonstrated interest, they’ll learn with minimal personal friction, they’ll enjoy being at your company, and the fact that you gave them a chance while they were under-qualified sure does give them even more appreciation and willingness to go above and beyond. We should keep in mind: this is an <strong>internship position</strong>. They are there to learn and to be tested. Interest should be paramount to these types of positions. In our situation, one candidate displayed that initiative more so than the other. </p><p>Take a chance on these types of applicants I say. They’ll exceed your expectations.</p><p><strong>Disclaimer:</strong>
I’ve been in this situation before. To be left with a simple 3 sentence email rejection after writing extensive cover letters, with no acknowledgement whatsoever of what I wrote hurts quite a bit. Of course, I never knew if they hired someone else after me because they seemed to be more skilled, but I think it can be easily assumed they did (provided they still had space! Which, if you have a job opening on Lever, then that should be the case).</p><p>Perhaps, this comes off as a salty rant, or maybe it has some substance. Who knows. I’d love to hear any critique or thoughts on this area either way.</p><p>--</p><p>[1]<!-- --> We don’t acknowledge any role if any that diversity may play within this process. I think that discussion should be reserved for a later time. </p><p>[2]<!-- --> Other differences include the time-span (months compared to however long a FTE stays on with the company) and mentorship (the type and the extent of it).</p><p>[3]<!-- --> Given a specific time span after hiring. Of course, incoming engineers learn some way or another. But not necessarily with the same focus as say an intern.</p><p>[4]<!-- --> Real world environment as in there is revenue tied in, one way or another, to the product/feature at hand and so the company places real value in it. There are internships that don’t do this, and instead use dummy projects interns work on. I’m not going to address those types (much less encourage that strategy either!).</p><p>[5]<!-- --> I use full-time hires as a word for engineers who aren’t interns but rather your “typical” engineer at a company. Obviously though, many internships are full-time too. But you know what I mean.</p><p>[6]<!-- --> Differentiating between varying levels of interest (between a letter, conversation, etc.) is definitely a good thing to wonder about. If you’re at the point where you have to do that though, I’d have to give you props! Sadly, I don’t have a very thought-out answer for it right now. But, I bet there are very <strong>few</strong> individuals who’ll have to deal with that. Barely any applicants are that <em>interested</em> in the companies they apply to, sadly. The game itself is spray and pray (sample size: 1 college student).</p><p>[7]<!-- --> For simplicity’s sake, a technical portion that measures general programming paradigms and concepts.</p><p>[8]<!-- --> Of course, a not-so-well written cover letter really isn’t going to go well. But, if you have an individual who’s willing to take that extra step and write an extensive letter like such, you’re probably not going to encounter a poorly written one. </p><p>[9]<!-- --> At this point, you’ve gauged the company fit for these individuals on the phone. But, we should also acknowledge there are many individuals you’ll miss if you’re analyzing the individuals you did talk to on the phone. </p></article></div></div>]]>
            </description>
            <link>https://adchen.co/interest-over-experience</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910953</guid>
            <pubDate>Tue, 27 Oct 2020 19:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Will Never Have Enough Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24910949">thread link</a>) | @bartdegoede
<br/>
October 27, 2020 | https://whoisnnamdi.com/never-enough-developers/ | <a href="https://web.archive.org/web/*/https://whoisnnamdi.com/never-enough-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://whoisnnamdi.com/content/images/size/w300/2020/10/header-v2-resized.png 300w,
                            https://whoisnnamdi.com/content/images/size/w600/2020/10/header-v2-resized.png 600w,
                            https://whoisnnamdi.com/content/images/size/w1000/2020/10/header-v2-resized.png 1000w,
                            https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png" alt="Why We Will Never Have Enough Software Developers">
            </figure>

            <section>
                <div>
                    <p>We will never have enough software developers.</p><p>Developers are dropping out of the profession in large numbers despite efforts to grow the number of computer science graduates and software engineers.</p><p>Here's why.</p><h2 id="developer-dropout-is-real">Developer dropout is real</h2><p>Software development has a <em>serious</em> retention problem:</p><ul><li>At age 26, 59% of engineering and computer science grads work in occupations <em>related</em> to their field of study. By age 50, only 41% work in the same domain, meaning a full <strong>~30% drop out of the field by mid-career</strong></li><li>In contrast, engineering and computer science majors who join <em>unrelated</em> fields upon graduation retain at much higher rates, with only 10-15% switching out after the age of 26:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/W-kECKz1nw.png"></figure><p>Engineers often leave engineering for non-STEM management roles. Graduation into management is not surprising. What's surprising is that these are <strong>non-STEM</strong> positions. Engineers swap technical roles for <em>non-technical</em> roles over time.</p><p>This phenomenon, which I'll call "<strong>developer dropout</strong>," is a real problem. What's behind it?</p><!--kg-card-begin: html--><section>
    <h3>Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>
                

</section><!--kg-card-end: html--><h2 id="out-with-the-old-skills-in-with-the-new-skills">Out with the old skills, in with the new skills</h2><p>Programming-related jobs have high rates of skill turnover. Over time, the types of skills required by companies hiring software developers change more rapidly than any other profession.</p><p>To demonstrate this, <a href="https://academic.oup.com/qje/article/135/4/1965/5858010">researchers</a> analyzed job postings on more than 40,000 online job boards and company websites between 2007 and 2019, controlling for employer, location, and occupation. They defined "new" skills as those that were rare or non-existent in 2007 but prevalent in 2019 and "old" skills as those that were prevalent in 2007 but rare or extinct in 2019.</p><ul><li>While only 30% of all job vacancies required at least one new skill by 2019, <strong>47% of computer and mathematical jobs required at least one new skill</strong> (i.e. a skill that was not common back in 2007)</li><li>This compares to <em>less than 20%</em> of jobs in fields like education, law, and community and social services</li><li>In addition, <strong>16% of jobs in computer and mathematical fields in 2007 required a skill that was obsolete by 2019</strong> (i.e. a skill that was common in 2007 but relatively rare in 2019), more than double any other job category:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/azDsA9n3rx.png"></figure><p>About a third of the change in required skills in computer-related occupations is due to specific new software:</p><ul><li>The fastest-growing software skills between 2007 and 2019 include <strong>Python, R, and Apache Hadoop</strong></li><li>Software that was popular in 2007 but effectively obsolete by 2019 includes QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah, finally a name I recognize)</li></ul><p>Data science, machine learning, and AI saw big increases among technology-intensive jobs as well. For example, the number of STEM-related jobs requiring skills in machine learning and AI grew more than 4x from 2007-2017, touching more than 15% of STEM jobs:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Pc3AjVflhW.png"></figure><p>To better compare rates of skill change across occupations, the researchers came up with a measure of skill change that tracks the absolute growth or decline of various skills within each profession from 2007 to 2019. Occupations whose required skills change rapidly in prevalence among job postings receive a high score, while jobs whose skills do not change much receive a lower score:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/xfeKvOWxo-.png"></figure><ul><li><strong>Computer-related occupations receive the highest score by far, 4.8</strong>. Note that the mean and standard deviation of this measure are ~3 and ~1 respectively, so computer-related jobs are <strong>nearly two standard deviations away from the typical job in America</strong></li><li>Meanwhile, jobs in education and and those involving manual labor have very low skill change scores, typically less than 2.</li></ul><p>We can get even more granular and look at specific job roles. This level of detail makes the difference even more stark (only showing the fastest changing roles):</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OwoB5xsSdO.png"></figure><p>Web development has the highest rate of skill change <em>among all jobs in the country</em>. Next up are sales engineers, another often technical role. Database administrators, computer network architects, sysadmins, and application developers all make the top 10, and we see many other technical roles among the top 30. The mean and standard deviation are similar here, placing web development <strong>more than 3 standard deviations away from the typical job in America</strong> in terms of skill change over time.</p><p>Suffice to say, <strong>software development is a rapidly changing profession</strong>.</p><p>You might think, however, that skill change would eventually settle down as one becomes more experienced.</p><p><em>You'd be wrong.</em> The skills for software engineering jobs change rapidly throughout the entire career lifecycle:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/7ItjXMaTE-.png"></figure><ul><li>In entry-level roles in computer and engineering occupations all the way through those requiring 12+ years of experience, <strong>the proportion of job postings requiring at least one new skill in 2019 was effectively the same, 40-45%</strong></li><li>In contrast, <strong>29% of entry-level non-computing and engineering roles in 2019 required at least one new skill, but this proportion declines to 24%</strong> for jobs requiring more than four years of experience</li></ul><blockquote>This means that experienced STEM workers seeking employment in 2019 are often required to possess skills that <strong>were not required</strong> when they entered the labor market in 2007 or earlier.</blockquote><p>Software engineers <strong>never</strong> escape the skill-change vortex, even many years into their careers. Experienced engineers must learn and adopt technologies that didn't even exist when they started out. Developers must constantly retool themselves, even well after their <a href="https://whoisnnamdi.com/college-degrees-software-engineers/">formal education</a> ends.</p><h2 id="nothing-s-changed-but-my-change"><a href="https://youtu.be/m1ERvlxgCD8?t=166">Nothing's changed but my change</a></h2><p><strong>College majors associated with faster changing jobs pay more early on.</strong></p><ul><li>In professions with one standard deviation increased skill change, pay is <strong>~30%</strong> higher in the first few years of one's career</li><li>If we exclude both the fastest and slowest-changing fields (Engineering/Computer Science at the high end, Health/Education at the low end), the early earnings premium for faster-changing roles increases to <strong>~60%</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/heMo13OsG1.png"></figure><p><strong>Fast-changing fields pay better.</strong></p><p>Notice however that the pay advantage declines over time. By the time one approaches the age of 50, the pay premium for working in rapidly changing fields falls dramatically to only 20-30% vs slower changing professions.</p><p>Here's another way to see the eroding pay advantage. The below chart simulates the earnings of the average worker by category of college degree from ages 23 to 50 in 2016 dollars.</p><ul><li>Computer science and engineering grads start off with sizable advantage vs any other major</li><li>However, this premium <em>falls</em> over time as the earnings of CS and engineering graduates plateau over time while the earnings of their peers grow <em>faster</em> for <em>longer</em></li><li>In fact, <strong>life and physical science graduates' earnings surpass their computer and engineering classmates by the age of 40</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Lifecyle-Earnings-by-Degree-Category.png"></figure><p>Excluding business majors, the earnings premium of software engineering declines over time in both percentage <em>and</em> absolute dollar terms, to the point where engineers barely out-earn social science majors:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Engineering-_-Computer-Science-Earnings-Premium.png"></figure><p>But the focus on college major is somewhat misleading. This phenomenon has less to do with one's field of study and more to do with <em>choice of occupation</em>.</p><p>To show this, researchers plotted the earnings premium of various categories workers relative to those with a non-Engineering/Computer Science major working in a non-Engineering/Computer Science job.</p><ul><li>Workers who major in Engineering or Computer Science but work in unrelated fields actually see their earnings advantage <em>compound</em> over time, rather than decline</li><li>On the other hand, regardless of major, individuals who work in Engineering or Computer Science jobs see their earnings advantage erode over the years:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OFffH9kBKA.png"></figure><blockquote><strong>Declining relative returns is a feature of STEM jobs, not majors.</strong> The earnings premium for non-STEM majors in STEM occupations starts off near 40%, but declines to 20% within a decade. In contrast, the relative earnings advantage grows over time for computer science and engineering majors working in non-STEM occupations.</blockquote><p>The <strong>profession</strong> of software development drives the declining earnings premium, <strong>not the college major</strong>.</p><p>In fact, computer science majors who work in non-CS fields experience the <em>opposite</em> dynamic of their non-developer peers — their relative earnings premium rises as they advance. A CS major who eschews the profession doesn't earn much more than otherwise similar non-CS majors early on, but eventually out-earns their peers by nearly 20%.</p><p>OK, that's enough about <em>what</em> is happening. Now let's see <em>why</em> it's happening.</p><h2 id="human-capital-depreciates-too"><em>Human</em> capital depreciates too</h2><p>Imagine a simple model where workers choose their profession in order to maximize income, which is a derivative of their own skill or human capital. Over time, workers gain new skills, while the value of their existing skills depreciates somewhat due to changing times.</p><p>Some workers, endowed with superior ability, learn faster than others, picking up skills at a quicker pace. Those workers will tend to sort into high-skilled, fast-changing professions initially, maximizing their early career earnings. Less impressive workers will sort into low-skilled, slower-changing professions.</p><p>In a world where human capital never depreciated, we could imagine that high-skilled individuals like software developers would maintain a relative human capital (and earnings) advantage over other professionals, leading to consistently increasing pay and a stable relative premium:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_o-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_o-Depreciation-.png"></figure><p>But, if human capital depreciates over time and that rate of depreciation is higher in rapidly-changing fields like software development, then developers' initial advantage would erode over time, narrowing the gap vs. non-developers:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_-Depreciation-.png"></figure><p>This simple model helps explain what we see in the data — the software engineering earnings advantage disappears as the <em>effective</em> human capital gap narrows.</p><blockquote>Applied majors such as computer science, engineering, and business teach vintage-specific skills that become less valuable as new skills are introduced to the workplace …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://whoisnnamdi.com/never-enough-developers/">https://whoisnnamdi.com/never-enough-developers/</a></em></p>]]>
            </description>
            <link>https://whoisnnamdi.com/never-enough-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910949</guid>
            <pubDate>Tue, 27 Oct 2020 19:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mendoza – The non-human readable diff format for structured JSON documents]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910944">thread link</a>) | @fjmvieira
<br/>
October 27, 2020 | https://www.sanity.io/blog/mendoza | <a href="https://web.archive.org/web/*/https://www.sanity.io/blog/mendoza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When we started work on the recently released feature <a href="https://www.sanity.io/blog/review-changes">Review Changes</a>, we needed a way to keep a significant part of the edit history of a document in the browser memory to be able to respond quickly to different user interface states. As the user picked various document versions to compare we wanted to be able to quickly reconstruct a specific section of the history of a document. </p><figure><div role="button"><div data-has-aspect="false"></div></div><figcaption>Review Changes for Sanity Studio. Powered by Mendoza.</figcaption></figure><p>For text diffs, we use the <a>diff-match-patch format</a>, and we just assumed someone would have implemented a similarly efficient and compact diff format for JSON documents, but no such luck. If we wanted a general JSON diff format that was super compact and fast to apply, we would have to invent it ourselves. And thus, Mendoza, the totally non-human readable diff format for structured JSON documents, was born.</p><p>Mendoza is:</p><ul><li>Lightweight JSON format</li><li>A flexible format that can accommodate more advanced encodings in the future</li><li>As a Go library for encoding and decoding</li><li>A JavaScript library for decoding</li><li>Efficient handling of the renaming of fields</li><li>Efficient handling of reordering of arrays</li><li>Not designed to be human-readable</li></ul><p>Mendoza differs (hah!) from normals diffs as they are:</p><ul><li>Made for humans to read and understand and based on simple operations (like keep, insert, and delete text)</li><li>Possible to apply even if the source has changed a bit by including some of the contexts around every part that has changed</li><li>Designed for text, and not structured documents</li></ul><p>Now, this is great when you are collaborating with humans on code development and use something like git to track your changes. What it isnâ€™t great for, however, is expressing differences between structured documents (such as JSON) in a compact manner that can be efficiently transferred over the network and parsed in JavaScript inside of browsers.</p><div data-block-key="27e85758c59a"><h2><a id="most-diffs-arent-meant-for-machines-27e85758c59a"></a><a href="#most-diffs-arent-meant-for-machines-27e85758c59a"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>Most diffs aren't meant for machines</h2></div><p>Most diff formats are made to be human-readable. Take these two documents, where a key and the array have some changes between them:</p><p>If these where two commits, the Git diff between them would be expressed like this:</p><p>This makes it somewhat practical for humans to understand what is going on when the latter change is applied. But as you can see, in terms of pure data, there is a lot of repetition going on. and expressing all changes with only plusses and minuses isn't very efficient.</p><p>The same diff with Mendoza is expressed like this:</p><p>Mendoza constructs a minimal recipe for transforming a document into another. All it really does is to compare two JSON documents and figure out the most minimal way to express their difference as strings and integers in an array. You can use this difference to reconstruct the first document to the other.</p><div data-block-key="308db67aa205"><h2><a id="how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"></a><a href="#how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>How to read a Mendoza patch (even though you shouldn't)</h2></div><p>A Mendoza patch consists of an array of integers and strings. The integers are <em>opcodes</em> (short for â€œoperation codesâ€�), 8-bit numbers that correspond to an operation. Opcodes take parameters as strings, positive numbers, or JSON values (that is: the actual data that is changing). The list of available opcodes is as follows, notice that 10-18 are composites of the preceding ones:</p><ul><li>0 <code>Value<!-- -->â€‹ </code></li><li>1 <code>Copy<!-- -->â€‹ </code></li><li>2 <code>Blank<!-- -->â€‹</code></li><li>3 <code>ReturnIntoArray<!-- -->â€‹ </code></li><li>4 <code>ReturnIntoObject<!-- -->â€‹ </code></li><li>5 <code>ReturnIntoObjectSameKey<!-- -->â€‹ </code></li><li>6 <code>PushField<!-- -->â€‹ </code></li><li>7 <code>PushElement<!-- -->â€‹ </code></li><li>8 <code>PushParent<!-- -->â€‹ </code></li><li>9 <code>Pop<!-- -->â€‹ </code></li><li>10 <code>PushFieldCopy</code></li><li>11 <code>PushFieldBlank</code></li><li>12 <code>PushElementCopy</code></li><li>13 <code>PushFieldBlank</code></li><li>14 <code>ReturnIntoObjectPop</code></li><li>15 <code>ReturnIntoObjectSameKeyPop</code></li><li>16 <code>ReturnIntoArrayPop</code></li><li>17 <code>ObjectSetFieldValue</code></li><li>18 <code>ObjectCopyField</code></li><li>19 <code>ObjectDeleteField</code>â€‹ </li><li>20 <code>ArrayAppendValue</code>â€‹ </li><li>21 <code>ArrayAppendSlice<!-- -->â€‹</code></li><li>22 <code>StringAppendString<!-- -->â€‹</code></li></ul><p>Mendoza reads these opcodes from the patch and produces the resulting document from them. Depending on the patch, Mendoza might choose not to strictly follow the opcodes but take a simpler path. If every field and value has changed, for example, itâ€™s more efficient just to replace the whole document with the new data without going through all the operations. Or if you have a list of objects where one has moved to another position and changed a key-value, Mendoza will manage to go back to the original and represent the change in a cheap way.</p><p>Mendoza is implemented in Go and can be found in this <a href="https://github.com/sanity-io/mendoza">GitHub repository</a>. We have also made <a href="https://github.com/sanity-io/mendoza-js">a parser for Mendoza patches in JavaScript</a>, that you can use in your own application. </p><p>Of course, you can dive into <a href="https://github.com/sanity-io/sanity/blob/a3f7158016d63728a9b435e6ab444ff2b90fd424/packages/%40sanity/desk-tool/src/panes/documentPane/documentHistory/history/timeline.ts#L421">the source code for the Sanity Studio</a> and explore how Mendoza is used there. If you want a slightly simpler use-case, you can also <a href="https://github.com/sanity-io/groq-store/blob/main/src/patch.ts">check out how weâ€™re using Mendoza to simulate a part of Sanityâ€™s real-time datastore</a> in the browser to power the <a href="https://github.com/sanity-io/next-sanity">real-time preview for Next.js</a>. </p><p>Naming a project is always difficult. Since this project is focused on representing changes between <em>JSON</em> documents I naturally started thinking about names like "JSON differ, JSON changes, JSON patch, â€¦". However, most of these names have already been used by existing projects. While I was muttering "JSON, JSON, JSON" it suddenly turned into "JSON, JSON, Jason, Jason Mendoza".</p><p>Jason Mendoza is a character from the show The Good Place, and while this project has little in common with the stupidest DJ from Florida, at least it's short and catchy.</p><p>Since a Mendoza patch is just describing the effect of a change it is also limited to work for the documents it was based on. It doesnâ€™t come with guarantees for consistency if the document you apply it on has changed from the original in meanwhile. This is one of the tradeoffs that we needed to do to make it really compressed. </p></div></div></div>]]>
            </description>
            <link>https://www.sanity.io/blog/mendoza</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910944</guid>
            <pubDate>Tue, 27 Oct 2020 19:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Northern hunter living hard reality described in new report on climate change]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910927">thread link</a>) | @colinprince
<br/>
October 27, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-friday-edition-1.5774327/northern-hunter-living-hard-reality-described-in-new-report-on-climate-change-1.5774429 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-friday-edition-1.5774327/northern-hunter-living-hard-reality-described-in-new-report-on-climate-change-1.5774429">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A new report from Human Rights Watch says that climate change is making it much more difficult for Indigenous people to survive in Canada's north, and it is infringing on their rights.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5774542.1603472007!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/sam-hunter.jpg"></p></div><figcaption>Sam Hunter is a member of the Weenusk First Nation and a resident of Peawanuck, Ont. He says that it's getting harder to hunt in Peawanuck because of climate change. This image is from the short film ‘Along the Winisk River.’<!-- --> <!-- -->(Daron Donahue for Human Rights Watch)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Northern hunter living hard reality described in new report on climate change"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/849/79/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:43</span><span>Northern hunter living hard reality described in new report on climate change</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-friday-edition-1.5774327/october-23-2020-episode-transcript-1.5777906">Read Story Transcript</a></p>  <p>Sam Hunter says this&nbsp;fall in Peawanuk, Ont.&nbsp;has been mild, where normally it would be freezing and there would be snow on the ground, and as a result, he has had to change how he hunts.&nbsp;</p>  <p>"I used to go hunting in a weekend, years prior, and now this year&nbsp;I had to be out along the coast for almost four&nbsp;weeks. It's a big difference," he told <em>As It Happens</em> host Carol Off.&nbsp; Hunter said he was hunting for geese, and also fishing.</p>  <p>Peawanuk is a Cree community on the Winisk River in northern Ontario, just south of Hudson's Bay, and west of James Bay.&nbsp;</p>  <p>A report released this week<a href="https://www.hrw.org/report/2020/10/21/my-fear-losing-everything/climate-crisis-and-first-nations-right-food-canada">&nbsp;from Human Rights Watch</a>&nbsp;says that Canada's changing climate is making it harder for Indigenous people&nbsp;to support themselves on the land. Unpredictable weather and changing conditions are disrupting wildlife habitats, causing&nbsp;available food resources to decline&nbsp;and making it more dangerous for Indigenous people to harvest food.&nbsp;&nbsp;</p>  <p>The report also says the federal government's failure to help Indigenous people adapt&nbsp;is leading to&nbsp;violations of their&nbsp;rights.</p>  <p><span><span><iframe src="https://www.youtube.com/embed/NKJpNuRdsiM" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>Human Rights Watch spoke to 120 people, including Hunter,&nbsp;in First Nations communities in northern Ontario, northwestern British Columbia, and northern Yukon between June 2018 and December 2019.</p>  <p>"The experiences of First Nations described in this report are illustrative of broader climate change impacts across Canada, however,&nbsp;each First Nation is unique, and none of their experiences can be generalized, making it imperative to tailor measures to address climate impacts and community needs in each of their traditional territories," the group wrote.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>We can see ... our&nbsp;peatlands&nbsp;thawing and the trees sinking into the ground, and the&nbsp;caribou&nbsp;that used to migrate in the hundreds of thousands, they're no longer here.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Sam Hunter</cite></span></blockquote>    <p>The report also noted that based on government statistics, half of First Nations people who live on reserves and nearly a third of Indigenous people who live off-reserve&nbsp;are food-insecure, which means they have difficulty accessing or are unable to access food to meet their dietary needs and preferences.</p>  <p>For Hunter, that means it's become harder to get food from the land.</p>  <p>"We used to have a fish run for about four weeks, maybe five weeks. But now, last couple years has been like one week of the fish run," he said.&nbsp;</p>  <p>Traditionally, Hunter and his community would have specific seasons for hunting geese, fish or caribou,&nbsp;but he says that's been affected by changes in the climate.</p>  <p>"With these changes, if you missed one of those seasons —&nbsp;because we tried to harvest enough to last 12 months of the year — if you missed that, if we missed this year's fish, you won't have any fish for a year," he explained.</p>  <p>Hunter says that might mean people have to turn to buying groceries, which are expensive. He said a loaf of bread might cost around $6, eggs about the same, while a can of pop might be almost $5.&nbsp;</p>  <p>"So what happens with the people that cannot afford food that they turn to Kraft dinner, canned food, cereal and they become sick with diabetes. They become overweight. That's the only thing they can afford," he said.</p>  <p>He said that if his family were forced to rely solely on the grocery store in his community&nbsp;they would not be able to make ends meet.&nbsp;</p>  <p>In the report, Human Rights Watch notes that an average family of four in Peawanuck must spend around 30 percent more to buy a standard selection of healthy food each month, compared with&nbsp;a family in Toronto.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/sam-hunter.jpg 300w,https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/sam-hunter.jpg 460w,https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/sam-hunter.jpg 620w,https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/sam-hunter.jpg 780w,https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/sam-hunter.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5774764.1603477193!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/sam-hunter.jpg"></p></div><figcaption>Sam Hunter paddles a canoe. <!-- --> <!-- -->(Isabel Souliere/Missinaibe Cree  )</figcaption></figure></span></p>  <p>Hunter said that he has been collaborating with Human Rights Watch for a few years, and feels that it is important for people living in the south of the country to understand what is going on.</p>  <p>"What used to take 4000 years, it's happening in decades now, it's happening really fast. We can see ... our&nbsp;peatlands thawing and the trees sinking into the ground, and the caribou&nbsp;that used to migrate in the hundreds of thousands, they're no longer here," he said.&nbsp;</p>  <p>"I think a lot of people think&nbsp;that Canada is a great place to live in. But some housing in the Native reserves is really bad. And the food they eat is terrible," he said.&nbsp;</p>  <hr>  <p><em>Written by Andrea Bellemare. Produced by Kevin Robertson.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-friday-edition-1.5774327/northern-hunter-living-hard-reality-described-in-new-report-on-climate-change-1.5774429</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910927</guid>
            <pubDate>Tue, 27 Oct 2020 19:33:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unofficial Guide to Rich Hickey's Brain]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910876">thread link</a>) | @diggan
<br/>
October 27, 2020 | http://www.flyingmachinestudios.com/programming/the-unofficial-guide-to-rich-hickeys-brain/ | <a href="https://web.archive.org/web/*/http://www.flyingmachinestudios.com/programming/the-unofficial-guide-to-rich-hickeys-brain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div class="page" id="content">
          
          <p>06 December 2012</p>
          <p><img src="http://www.flyingmachinestudios.com/assets/images/posts/rich-hickey-function.png" alt="The Rich Hickey Function"></p>
          
          <p>Part of my excitement in learning Clojure has been being exposed to
          Rich Hickey's thoughts on programming. Rich Hickey has a clear,
          consistent way of viewing fundamental programming concepts that I
          think any programmer would benefit from. Every time I watch one of his
          talks, I feel like someone has gone in and organized my brain.</p>
          
          <p>In this article (and more to come (possibly)), I begin my attempt to
          catalog Mr. Hickey's unique viewpoint. Eventually, I would like to
          produce a concise summary of his ideas. My hope is that this will
          provide an easily-scannable reference to Clojurists and an accessible
          introduction to non-Clojurists.</p>
          
          <p>What follows is derived from Rich Hickey's talk,
          "<a href="http://www.infoq.com/presentations/Are-We-There-Yet-Rich-Hickey">Are we there yet?</a>"</p>
          
          <h2>Introduction</h2>
          
          <p>Today's OOP languages - Ruby, Java, Python, etc. - are fundamentally
          flawed. They introduce
          <a href="http://en.wikipedia.org/wiki/No_Silver_Bullet">accidental complexity</a>
          by building on an inaccurate model of reality. Where they have
          explicit definitions for the following concepts, the definitions are
          wrong:</p>
          
          <ul>
          <li>Value</li>
          <li>State</li>
          <li>Identity</li>
          <li>Time</li>
          <li>Behavior</li>
          </ul>
          
          <p>Below, we'll contrast the OOP viewpoint on each of these topics with
          the Functional Programming viewpoint. But first, we'll compare the
          models of reality which underlie OOP and FP. It's this underlying
          difference which gives rise to their different approach to the topics
          above.</p>
          
          <h2>Metaphysics, Programming, and You: Comparing OOP and FP</h2>
          
          <p>When talking about metaphysics things tend to get a little fuzzy, but
          hopefully this will all make sense.</p>
          
          <p>As the ever-trusty
          <a href="http://en.wikipedia.org/wiki/Metaphysics">Wikipedia</a> explains,
          metaphysics attempts to answer two basic questions in the broadest
          possible terms:</p>
          
          <ul>
          <li>What is there?</li>
          <li>What is it like?</li>
          </ul>
          
          <p>Rich Hickey explains the difference between OOP and FP metaphysics by
          contrasting their explanations of what a river is. </p>
          
          <h3>Object Oriented Programming</h3>
          
          <p>In OOP metaphysics, a river is something which actually exists in the
          world. I know, I know, I can hear what you're saying: "Uh... yeah?
          So?" But believe me, the accuracy of that statement has caused many a
          sleepless night for philosophers.</p>
          
          <p>The wrinkle is that the river is always changing. Its water never
          ceases to flow. In OOP terms, we would say that it has mutable state,
          and that its state is ever fluctuating.</p>
          
          <p>The fact that the state of the River Object and that Objects in
          general are never stable doesn't stop us from nevertheless treating
          them as the fundamental building blocks of programs. In fact, this is
          seen as an advantage of OOP - it doesn't matter how the state changes,
          you can still interact with a stable interface and all will work as it
          should. An object can change, but to all observers it is still
          considered the same object.</p>
          
          <p>This conforms to our intuitive sense of the world. The position of the
          electrons of the coffee in my mug matters naught; the coffee still
          interacts with my taste buds in the way I expect.</p>
          
          <p>Finally, in OOP, objects do things. They act on each other. Again, this
          conforms to our intuitive sense of the world: change is the
          result of objects acting upon each other. A Person object pushes on a
          Door object and enters a House object.</p>
          
          <h3>Functional Programming</h3>
          
          <p><img src="http://www.flyingmachinestudios.com/assets/images/posts/fp-metaphysics.png" alt="FP Metaphysics"></p>
          
          <p>In FP metaphysics, we would say that we never step in the same river
          twice. What we see as a discrete <em>thing</em> which actually exists in the
          world independent of its mutations is in reality a succession of
          discrete, unchanging things.</p>
          
          <p>The "river" is not a thing in and of itself; it's a concept
          that we superimpose on a succession of related phenomena. This concept
          is very useful - I won't belabor that point - but it is just a
          concept.</p>
          
          <p>What really exists are atoms (in the sense of atomic, unchanging,
          stable entities) and processes. The river is not a stable object;
          rather, it is a succession of related atoms which are generated by
          some kind of process.</p>
          
          <p>These atoms don't act upon each other and they can't be changed. They
          can't <em>do</em> anything. Change is not the result of one object acting on
          another; change is the result of a process being applied to an
          unchangeable atom. To say that something has changed is to say, "Oh,
          there's a new atom in this stream of atoms." It's like saying that
          HEAD points to a new commit in your Git repo.</p>
          
          <p>OK! Enough with metaphysics. Now let's describe the more immediately
          useful topics, starting with Value.</p>
          
          <h2>Value</h2>
          
          <p>It's obvious that numbers like 3 and 6 and 42 are values. Numbers are
          stable, unchanging.</p>
          
          <p>It should also be obvious that OO languages have "no proper notion" of
          values in this sense. As Rich Hickey points out, you can create a
          class whose instances are composed of immutable components, but there
          is no high-level concept of immutable value implemented as a first
          class construct within the class.</p>
          
          <p>This is one of the main causes of headaches when doing OOP. How many
          times have you pulled your hair out trying to figure out how an
          object's attribute got changed? The fact is, in OO languages there is
          no built-in mechanism to ensure that the object you're dealing with is
          stable.</p>
          
          <p>This is the big reason why concurrent programming is so difficult.
          Even in single-threaded programs this is a problem, and it's one of
          the reasons why we develop sprawling test suites. You can't be sure if
          a method call on your Toupee object is somehow going to cause a change
          in your HipsterGlasses object.</p>
          
          <p>By contrast, in FP languages emphasis is placed on working with
          immutable values. Since these values can't change, a whole class of
          problems simply disappears.</p>
          
          <h2>Identity</h2>
          
          <p>In the video, Mr. Hickey says:</p>
          
          <blockquote>
          <p>The biggest problem we have is we've conflated two things. We've
          said the <em>idea</em> that I attach to this thing that lasts over time
          <em>is</em> the thing that lasts over time.</p>
          </blockquote>
          
          <p>In FP, identity is essentially a name we give to a sequence of related
          atoms. "River" refers to the sequence R1, R2, R3, etc, produced by the
          river process. This is directly analogous to HEAD in Git - it's just a
          name which is used to refer to actual values. In OO, there really
          isn't such a distinction.</p>
          
          <p>Or as the man himself says, </p>
          
          <blockquote>
          <p>Identity is a putative entity we associate with a series of causally
          related values (states) over time. It's a label, a construct we use
          to collect a time series.</p>
          </blockquote>
          
          <h2>State</h2>
          
          <p>In OO, there is no real clear definition of state. Maybe it's, "the
          values of all the attributes within an object right now." And it has
          to be "right now", because there's no language-supported way of
          holding on to the past.</p>
          
          <p>This becomes clearer if you contrast it with the notion of identity in
          FP. In the Hickeysian universe, a State is a specific value for an
          identity at a point in time. (For me, this definition really clarified
          my own thoughts.)</p>
          
          <h2>Time</h2>
          
          <p>There's no real notion of time in OO. Everything's just "right now".
          This is part of what causes problems in concurrent programs.</p>
          
          <p>By contrast, in the FP worldview we've been exploring, time is
          well-defined. Time is a by-product of ordering states within an
          identity.</p>
          
          <p>(By the way, I'd really like to write more here, and would appreciate
          any suggestions.)</p>
          
          <h2>Behavior</h2>
          
          <p>Finally, behavior. I don't have too much to write here - I might need
          to watch some more talks - but I'll include Mr. Hickey's
          thought-provoking observation:</p>
          
          <blockquote>
          <p>There is no behavior. When you get hit by lightning, who's behaving?</p>
          </blockquote>
          
          <p>This may be what inspired Steve Yegge's post,
          <a href="http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html">Execution in the Kingdom of Nouns</a>.</p>
          
          <h2>The End</h2>
          
          <p>Well, that's it for now. I hope you've found this post useful. If you
          have any suggestions, I'd love to hear them!</p>
          
          
          <h2>Comments</h2>
          
          
        </div>
      </div></div>]]>
            </description>
            <link>http://www.flyingmachinestudios.com/programming/the-unofficial-guide-to-rich-hickeys-brain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910876</guid>
            <pubDate>Tue, 27 Oct 2020 19:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blender 2.8 Launchpad]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910835">thread link</a>) | @Tomte
<br/>
October 27, 2020 | https://academy.cgboost.com/p/blender-2-8-launch-pad | <a href="https://web.archive.org/web/*/https://academy.cgboost.com/p/blender-2-8-launch-pad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-12175013">
      

        
  <div>
    <div>
      <div>
        <h2>
          <i></i>
          Frequently Asked Questions
        </h2>
        
        
        <p>
          When does the course start and finish?
        </p>
        <p>
          The course starts now and never ends! It is a completely self-paced online course - you decide when you start and when you finish.
        </p>
        
        <p>
          How long do I have access to the course?
        </p>
        <p>
          How does lifetime access sound? After enrolling, you have unlimited access to this course for as long as you like - across any and all devices you own.
        </p>
        
        <p>
          What if I am unhappy with the course?
        </p>
        <p>
          We would never want you to be unhappy! If you are unsatisfied with your purchase, contact us in the first 30 days and we will give you a full refund.
        </p>
        
        <p>
          I never used Blender before, am I able to follow this courses?
        </p>
        <p>
          Yes! This course is especially designed to help you get started, even if you don't know anything about Blender or 3D in general.
        </p>
        
        <p>
          Do I need a powerful system to run Blender 2.8?
        </p>
        <p>
          In general, Blender should also run on older systems. But when it comes to rendering, Blender 2.8 makes heavy use of your graphics card, especially when you're working with the EEVEE realtime renderer (what we will do a lot during this course). That's why we recommend to check if Blender 2.8 runs on your computer. <a href="https://code.blender.org/2019/04/supported-gpus-in-blender-2-80/">Here you can check if your graphics card is supported.</a> We also recommend <a href="https://builder.blender.org/download/">downloading the latest version of Blender 2.8</a> and check if it runs on your machine.
        </p>
        
        <p>
          Are you covering UV Mapping and Texturing in this course?
        </p>
        <p>
          To keep the content beginner friendly, we won't cover UV mapping and texturing in the main course. These topics are planned to be added in the future, as a bonus chapter. Stay tuned.
        </p>
        
        <p>
          Is this course suitable for advanced Blender users?
        </p>
        <p>
          It depends. When you feel really comfortable with Blender already, this course is probably not for you. However, if you want to make the switch from Blender 2.7x to Blender 2.8 this course can help you. Also, if you feel that after learning Blender for a while, you are still not able to bring the 3d projects to life which are in your head, this course can help you fill in the missing gaps.
        </p>
        
        <p>
          Can I get single chapters independently without buying the whole course?
        </p>
        <p>
          Sorry, this is not possible.
        </p>
        
        <p>
          Does this course work with Blender 2.9?
        </p>
        <p>
          Yes! The changes from Blender 2.8 to 2.9 won't much affect the course content. The UI of both versions are nearly identical, so you can easily follow. We also try to update outdated lessons. Also, if you get stuck, we are there to help you, just ask your questions in the comment section below the lessons.
        </p>
        
      </div>
    </div>
  </div>



      
        </div></div>]]>
            </description>
            <link>https://academy.cgboost.com/p/blender-2-8-launch-pad</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910835</guid>
            <pubDate>Tue, 27 Oct 2020 19:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tried 21 diet and exercise programs. None of them worked. Except for one]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910832">thread link</a>) | @Kortaggio
<br/>
October 27, 2020 | https://billmei.net/blog/fitness | <a href="https://web.archive.org/web/*/https://billmei.net/blog/fitness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      
      <p><img src="https://d33wubrfki0l68.cloudfront.net/f7870162b071951f3775d1abad3359269892043b/cbca1/assets/blog/img/fitness_main.jpg" alt=""></p>

<p>Deadlifting 337.5 lbs in my <a href="https://billmei.net/blog/gym-build">home gym</a>.</p>

<p>I wasted years failing at improving my health and fitness by following misguided “common sense” advice. I tried everything: P90X, cross-country running, bodybuilding, HIIT, swimming, BodBot, 2 types of yoga, CrossFit, rowing, personal training, F45, and cycling. None of them worked.</p>

<p>It seemed like everyone around me was getting results, but no matter how hard I tried, I wasn’t able to carry more things, attain a muscular physique, better outrun an emergency, or climb over a fence.</p>

<p>But after hundreds of hours of frustration and disappointment, I finally figured out what was preventing me from achieving the fitness results that I wanted.</p>

<p>I made 10 major mistakes by following “common sense” advice that hindered my progress for years. They are:</p>

<ol>
  <li><a href="#mistake-1-not-reasoning-from-first-principles">Not reasoning from first principles</a></li>
  <li><a href="#mistake-2-taking-action-instead-of-planning">Taking action instead of planning</a></li>
  <li><a href="#mistake-3-not-planning-all-the-way-until-the-end">Not planning all the way until the end</a></li>
  <li><a href="#mistake-4-doing-exercise-instead-of-training">Doing exercise instead of training</a></li>
  <li><a href="#mistake-5-listening-to-experts">Listening to experts</a></li>
  <li><a href="#mistake-6-following-a-plan-not-designed-for-me">Following a plan not designed for me</a></li>
  <li><a href="#mistake-7-not-wanting-results">Not wanting results</a></li>
  <li><a href="#mistake-8-not-gathering-information">Not gathering information</a></li>
  <li><a href="#mistake-9-using-nutrition-instead-of-mindfulness">Using nutrition instead of mindfulness</a></li>
  <li><a href="#mistake-10-not-prioritizing-recovery">Not prioritizing recovery</a></li>
</ol>

<h2 id="mistake-1-not-reasoning-from-first-principles">Mistake #1: Not reasoning from first principles</h2>

<h3 id="who">Who</h3>

<p>I learned that everyone’s body is different. A nutrition and exercise program that works for me may not work for you, or vice-versa. Our genetics, physiology, and lifestyles are not the same so do not read this article as “advice” for you. It is advice only for me.</p>

<p>For example, I use more extreme language than other articles on health and fitness, because I find it necessary to go “all or nothing” in forming habits, but this writing style may be counterproductive if it does not fit your predilection; e.g. I’ll say something like “If you miss a workout, you have to <em>start over from the beginning</em>”, and this is not technically true because you can make up for the workout later, but I need to be told that the stakes are much higher than they actually are to motivate myself to stay on track. I regret that nobody was ever this forceful with me. By being too forgiving they gave me an excuse to not take things as seriously as I should have. You may find this writing style off-putting, but I will remind you that this is written for me, not for you.</p>

<p>One way I wasted a lot of time in the beginning is assuming that other peoples’ advice can apply to me, but it can’t. What worked was to figure out what first principles apply to my situation, and then build up a strategy from there to solve my individual needs, and not copy or follow someone else’s advice from the Internet.</p>

<h3 id="why">Why</h3>

<p>Why are health and fitness important? Physical health is required to operate in the physical universe. It’s the wellspring from which all other actions depend. Therefore, to improve your cognition, mood, relationships, career, morals—work out.</p>

<h3 id="how">How</h3>

<p>Ground truth comes from physics. The irreducible first step is Force = Mass × Acceleration. This is an inviolable law of the universe. Force production is therefore the only objective performance metric. All other secondary goals (weight loss, flexibility, cardiovascular health, etc.) are therefore relevant only when they are on the critical path to improving force production.<sup id="fnref:critical-path" role="doc-noteref"><a href="#fn:critical-path">1</a></sup></p>

<p>Maintaining health is expensive, and biological organisms do not spend more resources than marginally required by their environments, because any wasteful organism will be evolutionarily outcompeted by a more resource-conserving rival. Therefore, any increase in wellness must be proportional to a preceding increase in stress. This leads us to the second step, the <a href="#mistake-4-doing-exercise-instead-of-training">Stress Recovery Adaptation cycle</a> (SRA), which I will describe later. Any strategy that does not follow this is disallowed by biology.</p>

<h3 id="mistake-2-taking-action-instead-of-planning">Mistake #2: Taking action instead of planning</h3>

<blockquote>
  <p>It’s important not to overthink things—just take action! You’ll figure it out as you go.</p>
</blockquote>

<blockquote>
  <p>No plan survives contact with the enemy.</p>
</blockquote>

<blockquote>
  <p>Just Do It.</p>
</blockquote>

<p>These are all wrong. It turns out that planning is <em>really, really</em> important. I did not expect this, but having an appropriate plan <em>makes or breaks</em> your success.</p>

<p>Based on what I learned from entrepreneurship and the “Lean Startup Approach”, I assumed that a mediocre plan with great execution is better than a great plan with poor execution. This is not true for health and fitness.</p>

<p>A mediocre plan with great execution is not better than a great plan with poor execution. A mediocre plan with great execution achieves <em>nothing</em>.</p>

<p>Good planning is the difference between achieving all your goals, and achieving <em>nothing at all</em>. Action is irrelevant to outcome.</p>

<p>The problem with bad plans is that taking the <em>wrong</em> action gives you negative progress. “Just Do It” is harmful advice, because it gives you the illusion of progress while actually accomplishing nothing, or taking you in reverse.<sup id="fnref:reverse" role="doc-noteref"><a href="#fn:reverse">2</a></sup></p>

<p>It took years for me to learn this because the vast majority of exercise programs are not good. It was only by luck that after years of trying many different programs I finally found one that worked. The probability that the average personal trainer you pick after walking into a random commercial gym can design the right program is effectively nil.</p>

<p>To understand why planning is more important than action, I have to explain four other mistakes:</p>
<ul>
  <li>Mistake #3: Not planning all the way until the end</li>
  <li>Mistake #4: Doing exercise instead of training</li>
  <li>Mistake #5: Listening to experts</li>
  <li>Mistake #6: Following a plan not designed for me</li>
</ul>

<h3 id="mistake-3-not-planning-all-the-way-until-the-end">Mistake #3: Not planning all the way until the end</h3>

<p>Strenuous exercise is not required for success in modern civilization. Thus, the vast majority of people lack any adaptation to physical stress, with the result that even a tiny amount of exercise will produce results. This gives the misleading impression that exercise is “easy” because almost anything you do in the beginning will work; but “doing anything” eventually causes you to stall out very quickly when the early progress ends, you get frustrated, and then you quit.</p>

<p>From <a href="https://billmei.net/books/practical-programming-for-strength-training/">Practical Programming for Strength Training</a>:</p>
<blockquote>
  <p>Virtually anything that makes a novice work harder than bed rest will produce positive results. As a result, many people have an erroneous impression of the quality of their training system. Single sets, multiple sets, high volume, high intensity, super slow, supersets, giant sets, gnarlmonster sets – quite literally anything resembling a training program will produce better results than no program at all in novice trainees. <strong>This is known as “the novice effect,” and must be considered when training this population.</strong></p>
</blockquote>

<p>This is what happened to me: I tried cross-country running which worked for a bit until it didn’t, then I got discouraged and quit. Then I tried P90X which also worked for a bit until it didn’t, then I got frustrated and quit. And so on ad infinitum.</p>

<p>After I understood the novice effect, I could see that the key to a successful fitness program is not about how effective it is for beginners, but about how effective it is for people at all skill levels from beginner to olympian.</p>

<h3 id="mistake-4-doing-exercise-instead-of-training">Mistake #4: Doing exercise instead of training</h3>

<p><em>Exercise</em> is about physical activity. Almost any strenuous physical action you take can be classified as <em>exercise</em>, no matter if it is helpful or harmful in the long term.<sup id="fnref:exercise-vs-training" role="doc-noteref"><a href="#fn:exercise-vs-training">3</a></sup></p>

<p><em>Training</em> is about long-term goal-directed progress. It requires that you set an objective, measurable goal you can achieve (e.g. deadlift 200lbs, run 1 mile in under 20 minutes, finish 1st in my city’s tennis tournament). If an external observer cannot unambiguously say whether you succeeded or failed at your goal<sup id="fnref:failure" role="doc-noteref"><a href="#fn:failure">4</a></sup>, then you also cannot tell whether your day-to-day actions are beneficial or harmful to your long-term goal, hence this is not <em>training</em>.<sup id="fnref:fire-your-trainer" role="doc-noteref"><a href="#fn:fire-your-trainer">5</a></sup></p>

<p>The reason for this distinction is the biological first-principle that determines whether you will succeed or fail in the long-term: the <strong>Stress Recovery Adaptation cycle</strong>.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/815fe3b43867cf07a9398a20126ed188b57f3071/be6bc/assets/blog/img/fitness_sra-primary.png" alt="One iteration of the Stress Recovery Adaptation (SRA) cycle. Performing exercise creates stress on the body, which diminishes your biological capabilities for a short time. As you eat and sleep, your body repairs itself during recovery, plus some additional extra capacity (adaptation) to handle future stress."></p>

<p>x and y axes exaggerated for emphasis in all of these graphs.</p>

<p>Performing <em>exercise</em> creates <em>stress</em> on the body, which diminishes your biological capabilities for a short time. As you eat and sleep, your body repairs itself during <em>recovery</em>, plus some additional extra capacity (<em>adaptation</em>) to handle future stress.</p>

<p>The stress is an external signal to your body that your environment must be more dangerous than it previously assumed, so your body tries to adapt to enable you to have a better chance of staying alive going forward.</p>

<p>Doing a workout that isn’t any harder than what you did before does not lead to additional adaptation, because you didn’t signal to your body that your environment is more dangerous than it previously assumed:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e279ba0e443b829d621c6490a4f5d66e69e78fa1/85ff1/assets/blog/img/fitness_sra-not-enough.png" alt="Undertraining in the Stress Recovery Adaptation (SRA) cycle. Insufficient stress creates a small drop in performance, but when you recover there is no additional adaptation above baseline. Hence, there is no performance improvement."></p>

<p>Biological organisms do not spend more resources than marginally required by their environments, because any wasteful organism will be evolutionarily outcompeted by a more resource-conserving rival. Thus, a lack of stress is a signal to your body that your environment must be safer than it previously assumed, so your body tries to conserve resources by decreasing its athletic capability:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/336a6ad7d7c8eefa02ca3dab85b92e046704afb9/ee30a/assets/blog/img/fitness_sra-atrophy.png" alt="Atrophy in the Stress Recovery Adaptation (SRA) cycle. When you skip a workout, no stress is applied, and performance slowly diminishes below baseline because your muscles atrophy. The result is a decrease in performance."></p>

<p>Conversely, too much stress that exceeds your body’s ability to recover will just result in your cells breaking down without being properly repaired:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/1fd88d0c95cbd5f093e41cdd5ac7628b54b9a72a/151b4/assets/blog/img/fitness_sra-too-much.png" alt="Overtraining in the Stress Recovery Adaptation (SRA) cycle. Too much stress creates a sharp performance drop-off that can't be recovered from properly. This leads to performance to revert to a level smaller than your original baseline, and hence is a performance decline."></p>

<p>Thus, the key to effective <em>training</em> is to carefully tune the amount of stress per <em>exercise</em> into the “Goldilocks zone” where you receive just enough stress to trigger an adaptation response, but not too much stress that you can’t recover, and not too little stress where you don’t trigger any adaptation response.</p>

<p>If you repeat this over a long time horizon, you get this classic (but incorrect!) graph that everyone draws, which you’ll see if you google this topic:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/9829068739fe825d7a72080130c41917eea6dda7/3478a/assets/blog/img/fitness_sra-wrong.png" alt="The classic diagram of the Strength Recovery Adaptation (SRA) cycle. Just as you recover to a higher baseline, you perform another workout to apply additional stress, and in order to move your fitness baseline even higher"></p>

<p>There is a key mistake made by everyone else who draws this graph. The big problem with the above diagram is that once you’ve adapted to a higher baseline, a larger amount of stress is required to trigger further adaptation!</p>

<p>Trying to exert the same stress on a higher baseline does not trigger adaptation, because your body has gotten used to it and the stress …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://billmei.net/blog/fitness">https://billmei.net/blog/fitness</a></em></p>]]>
            </description>
            <link>https://billmei.net/blog/fitness</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910832</guid>
            <pubDate>Tue, 27 Oct 2020 19:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s A14 Packs 134M Transistors/mm²]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24910778">thread link</a>) | @jonbaer
<br/>
October 27, 2020 | https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
				
<article id="post-604">
	
   
   
   <div>

   
   
      

   	
   	<div>
   		
<figure><amp-img width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9Jzg1Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>Our friends over at ICmasters have delved into the package of the Apple A14 Bionic. The die size has been unmasked, and it stands in at 88mm<sup>2</sup>. Despite cramming in 11.8 billion transistors, the die size is incredibly small thanks to utilization of TSMC’s 5nm process node.</p>



<figure><amp-img width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>The march of progress is not all rosy. Apple’s chips have historically achieved 90%+ of the process node’s theoretical density in their processors. This generation stands out by missing that mark by a large amount. A14 comes in at a cool 78% effective transistor density when compared to theoretical density. Despite TSMC claiming a 1.8x shrink for N5, Apple only achieves a 1.49x shrink.</p>



<figure><amp-img width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI2Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>This is not due to a failure of TSMC or Apple. These companies are clear leaders for the manufacturing and design of semiconductors respectively. Instead, this failure to convert theoretical to effective density stems from the slow death of SRAM scaling. SRAM is extensively used throughout a processor from registers to caches. Geoffrey Yeap of TSMC claims that the typical mobile SoC which consists of 60% logic, 30% SRAM, and 10% analog/IO.</p>



<figure><amp-img width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>TSMC’s N5 node diverges from prior shrinks by showing signs of slowing SRAM scaling. Despite being a full shrink with logic, the SRAM is a 1.35x shrink. This figure is overstated as it will end up being even lower once other the other assist circuitry is accounted for. Hence TSMC’s guidance of chip area reduction at 35%-40% with N5. SemiAnalysis expects this to be a trend that will persist with new nodes. TSMC and Samsung are already demonstrating 3D stacked SRAM which will help alleviate the issue of density.</p>



<figure><amp-img width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>3D Stacking is not the silver bullet. Cost scaling has begun slowing dramatically. With TSMC N5 wafer pricing in the ~$17k range, it is clear cost per transistor has not fallen. Even if SRAM scaling kept up, the cost per transistor would still have remained flat from N7 to N5.</p>



<figure><amp-img width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU5Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>




   	</div>

   </div>

	</article>

			
		</div></div>]]>
            </description>
            <link>https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910778</guid>
            <pubDate>Tue, 27 Oct 2020 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing mistakes happen. Here's how to resolve (or at least learn from) them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910669">thread link</a>) | @ohjeez
<br/>
October 27, 2020 | https://www.functionize.com/blog/5-survival-tips-for-when-software-testing-accidents-happen/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/5-survival-tips-for-when-software-testing-accidents-happen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/ft-button-collapse.jpg" alt="5 survival tips for when software testing accidents happen" srcset="https://www.functionize.com/wp-content/uploads/2020/10/ft-button-collapse.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/10/ft-button-collapse-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/10/ft-button-collapse-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/10/ft-button-collapse-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Serious defects happen, despite the best efforts of QA departments. Here’s what you can learn from real world screw-ups, so you can avoid making the same mistakes.</p></blockquote>
<p>Accidents in software development and testing have brought headlines ranging from hilarious to horrific. Back in 2013, for example, millions of PayPal users were tickled to learn that the long-standing online payment system had erroneously awarded more than $92 quadrillion – yes, <em>quadrillion</em> – to another user. Yet software mishaps have also been blamed for devastating incursions into credit rating services, massive billing mistakes by health insurers, and tragically, even fatal airplane crashes.</p>
<p>The rise of <a href="https://www.functionize.com/blog/the-mobile-testing-gotchas-you-need-to-know-about/">mobile devices and software apps</a> has also helped to bring software issues more out into public view. On sites like Apple’s App Store and Google Play, consumers rate mobile apps and sometimes leave bug reports, thereby themselves participating in software testing, albeit after the app has already seen the proverbial light of day.</p>
<p><a href="https://www.functionize.com/blog/3-lessons-from-big-software-failures/">Software testing accidents happen</a> all the time, and most go unheralded except by company managers, software developers and testers, and any end users directly impacted.</p>
<p>Generally speaking, companies are tightlipped about the causes of software flaws, even when the error gains public attention. If you’ve kept up with the progress of any mobile apps in online stores, you’ll see that a bug related to this-or-that was fixed in a subsequent release, although nobody would tell you why the bug got there or why it wasn’t eradicated earlier through the company’s quality assurance testing<em>.</em></p>
<p>If you’re a software developer or tester, you already know that bugs can slip through the cracks at any of the manifold stages of software testing. There can’t be a tech person on Earth, however, who’s experienced every single sort of software disaster.</p>
<p>Here are five tips gleaned from lessons learned by seasoned testers and developers, along with the nitty-gritty details on real-life examples of software projects gone awry. Let’s take the positive approach here, with the useful takeaways, rather than indulge wholly in schadenfreude.</p>
<h3>Tip #1: Enforce a culture of testing at every level</h3>
<p>“Software testing is not foolproof by any means. Apple, Microsoft, Zoom, and almost any company with an app in an app store keeps releasing updates with fixes to holes and flaws in both functionality and security,” maintains David Galownia, CEO of the <a href="https://www.slingshotsoftware.com/" target="_blank" rel="noopener noreferrer">Slingshot</a> software and app development firm.</p>
<p>“Even when companies have rigorous testing processes, problems can slip through anyway,” Galownia adds. “You’re talking hundreds of thousands of lines of code and untold numbers of different ways users can use the software. It’s impossible to test them all.”</p>
<p>If a software error is relatively innocuous and rarely evident, <a href="https://www.functionize.com/blog/improve-your-debugging-strategies/">chasing it down through testing</a> can be a highly frustrating experience, anyhow. Galownia recalls a time early in his company’s history when testers kept trying, again and again, to discover the cause of a bug in a client’s software.</p>
<p>“For a long time, we couldn’t duplicate the bug no matter what we did. We tested every scenario we could think of, tested with multiple browsers, and put multiple eyes on it,” Galownia remembers. “When we eventually did stumble on to the cause of the error, we found it happened during a unique series in which the user went forward exactly seven steps in a process, then went back exactly four steps using the backspace button, and then went forward clicking something else. Once we finally found that out, it was an easy fix.”</p>
<p>Due to all the potential complexities involved, the CEO recommends “enforcing a culture of testing at every level.”&nbsp; Testing should start with “developers testing their own code and only saying they’re done when they themselves believe they have no bugs,” &nbsp;Galownia elaborates.</p>
<p>“Ideally, at that point a QA analyst is testing, but project and product managers should also test. Designers even should test and finally the client or end users should test in an alpha or beta setting,” Galownia says. The key is to have multiple different types of people who come at your software at different angles.</p>
<h3>Tip #2: Negotiate test deadlines</h3>
<p>We don’t live in an ideal world, though. All too often, projects aren’t given as much time for testing as developers and testers think they need.</p>
<p>In one particularly egregious case, a major statewide health insurance company expanded a new software system before it was ready to go full scale. As a result, more than <a href="https://www.ciklum.com/da/blog/5-famous-software-glitches-which-could-be-avoided-with-good-testing/" target="_blank" rel="noopener noreferrer">25,000 customers were enrolled</a> in the wrong health care plans; the knowledge became public when a<a href="https://abc11.com/system-failure-blue-bross-shield-health-insurance/1158471/" target="_blank" rel="noopener noreferrer"> company whistleblower</a> approached a local TV network affiliate. Documents suggested that the insurance company management were aware of technical issues and testing delays for months, but they got impatient and deployed the software anyway.</p>
<p>Alan Zucker, founding principal at <a href="https://pmessentials.us/" target="_blank" rel="noopener noreferrer">Project Management Essentials</a>, once grappled with his own time crunch. He was managing the development of a specialized accounting program that integrated the processing of a dozen applications.</p>
<p>The accounting program Zucker worked on required the building of a processing hub that received and shared information with the other applications. The accounting process was executed daily, weekly, and monthly with specific timing requirements.</p>
<p>“Our project timeline was very short because the company needed to quickly enable this capability,” Zucker says. “We did not have time to run an end-to-end monthly test that would allow us to replicate the process. So we created a testing strategy where we simulated the processing cycle.&nbsp; Rather than having the process triggers execute based on the cycle clock, we manually executed the workflow.”</p>
<p>So far, so good. In test, everything worked fine. But executing the cycle the first time in production turned out to be a different matter. “Everything fell apart. In order to have the information loaded the application and available to the accountants by 8:00 a.m. the process first process executed at midnight and the second process kicked off at 2:00 a.m. Well, the first process did not take 30 minutes as expected. It took over two hours to complete,” Zucker recalls.</p>
<p>“The cascading impacts were disastrous,” Zucker says. “We had to take the application out of production and start over. We made the decision to execute a full end-to-end test simulating the actual daily, weekly, and monthly processing cycles.&nbsp; We spent nearly two months fixing the bugs and retesting the application suite.”</p>
<p>Zucker learned three lessons from this debacle:</p>
<ol>
<li>Creating a robust and well considered testing strategy early in the project is essential when building a complicated system;</li>
<li>Simulating a process cycle using test data is a not a substitute for real end-to-end testing;</li>
<li>Compressing project schedules to meet externally mandated timelines can be disastrous. Project managers need to negotiate deadlines and expectations with their project sponsors.</li>
</ol>
<h3>Tip #3: Users come first</h3>
<p>Software problems are often caused by not enough testing, agrees David (Grue) DeBry, CTO and co-founder at web startup company <a href="https://www.volleyapp.com/" target="_new" rel="noopener noreferrer">Volley</a>. Yet the opposite problem – too much testing – can lead to needless product delays.</p>
<p>Culprits behind excessive testing are often “code cowboys,” or “engineers going off the rails by throwing out code,” says DeBry, whose 20 years of industry experience also includes visual effects development for a string of Hollywood movies.</p>
<p>The “code cowboys” can become so driven by their own needs for meeting defined engineering processes that they lose sight of why the software is being developed in the first place.</p>
<p>“Unit tests. Smoke tests. Regression tests. The list goes on,” DeBry says. “There’s constant feature improvement. You’re unable to move forward, and testing can cause other things to happen.”</p>
<p>When in “cowboy mode,” engineers try to eliminate <a href="https://www.agilealliance.org/introduction-to-the-technical-debt-concept/" target="_blank" rel="noopener noreferrer">technical debt</a>, or what results when software teams expedite the delivery of a piece of functionality or a project which later needs to be refactored. In other words, they balk at prioritizing speedy delivery over perfect code. Cowboys want “to “pay back the tech debt now,” according to DeBry.</p>
<p>Yet teams should instead focus on the people who will use the software, DeBry maintains. “Users are humans, and engineers maybe not so much. You don’t just write code. Efforts need to be organized around what to test and where. What’s important to do? What are the users’ priorities? There’s the argument that you don’t spend time testing for something if the user doesn’t care about it.”</p>
<h3>Tip #4: Don’t neglect the negative</h3>
<p>“Only testers who do nothing make no mistakes,” echoes Bartek Nowakowski, test lead at career website <a href="https://www.geeksforgeeks.org/difference-between-positive-testing-and-negative-testing/" target="_blank" rel="noopener noreferrer">Zety,</a> “When testing big apps there are a lot of connections between functionalities, so it is easy to miss some of them.”</p>
<p>Zety has run into complications by not performing negative testing, a form of testing that checks to find out how software will behave under unexpected circumstances, such as if a user types letters instead of numbers into a phone number field.</p>
<p>“So even if functionality works as intended there can be circumstances in which incorrect or unpredicted user behavior creates an edge case situation,” says Nowakowski. “These can occur for months before someone realizes there’s an issue.”</p>
<h3>Tip #5: Doing live testing? Warn your users!</h3>
<p>A variety of industry best practices can and do get overlooked in the heat of the moment during a software crisis.</p>
<p>“After some changes to our database, we wanted to test the new elements. Unfortunately, there was an error that severed the connection between the backend and frontend,” says Reuben Yonatan, CEO of <a href="https://www.getvoip.com/" target="_blank" rel="noopener noreferrer">GetVoIP</a>. “We couldn’t connect to the database. It took a while, but our IT team found the bug and fixed it. However, we suffered disruption to our services.”</p>
<p>To GetVoIP, the incident underscored the need to always be prepared with a backup when running a software test. “That way, if something …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.functionize.com/blog/5-survival-tips-for-when-software-testing-accidents-happen/">https://www.functionize.com/blog/5-survival-tips-for-when-software-testing-accidents-happen/</a></em></p>]]>
            </description>
            <link>https://www.functionize.com/blog/5-survival-tips-for-when-software-testing-accidents-happen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910669</guid>
            <pubDate>Tue, 27 Oct 2020 19:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grafana Tempo (distributed tracing solution): A game of trade-offs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910557">thread link</a>) | @gouthamve
<br/>
October 27, 2020 | https://gouthamve.dev/tempo-a-game-of-trade-offs/ | <a href="https://web.archive.org/web/*/https://gouthamve.dev/tempo-a-game-of-trade-offs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://gouthamve.dev/content/images/size/w300/2020/10/tempo-header.png 300w,
                                https://gouthamve.dev/content/images/size/w600/2020/10/tempo-header.png 600w,
                                https://gouthamve.dev/content/images/size/w1200/2020/10/tempo-header.png 1000w,
                                https://gouthamve.dev/content/images/size/w2000/2020/10/tempo-header.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://gouthamve.dev/content/images/size/w2000/2020/10/tempo-header.png" alt="Tempo: A game of trade-offs">
                </figure>
                <section>
                    <div>
                        <p>About 2 years ago, <a href="https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/">I wrote</a><a href="https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/"> a long post</a> about why we built <a href="https://grafana.com/oss/loki/">Loki</a> and the tradeoffs we made. Now, we've just launched <a href="https://grafana.com/oss/grafana-tempo/">Tempo</a>, our tracing store, which I think takes a very unique approach to tracing. I've been raving about tracing <a href="https://grafana.com/blog/2019/09/09/how-grafana-labs-is-running-jaeger-at-scale-with-prometheus-and-envoy/">for a while now</a>, and I am <a href="https://promcon.io/2019-munich/talks/prometheus-and-jaeger-a-match-made-in-heaven/">personally a massive fan</a>! Before I dive in, I have to say that both <a href="https://twitter.com/mrannanay">Annanay</a> and <a href="https://twitter.com/actually_chores">Joe</a> did an amazing job with Tempo given the short amount of time they had and I am completely blown away, just watching from the sidelines! Amazing job team! Read the official blog and how to get involved here: <a href="https://deploy-preview-2675--grafana.netlify.app/blog/2020/10/27/announcing-grafana-tempo-a-massively-scalable-distributed-tracing-system/">https://grafana.com/blog/2020/10/27/announcing-grafana-tempo-a-massively-scalable-distributed-tracing-system/</a></p><h2 id="omg-the-index-">OMG the index!</h2><p>But tracing is not without its problems, the chief of them is cost. Most of the cost comes down to the indexing issues. You have to run <a href="https://www.jaegertracing.io/">Jaeger</a>, the leading open-source solution with either Cassandra or Elastic, both beasts of their own and extremely complex and costly to scale. The main reason to use them is because of the query and data patterns.</p><p>Traces have a varied datamodel, but fundamentally we track durations, and each of the object, called a span, we track has the following structure:</p><pre><code>spanID → string
traceID → string
functionName → string

tags → map[string]string

startTime → time.Time
duration → time.Duration

parentSpan → string (is a spanID if it has a parent span, else “” to indicate rootSpan)
</code></pre><p>Now in Jaeger, we basically have to answer a few queries, first of them is give me all the spans for a particular traceID, i.e, something like:</p><pre><code>SELECT spans WHERE traceID=XXXX</code></pre><p>Once, we have all the spans, we can reconstruct the full trace to be something like:</p><figure><img src="https://gouthamve.dev/content/images/2020/10/image-2.png" alt="" srcset="https://gouthamve.dev/content/images/size/w600/2020/10/image-2.png 600w, https://gouthamve.dev/content/images/2020/10/image-2.png 952w" sizes="(min-width: 720px) 720px"></figure><p>The second class of questions to answer is to select the traces matching a particular criteria, for example, give me all the traces emitted by the gateway for requests by user XXX on path `/home` that took more than `5s`.</p><pre><code>SELECT unique(traceIDs) 
LIMIT 1000 						[not-optional]
WHERE 
tags(user=XXX and service=gateway and operation=/home)		[optional]
duration &gt; 5s							[optional]
T1 &lt; time.start &lt; T2		</code></pre><p>Once we have all the traceIDs, we can use the query above to get all the spans for those traceIDs and we can get all the traces we want. Here in lies the problem, we need to lookup things on a set of arbitrary tags, and these tags are neither constant nor a predefined set.</p><p>Developers can and in most cases need to add 1000s of tags over the lifetime of the service, and each of these tags can have an insane cardinality, for example, the tags for userID or IPAddr have virtually infinite cardinality. To create a very efficient index is really hard, hence the dependency on Cassandra or Elasticsearch, but once you start using them, things start becoming expensive very quickly. One solution to the problem is to define a very strict set of tags with low cardinality, but the moment you start doing that you start losing out on a lot of the benefits of tracing.</p><h2 id="enter-tempo">Enter Tempo</h2><p>So, <a href="https://docs.google.com/document/d/153NHJ9RZttAMbIGUEY8x61W3TZej-jXKjOqOppJiuvc/edit">I've played around with this problem before</a> and I'm convinced that the best index for tracing is a columnar store, but hotdemn, there is not a single columnar store that is easy to operate, like Prometheus. The team went looking and realised the complexity and decided to break the problem into two parts:</p><h3 id="finding-the-relevant-traceids">Finding the relevant traceIDs</h3><p>Our biggest use case for tracing is to debug query and request performance and we realised most of our queries are of the form, give me all the traceIDs from this namespace, for this user that took longer than 5s. And tbh, the Jaeger querying <a href="https://github.com/jaegertracing/jaeger/issues/166">didn't really work for us</a> so we did the next best thing, <a href="https://github.com/weaveworks/common/pull/123">we printed out the traceID in the request logs</a> and then generated a daily report!</p><figure><img src="https://gouthamve.dev/content/images/2020/10/block-out-2.png" alt="" srcset="https://gouthamve.dev/content/images/size/w600/2020/10/block-out-2.png 600w, https://gouthamve.dev/content/images/size/w1000/2020/10/block-out-2.png 1000w, https://gouthamve.dev/content/images/size/w1600/2020/10/block-out-2.png 1600w, https://gouthamve.dev/content/images/2020/10/block-out-2.png 2271w" sizes="(min-width: 720px) 720px"><figcaption>Our daily report with the queries blurred out.</figcaption></figure><p>We basically traced and stored <em>all </em>the read path requests and then from this report, we picked the slowest queries and looked them up in Jaeger. This worked wonders, but over time, as our query load grew, we had to switch on sampling and could only store 50% of our queries. This meant when I was looking at a particularly interesting query, there is only a 50% chance I could look it up. Less than ideal, but we could live with it (for the short term ;)). We were using Loki to retrieve the logs and then had custom logic to generate this report but now with <a href="https://grafana.com/docs/loki/latest/logql/">Loki v2.0, you can basically use LogQL</a> to generate all the info in the report above!</p><p>As we started to explore how a new tracing solution would look like, we realised that we could offload the <em>discovery</em> of traceIDs to logs and metrics. For logs, the report above is enough, and in general we can figure out which traces are interesting by looking at the request logs. </p><figure><img src="https://gouthamve.dev/content/images/2020/10/image-4.png" alt="" srcset="https://gouthamve.dev/content/images/size/w600/2020/10/image-4.png 600w, https://gouthamve.dev/content/images/size/w1000/2020/10/image-4.png 1000w, https://gouthamve.dev/content/images/2020/10/image-4.png 1118w" sizes="(min-width: 720px) 720px"></figure><p>For metrics, we slowly started the work of adding exemplars into Prometheus, so that we can basically jump to a trace from a graph. A good example is the screenshot above. This is with an experimental version (<a href="https://github.com/prometheus/prometheus/pull/6635">open PR</a>) of Prometheus, you can see that the spikes in latency are only due to the very short spike (at the beginning) and the graph is over 1m, because of the <code>rate[1m]</code>. This is super interesting information already, but the killer feature is that you can click on a dot to jump to the trace for that latency!</p><p>We've been touting this holy grail of jumping between metrics, logs and traces for a while now and we decided for the first version, not having an index and powering all the lookups through Loki and Prometheus might be enough. It's an interesting experiment to run tbh, and it works quite well for us. We just have to see how others react to it, it takes <em>a lot of discipline</em>. You need to print traceIDs in your logs and expose exemplars in your applications and nothing in this workflow is commonplace.</p><h3 id="tempodb-the-kv-store-over-object-store">TempoDB: The KV store over Object Store</h3><p>Okay cool, we kinda sorta circumvented the problem of finding the right traceIDs, we still needed to figure out how to lookup the traces given a traceID. Now tracing is no small beast, you need to store a lot of information. For every single request, we need to store all the RPC calls, and the tags associated with each RPC call (namespace, pod, service, endpoint, function, etc.) <em>atleast</em> but the power of tracing is truly unlocked when you start instrumenting specific functions you're curious about and various other metadata.</p><p>This means for about 1K QPS (our query load), we're writing 170K spans/sec and and 40MB/s of data. This is insane, with a week of retention its <strong>24TB of data</strong>!<strong> </strong>Now, not a lot of storage systems can handle that load and even if they can, they're a pain to manage and build.</p><p>Going back a little, that amount of data is not new to us. We run our <a href="http://grafana.com/cloud">hosted Prometheus</a> solution on top of <a href="https://cortexmetrics.io/">Cortex</a>, which manages several hundred TB on top of Bigtable. Cortex also supports Cassandra, DynamoDB, but one problem ails all these systems: They're hard to manage and expensive to run! <a href="https://thanos.io/">Thanos</a>, another project that does long term storage for Prometheus, uses Object Storage like S3, GCS, Minio, etc. to store data. It saw a lot of adoption, even with the existence of a more mature Cortex project, and a large part of the credit goes to using Object Storage which reduces the TCO by an order of magnitude and makes the system overall much easier to use.</p><p>We've learnt from Thanos and made sure Loki could run purely off of object storage and made it super easy to use and we saw incredible success! At this point it was clear that if we wanted to build a scalable, robust but <em>inexpensive</em> tracing solution, we needed to build it on top of Object Storage. To put it in perspective, storing 24TB in GCS costs less than $500 per month! This is great, and now Cortex's new storage engine borrows from Thanos and is fully backed by an Object Store and easy to use as well!</p><p>With that decision, we needed to see what the datamodel looks like and we quickly realised that all we needed was a KV Store built on top of Object Storage. Literally the query model is to load all the spans for a <em>traceID</em>. Hence a KV store where the key is the <em>traceID </em>and the value is the blob of spans for that traceID. Now, a trace object (the collection of spans) is super small in the order of bytes to a few KB hence using the <em>traceID</em> as the key in the object store won't work, atleast not cost efficiently. We need much bigger objects for this to work.</p><p>Enter <a href="https://github.com/grafana/tempo/tree/master/tempodb">tempodb</a>, our KV store built on top of Object Store. tempodb collects the KV objects and builds them into large blocks, several 100MBs big and stores them in an object store. It has a lot of cool magic inside including bloom filters and compactions and I'll dive into it in its own blogpost.</p><h3 id="tempodb-is-not-tempo-">TempoDB is not Tempo!</h3><p>But a simple KV store won't cut it. When applications send us data, they will end up sending us individual spans, and not all the spans bunched together by traceID. We needed a system that could collect all the spans together, assemble them by traceID and store them in the Object Store. Basically we need to collect spans by the <em>traceID</em> and fortunately we have a lot of experience with this problem in Cortex (and Loki) where we needed to assemble all the samples by their metric for compression. It's a very robust and scalable system that uses a hash ring and we used the same system for Tempo. This guarantees us virtually infinite scalability!</p><p>Our docs are sparse now (we're working on them pronto!) but you can get some of the details here: <a href="https://grafana.com/docs/tempo/latest/architecture/">https://grafana.com/docs/tempo/latest/architecture/</a>. </p><figure><img src="https://gouthamve.dev/content/images/2020/10/image-5.png" alt=""></figure><p>I'll explain this in detail with the tempodb blogpost but the gist is, tempodb is a generic KV db built on top of an object store backend. In Tempo, we use it to index the high cardinality traceID field.</p><p>Now Tempo is not just the simple storage layer, but also does sampling if required and enforces retention and we are going to add more tracing specific features to it.</p><h3 id="tldr">TLDR?</h3><p>Overall, I can say this about Tempo, it's a <em>simple</em> but <em>scalable, easy to run </em>and <em>inexpensive</em> tracing store that relies on other systems for its …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gouthamve.dev/tempo-a-game-of-trade-offs/">https://gouthamve.dev/tempo-a-game-of-trade-offs/</a></em></p>]]>
            </description>
            <link>https://gouthamve.dev/tempo-a-game-of-trade-offs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910557</guid>
            <pubDate>Tue, 27 Oct 2020 18:52:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blueprints, making it easy to anonymize and balance datasets with a few clicks]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24910543">thread link</a>) | @alig90s
<br/>
October 27, 2020 | https://gretel.ai/blog/introducing-gretel-blueprints | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/introducing-gretel-blueprints">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We are launching Gretel Blueprints, making it easy to anonymize and balance datasets with just a few clicks.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x.png" alt="" sizes="(max-width: 767px) 100vw, 586.95654296875px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-500.png 500w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-800.png 800w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-1600.png 1600w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-2000.png 2000w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-2600.png 2600w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x.png 2880w"></figure><div><p>Working with developers using our <a href="https://console.gretel.ai/">Gretel beta</a> and open-source <a href="https://github.com/gretelai/gretel-synthetics">synthetic data libraries</a>, one of the top requests we have heard is developers asking us to make it incredibly simple to get started on use cases including <a href="https://gretel.ai/platform/synthetics">data anonymization</a>, <a href="https://gretel.ai/blog/fast-data-cataloging-of-streaming-data-for-fun-and-privacy">privacy engineering</a>, and <a href="https://gretel.ai/blog/improving-massively-imbalanced-datasets-in-machine-learning-with-synthetic-data">data balancing</a>. This week we are thrilled to release Gretel Blueprints. Gretel Blueprints are collections of sample code and sample datasets that utilize Gretel's SDKs that can be easily adapted to solve customer-specific use cases. </p><p>Feedback from our community has led us to believe that the application of code can actually be use case specific. &nbsp;Developers should not have to always make a series of technology decisions in order to solve a specific problem.</p><p>Just like customer use cases evolve, so will Blueprints. We will be adding new Blueprints based on new features and customer feedback- let us know on <a href="https://twitter.com/gretel_ai">Twitter</a> if you would like to see Blueprints for your use case. &nbsp;Several of our Blueprints will also have detailed blogs of their own to deep dive into the use case and more importantly, <em>how you can use Gretel to solve these challenges on your own.</em></p><p><a href="https://ctt.ac/jckQ9">Request a new blueprint on Twitter!</a></p><p>Gretel Blueprints will be accessible via <a href="https://console.gretel.cloud/">Gretel Cloud</a> and are hosted on <a href="https://github.com/gretelai/gretel-blueprints">GitHub</a>. &nbsp;Soon, when creating a Gretel Cloud Project, you will be able to choose our Blueprints as a starting template and several Blueprints will come with their own sample data. If you have a project already or are creating a blank project with your own data, the Blueprints will be available from the "Transform" page.</p><p>Once in the "Transform" page, you will be able to select any Blueprint to use with your current Gretel Cloud Project or for use with data in your own environment.</p><figure id="w-node-f6e20749aa2f-4f90fb03"><p><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860c67efde3660d36ee06_KvBJCmrzrdyXCy3ZKqbFbNgsCC3xU5UygnqoFjpF8p9hlEEfdVfE7oQXJjViHt46Oe80I-_w9HZ2TjFgi378oF80ptR-Qmoip527GCH3dhPIh4WgWaZQqmch2UR-iCwkaTynWJ6d.png" alt=""></p><figcaption>Screenshot of blueprints from the&nbsp;Gretel Console</figcaption></figure><p>‍</p><p>Like our core open source SDKs, Blueprints are hosted on <a href="https://github.com/gretelai/gretel-blueprints">GitHub</a> and licensed under Apache 2.0. We did this so customers can adopt our sample code to meet their needs specifically without being overly prescriptive on how to solve any one problem.</p><p>In the coming days, we'll be making announcements on our new Gretel Cloud workflows and releasing tutorials, walk-throughs, and even customer testimonials for many of our Blueprints. If you like it, give us a ⭐ on <a href="https://github.com/gretelai/gretel-blueprints">Github</a>! Stay tuned to our <a href="https://gretel.ai/blog">Blog</a> and <a href="https://twitter.com/gretel_ai">Twitter</a> for these exciting announcements and feel free to reach out via <a href="https://gretel.ai/cdn-cgi/l/email-protection#147c7d547366716071783a757d"><span data-cfemail="d3bbba93b4a1b6a7b6bffdb2ba">[email&nbsp;protected]</span></a>, GitHub, or social media to engage with our team!<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/introducing-gretel-blueprints</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910543</guid>
            <pubDate>Tue, 27 Oct 2020 18:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial: In-memory Git clone, commit and push using GO]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910451">thread link</a>) | @ish-xyz
<br/>
October 27, 2020 | https://ish-ar.io/tutorial-go-git/ | <a href="https://web.archive.org/web/*/https://ish-ar.io/tutorial-go-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Tutorial introduction and requirements</h2>
<p>Today’s article is a tutorial on how set up and use the go-git library to clone and update a repository with an in-memory filesystem.<br>
This procedure is quite useful if you want to push against or clone a repository without touching the OS filesystem and deal with permissions or temporary files.<br>
Albeit, there’s documentation about git-go, I find it not really clear and sometimes misleading due to the different versions and names of the library.<br>
For this reason, I’ve decided to share this tutorial, and hopefully will be helpful to someone.<br>
For the purpose of this tutorial, we will do everything inside a main.go file, however you might want something more sofisticated for your use case :)</p>
<p><strong>Requirements</strong>:</p>
<ul>
<li>An https Git repository (Github, Bitbucket doesn’t really matter as long as it’s accessible via https.)</li>
<li>Go installed and configured.</li>
<li>Basic Knowledge of Go.</li>
</ul>
<h2>Setting up the In-Memory Filesystem</h2>
<p>To set up the in-memory filesystem, we will use two packages storage and memfs.
The storer will contain the objects, references and other metadata (normally what the directory <code>.git</code> would do).<br>
The memfs filesystem will be our filesystem to read, create, remove any kind of file in our repository.<br>
First step, we need to create the two objects (the storer and the filesystem).</p>
<div data-language="text"><pre><code>package main

import (
        "fmt"

        billy "github.com/go-git/go-billy/v5"
        memfs "github.com/go-git/go-billy/v5/memfs"
        git "github.com/go-git/go-git/v5"
        http "github.com/go-git/go-git/v5/plumbing/transport/http"
        memory "github.com/go-git/go-git/v5/storage/memory"
)

var storer *memory.Storage
var fs billy.Filesystem

func main() {
        storer = memory.NewStorage()
        fs = memfs.New()

...</code></pre></div>
<h2>Setting up Git objects and Clone the repo</h2>
<p>Second step, in order to have our repository in the in-memory filesystem, we need to <strong>clone</strong> it and create the <strong>worktree</strong> object.<br>
The function <code>Clone()</code> will also return the Repository interface that we will then use to <code>Push()</code> to the remote.<br>
The method <code>Worktree()</code> will return the Worktree object that we will need to <code>Add()</code> &amp; <code>Commit()</code> our changes.<br>
Finally, if our repository is private, we would need to set up the basic authentication to clone it (We need the basic authentication to push anyway so better to set up it here!).</p>
<div data-language="text"><pre><code>...

        // Authentication
        auth := &amp;http.BasicAuth{
                Username: "your-git-user",
                Password: "your-git-pass",
        }

        repository := "https://github.com/your-org/your-repo"
        r, err := git.Clone(storer, fs, &amp;git.CloneOptions{
                URL:  repository,
                Auth: auth,
        })
        if err != nil {
                fmt.Printf("%v", err)
                return
        }
        fmt.Println("Repository cloned")

        w, err := r.Worktree()
        if err != nil {
                fmt.Printf("%v", err)
                return
        }</code></pre></div>
<h2>Create and commit your files</h2>
<p>Now, will we use the <code>fs</code> object to create an actual file, add &amp; commit it to the Worktree().</p>
<p><strong>NOTE</strong>:</p>
<ul>
<li>By default, the repository is always cloned into <code>"/"</code>. </li>
<li>For some reason (unknown to me), if the filename starts with ”/” it will create a folder and not a file.<br>E.g.: /hello/world.txt (world.txt would be a directory) hello/world.txt (world.txt would be a file inside the folder hello)</li>
</ul>
<div data-language="text"><pre><code>...

        // Create new file
        filePath := "my-new-ififif.txt"
        newFile, err := fs.Create(filePath)
        if err != nil {
                return
        }
        newFile.Write([]byte("My new file"))
        newFile.Close()

        // Run git status before adding the file to the worktree
        fmt.Println(w.Status())

        // git add $filePath
        w.Add(filePath)

        // Run git status after the file has been added adding to the worktree
        fmt.Println(w.Status())

        // git commit -m $message
        w.Commit("Added my new file", &amp;git.CommitOptions{})</code></pre></div>
<h2>Push and check errors</h2>
<p>The Push() will be performed using the method of the Repository interface as shown below.</p>
<div data-language="text"><pre><code>...

        //Push the code to the remote
        err = r.Push(&amp;git.PushOptions{
                RemoteName: "origin",
                Auth:       auth,
        })
        if err != nil {
                return
        }
        fmt.Println("Remote updated.", filePath)
        return
}</code></pre></div>
<p>Our final main.go would look like this: <a href="https://github.com/ish-xyz/ish-ar.io-tutorials/blob/master/tutorial-go-git/main.go">https://github.com/ish-xyz/ish-ar.io-tutorials/blob/master/tutorial-go-git/main.go</a></p>
<h2>Install and run our module</h2>
<p>Let’s try our new go module. Run the following commands:</p>
<div data-language="text"><pre><code>go mod init
go build
go run main.go

    Repository cloned
    ?? my-new-file.txt
    &lt;nil&gt;
    A  my-new-file.txt
    &lt;nil&gt;
    Remote updated. my-new-file.txt</code></pre></div>
<p>I know this is quite a specific topic, but I hope this tutorial will help someone!</p></div></div>]]>
            </description>
            <link>https://ish-ar.io/tutorial-go-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910451</guid>
            <pubDate>Tue, 27 Oct 2020 18:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does Apache Kafka with GitOps look like?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910344">thread link</a>) | @lefterisdvr
<br/>
October 27, 2020 | https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Infrastructure as code has been an important practice of DevOps for years.&nbsp;</p><p>Anyone running an Apache Kafka data infrastructure and running on Kubernetes, the chances are you’ve probably nailed defining your infrastructure this way.</p><p>If you’re running on Kubernetes, you’re likely using operators as part of your CI/CD toolchain to automate your deployments.&nbsp;</p><p>Adopting GitOps is natural evolution, whereby the state of your landscape is managed in Git (or any code repo) with automation systems ensuring the state of a deployment remains consistent with the repo.</p><p>Where we’ve seen a particular lack of maturity and best practices is in managing the application landscape of flows and microservices on technologies such as Kafka and Kubernetes.</p><p>GitOps is increasingly playing a big part of DataOps. DataOps promotes the accelerated delivery of data products through decentralized data governance, automation, self-service and lowering the skills required to operate data. GitOps brings standardization, governance and automation.&nbsp;</p><p>It’s a subject we’ve spoken about at a few events recently including at Kafka Summit this year and on DevOps.com:</p><p><iframe src="https://www.youtube.com/embed/iJygfiN-RR8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>What Kafka with GitOps should look like</h2><p>
When looking to automate real-time applications following DataOps, we need to be thinking about more than automating the app deployment. We need to define the correct data governance controls as part of the software delivery.&nbsp;</p><p>This means avoiding blind releasing apps where governance is an afterthought.&nbsp;</p><p>Lack of good governance will reduce the accessibility and trust in data and reduce the confidence to use the data downstream. Governance should cover the accessibility, availability, quality, integrity and confidentiality of the data.&nbsp;</p><p>We want the creator of the App, who best understands the data to be able to define the governance controls as a single package and then have it reviewed by a standard workflow.&nbsp;&nbsp;</p><p>Example: A data analyst builds their own data-processing application, but they also define the governance and compliance controls required to release it. This puts the app’s performance parameters in their hands - they decide what makes it production-ready and enterprise-grade.</p><p>When deploying Kafka on Kubernetes, it may look like this: The analyst defines the application logic in some form (such as SQL) and includes:&nbsp;</p><ul><li><p>The necessary Kafka ACLs</p></li><li><p>The data policies to mask any sensitive data</p></li><li><p>The lag and expected data throughput alerting rules</p></li><li><p>Where those events should be sent to (Slack, Pagerduty, etc)</p></li><li><p>The auditing rules to 3rd parties</p></li></ul><p>And so on...&nbsp;</p><p>This can then be pushed to Git, managed through your standard Git workflows and a merge request created, triggering a build pipeline to deploy across your different environments.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/57dTrzg6Sg6OORdvRTeebS/adef2d61514ca6b0e621c6343a22c4cf/GetYourGitOps.png" alt="GetYourGitOps"></p><p>If you’re working with Kafka and doing this, there are two areas we need to consider:</p><ol><li><p>How to define the the application &amp; governance landscape as config</p></li><li><p>How to best automate deployment in an infrastructure-agnostic and secure way.</p></li></ol><h2>Defining the App and Governance as config</h2><p>
Lenses provide a full experience for data practitioners (developers, analysts, even business users) to build real-time applications deploying on a Kafka &amp; Kubernetes data platform by ensuring all data is catalogued, made accessible and explorable.&nbsp;</p><p>The<a href="https://docs.lenses.io/4.0/tools/cli/"> Lenses CLI client</a> allows your “data landscape” to be exported as declarative configuration.&nbsp; Here’s for example a YAML file representing an AVRO schema:</p><pre>name:&nbsp;taxi_trips-value</pre><pre></pre><pre>avroSchema:&nbsp;|-</pre><pre></pre><pre>&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"taxi_trips",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"Dataset&nbsp;with&nbsp;the&nbsp;Lensicab&nbsp;taxi&nbsp;trips&nbsp;containing&nbsp;trip&nbsp;distance",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"fields":&nbsp;[</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"trip",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"fields":&nbsp;[</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"id",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"string",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;unique&nbsp;ID&nbsp;of&nbsp;this&nbsp;taxi&nbsp;ride/trip"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"date",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"string",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;date&nbsp;when&nbsp;the&nbsp;ride/trip&nbsp;happened"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"distance",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"double",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;distance&nbsp;of&nbsp;the&nbsp;taxi&nbsp;ride/trip&nbsp;in&nbsp;Km"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;]</pre><pre></pre><pre>&nbsp;&nbsp;}</pre><p>Or a Topic:</p><pre>name:&nbsp;payments</pre><pre></pre><pre>replication:&nbsp;1</pre><pre></pre><pre>partitions:&nbsp;4</pre><pre></pre><pre>configs:</pre><pre></pre><pre>&nbsp;&nbsp;cleanup.policy:&nbsp;delete</pre><pre></pre><pre>&nbsp;&nbsp;compression.type:&nbsp;lz4</pre><pre></pre><pre>&nbsp;&nbsp;retention.bytes:&nbsp;"800000000"</pre><pre></pre><pre>&nbsp;&nbsp;retention.ms:&nbsp;"4604800000"</pre><pre></pre><pre>&nbsp;&nbsp;segment.bytes:&nbsp;"8388608"</pre><p>Or a data masking rule (“data policy”)</p><pre>name:&nbsp;PersonalEmail</pre><pre></pre><pre>lastUpdated:&nbsp;"2020-03-04T14:37:17.821Z"</pre><pre></pre><pre>versions:&nbsp;0</pre><pre></pre><pre>impactType:&nbsp;MEDIUM</pre><pre></pre><pre>impact:</pre><pre></pre><pre>&nbsp;&nbsp;topics:</pre><pre></pre><pre>&nbsp;&nbsp;-&nbsp;customer_details</pre><pre></pre><pre>&nbsp;&nbsp;processors:&nbsp;[]</pre><pre></pre><pre>&nbsp;&nbsp;connectors:&nbsp;[]</pre><pre></pre><pre>&nbsp;&nbsp;apps:&nbsp;[]</pre><pre></pre><pre>category:&nbsp;PII</pre><pre></pre><pre>fields:</pre><pre></pre><pre>-&nbsp;mail</pre><pre></pre><pre>-&nbsp;email</pre><pre></pre><pre>-&nbsp;email_address</pre><pre></pre><pre>obfuscation:&nbsp;Email</pre><p>Configuration would include objects:</p><ul><li><p>AVRO Schemas</p></li><li><p>Topics</p></li><li><p>ACLs</p></li><li><p>Quotas</p></li><li><p>App Logic (as SQL or Kafka Connect config)</p></li><li><p>Monitoring alert rules (lag, throughput etc.)</p></li><li><p>Data masking rules</p></li><li><p>Secrets</p></li><li><p>Deployment definition (for example for Kubernetes or Kafka Connect)</p></li><li><p>Connections</p></li></ul><p>See<a href="https://docs.lenses.io/4.0/tools/cli/gitops/exporting/"> </a> for exporting as configuration.&nbsp;</p><h2>How to apply GitOps to Kafka and best maintain a consistent state</h2><p>
Here’s where there are a few different methods that are commonly adopted.&nbsp;</p><h3>Push Methods</h3><p>This is the method we see most organizations adopt. Teams will push to Git which will trigger a deploy pipeline in any CI/CD (such as Jenkins) using various APIs in Kafka, Kafka Connect, Kubernetes or wherever you’re running your applications. It also makes it difficult for Jenkins to monitor the desired state and ensure consistency with Git.</p><p>Of course you also need to open up the firewall to allow Jenkins into your data platform.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/74tcs9DG4E3jGe7mk34fku/3a4d4d3bd393f1de19d92d0f659ad9ff/GetYourGitOps_Pushing.png" alt="Traditional CI/CD push for Kafka automation"></p><h4>K8 Operator for Kafka</h4><p>You can use a Kubernetes operator to push the desired state. Jenkins or your CI/CD tool still needs to penetrate the data platform environment, however, which may increase security risk. Then you can use a Kubernetes operator (such as Strimzi’s) to monitor the desired state and apply the state to Kafka via APIs. This method is often used to operate the Kafka infrastructure, scale up Brokers etc. rather than to operate at the data layer (Topics, ACLs etc.)</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/47dnPqN0cGXI46XbqGx9gg/25f72efd0b1a927661c5dd0359e9916c/GetYourGitOps_K8s.png" alt="Traditional Kubernetes operator for GitOps"></p><h3>Pull Methods</h3><p>Pull methods are still based on an operator pattern, but through watching Git rather than watching Kubernetes.&nbsp;</p><p>This allows the pattern to work independently of using Kubernetes. </p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/RrcOkBDI9jgcm4KXBL9ca/73f4b286f539b47886b4854803fd7917/gitops_graffic_lenses_operator.png" alt="Lenses Operator for GitOps"></p><p>The operator is a Lenses operator which can run either inside or outside your data platform.&nbsp; The operator speaks with Lenses which applies the desired state to the data platform including any real-time applications. So for example for anyone using <a href="https://lenses.io/blog/2020/07/Why-new-Streaming-SQL-opens-up-data-platform/">Lenses Streaming SQL</a>, this would deploy the application over Kubernetes.&nbsp;</p><p>The desired state of course would have been created within a separate Lenses environment and exported as config with the CLI before being pushed into Git.&nbsp;</p><p>The benefit of this pull deployment approach is it provides a more secure environment by not needing your CI/CD to access your infrastructure, it also ensures your applications are secured, governed and audited in Git with the state actively monitored and the ability to rollback at any time.&nbsp;&nbsp;</p><p><b>You can practice GitOps in the free </b><a href="https://lenses.io/box/">Kafka+Lenses docker developer Box </a><b>now.&nbsp; If you’re interested in an early access to the Lenses Operator: get in touch with us now</b><a href="https://lenses.io/contact-us/"> by form</a><b> or via </b><a target="_blank" href="https://launchpass.com/lensesio">Slack.</a><b> </b></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910344</guid>
            <pubDate>Tue, 27 Oct 2020 18:32:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Signal User Survey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910337">thread link</a>) | @m_b
<br/>
October 27, 2020 | https://surveys.signalusers.org/s3/03fb88477ded | <a href="https://web.archive.org/web/*/https://surveys.signalusers.org/s3/03fb88477ded">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<div>
		

		
     	
		
		<div>
		<div id="sgE-5761642-1-35-box">
			<div>
		<p><img alt="" src="https://surveygizmolibrary.s3.amazonaws.com/library/700216/Type1.jpg"></p><p>
Hello! To improve Signal for everyone, we rely on voluntary user feedback that we gather via interviews, surveys, usability tests, and support requests.</p><p>
With this survey, we want to understand how you use Signal. Our survey doesn't collect any data that will identify you. If you’re interested in providing additional feedback, you'll have the option to provide contact information. We'll analyze your responses both in aggregate and individually (we promise to read any feedback you offer!). <a href="https://signal.org/blog/signal-research/" target="_blank">Learn more about Signal Research</a>.</p><p><em>By proceeding, you agree that your participation in this survey is voluntary. If you decide not to complete the survey, no personal information will be collected or shared with Signal. Your responses will be treated by Signal as confidential information. If you agree to share your personal data with Signal in the context of this study, it will only be used for the purposes of internal research and development, or for contacting you for future studies, and will be deleted after six months.</em></p></div>

			</div>
	

		
	
		<div id="sgE-5761642-1-49-box">
			<p><label for="sgE-5761642-1-49-element">
		<span>2.</span> <strong>You said you don't use Signal. If you don't mind, what's kept you from using Signal?</strong>	</label>
				</p>
							

				</div>
	</div>

		
		
		
	
	</div>
	
</div></div>]]>
            </description>
            <link>https://surveys.signalusers.org/s3/03fb88477ded</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910337</guid>
            <pubDate>Tue, 27 Oct 2020 18:32:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla's Fix the Internet Showcase]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24910188">thread link</a>) | @lightninglu10
<br/>
October 27, 2020 | https://talium.co/doc/xboZza/s/ | <a href="https://web.archive.org/web/*/https://talium.co/doc/xboZza/s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p dir="ltr">Our mission is to support founders and companies building amazing internet products that care about the health of the internet. Grow, but not at all costs. Build delightful products and retain your users, but not because you've exploited someone's addictive triggers. <span>Privacy, sustainability, inclusivity, are not something to "figure out later", but are core in the company culture. </span></p><p dir="ltr"><span>We want all of our founders building big, massive products and companies. Hopefully as big as Mozilla Firefox. We just want everyone to do it ethically.</span></p><p dir="ltr">Since our launch this Spring, weâ€™ve funded 50 amazing teams in our Incubator, and weâ€™ve mentored over 300 different projects in our Open Lab. All of these teams are working on building a better internet.</p><p dir="ltr"><span size="5">We're <b>thrilled</b> to announce the <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">Inaugural Mozilla Builders Fix The Internet Showcase</a> this Thursday, October 29 from 11:00am-12:30pm PDT.</span></p><p dir="ltr"><span>Our Showcase will feature:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘©â€�ðŸ�« Mozillaâ€™s CEO Mitchell Baker kicking us off with her thoughts on the state of the internet and What Needs Building</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ”¥ A fireside chat with founders on "Conscious Capitalism"</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span><span>ðŸ”¥ </span>Hot takes from Mozilla builders and mentors (incl. Rotten Tomatoes founder Patrick Lee, and others) on â€œHow To Build A Better Internetâ€�!  </span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘¥ Weâ€™ll be showing off the top projects weâ€™ve funded through our Incubator and helped along through our Open Lab.</span></p></li></ul><p dir="ltr"><span>Featured companies are building </span><a href="https://shopneutral.io/" target="_blank">Honey for carbon offsets</a>,<span> </span><a href="https://www.thekanary.com/" target="_blank">Swiffer for personal data</a><span>, high interest savings through crypto, </span><a href="https://www.inmotion.app/" target="_blank">Superhuman for the browser</a><span>, </span><a href="https://www.bravedns.com/" target="_blank">next-gen DNS resolvers</a>, top tech publication <a href="https://hackernoon.com/" target="_blank">Hacker Noon</a>, decentralized farming networks, and <a href="https://builders.mozilla.community/alumni.html" target="_blank">so much more</a>.</p><p dir="ltr"><span>Some of the problems our teams are solving include:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>How do we shift the balance of power from centralized forces back towards individuals, citizens and communities?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build a new way to communicate online that favors privacy and people? How do we make platforms safe for usersâ€™ voices while protecting their personal and professional interests? What needs to evolve?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build new business models for messaging, social networking, news and information that donâ€™t rely on excessive data mining or hijacking our attention?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>What will the next evolution of the internet networkâ€™s architecture and infrastructure look like?  How can decentralized technologies move the internet further towards the edge and the people?</span></p></li></ul><p dir="ltr"><span>With missions that large, it may feel like we need to rewire everything... but getting started doesnâ€™t have to be overwhelming.</span></p><p dir="ltr"><span>So if you want to learn from our </span><a href="https://builders.mozilla.community/?utm_source=www.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=builders-redirect" target="_blank">amazing mentors</a> and founders, or if you're a startup and want to learn more about our $75k and $16k funding opportunities, <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">come join us at the event</a>!</p><p dir="ltr"><span>If you're also a concerned internet citizen, help us spread the word by sharing the event with one or two of your friends. </span></p><p dir="ltr"><span>We're also doing a giveaway on Twitter of our </span><a href="https://twitter.com/mozillabuilders/status/1319380829303238656" target="_blank">Mozilla Builders Fix-The-Internet swag box</a><span>. All you need to do is </span><a href="https://talium.co/doc/xboZza/s/I'm%20going,%20are%20you?%20%20On%20October%2029th,%20join%20@mozillabuilders%20and%20@mozilla%20CEO%20and%20Founder%20@MitchellBaker%20for%20their%20inaugural%20Fix%20the%20Internet%20Showcase%20to%20learn%20from%20entrepreneurs%20and%20mentors%20on%20how%20to%20build%20a%20better%20net%20for%20all!%20RSVP:%20https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">tweet this tweet</a>, and <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">RSVP for the showcase</a> <span>to be eligible to win.</span></p><p dir="ltr">See you at our Showcase!</p><p dir="ltr">p.s. this post was written on&nbsp;<a href="http://talium.co/" target="_blank">talium.co</a>, one of the awesome products from our Summer batch!</p></div></div>]]>
            </description>
            <link>https://talium.co/doc/xboZza/s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910188</guid>
            <pubDate>Tue, 27 Oct 2020 18:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CS294: Building User-Centered Programming Tools]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909944">thread link</a>) | @azhenley
<br/>
October 27, 2020 | http://schasins.com/cs294-usable-programming-2020/ | <a href="https://web.archive.org/web/*/http://schasins.com/cs294-usable-programming-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>
 We are committed to creating a learning environment welcoming of all students that supports a diversity of thoughts, perspectives and experiences and respects your identities and backgrounds (including race, ethnicity, nationality, gender identity, socioeconomic class, sexual orientation, language, religion, ability, and more.) To help accomplish this:
</p><ul>
<li> If your name and/or pronouns differ from those that appear in your official records, please let us know.</li>
<li> If you feel like your performance in the class is being affected by your experiences outside of class (e.g., family matters, current events), please don’t hesitate to come and talk with us.  We want to be resources for you.</li>
<li> We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. You may also contact the department’s Faculty Equity Advisor Prof. Fox (fox@berkeley.edu).</li>
<li> As a participant in this class, recognize that you can be proactive about making other students feel included and respected. </li>
</ul> 

 
<p>
 We honor and respect the different learning needs of our students, and are committed to ensuring you have the resources you need to succeed in our class.  If you need religious or disability-related accommodations, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please share this information with us as soon as possible. You may speak with either instructor privately after class or during office hours.  Also see DSP under “Resources.”
</p>
</div><div>

<p>
Grades for this course will be based on:
</p><ul>
<li> Assignments: 40% (All assignments weighted equally)</li>
<li> Final project: 60%</li>
</ul> 

 
</div><div>

<div>
<p>
(<a href="https://www2.eecs.berkeley.edu/eecs-peers">https://www2.eecs.berkeley.edu/eecs-peers</a>)  Fellow EECS grad students doing peer mentoring!  EECS Peers aims to provide a private, independent, open-minded, and supportive ear and to serve as a resource to other students who are navigating issues with classes, advisors, exams, stress, and conflict.
</p></div>

<div>
<p>                            	
The Center for Access to Engineering Excellence (227 Bechtel Engineering Center;
<a href="https://engineering.berkeley.edu/student-services/academic-support">https://engineering.berkeley.edu/student-services/academic-support</a>) is an inclusive center that offers study spaces, nutritious snacks, and tutoring in &gt;50 courses for Berkeley engineers and other majors across campus.  The Center also offers a wide range of professional development, leadership, and wellness programs, and loans iclickers, laptops, and professional attire for interviews.  
</p></div>

<div>
<p>
The Disabled Student’s Program (260 César Chávez Student Center #4250; 510-642-0518;  <a href="http://dsp.berkeley.edu/">http://dsp.berkeley.edu</a>) serves students with disabilities of all kinds. Services are individually designed and based on the specific needs of each student as identified by DSP's Specialists. 
</p></div>

<div>
<p>   	
The main University Health Services Counseling and Psychological Services staff is located at the Tang Center (<a href="http://uhs.berkeley.edu/">http://uhs.berkeley.edu</a>; 2222 Bancroft Way; 642-9494) and provides confidential assistance to students managing problems that can emerge from illness such as financial, academic, legal, family concerns, and more. 

To improve access for engineering students, a licensed psychologist from the Tang Center also holds walk-in appointments for confidential counseling in 241 Bechtel Engineering Center (check here for schedule: <a href="https://engineering.berkeley.edu/student-services/advising-counseling">https://engineering.berkeley.edu/student-services/advising-counseling</a>).  
</p></div>

<div>
<p>
The Care Line (510-643-2005; <a href="https://care.berkeley.edu/care-line/">https://care.berkeley.edu/care-line/</a>) is a 24/7, confidential, free, campus-based resource for urgent support around sexual assault, sexual harassment, interpersonal violence, stalking, and invasion of sexual privacy. The Care Line will connect you with a confidential advocate for trauma-informed crisis support including time-sensitive information, securing urgent safety resources, and accompaniment to medical care or reporting.
</p></div>

<div>
<p>                                  	       	
The Ombudsperson for Students (102 Sproul Hall; 642-5754; <a href="http://students.berkeley.edu/Ombuds">http://students.berkeley.edu/Ombuds</a>)  provides a confidential service for students involved in a University-related problem (academic or administrative), acting as a neutral complaint resolver and not as an advocate for any of the parties involved in a dispute. The Ombudsman can provide information on policies and procedures affecting students, facilitate students' contact with services able to assist in resolving the problem, and assist students in complaints concerning improper application of University policies or procedures. All matters referred to this office are held in strict confidence. The only exceptions, at the sole discretion of the Ombudsman, are cases where there appears to be imminent threat of serious harm.
</p></div>

<div>
<p>	
The UC Berkeley Food Pantry (#68 Martin Luther King Student Union; <a href="https://pantry.berkeley.edu/">https://pantry.berkeley.edu</a>) aims to reduce food insecurity among students and staff at UC Berkeley, especially the lack of nutritious food. Students and staff can visit the pantry as many times as they need and take as much as they need while being mindful that it is a shared resource. The pantry operates on a self-assessed need basis; there are no eligibility requirements.  The pantry is not for students and staff who need supplemental snacking food, but rather, core food support.
</p></div>

</div></div>]]>
            </description>
            <link>http://schasins.com/cs294-usable-programming-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909944</guid>
            <pubDate>Tue, 27 Oct 2020 17:50:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Microservice Catalog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909803">thread link</a>) | @anishdhar
<br/>
October 27, 2020 | https://www.getcortexapp.com/post/taming-your-microservices | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/taming-your-microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Organizations that operate microservices/service-oriented architecture face a variety of technical and people related problems. Over the past few years, companies have been migrating massive monolithic applications into smaller microservices (think services that do one thing, like <em>archive a pdf</em>) or even service oriented architectures (e.g. service-per-domain, <em>payments, billing, auth</em>).</p><p>There are undoubtedly many issues that come from monolithic architectures: easy to tightly couple domains and data, slower deployment process, and long test runs to name a few. Breaking the monolith can seem like a panacea for these issues. An SOA can provide team level ownership of domains and their systems, data is decoupled, and features/fixes can be deployed separately. Unfortunately, a SOA comes with its own set of issues.</p><p>Monoliths have been around for a while. There's a lot that's been written about "taming the monolith". As we get to work building Cortex, we've been talking to engineers about their experiences dealing with microservice architectures. Here's some things we've learned about taming your microservices.</p><p>A monolith, for all its warts, is simple to reason about. There are no network calls. There's no overhead to calling a function elsewhere in the codebase. If you're using a typed language, you can catch API changes at compile time. All the code is in one place – if you're so inclined, you can easily peek under the hood.</p><p>An SOA brings with it a suite of technical challenges, including operational complexity and performance hits. You now have to think about:</p><ul role="list"><li>Network latency</li><li>API versioning - what if the payments team makes a breaking change to its API without notifying me?</li><li>Network issues - what happens if I don't receive confirmation that the payment went through?</li><li>Change management/releases - when an issue occurs</li></ul><p>Yet, these technical challenges are the least of your worries.</p><h2>PEBCAK - Problem exists between chair and keyboard</h2><p>While it may sound strange to think that cultural and people problems are a significant challenge stemming from architectural choices, keep in mind that most organizations move to an SOA to scale their team, not their software.</p><p><strong>Distributing ownership of domains, data, and release cadence across services and teams can increase the velocity of your engineering org.</strong></p><p>Unfortunately, distributing ownership does just that - teams start diverging in their operational procedures, documentation practices, and more. As an organization scales, this can wreak havoc on productivity, and ultimately bring your velocity back to square one.</p><p>People, process, and cultural issues around service oriented architectures have far reaching consequences:</p><ul role="list"><li>Ramping up engineers becomes costly - each team maintains their own processes. An engineer moving between teams may have to learn as much as a brand new hire.</li><li>Operational triage takes longer - tribal knowledge dissipates as an organization grows, making it harder to answer questions such as: what services exist, what they do, and who owns them</li><li>Communication overhead between teams - oversharing information is noisy, undersharing (e.g. when making API changes) can, in the worst case, cause outages or functionality issues and directly impact the bottom line</li></ul><p>Looking to scale your team? It's time to start thinking these challenges and how you can counter them.</p><p>There's no silver bullet to solve these problems. No combination of tools or processes can protect you. However, prevention really is better than the cure.</p><p>Think of it like a flu shot - you know its flu season, getting the flu sucks, and even though you may still get the flu, you'll never regret setting yourself up for success.</p><h2>Spec first design</h2><p>An excellent habit to promote is thinking about APIs and data models before jumping into the implementation.</p><h3>API Design</h3><p>It's important to ensure your SOA doesn't turn into a <em>distributed monolith</em>.</p><p>Signs of a distributed monolith:</p><ul role="list"><li>No separation of concerns</li><li>Shared databases and data models</li><li>Releasing one service requires coordination of deploys across multiple other services</li><li>Consuming a service's APIs requires knowledge about its data models, side effects, etc</li></ul><p>One way to prevent this is following the Amazon model - APIs are the only way teams communicate. This means that a service owner should:</p><ul role="list"><li>Think about their API request/responses <strong>before implementation</strong></li><li><strong>Share the API for review</strong> so that use cases for dependents are well covered</li><li><strong>Communicate API changes</strong> ahead of time</li><li><strong>Version their APIs</strong> to maintain backwards compatibility</li></ul><p>This workflow provides additional benefits when used in conjunction with tooling, such as OpenAPI or gRPC. If schemas and APIs are designed ahead of time, you can use:</p><ul role="list"><li><strong>Code gen</strong> for clients across different languages</li><li>Catch breaking changes to your API at <strong>build time</strong></li><li>Use your code review process to loop in the right stakeholders <em>before a change is released</em></li><li><strong>Contract testing</strong> to ensure you don't go out of compliance with your predetermined schema</li></ul><figure id="w-node-9def8f3c3ff0-f078b551"><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5ecd2f3387ce026d1c67c8e6_JqjXbRYzUWfOUOAN.png" alt=""></p></figure><p>Atlassian is an example of successfully using spec-first API design to improve their development lifecycle. I found <a href="https://www.atlassian.com/blog/technology/spec-first-api-development"><strong>https://www.atlassian.com/blog/technology/spec-first-api-development</strong></a> to be an excellent overview of using OpenAPI as the tooling to enable spec-first development.</p><h3>Data models</h3><p>The breaking point for a monolith is when multiple teams start depending on the same data models across domains. This slows down the development cadence across the org and the resulting spaghetti data models make it exponentially more difficult to reason about the code base.</p><p>It's easy to go down the same route in an SOA as well. There are some habits that help prevent this nightmare:</p><ul role="list"><li>Separate data stores for each service</li><li>Thinking carefully about data models and links before implementing APIs</li><li>Reducing dependencies at the data level between services - for example, store reference IDs to resources in a different service, and fetch data through their API</li><li>Ensuring stakeholders (business, developers, service consumers) don't build tooling directly on your data. This locks in your data model and prevents you from iterating as a service owner. Instead, expose data (with its own contract) through APIs or analytical data streams.</li></ul><h2>Standardization of platform/process</h2><p>There's one obvious solution to "each team doing things their own way" - make it easy for teams to do things in a standardized way.</p><p>Atlassian, for example, has built out an internal PaaS that is essentially a thin wrapper around AWS. By doing so, developers are provisioned their desired resources but the platform automatically augments it with standard monitoring, logging, and more.</p><p>Well designed tooling that provides a standard way of doing things speeds up developer velocity and makes sure teams are working in consistent ways.</p><p>This even extends to documentation. Spotify and Atlassian have built internal tooling that standardizes information discovery around their microservices. System-Z at Spotify and <a href="https://blog.developer.atlassian.com/why-atlassian-uses-an-internal-paas-to-regulate-aws-access/"><strong>Microscope at Atlassian</strong></a> provide a source of truth for details about each service, such as system ownership, links to documentation/runbooks, and recent deploys. What makes them even more powerful is that they are the entrypoint into further information about services – on-call rotations, links to monitoring dashboards, logging, etc.</p><figure id="w-node-a1aa57605d7f-f078b551"><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5ecd2f37ddc5afe80353230b_vpQZUjpsspzaKCVQ.png" alt=""></p></figure><p>This kind of standardization of information improves engineering ramp up time and operational efficiency - all services are operated in the same way and developers have a single source to look for critical information about their services.</p><p>Many organizations end up building an internal service registry for humans after the problem has gotten out of hand – too many services, growing teams and turnover, remote developers, etc.</p><p>Cortex provides a standard, opinionated way to organize information about all of your services and enables functionality such as:</p><ul role="list"><li>A dashboard to answer questions such as "what services exist?", "who owns this service?", "where are the runbooks for this service?"</li><li>An audit report that shows you the health of your services: does every service have an owner, an oncall rotation, etc.</li></ul><figure id="w-node-66b03bd1403c-f078b551"><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5ecd2f3276ebd32f1e32f034_YyoCvebvNYItDndV.png" alt=""></p></figure><ul role="list"><li>Integrations with third party tools - for example, when Pagerduty triggers an alert, Cortex can send a slack message with information about the service such as ownership, latest commits from github, latest deploys, and more.</li></ul><p>Reach out to us on our home page to request a demo, we'd love to show you what we've built and help prevent some of the headaches that come with a service oriented architecture. Onboard to a modern microservice catalog today!</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.getcortexapp.com/post/taming-your-microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909803</guid>
            <pubDate>Tue, 27 Oct 2020 17:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is your product the best in the world?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909716">thread link</a>) | @rjyoungling
<br/>
October 27, 2020 | https://www.younglingfeynman.com/essays/cheating | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/cheating">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ef3716540dd87cc37e7d"><div><p>Most founders are okay at 1 thing (which is bad) or okay at several things (which is even worse).</p><p>Look at it from the perspective of the consumer. Why on Earth would they pick you if there are <a href="https://www.younglingfeynman.com/essays/differentiation?rq=mountain" target="_blank">so many better alternatives</a>? And if, for some reason they did, why would they become repeat customers, let alone, fans?</p><p>Forget about being okay at 10 things. Focus on being the best in the world at 1 thing.</p><p>That’s actually much more doable than you think if you approach it the right way.</p><p><strong>DO LESS, BETTER</strong></p><p>We already started cheating, simply by throwing 90% of ‘’the homework’’ in the bin. And just picked 10% to work on.</p><p>It’s not hard to be the best if you’re the only one doing it.</p><p><strong>EXPLOIT GEOGRAPHICAL CONSTRAINTS</strong></p><p>Another way to cheat is to realize ‘’the world’’ doesn’t mean the entire planet. It just means your world.</p><p>No one travels further than a few miles to get a haircut which means your barber’s competition is geographically constrained. [1]</p><p><strong>EXPLOIT UNDERSERVED MARKETS</strong></p><p>You can simply pick an area that’s neglected.</p><p>I.e. No one was making delicious protein bars before <a href="https://www.questnutrition.com/" target="_blank">Quest</a>, or bone broth before <a href="https://www.kettleandfire.com/" target="_blank">Kettle &amp; Fire</a>.</p><p>Both of them could relatively easily become the best in the world because no one else was serving that respective audience.</p><p><strong>REFRAME YOUR WEAKNESS INTO A STRENGTH</strong></p><p>Netflix didn’t have any stores, unlike Blockbuster. But that lack of overhead actually allowed them the freedom to do things like ship DVDs and later, build an online platform. While at Blockbuster, their stores were actually a big part of their business model. Upsells with food, late fees with movies, and so on.</p><blockquote><p>‘’It is difficult to get a man to understand something, when his salary depends upon his not understanding it!”</p><p>-Upton Sinclair</p></blockquote><p>Something similar holds in business.&nbsp;</p><blockquote><p>‘’It’s difficult to get a CEO/board  to change the company’s business model when the short-term revenue relies on them not changing it.’’</p></blockquote><p><strong>SOLVE THE PROBLEM BETTER</strong></p><p>We can use Professor Christensen’s ‘’jobs to be done.’’ What is the job a product is being hired to do by the consumer/user?</p><p><a href="https://eu.ring.com/?gclsrc=aw.ds&amp;&amp;utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=NL_English_Search_Brand_Core_Exact_Google_CPC&amp;utm_content=Core_Exact+%2F+ring&amp;utm_term=ring&amp;gclid=Cj0KCQjwit_8BRCoARIsAIx3Rj4Q8ULDGh6zosjfW13kdpQmhvT4Qd_-Yl27c17JnceooMSUMEv7LqoaArpEEALw_wcB" target="_blank">Ring </a>(the doorbell) is supposed to solve security. But <a href="https://techcrunch.com/2017/04/28/deep-sentinel-raises-7-4m-to-bring-deep-learning-to-home-security/" target="_blank">Deep Sentinal</a> realized that footage doesn’t prevent property crimes, it just allows you to have a cute video after the fact. They created a real-time security system, that’s constantly being monitored in order to actually be able to prevent crimes from occurring.</p><p>I often hear non-founders say things like ‘’Easy for them to say because X.’’ But we all have advantages because we’re all different.</p><p>Remember the step from fact aggregation to benefit transformation in <a href="https://www.younglingfeynman.com/essays/salesletter3" target="_blank">Alchemy: Turning Words Into Money Part — 3</a>?</p><p>I showed you that, in creative, anything can be turned into a positive if you just frame it the right way.</p><p>A car is light: It’s fast, fun, and attracts cute girls.</p><p>A car is heavy: It’s a smooth, comfortable drive, that’s safe for the whole family.</p><p>Airbedandbreakfast: Come sleep on an airbed with 2 broke designers that can’t pay rent vs. Connect with other designers that’ll show you around the city.</p><p><em>More in the Airbnb series: </em><a href="https://www.younglingfeynman.com/essays/airbnb" target="_blank"><em>The Dumbest Startup That Ever Worked — What You Can Learn From Airbnb</em></a><em>.</em></p><p>It’s all just a matter of perspective. Category 4 of <a href="https://www.younglingfeynman.com/essays/reframing?rq=dutch%20school" target="_blank">Dutch School</a>: Context Changing.</p><p>A very important cheat is to create a product that a tiny audience loves rather than a product that a huge group is ambivalent about. [2] You’ll have an easier time identifying and creating something great in a small group than in a big group. And it’ll scale easier.&nbsp;</p><p>So:</p><blockquote><p>‘’Make something that’s WOW!! not eh…’’</p></blockquote><p><em>Some essays on this topic: </em><a href="https://www.younglingfeynman.com/essays/ten" target="_blank"><em>Ten</em></a><em>, </em><a href="https://www.younglingfeynman.com/essays/chair3?rq=chair" target="_blank"><em>The Third Chair</em></a><em>, </em><a href="https://www.younglingfeynman.com/essays/livewithout?rq=hard%20to%20live%20without" target="_blank"><em>Create A Product That’s Hard To Live Without</em></a><em>, </em><a href="https://www.younglingfeynman.com/essays/deeplove" target="_blank"><em>Do You Have Customers Who Deeply Love You?</em></a></p><p><em>[1] </em><a href="https://www.instagram.com/demeesterbarbier/?hl=en" target="_blank"><em>My barber</em></a><em> of 7 years, was one of maybe 3 barbershops to brand themselves as an old school men’s only barbershop. I was looking for a place that did 60s haircuts. Like the old school executive contour but with a skin fade.&nbsp;</em></p><p><em>They were the only ones in my city to do that. On top of that, they specialized in old school men’s haircuts and offered less than a dozen haircuts. It’s not hard to be the best when you have no competition and only have to do a dozen haircuts vs. hundreds. This is cheating!</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603817247586_33129"><div><p><em>[2] Paul Buchheit on going deep vs. broad.</em></p><blockquote><p>Right. So, one of the ideas is when you’re starting out building something new, especially if you’re going into an established category, like email, literally email was like 30 years old, when we started on it, right?</p><p>So there is a lot of history and a lot of opinions about how email should be, and people would sometimes angrily tell me, I’m doing it wrong, because we made the reply on top instead of the bottom, weird stuff like that.</p><p>And so there’s all this history. So it’s pretty much impossible to enter a space like that, and make a thing that appeals to everyone.</p><p>And if you try to do that, what you end up making is just a mediocre product that nobody really loves.</p><p>And so my philosophy and what we try to get all the startups to do is figure out a thing that will just have really deep appeal, even if it’s to a tiny fraction of people, if you can make that small fraction of people just obsessively love what you’re doing, it’s easier to then grow that group, because, there’s always people at the margin, where if I just make something slightly better, they’re going to join into that group.</p><p>So it’s easier to start with that like that deep but narrow appeal, and then broaden it over time than it is to start with just broad meh, and then try to convert people from meh to loving your thing in mass.</p></blockquote></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/cheating</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909716</guid>
            <pubDate>Tue, 27 Oct 2020 17:31:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Add Text to PDF Online]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24909599">thread link</a>) | @perrys
<br/>
October 27, 2020 | https://www.goodannotations.com/tools/add-text-to-pdf?ref=hackernews | <a href="https://web.archive.org/web/*/https://www.goodannotations.com/tools/add-text-to-pdf?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Add text to PDF like a business professional</h2><p>People judge books by their covers, and that is true for the digital world too. Your document format speaks volumes before the eyes ever glaze the title. In a business setting, If you’re not using PDF, you’re guilty of amateurism until proven otherwise. That’s why HR departments, Startup founders, freelancers, and rising talents add text to PDF to exchange serious communication.</p><h2>Write on PDF to stay organized and productive</h2><p>Typing on a PDF was always a troublesome task that would often end up with a call to the IT department. And that’s just awful. You’re losing both the time and mental bandwidth to do the actual work. Also, people in IT probably dislike your face if you’re nagging them to be your PDF editor.</p><p>‍<br>Choose a PDF document that needs extra words, and upload it to Good Annotations. Then, focus on your title, subtitle, text body, and callouts for important elements. Let the IT side and geeky tasks to us! </p><h2>Use red callouts to edit pdf for immediate attention</h2><p>The PDF editor comes with an array of tools that will help you add text to pdf. Once your file is online, choose the red text note, and draw attention in a mannered and robust way, without sounding unhinged with all caps or exclamation marks. Nobody likes to be screamed at through the screen. With the right callout, you can communicate in a robust and impactful way via your pdf documents. </p><h2>Add yellow callouts to PDFs for vibe and appreciation</h2><p>Bring out the right vibe with the right note. Nothing speaks,<em> I appreciate you</em>, better than an energetic yellow note under a well-done task. Your team members, employees, and employers all seek affirmation and appreciation. Tell them what’s good by adding a yellow callout to your PDF document.</p><h2>Add text to PDF with an entirely online PDF editor</h2><p>You don’t have to be boxed at your desk with your back bent and face inched away from the screen. Add text to pdf entirely online via Good Annotations from anywhere in the world, and any room, table, or street. Add text to pdf on trams, tubes, and tractors. Don’t drive and write on pdf, thought. That’s illegal. </p><h2>Write on PDF across all devices and gadgets</h2><p>If you can open Google, you can use Good Annotations, and if you can use Good Annotations, you can write on PDF from your device. Fire up any laptop, PC, tablet, smartphone, smart TV, or even a smart mirror and add text to your PDF.</p><h2>Fully free and beyond easy to use PDF editor </h2><p>Write on your pdf files for free. Entirely free, without ever having to leave a bank card, PayPal details, or provide your billing address. You can add text to PDF for free with effortless tools from the library.</p><p>We might charge for different features sometimes in the future, though. We’re working to bring you advanced tools for workflow, collaborative editing, and organized document libraries. Premium tools are mostly for bigger business users that require complicated tasks. If you’re just a guy with a laptop, you probably won’t ever have to pay to add text to your PDFs.<br></p></div></div></div></div>]]>
            </description>
            <link>https://www.goodannotations.com/tools/add-text-to-pdf?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909599</guid>
            <pubDate>Tue, 27 Oct 2020 17:22:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909579">thread link</a>) | @headalgorithm
<br/>
October 27, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let’s talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as “a place for just a single type argument”.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express “nested” types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let’s try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let’s try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really it starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don’t have to put everything into a single namespace</li>
</ul>

<p>Let’s try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we’ve achieved our goal, haven’t we? But, there’s a new problem. We have to manually list all possible cases in a function’s signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let’s see what happens for <code>Tuple</code> which is not listed in the function’s overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That’s where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There’s also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function’s type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let’s see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here’s <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let’s build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let’s say we want to apply a function to the value inside boxes and bags. Let’s use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won’t not exist during runtime. Only during type-checking.</p>

<p>Now, let’s change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Calla…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909579</guid>
            <pubDate>Tue, 27 Oct 2020 17:21:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an essay recommender system in 10 days]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909509">thread link</a>) | @jacobobryant
<br/>
October 27, 2020 | https://findka.com/blog/essays-implementation/ | <a href="https://web.archive.org/web/*/https://findka.com/blog/essays-implementation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently finished the MVP for an idea I had last month: <a href="https://essays.findka.com/" target="_blank">Findka Essays</a>, a newsletter that adapts to your preferences with machine learning. I pivoted to this from a much more complicated recommender system app, so I was already familiar with (almost) all the parts needed to build it. I'm extremely happy with the result: the new app is simple, the codebase is clean, and I launched it in under two weeks. In the grand tradition of our people, it is now time for an architecture + toolkit walkthrough. Feel free to skip to whichever sections interest you most. If you read only one section, I suggest <a href="https://findka.com/blog/essays-implementation/#recommendations">Recommendations</a>.</p><p>Note: I've abstracted a lot of the code into <a href="https://findka.com/biff">Biff</a>, a web framework I released several months ago. I'll reference Biff frequently.</p><ul>
<li><a href="https://findka.com/blog/essays-implementation/#language">Language</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#front-end">Front end</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#authentication">Authentication</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#crud">CRUD</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#recommendations">Recommendations</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#devops">Devops</a></li>
<li><a href="https://findka.com/blog/essays-implementation/#analytics">Analytics</a></li>
</ul><hr><h3 id="language">Language</h3><p>The vast majority of the app is written in Clojure (the only exception is the actual recommendation algorithm, which is written in Python). Clojure is a fabulous language that has a strong emphasis on simplicity and stability, which makes codebases easy to maintain and extend in the long run. As a Lisp, it also has an extremely tight feedback loop which is great for rapid development.</p><p>There is a trade-off: since Clojure focuses on long-term concerns over short-term concerns, it can take a while to get up to speed (though it's a lot easier if you have a mentor). For example, to do web dev in Clojure, you'll need to learn how to piece together a bunch of individual libraries—there isn't a go-to framework like Rails or Django. (<a href="https://luminusweb.com/" target="_blank">Luminus</a> is probably the best starting point, after you're familiar with the language itself).</p><p>In most cases, I'd say the trade-off is well worth it. But for small or experimental apps (like you might build in a startup), speed at the beginning is extra valuable. If you want to move fast right away but you're not already comfortable in the Clojure ecosystem, you might have a bad time. One of my goals for Biff is to help mitigate that.</p><h3 id="front-end">Front end</h3><p>OK, now for some actual code. Findka Essays, unlike its predecessor, is a humble multi-page application. No React here. So the front end is pretty simple.</p><p>(For brevity, I'll call it "Findka" from here on out).</p><p>I use <a href="https://github.com/tonsky/rum" target="_blank">Rum</a> for HTML generation. Here's a quick example:</p><pre><code>(ns hello.world
 (:require
   [rum.core :as rum]))

(defn -main []
  (spit "hello.html"
    (rum/render-static-markup
      [:html
       [:body
        [:p {:style {:color "red"}}
         "Hello world!"]]])))
</code></pre><p>After <a href="https://clojure.org/guides/getting_started" target="_blank">installing Clojure</a>, you could put that in <code>src/hello/world.clj</code> and then run the program with <code>clj -Sdeps '{:deps {rum/rum {:mvn/version "0.11.5"}}}' -M -m hello.world</code>. That's a great way to get started with Clojure, actually—you can make a whole static site with just functions, data structures, and Rum. That's how I made Findka's landing page. Here's a snippet:</p><pre><code>(defn home []
  (base-page {:scripts [[:script {:src "/js/ensure-logged-out.js"}]]}
    [:.bg-dark.text-white
     [:.container.px-3.mx-auto.max-w-screen-md
      [:.nunito-sans-bold.text-2xl.mt-4.mb-8.sm:text-center
       "Great essays delivered to your inbox. " [:br.hidden.md:inline]
       "Chosen specifically for you with machine learning."]
      [:a.btn.btn-green.btn-block.sm:max-w-sm.mx-auto
       {:href "/signup"}
       "Sign up"]
      ...
</code></pre><p>This project is the first time I've used <a href="https://tailwindcss.com/" target="_blank">Tailwind CSS</a> (I used Bootstrap previously). I give it two thumbs up. Tailwind gives you smaller, better building blocks than Bootstrap, and it has responsive variants for every class (hallelujah). Setup was straightforward. After an <code>npm init; npm install tailwindcss --save-dev</code>, you just need a few files:</p><p><code>tailwind.config.js</code>:</p><pre><code>module.exports = {
  purge: [
    './src/**/*.clj', // for tree-shaking
  ],
  theme: {
    extend: {
      colors: {
        'dark': '#343a40',
        'hn-orange': '#ff6600',
        ...
      }
    }
  }
}
</code></pre><p><code>tailwind.css</code>:</p><pre><code>@tailwind base;

@tailwind components;
@responsive {
  .btn-thin {
    @apply text-center py-2 px-4 rounded;
  }
  .btn {
    @apply btn-thin font-bold;
  }
  ...
}

@tailwind utilities;
@responsive {
  .nunito-sans-bold {
    font-family: 'Nunito Sans', sans-serif;
    font-weight : 900;
  }
  ...
}
</code></pre><p>Build with <code>npx tailwindcss build tailwind.css -o output.css</code>.</p><p>The last piece is fonts. I am not a designer, at all. Despite this, I have recently made a startling discovery: using different fonts, instead of just the default, can actually make your site look a lot better. It turns out you can just doom scroll through <a href="https://fonts.google.com/" target="_blank">Google Fonts</a> until you find some you like. I did that for Findka's logo (I tried AI logo generators in the past, but they weren't good).</p><h3 id="authentication">Authentication</h3><p>Findka supports signin via email link or Google. Biff mostly handles email link auth for you.
Just make a form with an <code>email</code> field that POSTs to <code>/api/signup</code>. Biff sends the user an email with a link, they click on it, boom. You have to provide an email template and a function that actually sends the email. I use Mailgun, so Findka's email function looks like this:</p><pre><code>(def templates
  {:biff.auth/signup
   (fn [{:keys [biff.auth/link]}]
     {:from "Findka Essays &lt;...&gt;"
      :subject "Create your Findka Essays account"
      :html (rum/render-static-markup
              [:div
               [:p "We received a request to create a Findka Essays account using this email address."]
               [:p [:a {:href link :target "_blank"} "Click here to create your account."]]
               [:p "If you did not request this link, you can ignore this email."]])})
   ...})

(defn send** [api-key opts]
  (http/post (str "https://api.mailgun.net/v3/mail.findka.com/messages")
    {:basic-auth ["api" api-key]
     :form-params opts}))

(defn send* [{:keys [mailgun/api-key template data] :as opts}]
  (if (some? template)
    (let [template-fn (get templates template)
          mailgun-opts (template-fn data)]
      (send** api-key mailgun-opts))
    (send** api-key (select-keys opts [:to :subject :text :html]))))

(defn send [{:keys [params template recaptcha/secret-key] :as sys}]
  (if (= template :biff.auth/signup)
    (let [{:keys [success score]}
          (:body
            (http/post "https://www.google.com/recaptcha/api/siteverify"
              {:form-params {:secret secret-key
                             :response (:g-recaptcha-response params)}
               :as :json}))]
      (when (and success (&lt;= 0.5 score))
        (send* sys)))
    (send* sys)))
</code></pre><p>As shown at the end, I use Recaptcha for bot control. It's nice because you
don't have to make the user do anything; Google's script will simply give you a
score that represents how likely the user is to be a human.</p><p>Biff doesn't have Google sign-in support built in (yet), but it's pretty simple to add.
After the front-end bit is taken care of, you just have to add an HTTP endpoint that receives
a token, verifies it using Google's library, and sets a session cookie.</p><p>That's sort of a funny way to use Google sign-in, I'll admit. You're "supposed" to send the token
with every request and verify it each time, letting Google's code handle sessions on the client.
However, Biff is already set up for authenticating requests via session cookie, and that's more convenient for multi-page applications anyway.</p><h3 id="crud">CRUD</h3><p>I use <a href="https://opencrux.com/" target="_blank">Crux</a> for the database. Crux is an immutable document database with datalog queries. Another way to explain it is that Crux works well as a general-purpose database (e.g. a replacement for postgres), but it fits better with functional programming. You also get flexible data modeling without giving up query power.</p><p>(That ignores Crux's raison d'être, bitemporal queries—a cool feature, and no doubt extremely useful if you need those. For my simple applications, I haven't.)</p><p>Crux doesn't enforce any schema, but Biff does. You can specify schema using <a href="https://clojure.org/about/spec" target="_blank">Clojure spec</a>:</p><pre><code>(require '[trident.util :as u])

(u/sdefs
  ::event-type #{:submit :email :click :like :dislike}
  ::timestamp  inst?
  ::url        string?
  ::parent     uuid?
  ::user       uuid?
  ::event      (u/only-keys
                 :req-un [::event-type
                          ::timestamp
                          ::user
                          ::url]
                 :opt-un [::parent]))

(def schema
  {:events {:spec [uuid? ::event]}})
</code></pre><p>This schema defines a "table" for events. The <code>[uuid? ::event]</code> part means that
the primary key for an event document should be a UUID, and the rest of the
document should conform to the spec given for <code>::event</code> above. In this case,
that means the document must have an event type, timestamp, user ID and URL,
and it can optionally have a "parent" key (which is set to the primary key of
another event).</p><p>Like a standard multi-page app, Findka has POST endpoints for writing to
the database and GET endpoints for reading (though I have no idea if the
endpoints adhere to REST or not). Here's one for submitting an essay:</p><pre><code>(defn submit-essay [{:keys [biff/node session/uid params] :as sys}]
  (if (nil? uid)
    {:status 302
     :headers/Location "/login/"}
    (do
      (crux/await-tx node
        (biff.crux/submit-tx sys
          {[:events] {:user uid
                      :timestamp :db/current-time
                      :event-type :submit
                      :url (:url params)}}))
      {:status 302
       :headers/Location "/settings"})))

(def routes
  [["/api/submit-essay"
   {:post submit-essay
    :name ::submit-essay
    :middleware [anti-forgery/wrap-anti-forgery]}]
   ...])
</code></pre><p>And here's a snippet from the <code>/settings</code> page. The call to <code>crux/q</code> performs
a datalog query which returns the current user's 10 most recent events, which
are displayed in the UI:</p><pre><code>(defn settings* [{:keys [biff/db session/uid]}]
  (let [events (map first
                 (crux/q db
                   {:find '[event timestamp]
                    :full-results? true
                    :args [{'user uid}]
                    :order-by '[[timestamp :desc]]
                    :limit 10
                    :where '[[event :event-type]
                             …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://findka.com/blog/essays-implementation/">https://findka.com/blog/essays-implementation/</a></em></p>]]>
            </description>
            <link>https://findka.com/blog/essays-implementation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909509</guid>
            <pubDate>Tue, 27 Oct 2020 17:16:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A super quick guide to PR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24909500">thread link</a>) | @entreprenerd
<br/>
October 27, 2020 | https://www.entreprenerd.blog/live-streams/a-quick-intro-to-pr | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/a-quick-intro-to-pr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>PR, or Public Relations, is just the process of getting people to write article about you. The type of press you can get does vary beyond that though.</p><p>It could be podcast interviews, it could be getting featured in a magazine or the newspaper, it could be getting on television for a local news channel.</p><p>But the process is relatively the same to get new press. You have a good story, and you pitch it to news sources. Before you pitch it to larger news sources like TechCrunch or WIRED you need to make a proof of concept. Most of the successful press pitches I've seen have used an existing piece of content almost as if to prove the story is interesting.</p><p>So you get that flagship smaller article, or a decent podcast interview, and then you email it to reporters at bigger publications to see if they'll pick it up.</p><p>But before you do that, you've got to get that flagship content. In my case, I do a lot of stuff on social media, and I connect with a lot of podcast hosts since I have my own show. Then, I emailed a local news outlet in the business space with the podcast link and a simple description. It helps that I've spoken with the reporter I pitched, as well. I had recommended her a few different people already for other articles she was writing, and so she knew me before I sent that request.</p><p>So, recommend other awesome companies or entrepreneurs you know, and then a little while later, pitch yourself with a podcast episode or personal article. Hopefully you'll get that first bit of press, and you can use it to scale.</p><p>Now let's say you have your first piece of content, article or otherwise, and you want to pitch it to larger publications - you'll need to target specific writers. Scroll through the articles each news outlet has published in the past, find a series they do, or a common thread, and for each article that seems to relate to your story, keep track of the author. If you find a common author among a few articles similar to the story you want to pitch, they're your point person.</p><p>Now, you'll likely want to pitch them over email, and if it's not immediately listed on the website, you can use <a href="https://hunter.io/">Hunter.io</a> to find it 95% of the time. I <a href="https://youtu.be/8UP8DiCMCDU">filmed a little guide</a> a long time ago on how I personally do it. </p><p>Great, now you have content about your story and a list of people that might be interested. That's all you need, just send a few incredibly short emails and hope. A lot of the successful press pitches I've seen look something like this:</p><p>"Hello [name],</p><p>There's a new startup helping dog owners get connected to local dog walkers and it seems to be solving a really big problem. I noticed you report on this kind of tech so I figured I would reach out.</p><p>Here's a link to an article recently written on it: [link]</p><p>I run the startup, and I would be happy to talk about what we're trying to solve if an interview is something you would be interested in!"</p><p>That's it - as simple as possible. Reporters are getting pitched all day. Make sure the topic is right in their wheelhouse, and make sure you keep the email short as hell so they can read it super quick. I'm not entirely sure what timing would be appropriate, but if I want someone to respond to an email I send it Tuesday morning, so it's at the top of their inbox when they get to work and they already cleared the weekend backlog on Monday.</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/a-quick-intro-to-pr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909500</guid>
            <pubDate>Tue, 27 Oct 2020 17:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My Product Hunt launch – what worked and what didn’t]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909417">thread link</a>) | @joemasilotti
<br/>
October 27, 2020 | https://masilotti.com/product-hunt-what-worked/ | <a href="https://web.archive.org/web/*/https://masilotti.com/product-hunt-what-worked/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <article>
  

  

  

  <hr>

  <p>
    8 minute read
  </p>
  <p>Yesterday I <a href="https://www.producthunt.com/posts/mugshot-bot">launched Mugshot Bot on Product Hunt</a> as a solo founder. It was a wild ride and I’ve never been glued to my computer like this.</p>

<p>The launch finished with with over 250 upvotes, 39 comments, and #5 Product of the Day. It generated close to 1000 visits, over 70 sign ups, and 6 paying customers.</p>

<p>I even got a cute little badge from Product Hunt!</p>

<p><a href="https://www.producthunt.com/posts/mugshot-bot?utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-mugshot-bot" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=271792&amp;theme=light&amp;period=daily" alt="Mugshot Bot - Automated link preview images for your website. | Product Hunt" width="250" height="54"></a></p>

<p>Here’s my journey on what worked, what didn’t work, and things I wish I spent more time on. I’m not guaranteeing following these will make your launch a success. But hopefully you can pick up a tip or two.</p>

<p>Oh, and for newcomers, <a href="https://www.mugshotbot.com/">Mugshot Bot</a> is a tool that automates link preview images for your website without design tools.</p>

<p><img src="https://masilotti.com/images/mugshotbot.gif" alt="Mugshot Bot in action generating link previews">
</p>

<h2 id="what-worked">What worked</h2>

<p>The single biggest contributor to the success of this Product Hunt launch was the work done, well, before the launch.</p>

<h3 id="build-in-public">Build in public</h3>

<p>First, I’ve been building Mugshot Bot in public, sharing progress as it happens. Almost every day for the past two months I’ve tweeted about a new feature, an idea, design progress, or a question.</p>

<p>Anything worth elaborating on (but not quite long enough for a blog post) I’ve been posting to <a href="https://www.indiehackers.com/joemasilotti">Indie Hackers</a>.</p>

<p>I’ve also been very active in the <a href="https://www.weekendclub.co/">Weekend Club</a> community on Slack. Shout out to <a href="https://twitter.com/charlierward">Charlie</a> for running an amazing community.</p>

<blockquote>
  <p>Weekend Club is a weekend co-working community and a very supportive Slack group. Mention <code>WEEKENDJOE</code> when you sign up for a free month.</p>
</blockquote>

<p>All of my metrics are <a href="https://www.mugshotbot.com/stats/">publicly available</a>, too: total visitors, registered accounts, MRR, etc.</p>

<h3 id="get-early-upvotes">Get early upvotes</h3>

<p>You only get one day on Product Hunt, and those <a href="https://blog.producthunt.com/how-to-launch-on-product-hunt-7c1843e06399">24 hours are based on the Pacific time zone</a>. Ideally, you are launching early in the morning so you can maximize your time for upvotes.</p>

<p>I’m in Eastern time and didn’t want to get up at 3am to start promoting my post. Instead, I had someone in London help me out.</p>

<p>Shout out to <a href="https://twitter.com/jmckinven">James</a> for getting the ball rolling. He shared the post with other indie hackers and makers in his circle which bumped the post right from the get-go.</p>

<h3 id="live-tweet">Live tweet</h3>

<p>About five seconds after I woke up I <a href="https://twitter.com/joemasilotti/status/1320674419077910530">tweeted a link</a> to the Product Hunt post. I followed up on every milestone, every mishap, and every little victory.</p>

<p><a href="https://twitter.com/joemasilotti/status/1320674419077910530">
  <img src="https://masilotti.com/images/mugshotbot-tweet-thread.png" alt="Beginning of Twitter thread about Product Hunt launch">
  </a>
</p>

<p>I also pinned the tweet to my profile and set my URL to the Product Hunt page for the day.</p>

<p>In total, the tweet received 7500 impressions and a whopping 500 engagements. I replied to <a href="https://twitter.com/joemasilotti/status/1320674419077910530">the thread</a> 20 times.</p>

<p>This was where people showed their excitement. If you click through the thread there’s a ton of people interacting with me, letting me know they upvoted, and just being generally awesome.</p>

<p>It was a highlight of the day for me to connect directly with people about Mugshot Bot on Twitter.</p>

<p>Shout out to <a href="https://twitter.com/panphora">David</a> for this idea and for providing a <em>ton</em> of feedback while building Mugshot Bot.</p>

<h3 id="be-genuine">Be genuine</h3>

<p>Product Hunt has a strict policy against asking for upvotes. Instead, they recommend asking folks to “check out the page.”</p>

<p>What worked well for me was being genuine. I wanted support from my audience so that’s what I asked for. “I would love if you could show me some support” seemed to resonate.</p>

<p>I also called out in my <a href="https://twitter.com/joemasilotti/status/1320674419077910530">initial tweet</a> that I was nervous. This was met with a lot of positive reinforcement from folks that went a long way towards ending the day feeling great.</p>

<h2 id="what-didnt-work">What didn’t work</h2>

<p>Not every second of my launch day was productive. Here are some things that I tried but didn’t seem to help very much.</p>

<h3 id="engaging-out-of-target-audiences">Engaging out-of-target audiences</h3>

<p>A big portion of my Twitter followers are indie makers, developers, and/or bloggers. Mugshot Bot helps content creators and hackers the most, so there’s a ton of overlap.</p>

<p>That isn’t the case for my Facebook audience. Most of these folks are friends from high school and college. I’ll also be the first to admit I don’t post on Facebook much anymore.</p>

<p>The takeaway is to pick the audience that matters and focus on that instead of spreading yourself too thin.</p>

<h3 id="email-campaign-asking-for-support">Email campaign asking for support</h3>

<p>This one surprised me the most. Before the launch I had about 100 registered accounts. I sent an email letting them know about the importance of the Product Hunt launch and asking for support.</p>

<p>Oddly enough, only 9 people clicked through the Product Hunt post. Here’s the email, if you’re interested.</p>

<p><img src="https://masilotti.com/images/product-hunt-launch-email.jpeg" alt="Screenshot of email campaign announcing Product Hunt launch"></p>

<p>Looking back, I can’t tell if these folks didn’t care enough or my messaging was off. Probably a combination of the two!</p>

<h3 id="twitter-ads">Twitter ads</h3>

<p>As soon as I got my first new customer I set up a Twitter campaign for the same amount. I focused on getting clicks to the Product Hunt post and promoted the first post in the Twitter thread.</p>

<p>I cancelled the campaign after two hours.</p>

<p>In 2 hours I received 2 clicks. For $15. This might make sense for a direct acquisition channel, but $7.50 per click was nowhere near worth it for potential upvotes.</p>

<h3 id="obsessively-refresh-metrics">Obsessively refresh metrics</h3>

<p>In the spirit of building in public all of <a href="https://www.mugshotbot.com/stats/">Mugshot Bot’s metrics are publicly available</a>.</p>

<p><a href="https://www.mugshotbot.com/stats">
  <img src="https://masilotti.com/images/mugshotbot-stats.png" alt="Mugshot Bot public metrics">
  </a>
</p>

<p>I probably refreshed this page over 100 times throughout the day. Sure, there were a few dopamine hits when a number spiked. But overall, it was a waste of time.</p>

<p>Metrics are important but being glued to them is a dangerous habit.</p>

<h2 id="what-i-wish-id-also-done">What I wish I’d also done</h2>

<p>There’s only so many hours the day. But here are a few things that I wish I carved out some extra time for.</p>

<h3 id="post-to-indie-hackers">Post to Indie Hackers</h3>

<p>Early last week I posted to Indie Hackers documenting <a href="https://www.indiehackers.com/post/my-prep-for-a-product-hunt-launch-on-monday-66f2757c1f">everything I did for seven days leading up to the launch</a>. It was really fun to update this throughout the week.</p>

<p>But for some reason I completely forgot to post on launch day! I think this could have strummed up a bit more excitement but nothing getting too upset over.</p>

<p>You could post in the <a href="https://www.indiehackers.com/group/product-launch">Product Launch</a>  or <a href="https://www.indiehackers.com/group/product-hunt">Product Hunt</a> groups, they both have about 150 members.</p>

<h3 id="fine-tune-a-welcome-e-mail">Fine-tune a welcome e-mail</h3>

<p>Late in the day I added a click-to-tweet link to the welcome email to people who have signed up for Mugshot Bot. A few people used it, too!</p>

<p>The link uses Twitter intents to automatically prompt a drafted tweet with populated content. I used <a href="https://tech.cymi.org/tweet-intents">Twitter Intent Creator</a> to generate the link.</p>

<p>In hindsight, I wish I added this earlier in the day to capitalize on some more reach.</p>

<h2 id="your-product-hunt-launch">Your Product Hunt launch</h2>

<p>That’s everything that I learned during my first big Product Hunt launch. I hope you picked up a tip or two for your launch!</p>

<p>My tl;dr is to build an audience before your launch. Without this you’ll be fighting an uphill battle.</p>

<p>If you used this post to help your launch I’d love to hear about it. <a href="https://twitter.com/joemasilotti/status/1321129876938649600">Reply to this tweet</a> or <a href="mailto:joe@masilotti.com">send me an email</a> and we can talk shop.</p>

  

</article>

      </section></div>]]>
            </description>
            <link>https://masilotti.com/product-hunt-what-worked/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909417</guid>
            <pubDate>Tue, 27 Oct 2020 17:06:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Code Isolation in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909326">thread link</a>) | @headalgorithm
<br/>
October 27, 2020 | https://rushter.com/blog/python-code-isolation/ | <a href="https://web.archive.org/web/*/https://rushter.com/blog/python-code-isolation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I started learning Python in 2009, and I had a pretty challenging task and somewhat unusual use of Python. I was working on a desktop application that used PyQT for GUI and Python as the main language.</p><p>To hide the code, I embedded Python interpreter into a standalone Windows executable. There are a lot of solutions to do so (e.g. <a href="https://www.pyinstaller.org/">pyinstaller</a>, <a href="https://www.py2exe.org/">pyexe</a>), and they all work similarly. They compile your Python scripts to <a href="https://docs.python.org/3/glossary.html#term-bytecode">bytecode</a> files and bundle them with an interpreter into an executable. Compiling scripts down to bytecode makes it harder for people with bad intentions to get the source code and crack or hack your software. Bytecode has to be extracted from the executable and decompiled. It can also produce obfuscated code that is much harder to understand.</p><p><img src="https://rushter.com/static/uploads/img/code_isolation.svg"></p><p>At one point, I wanted to add a plugin system so that users could benefit from extra features. Executing arbitrary third-party code on your server is dangerous. But can it harm your commercial product when you execute it on user's machines, and users have trust in that they are executing? At that time, the answer was not obvious, and I decided to implement the system.</p><p>A few years later, it became apparent that you should <strong>never</strong> execute third-party code using the same Python process (interpreter) if you don't want to leak the source code. There are a lot of commercial products that use Python for desktop software or as a <a href="https://wiki.python.org/moin/AppsWithPythonScripting">scripting language</a>. Some of them can be at risk.</p><p>There are many ways to extract Python bytecode even if you don't run any third-party code. It's a never-ending arms race between developers and reverse engineers, but it's much easier to extract the bytecode and crack your program when you can run your own code. My software was later cracked without using the plugins subsystem.</p><p>So what can you do to the "host" code when it executes your scripts?</p><p>Python is a very dynamic language, and you can do a lot of things. This article demonstrates a few approaches on how to modify or extract the source code.</p><blockquote><p>When you work with a regular Python process, you don't even need a plugins system. You can always <a href="https://wiki.python.org/moin/DebuggingWithGdb">attach to a running</a> process using GDB and inject your own code.</p></blockquote><h2>Monkey patching</h2><p>If a plugin can be initialized before a function that you want to modify, we can simply mock it.</p><p>Let's suppose we have a function that validates license:</p><div><pre><span></span><code><span>def</span> <span>validate_license</span><span>():</span>
    <span>hw_hash</span><span>,</span> <span>hw_id</span> <span>=</span> <span>get_hardware_id</span><span>()</span>
    <span>data</span> <span>=</span> <span>{</span><span>"timestamp"</span><span>:</span> <span>time</span><span>.</span><span>time</span><span>(),</span> <span>"hid"</span><span>:</span> <span>hw_id</span><span>,</span> <span>}</span>
    <span>r</span> <span>=</span> <span>requests</span><span>.</span><span>post</span><span>(</span><span>'https://rushter.com/validate'</span><span>,</span> <span>data</span><span>)</span>
    <span>server_hash</span> <span>=</span> <span>r</span><span>.</span><span>text</span>
    <span>return</span> <span>hw_hash</span> <span>==</span> <span>server_hash</span>
</code></pre></div><p>We can bypass the checks by replacing a few functions:</p><div><pre><span></span><code><span>def</span> <span>mock_licensing</span><span>():</span>
    <span>requests</span> <span>=</span> <span>__import__</span><span>(</span><span>'requests'</span><span>)</span>
    <span>licensing</span> <span>=</span> <span>__import__</span><span>(</span><span>'licensing'</span><span>)</span>


    <span>def</span> <span>post</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>mocked_object</span> <span>=</span> <span>types</span><span>.</span><span>SimpleNamespace</span><span>()</span>
        <span>mocked_object</span><span>.</span><span>text</span> <span>=</span> <span>"a8f5f167"</span>
        <span>return</span> <span>mocked_object</span>

    <span>licensing</span><span>.</span><span>get_hardware_id</span> <span>=</span> <span>lambda</span><span>:</span> <span>(</span><span>"a8f5f167"</span><span>,</span> <span>123</span><span>)</span>
    <span>requests</span><span>.</span><span>post</span> <span>=</span> <span>post</span>
</code></pre></div><h2>Frame objects</h2><p>In Python, frame objects keep the state of functions that are currently running. Each frame corresponds to single function execution. Python modules and class definition use frames too. That is a building block of the <a href="https://en.wikipedia.org/wiki/Call_stack">call stack</a>.</p><p>Given a frame object, you can:</p><ul><li>Change locals, globals, and builtins at runtime.</li><li>Get bytecode of a function (code block) that is being executed.</li></ul><p>Here is how you can list all frames in the current call stack:</p><div><pre><span></span><code><span>def</span> <span>list_frames</span><span>():</span>
    <span>current_frame</span> <span>=</span> <span>sys</span><span>.</span><span>_getframe</span><span>(</span><span>0</span><span>)</span>
    <span>while</span> <span>current_frame</span><span>.</span><span>f_back</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"""</span>
<span>locals: </span><span>{</span><span>current_frame</span><span>.</span><span>f_locals</span><span>}</span><span></span>
<span>globals: </span><span>{</span><span>current_frame</span><span>.</span><span>f_globals</span><span>}</span><span></span>
<span>bytecode: </span><span>{</span><span>current_frame</span><span>.</span><span>f_code</span><span>.</span><span>co_code</span><span>}</span><span></span>
<span>function name: </span><span>{</span><span>current_frame</span><span>.</span><span>f_code</span><span>.</span><span>co_name</span><span>}</span><span></span>
<span>line number: </span><span>{</span><span>current_frame</span><span>.</span><span>f_lineno</span><span>}</span><span></span>
<span>        """</span><span>)</span>
        <span>current_frame</span> <span>=</span> <span>current_frame</span><span>.</span><span>f_back</span>
</code></pre></div><p>The <a href="https://docs.python.org/3/library/inspect.html">inspect</a> module describes all available attributes of the frame and <a href="https://docs.python.org/3/c-api/code.html">code</a> objects.</p><h3>Changing locals</h3><p>Let's suppose we have a function that calls a <a href="https://en.wikipedia.org/wiki/Callback_(computer_programming)">callback</a>, and we have control over the callback. For example, the path to callback can be defined in the settings file.</p><div><pre><span></span><code><span>def</span> <span>get_amount</span><span>():</span>
    <span>return</span> <span>10</span>


<span>def</span> <span>update_database</span><span>(</span><span>user</span><span>,</span> <span>amount</span><span>):</span>
    <span>pass</span>


<span>def</span> <span>charge_user_for_subscription</span><span>(</span><span>user</span><span>,</span> <span>logger</span><span>=</span><span>logging</span><span>.</span><span>info</span><span>):</span>
    <span>amount</span> <span>=</span> <span>get_amount</span><span>()</span>
    <span>print</span><span>(</span><span>amount</span><span>)</span>
    <span>logger</span><span>(</span><span>amount</span><span>)</span>
    <span>update_database</span><span>(</span><span>user</span><span>,</span> <span>amount</span><span>)</span>
    <span>print</span><span>(</span><span>amount</span><span>)</span>
</code></pre></div><p>The last function charges a user for a monthly subscription and allows to specify a custom logging callback. I've added a few prints so that you can copy-paste the code and see the results.</p><p>Since logging happens in the middle, we can modify the <code>amount</code> variable.</p><div><pre><span></span><code><span>def</span> <span>fix_amount</span><span>(</span><span>_</span><span>):</span>
    <span>import</span> <span>ctypes</span>
    <span># Get parent frame</span>
    <span>frame</span> <span>=</span> <span>sys</span><span>.</span><span>_getframe</span><span>(</span><span>1</span><span>)</span>
    <span># Update locals dictionary</span>
    <span>frame</span><span>.</span><span>f_locals</span><span>[</span><span>'amount'</span><span>]</span> <span>=</span> <span>-</span><span>100</span>
    <span># Synchronize dictionary</span>
    <span>ctypes</span><span>.</span><span>pythonapi</span><span>.</span><span>PyFrame_LocalsToFast</span><span>(</span><span>ctypes</span><span>.</span><span>py_object</span><span>(</span><span>frame</span><span>),</span> <span>0</span><span>)</span>
</code></pre></div><div><pre><span></span><code><span>In</span> <span>[</span><span>8</span><span>]:</span> <span>charge_user_for_subscription</span><span>(</span><span>'Ivan'</span><span>,</span> <span>fix_amount</span><span>)</span>
<span>10</span>
<span>-</span><span>100</span>
</code></pre></div><h4>Fast locals</h4><p>In Python, local and global variables are stored in dictionaries. Every time you use a variable, Python needs to lookup it in a dictionary. Since dictionary lookups are not free and take time, Python uses various optimization techniques.</p><p>By analyzing the code of a function, it's possible to detect variable names that a function will be using when running. Our function has three local variables: <code>amount</code>, <code>user</code>, <code>logger</code>. Function arguments are local variables too.</p><p>When compiling source code to bytecode, Python maps known variable names to indexes in a special array and stores them there. Accessing a variable by an index is fast, and most of the functions use predefined names. Optimized variables are called <code>fast locals</code>. To keep variable names that are generated on the go, Python uses a dictionary as a fallback.</p><p>When dereferencing variables, Python prioritizes fast locals and ignores changes in the dictionary. That's why we use <code>ctypes</code> and call internal <a href="https://github.com/python/cpython/blob/cb9879b948a19c9434316f8ab6aba9c4601a8173/Objects/frameobject.c#L1148"><code>PyFrame_LocalsToFast</code></a> function.</p><h2>Patching bytecode</h2><p>I have an article on <a href="https://rushter.com/blog/python-bytecode-patch/">bytecode patching</a> that describes how to patch function definition. We can go even further and patch a running function.</p><p>Instead of source code, Python interpreter executes bytecode that was generated using a special compiler. When executing the code, a special virtual machine executes each instruction one by one. That allows us to replace unexecuted instructions on the go.</p><p>Let's use this function as an example:</p><div><pre><span></span><code><span>def</span> <span>is_valid</span><span>():</span>
    <span>return</span> <span>False</span>


<span>def</span> <span>check_license</span><span>(</span><span>callback</span><span>):</span>
    <span>callback</span><span>()</span>
    <span>if</span> <span>not</span> <span>is_valid</span><span>():</span>
        <span>print</span><span>(</span><span>'exiting'</span><span>)</span>
        <span>exit</span><span>(</span><span>0</span><span>)</span>
</code></pre></div><p>The builtin <code>dis</code> module allows us to see the bytecode in a human-readable format:</p><div><pre><span></span><code><span>In</span> <span>[</span><span>12</span><span>]:</span> <span>check_license</span><span>.</span><span>__code__</span><span>.</span><span>co_code</span>
<span>Out</span><span>[</span><span>12</span><span>]:</span> <span>b</span><span>'|</span><span>\x00\x83\x00\x01\x00</span><span>t</span><span>\x00\x83\x00</span><span>s</span><span>\x1c</span><span>t</span><span>\x01</span><span>d</span><span>\x01\x83\x01\x01\x00</span><span>t</span><span>\x02</span><span>d</span><span>\x02\x83\x01\x01\x00</span><span>d</span><span>\x00</span><span>S</span><span>\x00</span><span>'</span>

<span>In</span> <span>[</span><span>13</span><span>]:</span> <span>dis</span><span>.</span><span>dis</span><span>(</span><span>check_license</span><span>)</span>
  <span>6</span>           <span>0</span> <span>LOAD_FAST</span>                <span>0</span> <span>(</span><span>callback</span><span>)</span>
              <span>2</span> <span>CALL_FUNCTION</span>            <span>0</span>
              <span>4</span> <span>POP_TOP</span>

  <span>7</span>           <span>6</span> <span>LOAD_GLOBAL</span>              <span>0</span> <span>(</span><span>is_valid</span><span>)</span>
              <span>8</span> <span>CALL_FUNCTION</span>            <span>0</span>
             <span>10</span> <span>POP_JUMP_IF_TRUE</span>        <span>28</span>

  <span>8</span>          <span>12</span> <span>LOAD_GLOBAL</span>              <span>1</span> <span>(</span><span>print</span><span>)</span>
             <span>14</span> <span>LOAD_CONST</span>               <span>1</span> <span>(</span><span>'exiting'</span><span>)</span>
             <span>16</span> <span>CALL_FUNCTION</span>            <span>1</span>
             <span>18</span> <span>POP_TOP</span>

  <span>9</span>          <span>20</span> <span>LOAD_GLOBAL</span>              <span>2</span> <span>(</span><span>exit</span><span>)</span>
             <span>22</span> <span>LOAD_CONST</span>               <span>2</span> <span>(</span><span>0</span><span>)</span>
             <span>24</span> <span>CALL_FUNCTION</span>            <span>1</span>
             <span>26</span> <span>POP_TOP</span>
        <span>&gt;&gt;</span>   <span>28</span> <span>LOAD_CONST</span>               <span>0</span> <span>(</span><span>None</span><span>)</span>
             <span>30</span> <span>RETURN_VALUE</span>
</code></pre></div><p>Our license is not valid, and we want to remove the <code>not</code> statement from the code. To do so, we need to replace the <code>POP_JUMP_IF_TRUE</code> instruction with <code>POP_JUMP_IF_FALSE</code>.</p><p>Since we can control the <code>callback</code> function, we can apply a hot patch in the middle of a function.</p><div><pre><span></span><code><span>import</span> <span>sys</span><span>,</span> <span>ctypes</span>

<span>def</span> <span>fix</span><span>():</span>
    <span># get parent frame</span>
    <span>frame</span> <span>=</span> <span>sys</span><span>.</span><span>_getframe</span><span>(</span><span>1</span><span>)</span>
    <span># find bytecode location</span>
    <span>memory_offset</span> <span>=</span> <span>id</span><span>(</span><span>frame</span><span>.</span><span>f_code</span><span>.</span><span>co_code</span><span>)</span> <span>+</span> <span>sys</span><span>.</span><span>getsizeof</span><span>(</span><span>b</span><span>''</span><span>)</span> <span>-</span> <span>1</span>
    <span># update 10th bytecode element</span>
    <span>ctypes</span><span>.</span><span>memset</span><span>(</span><span>memory_offset</span> <span>+</span> <span>10</span><span>,</span> <span>dis</span><span>.</span><span>opmap</span><span>[</span><span>'POP_JUMP_IF_FALSE'</span><span>],</span> <span>1</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>check_license</span><span>(</span><span>fix</span><span>)</span>
</code></pre></div><p>As you can see above, internally, the bytecode is stored as <code>bytes</code>. Unfortunately, we can't modify the <code>frame.f_code.co_code</code> attribute since it's a read-only attribute.</p><p>To bypass this restriction, we use <code>ctypes</code> module that allows us to modify the RAM of a Python process. Every <code>bytes</code> object contains meta-information, such as <a href="https://rushter.com/blog/python-garbage-collector/">number of references</a> and information about the type. To locate the exact address of the raw C string, we use the <code>id</code> function that returns object address in memory, and we skip all meta information (size of the empty byte string). The output from <code>dis.dis</code> shows that the <code>POP_JUMP_IF_TRUE</code> instruction is the 10th element in the byte string that we need to replace.</p><h2>Extracting the source code</h2><p>Every script that Python runs or imports creates a <code>module</code> object that stores constants, functions, class definitions, and so on. If you don't have source code, you can get it back by decompiling the bytecode.</p><p>Here is how you can iterate over all modules and find all available functions:</p><div><pre><span></span><code><span>for</span> <span>name</span><span>,</span> <span>module</span> <span>in</span> <span>list</span><span>(</span><span>sys</span><span>.</span><span>modules</span><span>.</span><span>items</span><span>()):</span>
    <span>if</span> <span>name</span> <span>not</span> <span>in</span> <span>[</span><span>'license'</span><span>,</span> <span>'runner'</span><span>]:</span>
        <span>continue</span>
    <span>for</span> <span>obj_name</span><span>,</span> <span>obj</span> <span>in</span> <span>inspect</span><span>.</span><span>getmembers</span><span>(</span><span>module</span><span>):</span>
        <span>if</span> <span>inspect</span><span>.</span><span>isfunction</span><span>(</span><span>obj</span><span>):</span>
            <span>print</span><span>(</span><span>obj_name</span><span>,</span> <span>obj</span><span>.</span><span>__code__</span><span>)</span>
</code></pre></div><p>Fortunately (or unfortunately for some people), there is no easy way to extract the bytecode of a whole module if you don't have a <code>pyc</code> (bytecode cache) file. If you want to get the source code from a running Python process, you will need to extract the bytecode of each function, class, and module definitions as well as from some frame objects. After that, you will need to run it through one of the <a href="https://github.com/rocky/python-decompile3">decompilers</a>.</p><h3>Conclusion</h3><p>This article is a part of <a href="https://rushter.com/blog/tags/cpython/">CPython internals</a> series. It's hard to find a practical application to these techniques, but such language details are useful for people who perform security research or participate in CTF competitions. My previous articles on bytecode have helped people to get extra points in security competitions.</p></div></div>]]>
            </description>
            <link>https://rushter.com/blog/python-code-isolation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909326</guid>
            <pubDate>Tue, 27 Oct 2020 16:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OberonScript: a safe scripting language and runtime for web apps (2007)]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24909114">thread link</a>) | @lproven
<br/>
October 27, 2020 | http://www.ralphsommerer.com/obn.htm | <a href="https://web.archive.org/web/*/http://www.ralphsommerer.com/obn.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="flowhor">
  
  <div id="flowvert">
   
   <div id="mainbody">
       
<h2>OberonScript</h2>
<p>Oberon Script is a scripting language and runtime system for building interactive Web Client applications. It consists of a compiler that translates the full Oberon language into JavaScript code, and a small runtime system that detects and compiles at load-time script sections written in Oberon Script.</p>
<p>It is a complete re-implementation from scratch of an earlier compiler that I built
while being with <a href="http://research.microsoft.com/">Microsoft Research</a>
in <a href="http://en.wikipedia.org/wiki/Cambridge">Cambridge</a>. For legal reasons I was unable to take the code with me
but I cleared the code by MSR's legal department for publication via <a href="http://research.microsoft.com/research/downloads/default.aspx">Microsoft Research's code posting tool</a>.
However, I left MSR before completing the process, hence the complete rewrite.</p>
<h3>Code</h3>
<p>The code of the compiler is available in its current, far from final version in source code (obviously...) for personal,
non-commercial and non-governmental use. The usual disclaimers apply.</p>
<p>A very minimal documentation is also available. I may merge it some time with the prettyprinted HTML version below.</p>

<p>V2.0beta [<a href="http://www.ralphsommerer.com/oberon.js">JavaScript</a>] [<a href="http://www.ralphsommerer.com/oberon.js.htm">HTML</a> <small>color coded</small>] [<a href="http://www.ralphsommerer.com/obndoc.htm">Docu</a>] <small>July 6, 2007</small></p>

<h3>Presentations</h3>
<ul>
<li><a href="http://www.oberon-industry.ethz.ch/">Oberon Day 2007</a>, ETH Zürich, Switzerland, June 29, 2007</li>
<li>Joint Modular Languages Conference (<a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>), Oxford, UK, September 13-15, 2006</li>
</ul>
<h3>Publications</h3>
<p>Ralph Sommerer: 
<i>Oberon Script: A Lightweight Compiler and Runtime System for the 
Web</i>, Proceedings of the 7th Joint Modular Languages Conference, <a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>, Oxford, UK, September 13-15, 2006,
<a href="http://www.springer.com/dal/home/generic/search/results?SGWID=1-40109-22-173677107-0">LNCS Vol 4228</a>, Springer, 2006 
<small>[also available as <a href="http://research.microsoft.com/research/pubs/view.aspx?tr_id=1094">MSR 
Technical Report 2006-50</a>]</small> </p>

</div>
   
  </div>
 </div></div>]]>
            </description>
            <link>http://www.ralphsommerer.com/obn.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909114</guid>
            <pubDate>Tue, 27 Oct 2020 16:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Ideas Seriously Is Hard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24909024">thread link</a>) | @neilkakkar
<br/>
October 27, 2020 | https://neilkakkar.com/taking-ideas-seriously.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/taking-ideas-seriously.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Most people don’t practice taking ideas seriously. I think it’s because most people don’t know how to. I didn’t either, until I stumbled upon an implication.</p>

<p>For example, what would it mean to take compounding seriously?</p>

<p>Ugh. I can feel your aversion. You’ve already heard so much about compounding, how it works, how it’s the eight wonder of the world, etc. etc.</p>

<p>But, familiarity is not the same as taking it seriously.</p>

<p>Say you start with $100, and every year, make 10% more. This compounds, since the extra money is a function of how much you already have. The more you have, the more you get. It’s a positive loop that keeps on increasing.</p>

<p>That’s the familiar interpretation. The earlier you start, the more money you’ll make.</p>

<p>To take this interpretation seriously would mean investing your earnings for a similar return. <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail" target="_blank" rel="noopener">Reality has a surprising amount of detail</a>, and sometimes assumptions break. You don’t make 10% - which means you need to balance your investments somehow. That makes things complicated. However, this complication is not related to compounding.</p>

<p>Taking compounding seriously means taking it a step further. Your net worth is just one implication. What else compounds?</p>

<p>Your life experiences and knowledge. What would it mean to leverage compounding here?</p>

<p>If you’re taking compounding seriously, you’d learn the skills with the greatest return first. That means learning the broadest applicable skills you’d apply throughout your life first. That means learning how to think well - before learning the new fancy tech you want to learn.</p>

<p>Of course, sometimes you need a medium to learn the skill better. That makes sense: learn to think well via this new tech you wanted to learn. <a href="https://www.lesswrong.com/s/3HyeNiEpvbQQaqeoH" target="_blank" rel="noopener">Purposes are fragile</a> though, and it’s easy to get lost in the tool, instead of the overall goal.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>What makes this example so good is that you’re probably very familiar with compounding. What else are you familiar with, but haven’t realised you’re not taking seriously?</p>

<p>A good way to practice this is to ask this question: What are the implications of (idea) in (field of interest)?</p>

<p>For example, asking myself What are the implications of compounding for my self-directed knowledge base led to the above insight of learning broader skills first.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>You can reply to this post <a href="https://twitter.com/neilkakkar/status/1321126261775847424" target="_blank" rel="noopener">here</a>.</p><p>

    
      You can <a href="" onclick="return sendEmail(&quot;Taking Ideas Seriously is Hard&quot;, &quot;https://neilkakkar.com/taking-ideas-seriously.html&quot;)">send yourself an email</a> 
      with this post.
      

    
  </p></div></div>]]>
            </description>
            <link>https://neilkakkar.com/taking-ideas-seriously.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909024</guid>
            <pubDate>Tue, 27 Oct 2020 16:32:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Graphback to develop production-ready GraphQL applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908976">thread link</a>) | @craicoverflow
<br/>
October 27, 2020 | https://graphback.dev/blog/2020/10/01/announcing-graphback-1.0 | <a href="https://web.archive.org/web/*/https://graphback.dev/blog/2020/10/01/announcing-graphback-1.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><time datetime="2020-10-01T00:00:00.000Z">October 1, 2020  · 6 min read</time></p><div><p><a href="https://twitter.com/PhelanEnda" target="_blank" rel="noreferrer noopener"><img src="https://avatars2.githubusercontent.com/u/11743717?s=460&amp;u=3fd43aed3b4b8eb706fed5719e179d23c9c47eb1&amp;v=4" alt="Enda Phelan"></a></p></div></header><section><p>We are excited to announce the <strong>official release of Graphback 1.0</strong>! This release is the end result of the amazing work and collaboration between the Graphback team and our community. </p><p>To each and every one of you who helped by using Graphback and providing us with invaluable feedback, and to those who contributed in code and issues - thank you! You are all stars, and we would not have gotten here without you.</p><h2>What is Graphback?</h2><p>Graphback is a Node.js runtime framework and toolkit to generate a production-ready GraphQL project. Graphback is a core extension of the GraphQL CLI, used to generate a set of queries, mutations and subscriptions for each of your data models and connects to the database of your choice, allowing you to focus on the business objectives of your application.</p><p><img alt="Graphback logo" src="https://graphback.dev/assets/images/logo-df65e28e87b32b8790bc7436dbeb52b6.png"></p><p>The generated API layer follows the <a href="https://graphqlcrud.org/" target="_blank" rel="noopener noreferrer">GraphQL CRUD</a> specification developed by the GraphQL community, providing a common pattern for querying your data, and enables interoperability between GraphQL libraries which also adopt these patterns.</p><p>On top of the core framework, Graphback comes with a number of additional utility libraries which can optionally be used to aid development, like GraphQL Migrations for automatic database migration from your schema, and GraphQL Serve to instantly start up a Graphback API in-memory from the command-line.</p><h2>Why not ${otherGraphqlLibrary} instead?</h2><p>But, you might ask, why not some other library instead? The GraphQL ecosystem is evolving quickly, with a growing number of frameworks and libraries. Why should I choose Graphback and GraphQL CLI?</p><h3>No vendor lock-in</h3><p>The open design of Graphback and GraphQL CLI means there will be no vendor lock-in. You have full control over your code and you can easily extend, customise and replace to suit your use cases.</p><h3>Open Source, forever</h3><p>Graphback is, and always will be, 100% open source. We actively work with and use feedback from our awesome community to help drive Graphback in the right direction, and will continue to do so forever more.</p><h3>Committed to improving the GraphQL ecosystem</h3><p>One of our main philosophies is to ensure Graphback coexists and works with as many other GraphQL libraries and standards as possible, improving the overall experience for developers. Some of the libraries that Graphback works with:</p><ul><li><a href="https://graphql-cli.com/" target="_blank" rel="noopener noreferrer">GraphQL CLI</a> - Graphback helps to power the GraphQL CLI</li><li><a href="https://www.graphql-tools.com/" target="_blank" rel="noopener noreferrer">GraphQL Tools</a></li><li><a href="https://graphql-config.com/" target="_blank" rel="noopener noreferrer">GraphQL Config</a></li><li><a href="https://graphql-code-generator.com/" target="_blank" rel="noopener noreferrer">GraphQL Code Generator</a></li><li><a href="https://graphqlcrud.org/" target="_blank" rel="noopener noreferrer">GraphQL CRUD</a> - an open specification for common operations on top of GraphQL</li></ul><h3>Easy to use, easier to stay</h3><p>We tried to make Graphback as easy to use as possible. Whether you are highly experienced with GraphQL, or Graphback is your first venture into the world of GraphQL, we wanted to make it easy for you to add Graphback to your project and get up and running. You can bootstrap your server with Graphback through a couple of programmatic APIs.</p><div><div><div tabindex="0"><div><p><span>import</span><span> </span><span>{</span><span> buildGraphbackAPI</span><span>,</span><span> createCRUDService </span><span>}</span><span> </span><span>from</span><span> </span><span>'graphback'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> createKnexDbProvider </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/runtime-knex'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> </span><span>PubSub</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'graphql-subscriptions'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>Knex</span><span> </span><span>from</span><span> </span><span>'knex'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> db </span><span>=</span><span> </span><span>Knex</span><span>(</span><span>...</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>{</span><span> typeDefs</span><span>,</span><span> resolvers</span><span>,</span><span> contextCreator </span><span>}</span><span> </span><span>=</span><span> </span><span>buildGraphbackAPI</span><span>(</span><span>modelDefs</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  serviceCreator</span><span>:</span><span> </span><span>createCRUDService</span><span>(</span><span>{</span><span> pubSub</span><span>:</span><span> </span><span>new</span><span> </span><span>PubSub</span><span>(</span><span>)</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  dataProviderCreator</span><span>:</span><span> </span><span>createKnexDbProvider</span><span>(</span><span>db</span><span>)</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> apolloServer </span><span>=</span><span> </span><span>new</span><span> </span><span>ApolloServer</span><span>(</span><span>{</span><span></span></p><p><span>  typeDefs</span><span>,</span><span></span></p><p><span>  resolvers</span><span>,</span><span></span></p><p><span>  context</span><span>:</span><span> contextCreator</span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></div></div></div></div><h3>GraphQL CRUD out of the box</h3><p>The Graphback team is a founding contributor of the GraphQL CRUD specification. This means that Graphback stays up-to-date with the latest features and improvements in the specification.</p><div><div><div tabindex="0"><div><p><span>type</span><span> </span><span>Query</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>findNotes</span><span>(</span><span>filter</span><span>:</span><span> NoteFilter</span><span>,</span><span> </span><span>page</span><span>:</span><span> PageRequest</span><span>,</span><span> </span><span>orderBy</span><span>:</span><span> OrderByInput</span><span>)</span><span>:</span><span> NoteResultList</span><span>!</span><span></span></p><p><span>  </span><span>getNote</span><span>(</span><span>id</span><span>:</span><span> ID</span><span>!</span><span>)</span><span>:</span><span> Note</span></p><p><span>  </span><span>findComments</span><span>(</span><span>filter</span><span>:</span><span> CommentFilter</span><span>,</span><span> </span><span>page</span><span>:</span><span> PageRequest</span><span>,</span><span> </span><span>orderBy</span><span>:</span><span> OrderByInput</span><span>)</span><span>:</span><span> CommentResultList</span><span>!</span><span></span></p><p><span>  </span><span>getComment</span><span>(</span><span>id</span><span>:</span><span> ID</span><span>!</span><span>)</span><span>:</span><span> Comment</span></p><p><span></span><span>}</span></p></div></div></div></div><p>You can instantly begin performing mutations and queries without having to write any additional backend code.</p><p><img alt="GraphQL CRUD query" src="https://graphback.dev/assets/images/graphqlcrud-query-getone-5e011140c710c0dcbdc845a6d0c5f5b5.gif"></p><p>Graphback generates a CRUD service for each of your data models. First-class integration with <a href="https://graphql-code-generator.com/" target="_blank" rel="noopener noreferrer">GraphQL Code Generator</a> gives you a type-safe, GraphQL CRUD programmatic API for every model, making it easier to create custom filtering from your resolver code.</p><div><div><div tabindex="0"><div><p><span>import</span><span> </span><span>{</span><span> </span><span>NoteFilter</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'../generated-types'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> filter</span><span>:</span><span> </span><span>QueryFilter</span><span>&lt;</span><span>NoteFilter</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  title</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    startsWith</span><span>:</span><span> </span><span>'[DRAFT]'</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>const</span><span> results </span><span>=</span><span> </span><span>await</span><span> context</span><span>.</span><span>graphback</span><span>.</span><span>Note</span><span>.</span><span>findBy</span><span>(</span><span>{</span><span> filter </span><span>}</span><span>,</span><span> context</span><span>,</span><span> info</span><span>)</span><span>;</span></p></div></div></div></div><h3>Extensible by design, flexible by nature</h3><p>Graphback was designed with extensibility as a main priority. All core API functionality is generated through plugins, with additional customizations possible by using a community plugin or by <a href="https://graphback.dev/docs/plugins/create" target="_blank" rel="noopener noreferrer">creating your own</a>.</p><div><div><div tabindex="0"><div><p><span>...</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> </span><span>SchemaCRUDPlugin</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/codegen-schema'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> </span><span>DataSyncPlugin</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/datasync'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>{</span><span> typeDefs</span><span>,</span><span> resolvers</span><span>,</span><span> contextCreator </span><span>}</span><span> </span><span>=</span><span> </span><span>buildGraphbackAPI</span><span>(</span><span>modelDefs</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  serviceCreator</span><span>:</span><span> </span><span>createCRUDService</span><span>(</span><span>{</span><span> pubSub</span><span>:</span><span> </span><span>new</span><span> </span><span>PubSub</span><span>(</span><span>)</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  dataProviderCreator</span><span>:</span><span> </span><span>createKnexDbProvider</span><span>(</span><span>db</span><span>)</span><span>,</span><span></span></p><p><span>  plugins</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>    </span><span>new</span><span> </span><span>SchemaCRUDPlugin</span><span>(</span><span>{</span><span>...</span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>    </span><span>new</span><span> </span><span>DataSyncPlugin</span><span>(</span><span>{</span><span>...</span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>]</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></div></div></div></div><p>Graphback can be added to any existing GraphQL application (in Node.js), or you can create a project from scratch with <a href="https://graphql-cli.com/" target="_blank" rel="noopener noreferrer">GraphQL CLI</a>.</p><div><div><div tabindex="0"><div><p><span>$ npx graphql-cli init</span></p><p><span>? Select the best option </span><span>for</span><span> you I want to create a new project from a GraphQL CLI Project Template.</span></p><p><span>? What is the name of the project? cool-graphback-project</span></p></div></div></div></div><h3>Choose your database...or databases</h3><p>Graphback works with both SQL and NoSQL databases. Use the <a href="https://www.npmjs.com/package/@graphback/runtime-knex" target="_blank" rel="noopener noreferrer"><code>@graphback/runtime-knex</code></a> package to connect to a PostgreSQL database, and <a href="https://www.npmjs.com/package/@graphback/runtime-mongo" target="_blank" rel="noopener noreferrer"><code>@graphback/runtime-mongo</code></a> to connect to MongoDB.</p><p>It’s as straightforward as changing a couple of lines in your code to switch between database providers and start to query and persist your data.</p><div><div><div tabindex="0"><div><p><span>...</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> createMongoDbProvider </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/runtime-mongo'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> </span><span>DataSyncPlugin</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/datasync'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> db </span><span>=</span><span> </span><span>connectMongoDB</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>{</span><span> typeDefs</span><span>,</span><span> resolvers</span><span>,</span><span> contextCreator </span><span>}</span><span> </span><span>=</span><span> </span><span>buildGraphbackAPI</span><span>(</span><span>modelDefs</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  dataProviderCreator</span><span>:</span><span> </span><span>createMongoDbProvider</span><span>(</span><span>db</span><span>)</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></div></div></div></div><p>With <a href="https://graphback.dev/docs/api/graphback/modules/_buildgraphbackapi_#graphbackdataprovidercreator" target="_blank" rel="noopener noreferrer"><code>dataProviderCreator</code></a> you can easily use multiple data sources in one application:</p><div><div><div tabindex="0"><div><p><span>import</span><span> </span><span>{</span><span> </span><span>KnexDBDataProvider</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/runtime-knex'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> </span><span>MongoDBDataProvider</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'@graphback/runtime-mongo'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>{</span><span> typeDefs</span><span>,</span><span> resolvers</span><span>,</span><span> contextCreator </span><span>}</span><span> </span><span>=</span><span> </span><span>buildGraphbackAPI</span><span>(</span><span>modelDefs</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>dataProviderCreator</span><span>:</span><span> </span><span>(</span><span>model</span><span>:</span><span> ModelDefinition</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>[</span><span>'Note'</span><span>,</span><span> </span><span>'Comment'</span><span>]</span><span>.</span><span>includes</span><span>(</span><span>model</span><span>.</span><span>graphqlType</span><span>.</span><span>name</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>return</span><span> </span><span>new</span><span> </span><span>KnexDBDataProvider</span><span>(</span><span>model</span><span>,</span><span> </span><span>Knex</span><span>(</span><span>{</span><span>...</span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>return</span><span> </span><span>new</span><span> </span><span>MongoDBDataProvider</span><span>(</span><span>model</span><span>,</span><span> db</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></div></div></div></div><h2>Before we go</h2><p>Kickstart your GraphQL experience with Graphback today using the <a href="https://graphql-cli.com/" target="_blank" rel="noopener noreferrer">GraphQL CLI</a>, or follow <a href="https://graphback.dev/docs/getting-started/add-to-project" target="_blank" rel="noopener noreferrer">our guide to add Graphback to your existing project</a> with minimal work. </p><p>Enjoying Graphback? We’d love to hear from you; and if you can see things that could to be improved, tell us! We want your feedback so we can continue to make Graphback better every day. </p><p>Join our <a href="https://discordapp.com/invite/vSCavr" target="_blank" rel="noopener noreferrer">Discord server</a> to reach us directly or go to our <a href="https://github.com/aerogear/graphback" target="_blank" rel="noopener noreferrer">GitHub</a> to create an issue or pull request.</p><p>I can't leave without some special shout outs to the following people who were actively involved in shaping Graphback:</p><ul><li><a href="https://github.com/ssd71" target="_blank" rel="noopener noreferrer">@ssd71</a></li><li><a href="https://github.com/ankitjena" target="_blank" rel="noopener noreferrer">@ankitjena</a></li><li><a href="https://github.com/lastmjs" target="_blank" rel="noopener noreferrer">@lastmjs</a></li><li><a href="https://github.com/renovate-bot" target="_blank" rel="noopener noreferrer">@renovate-bot</a> - bots deserve ❤️ too 🤖!</li></ul></section></article></div>]]>
            </description>
            <link>https://graphback.dev/blog/2020/10/01/announcing-graphback-1.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908976</guid>
            <pubDate>Tue, 27 Oct 2020 16:27:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908917">thread link</a>) | @laybak
<br/>
October 27, 2020 | https://informedpm.com/posts/writing-product-manager | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/writing-product-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>Do you have "exceptional communication skills"? Well, it is a requirement in every product manager job description. Writing is a core part of a PM's job. Be it emails, documents, status updates. </span></p> <p><span>In this article, I distilled the principles and tactics collected from masters of the craft of writing in various domains. If it sounds too simple or basic, that means I've done my job.</span></p> <p><span>Enjoy.</span></p>  <p><h3><span>Keep It Simple</span></h3></p> <p><span>In written communication at work, your objectives are clarity and persuasion. If you remember just one thing from this post: keep it simple. </span></p> <p><span>In the words of </span> <a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/06/the_day_you_bec.html" target="_blank"><span>Scott Adams</span></a> <span>: </span> <em>"A good argument in five sentences will sway more people than a brilliant argument in a hundred sentences. Don’t fight it."</em></p> <p><span>Style is a small part of writing well, especially in a work setting. Focus on getting your point across.</span></p>  <p><h3><span>Miscommunication is Costly</span></h3></p> <p><span>Miscommunication is costly. And the reader likely </span> <em>won't tell you</em> <strong> </strong> <span>if they don't understand what you are saying. They will just ignore it, or interpret it the way they think is right. As the saying goes, "it's not what you say, it's what people hear".</span></p> <p><span>You can't persuade someone if they don't even understand you. Worse yet, misunderstanding among your stakeholders can lead to the wrong product being built. And that is expensive.</span></p> <p><span>Make your point as easy as possible to understand. </span></p>  <p><h3><span>Help the Reader Out</span></h3></p> <p><span>Everyone is busy. That's why people are much more likely to skim than to peruse your writing. </span></p> <p><span>Make your writing easy to parse. Optimize the content for scanning. Break up your walls of text, because no one will read them. Use more bullet points, whitespace, and clear headings.</span></p> <p><span>Just get your point across. And help your stakeholders move on with their day. </span></p>  <p><h3><span>Use Simple Words</span></h3></p> <p><span>Avoid words that would require the reader to reach for the dictionary, because most won't. And when they don't understand the word, they either skip it or guess it. </span></p> <p><span>Your job isn't to sound smart or write poetry. Your job is to communicate effectively to ship successful products.</span></p>  <p><h3><span>Use Fewer Words</span></h3></p> <p><span>Write with an eraser in hand. Messages with fewer words are easier to understand.</span></p> <p><span>In the words of George Orwell: "if it is possible to cut a word out always cut it out."</span></p> <p><span>Examples of words to cut out: "really", "very", "amazing", and adjectives in general. Chances are, the additional words won't add to your point. </span></p>  <p><h3><span>Use Short Sentences</span></h3></p> <p><span>Don't put more than one idea in each sentence. One sign that you are doing this wrong is having run-on sentences with lots of commas. To combat that, try using a period where you would normally use a comma.</span></p>  <p><h3><span>Use Visuals</span></h3></p> <p><span>Include visuals in your written communication where possible. Paint a vivid picture for the reader. This could mean diagrams, charts, or even sketches that illustrate your point.</span></p> <p><span>It both makes your message easier to understand, and it is </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>more persuasive</span></a> <span>. </span></p>  <p><h3><span>Order Matters</span></h3></p> <p><span>In written communication, you present a sequence of ideas in a particular order. And that order matters.</span></p> <p><span>Make your point early on. Your first sentence or two should grab the reader. Because again, people are busy. Is this something they would want to keep reading? </span></p> <p><span>The order also affects how the reader's brain understands the message. As a rule of thumb, we are faster at understanding active voice than passive voice in English. </span></p> <p><span>Once you are done writing, re-read it (preferably aloud) to check the flow.</span></p>  <p><h3><span>Provide Context</span></h3></p> <p><span>As the reader reads your writing, one thought question that they always have is "Why should I care?" The answer to that question should be clear. Establish this early.</span></p> <p><span>Hyperlinks are helpful for packing more context to your writing without taking up additional space. Link to shared documents where possible in case your stakeholders need more information. This saves some back-and-forth questions and keeps the source of truth easier to maintain.</span></p>  <p><h3><span>Repeat the Important Points</span></h3></p> <p><span>Because the reader is likely to skim, repeat the important points in case they missed them. And the down-side is limited. When the reader scans something they already read, they will just filter it out.</span></p> <p><span>The repetition doesn't need to take place in the same document either. You can repeat in the form of follow-ups, reminders, summaries etc.</span></p> <p><span>As a bonus side effect, repetition is </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>persuasive</span></a> <span>. </span></p>  <p><h3><span>Bold Words, Sparingly</span></h3></p> <p><span>Use contrast to make the key pieces of information pop, by bolding or highlighting keywords. This makes your writing easier to scan. </span></p> <p><span>Don't overdo it though. If everything is important, nothing is.</span></p>  <p><h3><span>Further Readings</span></h3></p>              


          
          
          <p><em>Each week, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/writing-product-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908917</guid>
            <pubDate>Tue, 27 Oct 2020 16:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: *scratch*.js – Interactive Javascript scratchpad]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908796">thread link</a>) | @kahole
<br/>
October 27, 2020 | https://hole.dev/scratch/ | <a href="https://web.archive.org/web/*/https://hole.dev/scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hole.dev/scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908796</guid>
            <pubDate>Tue, 27 Oct 2020 16:09:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing Teams client protocol to bypass Teams security policies]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24908776">thread link</a>) | @tommoor
<br/>
October 27, 2020 | https://o365blog.com/post/teams-policies/ | <a href="https://web.archive.org/web/*/https://o365blog.com/post/teams-policies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<figure>
				<img src="https://o365blog.com/images/posts/teams-policies.png" alt="Abusing Teams client protocol to bypass Teams security policies">
			</figure>
				<nav id="TableOfContents">
<ul>
<li><a href="#what-are-teams-policies">What are Teams policies?</a></li>
<li><a href="#bypassing-teams-policies">Bypassing Teams policies</a>
<ul>
<li><a href="#initial-discovery">Initial discovery</a></li>
<li><a href="#observing-teams-client-behaviour">Observing Teams client behaviour</a></li>
<li><a href="#testing-in-action">Testing in action</a></li>
</ul></li>
<li><a href="#detecting-and-protecting">Detecting and protecting</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References:</a></li>
</ul>
</nav>
			<p>Administrators can use teams policies for controlling what users can do in Microsoft Teams.</p>

<p>In this blog, I’ll show that these policies are applied only in client and thus can be easily bypassed.</p>





<p>Policies are used in Microsoft Office 365 and Azure AD for securing access to services and data. Besides the <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">common identity and device access policies</a>,
Microsoft has provided a set of <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Teams specific policies</a>:</p>

<ul>
<li>Teams and channel policies</li>
<li>Messaging policies</li>
<li>Meeting policies</li>
<li>App permission policies</li>
</ul>

<p>For example, administrators can configure Teams so that external users are not able to edit or delete any messages they’ve sent. Or, an owner of a Teams site can disable message editing for members of a certain channel.</p>



<h2 id="initial-discovery">Initial discovery</h2>

<p>While I was working with the previous version (v0.4.4) of <a href="https://o365blog.com/aadinternals" target="_blank">AADInternals</a> Teams functions I noticed an interesting thing: I was able to edit and delete chat messages using AADInternals as a guest
even when it was not allowed.</p>

<p>This led to a question that <strong>what if the policies are applied only at the client end?</strong> In practice this would mean that the Teams service tells to your Teams client that “Though shall not edit messages!” but the client
could still do so.</p>

<h2 id="observing-teams-client-behaviour">Observing Teams client behaviour</h2>

<p>I started by watching what was going on between the client and cloud when the Teams client started. The first observation was that the client made about 120 http requests to the cloud.
While browsing through those requests, I spotted one that caught my interest (headers stripped):</p>

<pre><code>POST https://teams.microsoft.com/api/mt/part/emea-02/beta/users/useraggregatesettings HTTP/1.1

{
    "tenantSettingsV2": true,
    "userResourcesSettings": true,
    "messagingPolicy": true,
    "clientSettings": true,
    "targetingPolicy": true,
    "tenantSiteUrl": true,
    "userPropertiesSettings": true,
    "callingPolicy": true,
    "meetingPolicy": true,
    "educationAssignmentsAppPolicy": true
}
</code></pre>

<p>The response contained all the settings and policies the Teams client is allowed to do as the logged in user. Below can be seen the <strong>messagingPolicy</strong> section:
</p><div><pre><code data-lang="json"><span></span><span>"messagingPolicy"</span><span>:</span> <span>{</span>
	<span>"value"</span><span>:</span> <span>{</span>
		<span>"allowUserEditMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserDeleteMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserChat"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowGiphy"</span><span>:</span> <span>true</span><span>,</span>
		<span>"giphyRatingType"</span><span>:</span> <span>"Moderate"</span><span>,</span>
		<span>"allowGiphyDisplay"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPasteInternetImage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowMemes"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowStickers"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserTranslation"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUrlPreviews"</span><span>:</span> <span>true</span><span>,</span>
		<span>"readReceiptsEnabledType"</span><span>:</span> <span>"UserPreference"</span><span>,</span>
		<span>"allowImmersiveReader"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPriorityMessages"</span><span>:</span> <span>true</span><span>,</span>
		<span>"audioMessageEnabledType"</span><span>:</span> <span>"ChatsAndChannels"</span><span>,</span>
		<span>"channelsInChatListEnabledType"</span><span>:</span> <span>"DisabledUserOverride"</span><span>,</span>
		<span>"allowRemoveUser"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowSmartReply"</span><span>:</span> <span>true</span>
	<span>}</span>
<span>}</span>
</code></pre></div>


<p>What we can learn here is that the Teams client asks from the cloud what the current user is allowed to do, which was the expected behaviour.</p>

<h2 id="testing-in-action">Testing in action</h2>

<p>Next I decided to try whether I could lie to Teams client:</p>

<ol>
<li><p>I saved the response from above to be used as a baseline.</p></li>

<li><div><p>I created a new Messaging policy to disable editing and deleting of sent messages.</p><p>
I applied the policy to a single demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies1.png" alt="Custom policy"></p><p>Now I had two policies, the default organisation wide and the restricted one for demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies2.png" alt="Policies"></p></div></li>

<li><p>I restarted the Teams client and noticed that the editing and deleting were correctly disabled (didn’t exists).</p></li>

<li><div><p>I compared the returned policies from the <strong>useraggregatesettings</strong> requests<br>
and as we can see, the request was missing two lines:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies3.png" alt="Policy comparison"></p></div></li>

<li><div><p>I closed the client and configured Fiddler to do an autoresponse using the saved http response from above:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies4.png" alt="Fiddler autoresponse"></p><p>
Now, when the client is requesting the settings file, it will be served the one that allows editing and deleting.</p></div></li>

<li><p>I started the Teams client and <strong>the editing and deleting were again allowed</strong> and I was able to edit and delete (my own) messages!</p></li>
</ol>

<p>What we can lean here is that <strong>we can lie to Teams client</strong> and change its behaviour 😂 <br>
Moreover, we learnt that <strong>Teams policies are applied only on the client</strong> 🤦‍♂</p>

<p>Here is the video demonstrating this with <strong>AADInternals</strong> and <strong>Fiddler</strong> (sorry for the bad audio after 03:20):</p>

<div><iframe width="560" height="315" src="https://www.youtube.com/embed/Zcqig-OyUMY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>

<p>Below is a video that shows in action that this works also with <strong>cloud file storage restrictions</strong>:<br></p>

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/a32TkLIBwS4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<br><strong>Note:</strong> Although not seen on the video, I was able to add my Google Drive account to Teams so this is not just a UI thing.</p>



<p>As far as I know, the “uncompliant” Teams client behaviour can not be detected.</p>

<p>Same verdict with protecting. Well, one could try to use Conditional Access (CA) with device ownership and compliance restrictions, but that doesn’t cover all scenarios.</p>



<p>Our little test here proves that <strong>Teams policies are applied ONLY on the client!</strong>.</p>

<p>If the user (or guest) is utilising Teams APIs directly, using for instance AADInternals <a href="https://o365blog.com/aadinternals/#teams-functions" target="_blank">Teams functionality</a>, he or she can bypass the restrictions set by the policies.
However, this is not a bug or vulnerability as such, but a (very very bad) design choice by Microsoft.</p>

<p>Users can do at least the following:</p>

<ul>
<li>Bypass messaging policies</li>
<li>Bypass cloud file storage restrictions</li>
<li>Bypass meetings policies</li>
</ul>

<p>⚠️ <strong>Teams policies are NOT a security measure and organisations should not rely on them!</strong> ⚠️</p>



<ul>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">Common identity and device access policies</a></li>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Policy recommendations for securing Teams chats, groups, and files</a></li>
</ul>
		</div></div>]]>
            </description>
            <link>https://o365blog.com/post/teams-policies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908776</guid>
            <pubDate>Tue, 27 Oct 2020 16:07:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 game development (TI-86)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908765">thread link</a>) | @todsacerdoti
<br/>
October 27, 2020 | http://jgmalcolm.com/z80/ | <a href="https://web.archive.org/web/*/http://jgmalcolm.com/z80/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

      <p>This is a collection of tutorials on developing games in z80 assembler for the
TI calculators.  While focused on the TI86, much of this applies to any
z80-based TI calculator: TI85, TI83/+, TI84/+, TI82.</p>

<ul>
  <li><a href="#beginner">Beginner</a> - getting started with assembler code, registers, arithmetic, flags, and memory</li>
  <li><a href="#intermediate">Intermediate</a> - more details on the beginner topics</li>
  <li><a href="#graphics">Graphics</a> - manipulating pixels and grayscale</li>
  <li><a href="#advanced">Advanced</a> - ports, hidden TI-OS features</li>
  <li><a href="#opcodes">Opcodes</a> - listing of all z80 opcodes (numeric or alphabetic)</li>
  <li><a href="#variables">Variables</a> - manipulate TI-OS variables</li>
  <li><a href="#menus">Menus</a> - creating native TI-OS menus</li>
  <li><a href="#design">Design</a> - planning and game design, writing clean code</li>
  <li><a href="http://jgmalcolm.com/z80/download/download">Downloads</a> - tools, examples, algorithms</li>
</ul>

<p><img src="http://jgmalcolm.com/z80/1996.png" alt="xkcd: 1996" title="xkcd #768: '1996'"></p>

<h2 id="beginner">Beginner</h2>

<ul>
  <li><a href="http://jgmalcolm.com/z80/beginner/numb">Number Bases</a> - Learn how to understand and convert
between the different number systems such as binary and hexadecimal. Make
your calculator do all the work.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/z80p">z80 Processor</a> - History and specifications of the z80
processor. What’s really behind the games.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/ti86">TI86 Specs</a> - Basic information about the TI86, ROM
versions, and the LCD.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/form">Format and Compiling</a> - Start coding. Get the necessary
tools to get you on your way. Walk through creating your first program
and running it.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/ohno">Oh, No! It Crashed!</a> - What to do when it freezes up on
you. A step-by-step diagnosis.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/ti-b">TI-BASIC versus Asm</a> - A simple chart to show you
equivalent tasks in z80 asm and the old TI-BASIC.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/alia">Aliases</a> - Equates and include files. Download the
hottest include files around. Make your own equates.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/regi">Registers</a> - How to store and manipulate values.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/inst">Instructions</a> - Start working up your own
programs. Learn the basic syntax of assembler instructions. A great place to
reference all those little mnemonics and what they do.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/flag">Flags and Conditions</a> - <code>if</code> statements.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/math">Math</a> - Learn the basics of simple math routines like
multiplying, dividing, adding, and subtracting.</li>
  <li><a href="http://jgmalcolm.com/z80/beginner/twos">Two’s Compliment</a> - Negative numbers and how to use
them.</li>
</ul>



<ul>
  <li><a href="http://jgmalcolm.com/z80/intermediate/logi">Logical Operators</a> - Introduction to <code>and</code>, <code>or</code>,
and <code>xor</code>. How to mask out bits and control binary data.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/misc">Miscellaneous Instructions</a> - These don’t fit in
anywhere? <code>neg</code>, <code>scf</code>, and others!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/allt">All the Flags</a> - Besides the zero and carry flags,
there are four others! What do they all do? Come find out!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/rstc">Restart Commands</a> - Faster <code>call</code>s with the help of
these one byte instructions used for some of the most frequent ROM calls.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/memo">Memory and Pages of It</a> - Dive into the
memory of your calculator. What is Consecutive Addressing and how to
reference addresses in memory. Explore some safe areas to store data at!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/vari">Variables</a> - Start off storing user input and data
like high scores and such.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/stac">The Stack</a> - Ever heard of "Last On, First Off"?
Save register pairs and recall their values later with <code>push</code> and <code>pop</code>!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/tabl">Tables and Arrays</a> - The famous <code>for</code> loop used in
recursion. Take advantage of the <code>ix</code> and <code>iy</code> register pairs for lists with
an intro into matrices!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/simu">Simulated 16-bit Addition</a> - A faster method of
adding <code>a</code> to <code>hl</code>. In time crunch areas, this beats conventional methods.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/rand">Random Numbers</a> - Need a random number? This is the
place for you! Take your pick of different routines, all designed to
give you a different number each time.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/romc">TI’s ROM Calls</a> - Why draw up your own routine when
TI’s already got a ton. Use their calls for printing text, checking
keypresses, clearing the screen, and much much more!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/getkey">Getkey</a> - Get user input in a flash with
<code>_GetKey</code>! This routine gives you the ability to respond to certain key
presses. Here you’ll find charts filled with key press codes with their
equates, a handy reference!</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/pcsp">Program Counter, Stack Pointer</a> - Two fundamental
registers the z80 uses to keep track of executing code.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/text">Text Display</a> - Print text on the screen in an
instant with your choice of several routines printing everything from
individual characters to entire paragraphs. Learn how to print in standard
or small text with a look at how to create your own
<a href="http://jgmalcolm.com/z80/advanced/font">custom fonts</a>.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/down">Down-Left Bug</a> - Why does the calculator freeze when
you press down-left?</li>
</ul>

<h2 id="graphics">Graphics</h2>

<p>Pixel manipulation and sprite animation. Line-by-line walk throughs of the
most popular graphics routines.</p>

<ul>
  <li><a href="http://jgmalcolm.com/z80/intermediate/scre">The Screen</a> - Introduction to the LCD, Video Memory,
and how the pixels are stored in memory.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/find">Find Pixel</a> - Find where on the screen pixels are
supposed to be from manipulating the coordinates.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/pixe">Pixel Manipulation</a> - Setting, reseting, and testing
pixels using Find Pixel.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/spri">Sprites</a> - Printing small images on the screen.</li>
  <li><a href="http://jgmalcolm.com/z80/intermediate/tile">Tile Maps</a> - Draw game levels on the screen using
compact level data.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/gray">Grayscale Graphics</a> - Blend black and white to make
gray. Check out this line-by-line analysis of one of the hottest Grayscale
routines out there.</li>
</ul>

<h2 id="advanced">Advanced</h2>

<ul>
  <li><a href="http://jgmalcolm.com/z80/advanced/inde">More Registers</a> - Now you have even more with the
addition of a whole hidden set of registers banks. Also, learn about the
Index and Refresh Registers.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/read">Reading Keys from Port</a> - Don’t wait up for that slow
<code>_GetKey</code>, scan for keys in an instant with Port 0. You can always count on
the Ports for quick results. Also included, a handy reference table with key
bitmasks for every key.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/asse">Assembler Directives</a> - Customize your source code in a
flash with macros. Reference just about every directive available for the
TASM Assembler.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/onof">On-Off</a> - Turn your calculator On or Off in a flash
using the ports. Even put it in low power mode to conserve energy. Take a
peek at how TI-OS turns itself On and Off.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/shif">Shift and Rotate</a> - Move bits left or right within a
byte. This handy reference provides examples and graphical representations
of what each instruction does!</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/entr">Entry Stack</a> - Access and manipulate the user input
history.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/morp">Morphic Code</a> - Programs that edit themselves, what a
dream! Preload code with values, manipulate routines, and more.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/allp">All the Ports</a> - Communicate with the z80’s hardware
behind the scenes. Change the Video Screen address, adjust the contrast,
change the power mode, etc.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/squa">Square Root Programs</a> - Take command of the many common
tasks of TI-OS such as Parsing, Tokenizing, <code>_GetKey</code>, Graphing, and much
much more! TI-OS lets you run your own programs before or after it performs
these tasks. Step in and manipulate data before TI-OS gets it.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/syst">System Flags</a> - Want a complete listing of TI-OS’ flags?
You got it! This reference gives you everything you need to know about
customizing the options of TI-OS from Graph Methods to Operand calculations.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/apd">Auto Power Down</a> - Like a screen saver, TI-OS will shut
down after inactivity. Learn how to control this process and use it to your
advantage.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/soun">Sound</a> - How to produce mono sound with a few small
parts. These step-by-step instructions walk you through the process of
building speakers and then programming sound into your games. You can even
convert Wave files.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/simu">Simulating Key Presses</a> - Kind of like macros, have the
TI86 think you’re pushing keys and respond to them when you’re not even
touching the calculator.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/font">Fonts</a> - Create your own fonts for TI-OS to for
everything.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/inte">Interrupt</a> - Create your own routine to be run about 200
times a second in the background of regular code.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/im1i">Interrupt Mode 1</a> - Run a routine 200 times a second
to perform background tasks.</li>
  <li><a href="http://jgmalcolm.com/z80/advanced/im2i">Interrupt Mode 2</a> - Run a routine randomly chosen from a
jump table 200 times a second.</li>
</ul>

<h2 id="opcodes">Opcodes</h2>

<ul>
  <li><a href="http://jgmalcolm.com/z80/opcodes/opcodes">Overview</a></li>
  <li><a href="http://jgmalcolm.com/z80/opcodes/opcodesB">Sorted by value</a></li>
  <li><a href="http://jgmalcolm.com/z80/opcodes/opcodesN">Sorted by name</a></li>
</ul>

<h2 id="variables">Variables</h2>

<ul>
  <li><a href="http://jgmalcolm.com/z80/variables/ti86">TI86 Variable Manipulation</a> - Manipulating data behind
TI-OS’ back. What are the Operator Registers?</li>
  <li><a href="http://jgmalcolm.com/z80/variables/vari">Variable Name Format</a> - How to set-up variables’ names
in the OP Registers. Learn about the Variable Type byte with the included
reference chart and numerous full examples.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/crea">Creating Variables</a> - You can generate just about any
variable type you want through these asm calls.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/findsym">_FindSym</a> - The basis for <em>all</em> variable manipulation,
<code>_FindSym</code> finds variable data addresses fast. A must for all who want to
work with TI-OS variables!</li>
  <li><a href="http://jgmalcolm.com/z80/variables/abso">Absolute Addressing</a> - A 24-bit address? That’s right!
Since there’s more than 64 kilobytes of memory, you need to be familiar with
TI’s method of absolute addressing. It’s used <em>all</em> the time with TI-OS
variables.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/mess">Messing with Data</a> - This is the meat of the topic: How
to manipulate the data within the TI-OS Variables! Through step-by-step
examples, you’ll learn how to edit everything from Lists and Complex
Matrices to Real Numbers and Strings! You can even download source code for
Tokenized, Un-Tokenized, and Assembler Programs.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/bcd">Binary Coded Decimal</a> - Format Floating Point decimal
numbers. Work with exponents, Complex and Real numbers, and negative
numbers. Examples are illustrated in tables and code snippets!</li>
  <li><a href="http://jgmalcolm.com/z80/variables/vats">VAT Searches</a> - Learn the methodology behind the
Variable Allocation Table and how to search through it. You can even walk
through the line-by-line analysis of one of the hottest search routines out
there! Learn how to make your own shell.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/exte">External Levels</a> - Access and execute other variables
on the calculator as level data, plug-ins, and much more. Customizable,
full-featured programs are just around the corner.</li>
  <li><a href="http://jgmalcolm.com/z80/variables/op_m">OP_ Math</a> - Get an understanding of how to perform
Floating Point math with the Operator Registers. You can even check out TI’s
own routine to input strings or values.</li>
</ul>



<p>Create full featured, native TI-OS Menu Trees. Have one on the bottom like the
Custom Menu or branch that one out into other Menu Trees. Create a menu with
conversions, constants, program names, and more.</p>

<ul>
  <li><a href="http://jgmalcolm.com/z80/menus/exec">Executing Menus</a> - The place to start, here you’ll learn
about two routines that tie up the whole process. It’s as simple as loading
a pointer!</li>
  <li><a href="http://jgmalcolm.com/z80/menus/crea">Creating Menus</a> - Here’s where the full customization of
the menus comes into play. Create multiple menus with Paste, Branch, or
Execute Items!</li>
  <li><a href="http://jgmalcolm.com/z80/menus/romm">ROM Menus</a> - Take advantage of TI’s own menu
structures. Use them as patches for your own structures!</li>
</ul>

<h2 id="design">Design</h2>

<ul>
  <li><a href="http://jgmalcolm.com/z80/design/desi">The Design Process</a> - Take a walk through designing a
game. Go step-by-step as you create a well designed game that will last for
ages. Great design is essential for great games.</li>
  <li><a href="http://jgmalcolm.com/z80/design/clea">Clean Code</a> - A must read for all programmers, this
section gives details and examples of what to do and what <em>not</em> to do. These
key points will change the way you program.</li>
</ul>

<h2 id="dedicated-to-those-who-taught-me">Dedicated to those who taught me</h2>
<p><a href="mailto:assets@eden.rutgers.edu">Dux Gregis</a>,
<a href="mailto:mja@algonet.se">Jimmy Mårdell</a>,
<a href="mailto:JayEll64@aol.com">Jay Hellrungen</a>,
<a href="mailto:luezma@netscape.net">Patrick Davidson</a>,
<a href="mailto:ComAsYuAre@aol.com">Jonah Cohen</a>,
<a href="mailto:kirkmeyer@bigfoot.com">Kirk Meyer</a>,
<a href="mailto:david@acz.org">David Phillips</a>,
<a href="mailto:bailela@charlie.cns.iit.edu">Alan Bailey</a>,
<a href="mailto:kazmet@sonic.net">Adrian Mettler</a></p>

<p>This …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jgmalcolm.com/z80/">http://jgmalcolm.com/z80/</a></em></p>]]>
            </description>
            <link>http://jgmalcolm.com/z80/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908765</guid>
            <pubDate>Tue, 27 Oct 2020 16:06:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game Trends #3 – Virtual Streamers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908694">thread link</a>) | @jonwalch
<br/>
October 27, 2020 | https://gametrends.gg/p/game-trends-3-virtual-streamers | <a href="https://web.archive.org/web/*/https://gametrends.gg/p/game-trends-3-virtual-streamers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Feel Good Inc. by Gorillaz was my first experience with a “virtual band”. Virtual bands, virtual YouTubers, and virtual streamers are all the same concept; the people creating and performing are not the focus. CGI characters are replacing humans, even outside of animation.&nbsp;</p><p>Virtual performers are not new. Alvin and the Chipmunks are the earliest example. Other notable Western examples include Dethklok and Crazy Frog.</p><p>Japan and the East, unsurprisingly, love virtual performers. Hatsune Miku is one of the most popular. She has widely attended live concerts. K/DA is a virtual K-pop group composed of characters from Riot’s League of Legends that has also seen enormous global success.</p><p id="youtube2-YSyWtESoeOc" data-attrs="{&quot;videoId&quot;:&quot;YSyWtESoeOc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/YSyWtESoeOc?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p>Virtual streaming was really kicked off in 2016 by Kizuna AI. Kizuna plays video games just like other streamers, but she is entirely virtual. Body movements are likely motion captured or pre animated. Her voice is a paid actress. She embodies many cutesy anime girl tropes.&nbsp;</p><p>Previously, streaming was dominated by young men on Twitch in the West, which didn’t appeal to Eastern audiences. Japan was already primed because of their penchant for virtual idols. Kizuna likely uses the same freeware, MikuMikuDance, as Hatsune Miku.</p><p id="youtube2-3AK24prZk-k" data-attrs="{&quot;videoId&quot;:&quot;3AK24prZk-k&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/3AK24prZk-k?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><div><p>The Japanese popularity of virtual streamers has influenced a new generation of Twitch streamers. Streamers like projektmelody (NSFW) and BuffPup do well in their niches. The vast majority of virtual streamers follow the trail blazed by virtual idols and Kizuna AI. Typically they are young female anime avatars that speak Japanese.</p><p>BuffPup stands out. BuffPup is one of the earliest virtual streamers to branch out from its anime roots into furry fandom. I’ll let you look that one up if you’re unfamiliar. Virtual streaming is clearly still in its infancy. Expressiveness of many virtual streamers is lacking, which leaves a huge opportunity for the right tech to push the medium forward. Many fall into uncanny valley territory.</p></div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F488692c5-d040-43fb-b228-79189c0dfe9e_1080x888.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F488692c5-d040-43fb-b228-79189c0dfe9e_1080x888.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/488692c5-d040-43fb-b228-79189c0dfe9e_1080x888.jpeg&quot;,&quot;height&quot;:888,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:112162,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><div><p>Since Riot is already getting their feet wet with virtual performers, I expect this trend to continue in the industry. Every major publisher will have a virtual version of their characters playing their games, streamed live. Publishers will pay actors to do motion / facial capture as well as live voice. Fans will finally be able to interact directly with their favorite video game characters. This market alone will be enormously profitable, since it can leverage existing live streaming monetization techniques.</p><p>Gaming companies will double down into motion capture and face filter-like technologies. They’ll branch into AI generated voice tech, or acquire it. Once the tech gets there, virtual streaming will be an extremely high margin business, because even the talent will be fully automated. At least in the short and medium term, this will mean more jobs for actors, so that’s a plus.</p></div><p>Stats:</p><ul><li><p>K/DA has over 384 million views on this video</p></li></ul><p id="youtube2-UOxkGD8qRB4" data-attrs="{&quot;videoId&quot;:&quot;UOxkGD8qRB4&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/UOxkGD8qRB4?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><ul><li><p>Kizuna AI has over 2.8 million subscribers on Youtube and videos with over 14 million views</p></li><li><p>projektmelody (NSFW) has 289,000 followers on Twitch, and routinely has 3,500+ concurrent viewers</p></li><li><p>64+ virtual streamers on Twitch (https://www.twitch.tv/team/antilewdarmy)</p></li></ul></div></div>]]>
            </description>
            <link>https://gametrends.gg/p/game-trends-3-virtual-streamers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908694</guid>
            <pubDate>Tue, 27 Oct 2020 15:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Election Forecast Correlations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908617">thread link</a>) | @1wheel
<br/>
October 27, 2020 | https://roadtolarissa.com/forecast-correlation/ | <a href="https://web.archive.org/web/*/https://roadtolarissa.com/forecast-correlation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
  
  
  <!-- <time>2020-10-25</time> -->
  


<p><a href="https://projects.fivethirtyeight.com/2020-election-forecast/">538</a> and the <a href="https://projects.economist.com/us-2020-forecast/president">Economist</a> have both released detailed data from their election forecasts, listing how each state votes in 40,000 simulations of the presidential election. To understand some unusual scenarios from the 538 model, like every state <a href="https://twitter.com/gelliottmorris/status/1300480869082292225">voting for Biden but New Jersey</a>, Andrew Gelman <a href="https://statmodeling.stat.columbia.edu/2020/10/24/reverse-engineering-the-problematic-tail-behavior-of-the-fivethirtyeight-presidential-election-forecast/">examined the correlation</a> in the Trump vote share between pairs of several states. </p>
<p>I was curious what the whole universe of pairwise correlations looked like; you can click on a grid cell below to see voting patterns in two states in more detail along with the electoral maps from individual simulation scenarios. In the 538 model, 242 pairs of states are <span>negatively correlated</span>!</p>


<p>Mousing around the edges of the scatter plot pulls out more unusual scenarios, like Trump losing everywhere but <code>CA-HI-VT</code>. </p>
<p>On the correlation matrices, it appears that both models have identified similar groups of states. A scatter plot shows this directly: </p>


<p>Outside of the <code>CA-DC-VT-WA</code> and <code>LA-MS-ND-KY</code> clusters, where the 538 correlation dips below 0, the models are mostly aligned. Glancing over the outliers, it looks like the Economist might not have an equivalent to 538’s <a href="https://fivethirtyeight.com/features/how-fivethirtyeights-2020-presidential-forecast-works-and-whats-different-because-of-covid-19/">regional regression</a> that groups states in the same geographic region together; the Economist has <code>HI</code> at 0.2 correlation with <code>WA</code> &amp; <code>OR</code>  while 538 has it around 0.7.</p>
<p>Stepping back from the funky correlation charts, comparing the Trump vote share state by state clearly shows a bigger difference between the models: the <span>Economist model</span> considers really surprising outcomes, like Trump decisively winning <code>CA</code>, less likely than the <span>538 model</span>.</p>


<p>I haven’t followed the extensive discussion around election modeling closely enough to have a strong opinion on what all of this means, but it does look like the 538 model is allowing for the <a href="https://twitter.com/Nate_Cohn/status/1320043524771991560">possibility</a> of a broad <a href="https://twitter.com/NateSilver538/status/1300825856072454145">realignment in politics</a>–something you’d want to incorporate when modeling 2024 today, but not plausible for an election next week with <a href="https://www.nytimes.com/interactive/2020/us/elections/absentee-ballot-early-voting.html">sixty million ballots</a> already cast.</p>
<div id="notes">
<p>Only 5,000 scenarios are shown on the scatter plots; the scenarios are a snapshot from 2020-10-25 and not updated (looking at the correlations over time might be interesting though!). The rendered electoral college scenarios ignore the possibility of <code>NE</code> or <code>ME</code> spliting their votes. 

</p><p>The correlations matrix orders states by clustering on 538’s correlations. Sorting using the Economist correlations <a href="https://i.imgur.com/JH9FC8I.png">splits up</a> the negative 538 correlations.

</p><p><a href="https://github.com/1wheel/roadtolarissa/tree/master/source/forecast-correlation">chart code</a>

</p></div> 











</div>]]>
            </description>
            <link>https://roadtolarissa.com/forecast-correlation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908617</guid>
            <pubDate>Tue, 27 Oct 2020 15:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spectral Neural Networks for Knowledge Graphs (In Scala)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908582">thread link</a>) | @gfrison1
<br/>
October 27, 2020 | https://gfrison.com/2020/graph-convolution-networks | <a href="https://web.archive.org/web/*/https://gfrison.com/2020/graph-convolution-networks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

7 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>The power of networks. Metaphors of our collective life, with all of its complexity and its entangled dependencies.
Two types of networks, the network of data and the network of artificial neurons when combined together open the way to a variety of interesting applications. Typical examples of data networks include social networks and the knowledge graphs, while, on the other hand, a new family of machine learning tasks based on neural networks has grown in the last few years. This lineage of deep learning techniques lay under the umbrella of graph neural networks (GNN) and they can reveal insights hidden in the graph data for classification, recommendation, question answering and for predicting new relations among entities. Do you want to know more about them?</p>
<p>When we talk of machine learning tasks, we refer to a set of algorithms that finds correlation between input and output. The input is basically a list of numbers also known as vectorized features:</p>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Vector representation</th>
</tr>
</thead>
<tbody>
<tr>
<td>hiking</td>
<td>0.12, 0.25, 0.66, 0.45</td>
</tr>
<tr>
<td>mountain</td>
<td>0.16, 0.29, 0.62, 0.40</td>
</tr>
<tr>
<td>seaside</td>
<td>0.02, 0.70, 0.39, 0.60</td>
</tr>
</tbody>
</table>
<p>The vector representation of the nodes in the knowledge graph should preserve, to the maximum extent, the information carried by the single node within its own attributes compressed in a low dimensional space. In other words, the embeddings (the name of the vectorized representation) should identify the related symbol with a vector, and such vectors should be as small as possible. The objective of this article is about to find a proper way to generate good embeddings out of knowledge graphs.</p>
<p>For being useful in downstream machine learning tasks, embeddings should not just identify the related symbol but also they should have an important property. Symbols that are similar to each other – for whatever criteria we define for ‘similarity’ – should be associated with embeddings that are also similar, according to the favorite distance functions. In the above example, Hiking embeddings are more closely related to Mountain rather than Seaside. Embeddings are very familiar for those practiced in <a href="https://gfrison.com/categories/#nlp">natural language processing</a>, and they are based on the principle <em>“a word is characterized by the company it keeps (R. Firth)”</em>, and the skip-gram technique is employed for predicting what is the most likely word surrounded by a given set of predecessors and successors. Applied to a huge corpora, the trained skip-gram (or its complementary cbow) network will contain the embeddings that fulfill the similarity property. While the words in a text are strictly in sequential order (with one predecessor and one successor), in a graph a node might hold a multitude of relations, and as if that is not enough, those relations might be different one to another.</p>
<p>Representation learning is flourishing and new approaches are invented at an increasing rate:</p>
<figure>
<img src="https://gfrison.com/assets/images/gcn/File.jpg" alt="Tecniques for generating embeddings with neural networks">
<figcaption>Tecniques for generating embeddings with neural networks</figcaption>
</figure>
<p>Hereafter, I will present just two techniques for generating embeddings in graphs. For the sake of statistics, I implemented Deepwalk and Graph convolutional networks (GCN) in Scala with ND4J for matrices, and Deeplearning4J as a neural network framework.</p>

<p>The Deepwalk (and its successor Node2Vec) is an unsupervised algorithm, one of the first in the realm of representation learning for graphs, and it is as simple in its design as it is effective on capturing topological and content information. In principle it is equivalent to the already mentioned skip-gram, but how can the graph structure match the streaming sequence of words in a text? Starting from any node of choice, the algorithm visits its neighbors and the entire network in a controlled random way. The random walk is balanced among two different approaches that emphasize differences in closely related nodes in one case, and the differences among distant clusters in the other. The first approach is the Breadth First Search (BFS) which selects the next node to visit among the siblings of the current node, in the respect of the previous node. The second approach is the Deep First Search (DFS) that selects the new node among the connected nodes with the current one. The first persists with all neighbors of the current node, while the second tends to explore the network in depth.</p>
<figure>
<img src="https://gfrison.com/assets/images/gcn/gcn-embeddings-karate.png" alt="Clusterization on Karate dataset with Deepwalk">
<figcaption>Clusterization on Karate dataset with Deepwalk</figcaption>
</figure>

<p>The graph convolutional networks, as the name might recall, share some commonalities with the convolutional neural network algorithm, the one that led the way to giant leaps in visual recognition. If a graph with nodes and edges is transposed in a two dimensional adjacent matrix, nothing can prevent us from running a sliding window function that compresses a grid of pixels and extracts features like CNNs do. The affinity with CNN ends here, because when we elaborate images we are more interested in complex visual features rather than single pixels. In knowledge graphs, on the other hand, we want to convolute in a single node its neighbours and recursively the information of the entire network.</p>

<p>The principle underlying GCNs lay its fundations on a method described several decades ago in the Weisfeiler-Lehman test. The test would determine whether two arbitrary graphs are isomorphic, i.e. they have exactly the same structure. According to the algorithm, all nodes are initialized with the same value, let’s put number 1 for all. Then, to that node is assigned that value plus the value of its neighbors, and this step is iterated. As you might think, in the first round the node already includes the information of first degree neighbors, but at the second iteration, the node will get a distilled notion of the second line of nodes, and so on as the iterations proceed. The test will confirm the isomorphism whether, after an arbitrary number of iterations, the partition of nodes by their current value does not change. Even though the isomorphism problem is not yet solved and the test is an heuristic attempt, the method brings the way to iteratively convolve information among the nodes.</p>

<p>The GCN method is described in Kipf &amp; Welling (ICLR 2017) and lies in the messaging passing methods family, whereas with “message” we intend solely the content of a single node and “passing” is the convolution which percolates throughout the network. While in the Weisfeiler-Lehman test the way to pass information is just a simple sum of values, in GCNs the convolution relies on the spectral propagation rule. What is this propagation rule? Let’s assume we know the graph structure (nodes and relations) and the content of all nodes (features). The propagation rule is applied with a linear matrix multiplication, but for not incurring in vanishing or exploding gradients in the downstream tasks, the features are normalized and a self-loop in the adjacency matrix is added.</p>
<figure><pre><code data-lang="scala"><span>import</span> <span>org.nd4j.linalg.factory.Nd4j._</span>

<span>def</span> <span>spectralLayer</span><span>(</span><span>adjacent</span><span>:</span> <span>INDArray</span><span>,</span> <span>input</span><span>:</span> <span>INDArray</span><span>,</span> <span>weights</span><span>:</span> <span>INDArray</span><span>)</span><span>:</span><span>INDArray</span> <span>{</span>
  <span>//add self-loops</span>
  <span>val</span> <span>ah</span> <span>=</span> <span>adjacent</span><span>.</span><span>add</span><span>(</span><span>eye</span><span>(</span><span>adjacent</span><span>.</span><span>columns</span><span>()))</span>
  <span>val</span> <span>ssm</span> <span>=</span> <span>create</span><span>((</span><span>0</span> <span>until</span> <span>ah</span><span>.</span><span>rows</span><span>).</span><span>map</span><span>(</span><span>ii</span> <span>=&gt;</span> <span>ah</span><span>.</span><span>getRow</span><span>(</span><span>ii</span><span>).</span><span>sumNumber</span><span>().</span><span>floatValue</span><span>())).</span><span>toArray</span>
  <span>//normalization</span>
  <span>val</span> <span>spectre</span> <span>=</span> <span>diag</span><span>(</span><span>pow</span><span>(</span><span>ssm</span><span>,</span> <span>-.</span><span>5</span><span>))</span>
  <span>//non linear-function (relu) to the spectral Rule</span>
  <span>relu</span><span>(</span><span>spectre</span><span>.</span><span>mmul</span><span>(</span><span>ah</span><span>).</span><span>mmul</span><span>(</span><span>spectre</span><span>).</span><span>mmul</span><span>(</span><span>input</span><span>).</span><span>mmul</span><span>(</span><span>weights</span><span>))</span>
<span>}</span>
<span>// the first layer takes a diagonal input and random weights</span>
<span>val</span> <span>l1</span> <span>=</span> <span>spectralLayer</span><span>(</span><span>adjacentMat</span><span>,</span> <span>eye</span><span>(</span><span>nodes</span><span>.</span><span>length</span><span>),</span> <span>rand</span><span>(</span><span>nodes</span><span>.</span><span>length</span><span>,</span> <span>4</span><span>))</span>

<span>// the second layer takes l1 as input and random weights</span>
<span>val</span> <span>out</span> <span>=</span> <span>spectralLayer</span><span>(</span><span>akat</span><span>,</span> <span>l1</span><span>,</span> <span>rand</span><span>(</span><span>l1</span><span>.</span><span>shape</span><span>()(</span><span>1</span><span>).</span><span>toInt</span><span>,</span> <span>2</span><span>))</span></code></pre></figure>
<p>I created some experiments with the small karate dataset, a fake set of node features (just a diagonal matrix) and a random set of weights. I repeated 4 experiments in sequence (no cherry-picking) in the image below where the color of the nodes indicates their similarity after running 2 iterations of the spectral algorithm.</p>
<figure>
<img src="https://gfrison.com/assets/images/gcn/karate-spectral.png" alt="2 Iterations with Spectral Propagation Rule. Each figure is a separated run">
<figcaption>2 Iterations with Spectral Propagation Rule. Each figure is a separated run</figcaption>
</figure>
<p>The results are clearly amazing! The two clusters are yet unrefined but as you can see the figure (d) is almost exactly what we obtained with Deepwalk! Those embeddings are elaborated with just random weights and 2 recursive iterations. Why not apply some learning mechanism for refining the clusterization with few examples?</p>

<p>I started this post on how your e-commerce could recommend new items according to your customers’ holiday preferences and I’ll run some experiments with a more pertinent dataset. If you are not familiar with ConceptNet, it is a huge graph database of general facts with 34 millions nodes, 34 types of different relations that I converted entirely in a OWL database. I extracted approximately 3 thousands of nodes about our topics of interest, the mountain and the seaside. Then I created a 2-layered neural network with the spectral propagation rule. I fed it with the adjacency matrix, the word-embeddings of the node names as input features and some labelled nodes. Two nodes classified as “seaside” category, and two nodes classified as “mountain” category. The 4 labelled nodes with 2 categories is all I need for classifying all the rest of the 3 thousands labels. That’s a ratio of 4/3000 labelled entries in the respect of the entire dataset, isn’t interesting? That’s why the name semi-supervised learning.</p>
<figure>
<img src="https://gfrison.com/assets/images/gcn/tourism-mountain-beach.png" alt="ConceptNet snapshot. Red nodes are labelled “mountain”, the blue are “seaside”. 5 epochs">
<figcaption>ConceptNet snapshot. Red nodes are labelled “mountain”, the blue are “seaside”. 5 epochs</figcaption>
</figure>
<p>This method of classification is really fast but has some drawbacks. The spectral propagation rule takes into account the adjacency matrix which is the whole network in a two dimensional vector. For a relatively small dataset that’s not an issue, but when it comes with real big data this method is actually unfeasible. The FastGCN comes into the rescue and scales to big sized graph DBs.</p>
</section>



</div></div>]]>
            </description>
            <link>https://gfrison.com/2020/graph-convolution-networks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908582</guid>
            <pubDate>Tue, 27 Oct 2020 15:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Software Eats Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908544">thread link</a>) | @venturegrit
<br/>
October 27, 2020 | https://andyjagoe.com/software-eats-money/ | <a href="https://web.archive.org/web/*/https://andyjagoe.com/software-eats-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://andyjagoe.com/content/images/size/w300/2020/10/jorge-salvador-clip.jpg 300w,
                            https://andyjagoe.com/content/images/size/w600/2020/10/jorge-salvador-clip.jpg 600w,
                            https://andyjagoe.com/content/images/size/w1000/2020/10/jorge-salvador-clip.jpg 1000w,
                            https://andyjagoe.com/content/images/size/w2000/2020/10/jorge-salvador-clip.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://andyjagoe.com/content/images/size/w2000/2020/10/jorge-salvador-clip.jpg" alt="How software eats money">
            </figure>

            <section>
                <div>
                    <p>People often say that software is eating the world. But have you ever wondered what that really means?</p><p>Ten years ago, software eating the world might have been hard to believe. In 2008, only one of the top ten companies in the S&amp;P 500 was a tech company: Microsoft. </p><p>Today, all five of the top five companies in the S&amp;P 500 are tech companies. Their combined market cap is <a href="https://www.startribune.com/the-s-p-500-has-never-been-more-top-heavy/572106152/">22% of the entire index</a>. Or as much as the bottom 363 companies combined. They are so dominant, lawmakers want to <a href="https://www.wsj.com/articles/house-panel-calls-for-congress-to-break-up-tech-giants-11602016985">break them up</a>.</p><p>How did this happen? And what happens next?</p><p>What role did software play in this outcome? And what does it mean for the future of financial services?</p><p>To understand what's really happening, you need to unpack the <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/">software eats the world hypothesis</a> and understand why digital is different and the implication this has on value chains everywhere.</p><p>In a <a href="https://a16z.com/2019/08/16/software-eaten-world-healthcare/">2019 interview</a>, Marc Andreessen describes in three layers how the software eats the world hypothesis unfolds across industries. Layer one is:</p><!--kg-card-begin: markdown--><blockquote>
<p>Any product or service in any field that can become a software product, will become a software product.</p>
</blockquote>
<!--kg-card-end: markdown--><p>If there's something you're used to doing on the phone, that will go to software. If there's something you're used to doing with paper, that will go to software. If there's something that you're used to doing in person and there is any way it can go to software, it will go to software.</p><p>Countless physical products are <a href="https://www.makeuseof.com/tag/apps-replacing-modern-devices/">now just apps on the phone</a> for most people: cameras, maps, keys, paper tickets, books, newspapers, magazines, calendars, radios, televisions, measuring tapes, remote controls, mirrors, and flash lights. Just to name a few. And more are being added all the time.</p><p>In other words, if it can become bits, it becomes bits.</p><p>What are <a href="https://en.wikipedia.org/wiki/Bit">bits</a>? Zeroes and ones―a basic unit of information in computing. Data expressed as a series of zeroes and ones is what we call <a href="https://www.google.com/search?q=digital">digital</a>.</p><p>And digital is different. On a deep and fundamental level.</p><p>An obvious reason is that digital products are easier to change, so it's faster to innovate and add new capabilities or features. Digital products are also easier to replicate at scale and are much more cost effective.</p><p>A less obvious reason is that digital products enable a shift from a world based on scarcity into a world based on abundance, unlocking large opportunities for value creation and re-arranging existing value chains in the process.</p><p><a href="https://www.usv.com/people/albert-wenger/">Albert Wenger</a>, a partner at Union Square Ventures, <a href="https://worldaftercapital.gitbook.io/worldaftercapital/digital">describes the two most important ways digital is different</a>:</p><ul><li><strong><strong>Zero marginal costs</strong></strong> Making one additional unit and delivering it across the network costs nothing. The price for a product with zero marginal cost trends towards free. Zero marginal cost is like an economic singularity similar to dividing by zero in math―as you approach it strange things begin to happen, ranging from digital near-monopolies to granting all of humanity access to the world's knowledge.</li><li><strong><strong>Universality of computation</strong></strong> Anything that can be computed in the universe, can be computed by the type of machines we already have today, given enough memory and time. Computation means taking information inputs, executing a series of processing steps, and producing information outputs. Which is essentially what a human brain does. In principle, a digital machine can do everything a human brain does.</li></ul><p>So if products and services in your field are becoming software products and can take advantage of zero marginal costs and universality of computation, how do you figure out what might happen to your market?</p><!--kg-card-begin: markdown--><p>Ask yourself some of the <a href="https://andyjagoe.com/investment-analysis/">questions an early stage investor asks</a>  before investing in a startup:</p>
<ul>
<li>What used to be scarce but is now abundant?</li>
<li>What used to be full of friction but is now no friction? And how will consumer behavior change?</li>
<li>What is the new scarcity that the startup is going to claim?</li>
<li>How is the value chain arranged today and how can it be re-arranged to eliminate existing players or reduce their margins so that the total friction to a customer is lower but that the new point of friction is the startup—and that is why the startup can collect money?</li>
</ul>
<!--kg-card-end: markdown--><p>For example, before the Web, information was scarce. Getting answers to questions was full of friction. It required knowing who to ask, or which physical books, magazines or articles to pore over. And then, how did you actually know if you had really found the best answer? Or just a local maxima?</p><p>With the emergence of &nbsp;the Web, information was digitized and only a click away. Information was now abundant. But there was a new problem. How did you find it?</p><p>Finding the best answers to questions was the new scarcity, and Google built clever software that did a much better job of ranking answers to questions than anyone else. Because of zero marginal costs, they allowed people to use it for free. The experience was 10x better than any alternative, and made users feel awesome. Like they had a superpower. </p><p>This was the beginning of a virtuous cycle. As people clicked on answers, Google recorded clicks as votes and then recalibrated their rankings. The more people used Google, the better it got. And the better it got, the more people used Google.</p><p>Software and digitalization enabled Google to aggregate the world's demand for answers on a scale never before seen. Google was the new point of friction in the value chain, and anyone who wanted to show up as the top answer had to pay. Many selling information (the old scarcity) had to find a new business.</p><p>OK, so what does all this mean for financial services?</p><p>Most money today is just information in a database. Deposits (checking and savings) should already be zero marginal cost, but banks have added friction and bureaucracy to keep money safe because of fraud and the absence of trust. Customers have been okay with this because trust is fundamentally what they've been buying.</p><p>As an individual, how can I trust that my money will be there when I need it? How can I trust that when I send a payment it's received by who I intended? How can I trust that I can borrow money when I need to? And that my loans will not be called in early? How can I trust that I own what I believe I have invested in? And when I have an accident, how can I trust my policy will pay as expected?</p><p>In today's world, trust is scarce.</p><p>But what if the world changed, and this was no longer true? What would happen to today's leading financial companies and their business models if trust became abundant?</p><p>Let's take a look at the evolution of the financial services platform stack¹ and see how things are changing.</p><h3 id="pre-internet-era">Pre-Internet Era</h3><p>For hundreds of years prior to the Internet, financial services were a vertically integrated oligopoly controlled by large banks. Names varied by country, but the story was always the same. Big banks managed every aspect of the stack, from the end user experience (bankers and ATMs) all the way down to the lowest level of infrastructure (settlements). </p><p>Regulation, infrastructure and customer acquisition cost made entry difficult, and so existing firms were very profitable. New products were rare, and old products hardly changed (aside from rates, fees or terms of service). Software was important at the platform and infrastructure layers, but would not be considered <a href="https://en.wikipedia.org/wiki/Software_design">good software</a> by today's standards. Software was used mainly to do old things better. There was no incentive to innovate, so things stayed the same.</p><figure><img src="https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--1-.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/10/Evolution-of-Finance--1-.png 600w, https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--1-.png 960w" sizes="(min-width: 720px) 720px"><figcaption>Evolution of Finance: Pre-Internet Era</figcaption></figure><h3 id="internet-era">Internet Era</h3><p>Mobile phones and broadband access to the Web meant that customers wanted always-on self-service access to financial services. Banks launched web sites and mobile apps, but there was no change to the underlying products and services being offered. Just a new way to interact with them that saved banks money. Once again, new technology was used to do old things better.</p><p>Meanwhile, a new class of innovators called fintechs emerged that were good at software, user experience and interfaces. They started targeting underserved customer segments and making improvements in the experience and interface layer, while partnering with existing financial services players for the middle office, back office and settlements.</p><p>These fintechs and neobanks are software companies in a way that banks are not. And some have become very big, like PayPal, Stripe, Square and Robinhood. Despite this, they are mainly innovating around the edge. Money and value still settles through fintechs essentially the same way paper bills settled hundreds of years ago.</p><figure><img src="https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--5-.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/10/Evolution-of-Finance--5-.png 600w, https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--5-.png 960w" sizes="(min-width: 720px) 720px"><figcaption>Evolution of Finance: Internet Era</figcaption></figure><h3 id="future-era">Future Era</h3><p>Large financial institutions from the Pre-Internet era are still in control of the financial system today. The top four US banks each hold over a <a href="https://www.usbanklocations.com/bank-rank/total-deposits.html">trillion dollars in deposits</a> and maintain their positions through bundling, regulation and scarcity of access to the financial system's platform and infrastructure layers―coupled with a good measure of inertia, fear, uncertainty, and doubt. </p><p>Their value proposition is trust. </p><p>But <strong>public blockchains make trust abundant</strong>. And when trust is no longer scarce, big changes will happen in financial services.</p><p>It's hard to overstate how important this is. Today's entire financial system is based on trust being scarce. And unlike fintechs innovating around the edge, trust becoming abundant will enable fundamental and deep re-ordering of the financial services value chain.</p><p>Like many new technologies, today public blockchains and crypto-assets seem <a href="https://cdixon.org/2010/01/03/the-next-big-thing-will-start-out-looking-like-a-toy">like toys</a>. <a href="https://cdixon.org/2019/01/08/strong-and-weak-technologies">Strange, unserious, and expensive</a>. Maybe even dangerous. But over time, new technologies like these get better and are adopted gradually, and then suddenly. And often massively expand a market, making it <a href="https://andyjagoe.com/why-the-market-for-bitcoin-may-be-bigger-than-you-think/">orders of magnitude bigger.</a></p><figure><img src="https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--6-.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/10/Evolution-of-Finance--6-.png 600w, https://andyjagoe.com/content/images/2020/10/Evolution-of-Finance--6-.png 960w" sizes="(min-width: 720px) 720px"><figcaption>Evolution of Finance: Future Era</figcaption></figure><p>This is how software eats money. <a href="https://andyjagoe.com/why-the-market-for-bitcoin-may-be-bigger-than-you-think/">Multi-sided networks like Bitcoin</a> will emerge and provide parallel platform and infrastructure layers that make trust abundant and can be freely innovated on. Like other multi-sided networks, they …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andyjagoe.com/software-eats-money/">https://andyjagoe.com/software-eats-money/</a></em></p>]]>
            </description>
            <link>https://andyjagoe.com/software-eats-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908544</guid>
            <pubDate>Tue, 27 Oct 2020 15:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Building an Elastic Cloud using Equinix Metal edge resources]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908494">thread link</a>) | @amarti
<br/>
October 27, 2020 | https://us02web.zoom.us/webinar/register/4916038002281/WN_ikVL6IWrQquZKQ8XfxH7BA | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/4916038002281/WN_ikVL6IWrQquZKQ8XfxH7BA">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><label for="timezone">Time Zone:</label>&nbsp;&nbsp;

</p>
</div>
</div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/4916038002281/WN_ikVL6IWrQquZKQ8XfxH7BA</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908494</guid>
            <pubDate>Tue, 27 Oct 2020 15:43:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prototyping with Python: Coding Effective Testing Tools Within Minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908490">thread link</a>) | @matt_d
<br/>
October 27, 2020 | https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html | <a href="https://web.archive.org/web/*/https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<pre>triangle(1, 6, 1) = 'isosceles #3'
triangle(2, 1, 3) = 'scalene'
triangle(1, 5, 8) = 'scalene'
triangle(3, 2, 7) = 'scalene'
triangle(2, 6, 3) = 'scalene'
triangle(7, 8, 6) = 'scalene'
triangle(5, 7, 7) = 'isosceles #2'
triangle(3, 8, 7) = 'scalene'
triangle(5, 1, 8) = 'scalene'
triangle(8, 4, 8) = 'isosceles #3'
</pre>
</div>

</div><div>

<div>
<pre>triangle:1 def triangle(a, b, c):                  (c = 1, b = 2, a = 2)
triangle:2     if a == b:                          (c = 1, b = 2, a = 2)
triangle:3         if b == c:                      (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
triangle:6             return 'isosceles #1'       (c = 1, b = 2, a = 2)
</pre>
</div>

</div><div>

<p>
<svg height="476pt" viewBox="0.00 0.00 1882.50 476.00" width="1883pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 472)">
<title>%3</title>
<polygon fill="#ffffff" points="-4,4 -4,-472 1878.5,-472 1878.5,4 -4,4" stroke="transparent"></polygon>
<!-- 0 -->
<g id="node1">
<title>0</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="119" y="-447.3">FunctionDef</text>
</g>
<!-- 1 -->
<g id="node2">
<title>1</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="50.5" y="-374.3">"triangle"</text>
</g>
<!-- 0&#45;&#45;1 -->
<g id="edge1">
<title>0--1</title>
<path d="M166.5,-432C166.5,-432 123.1482,-411.819 89.449,-396.1314" fill="none" stroke="#000000"></path>
</g>
<!-- 2 -->
<g id="node3">
<title>2</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="127.5" y="-375.3">arguments</text>
</g>
<!-- 0&#45;&#45;2 -->
<g id="edge2">
<title>0--2</title>
<path d="M166.5,-432C166.5,-432 166.1287,-411.9478 165.8386,-396.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 9 -->
<g id="node10">
<title>9</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="481" y="-375.3">If</text>
</g>
<!-- 0&#45;&#45;9 -->
<g id="edge9">
<title>0--9</title>
<path d="M166.5,-432C166.5,-432 384.3686,-395.5762 462.2396,-382.5575" fill="none" stroke="#000000"></path>
</g>
<!-- 3 -->
<g id="node4">
<title>3</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="44.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;3 -->
<g id="edge3">
<title>2--3</title>
<path d="M159.5,-360C159.5,-360 114.7843,-336.327 84.5663,-320.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 5 -->
<g id="node6">
<title>5</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="116.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;5 -->
<g id="edge5">
<title>2--5</title>
<path d="M159.5,-360C159.5,-360 148.3599,-339.9478 139.6566,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 7 -->
<g id="node8">
<title>7</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="188.5" y="-303.3">arg</text>
</g>
<!-- 2&#45;&#45;7 -->
<g id="edge7">
<title>2--7</title>
<path d="M159.5,-360C159.5,-360 175.0962,-339.9478 187.2807,-324.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 4 -->
<g id="node5">
<title>4</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="57.5" y="-230.3">"a"</text>
</g>
<!-- 3&#45;&#45;4 -->
<g id="edge4">
<title>3--4</title>
<path d="M57.5,-287.8314C57.5,-277 57.5,-263.2876 57.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 6 -->
<g id="node7">
<title>6</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="129.5" y="-230.3">"b"</text>
</g>
<!-- 5&#45;&#45;6 -->
<g id="edge6">
<title>5--6</title>
<path d="M129.5,-287.8314C129.5,-277 129.5,-263.2876 129.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 8 -->
<g id="node9">
<title>8</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-230.3">"c"</text>
</g>
<!-- 7&#45;&#45;8 -->
<g id="edge8">
<title>7--8</title>
<path d="M201.5,-287.8314C201.5,-277 201.5,-263.2876 201.5,-252.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 10 -->
<g id="node11">
<title>10</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="352" y="-303.3">Compare</text>
</g>
<!-- 9&#45;&#45;10 -->
<g id="edge10">
<title>9--10</title>
<path d="M507.5,-360C507.5,-360 456.4182,-338.1078 419.3042,-322.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 18 -->
<g id="node19">
<title>18</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="643" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;18 -->
<g id="edge18">
<title>9--18</title>
<path d="M507.5,-360C507.5,-360 582.7014,-331.7995 624.4147,-316.157" fill="none" stroke="#000000"></path>
</g>
<!-- 33 -->
<g id="node34">
<title>33</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1219" y="-303.3">If</text>
</g>
<!-- 9&#45;&#45;33 -->
<g id="edge33">
<title>9--33</title>
<path d="M507.5,-360C507.5,-360 1068.6377,-317.9147 1200.1543,-308.0509" fill="none" stroke="#000000"></path>
</g>
<!-- 11 -->
<g id="node12">
<title>11</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="256.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;11 -->
<g id="edge11">
<title>10--11</title>
<path d="M375.5,-288C375.5,-288 330.7843,-264.327 300.5663,-248.3292" fill="none" stroke="#000000"></path>
</g>
<!-- 14 -->
<g id="node15">
<title>14</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-230.3">Eq</text>
</g>
<!-- 10&#45;&#45;14 -->
<g id="edge14">
<title>10--14</title>
<path d="M375.5,-288C375.5,-288 364.3599,-267.9478 355.6566,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 15 -->
<g id="node16">
<title>15</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="400.5" y="-231.3">Name</text>
</g>
<!-- 10&#45;&#45;15 -->
<g id="edge15">
<title>10--15</title>
<path d="M375.5,-288C375.5,-288 391.0962,-267.9478 403.2807,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 12 -->
<g id="node13">
<title>12</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="201.5" y="-158.3">"a"</text>
</g>
<!-- 11&#45;&#45;12 -->
<g id="edge12">
<title>11--12</title>
<path d="M265.5,-216C265.5,-216 241.7344,-195.9478 223.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 13 -->
<g id="node14">
<title>13</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="273.5" y="-158.3">Load</text>
</g>
<!-- 11&#45;&#45;13 -->
<g id="edge13">
<title>11--13</title>
<path d="M265.5,-216C265.5,-216 268.4707,-195.9478 270.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 16 -->
<g id="node17">
<title>16</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="345.5" y="-158.3">"b"</text>
</g>
<!-- 15&#45;&#45;16 -->
<g id="edge16">
<title>15--16</title>
<path d="M409.5,-216C409.5,-216 385.7344,-195.9478 367.1675,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 17 -->
<g id="node18">
<title>17</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-158.3">Load</text>
</g>
<!-- 15&#45;&#45;17 -->
<g id="edge17">
<title>15--17</title>
<path d="M409.5,-216C409.5,-216 412.4707,-195.9478 414.7916,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 19 -->
<g id="node20">
<title>19</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="555" y="-231.3">Compare</text>
</g>
<!-- 18&#45;&#45;19 -->
<g id="edge19">
<title>18--19</title>
<path d="M657.5,-288C657.5,-288 630.3923,-267.9478 609.2145,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 27 -->
<g id="node28">
<title>27</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="660" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;27 -->
<g id="edge27">
<title>18--27</title>
<path d="M657.5,-288C657.5,-288 667.8975,-267.9478 676.0205,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 30 -->
<g id="node31">
<title>30</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="799" y="-231.3">Return</text>
</g>
<!-- 18&#45;&#45;30 -->
<g id="edge30">
<title>18--30</title>
<path d="M657.5,-288C657.5,-288 741.9072,-260.7067 790.7051,-244.9277" fill="none" stroke="#000000"></path>
</g>
<!-- 20 -->
<g id="node21">
<title>20</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="472.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;20 -->
<g id="edge20">
<title>19--20</title>
<path d="M580.5,-216C580.5,-216 543.6076,-194.1078 516.803,-178.2018" fill="none" stroke="#000000"></path>
</g>
<!-- 23 -->
<g id="node24">
<title>23</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-158.3">Eq</text>
</g>
<!-- 19&#45;&#45;23 -->
<g id="edge23">
<title>19--23</title>
<path d="M580.5,-216C580.5,-216 573.4446,-195.9478 567.9325,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 24 -->
<g id="node25">
<title>24</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="616.5" y="-159.3">Name</text>
</g>
<!-- 19&#45;&#45;24 -->
<g id="edge24">
<title>19--24</title>
<path d="M580.5,-216C580.5,-216 600.1809,-195.9478 615.5566,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 21 -->
<g id="node22">
<title>21</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="417.5" y="-86.3">"b"</text>
</g>
<!-- 20&#45;&#45;21 -->
<g id="edge21">
<title>20--21</title>
<path d="M481.5,-144C481.5,-144 457.7344,-123.9478 439.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 22 -->
<g id="node23">
<title>22</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="489.5" y="-86.3">Load</text>
</g>
<!-- 20&#45;&#45;22 -->
<g id="edge22">
<title>20--22</title>
<path d="M481.5,-144C481.5,-144 484.4707,-123.9478 486.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 25 -->
<g id="node26">
<title>25</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="561.5" y="-86.3">"c"</text>
</g>
<!-- 24&#45;&#45;25 -->
<g id="edge25">
<title>24--25</title>
<path d="M625.5,-144C625.5,-144 601.7344,-123.9478 583.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 26 -->
<g id="node27">
<title>26</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="633.5" y="-86.3">Load</text>
</g>
<!-- 24&#45;&#45;26 -->
<g id="edge26">
<title>24--26</title>
<path d="M625.5,-144C625.5,-144 628.4707,-123.9478 630.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 28 -->
<g id="node29">
<title>28</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="717.5" y="-159.3">Str</text>
</g>
<!-- 27&#45;&#45;28 -->
<g id="edge28">
<title>27--28</title>
<path d="M696.8554,-215.8314C703.625,-205 712.1953,-191.2876 718.9917,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 29 -->
<g id="node30">
<title>29</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="741.5" y="-86.3">"equilateral"</text>
</g>
<!-- 28&#45;&#45;29 -->
<g id="edge29">
<title>28--29</title>
<path d="M733.2758,-143.8314C734.9306,-133 737.0255,-119.2876 738.6869,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 31 -->
<g id="node32">
<title>31</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="844.5" y="-159.3">Str</text>
</g>
<!-- 30&#45;&#45;31 -->
<g id="edge31">
<title>30--31</title>
<path d="M832.8273,-215.8314C837.7917,-205 844.0765,-191.2876 849.0606,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 32 -->
<g id="node33">
<title>32</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="889.5" y="-86.3">"isosceles #1"</text>
</g>
<!-- 31&#45;&#45;32 -->
<g id="edge32">
<title>31--32</title>
<path d="M865.575,-143.8314C870.3889,-133 876.4833,-119.2876 881.3163,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 34 -->
<g id="node35">
<title>34</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1135" y="-231.3">Compare</text>
</g>
<!-- 33&#45;&#45;34 -->
<g id="edge34">
<title>33--34</title>
<path d="M1236.5,-288C1236.5,-288 1209.7637,-267.9478 1188.8759,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 42 -->
<g id="node43">
<title>42</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1247" y="-231.3">Return</text>
</g>
<!-- 33&#45;&#45;42 -->
<g id="edge42">
<title>33--42</title>
<path d="M1236.5,-288C1236.5,-288 1249.8682,-267.9478 1260.312,-252.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 45 -->
<g id="node46">
<title>45</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1585" y="-231.3">If</text>
</g>
<!-- 33&#45;&#45;45 -->
<g id="edge45">
<title>33--45</title>
<path d="M1236.5,-288C1236.5,-288 1483.0627,-250.7048 1566.374,-238.1031" fill="none" stroke="#000000"></path>
</g>
<!-- 35 -->
<g id="node36">
<title>35</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1056.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;35 -->
<g id="edge35">
<title>34--35</title>
<path d="M1161.5,-216C1161.5,-216 1126.694,-194.6418 1100.8614,-178.7899" fill="none" stroke="#000000"></path>
</g>
<!-- 38 -->
<g id="node39">
<title>38</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-158.3">Eq</text>
</g>
<!-- 34&#45;&#45;38 -->
<g id="edge38">
<title>34--38</title>
<path d="M1161.5,-216C1161.5,-216 1155.5586,-195.9478 1150.9169,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 39 -->
<g id="node40">
<title>39</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1200.5" y="-159.3">Name</text>
</g>
<!-- 34&#45;&#45;39 -->
<g id="edge39">
<title>34--39</title>
<path d="M1161.5,-216C1161.5,-216 1182.2949,-195.9478 1198.541,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 36 -->
<g id="node37">
<title>36</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1001.5" y="-86.3">"b"</text>
</g>
<!-- 35&#45;&#45;36 -->
<g id="edge36">
<title>35--36</title>
<path d="M1065.5,-144C1065.5,-144 1041.7344,-123.9478 1023.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 37 -->
<g id="node38">
<title>37</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1073.5" y="-86.3">Load</text>
</g>
<!-- 35&#45;&#45;37 -->
<g id="edge37">
<title>35--37</title>
<path d="M1065.5,-144C1065.5,-144 1068.4707,-123.9478 1070.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 40 -->
<g id="node41">
<title>40</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1145.5" y="-86.3">"c"</text>
</g>
<!-- 39&#45;&#45;40 -->
<g id="edge40">
<title>39--40</title>
<path d="M1209.5,-144C1209.5,-144 1185.7344,-123.9478 1167.1675,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 41 -->
<g id="node42">
<title>41</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1217.5" y="-86.3">Load</text>
</g>
<!-- 39&#45;&#45;41 -->
<g id="edge41">
<title>39--41</title>
<path d="M1209.5,-144C1209.5,-144 1212.4707,-123.9478 1214.7916,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 43 -->
<g id="node44">
<title>43</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1296.5" y="-159.3">Str</text>
</g>
<!-- 42&#45;&#45;43 -->
<g id="edge43">
<title>42--43</title>
<path d="M1281.8367,-215.8314C1287.4028,-205 1294.4494,-191.2876 1300.0376,-180.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 44 -->
<g id="node45">
<title>44</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1329.5" y="-86.3">"isosceles #2"</text>
</g>
<!-- 43&#45;&#45;44 -->
<g id="edge44">
<title>43--44</title>
<path d="M1314.5468,-143.8314C1317.5555,-133 1321.3646,-119.2876 1324.3852,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 46 -->
<g id="node47">
<title>46</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1496" y="-159.3">Compare</text>
</g>
<!-- 45&#45;&#45;46 -->
<g id="edge46">
<title>45--46</title>
<path d="M1603.5,-216C1603.5,-216 1574.5356,-195.9478 1551.9072,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 54 -->
<g id="node55">
<title>54</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1636" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;54 -->
<g id="edge54">
<title>45--54</title>
<path d="M1603.5,-216C1603.5,-216 1625.0376,-195.9478 1641.8638,-180.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 57 -->
<g id="node58">
<title>57</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1768" y="-159.3">Return</text>
</g>
<!-- 45&#45;&#45;57 -->
<g id="edge57">
<title>45--57</title>
<path d="M1603.5,-216C1603.5,-216 1705.4239,-187.0321 1759.9692,-171.5298" fill="none" stroke="#000000"></path>
</g>
<!-- 47 -->
<g id="node48">
<title>47</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1424.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;47 -->
<g id="edge47">
<title>46--47</title>
<path d="M1523.5,-144C1523.5,-144 1492.6587,-123.6898 1468.8048,-107.9812" fill="none" stroke="#000000"></path>
</g>
<!-- 50 -->
<g id="node51">
<title>50</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-86.3">Eq</text>
</g>
<!-- 46&#45;&#45;50 -->
<g id="edge50">
<title>46--50</title>
<path d="M1523.5,-144C1523.5,-144 1519.7866,-123.9478 1516.8855,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 51 -->
<g id="node52">
<title>51</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1568.5" y="-87.3">Name</text>
</g>
<!-- 46&#45;&#45;51 -->
<g id="edge51">
<title>46--51</title>
<path d="M1523.5,-144C1523.5,-144 1546.5229,-123.9478 1564.5096,-108.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 48 -->
<g id="node49">
<title>48</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1369.5" y="-14.3">"a"</text>
</g>
<!-- 47&#45;&#45;48 -->
<g id="edge48">
<title>47--48</title>
<path d="M1433.5,-72C1433.5,-72 1409.7344,-51.9478 1391.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 49 -->
<g id="node50">
<title>49</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1441.5" y="-14.3">Load</text>
</g>
<!-- 47&#45;&#45;49 -->
<g id="edge49">
<title>47--49</title>
<path d="M1433.5,-72C1433.5,-72 1436.4707,-51.9478 1438.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 52 -->
<g id="node53">
<title>52</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1513.5" y="-14.3">"c"</text>
</g>
<!-- 51&#45;&#45;52 -->
<g id="edge52">
<title>51--52</title>
<path d="M1577.5,-72C1577.5,-72 1553.7344,-51.9478 1535.1675,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 53 -->
<g id="node54">
<title>53</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1585.5" y="-14.3">Load</text>
</g>
<!-- 51&#45;&#45;53 -->
<g id="edge53">
<title>51--53</title>
<path d="M1577.5,-72C1577.5,-72 1580.4707,-51.9478 1582.7916,-36.2819" fill="none" stroke="#000000"></path>
</g>
<!-- 55 -->
<g id="node56">
<title>55</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1666.5" y="-87.3">Str</text>
</g>
<!-- 54&#45;&#45;55 -->
<g id="edge55">
<title>54--55</title>
<path d="M1666.0422,-143.8314C1668.75,-133 1672.1781,-119.2876 1674.8967,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 56 -->
<g id="node57">
<title>56</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1697.5" y="-14.3">"isosceles #3"</text>
</g>
<!-- 55&#45;&#45;56 -->
<g id="edge56">
<title>55--56</title>
<path d="M1684.0422,-71.8314C1686.75,-61 1690.1781,-47.2876 1692.8967,-36.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 58 -->
<g id="node59">
<title>58</title>
<text fill="#004080" font-family="Courier,monospace" font-size="14.00" font-weight="bold" text-anchor="start" x="1792.5" y="-87.3">Str</text>
</g>
<!-- 57&#45;&#45;58 -->
<g id="edge58">
<title>57--58</title>
<path d="M1796.5281,-143.8314C1798.3333,-133 1800.6187,-119.2876 1802.4311,-108.4133" fill="none" stroke="#000000"></path>
</g>
<!-- 59 -->
<g id="node60">
<title>59</title>
<text fill="#008040" font-family="Courier,monospace" font-size="14.00" text-anchor="middle" x="1828.5" y="-14.3">"scalene"</text>
</g>
<!-- 58&#45;&#45;59 -->
<g id="edge59">
<title>58--59</title>
<path d="M1811.3039,-71.8314C1814.7639,-61 1819.1442,-47.2876 1822.618,-36.4133" fill="none" stroke="#000000"></path>
</g>
</g>
</svg>

</p>

</div><div>

<div>
<pre>['z3.And((a == b), (b == c))',
 'z3.And((a == b), z3.Not(b == c))',
 'z3.And(z3.Not(a == b), (b == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), (a == c))',
 'z3.And(z3.Not(a == b), z3.Not(b == c), z3.Not(a == c))']
</pre>
</div>

</div><div>

<div>
<pre>[b = 1, a = 1, c = 1] equilateral
[b = 1, a = 1, c = 2] isosceles #1
[b = 2, a = 1, c = 2] isosceles #2
[b = 2, a = 1, c = 1] isosceles #3
[b = 3, a = 1, c = 2] scalene
</pre>
</div>

</div><div>
<div>
<div>
<div><h2 id="The-Virtues-of-Prototyping">The Virtues of Prototyping<a href="#The-Virtues-of-Prototyping">¶</a></h2><p>One neat thing about prototyping (with Python or whatever) is that it allows you to fully focus on your <em>approach</em>, rather than on the infrastructure. Very obviously, this is useful for <em>teaching</em> – you can use examples as the ones above in a lecture to very quickly communicate essential techniques of program analysis and test generation.</p>
<p>But prototyping has more advantages. A Jupyter Notebook (like this one) documents how you developed your approach, together with examples, experiments, and rationales – and still focusing on the essentials. If you write a tool the "classical" way, you will eventually deliver thousands of lines of code that do everything under the sun, but only once you have implemented everything will you know whether things actually work. This is a huge risk, and if you still have to change things, you will have to refactor things again and again. Furthermore, for anyone who will work on that code later, it will take days, if not weeks, to re-extract the basic idea of the approach, as it will be buried under loads and loads of infrastructure and refactorings.</p>
<p>Our consequence at this point is that we now implement new ideas <em>twice</em>:</p>
<ul>
<li><p>First, we implement things as a notebook (as this one), experimenting with various approaches and parameters until we get them right.</p>
</li>
<li><p>Only once we have the approach right, and if we have confidence that it works, we reimplement it in a tool that works on large scale programs. This can still take weeks to months, but at least we know we are on a good path.</p>
</li>
</ul>
<p>Incidentally, it may well be that the original notebooks will have a longer life, as they are simpler, better documented, and capture the gist of our novel idea. And this is how several of the notebooks in this book came to be.</p>
</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.fuzzingbook.org/beta/html/PrototypingWithPython.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908490</guid>
            <pubDate>Tue, 27 Oct 2020 15:43:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study shows how exercise stalls cancer growth through the immune system]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908425">thread link</a>) | @gmays
<br/>
October 27, 2020 | https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system | <a href="https://web.archive.org/web/*/https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/ZIM_6255ZIM_6255-custom20201026104950.jpg" alt="Randall Johnson and Helene Rundqvist, researchers at Karolinska Institutet. Credit: Stefan Zimmerman."></p><p>Randall Johnson and Helene Rundqvist, researchers at Karolinska Institutet. Credit: Stefan Zimmerman.</p>
                  </div><div>
        
            <p>Prior research has shown that physical activity can prevent unhealth as well as improve the prognosis of several diseases including various forms of cancer. Exactly how exercise exerts its protective effects against cancer is, however, still unknown, especially when it comes to the biological mechanisms. One plausible explanation is that physical activity activates the immune system and thereby bolsters the body’s ability to prevent and inhibit cancer growth.</p>

<p>In this study, researchers at Karolinska Institutet expanded on this hypothesis by examining how the immune system’s cytotoxic T cells, that is white blood cells specialized in killing cancer cells, respond to exercise.</p>

<h2>Cancer growth slowed in trained animals</h2>

<p>They divided mice with cancer into two groups and let one group exercise regularly in a spinning wheel while the other remained inactive. The result showed that cancer growth slowed and mortality decreased in the trained animals compared with the untrained.</p>

<p>Next, the researchers examined the importance of cytotoxic T cells by injecting antibodies that remove these T cells in both trained and untrained mice. The antibodies knocked out the positive effect of exercise on both cancer growth and survival, which according to the researchers demonstrates the significance of these T cells for exercise-induced suppression of cancer.</p>

<p>The researchers also transferred cytotoxic T cells from trained to untrained mice with tumors, which improved their prospects compared with those who got cells from untrained animals.</p>

<h2>Exercise altered T cell metabolism</h2>

<p>To examine how exercise influenced cancer growth, the researchers isolated T cells, blood and tissue samples after a training sessions and measured levels of common metabolites that are produced in muscle and excreted into plasma at high levels during exertion. Some of these metabolites, such as lactate, altered the metabolism of the T cells and increased their activity. The researchers also found that T cells isolated from an exercised animal showed an altered metabolism compared to T cells from resting animals.</p>

<p>In addition, the researchers examined how these metabolites change in response to exercise in humans. They took blood samples from eight healthy men after 30 minutes of intense cycling and noticed that the same training-induced metabolites were released in humans.</p>

<p>“Our research shows that exercise affects the production of several molecules and metabolites that activate cancer-fighting immune cells and thereby inhibit cancer growth,” says <a href="https://staff.ki.se/people/helame">Helene Rundqvist</a>, senior researcher at the <a href="https://ki.se/en/labmed/department-of-laboratory-medicine">Department of Laboratory Medicine</a>, Karolinska Institutet, and the study’s first author. “We hope these results may contribute to a deeper understanding of how our lifestyle impacts our immune system and inform the development of new immunotherapies against cancer.”</p>

<p>The researchers have received financing from the Knut and Alice Wallenberg Foundation, the Swedish Research Council, the Swedish Cancer Society, the Swedish Childhood Cancer Foundation, the Swedish Society of Medicine, Cancer Research UK and the Wellcome Trust.</p>

<h2>Publication</h2>

<p>“<a href="https://elifesciences.org/articles/59996">Cytotoxic T-cells mediate an exercise-induced reduction in tumor growth</a>,”<strong> </strong>Helene Rundqvist, Pedro Veliça, Laura Barbieri, Paulo A. Gameiro, David Bargiela, Milos Gojkovic, Sara Mijwel, Stefan Reitzner, David Wullimann, Emil Ahlstedt, Jernej Ule, Arne Östman and Randall S. Johnson, <em>eLife</em>, online October 23, 2020, doi: 10.7554/eLife.59996</p>
      
      </div></div>]]>
            </description>
            <link>https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908425</guid>
            <pubDate>Tue, 27 Oct 2020 15:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye Lenovo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908411">thread link</a>) | @iqandjoke
<br/>
October 27, 2020 | https://procesoid.com/blog/goodbye-lenovo/ | <a href="https://web.archive.org/web/*/https://procesoid.com/blog/goodbye-lenovo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>If you are into process management, you don’t see services. You see the processes behind them. And even though I was just an ordinary customer, I could see that Lenovo has some key processes that are seriously broken.</p><div>
			<p><i>Disclaimer: This text isn’t a lament from an angry customer, but rather a reflection of one customer’s experience which was determined by process flaws. The complaint itself went well and I have nothing to moan about there.</i></p>
<p>My old laptop died, so I went and bought a new <a href="https://www.lenovo.com/gb/en/laptops/thinkpad/l-series/ThinkPad-L580/p/22TP2TBL580">Lenovo ThinkPad L580</a>. The thin chassis made of black plastic combined with a powerful i7 processor wasn’t the right choice though:</p>
<p>Hot air was blowing from the right vent of the fan directly onto my right hand holding a mouse. And when I placed my hands onto the keyboard, the i7 processor located just under my right wrist was overheating under the load to the point where I felt like I was typing on a heater.</p>
<p>So it made me wonder:</p>
<ul>
<li>How could Lenovo put a laptop with such bad heat management on the market?</li>
<li>Don’t they have some <b>“not-to-do” </b>list of previous construction mistakes to avoid?</li>
<li>Does Lenovo have an autonomous <a href="https://procesoid.com/blog/process/">process</a> for testing prototypes to correct ill-conceived product designs?</li>
<li>And if it does, why is the vent for the fan on the right side, where most people hold their mouse, and why is the processor exactly where it would be felt by the user?</li>
<li>And if my particular laptop was overheating that much, how could it leave the factory in the first place? A well designed stress test would reveal such overheating easily.</li>
</ul>
<p>These problems aren’t expensive to detect and fix, nor does it take exceptional intelligence to do so. It only takes properly implemented and reliable <a href="https://procesoid.com/blog/business-process/">business processes</a>. And it’s not a trifle. The brand’s reputation is at stake.</p>
<p>Even more curious to me is that according to a heatmap published in the <a href="https://www.notebookcheck.net/Lenovo-ThinkPad-T580-i7-8550U-MX150-UHD-Laptop-Review.299796.0.html">review</a> by the renowned webzine <i>NotebookCheck</i> the heat problem extends also to the higher model T580. Although that one has the vent of the fan on the left side, the keyboard area can get as hot as a tropical 43,5°C (107 F):</p>
		<p><a href="https://www.notebookcheck.net/Lenovo-ThinkPad-T580-i7-8550U-MX150-UHD-Laptop-Review.299796.0.html"><img loading="lazy" src="https://procesoid.com/wp-content/uploads/2018/08/Stress_oben.jpg" alt="Lenovo T580 stress test heatmap" width="640" height="480" srcset="https://procesoid.com/wp-content/uploads/2018/08/Stress_oben.jpg 640w, https://procesoid.com/wp-content/uploads/2018/08/Stress_oben-300x225.jpg 300w, https://procesoid.com/wp-content/uploads/2018/08/Stress_oben-96x73.jpg 96w, https://procesoid.com/wp-content/uploads/2018/08/Stress_oben-76x58.jpg 76w" sizes="(max-width: 640px) 100vw, 640px"></a> Source: NotebookCheck.net		</p>
	
<p>Right after diagnosing the problem, I contacted the seller, who recommended me to file a fast <a href="https://www.computerhope.com/jargon/d/doa.htm">DOA</a> complaint through a national Lenovo partner. There I was first promised a fast resolution by some lady over the phone. But later, her less agreeable colleague told me after the arrival and diagnosing of my laptop that the heat<b> is a feature and not a flaw.</b> —&nbsp;<i>Excuse me? So I’ve bought a heater instead of a laptop?!</i></p>
<p>Thus, I pointed out to the gentleman that this is not what the customer <b>support </b>for business laptops should look like and that his duty is to <b>help </b>the customers. I have also stressed that if my complaint was denied, it would leave me no other option than to send a complaint directly to Lenovo. He called me back in a few minutes and suddenly <b>nothing was a problem. </b>He did a complete 180°, even suggested another round of testing and within two weeks my complaint was resolved to my satisfaction by a full refund.</p>
<p>Yet it made me wonder again:</p>
<ul>
<li>Why wasn’t there someone from the very beginning to express Lenovo’s commitment to resolve my obvious problem with a new $1,800 laptop?</li>
<li>How is it possible, that the “support” could initially promise a quick resolution and then have another staff member claim it is a feature? Don’t they have a CRM to be at least consistent in their communication?</li>
<li>Why is the ticketing support system unavailable most of the day and showing errors? And why was the ticket full of incomprehensible technical jargon?</li>
<li>Why does Lenovo outsource its customer care into the hands of such an incompetent local partner? Don’t they have a reliable process to choose and control the quality of their local support?</li>
<li>Why, after I have filled out a form sent from <i>Lenovo EMEA Customer Experience</i> and complained about my problems with the local support, wasn’t there someone to contact me <b>immediately </b>to restore my confidence in the company’s reputation?</li>
<li>Why hasn’t anyone apologized to me during all this for the problem with a new product and troubles it has caused me? Not to mention offered me some compensation for the time lost.</li>
</ul>
<p>Customer care isn’t difficult with competent staff and a strong process structure. But if one chooses to outsource it (and the brand’s reputation with it) into someone’s hands, it is <b>absolutely crucial</b> to guard the customer experience by something more than a stupid form send in an email full of grammatical mistakes, to which there is no follow-up reply anyway. It tells another story about the company and its culture.</p>
<p>Would I buy another laptop by Lenovo after this experience? Only under the condition that the whole company was running like a Swiss watch. At the moment it looks rather like a game of Chinese roulette.</p>
		</div></div>]]>
            </description>
            <link>https://procesoid.com/blog/goodbye-lenovo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908411</guid>
            <pubDate>Tue, 27 Oct 2020 15:35:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Builder.io Theme Studio – no-code for your entire Shopify storefront]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908400">thread link</a>) | @steve8708
<br/>
October 27, 2020 | https://www.builder.io/m/theme-studio | <a href="https://web.archive.org/web/*/https://www.builder.io/m/theme-studio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div builder-id="builder-82e77f0bd38b43db8bb523e11f103f92"><div><p><span><p>Endless customization, <span>endless possibilities</span></p>
</span></p><div builder-id="builder-f95d22afcdcc4695a853bfa4195712ce"><div><div><div builder-type="blocks"><div builder-id="builder-5f6230fe18e24054923b58a029b339e8"><p><span><p>Getting started is easy</p></span></p><p><span><p>Get started with our templates, import your own, or start from scratch.</p></span></p></div></div></div></div></div><div builder-id="builder-886bcaf20a7b4c3e90d25aa715e4b211"><div><div><div builder-type="blocks"><div builder-id="builder-1c3866b9927f402e854bea6ba6fd687a"><p><span><p>All the building blocks you need</p></span></p><p><span><p>Drag-and-drop it all, from text, images, and videos to products, collections, and add-to-carts.</p></span></p></div></div></div></div></div><div builder-id="builder-808ffbdc3d0a47d8ba346267933ecc1b"><div><div><div builder-type="blocks"><div builder-id="builder-5ab681dd85d640aabb05b8a8d428ff41"><p><span><p>Make it your own</p></span></p><p><span><p>Completely customize the look and feel of your content and make it come alive with animations. </p></span></p></div></div></div></div></div><div builder-id="builder-a3c8f76be1db4bb4a9a51111cc03e5ce"><div><div><div builder-type="blocks"><div builder-id="builder-87f5ddd77e2c4a19be0e7786a40b19a3"><p><span><p>Build for the entire customer journey</p></span></p><p><span><p>Create the optimal end-to-end experience, from high-impact pages (collections, product pages, cart) to the essential touches (pop-ups, slide-ups, announcement bars).</p></span></p></div></div></div></div></div><a href="https://apps.shopify.com/builder-2" target="_blank" builder-id="builder-4a1239c7e3d4426f960de6646b8d7ba9"><p><span><p>Start <span>Building</span></p>
</span></p></a><div builder-id="builder-e2fd12b8b3a141eda7353f09c7e1a02e"><div><div builder-id="builder-be77af7db25c41e38a5e2763eb59b17c"><div><div><div builder-type="blocks"><div builder-id="builder-67494a2120a84c2b839ac4a467a0320e"><p><span><p>Optimize</p></span></p><p><span><p>Make sure your content <span>converts</span></p>
</span></p><p><span><p>With Theme Studio, you can personalize your storefront by creating targeted page-level or content-specific experiences for different customer segments. Perform unlimited A/B tests to understand how and if changes impact funnel performance. Plus, our dashboards tell you just how much money each change made, and allows you to revert any misstep instantly. It's like magic.</p></span></p></div></div></div></div></div></div></div><div builder-id="builder-f93645b23cad41788c39f544ca9b889c"><div><div builder-id="builder-3e9e6d723a4541d690ff8d5fe6c6b3a6"><div><div><div builder-type="blocks"><div builder-id="builder-df4b9bebfa33471c9d36965a8829b14f"><p><span><p>Analyze </p></span></p><p><span><p>Know what is, and isn’t <span>working</span></p>
</span></p><p><span><p>The best merchants find ways to test, iterate, measure, and then do it better the next time. Theme Studio's analytics suite comes with site, page, and content-level insights, as well as heat maps that show both engagement (nice) and impact on conversation (very nice).</p></span></p></div></div></div></div></div></div></div><div builder-id="builder-9145da4b53554f83a6f34a9265ac9e67"><div><div builder-id="builder-95af03645cfe46de8a83ad1cc79eae22"><div><div><div builder-type="blocks"><div builder-id="builder-95575fd923c1458eb525babaa692c421"><p><span><p>It's like tons of apps, all out-of-the-box</p></span></p><p><span><p>Stop installing an endless number of apps. Theme Studio comes with so much power and so many capabilities, you'll be able to uninstall apps that needlessly slow down your storefront and only keep the ones providing real value.</p></span></p></div></div></div></div></div></div></div><div builder-id="builder-54695a4aa19e470d9b4a41c47163f10e"><div><div builder-id="builder-44c1540f0f654b919bf277467c87c228"><p><span><p>
  <span>&lt;</span> A little code makes for lots of possibilities
  <span>/&gt;</span>
</p>
</span></p><p><span><p>We think a lot about developer experience. We provide developers the ability to completely control Theme Studio in terms of what can be built and how it can be built. And with a little code you’ll never hit a ceiling.</p></span></p></div></div></div><div id="pricing" builder-id="builder-1348e5009b1c4c5b921ea438a68ae3ec"><div><p><span><p>Theme Studio <span>Pricing</span></p>
</span></p><div builder-id="builder-d2873d07b91544deb52acc258c19a639"><div builder-id="builder-9bd616f081d14596af773d3d2b615770"><div builder-id="builder-13ccd4588d5a49f6ae22ee477225185d"><p><span><p>Growth</p></span></p><p><span><p>8 Users</p><p>Unlimited pages</p><p>Build, optimize, and grow</p></span></p><p><a href="https://apps.shopify.com/builder-2" target="_blank" builder-id="builder-be3e7e34f4f248fc9a5d8ab5d49aa215">Try for free</a></p></div><div builder-id="builder-99538802074245b1b19c39783d4e4508"><p><span><p>Enterprise</p></span></p><p><span><p>More scale</p><p>More control</p><p>More support</p></span></p><p><span href="" builder-id="builder-90513e48454b4e0db1e91316ae48aab9">Talk to us</span></p></div></div></div><div builder-id="builder-569b9d7a4f834ddb8781acdbda6fd520"><div builder-id="builder-167968acab2143dd928e750ed1516821"><div builder-id="builder-56999ea3506848b0b1e77c7dff733cfc"><p><span><p>Drag &amp; Drop Visual Editor</p></span></p></div><div builder-id="builder-f2fb685d08434b58bdd2950456fc131e"><p><span><p>Priority Support (ticket queue)</p></span></p></div><div builder-id="builder-7a557144b8d14f4d9b1c889d32c2a359"><p><span><p>Custom roles and permissions</p></span></p></div><div builder-id="builder-2d0e06aeeab6439ea4b449450e71c437"><p><span><p>Advanced Developer Tools (plugins)</p></span></p></div><p><span builder-id="builder-8bbb4526fcf443819a2044ddebae8374">Talk to us</span></p></div></div></div></div><p><span><p><span>Frequently</span> Asked Questions</p>
</span></p><p><span><p>Have a different question about how Builder.io works or the pricing plans available? Try getting in touch with one of our specialists via live chat.</p></span></p><div builder-id="builder-a6e003c4083b4f979fef17f0b2cdab29"><div><div data-index="0"><div builder-type="blocks"><div builder-id="builder-e3306ccc75f84fd28c72b9053b9d04c2"><p><span><p>Do you offer a free trial?</p></span></p><p><span><p>⌃</p></span></p></div></div></div><div data-index="1"><div builder-type="blocks"><div builder-id="builder-3d8de02df7794c65ac44ceb63c23826c"><p><span><p>What if I need to add more users?</p></span></p><p><span><p>⌃</p></span></p></div></div></div><div data-index="2"><div builder-type="blocks"><div builder-id="builder-a511d7f022a94ae2aeab1e8454e28a63"><p><span><p>What happens to my content if I stop using the app?</p></span></p><p><span><p>⌃</p></span></p></div></div></div><div data-index="3"><div builder-type="blocks"><div builder-id="builder-ff033bf1e4db44aa87a637cab79ab033"><p><span><p>What if I need help building something?</p></span></p><p><span><p>⌃</p></span></p></div></div></div></div></div><div builder-id="builder-297592ee3eba4ed3b4ef3fad1f53e3e8"><div builder-id="builder-b14317f197c7475d881a91e957b528c0"><div><div><div builder-type="blocks"><p><span><p>
  Looking for a 
  <span>headless commerce</span>
  solution?
</p>
</span></p></div></div></div></div></div><div data-model="symbol" builder-id="builder-c0f8c80bf57240dfa251df28dd9d282c"><div data-name="symbol" data-source="Rendered by Builder.io on Fri, 30 Oct 2020 12:23:14 GMT"><div builder-content-id="9eb19487e49d4251ae17e09ec3fd2a3a" builder-model="symbol"><div data-builder-component="symbol" data-builder-content-id="9eb19487e49d4251ae17e09ec3fd2a3a" data-builder-variation-id="9eb19487e49d4251ae17e09ec3fd2a3a"><div builder-type="blocks"><p><img src="https://cdn.builder.io/api/v1/pixel?apiKey=YJIGb4i01jvw0SRdL5Bt" role="presentation" width="0" height="0" builder-id="builder-pixel-i7ty7g6fgr9"></p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.builder.io/m/theme-studio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908400</guid>
            <pubDate>Tue, 27 Oct 2020 15:34:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Journal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908337">thread link</a>) | @acmeyer9
<br/>
October 27, 2020 | https://decisionjournalapp.com/blog/2020/10/22/introducing-decision-journal.html | <a href="https://web.archive.org/web/*/https://decisionjournalapp.com/blog/2020/10/22/introducing-decision-journal.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
      <p>
        
        <h2>Make better decisions.</h2>
      </p>
      <p>A decision journal is a simple, yet effective tool. It helps us to avoid hindsight bias, recognize patterns of mistakes in our decision making, and provide accurate and honest feedback on the decisions we make.</p>

<p>For those unfamiliar with what a decision journal is, it is the simple idea of keeping track of your decisions by writing them down for the purpose of reviewing it in the future. The Nobel Prize winner and famous psychologist <a href="https://fs.blog/2014/02/decision-journal/" target="_blank">Daniel Kahneman introduced the basic concept of a decision journal</a>:</p>

<blockquote>
  <p>“Go down to a local drugstore and buy a very cheap notebook and start keeping track of your decisions. And the specific idea is whenever you’re making a consequential decision, something going in or out of the portfolio, just take a moment to think, write down what you expect to happen, why you expect it to happen and then actually, and this is optional, but probably a great idea, is write down how you feel about the situation, both physically and even emotionally. Just, how do you feel? I feel tired. I feel good, or this stock is really draining me. Whatever you think.”</p>
</blockquote>

<p>This, Kahneman said, helps us avoid hindisight bias. The bias where everyone tends to look back on their own past in a favorable light. It’s the tendency people have of attributing their success to their own skills and talent but their failures to bad luck.</p>

<p>By keeping a decision journal, we avoid this bias by writing down exactly how we feel in the moment of making the decision. That way our future self can’t create a false narrative. We’re forced to be honest with ourselves.</p>

<p>Many decision makers in all walks of life use decision journals to help them improve their decision making capabilities. The problem is they can be challenging to maintain and keep track of. They require you to always remember to write down the decisions you want to keep track of and to go back and review them periodically. This causes many people to stop using them or to use them sub-optimally.</p>

<p>What if there was a more convenient way to use a decision journal?</p>

<p>Now there is, introducing Decision Journal, now available on <a href="https://apps.apple.com/us/app/decision-journal/id1534768141" target="_blank">iOS</a> and <a href="https://play.google.com/store/apps/details?id=com.betterthinkingsoftware.decisionjournal" target="_blank">Android</a>.</p>

<p>With Decision Journal, we tried to take all of the awesome benefits decision journals offer and augment them with modern technology and software. Let’s go over some of the app’s key features.</p>

<h4 id="always-with-you">Always with you</h4>

<p>One of the challenges in keeping a good decision journal is making sure that you remember to write down the important decisions you want to keep track of. Not only that but the whole point of a decision journal is so that you can later recall exactly what you were thinking and feeling at the time of the decision. The challenge is that we don’t remember everything and the longer you go without writing down your thoughts, the more likely what you write down will be inaccurate.</p>

<p>That’s one of the great benefits of using the Decision Journal app as your decision journal. It’s always with you. Whenever you make a decision or begin thinking about making a particular decision, you can pull your phone out of your pocket and jot it down. Plus, given that it is on your phone, we’ll sync it to the cloud every time you save it so that you can keep track of your decisions on your own time, whenever is most convenient for you.</p>

<p><img src="https://decisionjournalapp.com/assets/img/screens/welcome-image.light.ios.png" height="350">
</p>

<h4 id="scheduled-reviews">Scheduled reviews</h4>

<p>Another important part of keeping a decision journal is so that you can accurately and honestly evaluate your decisions. However, one of the challenges is in remembering to do so in a timely manner.</p>

<p>We’re probably all too familiar with setting out our New Year’s resolutions at the beginning of each year, only to never follow up and review them. Why? Because life happens and we lose track of things. We’re human.</p>

<p>But that’s where technology can come in and assist us. With the Decision Journal app, we’ve made it super simple to mark a particular decision for a review at some point in the future. And you don’t have to remember to follow up, the app will do all of that for you. When it’s time to review a particular decision, the app will send you a notification letting you know that a particular decision is up for review.</p>

<p>And we didn’t just stop there. Sometimes you make decisions where the outcome of that decision can take place over long periods of time. That’s why we made it easy for you to schedule multiple reviews for any decision.</p>

<p><img src="https://decisionjournalapp.com/assets/img/screens/schedule-review.light.ios.png" height="350">
</p>

<h4 id="analyze-the-results">Analyze the results</h4>

<p>The whole point in keeping a decision journal in the first place is to try and improve on our decision making ability. That means picking up on patterns of errors and mistakes that we may be making.</p>

<p>With a paper and pen journal, this can be quite challenging. We may be able to remember the most frequent patterns of errors that we make but we might also miss a lot due to information overload.</p>

<p>This is another area where modern technology and software can help us. With the Decision Journal app, you can tag every decision you make to easily find trends and patterns in any particular category of decisions. In addition to tags, we’ve also added a powerful search capability that allows you to find decisions in a flash, so that you can be sure you’re not missing anything.</p>

<p><img src="https://decisionjournalapp.com/assets/img/screens/analyze-results.light.ios.png" height="350">
</p>

<h4 id="make-better-decisions-today">Make better decisions today</h4>

<p>Decision journals are such a powerful and effective tool for helping you make better decisions. Everyone should be using them. The problem is, they can also be a challenge and a burden to keep. That’s why we created the Decision Journal app for <a href="https://apps.apple.com/us/app/decision-journal/id1534768141" target="_blank">iOS</a> and <a href="https://play.google.com/store/apps/details?id=com.betterthinkingsoftware.decisionjournal" target="_blank">Android</a>.</p>

<p>It takes the powerful concept of a decision journal and expands on it with new capabilities made possible through modern technology and software. We think it is an essential tool for any decision maker out there, but don’t just take our word for it, give it a try today:</p>

<p><a href="https://apps.apple.com/us/app/decision-journal/id1534768141">
    <img src="https://decisionjournalapp.com/assets/img/apple-app-store-button.png">
  </a>
  <a href="https://play.google.com/store/apps/details?id=com.betterthinkingsoftware.decisionjournal">
    <img src="https://decisionjournalapp.com/assets/img/google-play-store-button.png">
  </a>
</p>

    </article>
  </div></div>]]>
            </description>
            <link>https://decisionjournalapp.com/blog/2020/10/22/introducing-decision-journal.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908337</guid>
            <pubDate>Tue, 27 Oct 2020 15:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Semantics for the Essence of React [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908308">thread link</a>) | @mpweiher
<br/>
October 27, 2020 | https://cs.uwaterloo.ca/sites/ca.computer-science/files/uploads/files/cs-2020-03.pdf | <a href="https://web.archive.org/web/*/https://cs.uwaterloo.ca/sites/ca.computer-science/files/uploads/files/cs-2020-03.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>}M:ÞkKdM’,¸ÐÇO?+¯ÆØ{L(ŠÔ{°”[Oi�ƒ‹·ñn&nbsp;S—1B2­Ã�OçzöË…€úûI=Ç
ÄE‡dò .õÆ»³V;åó$KíóFÆAƒ&amp;°p‰‚¯–ÃØK¢y�Ý‰®CDcæö«’ MÀ6VpoÁöö"'ß­›±éÚr³™
¯3³ä�r·Û ±ÙÀ=ë’ÆÙo¸gi£Æ˜ÖÍGÒiÆÑ}—2ñ›ÛßskW®Œt&gt;4ãš[fK¸´�`êÚ€KÍ#ïeÅ°qSõÍÎjƒ„ŒN\ Ê‘ós±â`£EHæ%’`)¿Ùî6f‹Ýatx´~lËmS1AÙÖÜÛ0�!4Nb¢¸3å8õ´Å�;–‚sÔFAÑì¦MI‰½iWÜik	âù†·UMn&lt;þ‘•ø‹aS“ãæÅ‰taD©fé&gt;0vÖ†R~œûŸU¢Þ|ü€Ÿ�:2,ØwÓjÍ£%ÿßîÃ-s—=÷¶¾@ÇÕ¿¾
¸õM'	jõ×&lt;2®›�[S»ë›¶j&nbsp;ÕZ–Ûíú®¬ˆ^6°1¨dbÇ¿{ûˆ1Uv"¯Š­Äšl&gt;­a”�—äcc·£üºù¬tZM¡²«àwjk&nbsp;Û“
aÛµ‹­,
#õÒmmNj3²JÛ�LpWVÍ¦‘&amp;dmÕ³a1[x�hÚ1ã™
9ÏJw,ŠÐ@'bÉ	j_4ÌÇôXÆHùÒJ÷fØq¢lÃC¶fäæ [B“^¶®à4B
Ä¹
¢H”Ê%ìB'	k5‰­§à“åèÈ�{îºo�…†®¿—®®çIv6ö‚„Ü�†ö‚�Á±&amp;�5Û�[Öbë^€$U·5B°6ƒy&amp;òã‘�¬hÅ‚ó-áPÂ")ÒYÊüÉN¨é
=Ì�…�F~K&amp;ªM=”{°cÖcÐèö¡»èúFÂÚÈèÀ%;j‘ï§‘Òšá9(‹“4ÐÀp+UN„Ð…¦=„¯Ü�H¬&lt;Ô&nbsp;$bµæ¿f�fL"sz#¤l;à–Bao)ts
Ýó‹òüu9ð#n·0O4ýØÀ©EÐPŸH#ÌS1]ovpwY‡½		&nbsp;iqø¡fŠÔA~ˆ@$[•üãÂMQì&lt;ÛÖ�øEùfr©ÇAJÄveêLÖËW·Ov½Lk¶Æ­ÝÖG›è
¡ÍsÕ8}*±(DXAYiâ,ˆÖ‰³m¹{]Vt1ÉÀÓÈ†8Ù
{á¡µ`ÿ–âh”&lt;%çÉƒyÉëÂ	r-Qó·ÁQá¸¹“
¦Q†:‘0B1“Ì–¤I€LmÐ�B&gt;'Ãm›ÖZ@ErÀÆR2Ç¨’c~�E1|lÜÁŠÑÄÈH€{Êó)®ÊZÇÀMú¥yK®E²âÔIUŽs¦o0ÃAaÁ Ným71Cö:ôðÑ˜ZÌù(ôÄj…X|¼âTûWqDmk¢¡Yµ%£ºd–ˆicÂæ~Ù–ƒ&gt;4~¿�˜'%È	jh+&amp;3µ^ØÝ[YmbJüMsg*lå‘nª�]+öÅŸ»{¡’ðÂˆiË¥£(¬°“-˜;¸ˆEªë·ÜCEã4&gt;ºišÚk,¾–ö±\–v˜~Y6Ã¹¬ó8Hò”%-«_§¦ëhg:Ê¼¨[†¹ÈÔM½äçÈo�©ÙÚyOçá§6
NãÆ%e�RQû­MsPe”¨è:
žß[Rö@ýPèïëf‰›%²pØasU¸¿ÏGºœ*û¹g9�Ò;æyxÎ}Ë•j¸•¢Vˆîhi˜…ªú–rD&nbsp;ˆÓé3�&nbsp;S–TºOcÈi{hÑÈ]ÀqèØK8Œcë*þ[®3C:58á™;.À]ÀpgÉ´6»YàX¹ãîÎM-ùÀ#TO×¯Å”ªÜQNœûÍ,br"cœÛ¡•ÑÌW…q!až³À¯¹Ïž†â‚½¤ðIƒ¨O™NöÛòÕÕÝe_N¡*¾]-H¹wÕqõé–£C�”÷ÝN|z™Æná«™¿uÍ�°æR.Î]|Î²Æ'²jD!öÜ×ÖXF&nbsp;çh¨ÍØDì9°pbœVÜ ñítþ”md{àÊäðK/…ÉA
gA2¦ÓlÆõpá·¶•ªX,êÄ9�uÅA*Gb†8ŠáDú�â¤pU-|ªÁ—³å!ú¿æ!‡úG�"ñ49b�S#¶-ŽòàÒÆjc%nÅðžÐYF¦ÇÏ�4t)–aŽñ‰#&lt;äÜ&gt;èéÜ-'‰35aš&nbsp;ÉMæäpp&amp;È?Y£à5y�ü/ÚŽ0¯?ÚÂ!¢råo›sIé€/Œ4ÝñÍ7FG=Ÿ¾æÛ–£Û(ªV
¹Ë‹Tñù!îõþ¸™–öDÎ—ç›rN ï…årk¤U�âÜáÔ{”ï¸Æ”¸Õ\iOãÌûò]V²v:Ê‚,ŒŽÙ}VJ�¹s;Ü†Ö¹½·;š÷ñH�Htáp1·¸øî»éîìI†/K{9ß’Cœq»ˆN™Z`¢ÅÊ¶ ]¡ü36×&gt;1
ƒ$¤bmòœLX"q47Gþ'}a�ô¥ù±G|g.ø
EùÁ©C08ÃnÝ—ƒ^ò�‚’»Ûè{	:[ð–¼CìsCt.K¡÷ÈBiK°ÇJ®?ô)&nbsp;üYEð–YÚÝrÓcôÂV5Qƒƒê"ˆâböwÈ–x5}MM›“ÖøÔý@j&amp;&lt;¥�aÚIéÔÛJ—úèôJ“p¹Ç!õþ0kŒFæ÷1zg“$¬¥&gt;¤8ö¦¿¾~·³0	œ;è,ó"„]T¸ëS¹üŠ©&amp;4e¿¿êJ$i®=–„úöÈ–¸J=&amp;¦ž-»ýÝÄkƒAd\­šÀ}Ž×�ýkÈ
O�²ùŽÉømåO£åAxkäÐu+ÝT[]\‘ƒT÷T#¶öÁ‘kHœ°ÆáK!2Ìt&nbsp;£â˜ñ-ëF‰ŸòÑKïŠRüÝ$7o|ŒPN¡”k;4�ÈÃ2µ7¿5|…e7)8ì¼Fš
êéÕÚÜÌÐ¼8tðó wGÞíþìÆz¦ãU�!.œû­ž�zèþþhÎ=v„©r!½€æ^ÑüîðEKŸ¾Dìº20Žì%´…�ðËE¾ÞOŠ(ÿÛvìùQ»žª}n¯€/Dé	zÖC`Gž¤ÎÃ0;”šbÉ¨®ä&gt;&gt;((&gt;„s)kûÖÆ:úÙEÐwö†ýÔ
§F8—Âd¾ÕÄ‡½5Ïí­9•¡á[zDyú¨rþ:(ŒÒ&nbsp;P‚'¶¬Ìì�›:½¥ŒUjß\2w)jiÜ›‹½ã±4ó&amp;}”2‘ß\¨%o.Ô×t38òGÕñQÙÈTz‡á7�Ì¾ÃÔ¼à{ÙÝ¿ø†Ž¤a2û£ÓùÞ7MèÆ‡ìÇ1ß@0¿ÃÐ‡$ÛäÉ;ŒÕQÈ;ŒÍŠ™&gt;P£�&gt;Ì³á“,	&nbsp;áMãÒQZ&nbsp;«7«—òµÜ/¢ð…ïÕN
endstream
endobj
125 0 obj
&lt;&lt;
/Type /XObject
/Subtype /Form
/FormType 1
/PTEX.FileName (./orcid.pdf)
/PTEX.PageNumber 1
/PTEX.InfoDict 150 0 R
/BBox [0 0 256 256]
/Resources &lt;&lt;
/ExtGState &lt;&lt;
/GS0 151 0 R
&gt;&gt;/Properties &lt;&lt;
/MC0 152 0 R
&gt;&gt;&gt;&gt;
/Length 324
/Filter /FlateDecode
&gt;&gt;
stream
H‰\RÉN1½û+üI�dœåJA\è¡âÀ�X$¤	‰¿Çv¦�ˆÃ8/Žýž—Ù=&lt;ÿ¾œqwØÞÜîN@9ÛçÔœ_à	¿€ü”	É×:Éù»ûGÂ·o8aP¿X
±âü	êPë
ù‚Ž‹Oèôm33¸Ðª¾šË{´BÒwÝÕ#¯¹k¾Ñ*¦F–ö
GÓ'+s+¯f‰ÎÍºÀ^»YV¨ø 7«òïÆ»±…8	]M&gt;otâbcãf´¹È³8
¥&amp;L3ÎÁGä$Ž¢±ñŠfá2°©
÷ÚZ=ÑÈ’hx�ÌÒŒa©#bæ~®:†CÔ‡`3L¾i5Ó
ç•¸ß–Qf€?ÿú®¶ˆÖ„vÜ3K“NÛw�dp£í:åâ‹$©=Þ`ß´"–YöÐ!ûB¡Ü†e#6åËªïòÛáO€Uç‡)
endstream
endobj
157 0 obj
&lt;&lt;
/Length 4216      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ�É’ã¶õî¯Ð-ì*5�…àâÛ¤¼¦âŒËÓ©&lt;&gt;P"Z¢‡"e‚œžÎ×ç=¼Š¤¤™rÝ"ö·o€Ø6bóÃWúêëïU²‘"NR‘ožž7iË"ßd™ŒM!7OÕæ·H=&lt;êDÑøM³è�=•íPï6Óè¹{Ð"ê©1-MúÎ9Ûî¹Ñ=Óè¯¶Ü¿?ýã+Á|ý½,6E\¤*ÅÓe,ô‹�˜²81‰Ö±Ê’@ò±vcÙÔÿ-‡ºk·�‰Ì¢ÝƒÊ¢Wø"ÀêóØ&lt;Èf´ê$˜Š"ú¶{xTy´O¶}€��Æßî&nbsp;;‹þ°›Ÿ÷3Í«lCí÷Âˆoßþ?2ìØw#r8R»¤Ÿ¦Ã]_ûa‚å€êFÄ@ÏN™Ì6™±Ö„Ò®§Uö³HE�Eo~ù)¦¯»úl&amp;ðÐlñ+½t�ûîÐ—§í‘Fû²¥�²ª¶ôÕÛœUDñ@Ë�ŸyÂÎq(Kë|úùŸ4bë	VDƒ»‹üê¬ ”ªºZ6¯¹‰�$‘ÑŽuƒÙOçÞ:WÄ=Rµ£á±=÷u»¯Ï�­¨§&lt;nåá;RÏ±äÉÎ.=r¹%8Ý•ÕÇ˜—Ëƒ…aç!QÑ÷uïª`@=N yR­�J‹$NTFH��¥ÈôÁ’F’`ë bðŒ¡‘Ï,+G­¡£á]_CÃsË¶¢�ª~/tº›a9{l+ÀNóö�ÔÊ2*ïì¾k‰¹0ÙÕ$&amp;LÌ;ŒJs'YJ8M”-¢#n#Ò¨T‘GÈUdØ°
?€6�YWZúîíèÊ¢†­ÑÙþ±&amp;òÛþ¹Üsÿ¾;�½nu-« ãqÄs›z×—ÈÎÚÇDôt¬û
zÂ9vEºF/Ícm‰	ŽÙx àAdõ´Ý@¶t5ŽWj6–¨žEœm&lt;Ÿ5s&amp;aÌu¾mo©Ÿå@ß$N �IÐbø¥^zwÜw&gt;7õž¤+pï
?cb“±éð*£‹h$šV&nbsp;»®£
²|±ª‹�ø\¯6j÷ýƒQêù€z”#^y«âÎNJæ±k�Z	4&lt;0ÚYê"Úž4ôåMÛy¨Õqok_èð)Ãn{[“¦WÔóÜw'úâ)d&gt;Ù&nbsp;à˜$zãÂ”{Ê�¨8Uì[d�ro€i}‰²R#3¼a‘žY1Kª9³÷x!€yÀcÐAÛRk7¯&lt;Ã‹|,Úž4ð{*YdJOGèù�ŒÃ�è˜§–p›5vI¢c™&amp;ËYÛåFIj5%½ÚÈè¸ég72Eœ¦«)²¸Ú)…iªøìN™‰õj†Wå0Ë¨ÏnTÈXJ½)_ïd˜ülùïñb+©`,•bšòD*®8˜ñjüìýÏ	W¡Cý@~+~§ßí]4*vYMG
BÍ2¿à®Ñ=²½9Z/ØÔk¿·}‹=Þ4‘ÍAQWFdQy©—iœÈW“OAs˜d™CüàHÊ‡Øö–-»à=ö&nbsp;óH¼£÷#»‘×Ö­,è�ox4á€¶âCÐ{âoI?ï…ë~QÑøè“[Þ!¹^ïª°Ð±IØG�ÜÐ�û�]¡ž3é¦ï!"—&lt;¥vÜc†Þ—¸£½…´!l,›æ•\øT÷ô	.�KÑµåqvá°øëcL! èfß¼G¡9–í½=„âÑ»‘º`£¬ØdKl`€p€�Œ5¼‚†·'@Ú’š•Ý7%p¤¦@•Wz aR·ótú%o?<v}�g€ xjÀÌk"™_Š52y§="" {b7x&6tæ—="" Ñxsbªà¨Ñ[Œ="" §èÜ�_³�7a¢æ="">ö`Ž†7—QÍ'•üëêÓ¹±ó&gt;&nbsp;-ª³¥‚Y%ô½4‰Ó‚½^Éá 
~IY¨"ùzI)B”#·7·Üôüï\�\óëƒA[ÿH¨MÊêî»‚Ê_§T—]‹4Î2µÜµæ•4gìƒA*Ýü¡·Ä=yáž¢AõTuÀÞ þ=‘72Î’ÉÏ¸ïÅ9DÖ)†çYbå»BbBÌ…É”g—ES–…0QÈCì
3.)E)e{½CS[ï¼¶ÃöÕk[žÀ¸6ÍdŽŠd•®pÑ!‚$8Ô¿‚Qî¨µ�”e&nbsp;èIÝîØ'½·GSDUQ?y½ÔÕÁ†É/5ÄÇ-O`Ãf¢sy&nbsp;¤!»-zsL
©¿Xb$O±ä¥�Œ`A†„x¸-{WW&amp;Î5;ŸÇ%3�.úüà9ìóy…êadä¾ky%r©¹¤\q±
Ä½­a•g±‚XvÏ¢`�þ³ùþ,Rà*âõi¾ÉBŠ¹¡À4ø@a;ƒå=Y�GF¾µ¶¢Àý&amp;Á¤Šóœœgy’"] ‚L£—Ý$”üÈÂ/ÅPâO0¦Nô6~'íÀ8÷ó4ÓÂ@î˜/Aš&lt;ÚçÈ$b	½‹uè«kÇžàðê¿&nbsp;4rùÑ»�™bø:•\éái	ê/Fb“mè'“½öHIÐiv¯C}²Ûy®
&amp;Q&nbsp;Ž^KC¸œÂâvÍEœi½Üµ·4,*\÷+]€
è¢
µÜ
$äÈù~¨1�62€êÓˆ„|§ˆŽTG
�sÅ`-
„iÍk^Ëø‡J�Xìè[v¬â’ErMØ&lt;… ¸úq7xe&amp;ÓlšCV--_I?§úÓ_´ˆeÈÍC‘ÊÌ}9Ù<dêÃÚ�ãêËi·<}²Æ.kb¡'o_‘‹‰®u9ÌÊ.–Ç(]:"â"&�—ðÔs l,¼Äïs°®,2»µ,="" 5Ãî'7£îdÉ,3l¹déÔ�m="" À="" !�Öæ988umŽ;‡ef="" „Íbwl?sè|1,‚4g¹8äm="%ß¨Ä^VfN²@'I|Q" mŠ3Ê`Š‰="–‚Zî" �p…m="" –êô<sŸk–¸7´àƒoðî¦,˜|k&à3Ÿ7â*¥€q¥sÒ‚]¾="" ]µ="" ”¥ŠrÀó@½·9="">;R%	è«ZI•ü.öh÷uSß‹g{iH˜3¥{mQ	0œ¯C•
aiRÝ0Ðz;È<k°l›³„xÃ€[À¿¤&-wa‰6±ÌØåÓ²ŸÔ ´ecö="" fœer­ˆ«Ü="" f1xûÄ,Ëñº¶zÕØe¡f½="">Qã’SFÝ‹sÀ(í.\5Ü‰’?…Á¢®³‹D�G•çÉÚ‘Ú\âŠ…­Dq¾-—ó…ÈLÂéwäùõÂºVcÏÛ'¡.ï�èT;½ØQô˜6&gt;Ä[š
Át»6üÓ}OD«©"Ý³ŽN˜’s2TT©/Á·³QôÖlXÁñžé!äHÐzî©4SpiFQÐÃ÷ Ä}A“ ä�¥I–Ð6õ3)Òë¾±_ÐH½òT-×9múàÞ•bb±£rõ&amp;Ç †nòOkMÀ�u(yM9m©�ß—»¡Å}„Œ‚)}îú;¦ýdUq“ÀÛË’g;LutK\¤•SIvrnhL†ÀùÚlÆ7\’‹½~×EÁ-à”ëX‡š²ºž+`á4�wm^/µ˜:Ø¯
a êo2›¼ƒýØ´¬ø•ª8KM˜_…ä\„\0V‚ÝÑÓC®"Ô8@Íé®2Æ™ ²1×©O—øã™8_•›êo&lt;õÔ9^ÌqÖäúÙd_�Nå$ä¾þˆzoÀÖ¼miðÝPzž}xËLãh:ü|ÙÞË;´�‰kž%]ß®A0ÑŸ¦£¼&lt;‚�‚?÷2ñA¨ÆS¸#æûáÙ-%…§öÄßÔg¬-M”¹Ü“P#ãh‰`9×A¾�§Bqs(‡éJDd«„wZª‹8ËóåÒ}ðî¶R_–¦&nbsp;Õ¹Z.åÚìOí¥îXöµóÖá’è )S@�•þ? ©¼ˆp(kBðe$O“J±™Lõð•íTÖü¤‰Ì!*H–Ç³Ò|Öòg
ñÝbñö‹G&amp;"NT±\å@±Ë/6&lt;•ò¯<n‹�îånðzyœÈe¶>Žîû[ÇÞRC-�D!ý÷ö…³?·ïëó—ª.,šÐ«]Êƒ7À"o  Ôý¡~w[R¯�”®–šðð:ž»±ŽÔÉ¶	z!&nbsp;ê}&amp;UQ»·l*\
¶ö-$ï�å)šÃè7/§Ï"›á¯$(%È—.ØÉDm…ùÀ¡!ð~ËaÇ¿~ùy»¸‰ÅÒyT´ø”n–-|÷Ô Ã„+Ã›�ør~:À'=8ÀÅ¬7“©‚/%¨-à�&nbsp;ÁÿÛ.
‹'¡^Q®Þ6?Ð“Îý¤øæ_…Mì„T!"x6¿?¯Àô�&lt;×¢÷iÎŽZ‹ gN_jò~N×ÒØ˜ß(QoXRsß5&gt;Ì
Ã&gt;Š/0Ð%ŠzÃr'öSY±‹¡Û•~å%p9#T;X�0Bþ‹1ÝK¼„]¾Ò&nbsp;"Uù1\	ï+v#—:Îå0ø‹¶Uá…¯¦Å‚–÷P³¡/oGòhôÚ"Ò¨±e�PŠŒ‚*�7aS8ZWá¡
&gt;Ÿñâ	ì§ï)¶t§LÂ-²ˆ÷ùci÷=KNß5�¼¹Ç†0zbÏO…"¤gB«kóÆŸ¤ú´·³i®zß0RÊèAxý3»Ü6‚k–Åò5‹™×«&nbsp;R23q‰ùc¸Ô�uY6%Å\P&lt;'CaË\Ò&gt;^A[Ï_Ã¼þ¡@ˆ®¯ØˆÎ&amp;�21Ø1„°3–\Š?ÊŸÒØOáBˆ_€œ›©x	ÝôàÌzsNºfC9
È1\ùªÛ&lt;|^™e¾9+ò5óT¨b~e� ½Œ�4!´ØÏëtgÙº´ìÄaL
(ßùâé×ZðýËÄìûL¢óO¦(ÚÐ³¢tÊ\ðÛ“?.W»dgR¶3©?e¡á§Døú¢ëÃ«¤Òù:Uð¡�ß�ÃêFëXúúOM;\N™Ìjºxú±½«þ<nÁæ™¼ vÆ¡;ÁÊ="¬/€oç¥ø˜¦“AJ°x¯_Ñ" séç="" |Ã:–ãjÆ…êsÍ‚Êêá="">¾Þ¤ÂÞ-ç ŽÞjœÖe	‰5Àp[WóêÞþ9ÖXC¦W	Æàƒ-;—3·mÀx[#OŽ¡ââÆé…–'£Âð›m¨º¬ÐáÌ5`Á‚xÀWð®pØekì2ðÐy±L¤ÑBžÑIºÕL;=pÕüÀ~½”x*ˆèíÈ/+×‡®šw¥£•áC9-ç¡\¨dyl€ße8üÓf“ÆE¦ý^çRm%¤	e²÷’†‰ºÐq®“åþË·GXf0iºœ"å5óT¾œ÷;?6e«”‘ä:.ŠeS¬`wÓXIÈÌ�žª}l|¥¬rºÜü­—S¿Y\Êlrpbfó¨$DèŠˆt¹Q\Ìü
&lt;„ˆÖ…7½ªÊ¡´zó&lt;�‡ÓoF5‹±ê�Ã4YŒ	˜»ÐÜ2×÷ÏcKÍ	C×»sðÃ{—ù.Ó …c:TýWäŒ�œcp…‰‰WÚqa\
žKPß¼^ûîé«ÿÞrën
endstream
endobj
185 0 obj
&lt;&lt;
/Length 4060      
/Filter /FlateDecode
&gt;&gt;
stream
xÚµZK“¤¸¾Ï¯¨›éˆn!�À·µ÷ox¦{Øõ�¦ÔÝx(¨jºÛ¿Þù¦ªgÖ¾Bè•©Ô—_¦*Ù=ì’Ý÷oþrûæ«ïR³SIlò¤ØÝÞïÊ$¶I¹³VÅY©v·ûÝ¯ÑÛê¡;�W7:·PÞ�®Ãr¹‰ëª6†‚2PÔWÿºýéM"ãõ�*we\æiŽc«8Q)|Hv
¦Ìâ&lt;Ó;«uœ0Ñ&amp;º½*Ò¨‡±Ò2Ú»Cß�ÓPMŽ+¦ÇjâÒ‡«´ˆÜ¿ôÇ«|…†
tàÊñTc›G~«¤öÐŸº«ÔFSÓ=\sÕ©ãÊ"¬¬º=W÷]Ý´
��¢í’¸,D¯ª4‰µf&amp;7š–#¥Y=ÑJ¡¬è·D›NÞ¦G*”Q×OÍ•Š`xzíïù{…³�þ@a‹ƒÉS“Ä¹)V³?¹öêÆQ{sw•¥‘{¬&gt;:,ìe¬òÂPeë‘êþÀjí;ÇÚáUÝaù…Ë�o2‚æü¢I†¡ê&gt;Ìu÷§®&amp;íÑÛe-&amp;6Ö¶¼4ýˆ[£�l
÷û©h­µ7ø€Š%qs³+@\x&nbsp;éÍj³+ízºÁu{7¬,÷‚‡Z³6VÛ‘nzìiå²LÜN\_Å¯ÁÊHÝwí7ÜtÈŒÏ6/¨//MlRË« ²p
¦¡©'™ÞUÛ‚˜0^‚[F÷Î­�y~¹*22S‹Ç�7–ŽC�ºÿˆ;îÆjÆ�lÙ-š¿Ç
›}¤Ú}çÆ‘›5£Ë�n�Ï\5ÛO:Êü›ó{�AÕkäÈ‹$ÎR1Ø;¿û
é.‹Žda&nbsp;k®ðg›Ýó&amp;Õ§Ñë1j\÷ƒwÐDï\UOü‘ÅFÁ&lt;¥+˜“…ÂvÆ™ÍÖUyü|þ8Îêö²Ì×ýp§LÈé^�ºTqšxj£²ØØu7Ø·Æùó7kÁD�ÕEcÌ-žr÷ž­‡¾#×ÑØ¤T£Á<vÝƒ¹¢éøÉ›€mog1ÿar{®k›{w¿Ô­4Á‡è ÍÀeÐ*Ó<º;m~¨~”–Õà»ô#�="" ,ÃÀ�=",®jIpPéFØ‹\$™zÜpP§�OèLúO‘Ç%ºÁ/&nbsp;ê‚K" {œ¡'cÜŸj·?‡ìÁÌižÀÞ­§~w•%`»ðÃsd6œ�×þÃxfkƒÑ´Òqrä«Ñ@kÆ*Ä$\açž¤¢?â‘]pýÁÕ¸tØ!8r*:`­†“#Â�zfÒÚfefÅyî±êªw˜�ˆÖ)ï3<+f¼{\|n�_Æ="" g~¡m†wîØ…="" l¢Ù�þ«4;ÑvÃˆ|dÓ¨n«êt4Òé1È="" 4ñ-»ˆ…]�³="µ°3*zp×Þ£¸AnCÏ6²¦El•ÀnG#ÖµJh²¬a2‚¦ÎïýÀÏ8Î,‘|cq&nbsp;s�z†@u%ïIÁ{rà*ÚlÏÂÍVZ¿æJv�Ð�²œŸ&nbsp;üÖUÃ¥��`ó|9Úšè‰wÄ‚×xžPÃlå\E'Òq<ØqêÞSéß´-7¸c�æêj�&amp;H">Ý.X­ü/Ðàa33`9…Öc6ñQ‘*"Ð/ìú0È=ŸA}k&lt;Ùšo’Æ…2"ïPí›Å2õ¢d}Æ´
3Mø¦¸ç;&nbsp;Ýz+$h:Û¦ý]°
ÞÝe°Ï“Qd“#:T
‘xeÃÇjö‚XZ¼ ¿ûú~xú®_+©¾ï[P^Ë]½wBà°EÊPºTü vÁ«`ÉÎ[øÃ¸Ì¹Ñ2E}ø”w÷\Ž„ðB¶O0�Ó¿ÿ&amp;ÂƒÔ©«ÝqšÜs2Väè}Û?¼p€Äl^5P}Ú:ƒF
–|AŒP5‘sOò¢®à,ºRÑƒ¸�ÐX¬IYgŠuv3NîÈï½ß«jÆal{,J-ý2	‡s�?lœË!©«`cP~y"ˆÒI²$N29Þóê5LgøáÃ–‘_+~œ£„c–èb®téÝ$Œ«¶PãÇ��ÄOÆ�XƒòÉGƒÁRf¦h6"j`ê‰œèízºªu.�˜]…å°DP&nbsp;ãlgÒŠ�Äñä�áÁË'ü<o`Ø$ãÇ¾‹è áë#¹‚'~="" iðã÷ºêü†&üÊr«l¯¤e7v�ÈÄ�§‡øÎµbï�c¤h 3\e{Œny¡hdj£\füÂßè8ÚëošéÈrëõ‘="" |„ó="" çšbø3¨œ)="" ´‰ð="" qm.ƒ°qaáq”x="" vÌØ‰ÊÃv›šwßq›ooßüþf³hc="" …„õá="" Õç@ã‹�210ñÁíîßüãË¦ßfg@f–rv|�…yÀ �Óqr&ýr±dÜÝ¯7*sÙ‚ÓgÒ4‹`)¼˜,�³r@âÜ[ÉÉˆ§tÉÇÆ="ùL�;“¨" 9Ì±pÊÄÃqÊ|z‰ì�s="" Ôo<ìnvíÊ•c9š]Æ¹ñÞ�£ÙÒ="">ãÕ²�0?Q0]ú„M‰,!àó´\Á©ˆ™	ŒÒLç¬T$H!Ôñ'Æ®;n°wŒGí!Ò‘Ô8ùV<oaþi�Áfau¶3iç¥ötÁãzƒ‡lïçÞml'%�ƒÃÚª©â9f€†²œf$€f(=§,pþÚ5eŒ<:qó½`5Î3ôn:cæœ àèÜ½æ�$Æ="·‹ÔX#dèŽÓOèÄÝð'²/}Ãk%p4øò3ƒâ¿]-og\ä÷ß’,ùæç·ðP\AÌ#EAa4ð†ÙÜU,ÝF££T‚" Õ:“ˆcjÓ‚©‹çÔˆ?Ýu#Ç„tð¶�’Àsèch‚Ükàá›îxšxÉ="" $Ñq€="" ‰~—Åy_Íqâzi¶`‘¸À;¿Õ•Œ±�rxÙ7°ø¼="">µ¾{ÏOæ¿×¾èYÌÌÛ|ðô,¬E�]øãè|‡ëLwÕ(©1žY!º�…)x­©²¶:.µòŸ)ÎÃEÌdÔ¿¦ž©7b2I±&nbsp;wïßsáÞ9Š5ÓÙ’¡rtL
Šà„ÑÒql&amp;?ì¿¤$„ï@�ŠÃj©†±¯/�L�£åË²q%…P¾¨ Ì‚r3µR$ø„g0¼Éê0ê€G¶ƒ¨¼ˆþ
ZÀf$êâD4ÿéØ&gt;lƒñØ¶š¦áa{1O¬ê—OD4Eœh9È÷§V¢,Y£DóBP4ÖjAÇ™µ¸;T:ž0öù�AóƒIîaÆ]£�›z™È[Àüõ*5¨½|ú�í”1Æ«Îš»ÎâD¬]|£°I7Ýf2Æ*¸g	1§UŒ‹ŽaÚ#øò¡áB*Í|€Çä}“¢ÓzA|:%Þgæk
�Ö£Ÿ¶š£&gt;µ¡à:Mc•
ŽíN»~ò!ë®j:OîÅ´¡¼Þ"'xÊ°2k�òØ�ÏF?ø¨¤û£÷KøG´œëà›@6sŽÏ‹Oñ¡ºŸøŠ€ˆÕ&amp;ˆÒI+kgGˆ¨Çö�S¶”½Ój¿‰$BkÈÀi¤ÉÝàž›	JÊ{pþ6w	-„\�åô~óû”Í•œÅ9÷l[¿áÃÏ¼«†ýÙ�s¼‘¯eOË<nÓ|ÅÌ=@Áã–ØŽ’¸b…4aú<ÑÍ–@äÑó€»°¯·6·:Š+&j™~ªÚ‡ Ì[év”bÇ©¿áçÂ½—44ld†f£¿÷“óããpºs`="">cg„&amp;å-Óã¸„ÃÅlð¼6è§Æn×Õ¥„�ÚL(šÍ"&nbsp;cç¹ü&lt;8[Õ«‘®yqMìâk9|•»ñ‰àOT6z³À9ýuÁÀ{)€“™îbíØÃŸ¤%Ð-MGB'ŠA»Õ:ŠÝêO,G/áànø2#Ü
wôì Í .Såro”˜öíÐ•ãµm©?{ùªÐ3gÅz¨wtçŠ?L”¡ªi¹,ºt¡¨óØ¦›Aéþ¬Pa¾.ïVI5?)¡„¯&nbsp;W€ê_A›2¶™ú¬´zLÑàƒò37p&gt;»i|]“f`µ›áE»ÄLèrž$»ç?=6|#4ƒìÆÈŒŽMnµhüÑµ÷7�ûp’¦ùç�œÚ~j8§?qs‘P�ëH*Â,I˜�’„GqY™å|FUl×+OtêS³úºËz›G*ÄmÅz,â5záÕÅ¹rþ€‡ä&lt;ÕJugJpÚ5x½Á‡»éÆ©‚Ð|\»Bº<a7ìë‡Ùe¾,z@ûáöíß1ðè¶ û,žÝ�c%µw§i’ÿkƒ»çi="" ˜\»§ü8!dñçcÁtÙ8ËÍŽ_n}8e="" fÊfù$„o5|öÏÚÄºškà#�?¸f="" ž°ÙzµÙ¯^Ñ&šüæjÌ¯ÁÓ¼z®<‘zõzþóèÿêbüÿ`Ø¶Å^jä¿ÊsÕñÏh="" Ÿrñº="" ½î?¹y÷oÀf•^yü,â^€ðÍœ«ÿ�á$�="" p�«×\ÅßÙ?â~Íæ£mä¯÷+áaÞzÃËúìó×ãeœäéz’wãø�sûÏÝ�ë�èœñúÖkämucƒu‰w£*¸6¸tœ¹^h#!;µ•xrgpa3�ü?dpwÁ�¿ö9}Äæe`Æe’­wyd3'›v–¹kÀ?�r¨ØØ|="Êµ&nbsp;SÇÏÆÇJrñþÚª€n®Æ›/Ÿ_YˆÉàˆl•">/D&nbsp;½zÍLü®Y¼äÝþUèS¢•øËaÎÏ¤éªcøÏ åÿÍqë¯®ÃK’ÆÉÅöLxª9»}�»ë{Ÿ‰?žäfhWs¸Á‡®K–ÒÿµÈ_J¦RÒÏ:Mç½†Ê3&nbsp;	eÙí{µb¯€Û˜NH|ä‘-—ÑP|ì[
=2L%Ü
'¤†æ÷™’U{â?™d‡ÄDF3»D‚«vüNZ€	¼&nbsp;x
¿œ/Øß,�™wqƒÑ´Òpƒ!Æ]õ\ÿ÷+¸g½ÿØ•ËMâéqy&amp;×à`¿p™ÿ&amp;±§Ãñîÿt7	B”Ÿ0øNª‚g%ÿhžçú3ùcR
€Aáï/Cú¸JÏTJ®]2âD`|ŠrÎ”�­F7}•?f„	;mCg~½ÅF4É‰²äwAjÈzéÎXušÒ™P8{Æ¨…œ4À¡q=û„¤HëŠÿu‚Í&amp;W)ai·÷ì¦ÛÄS4&lt;®xgÉW$çäãÜTRÈÀaû®™úÁ'×ÔHŽ+
QŠÿo(Ñkö¶Jn÷àÉ2áý&amp;ARý 	#üÏ_�¡Wg&nbsp;‹„JüÂ")}Þv±›e0%§}ÿ—‚Ók0z%__dœ	s-Ù«'6p"™-Ö×eà[ÕåO&nbsp;ÿ�»BQxˆš±²z¾+„…å% J—@ïþ‡ÛÂ?ÔVžÿCË¤ë
endstream
endobj
2 0 obj
&lt;&lt;
/Type /ObjStm
/N 100
/First 805
/Length 2304      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ­YkSãÆýî_1ßu/£y?(*µ^Ìn¨,w)L²ÉÝP·„&nbsp;`KŽ,ïB&gt;ä·ßÓ²Ìk16‹)`4£žž3Ý=ÓgF’	f™Ì1cYdÞ2)XÐLâ—þ“
mžI'˜xŠLIüšŽRLyÃõG£cÚ&nbsp;%2…</a7ìë‡ùe¾,z@ûáöíß1ðè¶></nó|åì=@áã–øž’¸b…4aú<ñí–@äñó€»°¯·6·:š+&j™~ªú‡></oaþi�áfau¶3iç¥ötáãzƒ‡lïçþml'%�ƒãúª©â9f€†²œf$€f(=§,pþú5eœ<:qó½`5î3ôn:cæœ></o`ø$ãç¾‹è></výƒ¹¢éøé›€mog1ÿar{®k›{w¿ô­4á‡è></náæ™¼></n‹�îånðzyœèe¶></k°l›³„xã€[à¿¤&-wa‰6±ìøåó²ÿô></dêãú�ãêëi·<}²æ.kb¡'o_‘‹‰®u9ìê.–ç(]:"â"&�—ðôs></v}�g€></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cs.uwaterloo.ca/sites/ca.computer-science/files/uploads/files/cs-2020-03.pdf">https://cs.uwaterloo.ca/sites/ca.computer-science/files/uploads/files/cs-2020-03.pdf</a></em></p>]]>
            </description>
            <link>https://cs.uwaterloo.ca/sites/ca.computer-science/files/uploads/files/cs-2020-03.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908308</guid>
            <pubDate>Tue, 27 Oct 2020 15:25:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome Deno Does this mean goodbye to Node.js?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908259">thread link</a>) | @jpvillaisaza
<br/>
October 27, 2020 | https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js | <a href="https://web.archive.org/web/*/https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>During the last 10 years, Node.js has become a big player in the backend framework market, powering several large scale applications across the globe. Meanwhile, JavaScript has also evolved greatly, not only because of the efforts of its development team, but also based on community feedback. However, integrating some of these new language features into a 10-year-old framework is not really straightforward, and has a high level of complexity.</p>
<p>Therefore we could say that Node.js’ architecture hasn’t evolved as fast as the language. As a basic example, Node.js is still based on callbacks, while there are far better ways to deal with asynchronicity in modern JavaScript. This is something that its creator, Ryan Dahl, has acknowledged in the past few years, and it has moved him to work on a new framework that addresses some of these issues. It is called Deno, and in the following article, we would like to explore some of its concepts to determine if it will render Node.js obsolete.</p>
<h2 id="what-is-deno">What is Deno?</h2>
<p>First of all, you should know that Deno is not a fork of Node.js. It’s a modern runtime for JavaScript and TypeScript, implemented from scratch by Ryan Dahl in 2018. It was built on <a href="https://v8.dev/">V8</a> just like Node.js, but Deno was written with <a href="https://www.rust-lang.org/">Rust</a> and <a href="https://tokio.rs/">Tokio</a>. The runtime was designed with TypeScript in mind, and for that reason Deno supports TypeScript without extra configurations or tooling.</p>
<p>Deno was built to improve security and help increase productivity in developers using the latest JavaScript features. At the time this article was written, Deno’s version is 1.4.0. It’s a stable release, so it’s a good time to go over its main features and learn how you can use them for your application.</p>
<h2 id="features">Features</h2>
<h3 id="typescript-out-of-the-box">TypeScript out of the box:</h3>
<p>TypeScript is powerful. This superset of JavaScript allows us to use types, interfaces, classes, inheritance, modules, generics, and other awesome things. However, it can be a bit tricky when using it with Node.js, because we need to install a module for TypeScript support and some tools to transpile the code. It also requires some additional configurations through tsconfig.json. However, after all of this setup, the JavaScript files that get compiled from TypeScript work pretty well with Node.js.</p>
<p>Deno offers native support for TypeScript at its 3.9 version. For it to run nothing else needs to be installed, and no compilation step is needed since Deno transpiles the code behind the scenes. It is also possible to run the code with a custom <code>tsconfig.json</code> file to customize how Deno compiles your code.</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span># Using a custom tsconfig.json file</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>deno</span> run -c tsconfig.json my-application.ts</span></code></pre></div>
<h3 id="url-imports">URL imports:</h3>
<p>Node.js projects have a <code>package.json</code> file that contains relevant information for your project. It also holds the dependency list that you’ll be using. Deno handles this part in a completely different way. The <code>package.json</code> file is not used anymore in favor of <code>ES Modules</code>. In order to use modules in a Deno project, you will need to reference each module with its URL or file path.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a># Import <span>module</span> <span>server</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span>import</span> <span>{</span>serve<span>}</span> <span>from</span> “https<span>:</span><span>//deno.land/std/http/server.ts”</span></span></code></pre></div>
<p>When the application is executed for the first time, Deno downloads and caches all modules in a global cache. It is possible to store them in a custom directory using the <code>$DENO_DIR</code> environment variable. With this approach, Deno decentralizes the modules and your project will not have a large <code>node_modules</code> folder.</p>
<p>To keep module versions locked, it is possible to create a lock file with the <code>--lock</code> and <code>--lock-write</code> flags.</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span># Create/update the lock file "lock.json"</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span>deno</span> cache --lock=lock.json --lock-write src/my-application.ts</span></code></pre></div>
<h3 id="secure-by-default">Secure by Default:</h3>
<p>Deno has some security measures in place to disallow potentially dangerous operations. By default, the code is executed in a secure sandbox, so it is not possible to access the network, file system, or environment unless you explicitly allow it. You can do this by adding flags when running the application. These are enabled by default in Node.js, which makes it insecure in some cases.</p>
<p>As a quick overview of what can be enabled we have the following flags:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span># Enable environment access with Deno.env.get</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span>deno</span> run --allow-env my-application.ts</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span>#Enable high resolution time measurement (used for profiling)</span></span>
<span id="cb4-5"><a href="#cb4-5"></a><span>deno</span> run --allow-hrtime my-application.ts</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a><span>#Enable network access</span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span># This is used in cases where we want to fetch from external servers</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span># or when we want to expose a port from our server</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span>deno</span> run --allow-net=https://example.com my-application.ts</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a><span># Enable plugin usage</span></span>
<span id="cb4-13"><a href="#cb4-13"></a><span>deno</span> run --allow-plugin my-application.ts</span>
<span id="cb4-14"><a href="#cb4-14"></a></span>
<span id="cb4-15"><a href="#cb4-15"></a><span># Enable filesystem access</span></span>
<span id="cb4-16"><a href="#cb4-16"></a><span># To read a file or directory with Deno.open, or write to a file</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span># or  directory with Deno.writeFile</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span>deno</span> run --allow-read=awesome.txt my-application.ts</span>
<span id="cb4-19"><a href="#cb4-19"></a><span>deno</span> run --allow-write=awesome.txt my-application.ts</span>
<span id="cb4-20"><a href="#cb4-20"></a></span>
<span id="cb4-21"><a href="#cb4-21"></a><span># Enable subprocess execution with Deno.run</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span>deno</span> run --allow-run my-application.ts</span>
<span id="cb4-23"><a href="#cb4-23"></a></span>
<span id="cb4-24"><a href="#cb4-24"></a><span># Disable all security checks</span></span>
<span id="cb4-25"><a href="#cb4-25"></a><span>deno</span> run --allow-all my-application.ts</span></code></pre></div>
<h3 id="built-in-utilities">Built-in utilities:</h3>
<p>In Deno, we have some nice tools available out of the box. This means that we don’t need to install any additional libraries for some common development tasks. At a glance, these utilities are:</p>
<p><strong>Debugger:</strong> Like Node, Deno supports the V8 Inspector Protocol, which means that it’s possible to debug the program in any client that supports it. This consists mainly of two commands:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span># Debugging flags</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>#   --inspect      : Allows debugger attachment at any point</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>#   --inspect-brk  : Pause execution on first line</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span># Usage:</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>deno</span> run --inspect-brk</span></code></pre></div>
<p>From this point, all you have to do is open your client and the program will stop on the first line, allowing you to set up breakpoints where you need to. For VSCode you can add the entry point and arguments to your <code>launch.json</code> to enable it.</p>
<p><strong>Formatter:</strong> In Node.js applications, it’s common to add a linter tool (typically ESLint) with a formatter like Prettier so the code is standardized. Deno has this feature built into it. You can access it by simply running <code>deno fmt</code></p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>deno</span> fmt          <span>#Formats everything in the current tree</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span>deno</span> fmt file1.ts <span>#Formats a single file</span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span>deno</span> fmt --check  <span># Checks if files are formatted correctly</span></span></code></pre></div>
<p><strong>Bundler:</strong> Bundling is a task that is currently done with webpack, gulp or Grunt in Node.js applications. We can use Deno’s bundler when we want to pack a module together with its dependencies and this will generate a single module we can reference from other files. These bundles can also be loaded in the web browser.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>deno</span> bundle https://foo.bar/test.ts test.bundle.js</span></code></pre></div>
<p>After that, we can import it from another JavaScript file or using a <code>&lt;script&gt;</code> tag in our HTML with the <code>type=”module”</code> property.</p>
<p><strong>Dependency inspector:</strong> We can display a tree structure of our dependencies using the <code>deno info</code> command, followed by the URL we want to inspect. This is similar to <code>npm ls</code> in Node</p>
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1"></a><span>deno</span> info https://deno.land/std/uuid/test.ts</span>
<span id="cb8-2"><a href="#cb8-2"></a><span>local</span>: /Users/foo/Library/Caches/deno/deps/https/deno.land/997789467b3621b5d93c6b18bf8b275f35057b24f934c2508e3d1ef52cd51644</span>
<span id="cb8-3"><a href="#cb8-3"></a><span>type</span>: TypeScript</span>
<span id="cb8-4"><a href="#cb8-4"></a><span>compiled</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js</span>
<span id="cb8-5"><a href="#cb8-5"></a><span>map</span>: /Users/foo/Library/Caches/deno/gen/https/deno.land/std/uuid/test.ts.js.map</span>
<span id="cb8-6"><a href="#cb8-6"></a><span>deps</span>:</span>
<span id="cb8-7"><a href="#cb8-7"></a><span>https</span>://deno.land/std/uuid/test.ts</span>
<span id="cb8-8"><a href="#cb8-8"></a>  ├─┬ <span>https</span>://deno.land/std/uuid/tests/isNil.ts</span>
<span id="cb8-9"><a href="#cb8-9"></a>  │ ├─┬ <span>https</span>://deno.land/std/testing/asserts.ts</span>
<span id="cb8-10"><a href="#cb8-10"></a>  │ │ ├── <span>https</span>://deno.land/std/fmt/colors.ts</span>
<span id="cb8-11"><a href="#cb8-11"></a>  │ │ └── <span>https</span>://deno.land/std/testing/diff.ts</span>
<span id="cb8-12"><a href="#cb8-12"></a>  │ └─┬ <span>https</span>://deno.land/std/uuid/mod.ts</span>
<span id="cb8-13"><a href="#cb8-13"></a>  │   ├─┬ <span>https</span>://deno.land/std/uuid/v1.ts</span>
<span id="cb8-14"><a href="#cb8-14"></a>  <span>.</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>  <span>.</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>  <span>.</span></span></code></pre></div>
<h3 id="asynchronous-handling">Asynchronous handling:</h3>
<p>JavaScript asynchronous operations have evolved over time. The standard way of making an asynchronous call was through the use of callbacks. Recently we’ve gotten better ways to handle these operations, by using Promises, async/await syntax or generators. For that reason, Deno has taken advantage of these modern features.</p>
<p>All async actions in Deno return a promise. This is interesting because the <code>await</code> keyword is supported on the top level and there is no need to define the function with the <code>async</code> keyword. This approach allows us to write more readable code when working with asynchronism.</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>// Await some asynchronous operation</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span>let</span> file <span>=</span> <span>await</span> <span>Deno</span><span>.</span><span>open</span>(<span>'./my-file.txt'</span>)<span>;</span></span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span>// Awaiting when starting the server</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span>import</span> <span>{</span> serve <span>}</span> <span>from</span> <span>'https://deno.land/std/http/server.ts'</span><span>;</span></span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span>const</span> server <span>=</span> <span>serve</span>(<span>{</span> port<span>:</span> <span>3000</span> <span>}</span>)<span>;</span></span>
<span id="cb9-8"><a href="#cb9-8"></a></span>
<span id="cb9-9"><a href="#cb9-9"></a><span>for</span> <span>await</span> (<span>const</span> req <span>of</span> server)<span>{</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span>req</span><span>.</span><span>respond</span>(<span>{</span> body<span>:</span> <span>'Running server!!'</span> <span>}</span>)<span>;</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span>}</span></span></code></pre></div>
<p>Deno supports promises out of the box. In the first example, the <code>await</code> keyword waits until <code>Deno.open</code> is resolved and its result is stored in the <code>file</code> variable. In the second example, <code>server</code> is an async iterator and the <code>for await</code> keywords are used to iterate them, each item will be a new incoming request.</p>

<p>Deno has incredible features, but there are two points that I think can be improved: - The permission flags could be handled in a different way like using a file that allows us to set the flags. If your code needs almost all the permissions you will have to use a long command. However, this is not a big issue on itself. - About the dependencies, NodeJS has a better project organization and the <code>lock</code> file is generated automatically. With Deno your dependencies will be placed in one directory, and to lock the dependencies you need to run an additional command. This might not be a good developer experience, but the community is working on some alternatives to change this.</p>
<p>Another point I would like to mention is regarding the examples and tutorials. On the NodeJS side, you can find a lot of examples/tutorials of any library or functionality you may need, while with Deno there are few examples/tutorials. But it will increase in the future for sure.</p>
<p>In this <a href="https://github.com/stackbuilders/deno-example">link</a> you will find a small example using Deno and Typescript that shows how to create routes with the <code>oak</code> module, submit data from a form and generate a CSV file with the provided data.</p>
<h2 id="conclusion">Conclusion:</h2>
<p>Deno is a good alternative for increasing security that allows us to use TypeScript without extra configurations or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js">https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</a></em></p>]]>
            </description>
            <link>https://www.stackbuilders.com/news/welcome-deno-does-this-mean-goodbye-to-node-js</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908259</guid>
            <pubDate>Tue, 27 Oct 2020 15:21:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alexa Seems to Be Getting Worse with Time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24908249">thread link</a>) | @cushychicken
<br/>
October 27, 2020 | http://cushychicken.github.io/alexa-seems-to-be-getting-worse/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/alexa-seems-to-be-getting-worse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I loved my Amazon Echo when they first came out. I love to cook, and I love to listen to music, so my Amazon Echo naturally won a spot in my kitchen when I first got it. Later on, it got upgraded to a Sonos One. Both speakers had voice control features that I loved, and used all the time. Hands-free timer setting and music control? Sign me up! However, Alexa’s shine has started to wear off - especially in the last six months. What’s changed?</p><p>Just in the last week or two, I’ve noticed a pretty serious bug in the Alexa software: its timers are not playing alarms when they expire! I can set a timer on my Sonos One using Alexa, open the Alexa app, and watch the timer count down to “00:00:00”. I expected hitting “00:00:00” to result in a tone from the speaker, like it’s done reliably for years. Instead: silence. As if to add insult to injury, the timer stays in the Alexa app, stuck forever at “00:00:00”. I’m not certain if this is a Sonos problem, or an Alexa problem - I see this behavior on my Sonos One, but not on my Sonos Move.</p><p>Whatever the case, it’s very literally burnt my biscuits. I do, primarily, use it as a kitchen timer, and it’s hard not to notice a bug that ruins your food!</p><p>Alexa unquestionably has a much lower success rate understanding my wife’s voice than mine. At first, I chalked this up to a matter of training, and understanding how the voice recognition technology works. I’ve participated in the development of a few voice speakers. I know that the best results come when you face the speaker, and speak slowly, clearly, and without pausing. Even with coaching to do this, Alexa either fails to understand my wife, or ignores her completely, at a rate of at least twice my own.</p><p>Unfortunately, I think I know the reason for this, and it’s not a pretty one. Voice assistant software naturally has a better success rate when tested against speech signals with lower frequency ranges. As a result, they naturally have better chance of understanding deeper voices, which predisposes them to understand men better than women. I thought this was just paranoid suspicion on my part, but <a href="https://www.techradar.com/news/smart-speakers-understand-men-better-than-women-according-to-study">I’m not the only one who has noticed this phenomenon</a>. Not to mention that it’s hard to argue with a plot of Voice Command Success Rate against average input frequency. The trend just goes down, down, down as the average input frequency increases.</p><p>It’s a disappointing bias set by technology.</p><p>I also get the impression that the quality of voice interactions has gone downhill over time. No longer does Alexa magically find the thing I want to do - whether that’s set a timer, add an item to a grocery list, or start playing a particular album I want to hear. I find myself leaning, more and more, on my smartphone to queue up music. Alexa is just not up to the task on any given day.</p><p>I have to admit that this might not be a real problem - or, rather, not a change in the voice recognition software. The only thing I know for sure has changed in the last six months is that I’m home a <em>lot</em> more. Working from home has given me many more opportunities to use my voice speaker. I’d estimate that, pre-COVID, I used the voice control functionality maybe five times a day, in two discrete blocks: in the morning, before leaving for work, and in the evening, after getting back home. Working from home has blown that schedule out of the water. Instead of a two-hour window at the start and end of each day, I’m at home <em>_</em>all the time_. This gives me more opportunities to use my voice speaker. Correspondingly, it gives more opportunities for Alexa to fail to meet my expectations.</p><p>Having previously worked at a company that makes voice speakers, I understand that there’s such a thing as an acceptable failure rate of voice transactions. (The terms of art are “False Accepts” and “False Rejects”, if you’re curious.) This leads me to wonder: is Alexa’s voice assistant technology getting worse, or am I just using it enough to expose its warts?</p><p>For example: let’s say I use the speaker an average of once per hour. If I’m home for four hours a day (like I was pre-pandemic), that averages out to four voice commands per day. If a voice command fails, on average, one time in twenty, this is likely an acceptable failure rate. It’s easy to forget a failed voice command if it only happens, on average, once a week or so.</p><p>Now, though, I’m <em>always</em> home. That gives me sixteen waking hours in which to issue voice commands. If we’re holding constant the once-per-hour rate of voice commands, and the one-in-twenty rate of failed voice transactions, then failures of the voice assistant start becoming a <em>daily</em> occurrence, rather than a weekly one. I suspect that this passes some sort of psychological threshold: even though the overall failure rate has not changed, I notice more failures just because the time between failures decreases. Since it’s now a daily occurrence instead of a weekly one, I have less other minutiae going on in my life to help me forget Alexa’s shortcomings.</p><p>I’d imagine the folks at Amazon would consider this a pretty serious problem, even though their underlying metrics for Alexa’s accept/reject rates likely haven’t changed at all. Being a consumer good, <em>perception</em> of its quality is almost as important as the reality of it!</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/alexa-seems-to-be-getting-worse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908249</guid>
            <pubDate>Tue, 27 Oct 2020 15:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StackHawk Raises $10M Series A to Bring AppSec to Developers]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908245">thread link</a>) | @sevs
<br/>
October 27, 2020 | https://www.stackhawk.com/blog/series-a-press-release/ | <a href="https://web.archive.org/web/*/https://www.stackhawk.com/blog/series-a-press-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="795a82f" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>DENVER, CO — Oct 27, 2020 — Application security startup StackHawk announced today that it has raised a $10 million in Series A funding. The pre-emptive, oversubscribed round was led by <a href="https://sapphireventures.com/">Sapphire Ventures</a> and included return seed backers Foundry Group, Costanoa Ventures, Flybridge Capital, and Matchstick Ventures. Launched just over a year ago, StackHawk has seen significant demand as a platform that helps developers implement security testing before applications are pushed into production — a trend in the industry known as “shifting security left.”</p>



<p>With widespread adoption of DevOps over the past decade, companies are shipping software to production more frequently than before, with many companies pushing to production multiple times per day. The traditional models of application security testing such as quarterly penetration tests or scheduled scans of the production application have struggled to keep up with this shift, resulting in inefficiencies and increased risk exposure. Modern companies, however, are integrating application security into their DevOps practices, checking for vulnerabilities early in the software development life cycle. This approach vastly shortens the time to find and fix vulnerabilities, leading to efficient development and secure applications.</p>



<p>StackHawk is an application security testing platform that allows DevOps teams to instrument automated dynamic application security testing (DAST) in the CI/CD pipeline. With this approach, engineering teams can instrument automated testing with every pull request, ensuring that vulnerabilities are caught long before they hit production. And with a strong focus on features for software developers, application security can scale across the engineering organization, creating significant efficiencies in fixing security bugs.</p>



<p>Adrián Moreno Peña, Tech Lead at VanMoof, describes the company’s use of StackHawk, “At VanMoof we work fast and lean, in a DevOps-way of working with empowered teams using smart tools to handle their work. It was about time to find InfoSec tools that fit with our vision — high productivity tools, flexible, adaptable and created with developers in mind. Using StackHawk we can make our security improvement process transparent, actionable and easy to understand for each developer in the team, applying best practices and preventing security issues from going to production.”</p>



<p>The modern approach to application security also resonates with Katie Teitler, industry analyst at TAG Cyber. “Coming early into the development lifecycle is an attractive proposition, both for development lifecycles and for security teams,” said Teitler. “Since the platform is lightweight and quick to deploy through Docker, devs should feel instantly comfortable with it.”</p>



<p>The StackHawk founding team has leveraged their backgrounds in DevOps and security to build the product that puts application security in developer’s hands. Joni Klippert, StackHawk founder &amp; CEO, has spent the past decade building DevOps products, most recently as the VP, Product at VictorOps (acquired by Splunk).&nbsp;</p>



<p>“Digital Transformation has allowed for automation of many tasks associated with building, delivering and operating software in production. DevOps automation enables companies to deliver business value to their customers faster than ever before,” said Klippert. “However, security practices are not keeping up with the speed of modern software delivery. StackHawk empowers software engineers to deliver secure software to their customers at the speed of DevOps.”&nbsp;</p>



<p>The focus on integrating into the modern engineering workflow and building features for developers was a leading factor for Sapphire to lead the round. “With the rise of DevOps, companies have shifted to the frequent release of software and reliance on automation. How companies approach application security should be no different,” says David Hartwig, Managing Director at Sapphire Ventures. “We believe that StackHawk has the product and the team in place, led by Founder and CEO Joni Klippert, to deliver on developer-first automated application security testing in the DevOps pipeline, and we are excited to partner with them along their journey.”</p>



<p>With the additional capital, StackHawk will continue product development, invest in go-to-market teams, and continue to support ZAP, the open source project that the company’s platform is built upon.&nbsp;</p>



<p><strong>About StackHawk</strong><br>StackHawk, an application security SaaS startup in Denver, CO, empowers engineers to easily find and fix application security bugs at any stage of software development. With a strong founding team that has deep experience in security and DevOps, and some of the best venture investors in the business, StackHawk is putting application security testing into the hands of engineers. Learn more and sign up for a free trial at <a href="http://www.stackhawk.com/">www.stackhawk.com</a>.</p>



<p><strong>About Sapphire Ventures</strong><br>Sapphire Ventures is a venture capital firm focused on helping innovative technology companies become global category leaders. Leveraging nearly two decades of experience and an extensive global executive network, Sapphire invests capital, resources and expertise to enable its portfolio companies to scale rapidly through a powerful business development, marketing and talent platform. With more than $4 billion in assets under management across its Sapphire Ventures, Sapphire Partners and Sapphire Sport investment platforms, Sapphire is positioned to elevate companies across technology sectors to the global stage. To learn more about Sapphire Ventures, please see: <a href="https://sapphireventures.com/">https://sapphireventures.com/</a></p>








		</div>
				</div></div>]]>
            </description>
            <link>https://www.stackhawk.com/blog/series-a-press-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908245</guid>
            <pubDate>Tue, 27 Oct 2020 15:20:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive API documentation using Swagger UI deployed with Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908202">thread link</a>) | @sashee
<br/>
October 27, 2020 | https://advancedweb.hu/interactive-api-documentation-using-swagger-ui-deployed-with-terraform/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/interactive-api-documentation-using-swagger-ui-deployed-with-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <h2 id="api-documentation">API documentation</h2> <p>When a backend provides an API how do you provide documentation for people who want to use it? It can be an informal process, using documents that describe the available paths, and how each of them should be called.</p> <p>This can be an ad-hoc list of methods and paths:</p> <ul> <li>GET <code>/user</code> =&gt; List users</li> <li>POST <code>/user</code> =&gt; Create a new user</li> <li>GET <code>/user/&lt;id&gt;</code> =&gt; Return a user by id</li> <li>PUT <code>/user/&lt;id&gt;</code> =&gt; Updates a user</li> <li>DELETE <code>/user/&lt;id&gt;</code> =&gt; Deletes a user</li> </ul> <p>Maybe accompanied by a graphical representation:</p> <p><svg xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="" style="width:312px;height:296px" viewBox="0 0 312 296"><defs><filter height="300%" id="prefix__a" width="300%" x="-1" y="-1"><feGaussianBlur result="blurOut" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blurOut" result="blurOut2" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0"></feColorMatrix><feOffset dx="4" dy="4" in="blurOut2" result="blurOut3"></feOffset><feBlend in="SourceGraphic" in2="blurOut3"></feBlend></filter></defs><path fill="#FEFECE" filter="url(#prefix__a)" d="M64 8H120V44.297H64z" stroke="#A80036" stroke-width="1.5"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="36" x="74" y="30.995">/user</text><ellipse cx="22" cy="120" fill="#FEFECE" filter="url(#prefix__a)" rx="12" ry="12" stroke="#A80036" stroke-width="2.0"></ellipse><path fill="#A80036" d="M18 108L24 103 22 108 24 113 18 108z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="29" x="7.5" y="148.995">GET</text><ellipse cx="92" cy="120" fill="#FEFECE" filter="url(#prefix__a)" rx="12" ry="12" stroke="#A80036" stroke-width="2.0"></ellipse><path fill="#A80036" d="M88 108L94 103 92 108 94 113 88 108z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="38" x="73" y="148.995">POST</text><path fill="#FEFECE" filter="url(#prefix__a)" d="M146.5 110H243.5V146.297H146.5z" stroke="#A80036" stroke-width="1.5"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="77" x="156.5" y="132.995">/user/&lt;id&gt;</text><ellipse cx="128" cy="228" fill="#FEFECE" filter="url(#prefix__a)" rx="12" ry="12" stroke="#A80036" stroke-width="2.0"></ellipse><path fill="#A80036" d="M124 216L130 211 128 216 130 221 124 216z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="29" x="113.5" y="256.995">GET</text><ellipse cx="195" cy="228" fill="#FEFECE" filter="url(#prefix__a)" rx="12" ry="12" stroke="#A80036" stroke-width="2.0"></ellipse><path fill="#A80036" d="M191 216L197 211 195 216 197 221 191 216z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="28" x="181" y="256.995">PUT</text><ellipse cx="273" cy="228" fill="#FEFECE" filter="url(#prefix__a)" rx="12" ry="12" stroke="#A80036" stroke-width="2.0"></ellipse><path fill="#A80036" d="M269 216L275 211 273 216 275 221 269 216z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="54" x="246" y="256.995">DELETE</text><path d="M79.81 44.42c-10.62 15.17-26.19 37.42-38.5 55" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M38.25 103.78L46.698 98.717 41.125 99.689 40.152 94.117 38.25 103.78z" stroke="#A80036" stroke-width="1.0"></path><path d="M92 44.42v54.1" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M92 103.78L96 94.78 92 98.78 88 94.78 92 103.78z" stroke="#A80036" stroke-width="1.0"></path><path d="M109.94 44.42c17.72 17.21 44.84 43.53 63.67 61.82" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M177.26 109.78L173.595 100.638 173.675 106.295 168.018 106.375 177.26 109.78z" stroke="#A80036" stroke-width="1.0"></path><path d="M184.24 146.03c-10.46 16.54-26.51 41.93-38.79 61.36" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M142.73 211.69L150.919 206.218 145.4 207.463 144.155 201.945 142.73 211.69z" stroke="#A80036" stroke-width="1.0"></path><path d="M195 146.03v60.37" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M195 211.69L199 202.69 195 206.69 191 202.69 195 211.69z" stroke="#A80036" stroke-width="1.0"></path><path d="M207.53 146.03c12.17 16.54 30.86 41.93 45.15 61.36" fill="none" stroke="#A80036" stroke-width="1.0"></path><path fill="#A80036" d="M255.85 211.69L253.727 202.073 252.882 207.666 247.289 206.821 255.85 211.69z" stroke="#A80036" stroke-width="1.0"></path><text font-family="sans-serif" font-size="14" lengthAdjust="spacingAndGlyphs" textLength="88" x="115" y="282.995">API structure</text></svg> </p> <p>The problem with this approach is that it’s <em>informal</em>. People can read it and it communicates the intent, but it’s different for every API.</p> <p>OpenAPI (formerly Swagger) is a <strong>standardized format that describes how an API works</strong>. It captures the important parts of the documentation and defines a structure for it:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>get</span><span>:</span>
      <span># ...</span>
    <span>post</span><span>:</span>
      <span># ...</span>
      <span>requestBody</span><span>:</span>
        <span># ...</span>
  <span>'</span><span>/user/{userid}'</span><span>:</span>
    <span>parameters</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>userid</span>
      <span>in</span><span>:</span> <span>path</span>
      <span>required</span><span>:</span> <span>true</span>
      <span>schema</span><span>:</span>
        <span>type</span><span>:</span> <span>string</span>
    <span>delete</span><span>:</span>
      <span># ...</span>
</code></pre></div></div> <p>The advantage of a standard format is that general-purpose tools can process it. One such tool is <a href="https://swagger.io/tools/swagger-ui/">Swagger UI</a> which provides <strong>interactive documentation</strong> for the API and allows easy experimentation in a familiar format.</p> <p>It provides a list of methods, so it’s easy to get an overview of how the API is structured:</p> <p><img alt="Swagger UI lists the available methods" integrity="sha256-iSVYciDpAz9zVxlnfTJLvhOZHro35bjx4BeaVJ98yp0=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/methods-8925587220e9033f735719677d324bbe13991eba37e5b8f1e0179a549f7cca9d.png"></p> <p>It also allows calling the methods, even with a request body:</p> <p><img alt="Send a POST with a request body" integrity="sha256-U1zQShkw479Cub/kAbcK+VE5rfv+5ByyZ3RZqcYr9Fo=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/create-535cd04a1930e3bf42b9bfe401b70af95139adfbfee41cb2677459a9c62bf45a.png"></p> <p>Generates copy-pastable Curl examples for the requests along with the response:</p> <p><img alt="Swagger UI shows the response and a Curl example" integrity="sha256-MpF9tEDrUNMFxHaB4q3+1u4jeoRcvM0xPPcWfsFRh2o=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/post_response-32917db440eb50d305c47681e2adfed6ee237a845cbccd313cf7167ec151876a.png"></p> <p>And supports path parameters too:</p> <p><img alt="Swagger UI supports path parameters too" integrity="sha256-MJc8mKSFe4VzQw9W9piheZMSEekwibU5lvw1PunTxY0=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/delete-30973c98a4857b8573430f56f698a179931211e93089b53996fc353ee9d3c58d.png"></p> <p>This provides developers an easy way to try out the API without first reading the informal documentation and figuring out how each part works.</p> <p>Let’s see how to deploy a live API with Swagger UI using Terraform!</p> <p> Learn the services needed to build a serverless HTTP-based API on AWS from our <a href="#" data-toggle="modal" data-target="#contextual-promo-popup">free email course</a> . </p> <h2 id="swagger-ui-webpage">Swagger UI webpage</h2> <p>The Swagger UI runs entirely on the client-side. It requires 2 Javascript and 1 CSS files, along with the API documentation YAML (or JSON). The frontend dependencies can be hosted along with the <code>index.html</code> or they can be referenced from a CDN. The latter provides an easier setup as the whole thing will be one file (the <code>index.html</code>) and using <a href="https://advancedweb.hu/frontend-dependencies-without-tools/#subresource-integrity">SRI</a> (Subresource Integrity) makes sure they are intact.</p><div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/frontend-dependencies-without-tools/#subresource-integrity"> <img integrity="sha256-hMT9HgeA64ZAZcsbEcPBVX2gfkdyHe+WxFvZ6U1SZOY=" crossorigin="anonymous" src="https://advancedweb.hu/assets/bdf95b-74013c7eab0f9d77240d5505f80e83c6acf639e251aebd340c58093bb023b861.png"> </a> </p> <div>  <p> A guide about front-end dependencies, part I: we'll look into the two simplest methods, those that do not rely on any tools </p> </div> </div> </div> <p>Here are the files needed:</p> <p><img alt="Bucket list with index.html and api.yaml" integrity="sha256-9GvuliM4YIkA+OV2PbOtg2QFJqTTDNRbXcFJ02pTAtg=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/docs_bucket-f46bee962338608900f8e5763db3ad83640526a4d30cd45b5dc149d36a5302d8.png"></p> <p>The <code>index.html</code> loads the <code>swagger-ui-standalone-preset</code>, the <code>swagger-ui-bundle</code>, and the <code>swagger-ui.css</code> from <a href="https://cdnjs.com/libraries/swagger-ui">cdnjs</a>. It’s a good practice to check for new versions and update them from time to time.</p> <div><div><pre><code><span>&lt;head&gt;</span>
	<span>&lt;script
		</span><span>src=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.35.0/swagger-ui-standalone-preset.min.js"</span>
		<span>integrity=</span><span>"sha512-WI88XrK/8xukiZdnlwlGrcdIyD9qgNXL15LiWbVnq0qpgd/YzRiewFplb5VyRxsbwZf7wRU5BnkCeNP/OV5CEg=="</span>
		<span>crossorigin=</span><span>"anonymous"</span><span>&gt;&lt;/script&gt;</span>
	<span>&lt;script
		</span><span>src=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.35.0/swagger-ui-bundle.min.js"</span>
		<span>integrity=</span><span>"sha512-7aNGLo3pjgERnsRoSSRrr8Xy6lX8QeKJG3sh8qAeKDvRCExTvDxG6IPRNrCoY0EZG9B5BzGWV5l0xK9DqSSu+w=="</span>
		<span>crossorigin=</span><span>"anonymous"</span><span>&gt;&lt;/script&gt;</span>
	<span>&lt;link</span>
		<span>rel=</span><span>"stylesheet"</span>
		<span>href=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.35.0/swagger-ui.min.css"</span>
		<span>integrity=</span><span>"sha512-jsql70MmFqKJfWGCXmi3GHPP2q2oi3Ad+6PRQWNeo6df+rxKB07IuBvcCXSrpgKPXaikkQgEQVO2YrtgmSJhUw=="</span>
		<span>crossorigin=</span><span>"anonymous"</span> <span>/&gt;</span>
<span>&lt;/head&gt;</span>
<span>&lt;body&gt;</span>
	<span>&lt;div</span> <span>id=</span><span>"main"</span><span>&gt;&lt;/div&gt;</span>
<span>&lt;/body&gt;</span>
</code></pre></div></div> <p>To initialize the UI call the <code>SwaggerUIBundle</code> function, passing it the <code>url</code> of the API documentation file and a DOM element.</p> <div><div><pre><code><span>window</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>DOMContentLoaded</span><span>"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> <span>ui</span> <span>=</span> <span>SwaggerUIBundle</span><span>({</span>
		<span>url</span><span>:</span> <span>"</span><span>api.yaml</span><span>"</span><span>,</span>
		<span>dom_id</span><span>:</span> <span>"</span><span>#main</span><span>"</span><span>,</span>
		<span>presets</span><span>:</span> <span>[</span>
			<span>SwaggerUIBundle</span><span>.</span><span>presets</span><span>.</span><span>apis</span><span>,</span>
			<span>SwaggerUIStandalonePreset</span>
		<span>],</span>
		<span>layout</span><span>:</span> <span>"</span><span>StandaloneLayout</span><span>"</span><span>,</span>
	<span>});</span>
<span>});</span>
</code></pre></div></div> <h2 id="bucket-configuration">Bucket configuration</h2> <p>Since the Swagger UI and the API documentation YAML are static files, any web hosting works for them. The simplest is to put them into an S3 bucket and enable the bucket website endpoint.</p> <div><div><pre><code><span>resource</span> <span>"aws_s3_bucket"</span> <span>"bucket"</span> <span>{</span>
  <span>force_destroy</span> <span>=</span> <span>"true"</span>
	<span>website</span> <span>{</span>
		<span>index_document</span> <span>=</span> <span>"index.html"</span>
	<span>}</span>
<span>}</span>

<span>resource</span> <span>"aws_s3_bucket_policy"</span> <span>"bucket_policy"</span> <span>{</span>
  <span>bucket</span> <span>=</span> <span>aws_s3_bucket</span><span>.</span><span>bucket</span><span>.</span><span>id</span>

  <span>policy</span> <span>=</span> <span>&lt;&lt;</span><span>POLICY</span><span>
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "${aws_s3_bucket.bucket.arn}/*"
    }
  ]
}
</span><span>POLICY
</span><span>}</span>
</code></pre></div></div> <p>The above configuration creates a bucket, enables the website endpoint, then attaches a bucket policy to allow anonymous access (<code>"Principal": "*"</code>). This gives a URL in the form of <code>http://&lt;bucket&gt;.s3-website.&lt;region&gt;.amazonaws.com</code>.</p> <p>Notice that it uses unencrypted HTTP and S3 does not support HTTPS. If you want to expose the API documentation via HTTPS (which you should), use CloudFront in front of S3.</p>  <h3 id="dynamic-server-url">Dynamic server URL</h3> <p>How does Swagger UI know <em>where is the API</em>? It is in the YAML file, in the <code>servers</code> section.</p> <p>But when, for example, the same API is managed by Terraform and the URL is different for every deployed stack, it needs to be set dynamically.</p> <p>Terraform supports the <code>templatefile</code> function that allows defining values and inserts them into the document:</p> <div><div><pre><code><span>resource</span> <span>"aws_apigatewayv2_api"</span> <span>"api"</span> <span>{</span>
	<span># ...</span>
<span>}</span>

<span>resource</span> <span>"aws_s3_bucket_object"</span> <span>"api_object"</span> <span>{</span>
	<span># ...</span>
	<span>content</span> <span>=</span> <span>templatefile</span><span>(</span><span>"api.yml"</span><span>,</span> <span>{</span><span>api_url</span> <span>=</span> <span>aws_apigatewayv2_api</span><span>.</span><span>api</span><span>.</span><span>api_endpoint</span><span>})</span>
<span>}</span>
</code></pre></div></div> <p>In the OpenAPI YAML, use the placeholder for the server URL:</p> <div><div><pre><code><span>servers</span><span>:</span>
<span>-</span> <span>url</span><span>:</span> <span>${api_url}</span>
</code></pre></div></div> <p>When it is deployed, the YAML contains the URL of the API Gateway:</p> <p><img alt="Swagger UI shows the dynamic server URL" integrity="sha256-Qo8nJxaZuK4YVZqQE5DeN09T4UGagEqK3E7rMj7zQzM=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/api_docs_terraform/api-428f27271699b8ae18559a901390de374f53e1419a804a8adc4eeb323ef34333.png"></p> <h3 id="files">Files</h3> <p>To put files into a bucket, use the <code>aws_s3_bucket_object</code> resource. The <code>index.html</code> has a <code>text/html</code> content type, so that the browser shows it as a webpage. Then the API document is templated with the API Gateway URL.</p> <div><div><pre><code><span>resource</span> <span>"aws_s3_bucket_object"</span> <span>"object"</span> <span>{</span>
  <span>key</span>    <span>=</span> <span>"index.html"</span>
  <span>content</span> <span>=</span> <span>file</span><span>(</span><span>"index.html"</span><span>)</span>
  <span>bucket</span> <span>=</span> <span>aws_s3_bucket</span><span>.</span><span>bucket</span><span>.</span><span>bucket</span>
	<span>content_type</span> <span>=</span> <span>"text/html"</span>
<span>}</span>

<span>resource</span> <span>"aws_s3_bucket_object"</span> <span>"api_object"</span> <span>{</span>
  <span>key</span>    <span>=</span> <span>"api.yaml"</span>
  <span>content</span> <span>=</span> <span>templatefile</span><span>(</span><span>"api.yml"</span><span>,</span> <span>{</span><span>api_url</span> <span>=</span> <span>aws_apigatewayv2_api</span><span>.</span><span>api</span><span>.</span><span>api_endpoint</span><span>})</span>
  <span>bucket</span> <span>=</span> <span>aws_s3_bucket</span><span>.</span><span>bucket</span><span>.</span><span>bucket</span>
<span>}</span>
</code></pre></div></div> <h3 id="output">Output</h3> <p>To export the URL of the Swagger UI, use an output with the <code>website_endpoint</code> attribute of the bucket:</p> <div><div><pre><code><span>output</span> <span>"url"</span> <span>{</span>
  <span>value</span> <span>=</span> <span>aws_s3_bucket</span><span>.</span><span>bucket</span><span>.</span><span>website_endpoint</span>
<span>}</span>
</code></pre></div></div> <h2 id="cors-configuration">CORS configuration</h2> <p>The above setup hosts the Swagger UI in a different domain than the API itself, which means CORS (Cross-Origin Resource Sharing).</p> <p>If you use an API Gateway HTTP API then it supports the <code>cors_configuration</code> block where you can define the CORS-related headers:</p> <div><div><pre><code><span>resource</span> <span>"aws_apigatewayv2_api"</span> <span>"api"</span> <span>{</span>
  <span># ...</span>
	<span>cors_configuration</span> <span>{</span>
		<span>allow_origins</span> <span>=</span> <span>[</span><span>"*"</span><span>]</span>
		<span>allow_methods</span> <span>=</span> <span>[</span><span>"GET"</span><span>,</span> <span>"POST"</span><span>,</span> <span>"PUT"</span><span>,</span> <span>"DELETE"</span><span>]</span>
		<span>allow_headers</span> <span>=</span> <span>[</span><span>"Content-Type"</span><span>]</span>
	<span>}</span>
<span>}</span>
</code></pre></div></div> <p>Some calls require a preflight request that is an OPTIONS and the browser requires it to have a success status code. Make sure to return a 200 response from the API:</p> <div><div><pre><code><span>if</span> <span>(</span><span>method</span> <span>===</span> <span>"</span><span>OPTIONS</span><span>"</span><span>)</span> <span>{</span>
	<span>return</span> <span>{</span>
		<span>statusCode</span><span>:</span> <span>200</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div> <p>Another solution is to host the Swagger UI on the same domain as the API. This can mean that the API returns the <code>index.html</code> and the API YAML files, or you can use CloudFront to bring everything under one domain.</p> <div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/how-cloudfront-solves-cors-problems/"> <img integrity="sha256-GvQ1G6uaZs6V9ipAqpvLYAcYG0VSYa5LrTd4oJE6Xqo=" crossorigin="anonymous" src="https://advancedweb.hu/assets/14080f-b305df7213cbec0c9b6f45dce255ff509b6ed3a9a17ee8b2d5d603bcf96b55c8.jpg"> </a> </p> <div>  <p> One domain means easier configuration and better security </p> </div> </div> </div> <h2 id="conclusion">Conclusion</h2> <p>OpenAPI provides a standard for API documentation and tools are available to process it. Swagger UI is a project that turns the API definition into an interactive documentation page where developers can get familiar with the API quickly and can experiment with it.</p> <p>When Terraform manages the API it needs to wire the API URL and the documentation together and expose the website for the browser. Using an S3 bucket website and the <code>templatefile</code> function it is possible to manage the API endpoint and its documentation together.</p> </div></div>]]>
            </description>
            <link>https://advancedweb.hu/interactive-api-documentation-using-swagger-ui-deployed-with-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908202</guid>
            <pubDate>Tue, 27 Oct 2020 15:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Unity Engine Objects (Unity for Engineers #5)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907975">thread link</a>) | @Eyas
<br/>
October 27, 2020 | https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We already discussed
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#gameobject">Game Objects</a> and
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#component">Components</a> as two
of the fundamental building blocks of the Unity Engine. Today, we’ll discuss
their programmatic representation.</p><p><em>This is <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>,
a series for folks familiar with software development best practices seeking an
accelerated introduction to Unity as an engine and editor. More is coming over
the next few weeks, so <a href="http://eepurl.com/gVgusL">consider subscribing</a> for
updates.</em></p><p>The Unity Engine <em>runtime</em> is primarily written in C++, and much of the Engine’s
primitives (such as the game objects and their components) live in C++ land.
You’ll also know that the Unity Engine <em>API</em> is in C#. The API gives you access
to all of Unity’s native objects in a way that<!-- -->—<!-- -->save for a few pitfalls
we’ll discuss today<!-- -->—<!-- -->feels like intuitive, idiomatic C#.</p><figure><p><img src="https://blog.eyas.sh/e1e4978ec3c78301c0c6b929c61f8bf7/object-hierarchy.svg" alt="A GameObject, MonoBehaviour, and ScriptableObject all inherit from UnityEngine Object."></p><figcaption><p>The <em>C#</em> class hierarchy of <code>UnityEngine.Object</code>, <code>GameObject</code>,
<code>ScriptableObject</code>, <code>Component</code>, and their children. This should map to the
<em>conceptual</em> hierarchy of how to think about these objects, though sometimes the
runtime implementation will look different.</p></figcaption></figure><h2 id="unityobject">UnityEngine.Object</h2><p>At the top of the Unity Object hierarchy sits <strong><code>UnityEngine.Object</code></strong>. For the
most part provides a <code>name</code> string, an <code>int GetInstanceID()</code> method, and a bunch
of equality comparers.</p><p>The class also provides a <code>static void Destroy(Object obj)</code> method (and some
overloads) that destroys a <code>UnityEngine.Object</code> and any of its subclasses. When
an Object is destroyed, the <em>native</em> part of the object is freed from memory,
and the smaller <em>managed</em> part will be garbage collected <em>at some point</em> after
there are no more references to it.</p><p>Because your valid reference to a <code>UnityEngine.Object</code> can point to a destroyed
native object, <code>UnityEngine.Object</code> overrides C#‘s <code>operator==</code> and <code>operator!=</code>
to make a destroyed Object <em>appear</em> null. Simply accessing methods on a
destroyed object will return <code>NullReferenceException</code>, albeit with a friendlier
error message that tells you which object you were trying to access.</p><h2 id="gameobject">GameObject</h2><p>A <strong>GameObject</strong> derives from Object and represents anything in your scene.</p><p>Let’s start at a high-level: A GameObject inherits a name and instance ID from
its parent. Otherwise, conceptually, a GameObject</p><ul><li>has a list of <a href="#component"><strong>Components</strong></a> on it,</li><li>has a <code>tag</code> string for organizational purposes, and</li><li>belongs to a <a href="https://docs.unity3d.com/Manual/Layers.html">layer</a>.</li></ul><p>A GameObject’s state</p><ul><li>is the product of all of its <em>Components’</em> state, and</li><li>whether an object is active or not.</li></ul><p>Let’s dig a bit deeper. When starting, most of the interesting stuff in a
GameObject is in its <strong>Components</strong>. A GameObject has at least one Component:
its <a href="https://docs.unity3d.com/ScriptReference/Transform.html"><code>Transform</code></a>. A
Transform describes the position and rotation of the GameObject. A Transform
includes helper properties that show an object’s <em>absolute world</em> position and
rotation, as well as the position and rotation <em>relative</em> to its parent. In the
Editor, the Transform position and rotation are set from the <em>parent relative</em>
variants.</p><p>Since every GameObject has a Transform (and also, given that a Transform is
frequently needed/accessed), the GameObject directly exposes a
<code>Transform transform</code> public property.</p><p>You can access individual components from <code>T GetComponent&lt;T&gt;()</code>, or lists of
components from <code>T[] GetComponents&lt;T&gt;()</code>, etc. These methods search through all
components on a GameObject and return ones with a compatible type (or null, if
none exist in the singular case). Since these methods search through components
and check type compatibility, it is often recommended to cache this lookup.</p><p>If you are building/extending a GameObject by hand, you can always use
<code>T AddComponent&lt;T&gt;()</code>. In most cases, however, you’re better off using the
Editor.</p><p>Individual Objects (a Component or ScriptableObject) might refer to other
<code>GameObjects</code> in a few ways:</p><ul><li><p><strong>By reference</strong>. By exposing a <code>GameObject</code> <em>serialized field</em> that you
then set from the inspector.</p><p><em>We have discussed serialization extensively throughout the series:
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#serialization">as a fundamental concept</a>
and in our tour of the Editor, when
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt4-editor-tour#inspector">describing the Inspector</a>,
and the <a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices">practice</a> of using
the Inspector as an injection framework</em>.</p></li><li><p><strong>Using tags</strong>. Every Game Object can have a <em>tag</em> string. You can find
objects in the scene using that tag through the static functions
<code>GameObject.FindGameObjectsWithTag</code> and <code>GameObject.FindGameObjectWithTag</code>.
A GameObject also exposes a public <code>bool CompareTag(string tag)</code> method.</p><p>This is a quick-and-dirty way to get the job done, but is still a popular
way. A common use of this in the wild is to have a <code>"Player"</code> tag to find
the Player. Ideally, these methods should not be called every frame, so if
you have to use them, consider caching the result.</p></li><li><p><strong>Using layers</strong>. A layer is an <code>int</code> between 0 and 31. Every Game Object is
in exactly one layer.</p><p>While you can’t directly look up all objects in a layer, if you already have
a reference to a GameObject (e.g., in a collision event), you can check a
GameObject against a
<a href="https://docs.unity3d.com/ScriptReference/LayerMask.html"><code>LayerMask</code></a>. A
<code>LayerMask</code> is typically used in functions like <code>Physics.Raycast()</code>. This
allows you to find objects with colliders intersecting with a given <em>ray</em>.
Passing a <code>LayerMask</code> to <code>Physics.Raycast()</code> will only return objects within
the specified set of layers.</p><p>Inside the Unity Engine, <em>Cameras</em> make heavy use of layers. E.g., you can
have one camera that renders “everything but UI”, and overlay another camera
for an in-game HUD, etc.</p></li><li><p><strong>Using indirect references</strong>. There are many reasons why the methods above
might be insufficient: you might not want to use tags to avoid depending on
copy-pasted strings, and layers might not fit your use case. If referencing
a fellow object in-scene is not an option (e.g., you’re dealing with a
dynamic set of objects or don’t have access to the current scene objects in
the context you need this reference, etc.), then you might want to look
further.</p><p>For this, an increasingly popular concept is <em>runtime sets</em> Scriptable
Objects. You can read more about this in Unity’s how-to article on
<a href="https://unity.com/how-to/architect-game-code-scriptable-objects">architecting your game with ScriptableObjects</a>,
based on <a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">the talk</a> by Ryan
Hipple. If you have an hour to spare, you might want to watch the whole
thing.</p></li></ul><p>A GameObject also exposes a <code>BroadcastMessage</code> and <code>SendMessage</code> functions that
propagate <em>messages</em> (described in the <a href="#component"><strong>Component</strong></a> section) to
all components in or under it.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/58ad8/ramin-khatibi-unsplash-bottom.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/28a80/ramin-khatibi-unsplash-bottom.webp 400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/8d2ea/ramin-khatibi-unsplash-bottom.webp 800w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/43d96/ramin-khatibi-unsplash-bottom.webp 1600w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/4293a/ramin-khatibi-unsplash-bottom.webp 2400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/88d9d/ramin-khatibi-unsplash-bottom.webp 3024w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/4cda9/ramin-khatibi-unsplash-bottom.jpg 400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/c60e9/ramin-khatibi-unsplash-bottom.jpg 800w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/56dca/ramin-khatibi-unsplash-bottom.jpg 1600w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/111a0/ramin-khatibi-unsplash-bottom.jpg 2400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/58ad8/ramin-khatibi-unsplash-bottom.jpg 3024w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
        <img src="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/56dca/ramin-khatibi-unsplash-bottom.jpg" alt="Photo of a Building Structure" title="Photo of a Building Structure" loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>Photo by <a href="https://unsplash.com/@raminix">Ramin Khatibi</a> via Unsplash.</p></figcaption></figure><h2 id="component">Component</h2><p>Every behavior on a GameObject is driven through its Components.
User-implemented Components will usually extend the <code>MonoBehaviour</code> subclass
(more on that later).</p><p>A Component inherits a name and instance ID from its parent. Otherwise,
conceptually, a Component</p><ul><li>always <em>belongs</em> to a single GameObject, exposed as a public
<code>GameObject gameObject</code> property, and</li><li>can receive <strong>messages</strong>, driving much of its behavior.</li></ul><p>The state of a component on an <em>active</em> GameObject lies entirely in its
implementation.</p><p>In addition to its <code>GameObject</code>, a component exposes shorthand properties and
methods such as <code>Transform transform</code>, <code>T GetComponent&lt;T&gt;()</code>, etc. These are
simply convenience shorthands for accessing those same methods on the
corresponding <code>gameObject</code>.</p><p>The most important functionality of a Component is driven through <strong>Unity
Messages</strong> (also sometimes called <em>Unity Event Functions</em> when referring to
built-in messages). These are effectively callbacks functions triggered <em>by the
Engine</em> in certain situations. Every Component will receive a <code>Awake()</code>,
<code>Start()</code>, <code>Update()</code> and other messages, for example. The Unity Docs on the
<a href="https://docs.unity3d.com/Manual/ExecutionOrder.html">Order of Execution</a> of
these messages is a convenient resource.</p><p>To have your component receive a particular message, simply add a
<em><code>private void</code></em> method with the appropriate message name. The runtime will use
reflection to call these messages, when applicable. This is why you don’t see an
<code>override</code> directive on these messages. Messages like <code>Update</code>, <code>LateUpdate</code>,
and <code>FixedUpdate</code> are inspected once per type, so don’t worry about reflection
being used in every frame. See more details in the
”<a href="https://blogs.unity3d.com/2015/12/23/1k-update-calls/">10000 Update() calls</a>”
Unity blog post for more information.</p><p>A <strong><code>Behaviour</code></strong> is a type of component that <em>can be enabled or disabled</em>. When
a <code>Behaviour</code> is disabled, <code>Start</code>, <code>Update</code>, <code>FixedUpdate</code>, <code>LateUpdate</code>,
<code>OnEnable</code>, and <code>OnDisable</code> messages are not called.</p><p>A <strong><code>MonoBehaviour</code></strong> is a <code>Behaviour</code> that also enables using
<a href="https://docs.unity3d.com/Manual/Coroutines.html">Coroutines</a>.</p><h2>A Note on Inactive Objects and Disabled Components</h2><p>A GameObject in a loaded scene will exist in memory until the object is
<em>Destroyed</em> explicitly or the scene is unloaded. A GameObject can be set to
<em>inactive</em>, which will cause it to stop receiving <code>Update</code> (and related) events.</p><p><strong>When an object is <em>created</em></strong>, the messages called on a component depend on
if: (1) the GameObject is active, and (2) the component is enabled:</p><table><thead><tr><th></th><th>GameObject is <em>active</em></th><th>GameObject is <em>inactive</em></th></tr></thead><tbody><tr><td>Component is Enabled</td><td><code>Awake</code>, <code>OnEnable</code>, <code>Start</code></td><td><em>Component implicitly disabled</em></td></tr><tr><td>Component is Disabled</td><td><code>Awake</code></td><td><code>Awake</code></td></tr></tbody></table><p><strong>When an object is <em>set to active</em> or a <code>Behaviour</code> is <em>set to enabled</em></strong>:</p><ul><li><code>OnEnable</code> will be called.</li><li>If <code>Start</code> has never been called on this <code>Behaviour</code>, it will be called
exactly once.</li></ul><h2 id="takeaways">Takeaways</h2><p>Some takeaways of all this:</p><ol><li>A Unity object might <em>appear to become <code>null</code></em> when destroyed. <code>== null</code>
checking does more than you think.</li><li>As a result, null-coalescing operators (<code>??</code>, <code>??=</code>) and null-conditional
operators (<code>?.</code>, <code>?[]</code>) don’t work as expected.</li><li>Yes, your Unity Messages can be private!</li><li>Don’t create abstract classes that unnecessarily declare <code>Update</code> or other
messages to make overriding easier; that’ll result in the engine always
calling these events.</li><li>Disabling an Object or Component is a great way to limit its game logic or
save on CPU-bound effort, but these objects still have a memory overhead.</li></ol></div></div>]]>
            </description>
            <link>https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907975</guid>
            <pubDate>Tue, 27 Oct 2020 14:52:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Photoshop with Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907717">thread link</a>) | @kelvin0
<br/>
October 27, 2020 | https://kelvin0.github.io/ImageAutomation/ | <a href="https://web.archive.org/web/*/https://kelvin0.github.io/ImageAutomation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        
<p>This is a brief blog post describing my experience with automating Photoshop using Python.
I am an experienced software developer, but had never really used Photoshop before. As you can tell from my wonderful programmer art in this post ;)</p>

<p>Here’s the <a href="https://www.adobe.com/content/dam/acom/en/devnet/photoshop/pdfs/photoshop-cc-vbs-ref.pdf">Adobe documentation</a> my work was based on.</p>

<p>Here’s a link to <a href="https://github.com/loonghao/photoshop-python-api">another project</a> that could also be of interest. <strong>I have not used their code,</strong> but it looks very promising.</p>

<p>The sample code and repo source code have been <strong>tested on Python 2.7</strong>, but should work fine on Python 3.
<a href="https://github.com/kelvin0/ImageAutomation">Source code</a></p>

<h2 id="generating-images">Generating images</h2>
<p>Some time ago we needed a solution to be able to quickly generate some product images using Photoshop.</p>

<p>The graphic designer wanted to combine 2 images into a final product image to be used for display their products online.</p>
<ul>
  <li>An environment image (PSD file).</li>
  <li>An object image (jpg).</li>
  <li>Combine the above images into a product image (jpg).</li>
</ul>

<p>This was done manually in Photoshop and as expected was very time consuming and error prone.</p>

<p>The scenario described for generating an image might seem very simple, <strong>why use Photoshop at all, right?</strong> PIL, Skimage, OpenCV would work fine! Well in this case, there were some very fine transformations and image processing being done in Photoshop and the graphic designer needed all these features required in order to generate high-quality images using filter, shears and other exotic (for me at least) visual effects.</p>

<p><img src="https://github.com/kelvin0/ImageAutomation/blob/gh-pages/Combine_2_images.png?raw=true" alt="Combination of 2 images"></p>

<h2 id="smart-objects">Smart objects?</h2>
<p>Prior to my involvement, the graphic designer had been looking for a way to simplify and automate this image generation process.
An important feature that would be key to this work is the concept of <a href="https://helpx.adobe.com/ca/photoshop/using/create-smart-objects.html">Smart Objects</a></p>

<p><strong>Smart objects</strong> in Photoshop allow you to ‘link’ 2 or more PSD files. Any changes made to the linked PSD are automatically made to any PSD linking to it!
Basically you create a PSD file, and have one of the layers be a Smart Object. Then you link that Smart Object layer to another PSD.
Afterwards when you open the background image and the product image in Photoshop, <strong>any changes you make to the product image, also are made in the background image</strong>.</p>

<p>Another cool thing about Smart Objects: <strong>all the transformations within the Smart Object layer are preserved</strong>, regardless of the changes you make to the source PSD.</p>

<p><img src="https://github.com/kelvin0/ImageAutomation/blob/gh-pages/smart_objects_update.png?raw=true" alt="Smart Objects workflow"></p>

<p><strong>This requires:</strong></p>
<ul>
  <li>Each background image (PSD) must contain a layer with a Smart Object.</li>
  <li>The Smart Object layer has  to be linked to a default image (PSD).</li>
  <li>Works best if both PSD files reside in same directory.</li>
</ul>

<p><strong>The manual steps for generating a final product image becomes:</strong></p>
<ol>
  <li>Open the background image in Photoshop (mountains).</li>
  <li>Open the default product image in Photoshop (ball).</li>
  <li>Open the desired product image in Photoshop (star).</li>
  <li>Copy the desired product image into the default product image. This updates the Smart Object.</li>
  <li>Save the background image as JPEG. This is our final image we want to generate with mountains and the star.</li>
  <li>Repeat this for every background/product combination image we want to generate.</li>
</ol>

<h2 id="python-and-com">Python and COM</h2>
<p>As mentionned at the beginning, we will be using the Photoshop COM programming interface.
The <a href="https://www.adobe.com/content/dam/acom/en/devnet/photoshop/pdfs/photoshop-cc-vbs-ref.pdf">Photoshop reference PDF</a> will be our guide in writing our automation scripts. Of course we could be doing this directly in VB script, but it is much more fun (and productive!) to use Python.</p>

<p>Here’s a basic sample that opens an image in Photoshop.</p>

<div><div><pre><code><span>import</span> <span>win32com.client</span>

<span># This actually fires up Photoshop if not already running.
</span><span>ps</span> <span>=</span> <span>win32com</span><span>.</span><span>client</span><span>.</span><span>Dispatch</span><span>(</span><span>"Photoshop.Application"</span><span>)</span>

<span># Open an image file (PSD in our case)
</span><span>doc</span> <span>=</span> <span>ps</span><span>.</span><span>Open</span><span>(</span><span>r"X:\Path\To\My.psd"</span><span>)</span>
<span># ... do something ...
</span><span>doc</span><span>.</span><span>Close</span><span>()</span>

<span>ps</span><span>.</span><span>Quit</span><span>()</span> <span># Stops the Photoshop application
</span></code></pre></div></div>
<p>This works on Windows, but some other scripting language might be more appropriate for Mac OS.
We will not be covering other platforms.</p>

<p><strong>There is no headless mode when running Python/COM automation scripts.</strong></p>

<p>Each script command actually translates to an action you see happen on the screen.
I will get into this and other annoyances later.</p>

<h2 id="basic-recipe">Basic Recipe</h2>

<p>Here is some basic sample code that illustrates the automated steps to generate our final product image, which is a star on a background of mountains.</p>

<p>Notice also that we duplicate the PSD documents once we open them. We do this in order not to accidentally change and save the original PSD files.</p>

<p><strong>Important:</strong> working with Photoshop’s object containers is different than native Python lists and tuples. The indices are <strong>1-based</strong>, so the first element of container has index=1 (as opposed to index=0 as per usual).</p>

<h3 id="basic_recipepy">basic_recipe.py</h3>
<hr>
<div><div><pre><code><span>import</span> <span>os</span>
<span>import</span> <span>win32com.client</span>

<span>SILENT_CLOSE</span> <span>=</span> <span>2</span>

<span>curdir</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>abspath</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>dirname</span><span>(</span><span>__file__</span><span>))</span>
<span>background_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"background.psd"</span><span>)</span>
<span>ball_base_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"C base.psd"</span><span>)</span>
<span>star_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"star.jpg"</span><span>)</span>
<span>gen_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"final.jpg"</span><span>)</span>

<span># This actually fires up Photoshop if not already running.
</span><span>ps</span> <span>=</span> <span>win32com</span><span>.</span><span>client</span><span>.</span><span>Dispatch</span><span>(</span><span>"Photoshop.Application"</span><span>)</span>
<span>ps</span><span>.</span><span>DisplayDialogs</span> <span>=</span> <span>3</span>            <span># psDisplayNoDialogs
</span><span>ps</span><span>.</span><span>Preferences</span><span>.</span><span>RulerUnits</span> <span>=</span> <span>1</span>    <span># psPixels
</span>
<span>"""1. Open the background image in Photoshop (mountains)."""</span>
<span>bg</span> <span>=</span> <span>ps</span><span>.</span><span>Open</span><span>(</span><span>background_path</span><span>)</span>
<span>background</span> <span>=</span> <span>bg</span><span>.</span><span>Duplicate</span><span>()</span> <span># Work with a clone
</span><span>bg</span><span>.</span><span>Close</span><span>(</span><span>SILENT_CLOSE</span><span>)</span>

<span>"""2. Open the default product image in Photoshop (ball)."""</span>
<span>ball</span> <span>=</span> <span>ps</span><span>.</span><span>Open</span><span>(</span><span>ball_base_path</span><span>)</span>
<span>ball_layer</span> <span>=</span> <span>ball</span><span>.</span><span>ArtLayers</span><span>.</span><span>Item</span><span>(</span><span>1</span><span>)</span>

<span>"""3. Open the desired product image in Photoshop (star)."""</span>
<span>target</span> <span>=</span> <span>ps</span><span>.</span><span>Open</span><span>(</span><span>star_path</span><span>)</span>
<span>star</span> <span>=</span> <span>target</span><span>.</span><span>Duplicate</span><span>()</span>
<span>target</span><span>.</span><span>Close</span><span>(</span><span>SILENT_CLOSE</span><span>)</span>
							  
<span>"""4. Copy the desired product image into the default product image. 
This also updates our background image."""</span>
<span># Place copy of desired product image on clipboard
</span><span>star_layer</span> <span>=</span> <span>star</span><span>.</span><span>ArtLayers</span><span>.</span><span>Item</span><span>(</span><span>1</span><span>)</span>
<span>star_layer</span><span>.</span><span>Copy</span><span>()</span> 
<span>star</span><span>.</span><span>Close</span><span>(</span><span>SILENT_CLOSE</span><span>)</span>

<span># Set as active image in Photoshop
</span><span>ps</span><span>.</span><span>ActiveDocument</span> <span>=</span> <span>ball</span>          

<span># Paste 'star' image from clipboard 
</span><span>pasted</span> <span>=</span> <span>ball</span><span>.</span><span>Paste</span><span>()</span>

<span># We apply new image to smart object layer. 
</span><span>ball</span><span>.</span><span>Save</span><span>()</span>                               

<span>"""5. This is our final image we want to generate with mountains and the star."""</span>
<span>jpgSaveOptions</span> <span>=</span> <span>win32com</span><span>.</span><span>client</span><span>.</span><span>Dispatch</span><span>(</span> <span>"Photoshop.JPEGSaveOptions"</span> <span>)</span>
<span>ps</span><span>.</span><span>ActiveDocument</span> <span>=</span> <span>background</span>
<span>background</span><span>.</span><span>SaveAs</span><span>(</span><span>gen_path</span><span>,</span> <span>jpgSaveOptions</span><span>,</span> <span>True</span><span>,</span> <span>2</span><span>)</span>

<span>background</span><span>.</span><span>Close</span><span>(</span><span>SILENT_CLOSE</span><span>)</span>
<span>ball</span><span>.</span><span>Close</span><span>(</span><span>SILENT_CLOSE</span><span>)</span>

<span>ps</span><span>.</span><span>Quit</span><span>()</span> <span># Stops the Photoshop application
</span></code></pre></div></div>

<h2 id="a-step-further">A step further</h2>
<p>In order to make this a little less painful to use, we created a psd_utils.py source file.
This file contains contains the <strong>Photoshop class</strong> to alleviate some of the boilerplate code.</p>

<h3 id="ps_samplepy">ps_sample.py</h3>
<hr>
<div><div><pre><code><span>import</span> <span>os</span>
<span>from</span> <span>psdbase_utils</span> <span>import</span> <span>Photoshop</span>

<span>curdir</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>abspath</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>dirname</span><span>(</span><span>__file__</span><span>))</span>
<span>background_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"background.psd"</span><span>)</span>
<span>star_path</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>curdir</span><span>,</span><span>"star.jpg"</span><span>)</span>

<span>ps</span> <span>=</span> <span>Photoshop</span><span>()</span>

<span>all_open_psd</span> <span>=</span>\
	<span>ps</span><span>.</span><span>compose</span><span>(</span><span>background_path</span><span>,</span>
		   <span>star_path</span><span>,</span>
		   <span>"C base"</span><span>,</span>
		   <span>curdir</span><span>,</span>
		   <span>"final.jpg"</span><span>)</span>
				
<span>for</span> <span>open_psd</span> <span>in</span> <span>all_open_psd</span><span>:</span>
	<span>ps</span><span>.</span><span>close</span><span>(</span><span>open_psd</span><span>)</span>

<span>ps</span><span>.</span><span>shutdown</span><span>()</span>
</code></pre></div></div>

<h2 id="watch-out">Watch out!</h2>
<p>As mentionned earlier, even though there are quite a few advantages to automating with Photoshop, there are also quite a few points to consider.</p>

<p>Photoshop scripts require running an actual instance of Photoshop and it’s <strong>main window will be visible on the desktop</strong>.</p>

<p>The <strong>Photoshop window should not be minimized while running a script.</strong> This might actually block Photoshop, and prevent your automated task from running properly.</p>

<p>If you make use of <strong>Copy/Paste commands in your script, this will hijack your clipboard</strong>, and prevent any other user/application from using it properly.</p>

<p><strong>Photoshop tends to hang/freeze/crash periodically.</strong> The crashes are frequent on big batches of images and don’t seem to be related to RAM/CPU usage. Just restart your script and it will eventually run to completion just fine. Regardless of crashes, <strong>you can still make huge productivity gains from automating some tasks.</strong></p>

<p>For all these reasons, we <strong>highly recommend that any automated tasks you create should run on a dedicated Windows PC.</strong> You don’t need a high end PC for most tasks and this will definitely make everyone more productive.</p>

<h2 id="hope-this-was-useful">Hope this was useful</h2>
<p>Of course, most of the code and samples discussed here are related to the specific use case described.
Almost all Photoshop commands can be scripted this way. The sample code should help you get started, and more details can be found in Photoshop scripting reference.
<strong>If you need any help with your project, we will gladly share our expertise if required!</strong></p>


      </section>
    </div></div>]]>
            </description>
            <link>https://kelvin0.github.io/ImageAutomation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907717</guid>
            <pubDate>Tue, 27 Oct 2020 14:26:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Privacy Puzzle: A Baffled Voter's Guide to California's Prop 24]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907559">thread link</a>) | @tolbish
<br/>
October 27, 2020 | https://sandiegoprivacy.org/prop24.html | <a href="https://web.archive.org/web/*/https://sandiegoprivacy.org/prop24.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      Proposition 24 is a 52-page law that overhauls privacy laws in California. It's so complex that it has split the privacy community, and experts disagree about what it would mean for Californians. Most voices agree Prop 24 has some changes to love, and some to reject. The typical voter is probably very uncertain about whether to vote "Yes" or "No".
    </p>
    <p>
      We are <strong>San Diego Privacy</strong>, a small group of privacy advocates in San Diego, and we'd like to help by offering a neutral analysis. Below you'll find 10 of the biggest issues with Prop 24, along with the main points supporters (the "Yes" side) and opponents (the "No" side) make about that issue.
    </p>
    <p>We suggest you first pick the issues in purple that jump out to you the most. Then, keep count of whether you find the Yes side or the No side more compelling, for the issues you've picked. Last, total up your counts.</p>
    <p>Then, as always, go vote your values.</p>

    <p><strong><i>Update</i></strong>: When you pick the issues below that matter to you, consider <a href="https://drive.google.com/drive/folders/1FSWtcqBEbe-SOUUWZ9d7j_M3Ft1ap5CR?usp=sharing" target="_blank">downloading a shareable image</a> of that issue as well, and posting it on social media to generate discussion.</p>

    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Pay For Privacy</strong></p>
            <div>
              <p>
                <strong>Pay for Privacy</strong> means that if you demand privacy, companies can charge you more for goods and services.
              </p>
              <ul>
                <li>Companies that rely on targeted advertising, like newspapers or free streaming music services, currently rely on targeted ads.</li>
                <li>Some privacy options allow you to block the ability to show you targeted ads.</li>
                <li>Pay-for-privacy is already allowed in existing California law.</li>
              </ul>
            </div>
            <p><a>What is "Pay For Privacy"?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Says Prop 24 keeps existing pay-for-privacy laws alive.</li>
                  <li>Claims companies who rely on targeted ads, like newspapers, would be imperiled if pay-for-privacy was eliminated.</li>
                
              </div>
              <div>
                <p>
                   <a href="https://medium.com/cr-digital-lab/consumer-reports-urges-californians-to-vote-yes-on-proposition-24-693c26c8b4bd" target="_blank">Consumer Reports says</a> Prop 24 doesn't substantially change pay-for-privacy law from the existing law.
                </p>
                <p>
                   When interviewed, Prop 24 author Alastair Mactaggart warns the newspaper industry would be hit hard if pay-for-privacy options were blocked. (<a href="https://youtu.be/eWOFZOPJm78?t=2186" target="_blank">Union-Tribune video interview</a> with Yes on 24)
                </p>
              </div>
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Says Prop 24 doesnt fix the problem of pay-for-privacy, which is already in current law.</li>
                  <li>Argues privacy is a constitutional right of Californians; it is not for sale.</li>
                  <li>Warns Prop 24 further emboldens businesses to charge consumers for privacy.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: It's important to emphasize here that pay-for-privacy is already allowed in current law. Opponents see Prop 24's choice to further expand pay-for-privacy, rather than ban it, as one reason to oppose it.
      </p>
    </section>

    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Global Opt-Out</strong></p>
            <div>
              <p>
                <strong>Global Opt-Out</strong> allows you to set up your privacy options in one place, and have them apply universally. Prop 24 allows companies to ignore those global settings, in some cases.

              </p>
              <ul>
                <li>In the future, you'll be able to set your privacy preferences in one place, rather than at each site or service.</li>
                <li>Prop 24 includes provisions for allowing companies to ignore your global privacy preferences for certain reasons, like if they want you to pay.</li>
                <li>There could be other reasons companies won't have to respect your global privacy preferences.</li>
              </ul>
            </div>
            <p><a>What is Global Opt Out?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Believes pay-for-privacy means companies must be allowed to ignore your global privacy settings in order to ask you to pay (See "Pay For Privacy" above).</li>
                
              </div>
              <p>
                    The <a href="https://www.wired.com/story/california-prop-24-fight-over-privacy-future/" target="_blank">Wired article</a> covers Yes on 24's argument for why they believe it is important for companies to have the option to ignore your privacy settings.
                </p>
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues consumers should be opted-out of all data collection by default.</li>
                  <li>Warns that Prop 24 allows companies to ignore your universal opt-out if they put a "Do Not Sell" button on their site.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: This is a good place to note that many privacy advocates believe all efforts to collect your data should require affirmative consent from you, rather than using the "opt-out" model where companies collect your data first, and then require you to ask it be deleted or not collected.
      </p>
    </section>
    <section>
      <div>
        <div>
          <div>
            <p>I'm concerned about privacy law <strong>Enforcement</strong></p>
            <div>
              <p>
                Current privacy laws in California are rarely <strong>enforced.</strong> Only the California Attorney General can enforce California's privacy laws.
              </p>
              <ul>
                <li>California previous privacy agency was previously closed during budget cuts.</li>
                <li>The California attorney general has signaled that they don't have enough resources for enforcement.</li>
                <li>The California attorney general has asked the legislature to allow individuals the right to sue to enforce their privacy.</li>
              </ul>
            </div>
            <p><a>What's going on with enforcement?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Says Prop 24 establishes a new state enforcement agency, with funding.</li>
                  <li>Says Prop 24 will enable some city and county officials to enforce the law, in addition to the California attorney general.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues individuals should be able to sue companies to enforce their privacy choices, but Prop 24 left that out.</li>
                  <li>Believes the new enforcement agency established by Prop 24 would be underfunded and ineffective.</li>
                
              </div>
              <div>
                <p>
                    Private right of action (the right for individuals to sue) is desired by many privacy organizations, <a href="https://www.eff.org/deeplinks/2020/07/why-eff-doesnt-support-cal-prop-24#:~:text=no%20enforcement%20by%20consumers" target="_blank">including the EFF</a>.
                </p>
                <p>
                   Opponents stated their objection to Prop 24's new enforcement agency in <a href="https://youtu.be/DuWspeTzOA0?t=780" target="_blank">their video interview</a> with the Union-Tribune.
                </p>
              </div>
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: Privacy advocates feel very strongly that Californians should have the "private right of action," or the right to sue companies to enforce privacy law. It seems to us unlikely that privacy organizations will support overhauls to California's privacy laws without that private right of action being included.
      </p>
    </section> 
    <section>
      <div>
        <div>
          <div>
            <p>I'm concerned about <strong>How Prop 24 Was Created</strong></p>
            <div>
              <p>
                Prop 24 is a 52-page law with so much complexity that even experts disagree on its meaning. It was written privately and then submitted directly to voters.
              </p>
              <ul>
                <li>Alastair Mactaggart wrote Prop 24. It has not been reviewed by the legislature.</li>
                <li>Mactaggart invited some industries to provide changes to Prop 24 as it was drafted.</li>
                <li>Mactaggart helped get California's existing CCPA privacy law passed through the legislature.</li>
              </ul>
            </div>
            <p><a>What's the deal with Prop 24's origins?</a>
          </p></div>
        </div>
        <div>
          <div>
            <div>
              <div>
                <p>Yes Side Says:</p>
                <li>Argues privacy laws are under assault by lobbyists, and Prop 24 is the fastest way to stop that.</li>
                  <li>Warns that there isn't enough enforcement of existing privacy laws, and that Prop 24 provides more enforcement.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
          <div>
            <div>
              <div>
                <p>No Side Says:</p>
                <li>Argues existing privacy laws only started to be enforced three months ago, and that it's too soon to overhaul those privacy laws.</li>
                  <li>Believes the legislature should write and pass future privacy laws, not private parties.</li>
                  <li>Warns that privacy organizations were excluded from writing Prop 24, but that industries were invited.</li>
                
              </div>
              
              <p><a>Sources</a>
            </p></div>
          </div>
        </div>
      </div>
      <p>
        Authors' Note: Due to the way this law is being proposed directly to voters, rather than going through the long process of the legislature, there are a lot of experts disagreeing with each other regarding Prop 24's implications.
      </p>
    </section>
    <section>
      <div>
        <div>
          <div>
            <p>I feel strongly about <strong>Protecting Sensitive Data</strong></p>
            <div>
              <p>
                Prop 24 classifies some types of data as "sensitive," such as race, sexual orientation and precise GPS coordinates, and restricts how companies can use them.
              </p>
              <ul>
                <li>Prop 24 sets up a new class of information called Sensitive Information.</li>
                <li>Sensitive information includes: precise geolocation; race; ethnicity; religion; genetic data; private communications; sexual orientation; and specified health information.</li>
                <li>Fines are tripled for violations of the law for children under the age of 16.</li>
              </ul>
            </div>
            <p><a>What's the …</a></p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sandiegoprivacy.org/prop24.html">https://sandiegoprivacy.org/prop24.html</a></em></p>]]>
            </description>
            <link>https://sandiegoprivacy.org/prop24.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907559</guid>
            <pubDate>Tue, 27 Oct 2020 14:10:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beam Marches Forward]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907554">thread link</a>) | @etxm
<br/>
October 27, 2020 | https://underjord.io/the-beam-marches-forward.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-beam-marches-forward.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-10-26</small>
        <p>The BEAM is the virtual machine that Erlang and Elixir runs on. It is widely cited as a battle-tested piece of software though I don’t know in which wars it has seen action. It has definitely paid its dues in the telecom space as well as globally scaled projects such as Whatsapp and Discord. It is well suited to tackle soft-realtime distributed systems with heavy concurrency. It has been a good platform chugging along. And with a small team at Ericsson responsible for much of its continuing development it has been managed in a deeply pragmatic way. Erlang has always been a bit of a secret and silent success. Almost no-one uses it if you look at market shares. But among the ones that use it there seems to be a very positive consensus. And then Elixir came and caused a bit of a boom. I think the BEAM has benefited from Elixir and Elixir wouldn’t exist without the BEAM. With that bit of background I’d like to shine a light on some cool developments that I think makes the BEAM more interesting or even uniquely interesting in the future.</p>
<h2 id="the-jit-is-here-soon-otp-24">The JIT is here (soon, OTP 24)</h2>
<p>With OTP 24 landing sometime next year we are going to get the a JIT for the BEAM. Based on the project <a href="https://github.com/asmjit/asmjit">AsmJit</a> this will mean that some BEAM code will be translated to native instructions. It will not be the kind of warm-up-for-performance-gains JIT that I’ve heard of in PyPy but rather significantly simpler. The goal of the project was to introduce a JIT that could give performance gains for some cases but would not cause any performance regressions. A pragmatic and laudable approach. Considering this made the Jason JSON-library (written in Elixir) beat the Jiffy JSON-library (written as a C NIF) in <strong>some</strong> tests I think this has the potential to obviate the need for some NIF implementations. Avoiding reaching out to the lower level code that is more capable but more dangerous is a good win.</p>
<p>Anyone running RabbitMQ should look forward to the update as measurements indicate 30-50% increased message throughput. Which is a nice thing to get for no code changes at all.</p>
<p>Pushing the performance of the BEAM closer to native is magnificent. To be clear the BEAM is already quite a good performer. I would put Erlang and Elixir at the abstraction level of languages like Python/Ruby/Node.js. Python and Ruby are poor performers. The Python ML stuff all goes into C++ or similar for performance. I’ve worked a bunch with Python and the things I hear from the Ruby world makes them sound quite equivalent in performance. They are a bit slow and can only <a href="https://underjord.io/more-than-one-thing-at-a-time.html">do one thing at a time</a>. Node.js is a bit different. It can do multiple things at a time, if you append asterisks and squint. It does it largely the same way Python + Gevent does it. This approach is incredibly susceptible to CPU-bound work causing head-of-line blocking. It becomes the single most important consideration for building a performant application “get to IO, don’t compute”. V8 that Node.js runs on is heavily optimized and fast for such a dynamic language. I think the BEAM provides a better approach that can deliver comparable results without as many footguns (opportunities for shooting yourself in the foot). But getting better at the raw crunching is a big gain with this JIT implementation and I look forward to the release.</p>
<h2 id="lumen---static-compilation--wasm">Lumen - Static compilation &amp; WASM</h2>
<p>The <a href="https://getlumen.org/">Lumen project</a> is a huge effort by a gang of open source developers and DockYard to implement a compiler (and more) that can take Elixir and Erlang into the browser. By solving that they end up solving static compilation for Erlang and Elixir as well. So this isn’t compiling and shipping the BEAM to the browser. This is a faithful reimplementation of the BEAM functionality in a way that allows it to be compiled statically. It uses LLVM and requires quite a bit of effort both in development and in wrangling the Web Assembly work group process stuff to make sure that the standard is not entirely run by Object-Oriented Programming needs.</p>
<p>I don’t think Lumen will replace the BEAM. The BEAM has a brilliant track record for long-running services and distributed computing that the Lumen project do not even attempt to achieve right now. Instead the Lumen project will allow Elixir and Erlang to move into spaces where the BEAM might be a bit too heavy and still provide the same guarantees. Typically I see it being good for command line tools, web frontends (super interesting to consider the Actor model going there), serverless/edge computing and potentially with WASM competing with Docker as a delivery mechanism for code in Kubernetes, using something like <a href="https://github.com/deislabs/krustlet">Krustlet</a> (<a href="https://player.fm/series/software-sessions/webassembly-on-the-server-with-krustlet">good podcast episode on WASM/Krustlet</a>). It’s probably Cloud Native or something. Who knows.</p>
<p>What gives Lumen the potential to be a better fit in these circumstances is that it can optimize for filesize (by cutting out hot code updates) and it is likely able to start much faster. Lumen is written in Rust. Which seems to be the popular choice around Web Assembly from what I’ve seen. Lumen is still an early release project and not fit for production. But it is beeing actively pushed forward.</p>
<h2 id="nerves---an-iot-platform-with-minimal-suck">Nerves - An IoT platform with minimal suck</h2>
<p>The <a href="https://www.nerves-project.org/">Nerves project</a> is fantastic. I’m a hardware hobbyist, not an IoT dev but I’ve worked a fair bit with Nerves and it is so, so good. What Nerves gives you when working with a Raspberry Pi for example is a way to let your code run all of the device. The BEAM is basically your operating system on top of a minimal Linux installation. The Linux you have is based on the solid foundation of Buildroot so it is quite feasible to modify it as you see fit. The big idea is that if you are running a Linux-level SBC already you might as well build on something that gives you the guarantees of the BEAM.</p>
<p>Beyond that the default setup encodes a lot of good embedded practices by default so that you avoid bricking devices with firmware updates, you get easy support for pushing firmware over the network or USB and much, much more.</p>
<p>There are a ton of good libraries for sensors and assorted hardware, as well as the common protocols like GPIO/SPI/I2C/UART. Networking support is well considered and has been reworked since I first started using Nerves a few years back (and it worked well then too). BLE is getting more and more good support recently.</p>
<p>The project also created <a href="https://www.nerves-project.org/nerveshub">NervesHub</a> which is a solution for managing a fleet of devices by securely providing firmware updates, allowing the switching on of a remote console on devices if that’s a need on your product. I think the most recent stuff is a UI revamp and some serious work on binary diffed patches to minimize firmware update sizes for data-constrained deployments.</p>
<p>This is very much a production project and people are shipping hardware with Nerves. It keeps marching forward.</p>
<h2 id="the-beam-can-be-your-entire-application">The BEAM can be your entire application</h2>
<p>Saša Jurić, author of the much-acclaimed Elixir in Action book has produced a library called <a href="https://github.com/sasa1977/site_encrypt">site_encrypt</a>. It allows you to handle LetsEncrypt configuration without a separate webserver or actually using certbot.</p>
<p>Now this library is good and meaningful in its own right but the underlying idea is why I bring it up. The BEAM can be your entire application. This is something I’ve realized over time. Where in Python you would reach for Gunicorn to run you Django app and Nginx to protect Gunicorn from the big bad world.. The BEAM is made for this. Introducing an intermediate layer of Nginx (or another HTTP server) might actually be detrimental in that you now have two things you need to configure correctly and two pools of multi-core processing workers that care about this request/response cycle and can independently screw it up.</p>
<p>The BEAM was always built for this. OTP has a lot weird corners where you find interesting libraries such as <code>wx</code> for WxWidgets (window management) and <code>ssh</code> for both SSH client and server work I believe. Because it is meant to be delivered as a full solution. It can run and manage multiple different types of work inside of it. Gracefully. It doesn’t replace Kubernetes for the large deployment or polyglot environments. But it might very well mean you don’t actually need to go there early. Or you can reduce how much Ops you need in your Dev. If your entire stack is Elixir or Erlang front to back I think you have empowered your developers significantly.</p>
<p>There is already a move towards this where tools are converging that give us a lot of things out of the box that we’d otherwise need to move outside our application for. These are pragmatic 80-90% solutions. The normal solutions are still all there if you need to reach for them. But maybe you don’t. I see these as moves in the same vein:</p>
<ul>
<li>LiveView - We can reduce the amount of frontend we need to build that isn’t BEAM code (Elixir or Erlang), in some cases get rid of it entirely.</li>
<li>Live Dashboard - Application insights right in your application stack instead of pushing them out to another solution.</li>
<li>Phoenix PubSub - Distributed PubSub without requiring coordination via something like Redis.</li>
<li>Phoenix Channels - Distributed PubSub over WebSockets using the above PubSub to coordinate delivery.</li>
<li>Phoenix Presence - Distribute Presence. A CRDT-powered thing for maintaining information about if someone is connected to a channel or not, like chatrooms and online/offline. Using Channels.</li>
</ul>
<p>Lowering complexity by keeping the solutions in a system you understand well is potentially very powerful. At some point many projects will need to pick up external dependencies such as Nginx, Redis or whatever. But I think there is something compelling about building your application inside a system that can do all of it quite well. Elixir and Phoenix already have significant mind-share in the startup world. I wouldn’t be surprised if this ends up being a very popular solution for startups. No frontend-specific code for the MVP, no New Relic or Mixpanel bill we make do with the Live Dashboard. Distribution is Erlang distribution + Swarm/Horde/Libcluster or something …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/the-beam-marches-forward.html">https://underjord.io/the-beam-marches-forward.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/the-beam-marches-forward.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907554</guid>
            <pubDate>Tue, 27 Oct 2020 14:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taming the Tech Giants]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24907404">thread link</a>) | @jakelazaroff
<br/>
October 27, 2020 | https://jake.nyc/words/taming-the-tech-giants/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/taming-the-tech-giants/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
  <header>
    <time datetime="Tue Oct 27 2020 01:00:00 GMT-0400 (Eastern Daylight Time)">October 27, 2020</time>
    
  </header>
  <p>Everyone's angry at the tech industry these days! Tech companies continue to cement their place as some of the most powerful companies in the world, and taking shots at them has become a popular sport. Most recently, <a href="https://www.npr.org/2020/10/14/923766097/facebook-and-twitter-limit-sharing-new-york-post-story-about-joe-biden">Facebook and Twitter suppressed a controversial New York Post article</a>, raising accusations that the social networks are putting their thumbs on the scale of the upcoming election.</p>
<p>In response, conservatives — <a href="https://twitter.com/realDonaldTrump/status/1316821530769149952?s=20">led by the President</a> — have set their sights on Section 230, the <a href="https://www.eff.org/issues/cda230">legislation that protects the right of Internet companies to moderate content</a>. “Repeal Section 230” has become a popular rallying cry from people who believe that large social networks are abusing this ability to enact a political agenda. There’s a lot of rhetoric around “publishers” and “platforms” (the idea being that if you decide to moderate content on your app or website, you should assume legal liability for it) and that Internet companies are breaking the rules by deciding what content to allow.</p>
<p>Naturally, the left disputes the claim that conservatives are being censored. But we can still analyze the power of gatekeeper platforms even if we disagree about how they're wielding it.</p>
<!--more-->
<p>As we'll see, the law as it exists today expressly permits the moderation in which tech companies engage. More to the point, the platform/publisher dichotomy is rooted in constraints of traditional media that don't apply to the Internet.</p>
<p>Those constraints — or the lack thereof — should guide our efforts to make the Internet a more equitable place. The web in particular was built with the promise of giving everyone a voice; it's only in the last decade or so that power became truly centralized. We keep that promise not by forcing gatekeepers to play fair, but by getting rid of them entirely.</p>
<hr>
<p>In the analog era, the act of publishing was subject to physical constraints. A newspaper, for example, printed a set number of pages a few times daily. If they wanted to publish content by third parties, they had to read it all and make an editorial decision about what made the cut. As a result, publishers were responsible for vetting everything that ran under their masthead.</p>
<p>By contrast, it was unreasonable to expect a news stand to check every word in every newspaper they sold every day. These entities were called “distributors”. If an article in a newspaper turned out to be libelous, only the publisher was on the hook legally, while the distributor enjoyed legal immunity.</p>
<p>The Internet turned this model on its head. Space to publish became infinite, time to publish became instant and distributors became unnecessary. Websites could host discussions between thousands of people in real time, and checking every single comment was infeasible. That then raised the question: who was liable for the comments?</p>
<p>Two lawsuits that are often cited as catalysts for Section 230 are <a href="https://en.wikipedia.org/wiki/Cubby,_Inc._v._CompuServe_Inc"><em>Cubby, Inc. v. CompuServe, Inc.</em></a> and <a href="https://en.wikipedia.org/wiki/Stratton_Oakmont,_Inc._v._Prodigy_Services_Co"><em>Stratton Oakmont, Inc. v. Prodigy Services Co.</em></a> <sup><a href="#1">1</a></sup> — both defamation cases against Internet service providers. In the former case, the court ruled that because CompuServe didn’t review any of the content on its forums, it was acting as a distributor and therefore not liable for defamatory content. In the latter case, the court ruled the opposite: because Prodigy moderated users’ comments, it was acting as a publisher.</p>
<p>To resolve this ambiguity, Congress added Section 230 to the Communications Decency Act, which it passed in 1996. The <a href="https://www.law.cornell.edu/uscode/text/47/230">portion most people are talking about</a> is printed below:</p>
<blockquote>
<p><strong>(1) Treatment of publisher or speaker</strong> No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.</p>
<p><strong>(2) Civil liability</strong> No provider or user of an interactive computer service shall be held liable on account of—</p>
<p><strong>(A)</strong> any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected; or</p>
<p><strong>(B)</strong> any action taken to enable or make available to information content providers or others the technical means to restrict access to material described in paragraph (1).</p>
</blockquote>
<p>Both the letter and the spirit of the law are intended to allow Internet services to moderate third-party content however they wish, while shielding them from legal liability if it turns out to be defamatory. Legally, the “publisher vs. platform” dichotomy does not exist.<sup><a href="#2">2</a></sup></p>
<hr>
<p>The logic behind the repeal of Section 230 seems to be that doing so would force platforms like Twitter to not moderate content. This isn’t strictly true; surely everyone, no matter where they sit on the political spectrum, can think of a biased publisher or two! Twitter would still be free to censor conservative content. The difference is that they would then be liable for any unrelated content they allowed that happened to be defamatory.</p>
<p>A more nuanced read is that the threat of litigation would essentially be a stick that would prevent platforms from moderating. Users couldn’t sue Twitter for removing content — but Twitter would choose not to anyway, for fear of getting sued by someone with deep pockets if they accidentally let a defamatory tweet go viral.</p>
<p>There's no way to know exactly what would happen if 230 were repealed, but here’s a guess at how things might shake out.</p>
<p>At first, a lot of platforms might stop moderating. This would seem like a win for Team Repeal, until they realized what moderation keeps at bay. Blatant racism, doxxing and threats of violence would be commonplace. Spam filtering is a form of moderation, so discussions would be filled with links to porn sites and scams. Actual conversations would get drowned out.</p>
<p>That would be a deal breaker for a lot of people, who would stop using those platforms. It's possible things would end here, and those who could be more thick-skinned would just deal with the death threats and spam. On the other hand, since there's no actual legislation indemnifying platforms if they <strong>don't</strong> moderate — just a shaky legal precedent resting on some decades–old cases — it's possible that we'd start seeing lawsuits anyway.</p>
<p>In response to the legal risk and decaying user bases, companies would start <strong>heavily</strong> moderating — spending a lot of money to make sure they only allow content that doesn’t risk a lawsuit. This might function similarly to the New York Times comment section, where comments are screened before being published. Most of the content people say is being censored now (like the story in the New York Post, which was <a href="https://www.nytimes.com/2020/10/18/business/media/new-york-post-hunter-biden.html">explicitly chosen as a publisher because it wouldn't vet the story</a>) would probably end up on the cutting room floor — it might give someone grounds to sue, so better to just err on the side of caution.</p>
<p>Smaller platforms wouldn’t have the resources to do this. They’d end up either limping on with severely compromised experiences or just going out of business. There would be a steep drop in the number of platforms created, since the spam issue would be especially overwhelming for those in their infancy.</p>
<p>Independent websites would suffer even more. Let's say I added a comments section to this blog, and then one day I started getting flooded with spam. I'd face a dilemma: delete the spam and risk a lawsuit, or let it continue to suffocate the conversation? (Assuming that allowing a free-for-all would indemnify me, which, again, is not guaranteed). I'm not even making any money from this website — is it worth the legal risk?</p>
<p>Meanwhile, some crucial web infrastructure simply could not exist without incurring liability. Ranking, for example, is a fundamentally biased act that depends on inferences about both the intent of the reader and the nature of the content being ranked.<sup><a href="#3">3</a></sup> Search engines would be the most obvious casualty, as every search result would present a legal liability. Requiring humans to check each of the <a href="https://www.weforum.org/agenda/2019/09/chart-of-the-day-how-many-websites-are-there/">1.7 billion websites</a> would result in far less of the web being searchable. The added difficulty and expense would further entrench Google's search monopoly, which is already <a href="https://www.wsj.com/articles/justice-department-to-file-long-awaited-antitrust-suit-against-google-11603195203">the target of a Justice Department antitrust lawsuit</a>.</p>
<p>Whatever the case, the end result would be a chilling effect at all levels of Internet discourse. Most platforms would be far more censorious than they are today, and the rest would be overrun by trolls and spammers. Small platforms would go under — and worse, far fewer would be created in the first place. Interaction on personal websites would almost entirely disappear. Many people would feel intimidated by abuse and threats and withdraw from their public presence online. Others would just get fed up with the spam.</p>
<hr>
<p>A common response to these scenarios is that platforms should have to be neutral with regard to <strong>ideology</strong>, but still be free to filter <strong>spam</strong>.</p>
<p>Okay, so what counts as spam? Some is obvious "I made $1,000 from my couch" type stuff. But the majority falls in a gray area that would create huge headaches for platforms trying to comply with the law and courts trying to enforce it.</p>
<p>Most people who have been online have seen messages for erectile dysfunction drugs or porn sites. But how do you disambiguate between that and online sex workers promoting themselves? What’s the fundamental difference between a sketchy online pharmacy and <a href="https://www.getroman.com/">Roman</a>?<sup><a href="#4">4</a></sup></p>
<p>If you think those examples are a bit contrived, it’s easy to come up with an example where it’s not only ambiguous whether something is spam, but also unclear whether blocking it would be political censorship.</p>
<p>Say I run a pro-Trump forum on which I occasionally encourage people to buy Trump campaign merch. One day, someone shows up and starts posting links to Biden merch. Is that spam, or political discourse? I can’t very well say advertising campaign merch is prohibited, since I do it myself. Could I ban all promotion of campaign merch? What if they’re not …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jake.nyc/words/taming-the-tech-giants/">https://jake.nyc/words/taming-the-tech-giants/</a></em></p>]]>
            </description>
            <link>https://jake.nyc/words/taming-the-tech-giants/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907404</guid>
            <pubDate>Tue, 27 Oct 2020 13:51:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intake of sugary&artificially sweetened drinks associated w higher risk of CVD]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24907350">thread link</a>) | @bookofjoe
<br/>
October 27, 2020 | https://www.jacc.org/doi/10.1016/j.jacc.2020.08.075?_ga=2.122659403.1986902380.1603796490-481022351.1603796490& | <a href="https://web.archive.org/web/*/https://www.jacc.org/doi/10.1016/j.jacc.2020.08.075?_ga=2.122659403.1986902380.1603796490-481022351.1603796490&">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.jacc.org/doi/10.1016/j.jacc.2020.08.075?_ga=2.122659403.1986902380.1603796490-481022351.1603796490&amp;</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907350</guid>
            <pubDate>Tue, 27 Oct 2020 13:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning Scooter Data into Infrastructure Improvements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907316">thread link</a>) | @andrewfromx
<br/>
October 27, 2020 | https://www.bird.co/blog/3-cities-turning-scooter-data-into-infrastructure-improvements/ | <a href="https://web.archive.org/web/*/https://www.bird.co/blog/3-cities-turning-scooter-data-into-infrastructure-improvements/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="blog-single-container">

					

					<section>

						
<p>There’s a lot we can learn from hundreds of millions of micromobility trips.&nbsp;</p>



<p>Over the past three years, that fact has become increasingly evident—and increasingly important. Electric scooters have carried tens of millions of riders across hundreds of cities around the world. When combined, these unique trips tell the story of human-sized urban mobility at a macro scale. What streets are the most convenient to travel on two wheels? What times of day are best suited for riding? Where do we tend to park when given the opportunity?</p>



<p>Cities that are listening closely to this story find themselves in a position to do something incredible: make low-cost, high-impact improvements to urban infrastructure based on the real time needs of their inhabitants. It’s the first time in history that such precise, data-backed decision making has been possible for city planning purposes.&nbsp;</p>



<p>As one of the founding members of the <a href="https://www.openmobilityfoundation.org/" target="_blank" rel="noreferrer noopener"><span>Open Mobility Foundation</span></a>, Bird is proud to have committed to responsible data sharing principles since pioneering shared e-scooters in 2017. To us, the data we learn from is just as important as the vehicles we build, because that’s what allows cities to make critical infrastructure and transit improvements for the benefit of all road users.&nbsp;</p>



<p>When it comes to turning such information into action, these three cities are doing a particularly good job.</p>



<h3>Atlanta, Georgia, USA</h3>



<p><br>When Bird scooters first arrived in Atlanta, the city had just 4 miles of protected bike lanes. This quickly proved insufficient to safely accommodate the increasing number of micromobility riders, and Mayor Keisha Lance Bottoms’ administration took action.&nbsp;</p>



<p>By September of 2019, not only had a <a href="https://atlanta.curbed.com/2019/9/25/20882978/mayor-keisha-lance-bottoms-protected-bike-lanes" target="_blank" rel="noreferrer noopener"><span>$5 million action plan</span></a> been unveiled to add an additional 12 miles of protected Light Individual Transport lanes by 2021, but Mayor Bottoms was already implementing and testing temporary protected infrastructure along the city’s busy 10th Street corridor. The resulting data, shared earlier this year, demonstrate two crucial, correlated points:&nbsp;</p>



<ul><li>87% of cyclists and 83% of scooter riders said they felt safer during the popup, leading to a</li><li>58% increase in bike and scooter rides during the popup&nbsp;</li></ul>



<p><br>“We have heard from residents of Atlanta loud and clear – people want safer streets, and they want to see real changes,” the Mayor <a href="https://www.ajc.com/news/local-govt--politics/atlanta-mayor-bottoms-promises-triple-city-bike-scooter-lanes/zl0kpszowj2E7z7SXLM1mJ/" target="_blank" rel="noreferrer noopener"><span>said in a statement</span></a>.<br></p>



<div><figure><img width="1024" height="1024" src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-1024x1024.jpg" data-src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-1024x1024.jpg" alt="" data-srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-1024x1024.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-300x300.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-150x150.jpg 150w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-768x768.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-665x665.jpg 665w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-640x640.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-980x980.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-490x490.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7.jpg 1080w" data-sizes="(min-width: 1024px) 1024px, (min-width: 2048px) 100vw, 100vw" srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-1024x1024.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-300x300.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-150x150.jpg 150w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-768x768.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-665x665.jpg 665w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-640x640.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-980x980.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7-490x490.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-7.jpg 1080w"></figure></div>



<h3><br>Tel Aviv, Israel</h3>



<p><br>Last year, Tel Aviv was ranked <a href="https://www.haaretz.com/israel-news/business/.premium-tel-aviv-ranked-5th-worst-in-world-for-traffic-congestion-1.8069979" target="_blank" rel="noreferrer noopener"><span>5th worst in the world</span></a> for traffic congestion. This year, the city is <a href="https://www.bird.co/blog/reversing-pyramid-tel-aviv-goes-all-in-pedestrians-micromobility/" target="_blank" rel="noreferrer noopener"><span>reversing that trend</span></a> by launching an ambitious initiative that will add 160 km of new micromobility infrastructure by 2025.</p>



<p>The coastal Israeli city has become a global leader in e-scooter adoption. Earlier this year, we announced that riders in Tel Aviv had <a href="https://www.bird.co/blog/tel-aviv-modeshift-milestone-5-million-bird-rides-2-years/" target="_blank" rel="noreferrer noopener"><span>surpassed 5 million trips on Bird alone</span></a>. The data collected from these rides has been instrumental in helping city officials plan for infrastructure improvements:&nbsp;</p>



<p>“Thanks to the support from and data shared by micromobility operators like Bird, we’ve been able to identify where new infrastructure is most needed in order to encourage modeshift and reduce our dependence on private cars,” said Deputy Mayor Meital Lehavi.&nbsp;</p>



<p>The city plans to use its new infrastructure to coax drivers out of their cars, increasing the amount of micromobility commuters from 11% to 25% over the next 5 years.&nbsp;<br></p>



<div><figure><img width="1024" height="683" src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1024x683.jpg" data-src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1024x683.jpg" alt="" data-srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1024x683.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-300x200.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-768x512.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1250x833.jpg 1250w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-640x427.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-980x653.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-490x327.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3.jpg 1485w" data-sizes="(min-width: 1024px) 1024px, (min-width: 2048px) 100vw, 100vw" srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1024x683.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-300x200.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-768x512.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-1250x833.jpg 1250w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-640x427.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-980x653.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3-490x327.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-3.jpg 1485w"></figure></div>



<h3><br>Santa Monica, California, USA</h3>



<p><br>The beachside city of Santa Monica in Los Angeles County passed a Bike Action Plan in 2011 that was one of the first of its kind in the country. It created <a href="https://www.smdp.com/letter-to-the-editor-in-support-of-santa-monicas-proposed-bike-action-plan-amendment/197427" target="_blank" rel="noreferrer noopener"><span>hundreds of miles</span></a> of bike lanes and bike friendly corridors, reinforcing the city’s commitment to safer streets and cleaner air.&nbsp;</p>



<p>In 2020, city officials decided to amend that plan in order to once again take a leading role nationwide in micromobility infrastructure—this time by focusing on protected bike and scooter lanes. By analyzing scooter data from millions of trips along with information on car congestion and accidents, those drafting the amendment were able to lay out an additional 19 miles of separated micromobility infrastructure and amenities that will increase bike and scooter use and decrease reliance on personal cars and ride hailing.</p>



<p>The amendment reflects Santa Monica’s ambitious goal of reducing carbon emissions <a href="https://www.smartcitiesdive.com/news/santa-monica-ca-passes-800m-plan-to-go-carbon-neutral-by-2050/555693/#:~:text=The%20Climate%20Action%20%26%20Adaptation%20Plan,%2C%20bike%2C%20scooter%20or%20skateboard." target="_blank" rel="noreferrer noopener"><span>80% below 1990 levels</span></a> by 2030. A survey conducted last year reported that nearly 50% of micromobility riders used either a shared bike or scooter to <a href="https://www.smgov.net/uploadedFiles/Departments/PCD/Transportation/SharedMobilityUserSurveyReports_Combined.pdf" target="_blank" rel="noreferrer noopener"><span>replace a car</span></a> during their most recent trip. That’s an impressive accomplishment by any measure.</p>



<p>Councilmembers <a href="https://www.smdp.com/city-amends-bike-action-plan-to-include-more-safety-lanes/197572" target="_blank" rel="noreferrer noopener"><span>voted unanimously</span></a> to pass the Bike Action Plan Amendment earlier this month.<br></p>







<div><figure><img width="1024" height="582" src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1024x582.jpg" data-src="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1024x582.jpg" alt="" data-srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1024x582.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-300x171.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-768x437.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1250x711.jpg 1250w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-640x364.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-980x557.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-490x279.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4.jpg 1280w" data-sizes="(min-width: 1024px) 1024px, (min-width: 2048px) 100vw, 100vw" srcset="https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1024x582.jpg 1024w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-300x171.jpg 300w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-768x437.jpg 768w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-1250x711.jpg 1250w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-640x364.jpg 640w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-980x557.jpg 980w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4-490x279.jpg 490w, https://www.bird.co/wp-content/uploads/2020/10/3-cities-turning-scooter-data-into-infrastructure-improvements-4.jpg 1280w"></figure></div>

					</section> <!-- end article section -->
				</div>
			</div></div>]]>
            </description>
            <link>https://www.bird.co/blog/3-cities-turning-scooter-data-into-infrastructure-improvements/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907316</guid>
            <pubDate>Tue, 27 Oct 2020 13:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Islands Architecture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907279">thread link</a>) | @mwcampbell
<br/>
October 27, 2020 | https://jasonformat.com/islands-architecture/ | <a href="https://web.archive.org/web/*/https://jasonformat.com/islands-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p><img src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095361/krzysztof-grech-6orUY98fw9s-unsplash_r6wjnf.jpg"></p>



<p>I’ve struggled to find references to this online, but heard the name used multiple times this year when describing the approach outlined here.</p>

<p>The general idea of an “Islands” architecture is deceptively simple: render HTML pages on the server, and inject placeholders or slots around highly dynamic regions. These placeholders/slots contain the server-rendered HTML output from their corresponding widget. They denote regions that can then be "hydrated" on the client into small self-contained widgets, reusing their server-rendered initial HTML.</p>

<p>You can think of this like a static HTML document that contains multiple separate embedded applications:</p>

<p>  
<img width="600" src="https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-1.png">  
</p>

<p>This may seem similar to "micro-frontends" at first glance. Both approaches share the idea of breaking applications up into independent units, however "micro-frontends" do not typically imply that composition of those units is achieved using HTML.</p>

<p>A closer analog to the "islands" approach would be progressive enhancement, to which we're essentially adding SSR hydration and a consistent metaphor for adding interactivity to a region of the page. In traditional progressive enhancement, we might have a <code>&lt;script&gt;</code> that looks for an image carousel in the page and instantiates a jQuery plugin on it. Instead, that image carousel would be rendered on the server and a dedicated <code>&lt;script&gt;</code> emitted for it that loads the image carousel implementation and in-place upgrades it to be interactive.</p>

<h3 id="whydoesthismatter">Why does this matter?</h3>

<p>As it turns out, there are a number of benefits to the group of approaches described here when compared to typical Single Page Application architectures.</p>

<h5 id="progressivehydrationforfree">"Progressive Hydration" for free</h5>

<p>I’ve touted the performance benefits of <a href="https://www.youtube.com/watch?v=k-A2VfuUROg">Progressive Hydration</a> techniques for frameworks like React, Angular, Preact and Vue. With these architectures, individual widgets on a page are loaded and initialized over time. This can be done using a simple scheduling approach via requestIdleCallback, or can take additional factors into account like viewport visibility, interaction likelihood, product value, etc.</p>

<p>Similar to Progressive Hydration, rendering pages using an islands architecture results in the heavier dynamic portions of the page being initialized not just progressively, but <em>separately</em>. This means individual regions of the page become interactive without anything else on the page needing to be loaded first.</p>

<p>Unlike Progressive Hydration, the approaches that fall out of building around an islands architecture do not require top-down rendering. This is a distinct advantage, since there are no outer “root” components that must be initialized before their descendants. Each part of the page is an isolated unit, and a performance issue in one unit doesn't affect the others.</p>

<h5 id="seoanduxarentatradeoff">SEO and UX aren’t a tradeoff</h5>

<p>The status quo for SSR as used by Single Page Applications is that it’s often cited as a necessity for SEO reasons. However, SSR can actually have a net <em>negative</em> impact on User Experience - visitors are left waiting for the actual functionality of a page to arrive while staring at a frustratingly fake version of that page.</p>

<p>Many applications also suffer from silent SSR performance pitfalls without realizing it. In virtual DOM libraries, it's easy (and common) to accidentally construct a situation where first render destroys the server-rendered HTML DOM, only to recreate it again from scratch (often synchronously). This is the result of some common misconceptions, which may stem from documentation giving an idealized view of hydration while passing over tricky caveats and footguns.</p>

<p>Even in cases where SSR hydration is functioning as designed, the status quo leaves a lot to be desired. The amount of JavaScript work being performed during page load is still many orders of magnitude more than what might be considered "efficient".</p>

<figure>  
<img width="500" src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_1000/v1597095374/dave-hoefler-NYVc84Gh78I-unsplash_oqyquc.jpg">  
<figcaption><a href="https://unsplash.com/photos/NYVc84Gh78I" target="_blank">Photo by Dave Hoefler</a></figcaption>  
</figure>

<p>In an "islands" model, server rendering is not a bolt-on optimization aimed at improving SEO or UX. Instead, it is a fundamental part of how pages are delivered to the browser. The HTML returned in response to navigation contains a meaningful and immediately renderable representation of the content the user requested.</p>

<p>Sections of that HTML may be missing their client-side interactivity, but the document should at least contain the most essential content. For example: a news page’s HTML would contain the article body, and a product page would contain that product’s description.</p>

<p>All of the other content is secondary to this information, and its inclusion in the HTML becomes a product decision. How vital is this bit of information to a user visiting the page? How important is that widget to the business model? A "buy now" button that directly relates to revenue should be easily prioritized over a site feedback survey button that relates to information gathering.</p>

<h5 id="betterforaccessibilityanddiscoverability">Better for accessibility and discoverability</h5>

<p>A website that uses standard HTML links for navigation is easier for assistive technologies and web crawlers to use. This is true regardless of whether links or forms are intercepted by JavaScript and rerouted to client-side logic, because the underlying assumptions remain true: clicking a link navigates to the given page.</p>

<p>Anecdotally, think of the number of times you’ve been sent a “link” to what the sender assumed was the page they were viewing, only to realize the link contained none of the necessary information:</p>

<p>  
<img width="350" src="https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-3.png">  
</p>

<p>Building page-based applications doesn't completely prevent these types of strange experiences, it only makes the decision to do so more direct. It makes the default outcome the accessible one.</p>

<hr>

<p>When it comes down to it, shipping an architecture that requires less code to do something is the type of long-term benefit your future self (or coworkers) will thank you for. It's possible — likely, even — that adopting a model like this requires more up-front design thinking. There are far few batteries-included options available for decomposing apps into independently deliverable widgets. Who knows, maybe we can fix that.</p>

<figure>  
<img src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095373/max-hermansson-3AsAVTBIw5I-unsplash_t7bmip.jpg">  
<figcaption><a href="https://unsplash.com/photos/3AsAVTBIw5I" target="_blank">Photo by Max Hermansson</a></figcaption>  
</figure>


        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://jasonformat.com/islands-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907279</guid>
            <pubDate>Tue, 27 Oct 2020 13:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Entity Framework Core’s query cache works]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24907003">thread link</a>) | @cincura_net
<br/>
October 27, 2020 | https://www.tabsoverspaces.com/id/233841 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233841">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>How Entity Framework Core’s query cache works <a href="https://www.tabsoverspaces.com/id/233841" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 27 Oct 2020
	<span></span>
	<span aria-label="Time to read"></span> 3 mins
	<span></span>
	<span aria-label="Tags"></span> Entity Framework Core
</p>
<p>Last week, when <a href="https://www.tabsoverspaces.com/233837-net-developerdays-2020">speaking at .NET Developer Days</a>, I got a question about the query cache in Entity Framework Core – is it shared across <code>DbContext</code>s or is it per instance? With this question I realized I know how the cache work(ed) in Entity Framework 6, but I’m not entirely sure how it’s done in Entity Framework Core. Time to explore! And you can go with me.</p>
<!-- excerpt -->
<p>Let’s do some basic thinking first. Does it make sense to have query cache across instances? For the same <code>DbContext</code> type and hence same model (<code>IModel</code>) for sure. Could it be useful for different <code>DbContext</code>s? Maybe. Probably not. Although you can have, i.e. when using <em>bounded contexts</em>, <code>DbContext</code>s with overlap, the query would have to use only the overlapping part of the model and the cache would have to be able to work on fine granularity.</p>
<p>I’ll try to figure out the result only searching file names, types, content and reading pieces of code. Here we go.</p>
<p>The query cache should be in some file containing <em>query</em> and <em>cache</em> in its name, right? Luckily there’s a <code>CompiledQueryCache.cs</code>. Nice, there’s a <code>IMemoryCache</code> being used and the description states it is a <em>singleton</em>. And the <code>GetOrAddQuery</code> method already has the <em>key</em> as an input argument. This comes from <code>QueryCompiler</code> class and <code>ICompiledQueryCacheKeyGenerator.GenerateCacheKey</code> is used. The <code>CompiledQueryCacheKeyGenerator</code> is the implementation of that interface and it just returns instance of <code>CompiledQueryCacheKey</code>, which is defined as <code>protected readonly struct CompiledQueryCacheKey : IEquatable&lt;CompiledQueryCacheKey&gt;</code>. Cool. The equality is implemented as follows.</p>
<pre><code>public bool Equals(CompiledQueryCacheKey other)
{
    return ReferenceEquals(_model, other._model)
        &amp;&amp; _queryTrackingBehavior == other._queryTrackingBehavior
        &amp;&amp; _async == other._async
        &amp;&amp; ExpressionEqualityComparer.Instance.Equals(_query, other._query);
}

public override int GetHashCode()
{
    var hash = new HashCode();
    hash.Add(_query, ExpressionEqualityComparer.Instance);
    hash.Add(_model);
    hash.Add(_queryTrackingBehavior);
    hash.Add(_async);
    return hash.ToHashCode();
}
</code></pre>
<p>OK, so it’s checking the selected <a href="https://docs.microsoft.com/en-us/ef/core/querying/tracking"><em>tracking</em> behavior</a>, whether it’s <em>async</em> and finally the model plus query. The <code>ExpressionEqualityComparer</code> and specifically the <code>ExpressionComparer</code> seems to be checking whether the “structure” of the query is the same. Makes sense, the <em>canonical</em> version of the query is very likely done in another place. That leaves us only with <code>ReferenceEquals(_model, other._model)</code>.</p>
<p>Clearly this is comparing references, hence the question is whether the model (<code>IModel</code>) is somewhat cached between instances too. Again, probably the file is gonna have <em>model</em> and <em>cache</em> in its name. And there seems to be <code>IModelCacheKeyFactory</code> where the implementation <code>ModelCacheKeyFactory</code> is using just <code>ModelCacheKey</code>. And this class has a nice comment.</p>
<pre><code>///         A key that uniquely identifies the model for a given context. This is used to store and lookup
///         a cached model for a given context. This default implementation uses the context type as they key, thus
///         assuming that all contexts of a given type have the same model.
</code></pre>
<p>So, the <code>Type</code> of <code>DbContext</code> is used for equality comparisons.</p>
<p>And here you have it. When everything is put together, we can infer the query cache is using <code>IMemoryCache</code> as an implementation, it’s a <em>singleton</em> (aka shared across everything in Entity Framework Core) and caching key ultimately depends on the model, which is the same across same <code>DbContext</code>s.</p>

</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233841</link>
            <guid isPermaLink="false">hacker-news-small-sites-24907003</guid>
            <pubDate>Tue, 27 Oct 2020 13:07:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enormous security leak at the Rikssbanken and banks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906931">thread link</a>) | @Brajeshwar
<br/>
October 27, 2020 | https://nord.news/2020/10/27/enormous-security-leak-at-the-rikssbanken-and-banks/ | <a href="https://web.archive.org/web/*/https://nord.news/2020/10/27/enormous-security-leak-at-the-rikssbanken-and-banks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-25807">

	
<!-- .entry-header -->

	<figure>

		<p><img fifu-featured="1" width="1200" height="9999" src="https://i1.wp.com/static-cdn.sr.se/images/83/41c2f6f7-2399-4071-8a32-d279a77d8a6a.jpg?w=1200&amp;resize=1200%2C&amp;ssl=1&amp;is-pending-load=1" alt="" title="" loading="lazy" data-lazy-src="https://i1.wp.com/static-cdn.sr.se/images/83/41c2f6f7-2399-4071-8a32-d279a77d8a6a.jpg?w=1200&amp;resize=1200%2C&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
		</p><!-- .featured-media-inner -->

	</figure><!-- .featured-media -->

	
	<div>

		<div>

			<p>A data breach at the security company Gunnebo has led to large amounts of sensitive information about security systems around the world being published openly online.</p>
<p>This is what Dagens Nyheter reveals today.</p>

<p>These will be 38,000 files, including drawings of bank vaults, monitoring and alarm equipment and security functions for ATMs.</p>
<p>The intrusion must have taken place in August and include information for customers worldwide.</p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://nord.news/2020/10/27/enormous-security-leak-at-the-rikssbanken-and-banks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906931</guid>
            <pubDate>Tue, 27 Oct 2020 12:57:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gaming on Linux – Not Just for Hipsters]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906920">thread link</a>) | @thejokersthief
<br/>
October 27, 2020 | https://m1cr0man.com/posts/gaming-on-linux/ | <a href="https://web.archive.org/web/*/https://m1cr0man.com/posts/gaming-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>For the past 15 years I’ve been a very opinionated PC gamer, along with the rest of my family. However it’s always been a pain in some shape or form to <em>be</em> a PC gamer, be it with the constant software updates, the lack of first-party support, or just the general cost. I’m one of these people that has stuck to good old Windows 7 because a mobile UI on my gaming PC is what I imagine hell to be. I’ve had no problems thus far, but there are more and more 10-only games coming out by the day, and some of them are enticing an upgrade.</p>
<p>Fortunately, there has been a LOT of activity around Wine and Vulkan to get Windows games running on Linux, to the point where I scheduled some time this Christmas break to give it a shot. My goal was to run the few games I actually wanted to play (Elite Dangerous, Minecraft, Subnautica, Garry’s Mod) on Linux on a spare computer before the 25th, whilst also proving to my family of gamers that it was time to “break the glass” and get away from the proprietary OS.</p>
<h2 id="by-the-way-i-tried-to-use-arch">By the way I tried to use Arch</h2>

<p><a href="https://m1cr0man.com/posts/gaming-on-linux/images/2018-12-24-003401_1440x900_scrot.jpg"><img src="https://m1cr0man.com/posts/gaming-on-linux/images/2018-12-24-003401_1440x900_scrot_hue660b04f3b99512430f28cfa69e907e7_222930_0x384_resize_q85_gaussian.jpg" title="Desktop"></a></p><p>I don’t think it’s possible to ever finish installing Arch, you just get more things configured (and broken) over time. I started this week trying to set up a system with Steam installed and Linux compatible games running. It took a full day’s work to get through the numerous issues I encountered, but I eventually had Garry’s Mod launching, albeit with some weird error about <code>en_US.UTF8</code> not being available.</p>
<p>At that point, I wasn’t at all happy with the setup. I had a very minimal i3, a very broken version of Steam with all sorts of rendering issues, and one native Linux game limping along. I installed LXDE so that I had a window manager that cooperated with the concept of full screen graphics applications, but even with my high tolerance for outdated looking UIs I still couldn’t help but dislike the default theme. I spent a good few hours fixing that but it was still uncomfortable to use.</p>
<p>I tried setting up <a href="https://lutris.net/">Lutris</a> too. They recommend installing wine-staging which is no problem on Arch because you just grab the <a href="https://aur.archlinux.org/packages/wine-staging-git/">wine-staging AUR package</a> and job done. However I still couldn’t get it to launch any games due to all sorts of missing dependencies in Wine (and maybe due to my Donegal internet too).</p>
<p>When I realized I needed to install most 32 bit versions for everything I accepted defeat. It was going to be too much hassle to configure + maintain an Arch gaming install, and I’d never want to reload that machine. I took a night to think about it, then I broke up with Arch in the morning.</p>
<h2 id="solus-is-new-bae">Solus is new bae</h2>
<p>Whilst I was browsing around on Lutris, Reddit, and some other sites I kept seeing mentions of this new Debian based distro with some real fancy window manager. With my lack of motivation to do configuration myself my requirements were now very different as to when I picked Arch. However, with the need for a very new version of Steam + Wine in order to play games I needed something that had either frequent updates or a way to easily update manually.</p>
<p>The Solus website looked very appealing. “Designed for Home Computing”. Last time I read that I set up Mint on my granny’s laptop, and I don’t think she used it since. However something about the material design of its site and UI made me think it was at least worth a shot.</p>
<p>I downloaded the ISO, booted up a computer, and in about 10 minutes I had a running machine. This PC does have an SSD in it, but even so it took just 4 seconds to boot to the login screen! My mentality of it needing to be Arch to boot fast went right out the window.</p>
<p>I logged in and a lot of things were just working, which was great, but then again my expectations were very low coming from Arch. There was a remarkable lack of shit installed by default. LibreOffice is there but not GIMP, and there’s only 1 video player instead of 4. As a result I didn’t spend any time undoing defaults, which I had fully expected from a “home computing” distribution.</p>
<h2 id="who-needs-terminals">Who Needs Terminals?</h2>
<p>I got Steam and Proton installed again, this time with no hassle because I used the Solus Software Centre and it just worked. Whilst that was downloading I copied Garry’s Mod over from another Windows computer on the network through the file manager because apparently it just supports CIFS out of the box. I launched that game no problem, so then I started looking at Lutris again.</p>
<p>I was under the impression that I was going to need Lutris to play basically anything that wasn’t a Steam native Linux game. It turns out that is not entirely true. My next game goal was Elite Dangerous, so I copied it over the network too and Steam picked it up fine. Testing my luck I just hit “play” with the Steam Proton version set to the latest beta, but it did absolutely nothing. Then I tried launching it through Lutris. I got a bit suspicious when I saw the Steam install downloader pop up, and then I realized it was creating its own “prefix” for Steam Windows under Wine, ignoring the system version I had installed entirely.</p>
<p>So I wasn’t going to use Lutris for Elite then, and I got a bit worried. If it didn’t launch through Steam would it work at all? I searched around and saw lots of people trying to get it to work, and then I found <a href="https://github.com/ValveSoftware/Proton/issues/150">this Github issue</a> which lead to <a href="https://github.com/redmcg/wine/releases/tag/ED_Proton_3.16-6_Beta">this forked repo release</a>. With that, I had the game running flawlessly in like 20 minutes, and I even <a href="https://twitter.com/m1cr0m4n/status/1076614809414782976">tweeted about it</a>.</p>
<p>Other than installing the ED Proton fork, I had no need for a terminal during this process. I call that a testament to this OS. Generally, I only need a terminal when something breaks or something is more easily/quickly done at the prompt. My point being that if you were a Windows gamer trying to justify the conversion, you can rest assured that there is no need for any prior knowledge of Linux, or maybe even computers, to pull this off.</p>
<h2 id="real-work-on-solus">Real Work on Solus</h2>

<p><a href="https://m1cr0man.com/posts/gaming-on-linux/images/Screenshot%20from%202018-12-24%2001-20-04.jpg"><img src="https://m1cr0man.com/posts/gaming-on-linux/images/Screenshot%20from%202018-12-24%2001-20-04_huc4494bcc592d409b6b1867b12478b696_518421_0x384_resize_q85_gaussian.jpg" title="Solus"></a></p><p>It’s been so long since I used a “real” distro I can’t really separate what is unique to Solus from the common features you get nowadays. Setting up my networking and audio was painless. It’s Network Manager based networking with that regular GNOME GUI you see everywhere. You can control your audio volumes per-application from the pop out side bar in the UI. I noticed whilst I was installing all sorts of random stuff that the Solus not-a-start-menu was populating shortcuts and categories for everything. Also once I got the Nvidia driver installed everything like moving windows around was silky smooth. Honestly, I don’t think I want to use i3 any more.</p>
<p>With this level of confidence, I even went and setup my browser, IRC client, and a bunch of other stuff I would only do if I was committed to an install. What I wanted to try next was remote desktop gaming using TurboVNC, and I immediately encountered a problem. TurboVNC wasn’t in Solus' repositories so I was going to have to build it myself. I’m so glad I did.</p>
<p>Solus has a really nice YAML based system for developing packages. It does 90% of the work for you which is awesome. It will setup a build environment in a chroot, install dependencies, run commands, and generate a package all based on this one package.yaml. Their documentation on this setup is quite easy to follow, but I did pop into their IRC for a few questions.</p>
<p>I ended up building 3 packages for TVNC + its dependencies, and it didn’t take too long. From talking to a few developers and package maintainers, I’m quite tempted to submit + maintain these packages for Solus too. This blog post isn’t going to be about remote desktop gaming though so I’ll leave that for another day.</p>
<h2 id="convincing-the-family">Convincing the Family</h2>
<p>Over this weekend I played around 8 hours of Elite, whilst on Discord, on this really weirdly spec’d computer with an i3 2100 and a GTX 970. I had zero issues, both in setup and performance, and I spent way more time actually playing the games than I expected to.</p>
<p>When I mention the idea of using Linux to my brother, I always get an immediate no. “It’s for geeks”, “I can’t code”, “X won’t run on it”. I was able to prove him wrong on at least 2 of his points, but really it would be so much better if we all ran Linux. One of the biggest problems we have at the moment is that every time we make a significant hardware change to one of our computers, we have to reload the OS. We wouldn’t have to do that if we were running Solus on all the PCs. Also, Windows 7 isn’t exactly secure anymore. It hasn’t got real updates in like 2 years now, and we have turned them off before that to avoid breaking some games relying on old DRM (read: Securom) technology.</p>
<p>I don’t think it is going to take me much longer to convert every one given how much faster, simpler and prettier running a modern Linux distribution is. So long as I can prove that new and old games will work fine and continue to work when I’m not around I might be in for a chance of having a standardized boot image on all of our computers. This is appealing because living in Donegal you can’t be doing any sort of updates whilst playing games online otherwise your ping will go through the roof. You still have to do updates at some point, the question is how many times do you have to do them.</p>
<p>I’ll continue to test more games and work out a way I can easily deploy an entire Linux gaming setup to more computers. It is already exceptionally simple, but I need a turnkey solution to running Windows games on Steam that I can hand to people that have no idea what <code>ls</code> does.</p>

	</div></div>]]>
            </description>
            <link>https://m1cr0man.com/posts/gaming-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906920</guid>
            <pubDate>Tue, 27 Oct 2020 12:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build real-time search filtering with voice with React]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906877">thread link</a>) | @voiceux
<br/>
October 27, 2020 | https://www.speechly.com/docs/client-libraries/react-client/ | <a href="https://web.archive.org/web/*/https://www.speechly.com/docs/client-libraries/react-client/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <div>
      <h3 id="introduction">Introduction</h3>
<p>This tutorial will help you to get up and running with Speechly by guiding you through the process of building a simple voice filtering web app with Speechly and React.</p>
<p>You can find the source code for this tutorial <a href="https://github.com/speechly/react-example-repo-filtering">on GitHub</a> and you can also try out the final result <a href="http://speechly.github.io/react-example-repo-filtering/">hosted on GitHub Pages</a>.</p>
<h3 id="prerequisites">Prerequisites</h3>
<p>Since we’ll be using <a href="https://create-react-app.dev/docs/getting-started">create-react-app</a> for this tutorial, we’ll need the following tools:</p>
<ul>
<li>Node.js 8.10+</li>
<li>npm 5.2+</li>
</ul>
<p>Note that this tutorial also uses TypeScript, so feel free to check out <a href="https://www.typescriptlang.org/docs">TypeScript documentation</a> if you’re not familiar with it.</p>
<h3 id="1-creating-an-app">1. Creating an app</h3>
<p>Let’s get started by creating an app and installing its dependencies:</p>
<div><pre><code data-lang="sh">npx create-react-app speechly-voice-filter --typescript
<span>cd</span> speechly-voice-filter
npm i
</code></pre></div><p>Now that you’ve created the app, you can check it out by running <code>npm start</code> - it should open a browser tab with your app running in it.</p>
<h3 id="2-adding-data-and-layout">2. Adding data and layout</h3>
<p>Since we are building a filtering app, let’s add some data to filter and layout to display it.</p>
<p>To make it simple, our data source will be just a static array with some popular repositories on GitHub. Let’s add the following code and save it as <code>src/data.ts</code>:</p>
<div><pre><code data-lang="ts"><span>export</span> type Repository <span>=</span> {
  name: <span>string</span>;
  description: <span>string</span>;
  language: <span>string</span>;
  followers: <span>number</span>;
  stars: <span>number</span>;
  forks: <span>number</span>;
};

<span>export</span> <span>const</span> repositories: <span>Repository</span>[] <span>=</span> [
  {
    name<span>:</span> <span>"microsoft/typescript"</span>,
    description<span>:</span>
      <span>"TypeScript is a superset of JavaScript that compiles to clean JavaScript output"</span>,
    language<span>:</span> <span>"TypeScript"</span>,
    followers: <span>2200</span>,
    stars: <span>65000</span>,
    forks: <span>8700</span>,
  },
  {
    name<span>:</span> <span>"nestjs/nest"</span>,
    description<span>:</span>
      <span>"A progressive Node.js framework for building efficient, scalable, and enterprise-grade server-side applications on top of TypeScript &amp; JavaScript (ES6, ES7, ES8)"</span>,
    language<span>:</span> <span>"TypeScript"</span>,
    followers: <span>648</span>,
    stars: <span>30900</span>,
    forks: <span>2800</span>,
  },
  {
    name<span>:</span> <span>"microsoft/vscode"</span>,
    description<span>:</span> <span>"Visual Studio Code"</span>,
    language<span>:</span> <span>"TypeScript"</span>,
    followers: <span>3000</span>,
    stars: <span>105000</span>,
    forks: <span>16700</span>,
  },
  {
    name<span>:</span> <span>"denoland/deno"</span>,
    description<span>:</span> <span>"A secure JavaScript and TypeScript runtime"</span>,
    language<span>:</span> <span>"TypeScript"</span>,
    followers: <span>1700</span>,
    stars: <span>68000</span>,
    forks: <span>3500</span>,
  },
  {
    name<span>:</span> <span>"kubernetes/kubernetes"</span>,
    description<span>:</span> <span>"Production-Grade Container Scheduling and Management"</span>,
    language<span>:</span> <span>"Go"</span>,
    followers: <span>3300</span>,
    stars: <span>70700</span>,
    forks: <span>25500</span>,
  },
  {
    name<span>:</span> <span>"moby/moby"</span>,
    description<span>:</span>
      <span>"Moby Project - a collaborative project for the container ecosystem to assemble container-based systems"</span>,
    language<span>:</span> <span>"Go"</span>,
    followers: <span>3200</span>,
    stars: <span>58600</span>,
    forks: <span>16900</span>,
  },
  {
    name<span>:</span> <span>"gohugoio/hugo"</span>,
    description<span>:</span> <span>"The world’s fastest framework for building websites"</span>,
    language<span>:</span> <span>"Go"</span>,
    followers: <span>1000</span>,
    stars: <span>47200</span>,
    forks: <span>5400</span>,
  },
  {
    name<span>:</span> <span>"grafana/grafana"</span>,
    description<span>:</span>
      <span>"The tool for beautiful monitoring and metric analytics &amp; dashboards for Graphite, InfluxDB &amp; Prometheus &amp; More"</span>,
    language<span>:</span> <span>"Go"</span>,
    followers: <span>1300</span>,
    stars: <span>37500</span>,
    forks: <span>7600</span>,
  },
  {
    name<span>:</span> <span>"pytorch/pytorch"</span>,
    description<span>:</span>
      <span>"Tensors and Dynamic neural networks in Python with strong GPU acceleration"</span>,
    language<span>:</span> <span>"Python"</span>,
    followers: <span>1600</span>,
    stars: <span>43000</span>,
    forks: <span>11200</span>,
  },
  {
    name<span>:</span> <span>"tensorflow/tensorflow"</span>,
    description<span>:</span> <span>"An Open Source Machine Learning Framework for Everyone"</span>,
    language<span>:</span> <span>"Python"</span>,
    followers: <span>8300</span>,
    stars: <span>149000</span>,
    forks: <span>82900</span>,
  },
  {
    name<span>:</span> <span>"django/django"</span>,
    description<span>:</span> <span>"The Web framework for perfectionists with deadlines"</span>,
    language<span>:</span> <span>"Python"</span>,
    followers: <span>2300</span>,
    stars: <span>52800</span>,
    forks: <span>22800</span>,
  },
  {
    name<span>:</span> <span>"apache/airflow"</span>,
    description<span>:</span>
      <span>"Apache Airflow - A platform to programmatically author, schedule, and monitor workflows"</span>,
    language<span>:</span> <span>"Python"</span>,
    followers: <span>716</span>,
    stars: <span>18500</span>,
    forks: <span>7200</span>,
  },
];
</code></pre></div><p>We can display this data in a simple table, so let’s add a component for that under <code>src/RepoList.tsx</code>:</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;

<span>import</span> { Repository } from <span>"./data"</span>;

type Props <span>=</span> {
  repos: <span>Repository</span>[];
};

<span>export</span> <span>const</span> RepoList <span>=</span> ({ repos }<span>:</span> Props)<span>:</span> JSX.Element <span>=&gt;</span> {
  <span>return</span> (
    <span>&lt;</span>div className<span>=</span><span>"block"</span><span>&gt;</span>
      <span>&lt;</span>table<span>&gt;</span>
        <span>&lt;</span>thead<span>&gt;</span>
          <span>&lt;</span>tr<span>&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Name<span>&lt;</span><span>/th&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Language<span>&lt;</span><span>/th&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Description<span>&lt;</span><span>/th&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Followers<span>&lt;</span><span>/th&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Stars<span>&lt;</span><span>/th&gt;</span>
            <span>&lt;</span>th<span>&gt;</span>Forks<span>&lt;</span><span>/th&gt;</span>
          <span>&lt;</span><span>/tr&gt;</span>
        <span>&lt;</span><span>/thead&gt;</span>
        <span>&lt;</span>tbody<span>&gt;</span>
          {repos.map((repo) <span>=&gt;</span> (
            <span>&lt;</span>RepoRow repo<span>=</span>{repo} key<span>=</span>{repo.name} <span>/&gt;</span>
          ))}
        <span>&lt;</span><span>/tbody&gt;</span>
      <span>&lt;</span><span>/table&gt;</span>
    <span>&lt;</span><span>/div&gt;</span>
  );
};

<span>const</span> RepoRow <span>=</span> React.memo(
  ({ repo }<span>:</span> { repo: <span>Repository</span> })<span>:</span> JSX.Element <span>=&gt;</span> {
    <span>return</span> (
      <span>&lt;</span>tr<span>&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.name}<span>&lt;</span><span>/td&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.language}<span>&lt;</span><span>/td&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.description}<span>&lt;</span><span>/td&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.followers}<span>&lt;</span><span>/td&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.stars}<span>&lt;</span><span>/td&gt;</span>
        <span>&lt;</span>td<span>&gt;</span>{repo.forks}<span>&lt;</span><span>/td&gt;</span>
      <span>&lt;</span><span>/tr&gt;</span>
    );
  }
);
</code></pre></div><p>In order to show the table, we’ll need to render it. We could render our table right in our top-level <code>App</code> component, but let’s instead use a top-level component for our app under <code>src/SpeechApp.tsx</code> - it will come in handy later on:</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;

<span>import</span> { repositories } from <span>"./data"</span>;

<span>import</span> { RepoList } from <span>"./RepoList"</span>;

<span>export</span> <span>const</span> SpeechApp: <span>React.FC</span> <span>=</span> ()<span>:</span> JSX.Element <span>=&gt;</span> {
  <span>return</span> (
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>RepoList repos<span>=</span>{repositories} <span>/&gt;</span>
    <span>&lt;</span><span>/div&gt;</span>
  );
};
</code></pre></div><p>Now let’s add it to our top-level component:</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;
<span>import</span> { SpeechProvider } from <span>"@speechly/react-client"</span>;

<span>import</span> <span>"./App.css"</span>;

<span>import</span> { SpeechApp } from <span>"./SpeechApp"</span>;

<span>function</span> App()<span>:</span> JSX.Element {
  <span>return</span> (
    <span>&lt;</span>div className<span>=</span><span>"App"</span><span>&gt;</span>
      <span>&lt;</span>SpeechApp <span>/&gt;</span>
    <span>&lt;</span><span>/div&gt;</span>
  );
}

<span>export</span> <span>default</span> App;
</code></pre></div><h3 id="3-adding-speechly-client-and-a-microphone-button">3. Adding Speechly client and a microphone button</h3>
<p>Before we proceed with the app, let’s take a quick detour and train a very simple and not very useful Speechly app, so that we can use it to test our integration later on.</p>
<p>Go to <a href="https://speechly.com/dashboard">https://speechly.com/dashboard</a> and login (or sign up if you haven’t yet) and create a new app (you can <a href="https://www.speechly.com/docs/quick-start/">check our Speechly Dashboard quickstart guide</a> if you feel lost). Feel free to use any configuration you want, even an almost empty configuration with just “Hello world” will suffice, but make sure your app is deployed!</p>



<figure>
    <img src="https://www.speechly.com/docs/client-libraries/react-client/hello_world_config.png" alt="A simple Speechly configuration example"> <figcaption>
            <em>A simple Speechly configuration example</em>
        </figcaption>
</figure>
<p>Once you have your Speechly app deployed, let’s integrate it. Start by installing Speechly React client:</p>
<div><pre><code data-lang="sh">npm i --save @speechly/react-client
</code></pre></div><p>The client exposes a context provider and a hook that allows you to consume that context. Let’s add the context provider to <code>src/App.tsx</code>. Make sure you provide the <code>App ID</code> of your Speechly app as a property for <code>SpeechProvider</code>!</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;
<span>import</span> { SpeechProvider } from <span>"@speechly/react-client"</span>;

<span>import</span> <span>"./App.css"</span>;

<span>function</span> App()<span>:</span> JSX.Element {
  <span>return</span> (
    <span>&lt;</span>div className<span>=</span><span>"App"</span><span>&gt;</span>
      <span>&lt;</span>SpeechProvider appId<span>=</span><span>"your-app-id-here"</span> language<span>=</span><span>"en-US"</span><span>&gt;</span>
        <span>&lt;</span>SpeechApp <span>/&gt;</span>
      <span>&lt;</span><span>/SpeechProvider&gt;</span>
    <span>&lt;</span><span>/div&gt;</span>
  );
}

<span>export</span> <span>default</span> App;
</code></pre></div><p>Next, let’s add some code to act as the microphone button. Also, it would be nice to see what we are saying, so let’s also render the transcript next to the button for some feedback. Let’s make that a separate component and save it as <code>src/Microphone.tsx</code>:</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;
<span>import</span> {
  Word <span>as</span> SpeechWord,
  SpeechSegment,
  SpeechState,
} from <span>"@speechly/react-client"</span>;

type Props <span>=</span> {
  segment?: <span>SpeechSegment</span>;
  state: <span>SpeechState</span>;
  onRecord<span>:</span> () <span>=&gt;</span> Promise<span>&lt;</span><span>void</span><span>&gt;</span>;
};

<span>export</span> <span>const</span> Microphone <span>=</span> React.memo(
  ({ state, segment, onRecord }<span>:</span> Props)<span>:</span> JSX.Element <span>=&gt;</span> {
    <span>let</span> enabled <span>=</span> <span>false</span>;
    <span>let</span> text <span>=</span> <span>"Error"</span>;

    <span>switch</span> (state) {
      <span>case</span> SpeechState.Idle:
      <span>case</span> SpeechState.Ready:
        <span>enabled</span> <span>=</span> <span>true</span>;
        text <span>=</span> <span>"Start"</span>;
        <span>break</span>;
      <span>case</span> SpeechState.Recording:
        <span>enabled</span> <span>=</span> <span>true</span>;
        text <span>=</span> <span>"Stop"</span>;
        <span>break</span>;
      <span>case</span> SpeechState.Connecting:
      <span>case</span> SpeechState.Loading:
        <span>enabled</span> <span>=</span> <span>false</span>;
        text <span>=</span> <span>"Loading..."</span>;
        <span>break</span>;
    }

    <span>return</span> (
      <span>&lt;</span>div<span>&gt;</span>
        <span>&lt;</span>button onClick<span>=</span>{onRecord} disabled<span>=</span>{<span>!</span>enabled}<span>&gt;</span>
          {text}
        <span>&lt;</span><span>/button&gt;</span>
        <span>&lt;</span>Transcript segment<span>=</span>{segment} <span>/&gt;</span>
      <span>&lt;</span><span>/div&gt;</span>
    );
  }
);

<span>const</span> Transcript <span>=</span> React.memo(
  ({ segment }<span>:</span> { segment?: <span>SpeechSegment</span> })<span>:</span> JSX.Element <span>=&gt;</span> {
    <span>if</span> (segment <span>===</span> <span>undefined</span>) {
      <span>return</span> (
        <span>&lt;</span>div<span>&gt;</span>
          <span>&lt;</span>em<span>&gt;</span>Waiting <span>for</span> speech input...<span>&lt;</span><span>/em&gt;</span>
        <span>&lt;</span><span>/div&gt;</span>
      );
    }

    <span>return</span> (
      <span>&lt;</span>div<span>&gt;</span>
        {segment.words.map((w) <span>=&gt;</span> (
          <span>&lt;</span>Word word<span>=</span>{w} key<span>=</span>{w.index} <span>/&gt;</span>
        ))}
      <span>&lt;</span><span>/div&gt;</span>
    );
  }
);

<span>const</span> Word <span>=</span> React.memo(
  ({ word }<span>:</span> { word: <span>SpeechWord</span> })<span>:</span> JSX.Element <span>=&gt;</span> {
    <span>if</span> (word.isFinal) {
      <span>return</span> <span>&lt;</span>strong<span>&gt;</span>{<span>`</span><span>${</span>word.value<span>}</span><span> `</span>}<span>&lt;</span><span>/strong&gt;;</span>
    }

    <span>return</span> <span>&lt;</span>span<span>&gt;</span>{<span>`</span><span>${</span>word.value<span>}</span><span> `</span>}<span>&lt;</span><span>/span&gt;;</span>
  }
);
</code></pre></div><p>As you can see, this component renders a button that calls the <code>onRecord</code> callback passed in the properties and uses the state of Speechly client to determine when to enable the button and which text to use as its label. In addition to that, the component also renders the transcript of the phrase by assembling individual transcripted words from a segment (check out <a href="https://www.speechly.com/docs/speechly-api/#understanding-server-responses">this article in our documentation</a> for more information about how SLU API works). Since a word can be either tentative (i.e., its value can change as the API receives more audio data) or final, we use bold text to highlight final words.</p>
<p>One more step - we’d need to render our component and hook it up to the API. Let’s add it to our <code>SpeechApp</code> component:</p>
<div><pre><code data-lang="tsx"><span>import</span> React from <span>"react"</span>;
<span>import</span> { useSpeechContext } from <span>"@speechly/react-client"</span>;

<span>import</span> { repositories } from <span>"./data"</span>;

<span>import</span> { RepoList } from <span>"./RepoList"</span>;
<span>import</span> { Microphone } from <span>"./Microphone"</span>;

<span>export</span> <span>const</span> SpeechApp: <span>React.FC</span> <span>=</span> ()<span>:</span> JSX.Element <span>=&gt;</span> {
  <span>const</span> { toggleRecording, speechState, segment } <span>=</span> useSpeechContext();

  <span>return</span> (
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>Microphone
        …</code></pre></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.speechly.com/docs/client-libraries/react-client/">https://www.speechly.com/docs/client-libraries/react-client/</a></em></p>]]>
            </description>
            <link>https://www.speechly.com/docs/client-libraries/react-client/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906877</guid>
            <pubDate>Tue, 27 Oct 2020 12:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Takeaway Tuesday – Stand Up Straight with Your Shoulders Back]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24906813">thread link</a>) | @stanrivers
<br/>
October 27, 2020 | https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight | <a href="https://web.archive.org/web/*/https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Takeaway Tuesday</strong>&nbsp;on&nbsp;<strong><a href="https://amzn.to/2HaaKeZ">12 Rules for Life</a> - Rule 1: Stand Up Straight with Your Shoulders Back</strong></p><p><em>We appreciate all our subscribers’ ongoing support. Please continue to share with those who might also enjoy receiving our free newsletter. Any suggested materials for our Sunday newsletter can be sent to <a href="https://newsletter.butwhatfor.com/cdn-cgi/l/email-protection" data-cfemail="21524e4248404d6143545556494055474e530f424e4c0f">[email&nbsp;protected]</a> Thank you!</em></p><p><strong><a href="https://www.butwhatfor.com/jordan-peterson/">Jordan B. Peterson</a></strong>&nbsp;is a Canadian clinical psychologist and psychology professor at the University of Toronto who became a controversial figure in late-2016 for his critiques of political correctness. Peterson’s most recent book, 12 Rules for Life, has sold over 3 million copies worldwide. Most recently, Peterson has suffered from health issues that necessitated a year-long reprieve from the public eye.</p><h4><strong>Success compounds, meaning those that win tend to continue to win</strong></h4><p>Lobsters are interesting animals, but most people don’t think about them too often. <a href="https://www.smithsonianmag.com/science-nature/dont-listen-to-the-buzz-lobsters-arent-actually-immortal-88450872/">While they may not be immortal as many like to think</a>, they never stop growing and can regenerate lost limbs. Unfortunately for them, they taste good with butter - but let’s circle back to lobsters here in a minute.</p><p>In the early 1900s, an Italian engineer, sociologist, economist, political scientist, and philosopher (but he was probably no fun at parties, so you got him there) named <a href="https://en.wikipedia.org/wiki/Vilfredo_Pareto#Economic_concepts">Vilfredo Pareto</a> became fascinated by the ideas of wealth and power - namely, how is wealth distributed across society? (Interestingly, he did not start this work until his forties, <a href="https://newsletter.butwhatfor.com/p/takeaway-friday-a-stoic-philosopher">so it is never too late to make a difference</a>.)</p><p>Ever diligent, he pulled data from the 1400s through his modern times and found the same pattern everywhere. Whereas people had previously assumed that wealth would be distributed in a flat, upward-sloping line from poor to rich, what Pareto found was in fact a hockey stick - a small percentage of the population holds a majority of the wealth.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png&quot;,&quot;height&quot;:400,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:110387,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p>This kind of distribution - the most successful / most productive / largest “winners” continuously having a greater chunk of the pie - can be seen across many different fields.</p><blockquote><p>That same brutal principle of unequal distribution applies outside the financial domain—indeed, anywhere that creative production is required. The majority of scientific papers are published by a very small group of scientists. A tiny proportion of musicians produces almost all the recorded commercial music. Just a handful of authors sell all the books. A million and a half separately titled books (!) sell each year in the US. However, only five hundred of these sell more than a hundred thousand copies. Similarly, just four classical composers (Bach, Beethoven, Mozart, and Tchaikovsky) wrote almost all the music played by modern orchestras. Bach, for his part, composed so prolifically that it would take decades of work merely to hand-copy his scores, yet only a small fraction of this prodigious output is commonly performed...</p><p>It also applies to the population of cities (a very small number have almost all the people), the mass of heavenly bodies (a very small number hoard all the matter), and the frequency of words in a language (90 percent of communication occurs using just 500 words), among many other things. Sometimes it is known as the Matthew Principle (Matthew 25:29), derived from what might be the harshest statement ever attributed to Christ: “to those who have everything, more will be given; from those who have nothing, everything will be taken.”</p></blockquote><p>This idea was further expanded in the mid-1900s when British physicist <a href="https://en.wikipedia.org/wiki/Derek_J._de_Solla_Price">Derek Price</a> noticed that certain of his colleague were prolific publishers and others - well, not so much. In fact, Price could fit most domains of publication to a “law” stating that half of all papers are written by the square root of the number of all writers - if you had 100 papers written by 25 people, 50 papers would have been written by only 5 individuals. If it was 1,000 papers and 250 people, 500 papers were written by only 16 people. Thus, there was always an active minority generating the majority of the work.</p><p>These results can be understood as it relates to the compounding effects of resources - those that have previously “won” generally have access to the greatest resources and can more easily utilize those resources to achieve additional success. Those without resources cannot. </p><p>Thus, resources beget additional resources while losing resources restricts your ability to gain resources in the future - <em>winners are more likely to win again, and losers more likely to lose</em>.</p><p>However, there is also something going on in the brain that makes those that win more likely to pursue meaningful, productive activities again in the future.</p><h4>Your brain is aware of where you are within the winner-loser continuum and makes plans based on where it thinks you sit</h4><p>Back to the lobsters. Lobsters live in a cold, brutal world where things such as ideal lobster nests (think “safe hiding places”) and access to food are both paramount and scarce. This scarcity can result in conflict. So how do you determine which lobsters lay claim to the best nests?</p><p>As you might have guessed, they fight for them - and Peterson goes into detail on lobster confrontation rituals in his book. Important to this conversation is what happens in the brains of lobsters that win and lobsters that lose.</p><blockquote><p>A lobster loser’s brain chemistry differs importantly from that of a lobster winner. This is reflected in their relative postures. Whether a lobster is confident or cringing depends on the ratio of two chemicals that modulate communication between lobster neurons: serotonin and octopamine. Winning increases the ratio of the former to the latter.</p><p>A lobster with high levels of serotonin and low levels of octopamine is a cocky, strutting sort of shellfish, much less likely to back down when challenged. This is because serotonin helps regulate postural flexion. A flexed lobster extends its appendages so that it can look tall and dangerous, like Clint Eastwood in a spaghetti Western…</p><p>High serotonin/low octopamine characterizes the victor. The opposite neurochemical configuration, a high ratio of octopamine to serotonin, produces a defeated-looking, scrunched-up, inhibited, drooping, skulking sort of lobster, very likely to hang around street corners, and to vanish at the first hint of trouble.</p></blockquote><p>The lobster’s brain knows whether it just lost or won a fight. The victor confidently holds himself up high and the loser shirks from potential conflict. And this makes sense - it is advantageous to your survival to avoid conflict if you tend to lose because 1) you tend to lose and 2) having lost, you now have access to less advantageous resources (food and shelter). The winner is confident in his access to resources and knows, based on experience, that he can win future fights.</p><p>These changes in how the lobster orients itself to the world start deep within its brain, with levels of serotonin driving physical changes in the external lobster. This brain infrastructure is very similar to what sits inside humans, who also take into account where they are in the “tend to win and have resources / tend to lose and don’t have resources” continuum.</p><blockquote><p>The part of our brain that keeps track of our position in the dominance hierarchy is therefore <a href="https://newsletter.butwhatfor.com/p/takeaway-tuesday-knowing-history">exceptionally ancient and fundamental</a>.&nbsp;It is a master control system, modulating our perceptions, values,&nbsp;emotions, thoughts and actions…</p><p>The ancient part of your brain specialized for assessing dominance watches how you are treated by other people. On that evidence, it renders a determination of your value and assigns you a status. If you are judged by your peers as of little worth, the counter restricts serotonin availability. That makes you much more physically and psychologically reactive to any circumstance or event that might produce emotion, particularly if it is negative. You need that reactivity. Emergencies are common at the bottom, and you must be ready to survive.</p></blockquote><p>If you are lower on the totem pole, being constantly prepared for emergencies eventually takes its toll on you given your orientation towards short-term survival at the expense of long-term success. It impacts everything, from the way your body allocates resources to its immune system (long-term investment) to your fight-or-flight response sensitivity (expensive short-term preparedness). </p><p>But this all makes sense for the competitive world our ancestors grew up in. </p><blockquote><p>Unfortunately, that physical hyper-response, that constant alertness, burns up a lot of precious energy and physical resources. This response is really what everyone calls stress, and it is by no means only or even primarily psychological. It’s a reflection of the genuine constraints of unfortunate circumstances. When operating at the bottom, the ancient brain counter assumes that even the smallest unexpected&nbsp;impediment might produce an uncontrollable chain of negative events, which will have to be handled alone, as useful friends are rare indeed, on society’s fringes. You will therefore continually sacrifice what you could otherwise physically store for the future, using it up on heightened readiness and the possibility of immediate panicked action in the present… The physical demands of emergency preparedness will wear you down in every way.</p><p>If you have a high status, on the other hand, the counter’s cold, pre-reptilian mechanics assume that your niche is secure, productive and safe, and that you are well buttressed with social support. It thinks the chance that something will damage you is low and can be safely discounted. Change might be opportunity, instead of disaster. The serotonin flows plentifully. This renders you confident and calm, standing tall and straight, and much less on constant alert. Because your position is secure, the future is likely to be good for you. It’s worthwhile to think in the long term and plan for a better tomorrow.</p></blockquote><h4>Feedback loops can both hurt you and help you</h4><p>This whole process is an example of an <a href="https://en.wikipedia.org/wiki/Autocatalysis#:~:text=A%20single%20chemical%20reaction%20is,is%20called%20an%20autocatalytic%20reaction.">autocatalytic reaction</a> - a chemical reaction where one of the reaction products (in this case “losing”) …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight">https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight</a></em></p>]]>
            </description>
            <link>https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906813</guid>
            <pubDate>Tue, 27 Oct 2020 12:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Notion Landing Pages]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24906774">thread link</a>) | @saviorand
<br/>
October 27, 2020 | https://optemization.com/notion-landing-page-guide | <a href="https://web.archive.org/web/*/https://optemization.com/notion-landing-page-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="notion-landing-page-guide"><div id="4ef8369dd07944578af5ecae07585f8f"><div id="ec8a50571edc41dea01826949daf52b2"><p><span><span>We at Optemization know a thing or two about  Notion landing pages. In fact, Tem published the first Notion website back in March 2020 (oh, how the world has changed). </span></span></p><p><span><span>Thanks in large to awesome projects like Super and Fruition, building websites on Notion became easier and faster. </span></span></p><p><span><span>Given the surge in popularity, I deciced to pen this comprehensive guide and create some duplicable blocks, so you can create your own Notion website in no time — enjoy 🙌</span></span></p></div></div><h2><span id="cc149452e88b42e8b29622443a589d9c"></span><span><span>🔑 An overview of the guide</span></span></h2><div id="c496b9ce8126498e85222feb210e850b"><div id="4e7f6e020650473a8d103736b9068090"><p><span><span>Making a landing page with Notion is easy to the point of enjoyable — you don't need any coding skills at all. It's also flexible — you can mix, match, and style various blocks to get the look and feel needed to present your idea (or product) just the right way.</span></span></p><p><span><span>This guide will walk you through every step of setting up your landing with Notion, publishing it to the web, adding analytics and custom styling. As a cherry on top, we've also curated 10 ready-made components that you can use to get your Notion landing page out in no time.</span></span></p></div></div><h2><span id="4b158c7e538e49518051b4d9b3d1f780"></span><span><span>🎯 Setting your landing page goals</span></span></h2><p><span><span>Landing pages are the best way to "sell" something, to tell people about a specific product, service or a resource, and make them do a specific action. </span></span></p><p><span><span>When user does an action, this is called "conversion", and usually landing pages are fine-tuned to get as much conversions as possible. Conversions could be anything: from subscribing to a newsletter or joining a community, to buying a product or a service. Landing pages can be purely informational, too. </span></span></p><p><span><span>Think what's the purpose of your page, and what the user needs to do to contribute.</span></span></p><h2><span id="cbfc301b7d274e27a06afc720d7eb511"></span><span><span>🤔 Deciding on what to show on the landing page</span></span></h2><p><span><span>Defining your goal was the hard part — after you know what action you want the user to make, it's easy to define what to show on your landing. </span></span></p><p><span><span>If they're subscribing to a newsletter, tell what it's about. If the goal is to grow a community, tell about the people already there and show what's the purpose of this community. If you're selling a product, focus on the value it offers and on core functionality. Don't forget call-to-actions to let the user actually realize their interest when they're convinced.</span></span></p><p><span><span>Take a look at </span><span><a target="_blank" rel="noopener noreferrer" href="https://demandcurve.com/#1opac8uusrjldfqjb39wpp">Demand Curve</a></span><span>'s landing page, for example. </span></span></p><div id="54fa9f431f9a45fc970d6e7fc90bf338"><picture><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>They're advertising their start-up program, focusing on what the program is about, how it's structured and why people learn valuable things during that program. It's all there — right on the first screen you can see the bullet points describing what the program is about (Growth Strategy, Ads, etc.).</span></span></p><p><span><span>Demand Curve's team also put a special emphasis on social proof — there's a ton of different testimonials and stories from people on the page.</span></span></p><p><span><span>Sometimes short landing pages that span 1-2 screens have higher conversion that longer ones, that span 3 and more screens. When you need your user to perform a simple action, like sharing their email, a short page works better. Short landings also make more sense for "warm" clients who already know what you are offering.</span></span></p><p><span><span>Longer landings with lots of information work better for "cold" clients, because they need more context. After you have an idea on what size is appropriate in your case, you can start experimenting with content.</span></span></p><h2><span id="3812d49b74904f9d961961ff3c8b07b9"></span><span><span>🖋️ Adding some content</span></span></h2><p><span><span>On a typical landing page, the information is arranged into standard "blocks" with valuable information:  there's an eye-catching Hero image, simple text blocks describing your value proposition, a call-to-action that lets you collect interest, and a footer with terms. </span></span></p><p><span><span>Like on </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.refactoringgrowth.com/">Refactoring Growth</a></span><span>'s landing page, you have an elaborate introduction, several sections with a value proposition (simple text) block and a picture or a graphic, a pricing block and a Call-to-Action.</span></span></p><div id="c32142c387d44b52b7995b22ae6c17c9"><picture><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Optionally, you can add more useful stuff. It's a good idea to include social proof (which is very important for conversions and creates a sense of community around your value prop), juicy product shots or screenshots and a blog section linking to your posts somewhere else. </span></span></p><div id="d3e8989030c247cba938e6e513c95e1d"><picture><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500" alt="image" loading="lazy"></picture></div><h2><span id="f07e89f0db6c4c5188083b57316e7685"></span><span><span>🎁 Ready-made landing page blocks</span></span></h2><p><span><span>We've assembled some common sections in Notion so you can borrow them for your website.</span></span></p><p><span><span>Just open the component you like below, click on the bookmark, then click "Duplicate" and drag your component's page into any page you like. Select "Turn into", then "text". You've got your landing page! Add some space between the blocks, change the content and delete the toggle. Then customize it as you like.</span></span></p><p><span><span>Here's a 53-second demo: </span></span></p><p><span><span>Mix and match the blocks and add your own section to make your own converting landing page in 10 minutes.</span></span></p><h2><span id="dbfa3c0dca5f4aada94f5376166f8281"></span><span><span>🌐 Publish your page to the web </span></span></h2><p><span><span>It's easy to publish your page and make it accessible from a custom domain. 
We like two services: </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">Fruition</a></span><span> is free and open-source, while </span><span><a target="_blank" rel="noopener noreferrer" href="https://super.so/">Super</a></span><span> offers more functionality and better performance. </span></span></p><p><span><span>Fruition has a </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">very elaborate guide</a></span><span> right on their home page, and a </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=aw0x54PzCaI">video tutorial</a></span><span>, and Super gives a good onboarding when you sign up, leading you through all the necessary steps. 

</span><span><span>Here's a step-by-step to get you going on Super:</span></span></span></p><ol><li id="30fa5f0ef68b4ad79354c951f1b9aba1"><span><span>Sign up, select a plan (essentially boils down to how many sites you need, keep in mind that one site can have many subpages, like any website on the Web)
</span></span></li><li id="787193987a0b4c7c95437a027e1bd716"><span><span>Select whether you want to make a static website out of your page, or go with a default Notion-based method. 

First option offers great performance, but doesn't allow for filtered views and calendars on your page. 

Default Notion page is relatively poor in terms of performance and SEO, but all Notion functionality will work and it's still enough for simple personal websites or pages where you don't need fast loading.
</span></span></li><ol></ol><li id="e44a993f1fce466193429d780f87fd90"><span><span>Select your site name used in Super, a custom domain from a domain provider, and the URL to your original Notion page with the page set to public via the "Share" menu at the top ("Share" → "Share to the Web")
</span></span></li><li id="2aa6fd185ae9449084ed3674d150ac83"><span><span>Add one or more pretty URLs if you need them. By default, all the sub-pages you add inside your home page will have ugly Notion URLs. You can change that by providing links to sub-pages you want to add slugs to and specifying the slug (e.g. </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/preconceived">optemization.com/preconceived</a></span><span>)
</span></span></li><li id="ff4df464b80145149fe1675f38702e2b"><span><span>Add A and CNAME records to point Super to your domain name (Super provides these and you need to enter them in your domain provider's control panel). You can also provide an API Key if it's GoDaddy.</span></span></li><ol></ol><li id="52d2dce988b94c798bc7fafc30303552"><span><span>Enter your site's description, attach an image and an icon for social sharing. You can also select a custom font for your page's contents at this point.
</span></span></li></ol><p><span><span>Voila! The site should now be public. You're awesome.</span></span></p><h2><span id="728b3a07a7f3429b818b7992351d8dfa"></span><span><span>🔢 Add analytics</span></span></h2><p><span><span>With both Super and Fruition, you can inject your own Javascript into your page. This means you can use most of analytics solutions available.</span></span></p><p><span><span>For example, you can get your Fathom Analytics script to inject by going to Settings → Site → Site ID. Here's their own Fathom's </span><span><a target="_blank" rel="noopener noreferrer" href="https://usefathom.com/support/tracking">instruction</a></span><span>. Google Analytics also has a global site tag you can inject. </span></span></p><p><span><span>Both look like this (from Super's landing):</span></span></p><pre id="c777ed719650472ea7f2d1bb17322dd3"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://cdn.analytics.com"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span></code></pre></span></code></pre><p><span><span>After you copy and paste the script into the right field in Super or with Fruition, it should should auto-magically start collecting your stats and you'll be able to see them in your analytics dashboard. These are statistics we measure for </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/">optemization.com</a></span><span>:</span></span></p><h2><span id="4b1780ab79904f75abb4ecda48f54fd6"></span><span><span>✨Add styling </span></span></h2><p><span><span>In theory, with Super or Fruition you can style practically any part of your page. One of the simple things to do is to change default Notion colors. To change any color on your page just add a script (the same way you add an analytics script) that replaces Notion's CSS values.</span></span></p><p><span><span><a target="_blank" rel="noopener noreferrer" href="https://demo.super.so/guides/colors">Super</a></span><span> has a great mini-guide on doing that, below is the script with every default Notion color. Just replace the color you want to change with a HEX value (#000 for black, #fff for white) and delete the rest to change colors for a site hosted with Super (Fruition works the same way).</span></span></p><details id="cd15c584098c4a26b2e6aeadc95bd312"><summary><span><span>Notion's core colors (check the full list here: </span><span><span><a id="/fed8e0f6059d469fadaeeac47812b6e7" href="https://optemization.com/fed8e0f6059d469fadaeeac47812b6e7"><div><p><img src="https://super.so/icon/dark/hexagon.svg" alt="Notion Colors"></p><p><span><span>Notion Colors</span></span></p></div></a></span></span><span>)</span></span></summary><div><pre id="675898bed12c4045ac7bdd3c20ed3ae3"><code><span><pre><code><span>&lt;</span><span>style</span><span>&gt;</span><span>
</span><span>  </span><span>:</span><span>root </span><span>{</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>:</span><span> #</span><span>37352</span><span>f</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.6</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>gray</span><span>:</span><span> #</span><span>9</span><span>b9a97</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>brown</span><span>:</span><span> #</span><span>64473</span><span>a</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>orange</span><span>:</span><span> #d9730d</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>yellow</span><span>:</span><span> #dfab01</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>green</span><span>:</span><span> #</span><span>0</span><span>f7b6c</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>blue</span><span>:</span><span> #</span><span>0</span><span>b6e99</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>purple</span><span>:</span><span> #</span><span>6940</span><span>a5</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>pink</span><span>:</span><span> #ad1a72</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>red</span><span>:</span><span> #e03e3e</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>default</span><span>:</span><span> #fff</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>:</span><span> #ebeced</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>:</span><span> #e9e5e3</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>:</span><span> #faebdd</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>:</span><span> #fbf3db</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>:</span><span> #ddedea</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>:</span><span> #ddebf1</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>:</span><span> #eae4f2</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>:</span><span> #f4dfeb</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>:</span><span> #fbe4e4</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>235</span><span>,</span><span>236</span><span>,</span><span>237</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>229</span><span>,</span><span>227</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>250</span><span>,</span><span>235</span><span>,</span><span>221</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>243</span><span>,</span><span>219</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>237</span><span>,</span><span>234</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>235</span><span>,</span><span>241</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>234</span><span>,</span><span>228</span><span>,</span><span>242</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>244</span><span>,</span><span>223</span><span>,</span><span>235</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>228</span><span>,</span><span>228</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>default</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>206</span><span>,</span><span>205</span><span>,</span><span>202</span><span>,</span><span>0.5</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>gray</span><span>:</span><span> </span><span>hsla</span><span>(</span><span>45</span><span>,</span><span>2</span><span>%</span><span>,</span><span>60</span><span>%</span><span>,</span><span>0.4</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>brown</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>140</span><span>,</span><span>46</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>orange</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>245</span><span>,</span><span>93</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>yellow</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>168</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>green</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>135</span><span>,</span><span>107</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>blue</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>120</span><span>,</span><span>223</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>purple</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>103</span><span>,</span><span>36</span><span>,</span><span>222</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>pink</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>0</span><span>,</span><span>129</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>red</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>255</span><span>,</span><span>0</span><span>,</span><span>26</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>ui</span><span>-</span><span>hover</span><span>-</span><span>bg</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.08</span><span>)</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span></span><span>&lt;</span><span>/</span><span>style</span><span>&gt;</span></code></pre></span></code></pre></div></details><h2><span id="86c16edd25c04182b7d14ae872bed16d"></span><span><span>🍾 Add a pop-up Call-to-Action block</span></span></h2><p><span><span>We've made an opinionated CTA block you can use to ask your user to sign up at some point when they engage with the page. This one is shown 3 seconds after the page is opened (change the "3000" value inside the window.onload to adjust the duration).</span></span></p><div id="735cc70d16a944f19b754c5ed6b73d83"><picture><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Simply include the following script in your Super or Fruition "Inject scripts" section, similar to how you included analytics:</span></span></p><pre id="567243414569454490cb895f08584391"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://unpkg.com/sweetalert/dist/sweetalert.min.js"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>// Thanks Sweetalert for the alert! </span><span>
</span><span></span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>window</span><span>.</span><span>on…</span></code></pre></span></code></pre></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://optemization.com/notion-landing-page-guide">https://optemization.com/notion-landing-page-guide</a></em></p>]]>
            </description>
            <link>https://optemization.com/notion-landing-page-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906774</guid>
            <pubDate>Tue, 27 Oct 2020 12:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research team discovers breakthrough with potential to reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24906758">thread link</a>) | @elorant
<br/>
October 27, 2020 | https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary’s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer’s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer’s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>“The significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer’s disease benefits can’t be overstated,” says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer’s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer’s disease is driven by a vicious cycle of the protein amyloid β (Aβ) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn’t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen’s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer’s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>“We treated them for a month and the effect was quite amazing,” says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer’s disease. “We couldn’t tell the drug-treated disease models and the healthy models apart.” </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, noting the next step will be clinical trials in people.</span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906758</guid>
            <pubDate>Tue, 27 Oct 2020 12:32:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hive Time finances and pay-what-you-want videogame pricing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906735">thread link</a>) | @homarp
<br/>
October 27, 2020 | http://cheesetalks.net/hive-time-finances.php | <a href="https://web.archive.org/web/*/http://cheesetalks.net/hive-time-finances.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="backgroundWrapper">
		
		
		<div id="pageContent">
			<p>In Beecember last year, I released a bee-themed management simulator called <a href="http://hivetime.twolofbees.com/">Hive Time</a>. For this project, I was in a position to commit to pay-what-you-want pricing. Now that the game's been out for a while and its lifetime sales curve feels established, I wanted to take some time to reflect on how that's gone.</p>

			<p><img src="http://cheesetalks.net/images/hive-time-finances/banner.png" alt="Money for the honey! A look at Hive Time's finances and pay-what-you-want pricing."></p><p>Hive Time is a bee themed management sim in which players build and maintain a sustainable bee hive. It's a niche game that aims to provide a sandbox experience in which players can explore and experiment role diversity with a generational community once they've mastered the sustainability requirement of producing enough Royal Jelly to spawn a new Queen. It's punctuated by humour and zany characters who from time to time upset the balances that players work to achieve.</p>

			<p>This article dives into Hive Time's budget, costs, marketing, and revenue between the game's release in December 2019 and reaching a sales milestone in July 2020.</p>

			<ul>
				<li><a href="#before-we-begin">Before we begin</a></li>
				<li><a href="#budget-none-costs-some">Budget: None, Costs: Some</a></li>
				<li><a href="#finding-a-price-point">Finding a price point</a></li>
				<li><a href="#overcoming-launch-hurdles">Overcoming launch hurdles</a></li>
				<li><a href="#spreading-the-word">Spreading the word</a></li>
				<li><a href="#money-for-the-honey">Money for the honey</a></li>
				<li><a href="#player-platforms">Player platforms</a></li>
				<li><a href="#what-worked-and-what-didnt">What worked and what didn't</a></li>
				<li><a href="#if-wishes-were-horseflies">If wishes were horseflies</a></li>
				<li><a href="#direct-reflections">Direct reflections</a></li>
			</ul>
			<br>

			<h2 id="before-we-begin">Before we begin</h2>

			<p>Before diving in, this article needs to be prefaced with a few important notes:</p>
			<ul>
				<li>I don't mind talking about money, but I absolutely despise fixating on it. This has been a difficult article to write.</li>
				<li>So as to stay on topic, I'll avoid diving into what worked/didn't work about the game itself (as opposed to its marketing, its identity, and its "performance") as much as possible.</li>
				<li>My overheads and living costs are significantly low and are not indicative of typical development costs.</li>
				<li>I'm very happy to have worked on Hive Time and am glad that it has been played and enjoyed by so many people.</li>
				<li>Every game is different, every audience is different, and the specifics of the context in which every game exists are different.</li>
				<li>Hive Time's budget and expenses involve multiple currencies. Where unspecified, assume Australian dollars.</li>
				<li>From one perspective, I did everything discussed in this article myself, but realistically, every player, every journalist, every youtuber, every streamer, every tester, and my four collaborators contributed to Hive Time's post-release identity. Without them, my game would have sat unknown, unloved, and (so far as what's relevant to this article goes) unbought.</li>
			</ul>


			<p><a href="#pageContent">↑return to page top↑</a></p><h2 id="budget-none-costs-some">Budget: None, Costs: Some</h2>

			<p>After completing the <a href="https://www.patreon.com/posts/small-project-26593300">10 day jam</a> that <a href="https://twitter.com/mimlofbees">Mim</a> and I initially prototyped Hive Time for in May 2019, I took most of the rest of the month to weigh up continuing development against getting back onto other outstanding projects. Based on positive responses to the progress I'd been sharing and tester feedback, I decided to move ahead and plan out a zero dollar budget and rough six month timeline for development.</p>

			<p>Initially, my budget was comprised of my own labour donated in-kind with the expectation of recouping my labour costs after release. Mim was undecided about contributing further art, but preferred to donate her contributions if that happened (it did). With this approach, I'm free from having to worry about money as a tangible development resource, which is generally how I prefer it when I'm working solo. It also means that if a project doesn't sell a single copy, I don't have any debts or other obligations that I'd need to invest more unpaid work into fulfilling.</p>

			<p>For the sake of similar simplicity, I also considered things like plant and equipment, utilities costs, and exhibiting costs as out of scope for the budget since all of those were things that I already owned or could justify as being covered by other projects. I bought my primary workstation and travel laptop years ago, we would be paying for home power and internet regardless, and I have a big tub worth of spare mice and keyboards, cables, adapters, tablecloths, A4 table stands, etc. left over from exhibiting other games in the past. Since I was working from home, I didn't have office rent to worry about (but I did have to ignore my mortgage for a little while). These are all real overheads that should not be ignored, but are outside the scope of what I will be covering here - in this case, there's so much overlap with my personal living expenses and they're low enough that I could comfortably pay them out of Hive Time revenue if it makes enough that I can pay myself the equivalent of Australia's <a href="https://www.fwc.gov.au/documents/wage-reviews/2018-19/decisions/c20191-order.pdf">National Minimum Wage</a>.</p>

			<p><img src="http://cheesetalks.net/images/hive-time-finances/field_recording_r_stephens_apiarists.jpg" alt="Me recording bees at R. Stephens Apiarists in Mole Creek, Tasmania (photo courtesy of Mim)."></p><p>Me recording bees at R. Stephens Apiarists in Mole Creek, Tasmania (photo courtesy of <a href="https://twitter.com/mimlofbees">Mim</a>)</p>

			<p>I use Free/Open Source software for all of my development tools, and though I donate and contribute upstream to some projects, I've chosen to not include that in the budget since that's something I'd be doing regardless. The tools I used for developing Hive Time were the <a href="https://godotengine.org/">Godot Engine</a>, <a href="https://www.blender.org/">Blender</a>, the <a href="https://gimp.org/">GNU Image Manipulation Program</a>, <a href="https://inkscape.org/">Inkscape</a>, and <a href="https://www.audacityteam.org/">Audacity</a>.</p>

			<p>I was hoping to submit Hive Time to the 2020 PAX Australia Indie Showcase, which I would have had to have allocated a travel budget for (exhibiting costs are typically covered for showcase winners), but since PAX Aus didn't happen this year and PAX Online's Indie Showcase was <a href="https://twitter.com/ValiantCheese/status/1274166825056518144">only available to games on Steam</a>, that became one less expense to worry about.</p>

			<p>I did spend about $175 on some <a href="https://twitter.com/ValiantCheese/status/1209741464726454273">business cards</a>, but given that a global pandemic is not the best time to be handing things around to people or circulating in contexts where one would normally hand things out, they've sat unused. Since some very extenuating circumstances prevented me from using them, we can pretend for the purposes of this article that I didn't buy them.</p>

			<p>Although I had planned to do everything myself and only rely on Mim for things she was interested in contributing along the way, I found myself bringing on board other collaborators who helped elevate the project in ways that I wouldn't have been able to on my own.</p>

			<p>When <a href="http://www.kestrelpi.co.uk/">Peter</a> expressed interest in composing a soundtrack and demonstrated that he understood and had enthusiasm for the project, I decided to give him the opportunity. I wanted to be sure I could pay him adequately, so I dug into <a href="https://www.patreon.com/Cheeseness">Patreon</a> funds that I'd planned to use for <a href="http://winterswake.com/">Winter's Wake</a> with the expectation that based on general enthusiasm for the project, I should be able to make that back as a minimum from Hive Time's revenue. As <a href="https://kestrelpi.bandcamp.com/album/hive-time">the soundtrack</a> expanded and took shape, we decided to produce a human-voiced version of the Beatles homage "Beeing Together," which carried some extra costs for a vocalist and recording time.</p>

			<p><img src="http://cheesetalks.net/images/hive-time-finances/queen_portrait_event.png" alt="The initial Queen portrait that shipped in the first version of Hive Time."></p><p>Several days before release, I had resolved to cut a feature that adorned the Throne Room with portraits of passed Queens in order to keep my workload manageable. During an unrelated conversation, <a href="https://twitter.com/AubreySerr">Aubrey</a> offered to help out, painting the <a href="https://twitter.com/ValiantCheese/status/1204911573564706816">initial portrait</a> that appeared in 1.0-x releases as well as the eight portraits that were added in the <a href="https://cheeseness.itch.io/hive-time/devlog/147869/v11-the-informational-update">Informational Update</a>. Aubrey has doggedly refused to let me pay him, but he has kindly given me an indicative rate to use in this article.</p>

			<p>I also gave out around a hundred or so keys before release to people interested in giving feedback on/playing early builds. I've had to rely on volunteer testing for projects in the past, and had a <a href="https://twitter.com/ValiantCheese/status/1207441828619776000">solid core group</a> of experienced testers who've enjoyed working with me in the past enough to want to contribute their invaluable attention. Ideally, I'd like to be in a position to do paid QA/testing on my games and give back to these people, but sadly, that wasn't an option for this project. As I didn't audit their work or demand a minimum amount of attention, I have no way of gauging even a rough figure for the amount of hours these people have invested in Hive Time (it could be as little as ten, or it could be hundreds or thousands), and so I'll be leaving QA out (aside from my own testing as part of development/bug fixing, but as with proof reading, you're much less likely to find the holes in your own work).</p>

			<p>Prior to release, but after the bulk of development was completed, I was contacted by an arts funding agency that was getting into games. After some discussion and reading terms, I decided to decline the recoupable investment they were offering. Since I'd already spent all the money I was going to spend, and paying back that investment pro-rata would just erode my revenue until it was paid back, it didn't feel like a good fit. I could potentially have used that funding to produce more content, but I had a release date more or less locked in, and it didn't make sense to push things back just so that I could get a loan of money I didn't need. I also considered using it to cover localisation, but with some rough post-release development making the game's content a moving target, I didn't want to commit to localising into languages I don't speak until after the game has made enough money to support itself (otherwise the risk is that I'd just end up shipping the game in more languages that it could be unsuccessful in).</p>


			<table>
				<thead>
					<tr>
						<th>Item</th>
						<th>Note</th>
						<th>Contributor</th>
						<th>Cost</th>
						<th>Deduction</th>
					</tr>
				</thead>
				<tfoot>
					<tr>
						<td>Totals</td>
						<td></td>
						<td></td>
						<td>$25,131.37</td>
						<td>-$20,956.85</td>
					</tr>
					<tr>
						<td>Adjusted</td>
						<td></td>
						<td></td>
						<td>$4,174.52</td>
						<td></td>
					</tr>
				</tfoot>
				<tbody>
					<tr>
						<td>Release development</td>
						<td>1000 hours at $19.49</td>
						<td>Cheese</td>
						<td>$19,490.00</td>
						<td>-$19,490.00</td>
					</tr>
					<tr>
						<td>Additional event art </td>
						<td>15 hours at $19.49</td>
						<td>Mim</td>
						<td>$292.35</td>
						<td>-$292.35</td>
					</tr>
					<tr>
						<td>Soundtrack</td>
						<td>£1,778 + currency conversion fees</td>
						<td>Peter</td>
						<td>$3,539.48</td>
						<td>$0.00</td>
					</tr>
					<tr>
						<td>Beeing Together</td>
						<td>£319 + currency conversion fees</td>
						<td>Peter</td>
						<td>$635.04</td>
						<td>$0.00</td>
					</tr>
					<tr>
						<td>Queen portrait</td>
						<td>1 painting at $200</td>
						<td>Aubrey</td>
						<td>$200.00</td>
						<td>-$200.00</td>
					</tr>
					<tr>
						<td>Misc admin, bug fixing, promotion, etc.</td>
						<td>50 hours at $19.49</td>
						<td>Cheese</td>
						<td>$974.50</td>
						<td>-$974.50</td>
					</tr>
				</tbody>
			</table>
			<p>Initial release costs</p>

			<table>
				<thead>
					<tr>
						<th>Item</th>
						<th>Note</th>
						<th>Contributor</th>
						<th>Cost</th>
						<th>Deduction</th>
					</tr>
				</thead>
				<tfoot>
					<tr>
						<td>Totals</td>
						<td></td>
						<td></td>
						<td>$3,910.42</td>
						<td>-$3,860.84</td>
					</tr>
					<tr>
						<td>Adjusted</td>
						<td></td>
						<td></td>
						<td>$49.58</td>
						<td></td>
					</tr>
				</tfoot>
				<tbody>
					<tr>
						<td>Informational Update development</td>
						<td>100 hours at $19.49</td>
						<td>Cheese</td>
						<td>$1,949.00</td>
						<td>-$1,949.00</td>
					</tr>
					<tr>
						<td>Informational Update trailer music</td>
						<td>USD$34.50 (no conversion fees)</td>
						<td>Peter</td>
						<td>$49.58</td>
						<td>$0.00</td>
					</tr>
					<tr>
						<td>Informational Update trailer art</td>
						<td>8 hours at $19.49</td>
						<td>Mim</td>
						<td>$155.92</td>
						<td>-$155.92</td>
					</tr>
					<tr>
						<td>Additional Informational Update art</td>
						<td>8 hours at $19.49</td>
						<td>Mim</td>
						<td>$155.92</td>
						<td>-$155.92</td>
					</tr>
					<tr>
						<td>Informational Update Queen portraits</td>
						<td>8 paintings at $200</td>
						<td>Aubrey</td>
						<td>$1,600.00</td>
						<td>-$1,600.00</td>
					</tr>
				</tbody>
			</table>
			<p>Informational update costs</p>


			<p><a href="#pageContent">↑return to …</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://cheesetalks.net/hive-time-finances.php">http://cheesetalks.net/hive-time-finances.php</a></em></p>]]>
            </description>
            <link>http://cheesetalks.net/hive-time-finances.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906735</guid>
            <pubDate>Tue, 27 Oct 2020 12:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Youtubedown Downloads from YouTube]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906669">thread link</a>) | @ZnZirconium
<br/>
October 27, 2020 | https://blog.spiralofhope.com/15309/youtubedown.html | <a href="https://web.archive.org/web/*/https://blog.spiralofhope.com/15309/youtubedown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
	<div id="main" role="main">
													
<article id="post-15309">

	<div>
					<h2>youtubedown</h2>				
    <div>
            <p><a href="https://blog.spiralofhope.com/tag/commandline-software" rel="tag">commandline software</a>, <a href="https://blog.spiralofhope.com/tag/free-software" rel="tag">free software</a>, <a href="https://blog.spiralofhope.com/tag/freeware" rel="tag">freeware</a>, <a href="https://blog.spiralofhope.com/tag/glances" rel="tag">Glances</a>, <a href="https://blog.spiralofhope.com/tag/jamie-zawinskis-software" rel="tag">Jamie Zawinski's software</a>, <a href="https://blog.spiralofhope.com/tag/liked" rel="tag">liked</a>, <a href="https://blog.spiralofhope.com/tag/linux-software" rel="tag">Linux software</a>, <a href="https://blog.spiralofhope.com/tag/open-source-software" rel="tag">open-source software</a>, <a href="https://blog.spiralofhope.com/tag/perl-software" rel="tag">Perl software</a>, <a href="https://blog.spiralofhope.com/tag/vimeo" rel="tag">Vimeo</a>, <a href="https://blog.spiralofhope.com/tag/youtube" rel="tag">YouTube</a>          </p></div>
	</div>

	<div>
		<p><a href="https://blog.spiralofhope.com/11643/software.html">Software</a> (<a href="https://blog.spiralofhope.com/1721/youtube.html">YouTube</a>) &gt; </p>
<p><a href="https://www.jwz.org/hacks/youtubedown" target="_blank">https://www.jwz.org/hacks/youtubedown</a></p>
<p>Given a <a href="https://blog.spiralofhope.com/1721/youtube.html">YouTube</a> or <a href="https://blog.spiralofhope.com/12477/vimeo.html">Vimeo</a> URL, downloads the underlying video file, with a sensible file name. It downloads the highest resolution version of the video available: first it tries HD MP4, then regular MP4, then WebM, and finally FLV. It also works on playlists, and works as a <a href="https://blog.spiralofhope.com/22505/bookmarklets.html">bookmarklet</a> to download the video you're watching.</p>
<p>I liked it well enough.</p>

<hr>
<ul>
<li>
<p><a href="#2016-03-18">2016-03-18 - (version not recorded)</a> on <a href="https://blog.spiralofhope.com/3866/lubuntu.html">Lubuntu</a> (version not recorded)</p>
</li>
</ul>


<p>Usage:</p>
<pre>.<span>/</span>youtubedown.pl &nbsp;https:<span>//</span>www.youtube.com<span>/</span><span>watch</span>\?v\=jNQXAC9IVRw</pre>
<p><a href="#footnote_plugin_reference_15309_1"><sup id="footnote_plugin_tooltip_15309_1" onclick="footnote_moveToAnchor('footnote_plugin_reference_15309_1');">[&nbsp;1&nbsp;]</sup></a><span id="footnote_plugin_tooltip_text_15309_1"> 2020-10-29 - The URL format may be an anomaly from the automatic-modification that my <a href="https://blog.spiralofhope.com/3017/zsh.html">Zsh</a> does.  It may just be <code>https://www.youtube.com/watch?v=jNQXAC9IVRw</code> </span> </p>
<p>For higher quality stuff, it begs for <a href="https://blog.spiralofhope.com/6366/ffmpeg.html">FFmpeg</a>.</p>
<pre>\<span>sudo</span> &nbsp;\<span>apt-get</span> &nbsp;<span>install</span> &nbsp;<span>ffmpeg</span></pre>
	</div>

  

</article>
				



						</div><!-- end main -->

	<!-- end sidebar -->
</div></div>]]>
            </description>
            <link>https://blog.spiralofhope.com/15309/youtubedown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906669</guid>
            <pubDate>Tue, 27 Oct 2020 12:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LeoFS – A Storage System for a DataLake and the Web]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906665">thread link</a>) | @GordonS
<br/>
October 27, 2020 | http://leo-project.net/leofs/ | <a href="https://web.archive.org/web/*/http://leo-project.net/leofs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="features">
      <div>
        <!-- SECTION-1 -->
        <p>
          <h3>What's New</h3>
        </p>

        <div>
          <div>
            <h3>LeoFS v1.4</h3>
            <h4><a href="https://github.com/leo-project/leofs/releases/tag/1.4.3" target="_blank">Released LeoFS v1.4.3 on February 20, 2019</a></h4>
            <h4>Status: Stable</h4>
            <h4>New features:</h4>
            <h5>Improve AWS S3-API Compatibility</h5>
            <ul>
              <li>AWS Signature v4 support</li>
              <li>Custom metadata support</li>
            </ul>
            <h5>Improve NFS v3 support</h5>
            <ul>
              <li>Improving the performance and stability</li>
            </ul>
            <h5>Integration</h5>
            <ul>
              <li>Improving Spark integration</li>
            </ul>
          </div>

          <div>
            <h3>Data Lake</h3>
            <p>LeoFS moved a step closer to <a href="https://en.wikipedia.org/wiki/Data_lake" target="_blank">Data Lake</a> with <a href="https://github.com/leo-project/leofs#milestones" target="_blank">v1.4</a>. We're aiming to achieve a highly beneficial effect to Big Data analytics as a data repository.</p>
            <p><img src="http://leo-project.net/leofs/img/architecture/leofs-datalake.20160809.jpeg" width="480px">
          </p></div>
        </div>

        <!-- SECTION-2 -->
        <div id="service_1">
          <div id="resources">
            <p>
              <h3>Resources</h3>
            </p>
            <div>
              
              <div>
                <div>
                  <div>
                    <h6><img src="http://leo-project.net/leofs/img/icons/flat/github-10-32.png">&nbsp;Code</h6>
                    <p>Built for and maintained by the community via <a href="https://github.com/leo-project/leofs" target="_blank">GitHub</a>. LeoFS's license is <a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank">Apache V2</a>.</p>
                    
                    <p>We provide all LeoFS-related codes on <a href="https://github.com/leo-project">GitHub</a>, there are <i>"no magic black boxes"</i>.</p>
                    
                  </div>
                </div>
              </div>
              
            </div>
          </div>
        </div>

        <!-- SECTION-3 -->
        <p id="latest_articles">
          <h3>Latest Articles</h3>
        </p>
        
        <!-- SECTION-4 -->
        
        <!-- SECTION-5 -->
        
        <!-- SECTION-5.end -->
      </div>
    </div></div>]]>
            </description>
            <link>http://leo-project.net/leofs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906665</guid>
            <pubDate>Tue, 27 Oct 2020 12:17:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Dr GPT-3 see you now?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906655">thread link</a>) | @l5t
<br/>
October 27, 2020 | https://www.nabla.com/blog/gpt-3/ | <a href="https://web.archive.org/web/*/https://www.nabla.com/blog/gpt-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You may have heard about GPT-3 this summer, the new cool kid on the AI block. GPT-3 came out of OpenAI, one of the top AI research labs in the world which was founded in late 2015 by Elon Musk, Sam Altman and others and later backed with a $1B investment from Microsoft.</p>
<p>You’ve probably also heard about the ongoing AI revolution in healthcare, thanks to promising results in areas such as automated diagnosis, medical documentation and drug discovery, to name a few.
Some have claimed that algorithms now outperform doctors on <a href="https://hbr.org/2019/10/ai-can-outperform-doctors-so-why-dont-patients-trust-it">certain tasks</a> and others have even announced that robots will soon receive <a href="https://www.forbes.com/sites/insights-intelai/2018/09/21/the-ultimate-physicians-assistant/">medical degrees</a> of their own! This can all sound far-fetched... but could this robot actually be GPT-3?</p>
<p>Our unique multidisciplinary team of doctors and machine learning engineers at Nabla had the chance to test this new model to tease apart what’s real and what’s hype by exploring different healthcare use cases.</p>
<p><img src="https://www.nabla.com/uploads/gp0.jpg" alt="Primary care and GPT-3"></p>
<h2>But first, coffee</h2>
<p>In machine learning, a language model like GPT-3 simply tries to predict a word in a sentence given the previous words, called the context. It’s a supercharged autocomplete system like the one you may use with Gmail. Being able to predict the next word in a sentence seems deceptively simple at first, but this actually enables many compelling use cases, such as chatbots, translation or Q&amp;A.</p>
<p>At the time of writing, GPT-3 is the most complex language model ever trained, with a whopping 175 billion parameters in total - that’s as many knobs that are fine-tuned over weeks of intensive cloud computing to make the AI magic work. Certainly a huge number, but still way below the 100 (or maybe 1000+) trillion synapses in the human brain that enable reasoning, perception and emotions.</p>
<p>Thanks to the large size of the model, GPT-3 can be applied on new tasks and ‘few-shot’ demonstrations without any further fine-tuning on specific data. In practice, this means the model can successfully understand the task to perform with only a handful of initial examples. This property is a huge improvement compared to previous, less complex language models, and is much closer to actual human behavior - we don’t need thousands of examples to distinguish a cat from a dog.</p>
<p>Despite obvious biases learned from the data used for training - basically books plus the whole Internet, from Wikipedia to the New York Times - GPT-3's ability to transform natural language into websites, create basic financial reports, solve langage puzzles, or even generate guitar tables has been very promising so far. But what about healthcare?</p>
<h2>Then, the obvious disclaimer</h2>
<p>As Open AI itself warns in GPT-3 guidelines, healthcare “is in the high stakes category because people rely on accurate medical information for life-or-death decisions, and mistakes here could result in serious harm”. Furthermore, diagnosing medical or psychiatric conditions falls straight in the “unsupported use” of the model. Despite this we wanted to give it a shot and see how it does on the following healthcare use cases, roughly ranked from low to high sensitivity from a medical perspective: admin chat with a patient, medical insurance check, mental health support, medical documentation, medical questions &amp; answers and medical diagnosis. We also looked at the impact of some parameters of the model on the answers - spoiler alert, it’s fascinating!</p>
<h2>GPT-3, your next medical assistant?</h2>
<p>Our first tests showed that GPT-3 seemed to work for basic admin tasks such as appointment booking, but when digging a bit we found that the model had no clear understanding of time, nor any proper logic. Its memory also sometimes fell short - for the appointment in the example below, the patient’s initial 6pm constraint is overlooked as GPT-3 suggests booking for 7pm after a few messages.</p>
<p><img src="https://www.nabla.com/uploads/gp1.jpg" alt="Medical assistant example with GPT-3"></p>
<h2>What about insurance checks?</h2>
<p>Similar to the admin tasks above, GPT-3 could help nurses or patients to quickly find a piece of information in a very long document, like finding insurance benefits for specific medical examinations. In the example below we seeded the model with a 4-page standard benefits table that shows a $10 copay for an X-ray, $20 for an MRI exam, and then asked 2 simple questions. GPT-3 was able to get the copay for an X-ray but could not sum up the copays for several exams, which again highlights a lack of basic reasoning.</p>
<p><img src="https://www.nabla.com/uploads/gp2.jpg" alt="Insurance checks example with GPT-3"></p>
<h2>Recycle to relieve stress!</h2>
<p>Relax on your living room sofa and talk, GPT-3 will listen to your problems endlessly and may even give you some actionable tips! This is probably one of the best use cases for GPT-3 in healthcare, and it’s not so surprising given the already good results from the Eliza algorithm back in 1966, which managed to give a human touch with only pattern matching rules operating behind the scenes.</p>
<p>One key difference between the two approaches though is that rule-based systems like Eliza were in full control of the computer’s response. In other words, we are certain that nothing potentially harmful could be said.</p>
<p>This contrasts with the example below in which GPT-3 sadly tells us that committing suicide is a good idea…</p>
<p><img src="https://www.nabla.com/uploads/gp4.jpg" alt="Kill switch example with GPT-3"></p>
<p>The model can also shoot unexpected answers where it suggests recycling more to ease stress - using a rationale which, while being convoluted, is actually quite sensible!</p>
<p><img src="https://www.nabla.com/uploads/gp3.jpg" alt="Recycling and stress example with GPT-3"></p>
<h2>Medical documentation</h2>
<p>GPT-3 has already shown promising results in summarizing and simplifying text, something that could be very useful for patients to understand medical reports often full of jargon, or for doctors to quickly get the gist of a patient’s long medical history. Well, GPT-3 is probably not quite ready for this (yet?). Our tests show dangerous oversimplifications, difficulties to associate causes and consequences, and once again a lack of basic deductive reasoning.</p>
<h2>Medical Q&amp;A: not as good as good ol’ Google yet</h2>
<p>When looking for specific scientific information, drug dosages or prescription support, our experiments show that GPT-3 is not reliable enough to be safely used as a trustworthy support tool for doctors. One serious concern is that GPT-3 very often gives wrong yet grammatically correct answers, with no scientific reference that a physician could check. A tired doctor caught in the rush of an emergency department could easily confuse a syntactically sound statement for a medically valid one. For example the first answer below is correct but not the second.</p>
<p><img src="https://www.nabla.com/uploads/gp5.jpg" alt="Q&amp;A medical example with GPT-3"></p>
<h2>Diagnosis: at your own risk</h2>
<p>A more complex Q&amp;A task is diagnosis: input symptoms and get possible underlying conditions that may explain these symptoms. Recent symptom checker systems (Babylon, Ada, KHealth, etc.), if not perfect, seem to be a better option here than GPT-3 as they’ve been carefully optimized for this sole purpose. One benefit of these systems is that they can output different diagnoses with their probabilities, which acts as a measure of confidence for the practitioner. If the first diagnosis example below GPT-3 ignores the fever of the little girl that suggests ethmoiditis and mentions a “rash” that does not exist.</p>
<p><img src="https://www.nabla.com/uploads/gp6.jpg" alt="Medical diagnosis 1 example with GPT-3"></p>
<p>In another test, GPT-3 misses a pulmonary embolism. Fortunately nobody died here!</p>
<p><img src="https://www.nabla.com/uploads/gp7.jpg" alt="Medical diagnosis 2 example with GPT-3"></p>
<h2>Under the hood</h2>
<p>As others have observed, the quality of GPT-3 outputs is much impacted by the seed words used - the same question formulated in two different ways can result in very different answers. The model’s various parameters, such as the temperature and the top P also play a big role. Temperature and top P control the risks and creativity that the engine will exhibit in its answers.</p>
<h3>Temperature</h3>
<p>For the same input and a high temperature we get two answers with very different tones telling two opposite things. Here is an example with T = 0.9.</p>
<p><img src="https://www.nabla.com/uploads/gp8.jpg" alt="High temperature parameter and GPT-3"></p>
<p>By contrast, a similar seed with a very low temperature (T = 0) will always result in the same and quite straightforward answer.</p>
<p><img src="https://www.nabla.com/uploads/gp9.jpg" alt="Low temperature parameter and GPT-3"></p>
<h3>Frequency penalty and presence penalty</h3>
<p>It is also pertinent to mention the frequency penalty and presence penalty parameters, which prevent both word repetition and subject repetition. In a medical context, the intuition would be to reduce them as much as possible since a too abrupt subject switch can be very confusing and repetition can actually be pedagogical. However, comparing two conversations where the human asks the same questions, we clearly observe that the model with repetition penalties seems more empathic and friendly than the other one which appears cold and too repetitive to be human. Here is an example with no penalty.</p>
<p><img src="https://www.nabla.com/uploads/gp10.jpg" alt="No penalty parameter and GPT-3"></p>
<p>And an example with full penalty.</p>
<p><img src="https://www.nabla.com/uploads/gp11.jpg" alt="Full penalty parameter and GPT-3"></p>
<h2>Conclusion</h2>
<p>As warned by OpenAI, we are nowhere near any real time scenario where GPT-3 would significatively help in healthcare. Because of the way it was trained, it lacks the scientific and medical expertise that would make it useful for medical documentation, diagnosis support, treatment recommendation or any medical Q&amp;A. Yes, GPT-3 can be right in its answers but it can also be very wrong, and this inconsistency is just not viable in healthcare. Even for more administrative tasks such as translating or summarizing medical jargon, GPT-3 while promising is still many moons away for a production use case actually supporting doctors. We’re still in this phase where multiple, narrow-task supervised models win over a single, very ambitious approach.</p>
<p>That being said, GPT-3 seems to be quite ready to fight burnout and help doctors with a chit-chat module. It could bring back the joy and empathy you would get from a conversation with your medical residents at the end of the day, that conversation that helps you come down to earth at the end of a busy day. Also, there is no doubt that language models in general will be improving at a fast pace, with a positive impact not only on the use cases described above but also on other important problems, such as information structuring and normalisation or automatic consultation summaries.</p>
<p>And at Nabla, we are working on it!<br>
<strong><em>Thanks to Megan Mahoney (Clinical Professor at Stanford University School of Medicine and Chief of Staff of Stanford Health Care) and Yann LeCun for reading drafts of …</em></strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nabla.com/blog/gpt-3/">https://www.nabla.com/blog/gpt-3/</a></em></p>]]>
            </description>
            <link>https://www.nabla.com/blog/gpt-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906655</guid>
            <pubDate>Tue, 27 Oct 2020 12:15:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Happening to the Supply Chain?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906572">thread link</a>) | @imartin2k
<br/>
October 27, 2020 | https://digitstodollars.com/2020/10/27/what-is-happening-to-the-supply-chain/ | <a href="https://web.archive.org/web/*/https://digitstodollars.com/2020/10/27/what-is-happening-to-the-supply-chain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The Global Electronics supply chain is in a strange place right now. Ostensibly the world’s economy is slowing down with massive unemployment all over and surging Covid cases in many parts of the world.  Despite that, if you try to buy many types of electronic components you will find lead times extending into next year and outright shortages of all kinds of components. </p>



<p>There are a few things going on here. First, despite the lockdowns, or maybe because of them, people are still buying a lot of electronics. There are definite signs that consumers have been stocking up on gadgets as they fit out their Zoom lairs. It is also the season of the year when all the new phones come out ahead of Christmas and Chinese New Year. Components are always tight around this time as the big handset and PC companies gear up their production for Holiday orders. As one component vendor told us “If your name is not Apple, you probably can’t get that part.”</p>



<p>On top of that, many suppliers are operating under capacity constraints as a result of Covid shutdowns. China has largely opened up again, but many companies there are still racing to catch up after months of being closed. </p>



<p>This has not only caused a direct shortage, but it has had a large indirect impact as large component buyers worried about shortages started “double ordering” a few months back. That is to say, they ordered more than they really thought they would need to make sure they were at the head of the line when parts get rationed out. This problem occurs every few years, but is particularly acute this year for all the standard 2020 reasons. </p>



<p>On top of that, there is Huawei. Huawei ordered as many components as they could ahead of the US sanctions. There are all kinds of examples of this from TSMC all the way down. And of course, their stockpiling fed into the double ordering panic above. </p>



<p>Making matters worse, every company we speak to in China is worried that they are next. This is not wholly rational, but then again, Uncertainty is the order of the day. So there are dozens of large Chinese companies stockpiling parts, just in case they come under the scrutiny of the Eye of the US Government. And of course, this feeds into all the factors above. </p>



<p>One of the hardest parts of all this is that it is so hard to predict. The Global Electronics Supply Chain is complicated. Take a semiconductor as an example. The part is likely produced in Taiwan or Korea, then sent to Malaysia for testing, then sent to Singapore for packaging, then sent to China for assembly into a module. That module may then be sent back for testing before sent to China again for final assembly into a phone or other device. If there is a shortage of some part or factory capacity anywhere along this chain, the whole thing backs up. The industry has gotten pretty good about smoothing out these wrinkles, but this year we are pushing all the bounds. </p>



<p>We have found that a lot of the time it is the most ignored, taken-for-granted parts that are in the shortest supply. How often do you think of the plastic packaging or substrate in which a semiconductor sits? Not often? Don’t feel bad, a lot of supply chain people do not think of these much either. So of course, those are out of stock everywhere right now, adding a month or more to some timelines. </p>



<p>The strangest part is that in all of this discussion of supply shortages there is  little thought given to the demand side. Maybe the economy will remain strong and these supply shortages will go away. Or maybe, we are just seeing a cascading series of temporary supply constrictions, and all the woes of 2020 finally catch up with the broader economy. In years past, double ordering usually ended poorly for the company that temporarily benefited from tight supply. All too often those buyers fighting to jump the queue ended up canceling orders at the last minute, leaving mountains of supplier inventories and financial woe in their wake. Our best guess is that we end up somewhere in between those two extremes. There are some legitimate reasons that capacity is scarce right now, but there are equally many cases of ephemeral demand. So spare a thought for your operations team, and maybe have them call all your suppliers again, for every component. Just to double check. </p>



<p><em>Photo by <a href="https://unsplash.com/@urielsc26?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Uriel SC</a> on <a href="https://unsplash.com/s/photos/shortage?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			</div></div>]]>
            </description>
            <link>https://digitstodollars.com/2020/10/27/what-is-happening-to-the-supply-chain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906572</guid>
            <pubDate>Tue, 27 Oct 2020 12:02:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Stopped Using ORMs to Get the Job Done]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906571">thread link</a>) | @fruty
<br/>
October 27, 2020 | https://fruty.io/2020/10/27/why-i-stopped-using-orms-to-get-the-job-done/ | <a href="https://web.archive.org/web/*/https://fruty.io/2020/10/27/why-i-stopped-using-orms-to-get-the-job-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For starters, this post is not a theoretical demonstration regarding whether you should use or not use ORMs (Object Relational Mapping) in your projects. It’s a description of why, in my own context, I decided to stop using ORMs. The ambition is to give a particular point of view that may be of use for people working in tech, to make up their mind.</p>



<p><strong><span>The Context</span></strong></p>



<p>First, the context. I’ve been working for 6 years as a tech startup CTO, at times as a cofounder, at times as a freelance. I’ve worked in or with a dozen of tech teams, using various kinds of technologies. Some teams were venture-backed, some were not.<br>If I had to sum up the context for the subject at hand, I would say that my point of view on ORMs is relevant for startup tech teams with &lt; 30 persons.</p>



<p>When I started coding, like most people, I started with a specific language, and that was not SQL. So, as soon as I started to need using a database, I naturally used ORMs to handle the database stuff. If we’re being honest here, most people don’t do a thorough research regarding the ORM topic, and just end up using one because they feel like they can get things done quicker, in a language they’re familiar with. I myself began coding in Python, and I quickly ended up using Django.</p>



<p>As time passed, I began appreciating several things about it, especially the migrations management part. Having all data schema modifications done in code (= versioned in Git) felt safer, especially when working with other people on that data schema. As the complexity of my projects grew, the backend code became more and more complex, but I didn’t give it second thoughts, since I had always used ORMs.<br>One thing that bothered me is that each time a requirement a little bit complex came up on a project, I had to dig very deep in the ORM documentation, like if I was cursed and that when a customer asked me something it would invariably be a specific corner case where the ORM fell short.</p>



<p>One day, I started taking data science projects, and I started learning SQL, since I had to perform a lot of queries on structured data.<br>I did my research and for various reasons I ended up selecting Postgres for my database of choice, due to its open source nature, its awesome views features (named reusable SQL queries), and its GIS extension Postgis.<br>One thing leading to the other, I worked on multiple data science projects in a row, and began to be quite good with SQL. It started to dawn on me how quick I was to make complex queries, with very few lines of SQL code.<br>I then worked again on web projects, and with my experience in SQL, decided that this time I would still write the backend in Python, but without ORM, and use a database driver instead (Psycopg2) to interact with the DB (database).</p>



<p>It has been a few years now that I work without ORMs, and I think my productivity more than doubled. I’m currently a freelance CTO, and I’m responsible (among other things) for the production infrastructure, including database schemas, of 4 startups.<br>I tried to analyze retrospectively what happened and here are a few thoughts.</p>



<p><strong><span>There is no Free Lunch</span></strong></p>



<p>ORM make one promise: that they will abstract the DB away. Solving problems in a generic way that works for everybody can mean 2 things: either it’s a technological breakthrough, either someone made some kind of middle-ground trade-off with existing tech. ORMs clearly fall in the latter.<br>ORMs make so many abstractions that starting off may be easier, but very quickly as you encounter more evolved real-world use cases, you end up spending your time reading documentation to understand the ORM abstractions, and how to configure it the way you need.</p>



<p>When a piece of software abstracts away a problem for you, if the scope of the problem is well defined, you can end up always using sensible defaults config parameters and a few of their variants. In this case, abstraction is a winning proposition.<br>The problem with ORMs is that the scope of what they usually try to achieve is too big, and in a real-world situation, when complexity arises, you often end up reading dark corners of your ORM documentation to find out whether your situation can fit in their abstractions. A great <a rel="noreferrer noopener" href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/" target="_blank">blog post</a> sums this up:  </p>



<p>“Although it may seem trite to say it, Object/Relational Mapping is the Vietnam of Computer Science. It represents a quagmire which starts well, gets more complicated as time passes, and before long entraps its users in a commitment that has no clear demarcation point, no clear win conditions, and no clear exit strategy.”</p>



<p>ORMs often seemed at first to be a winning proposition, but as time passes, I spent more time reading complex documentation for seemingly simple real-world situations, and I realized that the scope of what ORMs try to accomplish is just too large. When life keeps throwing at you different use cases with many little variants (and rest assured, this never stops), any endeavour to abstract it all quickly turns into a quagmire.</p>



<p><strong><span>Requirements You don’t have</span></strong></p>



<p>A huge problem of ORMs is that they abstract away the database, which means that if you have a favorite database, you can’t use its specific features.<br>If we’re being honest, in the context I’m talking about (startup with tech team &lt; 30 persons), who really needs DB portability?<br>The DB field is competitive and different DBs do differentiate themselves with great features (MySQL, Postgres, Mongo…). Abstracting the DB away means you have to settle for a common denominator, which is usually frankly quite mediocre.</p>



<p>For example, if in Django you need to perform a classic array aggregation, you end up using django.contrib.postgres.aggregates module, and lose DB portability right away. Array aggregations are very useful in many use cases, but not all DB propose it, so you end up using DB-specific modules anyway.</p>



<p><strong><span>The Performance Problem</span></strong></p>



<p>ORMs usually come with a SQL generator, that you’re never supposed to see. Problem is, in real-life, your DB schema will eventually get complex enough, and you will start having performance issues.<br>Business requirements change over time, retrocompatibility requirements pile up, and there is no way you can keep your DB schema theoretically optimal for your company’s needs at time t.<br>This fact translates into increased complexity for your DB queries, and a need to be smart about your queries.<br>When this complexity increases a bit, there is simply no way the ORM SQL generator can output optimized queries. Things will get slow, and I’ve yet to see an efficient way of querying a complex DB other than by writing the SQL yourself.</p>



<p><strong><span>DB Schema Consistency</span></strong></p>



<p>Initially I loved ORM for the fact that data structures were defined in code, which means versioned in Git, which means people could collaborate on them. Over the years I’ve changed my mind completely about this. Having multiple people make changes on DB schema invariably leads to huge inconsistencies, suboptimal choices and huge legacy.<br>This is why I enjoy working in small teams. I know it’s not possible for big corporations to have only 1 or 2 guys be the data masterminds, and I think that’s the reason why software quality drops so rapidly with the size of an organization. We just don’t know how to work efficiently in tech when the problem becomes too big for one brain (and by the way I think this is one of the biggest challenges to the advancement of humankind but that’s a story for another time).<br>I think that in the context of a startup with a tech team &lt; 30 persons, you should not have multiple persons making decisions about the DB schema. There should be 1 owner for this (which does not mean there can’t be collaborative discussions of course).<br>Currently I usually am the owner of DB schemas, and I manage SQL migrations by hand, via SQL scripts that are versioned in git, separately from backend code repos. I’m still regularly surprised by how many bad product/code decisions become obvious when considering DB schema issues, with context and history in mind.</p>



<p><strong><span>Be pragmati</span><span>c</span></strong></p>



<p>I had the opportunity to discuss the ORM topic with friends, and many had experienced more or less the same things, however some of them had an interesting take on the matter: they kept using ORMs, but only for particular things such as migrations management, handling connection pools with DB (for concurrent querying), input validations… To come back to the Vietnam analogy, I think it’s perfectly OK to use ORMs, if you know exactly what for, with a clear goal in mind and a well defined perimeter.</p>



<p><strong><span>The stack I use now</span></strong></p>



<p>Now when I start a web project, on the backend side I set up a REST API with a lightweight HTTP framework (Flask in Python, ExpressJS in Javascript), I interact with the DB with a driver (Psycopg2 in Python, pg-native in NodeJs), and I use Postgres, with a heavy use of Postgres Views to put as many data-related code in SQL, and as few as possible in backend Python/Js code.</p>



<p>The resulting backends, if you know SQL, are insanely quick to write, easy to read, and thus to maintain.</p>




	</div></div>]]>
            </description>
            <link>https://fruty.io/2020/10/27/why-i-stopped-using-orms-to-get-the-job-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906571</guid>
            <pubDate>Tue, 27 Oct 2020 12:02:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Psychology of User Decisions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906554">thread link</a>) | @jrdnbwmn
<br/>
October 27, 2020 | https://learnuxd.io/posts/the-psychology-of-user-decisions | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/the-psychology-of-user-decisions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/cover.png" alt="The Psychology of User Decisions">
</figure>

<p>We like to apply labels to users: they’re irrational, lazy, unpredictable, rushed, and so on.</p>

<p>To some extent that may be true<span>—</span>we aren’t machines.</p>

<p>But research shows that users actually make decisions based on a set of predictable subconscious patterns.</p>

<p>To create satisfying digital experiences, UX designers should be aware of<span>—</span>and support<span>—</span>these cognitive habits.</p>

<h2 id="heuristics">Heuristics</h2>

<p>Human beings use psychological tactics and biases to get to decisions quickly. These mental shortcuts are called <a href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555" target="_blank">heuristics</a>. We use heuristics in everyday life, but we especially like using them with software.</p>

<p>We don’t follow these patterns out of laziness or because we’re scatter-brained. It’s quite rational to take advantage of heuristics as a user because…</p>

<ul>
  <li>In the digital world, there’s <strong>very little penalty for being wrong</strong>. The cost of most errors is close to zero. Guessing wrong on a link and hitting the back button is still more efficient than reading the whole page to find an exact match.</li>
  <li>Carelessly clicking around is <strong>more fun</strong> because we get a small dopamine rush from each click.</li>
  <li>Web pages can be complicated. We’d rather <strong>make a decision and get on with our lives</strong>. It’s a matter of trade-offs<span>—</span>a balancing act.</li>
  <li>The web enables us to <strong>move quickly from one decision to the next</strong>, at a much faster pace than the physical world. So that’s what we do.</li>
</ul>

<p>Let’s take a look at some of the most common heuristics that users employ.</p>

<h3 id="satisficing">Satisficing</h3>

<p>A combination of the words “satisfy” and “suffice.” It means to <a href="https://www.nngroup.com/articles/satisficing/" target="_blank">settle for the first reasonable option you find</a>, without considering the whole set of possibilities. We don’t look for the right answer<span>—</span>we look for whatever is good enough.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/satisficing.png" alt="Users make quick and dirty scans. When they come across something that refers even a little to what they've come for, they instinctively click it.">
</figure>

<h3 id="loss-aversion">Loss Aversion</h3>

<p><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.320.8769" target="_blank">Losses loom larger than gains</a> in our minds. It is thought that the pain of losing is about twice as powerful as the pleasure of gaining. We put in more work and take more risks to avoid losses than we do to make gains. Part of <a href="https://www.nngroup.com/articles/prospect-theory/">Prospect Theory</a>.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/loss-aversion.png" alt="Users will go to great lengths to avoid something that’s potentially negative, or that could cause them to lose what they already have.">
</figure>

<h3 id="availability">Availability</h3>

<p><a href="https://www.nngroup.com/videos/availability-heuristic/" target="_blank">People draw conclusions based on what comes to mind immediately</a>. We give a lot of importance to things that we recall quickly and things we can already see right in front of us.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/availability.png" alt="If a user needs to make a decision on a page, what's right in front of them? What can they recall quickly from other pages? What do they notice first?">
</figure>

<h3 id="decision-fatigue">Decision Fatigue</h3>

<p>Making a lot of decisions <a href="https://archive.org/details/psychologyofecon0000unse/mode/2up" target="_blank">lowers a person’s ability to make rational ones</a>. It’s also exhausting.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/decision-fatigue.png" alt="If a user is forced to make decision after decision after decision, they'll eventually start making sub-optimal choices... or give up entirely.">
</figure>

<h3 id="reference-dependence">Reference Dependence</h3>

<p>Human beings do not have an innate way to determine absolute value. So <a href="https://www.uxmatters.com/mt/archives/2011/01/the-power-of-comparison-how-it-affects-decision-making.php" target="_blank">we assign value by comparing one thing to another</a>. We make judgments in relative rather than absolute terms.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/reference-dependence.png" alt="In a set of choices in an interface, how the options relate to each other will determine what the user will do.">
</figure>

<h3 id="status-quo-bias">Status Quo Bias</h3>

<p>Unless there’s a compelling incentive, <a href="https://www.nngroup.com/articles/the-power-of-defaults/" target="_blank">people are more likely to stick to the default</a>. In other words, we tend not to change the established situation.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/status-quo-bias.png" alt="This explains, for example, why users rarely utilize fancy customization features or change default settings.">
</figure>

<h3 id="hicks-law">Hick’s Law</h3>

<p>The number of stimuli present <a href="https://lawsofux.com/hicks-law" target="_blank">influences the time and effort required to make a decision</a>.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/hicks-law.png" alt="When users come across a situation with too many options, sometimes they'll try to bypass the unpleasantness of Hick's Law by hastily making any decision, which they later regret.">
</figure>

<h2 id="so-what">So what?</h2>

<p>As designers, what do we do about all this?</p>

<p>Here are a few ways we can tailor our digital experiences to these heuristics.</p>

<h3 id="decrease-your-dpp">Decrease your DPP</h3>

<p>One helpful exercise is to look at what we can call our DPP: <em>Decisions Per Page</em>.</p>

<p>Take an important page from your interface and count the number of possible decisions a user could make on that page. This includes actions (which always require a decision) or information that leads to a decision.</p>

<p>I’m willing to bet the number is higher than you would have guessed.</p>

<p><strong>If the DPP is too high, what do you do?</strong></p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/decisions-per-page.png" alt="Decisions per page">
</figure>

<h3 id="reduce-visual-signals">Reduce visual signals</h3>

<p>Start by reducing the number of colors and fonts. Using more than four meaningful colors causes the “<a href="https://www.nngroup.com/articles/first-impressions-human-automaticity/" target="_blank">rainbow effect</a>” which disorients the brain and creates an impression of ugliness.</p>

<p>Movement is distracting. Use animation sparingly and only for a specific purpose.</p>

<p>Build a design system. It ensures consistency between elements, and prevents users from having to re-learn the interface on every new page.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/design-system.png" alt="Design system">
</figure>

<h3 id="optimize-the-default-experience">Optimize the default experience</h3>

<p>Be aware that many people will never use fancy customization options. Make sure the general default experience provides for all the important <a href="https://learnuxd.io/posts/the-how-and-why-of-user-flows" target="_blank">task flows</a>.</p>

<p>Forms provide lots of opportunities to be helpful. For example, we could pre-populate fields with the most common value or a realistic example. This representative value helps the user understand how to complete the field and what the expected response is. Not to mention it will save most users time and decision-making energy.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/sensible-defaults.png" alt="Sensible defaults">
</figure>

<h3 id="prioritize-for-the-user">Prioritize for the user</h3>

<p>Since many users aren’t going to accurately prioritize things on their own, we should do some of that work for them. The ultimate goal is that they can glance at any page and know instinctively which items are most important.</p>

<p>Knowing what to prioritize requires that you learn about your users, their goals, and their main <a href="https://learnuxd.io/posts/the-how-and-why-of-user-flows" target="_blank">workflows</a>. Think about what is <em>essential</em> (vs. what is optional) and what moves the user <em>forward</em>.</p>

<p>We can give the user visual clues to create a clear hierarchy. Our brain assigns importance to things based on size, color, imagery, contrast, white space, and alignment.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/visual-priority.png" alt="Visual priority">
</figure>

<h3 id="evaluate-your-content">Evaluate your content</h3>

<p>Remember almost all users scan<span>—</span>they don’t read. Classic principles of good writing, including descriptive headings and <a href="https://www.nngroup.com/articles/inverted-pyramid/" target="_blank">inverted-pyramid</a> structures, help users get meaning from content.</p>

<p>Some common red flags include a lack of headings and big, long blocks of text. Call attention to important information using bulleted lists and bold or italic fonts. Take the time to craft your <a href="https://learnuxd.io/posts/7-practical-tips-for-better-microcopy" target="_blank">microcopy</a>.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/content.png" alt="Evaluate content">
</figure>

<h3 id="consider-the-post-click-experience">Consider the post-click experience</h3>

<p>What happens when a user clicks on something? What’s the next thing they see and how does it connect to where they just were? How does it fit into their whole journey through your interface?</p>

<p>It could be easy to think of each page in isolation. <strong>But remember pages aren’t individual silos<span>—</span>they’re pieces of flows.</strong> It’s all a series of connected actions.</p>

<p>Give good <a href="https://learnuxd.io/posts/7-practical-tips-for-better-microcopy" target="_blank">information scent</a> with link labels so users know where they’re going. Allow them to gracefully recover from clicking on the wrong thing to eliminate the “cost” of clicking. Make sure they’re always moving forward.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-decisions/post-click-experience.png" alt="Post-click experience">
</figure>

<h2 id="tying-it-off">Tying it off</h2>

<p>Remember: we never truly know what an individual user is thinking until we research. When in doubt, <a href="https://learnuxd.io/posts/usability-testing-in-4-simplified-steps" target="_blank">test it out</a>.</p>

<p>What are you going to do differently with your products to better support these heuristics?</p>

<p>Thanks for reading. Check out the Twitter thread, and consider sharing it with someone who would find this useful:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>👨🏻‍💻 Are users irrational? Research shows that they make decisions based on a set of predictable subconscious patterns.</p><p>[read the thread for Part 2 👇] <a href="https://t.co/CjEIR3ABU4">pic.twitter.com/CjEIR3ABU4</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1321051344258715650?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote>  
    </div>
</div>
</div></div>]]>
            </description>
            <link>https://learnuxd.io/posts/the-psychology-of-user-decisions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906554</guid>
            <pubDate>Tue, 27 Oct 2020 11:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Labeling of time series data for ML applications]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906268">thread link</a>) | @deppp
<br/>
October 27, 2020 | https://labelstud.io/blog/release-080-time-series-labeling.html | <a href="https://web.archive.org/web/*/https://labelstud.io/blog/release-080-time-series-labeling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
            
  

<div>

  
  

  
  
  <p>Time series is everywhere! Devices, sensors and events produce time series, for example, your heartbeat can be represented as a series of events measured every second, or your favorite step tracker recording a number of steps you take per minute. </p>
<p>All these signals can be used for ML model development, and we’re excited to present you with one of the first time series data labeling solutions that work across a variety of use-cases and can help you develop ML applications based on time series data!</p>

<p><img src="https://labelstud.io/images/release-080/main.gif"></p><blockquote>
<p>Labeled time series data is crucial if you want to develop supervised ML models for pattern recognition. It can also serve as a ground truth data for validating methods performance. Read below for some of the scenarios and implementation details</p>
</blockquote>
<h2 id="Labeling-UI-Performance"><a href="#Labeling-UI-Performance" title="Labeling UI Performance"></a>Labeling UI Performance</h2><p>A majority of time series datasets tend to have a lot of points. Therefore the tool has to scale well to handle the situation when you have more than 100K points. Initially we’ve tried to use some existing frontend libraries that provide time series implementation, but it turned out that none of them were up for the task, even with just 10,000 points you’d start to experience the lag when zooming or panning. It was clear that we need to come up with a more robust implementation. We’ve based the rendering on d3 and after numerous optimization attempts we’ve got to the desired result:</p>
<h3 id="1-000-000-data-points-and-10-channels"><a href="#1-000-000-data-points-and-10-channels" title="1,000,000 data points and 10 channels"></a><strong>1,000,000 data points and 10 channels</strong></h3><p><img src="https://labelstud.io/images/release-080/ui.gif"></p><p>Some of the techniques we have used include tiling - when we have a big number of datapoint we split it into chunks and render those chunks first, this helps us achieve great performance when the number of data points is very large. When you zoom out the algorithm samples specific points to give you an overview of your time series data.</p>
<h2 id="Working-with-a-variety-of-input-types-out-of-the-box"><a href="#Working-with-a-variety-of-input-types-out-of-the-box" title="Working with a variety of input types out of the box"></a>Working with a variety of input types out of the box</h2><p>For examples below we will be using the following configuration:</p>
<pre><code><span>&lt;<span>View</span>&gt;</span>
  <span>&lt;<span>TimeSeriesLabels</span> <span>name</span>=<span>"label"</span> <span>toName</span>=<span>"ts"</span>&gt;</span>
    <span>&lt;<span>Label</span> <span>value</span>=<span>"Walk"</span> /&gt;</span>
    <span>&lt;<span>Label</span> <span>value</span>=<span>"Run"</span> /&gt;</span>
  <span>&lt;/<span>TimeSeriesLabels</span>&gt;</span>
  
  <span>&lt;<span>TimeSeries</span> <span>name</span>=<span>"ts"</span> <span>valueType</span>=<span>"url"</span> <span>value</span>=<span>"$csv"</span> <span>sep</span>=<span>","</span> <span>overviewChannels</span>=<span>"sen1,sen2"</span>&gt;</span>
    <span>&lt;<span>Channel</span> <span>column</span>=<span>"sen1"</span> /&gt;</span>
    <span>&lt;<span>Channel</span> <span>column</span>=<span>"sen2"</span> /&gt;</span>
  <span>&lt;/<span>TimeSeries</span>&gt;</span>
<span>&lt;/<span>View</span>&gt;</span></code></pre>

<blockquote>
<p>If you’re new to Label Studio, <a href="https://labelstud.io/tags/">learn</a> how you can use tags to setup different labeling interfaces for your data</p>
</blockquote>
<p>Depending on where your time series data is coming from it can be formatted very differently. Label Studio provides a way to configure how time series parsing is done so you don’t have to transform the original file. Let’s start with a simple CSV like that:</p>
<pre><code>time,sen1,sen2
100,1,23
101,2,34
102,3,45</code></pre>

<p>CSV with weirdly formatted datetime, because you’ve captured that from a weird sensor that doesn’t follow the standard:</p>
<pre><code>time,sen1,sen2
2020-Feb-01 9:30,34.23,272
2020-Feb-01 9:31,251.23,352
2020-Feb-01 9:32,337.124,327</code></pre>

<p>In that case, there is <code>timeFormat</code> that can handle parsing for you, it uses <a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes" target="_blank" rel="noopener">strftime</a>.</p>
<p>The <code>valueType</code> controls whether the input is provided as-is, or via a URL. For example, the input file may look like a list of URLs and in that case <code>valueType="url"</code> will load the contents of each URL and expect a time series data inside.</p>
<pre><code>csvURL
http://example.com/path/to/timeseries1.csv
http://example.com/path/to/timeseries2.csv</code></pre>

<p>For the headless CSV, you can use a columns index to point to the right columns. For example, using <code>2</code> in Channel’s <code>column</code> attribute would look for the third column (it starts from zero) inside headless CSV.</p>
<p><code>timeColumn</code> is the name of the column with temporal data, notice that you can skip that altogether, and then it generates that for you.</p>
<p>You can also use <code>timeDisplayFormat</code> to configure the desired output of the temporal column. It can be a number or a date, if a temporal column is a date then use strftime to format it, otherwise, if it’s a number then use <a href="https://github.com/d3/d3-format#locale_format" target="_blank" rel="noopener">d3 number</a> formatting.</p>
<h2 id="Zoom-and-Pan"><a href="#Zoom-and-Pan" title="Zoom and Pan"></a>Zoom and Pan</h2><p>Press <code>ctrl</code> key and use your mouse wheel to zoom and pan. If you have a huge time series, then changing the window position and size inside an overview may not let you zoom as much as you like, because it has a certain limit on its width, then you can continue zooming with a mouse wheel</p>

<p><img src="https://labelstud.io/images/release-080/zoom.gif"></p><h2 id="Multivariate-and-Univariate"><a href="#Multivariate-and-Univariate" title="Multivariate and Univariate"></a>Multivariate and Univariate</h2><p>There are plenty of ways how you can setup the plots, every defined channel is synchronized with any other channel defined inside the same time series object, giving you a multivariate time series labeling experience. You can also define multiple time series objects and get distinct objects.</p>

<p><img src="https://labelstud.io/images/release-080/multi-uni.png"></p><p>Use the <code>Channel</code> tag to represent each additional time-series channel. By providing multiple channels you get a multivariate labeling interface and can label one channel by looking at the behavior of other items at the same timestamp on another channel.</p>
<blockquote>
<p><code>showTracker</code> attribute on TimeSeries object controls if you see the tracker and holding <code>shift</code> key makes it sync between the channels</p>
</blockquote>
<h2 id="Instance-labeling-and-snapping-to-the-point"><a href="#Instance-labeling-and-snapping-to-the-point" title="Instance labeling and snapping to the point"></a>Instance labeling and snapping to the point</h2><p>Double-click to put a bar labeling one particular data point, instead of labeling an entire region. And when you’re creating a region it always gets snapped to the closest point.</p>

<p><img src="https://labelstud.io/images/release-080/instance.png"></p><h2 id="Configuring-overview"><a href="#Configuring-overview" title="Configuring overview"></a>Configuring overview</h2><p>By default, an overview is created from the first channel, but you have control over that. Use <code>overviewChannels</code> and define what columns are included, it uses the same format as the <code>column</code> parameter, and can also use multiple channels inside an overview if you comma separate it.</p>

<p><img src="https://labelstud.io/images/release-080/overview.png"></p><h2 id="Synchronizing-across-data-types-experimental"><a href="#Synchronizing-across-data-types-experimental" title="Synchronizing across data types [experimental]"></a>Synchronizing across data types [experimental]</h2><p>It’s not always the case that you can label time series just by looking at the plots. Different events may have different representations, and in such cases, visual support is required. TimeSeries tag can synchronize to audio or video.</p>

<p><img src="https://labelstud.io/images/release-080/videosync.png"></p><p>This is an experimental feature right now, and we’re working on finalizing the implementation, but if you have use-cases, ping us in <a href="https://join.slack.com/t/label-studio/shared_invite/zt-cr8b7ygm-6L45z7biEBw4HXa5A2b5pw" target="_blank" rel="noopener">Slack</a>, we will help you to set it up.</p>
<h2 id="Next"><a href="#Next" title="Next"></a>Next</h2><p>Ready to try? <a href="https://labelstud.io/guide/#Running-with-pip">Install Label Studio</a> following our guide and check the <a href="">template</a> on time series configuration. Also, join the Slack channel if you need any help, have feedback, or feature requests. </p>
<p>Cheers!</p>
<h2 id="Resources"><a href="#Resources" title="Resources"></a>Resources</h2><ul>
<li>Label Studio<ul>
<li><a href="https://labelstud.io/templates/time_series.html">Templates</a> - Label Studio pre configured templates for Time Series</li>
<li><a href="https://labelstud.io/tags/timeseries.html">TimeSeries</a> - Time Series tag specification</li>
<li><a href="https://labelstud.io/tags/timeseries.html#Channel">Channel</a> - Channel tag specification</li>
</ul>
</li>
<li>Machine Learning<ul>
<li><a href="https://github.com/awslabs/gluon-ts" target="_blank" rel="noopener">https://github.com/awslabs/gluon-ts</a> - Probabilistic time series modeling in Python</li>
<li><a href="https://github.com/alan-turing-institute/sktime" target="_blank" rel="noopener">https://github.com/alan-turing-institute/sktime</a> - sktime is a Python machine learning toolbox for time series with a unified interface for multiple learning tasks. </li>
<li><a href="https://github.com/blue-yonder/tsfresh" target="_blank" rel="noopener">https://github.com/blue-yonder/tsfresh</a> - Time Series feature extraction package</li>
</ul>
</li>
</ul>

  

  
</div>

        </div></div>]]>
            </description>
            <link>https://labelstud.io/blog/release-080-time-series-labeling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906268</guid>
            <pubDate>Tue, 27 Oct 2020 11:13:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How you could have come up with Paxos yourself]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24906225">thread link</a>) | @todsacerdoti
<br/>
October 27, 2020 | https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html | <a href="https://web.archive.org/web/*/https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the field of computer science, the Paxos algorithm is notorious for how difficult it is to understand. I had to learn the Paxos algorithm in my distributed systems class. I even have "implemented" it by translating Leslie Lamport's TLA+ to Python. But I didn't understand it until much much later.</p>

<p>Now I have a better understanding of Paxos than I used to, I want to explain it to other people. Not because I'd like to help people, rather, I find that explaining things is a very good way to find blind spots in my own understanding.</p>

<p>So, where do we start? Personally, I dislike explanations that start with a step-by-step breakdown of the algorithm, followed by a proof of why those steps do what they claim to do. Instead, I much prefer to start with the problem the algorithm tries to solve, then iteratively come up with a solution together with the reader. So that's what I am going to do. And now you understand the title.</p>

<p><em>Small disclaimer:</em> The glossaries used in this article is different from what is commonly used for Paxos. I just picked the ones that made the most sense for my narrative.</p>

<h2 id="the-problem">The problem</h2>

<p>The distributed consensus problem is widely useful, so the reader probably doesn't need to be motivated. Here I will just simply state the problem.</p>

<p>There is a group of agents (let's call them $\sc{CLIENT}s$), who want to choose a number among their selections. Any number is fine, as long as everyone agrees on the same number.</p>

<p>Here, there are a few assumptions we will make to make this problem meaningful:</p>

<ul>
  <li>All the agents - including but not limited to the $\sc{CLIENT}s$, as we will add more types of agents later - are well-behaved. Meaning they all execute the prescribed algorithms faithfully, and don't maliciously try to trick other agents. (If you like jargons: Byzantine failures don't occur.)</li>
  <li>Agents can talk to each other by sending each other messages, but the messages they send to each other could take arbitrarily long before reaching their destination, and might get lost (but never altered).</li>
</ul>

<p>The agents could also "fail". However, failing is equivalent to all messages sent to/from that agent being lost forever. So whether we have this assumption or not won't change the algorithm we come up with.</p>

<p>Also, to not complicate things, we are only solving the "single-round" consensus problem in this article, meaning as the output of this algorithm, all of the $\sc{CLIENT}s$ will get a single number which they agree on.</p>

<h2 id="solution-searching-adventure">Solution searching adventure</h2>

<h3 id="iteration-0">Iteration 0</h3>

<p>When trying to solve a complex problem such as this one, it's usually a good idea to start by simplifying the problem.
As a start, let's just ignore the need to be reliable entirely.</p>

<p>If we throw reliability out the window, it should be easy to come up with a very simple solution: we add an agent (let's call it $\sc{COORDINATOR}$).
The $\sc{CLIENTS}$ send whatever number they pick to the $\sc{COORDINATOR}$ in a $\sc{PROPOSAL}(client_i, x)$ message, where $x$ is the number
proposed by the $i$-th $\sc{CLIENT}$. The $\sc{COORDINATOR}$ picks an arbitrary proposal (say, $x'$),
and informs the other $\sc{CLIENT}s$ about this decision.
Specifically, the $\sc{COORDINATOR}$ will just reply with a $\sc{CHOSEN}(x')$ message to all the $\sc{PROPOSAL}(\ldots)$ messages it has
received and will receive.</p>

<p>If we assume no messages ever get lost, it is quite easy to see that every $\sc{CLIENT}$ will get a number. And because only one number is ever chosen, they will all get the same number.</p>

<p>It is also easy to see why this solution is impractical: it has a single point of failure. Once the singular $\sc{COORDINATOR}$ fails, no further progress can be made.</p>

<h3 id="iteration-1">Iteration 1</h3>

<p>To improve this almost looks easy at first glance: just add more $\sc{COORDINATOR}s$!</p>

<p>Sure, more $\sc{COORDINATOR}s$ would remove the single point of failure. However, if there are more than one $\sc{COORDINATOR}s$, they might individually make different decisions, which results in the $\sc{CLIENT}s$ having disagreement.</p>

<p>What if we let the $\sc{COORDINATOR}s$ reach an agreement among themselves before responding? But wait, doesn't that sound familiar? Having a group of agents reaching an agreement, that's exactly what we added the $\sc{COORDINATOR}s$ to solve. We just made the problem cyclic.</p>

<p>Let's take a step back. Is there a way for the clients to reach an agreement without having the $\sc{COORDINATOR}s$ communicate with each other?</p>

<p>In other words, among the decisions of the $\sc{COORDINATOR}s$, is there an deterministic algorithm to pick out a specific one that is robust against message losses?</p>

<p>This might sound hard, but it's actually quite simple: pick the decision that is backed by more than half of the $\sc{COORDINATOR}s$.</p>

<p>There can't be two decisions both with more than half of the $\sc{COORDINATOR}s$ backing them; and if a decision doesn't have that many $\sc{COORDINATOR}s$ backing it, it won't appear to have more backing $\sc{COORDINATOR}s$ through message losses.</p>

<p>Since this approach resembles a majority vote, let's call $\sc{COORDINATOR}$ decisions $\sc{VOTE}(coord_i, x)$ from now on, where $x$ is the number picked by the $i$-th $\sc{COORDINATOR}$. Each $\sc{COORDINATOR}$ has a single vote, because each of them only makes a single decision.</p>

<p>Obviously, our solution cannot be infinitely reliable. If more than half of the $\sc{COORDINATOR}s$ went down, there will never be a majority reached. But this is already vastly better than our first solution, and the reliability scales with the number of $\sc{COORDINATOR}s$. So we will call it good enough.</p>

<p>Sadly, this solution doesn't actually work: there might not be a majority at all! For example, it's possible that three of the proposals each get a third of the votes. We would have a stalemate in that case.</p>

<h3 id="iteration-2">Iteration 2</h3>

<p>Again, a solution seems straightforward: just try again in case of a stalemate.</p>

<p>But then again, things aren't that simple.</p>

<p>First of all, the $\sc{COORDINATOR}s$ need to be made aware of a retry. Otherwise, because each $\sc{COORDINATOR}$ only has one vote, they won't be able to vote again even if the $\sc{CLIENT}s$ retry.</p>

<p>To do that, we attach an attempt id to all the messages sent. i.e. $\sc{PROPOSAL}(client_i, x)$ becomes $\sc{PROPOSAL}(\#attempt, client_i, x)$, and so forth. Each time a $\sc{CLIENT}$ retries, it bumps $\#attempt$ to the maximum $\#attempt$ it knows of plus 1. And the $\sc{COORDINATOR}s$ should only responds to messages with the most recent $\#attempt$.</p>

<p>Hopefully the intent of the $\#attempt$ number is clear. (<a href="https://github.com/yshui/explain-algorithms/issues/new">Let me know</a> if not.)</p>

<p>Are we good now? Unfortunately, no. Consider this scenario:</p>

<p>There were 2 clients. They proposed their numbers, the $\sc{COORDINATOR}$ voted on them and all agreed on a single number, $x_1$, all is good. But, all of the $\sc{VOTE}(\ldots)$ messages got lost on the way to $client_2$, while $client_1$ received all of the messages just fine. At this point, $client_1$ thought $x_1$ is the number, but $client_2$ went on to retry. The $\sc{COORDINATOR}s$ voted again, and got $x_2$. This time, all the messages sent to $client_1$ got lost.</p>

<p>And behold, we got the two clients to disagree.</p>

<p>There is an important insight to be had here. Whenever a $\sc{COORDINATOR}$, say $coord_i$, sends out a $\sc{VOTE}(\ldots, coord_i, x)$, there is a chance that some $\sc{CLIENT}$ would adopt $x$. If $coord_i$ ever sends out two votes with different $x$, there is a chance that some of the $\sc{CLIENT}s$ would disagree.</p>

<p>In other words, once a $\sc{COORDINATOR}$ has revealed its vote, it has to stick to it.</p>

<p>This seems to run contrary to our attempt: if the $\sc{COORDINATOR}s$ cannot change their votes, what's the point of retrying? A stalemate will be a stalemate forever.</p>

<p>Looks like we reached a dead end with this type of voting. It appears the problem stems from the fact that the $\sc{COORDINATOR}s$ have to commit to their votes.</p>

<p>So, what if we introduce a form of non-commitment voting?</p>

<h3 id="iteration-3">Iteration 3</h3>

<p>Let's explore this idea. Say, the $\sc{COORDINATOR}s$ could now send a $\sc{TENTATIVE}\sc{VOTE}(\#attempt, coord_i, x)$ message, to tentatively vote for $x$.</p>

<p>Obviously, the $\sc{CLIENT}s$ couldn't adopt $x$ right away. So what's this vote good for?</p>

<p>Ah, right, it could get us to a majority.</p>

<p>It is correct that tentative votes don't lead directly to an agreement among $\sc{CLIENT}s$, but it can show us when a majority has formed among the $\sc{COORDINATOR}s$.</p>

<p>Once a $\sc{CLIENT}$ sees a majority tentative vote, it can then message the $\sc{COORDINATOR}s$ to ask for an actual vote. (Let's call this message $\sc{PLEASE}\sc{VOTE}(\#attempt, client_i)$). Intuitively, the $\sc{COORDINATOR}s$ have to make the same vote in the actual vote as their tentative votes.</p>

<p>If all goes well, we would get a majority and an agreement. If there is no majority, the $\sc{COORDINATOR}s$ won't even start a vote, so they are free to change their mind. So the $\sc{CLIENT}s$ could start another attempt which might have a different outcome.</p>

<p>What if things don't go well? What if the $\sc{PLEASE}\sc{VOTE}$ messages weren't received by some of the $\sc{COORDINATOR}s$?
In that case, some of the $\sc{COORDINATOR}s$ would have voted, and their decisions cannot be changed. That is to say, in all subsequent attempts, these $\sc{COORDINATOR}s$ will always vote for what they have voted for, whether it's a tentative vote, or the actual vote. But that doesn't create a problem for us. There was a majority in the tentative votes, and now we solidified part of the tentative votes. There is at least one way we can still reach a majority in the next round: everyone votes the same as they did in this round. And we can prove this inductively for all future rounds.</p>

<p>From this, we can have a rough image of how the algorithm functions: as attempts are being made, more and more $\sc{COORDINATOR}s$ start to make up their mind which number they will commit to, while making sure a majority could still be reached. Eventually, …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</a></em></p>]]>
            </description>
            <link>https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906225</guid>
            <pubDate>Tue, 27 Oct 2020 11:06:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Educational TV]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24906210">thread link</a>) | @schwartzworld
<br/>
October 27, 2020 | https://schwartz.world/blog/educational_tv/ | <a href="https://web.archive.org/web/*/https://schwartz.world/blog/educational_tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main">

<p>I don’t want to be one of those complaining old men, constantly bemoaning every difference that I see between the world of my youth and that of today.I’m not that old anyway; at 38 I consider myself to be just barely reaching adulthood.</p>
<p>I have two small children of the girl persuasion, ages 2 and 4. The pandemic has changed so much about their lives, but one change is that we all have a lot more screen time than before.</p>
<p>Children’s programming is shit today. Boring computer-generated animation, interchangeable characters with impossibly cheerful voices. Most of it seems lazy and half-baked. You could take the plots and characters from any number of shows and switch them around and it would all fit fine. I’m talking about shows like <em>PJ Masks</em>, <em>Paw Patrol</em>, and <em>Mickey Mouse Clubhouse</em>.</p>
<p><em>Mickey Mouse Clubhouse</em> is a particularly bad offender, because I have such strong childhood attachments to the source material. It might be the worst show ever made. It’s weird, but not in a fun way like <em>Yo Gabba Gabba</em>. Completely humorless.</p>
<p>Even <em>Sesame Street</em>, of which I am a staunch advocate, uses obvious filler sketches like <a href="https://www.youtube.com/watch?v=M6TkpZx1dzQ"><em>Journey to Ernie</em></a>, which is absolute garbage.</p>
<p>Contrast that to the shows I watched as a kid. We’ve been playing <em>Fraggle Rock</em>, <em>The Elephant Show</em>, <em>Magic Schoolbus</em>, <em>Beakman’s World</em>, <em>Bill Nye the Science Guy</em>. They’re just better.</p>
<p>The Fraggles are such well-developed characters, and the show does such a good job of showing the fragile beauty of their ecosystem. There are layers of information that can be gleaned on subsequent rewatches. As children mature, there are jokes and nuances they start to grasp. The show is actually entertaining for adults.</p>
<p>Contrast that to <em>The PJ Masks</em>, a show that makes me want to actually put my head through the TV.</p>
</section></div>]]>
            </description>
            <link>https://schwartz.world/blog/educational_tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906210</guid>
            <pubDate>Tue, 27 Oct 2020 11:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write a great Dockerfile for Python apps: 6 ways to improve it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906152">thread link</a>) | @barrachri
<br/>
October 27, 2020 | https://www.pybootcamp.com/blog/how-to-write-dockerfile-python-apps/ | <a href="https://web.archive.org/web/*/https://www.pybootcamp.com/blog/how-to-write-dockerfile-python-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><article><p>In the previous article, <a href="https://www.pybootcamp.com/blog/how-to-containerize-python-application/" title="How to containerize a Python Application">how to containerize a Python application</a>, we created a Dockerfile and containerized our application from scratch.</p>
<p>Now we really want our Dockerfile to stand out, <strong>make it more production-ready</strong>, that's the goal of this article.</p>
<p>We will cover 6 different ways to improve our <code>Dockerfile</code>:</p>
<ul>
<li>setting env variables and a working directory</li>
<li>avoiding invalidating the Docker cache</li>
<li><strong>changing the default user to non-root</strong></li>
<li>taking care of zombie processes</li>
<li>correctly forwarding signals to our application</li>
<li>updating <code>pip</code>, <code>setuptools</code> and <code>wheel</code></li>
</ul>
<h3>Intro</h3>
<p>This is the <code>Dockerfile</code> we created last time:</p>
<div data-language="dockerfile"><pre><code>
<span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster


<span>COPY</span> . /src


<span>RUN</span> pip install <span>-</span>r /src/requirements.txt</code></pre></div>
<p>While fully functional, there are a few things we can improve regarding usability, security and performance.</p>
<p>You can clone this <a href="https://github.com/py-bootcamp/movie-recommender/tree/part-1">repository</a> if you want to follow along.</p>
<h3>Passing the git commit hash</h3>
<p>We want to <em>mark</em> each Docker image and container with a tag, this tag is the <code>git commit hash</code>.</p>
<p><strong>At runtime we should be able to determine which version of our software we are running.</strong></p>
<blockquote>
<p>The idea is that every artifact we generate is traceable, we can go back and check which commit generated it.</p>
</blockquote>
<p>The <a href="https://docs.docker.com/engine/reference/builder/#arg">ARG</a> and <a href="https://docs.docker.com/engine/reference/builder/#env">ENV</a> instructions can help us achieving it.</p>
<p><code>ARG</code> specifies arguments that we can pass to the <code>docker build</code> command, <code>ENV</code> are env variables set inside the <code>Dockerfile</code> and accessible at runtime, from within the container.</p>
<p>This is the new <code>Dockerfile</code>, with <code>ARG</code> and <code>ENV</code>:</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster


<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>


<span>COPY</span> . /src

<span>RUN</span> pip install <span>-</span>r /src/requirements.txt</code></pre></div>
<p>The <code>-dev</code> is a way to specify defaults. If the <code>GIT_HASH</code> argument is omitted then <code>GIT_HASH</code> will be set to <code>dev</code>.</p>
<p>Let's build our Docker image and check the <code>GIT_HASH</code> env variable:</p>
<div data-language="bash"><pre><code><span>&gt;</span> docker build -t movie-app <span>.</span>
<span>&gt;</span> docker run --rm movie-app <span>env</span> <span>|</span> <span>grep</span> GIT_HASH
<span>GIT_HASH</span><span>=</span>dev</code></pre></div>
<p>How do we pass the git commit hash to our Docker image?</p>
<p>We use the <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg"><code>--build-arg</code></a> flag from the Docker cli:</p>
<div data-language="bash"><pre><code>
<span>&gt;</span> <span>export</span> <span>GIT_HASH</span><span>=</span><span><span>$(</span><span>git</span> rev-parse HEAD<span>)</span></span>
<span>&gt;</span> docker build --build-arg <span>GIT_HASH</span><span>=</span><span>${GIT_HASH<span>:</span><span>:</span>7}</span> -t movie-app <span>.</span>
<span>&gt;</span> docker run --rm movie-app <span>env</span> <span>|</span> <span>grep</span> GIT_HASH
<span>GIT_HASH</span><span>=</span>6a78e6b</code></pre></div>
<p>We don't need the whole commit hash, the first 7 characters are enough.</p>
<blockquote>
<p>Why are we not passing the base image using <code>ARG</code>?
Because we don't want to change the base Docker image from the Docker cli, but only through a new commit.</p>
</blockquote>
<h3>Adding a working directory</h3>
<p>Right now we are copying our files inside a <code>/src</code> folder and then we specify all the other paths relative to <code>/src</code>.</p>
<p>Wouldn't be nicer if we could specify a working directory and run commands from that folder?</p>
<p>That would be neat, and <a href="https://docs.docker.com/engine/reference/builder/#workdir">WORKDIR</a> is exactly what we need.</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster

<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>


<span>WORKDIR</span> /project


<span>COPY</span> . .


<span>RUN</span> pip install <span>-</span>r requirements.txt</code></pre></div>
<p>After we specify a <code>WORKDIR</code>, any <code>RUN</code>, <code>CMD</code>, <code>ENTRYPOINT</code>, <code>COPY</code> and <code>ADD</code> instructions that follow will use that working directory.</p>
<p>Note how the path of <code>COPY</code> and <code>pip install</code> changed.</p>
<p>Let's test our application:</p>
<div data-language="text"><pre><code>&gt; docker build -t movie-app .
# 💥 it's not python /src/app.py anymore 💥
&gt; docker run --rm -p 8888:8888 movie-app python app.py
&gt; curl localhost:8888</code></pre></div>
<h3>Caching dependencies</h3>
<p>Our application has a small number of external dependencies, the <code>requirements.txt</code> contains only a few dependencies, so the <code>pip install</code> command is fast, just a couple of seconds.</p>
<p>What if it were taking minutes instead of seconds?</p>
<p>Wouldn't be better to cache our dependencies until something changes?</p>
<p>If you try to modify any file inside our application's folder and try to run the Docker build command you will see how Docker builds the image starting from zero.</p>
<p>If you check the console output you should see something like this:</p>
<div data-language="bash"><pre><code>Step <span>6</span>/7 <span>:</span> RUN pip <span>install</span> -r requirements.txt
 ---<span>&gt;</span> Running <span>in</span> 2233484e3f72</code></pre></div>
<p>Basically any change to our codebase, even if it's not related to <code>requirements.txt</code> will invalidate the Docker cache.</p>
<p>We can be smarter and save some time, <strong>we just need to install our dependencies first</strong>.</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster

<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>

<span>WORKDIR</span> /project


<span>COPY</span> requirements.txt ./
<span>RUN</span> pip install <span>-</span>r requirements.txt


<span>COPY</span> . .</code></pre></div>
<p>We added a new <code>COPY</code>, just for <code>requirements.txt</code>, and moved the <code>pip install</code> right after.</p>
<p>If you now try to build the Docker image again, then change the <code>main.py</code> and rerun the <code>docker build</code> command again that shouldn't invalidate the cache.</p>
<p>This is the output you should see, <code>Using cache</code>:</p>
<div data-language="text"><pre><code>&gt; docker build -t movie-app .
Step 6/7 : RUN pip install -r requirements.txt
 ---&gt; Using cache
 ---&gt; cbe7b2865e10</code></pre></div>
<h3>Running your container as non-root user</h3>
<p>By default the user running your command inside a Docker container is <code>root</code>.</p>
<div data-language="text"><pre><code>&gt; docker run --rm movie-app whoami
root</code></pre></div>
<blockquote>
<p>Long story short, Docker containers should not run as root and is highly recommended to change the default user to a non-root user.</p>
</blockquote>
<p>How do we change the user?</p>
<p>We create a new one and we set the new user with the <a href="https://docs.docker.com/engine/reference/builder/#user">USER</a> instruction.</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster

<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>

<span>WORKDIR</span> /project




<span>RUN</span> useradd <span>-</span>m <span>-</span>r user &amp;&amp; \
    chown user /project


<span>COPY</span> requirements.txt ./
<span>RUN</span> pip install <span>-</span>r requirements.txt

<span>COPY</span> . .


<span>USER</span> user</code></pre></div>
<div data-language="text"><pre><code>&gt; docker build -t movie-app .
&gt; docker run --rm movie-app whoami
user</code></pre></div>
<p>Our <code>user</code> can't create new files outside of the <code>/project</code> folder (user is the owner of the folder):</p>
<div data-language="text"><pre><code>&gt; docker run --rm touch /hello
touch: cannot touch '/hello': Permission denied
# 👇 but this command would work
&gt; docker run --rm touch hello</code></pre></div>
<p>Let's test our application to be sure it has all the necessary permissions:</p>
<div data-language="bash"><pre><code><span>&gt;</span> docker run --rm -p <span>8888</span>:8888 movie-app python app.py
<span>&gt;</span> <span>curl</span> localhost:8888</code></pre></div>
<h3>Taking care of zombie processes and signals</h3>
<p>Each Docker container is a PID namespace, and A PID namespace is a tree, which starts at PID 1, commonly called init.</p>
<p>The entire process of starting the system and shutting it down is maintained by init, when you run a Docker container, PID 1 is what you set inside your <code>ENTRYPOINT</code>.</p>
<p>If you don't set it by default Docker will use <code>/bin/sh -c</code>, which does not pass signals, making almost impossible to gracefully stop your application.</p>
<p>This is why we need a better init, <a href="https://github.com/krallin/tini">Tini</a>.</p>
<p><code>Tini</code> doesn't only take care of reaping zombie processes but also of forwarding any signals we send to the Docker container to our application process.</p>
<blockquote>
<p>Forwarding signals correctly is really important. Kubernetes relies on signals during the lifecycle of a pod.</p>
</blockquote>
<p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">More about Kubernetes and signals here</a>.</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster

<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>

<span>ENV</span> TINI_VERSION=<span>"v0.19.0"</span>


<span>ADD</span> https<span>:</span>//github.com/krallin/tini/releases/download/$<span>{</span>TINI_VERSION<span>}</span>/tini /tini
<span>RUN</span> chmod +x /tini


<span>WORKDIR</span> /project

<span>RUN</span> useradd <span>-</span>m <span>-</span>r user &amp;&amp; \
    chown user /project

<span>COPY</span> requirements.txt ./
<span>RUN</span> pip install <span>-</span>r requirements.txt

<span>COPY</span> . .

<span>USER</span> <span>user</span>


<span>ENTRYPOINT</span> <span>[</span><span>"/tini"</span><span>,</span> <span>"--"</span><span>]</span></code></pre></div>
<p>We have two new instructions here, <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ADD</a> and <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a>.</p>
<p><code>ADD</code> is a really useful instruction, it can add remote files to you Docker image.</p>
<p>The <code>ENTRYPOINT</code> specifies the entry point for any command, in our case <code>python app.py</code>, pretty much like running <code>/tini -- python app.py</code></p>
<h3>Updating pip, setuptools and wheel</h3>
<p>One last thing, it's important to keep <code>pip</code>, <code>setuptools</code> and <code>wheel</code> updated, so it's wise to bump them directly inside our Docker image.</p>
<div data-language="dockerfile"><pre><code><span>FROM</span> python<span>:</span>3.8.3<span>-</span>slim<span>-</span>buster

<span>ARG</span> GIT_HASH
<span>ENV</span> GIT_HASH=$<span>{</span>GIT_HASH<span>:</span><span>-</span>dev<span>}</span>
<span>ENV</span> TINI_VERSION=<span>"v0.19.0"</span>

<span>ADD</span> https<span>:</span>//github.com/krallin/tini/releases/download/$<span>{</span>TINI_VERSION<span>}</span>/tini /tini
<span>RUN</span> chmod +x /tini


<span>RUN</span> pip install <span>-</span>U \
    pip \
    setuptools \
    wheel

<span>WORKDIR</span> /project

<span>RUN</span> useradd <span>-</span>m <span>-</span>r user &amp;&amp; \
    chown user /project

<span>COPY</span> requirements.txt ./
<span>RUN</span> pip install <span>-</span>r requirements.txt

<span>COPY</span> . .

<span>USER</span> <span>user</span>

<span>ENTRYPOINT</span> <span>[</span><span>"/tini"</span><span>,</span> <span>"--"</span><span>]</span></code></pre></div>
<p>Let's test our application once again:</p>
<div data-language="text"><pre><code>&gt; docker build -t movie-app .
&gt; docker run --rm -p 8888:8888 movie-app python app.py
curl localhost:8888</code></pre></div>
<p>And with this last step we are done!</p>
<h3>Quick recap</h3>
<ul>
<li><code>ARG</code> and <code>ENV</code> are neat, use them</li>
<li>Copy and install your dependencies before copying your application</li>
<li>Don't run containers as root, set a new user with <code>USER</code></li>
<li>Try to prettify your dockerfiles</li>
<li>Always use <code>Tini</code></li>
<li>Defining a <code>WORKDIR</code> helps</li>
</ul>
<h3>Useful resources</h3>
<ul>
<li><a href="https://github.com/py-bootcamp/movie-recommender/tree/part-2">Github repo for movie-recommender</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/#arg">ARG</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/#env">ENV</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/#workdir">WORKDIR</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/#user">USER</a></li>
<li><a href="https://docs.docker.com/engine/reference/builder/#entrypoint">ENTRYPOINT</a></li>
</ul></article></div></div></div></section></div>]]>
            </description>
            <link>https://www.pybootcamp.com/blog/how-to-write-dockerfile-python-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906152</guid>
            <pubDate>Tue, 27 Oct 2020 10:52:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An incident response starter-pack: how do you handle production outages?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24906103">thread link</a>) | @lawrjone
<br/>
October 27, 2020 | https://blog.lawrencejones.dev/incident-response/ | <a href="https://web.archive.org/web/*/https://blog.lawrencejones.dev/incident-response/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  <header>
    
    
    <p>
      October 27, 2020
      
    </p>
  </header>
  <section><p>Throughout my career, I’ve always gravitated toward incidents. Maybe it’s the
drama, or I like to see how things go wrong. Perhaps… maybe I even cause them?</p>

<p>Whatever the reason, this experience has helped me develop a sense of how I like
handling incidents, something I’ve tried passing onto my team. So when a
colleague asked what our methods were, I was more than happy to respond with
some unstructured ramblings.</p>

<figure>
  <img src="https://blog.lawrencejones.dev/assets/images/incident-response-email.png" alt="email asking for incident response advice">
</figure>

<p>Since then, Matthieu has regularly nudged me to share these thoughts more
widely. This article is what happened when I took those words, dressed them up
all fancy, and sent them into the world.</p>

<p>I hope you find it useful!</p>

<hr>

<p>If you’ve ever Googled incident response, you’ll have found a load of results
about <strong>incident roles</strong>. Atlassian has some <a href="https://www.atlassian.com/incident-management">incredible docs</a> that
explain the concepts well.</p>

<p>In brief:</p>

<ul>
  <li>Incident roles help scale incidents as your response team grows. Roles help
separate responsibilities, ensuring someone is properly focused on each aspect
of an incident. Defining these roles can help make everyone clear about what
they’re expected to do, and what to expect of one another.</li>
  <li>Two <a href="https://www.atlassian.com/incident-management/incident-response/roles-responsibilities">roles</a> you must be aware of:
    <ul>
      <li>Incident commander, the single point of contact for actions taken related
to this incident. They don’t need to be the person taking the action, but
before you reboot that server, you check with them. This avoids the
classic ‘shit, I didn’t realise you were restoring the database onto
<em>that</em> node’ when you clash with a well-intentioned colleague</li>
      <li>Communications. Essential, and typically the first thing forgotten when
lacking a structured incident response process. Don’t be that team-
nominate someone to manage comms as early as possible, and make sure all
responders actively offload communication to them. Don’t ever split
people’s focus by requiring them to debug and communicate, or you’ll
half-ass both!</li>
    </ul>
  </li>
  <li>There are many other roles defined in the literature, but roles only help when
your team has a strong understanding of what each role entails. Commander and
communications are, in my opinion, essential- adding more granularity without
sufficient training can confuse incidents and impair your response</li>
</ul>

<p>If you become comfortable with the roles you want to use, and your team are well
practiced in all of them, you’ll have taken the first step towards an effective
response. But now you have the roles, how does your team go about fixing the
issue?</p>

<p>Firstly, identify <strong>what is bleeding</strong>. If you can establish the scope of an
incident early, it means your next steps will be much more likely to address the
problem.</p>

<p>Try to:</p>

<ul>
  <li>Identify which systems are failing, then work through the dependencies to
understand whether the issue is due to an upstream or downstream component</li>
  <li>Be extremely wary of assumptions. For everything you receive from a
third-party, trust but verify. Record whatever you did to verify, such as the
commands you ran and the time you ran them. An incorrect assumption can derail
your response, so do your best to avoid them!</li>
  <li>Once you’ve found the technical source, consider running some impact analysis.
Don’t delay your response with this work, but if someone is spare, get them to
estimate the scope of the impact- who and how many are affected. An inaccurate
understanding of impact can lead to poor decisions, and clarity on who is
affected can help other parts of your organisation (Customer Success, Support,
etc) respond appropriately</li>
</ul>

<p>Once the team understands the nature of the incident, you can begin to <strong>stop
the bleeding</strong>. Put differently, your goal should be to stop the immediate pain
and defer clean-up to a less pressured time.</p>

<p>For this, we need to prioritise actions to achieve the best chance of a positive
outcome. Note the phrase <strong>“best chance”</strong>: routine remediations that are quick
to apply should be taken first, even if you suspect it may only partially fix
the problem.</p>

<p>This means:</p>

<ul>
  <li>Rollback to a known good revision, even if you think you can write a fix
really quickly- you can always do that after you’ve rolled back, when there is
less urgency</li>
  <li>Take action to preserve critical systems, even at the expense of other less
critical flows. If a single endpoint is causing the whole system to fail,
don’t hesitate to no-op that endpoint if it restores service to the parts that
matter</li>
  <li>Make full use of your team and proactively apply whatever fixes you think are
low-risk, even if you suspect it might not fix the whole problem: scale down
non-essential queues, put a freeze on deploys, restart that server. Effective
delegation means it costs little to try, provided other responders continue to
work on root cause analysis assuming the easy fixes will fail</li>
</ul>

<p>This should give you an idea of what your team should work on. The question is
now how should they work together to execute them?</p>

<p>Given incident response is so much about communication, you’ll be wanting an
effective tool for <strong>instant messaging</strong>, and to record a log of your actions.</p>

<p>Turn to Slack (or whatever your equivalent is):</p>

<ul>
  <li>The first action in any incident should be creating a message channel. Several
tools (<a href="https://github.com/monzo/response">monzo/response</a>, <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Netflix’s
Dispatch</a>) can automatically create that (and more) for you,
but even if you have to painstakingly click those buttons yourself, do it.
It’s way worth the additional minute of downtime to get that space
ready-to-go.</li>
  <li>I strongly advocate against private incident response channels. Company
culture providing, a public channel can level-up your response by increasing
ease of access to information. This can prevent coordination issues that you’d
head-desk to encounter (I’ve seen two separate incident teams tackling the
same incident, with no knowledge of each others existence…)</li>
  <li>Whenever you’re about to do something destructive, such as run a command or
restart some resource, message the channel. Not only can this improve
awareness across the team, but it provides an invaluable resource when
building an incident log for your post-mortem</li>
</ul>

<p>Instant messaging is great for information that is timestamped and should not be
changed. For content you expect to modify as the incident progresses, create an
<strong>incident document</strong> in your favourite collaborative editor (Google Docs,
Dropbox Paper, Notion, etc):</p>

<ul>
  <li>Your organisation can draft incident doc templates that contain the structure
you need: perhaps you have reporting responsibilities, or have a specific
communications flow? Put it all in here, and make it easy to create documents
from these templates with a single click</li>
  <li>Especially for large-scale incidents where people rotate through the incident
team, this doc can act as the entry-point for onboarding people into the
incident. Have whoever runs comms manage this document, maintaining a timeline
of important events, and even draft an executive summary if the incident is
particularly complex</li>
  <li>Have your technical team post code snippets or relevant logs lines into the
document appendix, so everyone can lean on a central view of the incident</li>
</ul>

<p>Paired together, chat log and incident doc can be powerful tools to help
coordinate the response team, while providing transparency to any invested
onlookers. Even better, this content can be easily reshaped into a post-mortem
once the dust has settled.</p>

<p>Finally, and most importantly, the <strong>human element</strong>. People make bad decisions
when stressed, and the excitement of an incident can make you forget entirely
about caring for yourself. Lead by example and be forceful when encouraging your
responders to care for themselves.</p>

<p>Some things to consider:</p>

<ul>
  <li>One highly effective method to reduce stress is to take breaks, going away
from your screen, and breathing. Actively encourage your team to take these
pauses with you, reducing the chance you’ll screw things up by rushing</li>
  <li>As a general rule, take pauses whenever:
    <ul>
      <li>You get paged. It doesn’t have to be long; just 10s of breathing can
remind your body that you’re in control, and lower your adrenaline.</li>
      <li>Whenever the production impact has ceased. As soon as the alarms go quiet
and things seem stable, call a break for the entire team. It’s rare that
incidents don’t have extended follow-up work: rest yourself for at least
15m before you start that process</li>
      <li>During follow-up, before commencing any sort of procedure, such as
‘recovery of X cluster’. Get everyone to grab some air before running the
checklist, allowing each individual to recharge in case the process goes
wrong, or takes much longer than expected</li>
    </ul>
  </li>
  <li>Ensure your incident commanders are trained to detach responders before they
burn themselves. One important job is to order (and expense!) food before
people get hungry. You’ll be surprised at how an incident response team will
eat, after noisily protesting that they don’t need any food!</li>
</ul>

<p>That’s all folks! A whistle-stop tour through my essential shopping list of
incident response practices. This list is far from complete, but can be used as
a great starter pack, or a prompt for the more experienced to consider what they
care about in their incident response process.</p>

<p>Just remember: take a deep breath, look out for your colleagues, blame systems
not people, and don’t rush. Good luck!</p>

<p><em>Missing from this post is any discussion of post-mortems, preparations you can
make before an incident occurs, or any trade-offs like security vs
data-integrity, vs availability. If you’re interested in hearing my opinions on
these, please do tweet me (<a href="https://twitter.com/lawrjones">@lawrjones</a>) and I’ll be delighted to
share!</em></p>

<p><em>Discuss this post on <a href="https://news.ycombinator.com/item?id=24906103">Hackernews</a>.</em></p>
</section>
</article>

<!-- Disqus -->


<!-- Post navigation -->


    </div></div>]]>
            </description>
            <link>https://blog.lawrencejones.dev/incident-response/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906103</guid>
            <pubDate>Tue, 27 Oct 2020 10:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text layout is a loose hierarchy of segmentation]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24906010">thread link</a>) | @adamnemecek
<br/>
October 27, 2020 | https://raphlinus.github.io/text/2020/10/26/text-layout.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/text/2020/10/26/text-layout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I love text layout, and have been working with it in one form or other for over 35 years. Yet, knowledge about it is quite arcane. I don’t believe there is a single place where it’s all properly written down. I have some explanation for that: while basic text layout is very important for UI, games, and other contexts, a lot of the “professional” needs around text layout are embedded in <em>much</em> more complicated systems such as Microsoft Word or a modern Web browser.</p>

<p>A complete account of text layout would be at least a small book. Since there’s no way I can write that now, this blog post is a small step towards that – in particular, an attempt to describe the “big picture,” using the conceptual framework of a “loose hierarchy.” Essentially, a text layout engine breaks the input into finer and finer grains, then reassembles the results into a text layout object suitable for drawing, measurement, and hit testing.</p>

<p>The main hierarchy is concerned with laying out the entire paragraph as a single line of text. Line breaking is also important, but has a separate, parallel hierarchy.</p>

<h2 id="the-main-text-layout-hierarchy">The main text layout hierarchy</h2>

<p>The hierarchy is: paragraph segmentation as the coarsest granularity, followed by rich text style and BiDi analysis, then itemization (coverage by font), then Unicode script, and shaping clusters as the finest.</p>

<p><img src="https://raphlinus.github.io/assets/layout_pyramid.svg" alt="diagram of layout hierarchy"></p>

<h3 id="paragraph-segmentation">Paragraph segmentation</h3>

<p>The coarsest, and also simplest, segmentation task is paragraph segmentation. Most of the time, paragraphs are simply separated by newline (U+000A) characters, though Unicode in its infinite wisdom specifies a number of code point sequences that function as paragraph separators in plain text:</p>

<ul>
  <li>U+000A LINE FEED</li>
  <li>U+000B VERTICAL TAB</li>
  <li>U+000C FORM FEED</li>
  <li>U+000D CARRIAGE RETURN</li>
  <li>U+000D U+000A (CR + LF)</li>
  <li>U+0085 NEXT LINE</li>
  <li>U+2008 LINE SEPARATOR</li>
  <li>U+2009 PARAGRAPH SEPARATOR</li>
</ul>

<p>In rich text, paragraphs are usually indicated through markup rather than special characters, for example <code>&lt;p&gt;</code> or <code>&lt;br&gt;</code> in HTML. But in this post, as in most text layout APIs, we’ll treat rich text as plain text + attribute spans.</p>

<h3 id="rich-text-style">Rich text style</h3>

<p>A paragraph of rich text may contain <em>spans</em> that can affect formatting. In particular, choice of font, font weight, italic or no, and a number of other attributes can affect text layout. Thus, each paragraph is typically broken into a some number of <em>style runs,</em> so that within a run the style is consistent.</p>

<p>Note that some style changes don’t <em>necessarily</em> affect text layout. A classic example is color. Firefox, rather famously, does <em>not</em> define segmentation boundaries here for color changes. If a color boundary cuts a ligature, it uses fancy graphics techiques to render parts of the ligature in different color. But this is a subtle refinement and I think not required for basic text rendering. For more details, see <a href="https://gankra.github.io/blah/text-hates-you/">Text Rendering Hates You</a>.</p>

<h3 id="bidirectional-analysis">Bidirectional analysis</h3>

<p>Completely separate from the style spans, a paragraph may in general contain both left-to-right and right-to-left text. The need for bidirectional (BiDi) text is certainly one of the things that makes text layout more complicated.</p>

<p>Fortunately, this part of the stack is defined by a standard (<a href="http://www.unicode.org/reports/tr9/">UAX #9</a>), and there are a number of good implementations. The interested reader is referred to <a href="https://www.w3.org/International/articles/inline-bidi-markup/uba-basics">Unicode Bidirectional Algorithm basics</a>. The key takeaway here is that BiDi analysis is done on the plain text of the entire paragraph, and the result is a sequence of <em>level runs,</em> where the level of each run defines whether it is LTR or RTL.</p>

<p>The level runs and the style runs are then merged, so that in subsequent stages each run is of a consistent style and directionality. As such, for the purpose of defining the hierarchy, the result of BiDi analysis could alternatively be considered an implicit or derived rich text span.</p>

<p>In addition to BiDi, which I consider a basic requirement, a more sophisticated text layout engine will also be able to handle vertical <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/writing-mode">writing modes</a>, including mixed cases where short strings are horizontal within the vertical primary direction. Extremely sophisticated layout engines will also be able to handle ruby text and other ways of annotating the main text flow with intercalated strings. See <a href="https://www.w3.org/TR/jlreq/">Requirements for Japanese Text Layout</a> for many examples of sophisticated layout requirements; the scope of this blog post really is basic text layout of the kind needed in user interfaces.</p>

<h3 id="itemization-font-coverage">Itemization (font coverage)</h3>

<p>Itemization is the trickiest and least well specified part of the hierarchy. There is no standard for it, and no common implementation. Rather, each text layout engine deals with it in its own special way.</p>

<p>Essentially, the result of itemization is to choose a single concrete font for a run, from a <em>font collection.</em> Generally a font collection consists of a main font (selected by font name from system fonts, or loaded as a custom asset), backed by a <em>fallback stack,</em> which are usually system fonts, but thanks to <a href="https://www.google.com/get/noto/">Noto</a> it is possible to bundle a fallback font stack with an application, if you don’t mind spending a few hundred megabytes for the assets.</p>

<p>Why is it so tricky? A few reasons, which I’ll touch on.</p>

<p>First, it’s not so easy to determine whether a font can render a particular string of text. One reason is <a href="https://unicode.org/reports/tr15/">Unicode normalization</a>. For example, the string “é” can be encoded as U+00E9 (in NFC encoding) or as U+0065 U+0301 (in NFD encoding). Due to the principle of <a href="https://en.wikipedia.org/wiki/Unicode_equivalence">Unicode equivalence</a>, these should be rendered identically, but a font may have coverage for only one or the other in its <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cmap">Character to Glyph Index Mapping</a> (cmap) table. The shaping engine has all the Unicode logic to handle these cases.</p>

<p>Of course, realistic fonts with Latin coverage will have both of these particular sequences covered in the cmap table, but edge cases certainly do happen, both in extended Latin ranges, and other scripts such as Hangul, which has complex normalization rules (thanks in part to a Korean standard for normalization which is somewhat at odds with Unicode). It’s worth noting that <a href="https://devblogs.microsoft.com/oldnewthing/20201009-00/?p=104351">DirectWrite gets Hangul normalization quite wrong</a>.</p>

<p>I believe a similar situation exists with the Arabic presentation forms; see <a href="https://www.arabeyes.org/Developing_Arabic_fonts">Developing Arabic fonts</a> for more detail on that.</p>

<p>Because of these tricky normalization and presentation issues, the most robust way to determine whether a font can render a string is to try it. This is how LibreOffice has worked for a while, and in 2015 <a href="https://lists.freedesktop.org/archives/harfbuzz/2015-October/005168.html">Chromium followed</a>. See also <a href="https://www.chromium.org/teams/layout-team/eliminating-simple-text">Eliminating Simple Text</a> for more background on the Chromium text layout changes.</p>

<p><em>Another</em> whole class of complexity is emoji. A lot of emoji can be rendered with either <a href="https://en.wikipedia.org/wiki/Emoji#Emoji_versus_text_presentation">text or emoji presentation</a>, and there are no hard and fast rules to pick one or the other. Generally the text presentation is in a symbol font, and the emoji presentation is in a separate color font. A particularly tough example is the smiling emoji, which began its encoding life as 0x01 in <a href="https://en.wikipedia.org/wiki/Code_page_437">Code page 437</a>, the standard 8-bit character encoding of the original IBM PC, and is now U+263A in Unicode. However, the suggested default presentation is text, which won’t do in a world which expects color. Apple on iOS unilaterally chose an emoji presentation, so many text stacks follow Apple’s lead. (Incidentally, the most robust way to encode such emoji is to append a <a href="https://en.wikipedia.org/wiki/Variation_Selectors_(Unicode_block)">variation selector</a> to pin down the presentation.)</p>

<p>Another source of complexity when trying to write a cross-platform text layout engine is querying the system fonts. See <a href="https://raphlinus.github.io/rust/skribo/text/2019/04/04/font-fallback.html">Font fallback deep dive</a> for more information about that.</p>

<p>I should note one thing, which might help people doing archaeology of legacy text stacks: it used to be pretty common for text layout to resolve “compatibility” forms such as NFKC and NFKD, and this can lead to various problems. But today it is more common to solve that particular problem by providing a font stack with <em>massive</em> Unicode coverage, including all the code points in the relevant compatibility ranges.</p>

<h3 id="script">Script</h3>

<p>The <em>shaping</em> of text, or the transformation of a sequence of code points into a sequence of positioned glyphs, depends on the script. Some scripts, such as Arabic and Devanagari, have extremely elaborate shaping rules, while others, such as Chinese, are a fairly straightforward mapping from code point into glyph. Latin is somewhere in the middle, starting with a straightforward mapping, but ligatures and kerning are also required for high quality text layout.</p>

<p>Determining script runs is reasonably straightforward - many characters have a Unicode script property which uniquely identifies which script they belong to. However, some characters, such as space, are “common,” so the assigned script just continues the previous run.</p>

<p>A simple example is “hello мир”. This string is broken into two script runs: “hello “ is <code>Latn</code>, and “мир” is <code>Cyrl</code>.</p>

<h3 id="shaping-cluster">Shaping (cluster)</h3>

<p>At this point, we have a run of constant style, font, direction, and script. It is ready for <em>shaping.</em> Shaping is a complicated process that converts a string (sequence of Unicode code points) into positioned glyphs. For the purpose of this blog post, we can generally treat it as a black box. Fortunately, a very high quality open source implementation exists, in the form of HarfBuzz.</p>

<p>We’re not <em>quite</em> done with segmentation, though, as shaping assigns substrings in the input to <a href="https://harfbuzz.github.io/clusters.html">clusters</a> of glyphs. The correspondence depends a lot on the font. In Latin, the string “fi” is often shaped to a single glyph (a ligature). For complex scripts such as Devanagari, a cluster is most often a syllable in the source text, and complex reordering can happen within the cluster.</p>

<p>Clusters are important for <em>hit testing,</em> or determining the correspondence between a physical cursor position in the text layout and the offset within the text. Generally, they can be ignored if the text will only be rendered, not edited (or selected).</p>

<p>Note that these shaping clusters are distinct from grapheme clusters. The “fi” example has two grapheme clusters but a single shaping cluster, so a grapheme cluster boundary can cut a shaping cluster. Since …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/text/2020/10/26/text-layout.html">https://raphlinus.github.io/text/2020/10/26/text-layout.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/text/2020/10/26/text-layout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906010</guid>
            <pubDate>Tue, 27 Oct 2020 10:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Sink, Swim: Guide for Dev Mentors]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905975">thread link</a>) | @morchen
<br/>
October 27, 2020 | https://swimm.io/blog/2020-07-14-who%E2%80%99s-mentoring-the-mentor/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-14-who%E2%80%99s-mentoring-the-mentor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-61c0ab88=""> <!----> <div data-v-2ee12136="" data-v-61c0ab88=""><div><p>Anyone who has ever queried information about developer onboarding, could notice right away, what we at Swimm call ‘The Onboardee Bias’. Most onboarding approaches are centered on guiding new hires through their first days, tasks or overcoming the hurdles of getting started. But this approach rarely highlights the troubles and challenges of the mentors*. While we frequently hear about the “Sink or Swim” approach by which new engineers are “thrown into the deep end” with hands-on tasks on their first day in, the truth is, mentors are also treated this way, although unintentionally with no buoy waiting for them.</p>
<p>Mentors are, by definition, some of the more experienced and confident engineers on the team, so it’s almost counter intuitive to highlight their insecurities. Yet, our experience is that this is in-fact the core problem of engineer onboarding.** <strong>In this post we try to shed light on the role of the mentor in the onboarding process:</strong></p>
<ul>
<li>‘The Good Mentor Checklist’</li>
<li>How Poor Mentorship Reflects in Business</li>
<li>Mentoring the Mentor 101</li>
</ul>
<p><em>* By ‘mentors’ we mean experienced engineers tasked with onboarding a new hire, sometimes also called “buddies” among engineering teams.</em></p>
<p><em>** There are some awesome onboarding experiences out there. We are not saying they don’t exist. But our experience is that they are not the norm.</em></p>
<h2>1. ‘The Good Mentor Checklist’</h2>
<p>The journey to good mentorship starts with reflecting on your own experiences (as a mentor or mentee). Form a list with some of the tools and traits of a super successful mentor, and then try to map out the hurdles - why do some mentors fail to thrive? Here are some key reasons:</p>
<ul>
<li><strong>Time.</strong> Or lack of it. It’s no coincidence that most mentors are extremely busy. Knowing their way around means they get picked for harder tasks. Good mentorship requires ample time and patience, and many mentors lack those.</li>
<li><strong>Good Documentation.</strong> So much has been written and said about how challenging it is to create and maintain good documentation. Suffice to say that a mentor’s life would be much easier with it, and it rarely exists.</li>
<li><strong>Mentorship Skills.</strong> If you have been picked to be a mentor (congrats), you are likely very experienced and know your way around the company or code. But being a really good mentor means you also need an entire skill-set associated with mentorship such as leadership skills, best practices, up to date training techniques, and more.</li>
<li><strong>A Realistic Plan.</strong> While most organisations create a basic onboarding plan for the first few days on the job, this plan consists mostly of HR issues and basic orientation. Our experience shows that most teams don’t have a plan for onboarding the new hires onto the codebase, explaining common issues, legacy code, best practice or edge cases. If they do, it’s a basic checklist.</li>
<li><strong>Passion for apprenticeship</strong>. It goes without saying that a little passion for paying it forward and teaching others, goes a long way and makes all the difference between a mentor and a really good mentor. A major hurdle is identifying such spirit in mentors and leveraging it, but also making sure they don’t burn out.</li>
</ul>
<p><img src="https://swimm.io/media/headway-5qgiuubxkwm-unsplash.jpg" alt="Developers at Swimm working on CSS and Front End Deploying new website" title="The journey to good mentorship starts with reflecting on your own experiences"></p>
<h2>2. How Poor Mentorship Reflects in Business</h2>
<p>So we have established some key elements needed for the job. We also established that many times, mentors, experienced and competent as they may be, are not properly prepared for the task.</p>
<p>How does this affect our job and business?</p>
<ul>
<li><strong>The Swiveling Chair Syndrome</strong>. Getting a task you feel unqualified for, might lead many mentors - even potentially great ones to procrastinate. Preparations for the new hire are pushed to the day before their arrival, and sometimes happen on-the-go. The result of which - talented new engineers swiveling in their chairs for quite some time, waiting for something to happen…(or in other words, stretched out time-to-value).</li>
<li><strong>System malfunctions</strong>. Another unfortunate product could be finger-pointing and blaming “the system”. Feeling embarrassed with their inadequacy, mentors might vent hints of frustration with the new hire: “Yeah, there’s some documentation, but I wouldn’t bother with it… Just try to figure it out…” or “They told me you were coming last week, but we have a version coming out, so I guess you’ll have to manage…”. Of course, these are the last things you want new hires to hear in their first few weeks.</li>
<li><strong>Sinking, not swimming</strong>. We mentioned the “sink or swim” approach earlier. Sure, letting new hires struggle with no help is a way to weed out weaker hires, and it may shorten the time it takes to spot a poor fit. But this also means you are giving the good hires a hard time, sending them to fend for themselves. This method is often used to mask insecurity. Rather than admitting you don’t know how to deal with onboarding someone, it is much easier to explain a lack of a plan with ideology. So, even if this method is not beneficial in the long run, unprepared mentors might adopt it anyway.</li>
</ul>
<h2><strong>3. Mentoring the Mentor 101</strong></h2>
<p>So, what can you do about this naturally occurring bias?</p>
<p>Like with other issues, acknowledging there is a problem (i.e. that mentors are being overlooked) is a good starting point. Ask senior developers how prepared they were or currently feel to mentor. Ask them how their own onboarding was like, and whether they would have wanted it to be different. Recall your own onboarding experiences, both as a mentor and a new hire. But mainly, focus on cultivating a culture of knowledge sharing, and creating a tier of mentors equipped with the best tools to handle their next mentoring assignment.</p>
<p>---</p>
<p><a href="https://www.linkedin.com/in/tom-ahi-dror/">Tom Ahi Dror</a> is the co-founder of <strong>Swimm</strong>, a DevTool that helps engineers ramp-up to any codebases at ease and speed optimizing team productivity, independent work and time-to-value. Tom joined his partners in creating Swimm, after witnessing how engineer onboarding practices could massively affect R&amp;D effectiveness. Tom was commander of the Israeli elite program Talpiot , and was one of leaders behind ITC.tech. He has a Masters in Public Policy from Princeton, a MBA from Tel Aviv University and a B.Sc. in Physics and Math from the Hebrew University.</p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-14-who%E2%80%99s-mentoring-the-mentor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905975</guid>
            <pubDate>Tue, 27 Oct 2020 10:18:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmable In-Memory Image Processing Accelerator Using Near-Bank Architecture [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24905827">thread link</a>) | @blopeur
<br/>
October 27, 2020 | https://miglopst.github.io/files/gu_isca2020.pdf | <a href="https://web.archive.org/web/*/https://miglopst.github.io/files/gu_isca2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://miglopst.github.io/files/gu_isca2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905827</guid>
            <pubDate>Tue, 27 Oct 2020 09:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series on building a Swift HTTP framework]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905824">thread link</a>) | @Austin_Conlon
<br/>
October 27, 2020 | https://davedelong.com/blog/2020/06/27/http-in-swift-part-1/ | <a href="https://web.archive.org/web/*/https://davedelong.com/blog/2020/06/27/http-in-swift-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    


    

    
    
    
    


    

    
    
    
    


    

    
    
    
    

<p>Part 1 in a series on building a Swift HTTP framework:</p>

<ol>
	
	
	<li>HTTP in Swift, Part 1: An Intro to HTTP</li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/06/28/http-in-swift-part-2-basic-structures/">HTTP in Swift, Part 2: Basic Structures</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/06/30/http-in-swift-part-3-request-bodies/">HTTP in Swift, Part 3: Request Bodies</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/02/http-in-swift-part-4-loading-requests/">HTTP in Swift, Part 4: Loading Requests</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/03/http-in-swift-part-5-testing-and-mocking/">HTTP in Swift, Part 5: Testing and Mocking</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/04/http-in-swift-part-6-chaining-loaders/">HTTP in Swift, Part 6: Chaining Loaders</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/05/http-in-swift-part-7-dynamically-modifying-requests/">HTTP in Swift, Part 7: Dynamically Modifying Requests</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/09/http-in-swift-part-8-request-options/">HTTP in Swift, Part 8: Request Options</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/12/http-in-swift-part-9-resetting/">HTTP in Swift, Part 9: Resetting</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/19/http-in-swift-part-10-cancellation/">HTTP in Swift, Part 10: Cancellation</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/20/http-in-swift-part-11-throttling/">HTTP in Swift, Part 11: Throttling</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/23/http-in-swift-part-12-retrying/">HTTP in Swift, Part 12: Retrying</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/27/http-in-swift-part-13-basic-authentication/">HTTP in Swift, Part 13: Basic Authentication</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/07/28/http-in-swift-part-14-oauth-setup/">HTTP in Swift, Part 14: OAuth Setup</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/08/03/http-in-swift-part-15-oauth/">HTTP in Swift, Part 15: OAuth</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/08/05/http-in-swift-part-16-composite-loaders/">HTTP in Swift, Part 16: Composite Loaders</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/10/03/http-in-swift-part-17-brain-dump/">HTTP in Swift, Part 17: Brain Dump</a></li>
	
	
	
	<li><a href="https://davedelong.com/blog/2020/10/03/http-in-swift-part-18-wrapping-up/">HTTP in Swift, Part 18: Wrapping Up</a></li>
	
	
</ol>
    
    




<hr>

    <p>For a while now I’ve had a series of blog posts floating around in my head on how to build an HTTP stack in Swift. The idea started last spring with Rob Napier’s <a href="https://robnapier.net/start-with-a-protocol">blog posts on protocols</a>, and matured last summer and fall while I was working at WeWork on an internal Swift framework.</p>

<p>So, with my <a href="https://davedelong.com/blog/2020/06/14/anything-worth-doing/">newfound blogging powers</a>, I think it’s time to tackle this problem. Over the course of several posts, I’ll walk through a number of topics related to HTTP and how we can fit them together into a great Swift framework. We’ll end up with a framework that supports things like:</p>

<ul>
  <li>automatically retrying requests</li>
  <li>throttling to a customizable maximum number of concurrent requests</li>
  <li>specifying custom server environments for an entire connection stack, or for a single request</li>
  <li>automatically cancelling in-flight requests when the stack is reset</li>
  <li>basic mesh networking</li>
  <li>implementing OAuth (or any sort of authenticated request)</li>
  <li>multi-part form uploads</li>
  <li>easy mocking of responses</li>
  <li>… and a whole lot more I’m glossing over</li>
</ul>

<p>We’ll be building all of this on top of <code>URLSession</code>. And along the way, we’ll be addressing a lot of the feedback I <a href="https://davedelong.com/blog/2018/03/02/apple-networking-feedback/">provided to Apple Engineers</a> about the state of the built-in networking stack. (Awesomely, in the past 2 years a couple of those items have already been addressed)</p>

<p>I will preempt any questions by saying: I will <em>not</em> be publishing the actual code for this framework online. The purpose of these posts is to describe the problems and solutions, but implementing them will be left up to you. I will have small embedded snippets to illustrate concepts, but largely the entire thing will be left as an “exercise for the reader”. There’s just no substitute for sitting down and writing the code yourself.</p>

<p>But… before we get started in Swift, we need to answer a really fundamental question.</p>

<h2 id="what-on-earth-is-http">What on earth is HTTP?</h2>

<p>HTTP, or the <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">“Hypertext Transfer Protocol”</a>, is a specification for describing how two different systems can communicate with each other. As its name implies, it’s a <em>text</em>-based specification. This is great for humans, because text is nicely readable, and it’s good for machines, because text is pretty nicely compressible (which is a major part of the 2.0 specification).</p>

<p>HTTP defines a very specific <a href="https://en.wikipedia.org/wiki/Request%E2%80%93response">“request/response”</a> model. You send out a request for information, and you get a response back. One request, one response.</p>

<p>A request has the following format:</p>

<ol>
  <li>A request line</li>
  <li>Zero-or-more header value lines</li>
  <li>A blank line</li>
  <li>An optional body</li>
</ol>

<h3 id="request-lines">Request Lines</h3>

<p>A request line looks something like:</p>



<p>The first part of the line is the <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods">request method</a>. We’re most familiar with <code>GET</code> and <code>POST</code>, but other common HTTP methods include things like <code>HEAD</code>, <code>PUT</code>, <code>DELETE</code>, and so on. In reality, the HTTP spec itself does not place a limit on the value of the request method, which allows for specs like <a href="https://en.wikipedia.org/wiki/WebDAV">WebDAV</a> (which powers CalDAV and CardDAV) to add their own methods like <code>COPY</code>, <code>LOCK</code>, <code>PROPFIND</code>, and so on.</p>

<p>This leads us to the simplest of problems with a lot of Swift networking frameworks. It’s really common to see something like this:</p>

<div><div><pre><code><span>public</span> <span>enum</span> <span>HTTPMethod</span><span>:</span> <span>String</span> <span>{</span>
    <span>case</span> <span>get</span> <span>=</span> <span>"GET"</span>
    <span>case</span> <span>post</span> <span>=</span> <span>"POST"</span>
    <span>case</span> <span>put</span> <span>=</span> <span>"PUT"</span>
    <span>case</span> <span>delete</span> <span>=</span> <span>"DELETE"</span>
<span>}</span>
</code></pre></div></div>

<p>Since the HTTP spec allows for <em>any</em> single-word method, defining this value in Swift as an <em>enum</em> is incorrect, because an enum only allows for a finite number of values, but there are an infinite number of possible “single word” values. A <em>better</em> implementation of this is to use a <code>struct</code>:</p>

<div><div><pre><code><span>public</span> <span>struct</span> <span>HTTPMethod</span><span>:</span> <span>Hashable</span> <span>{</span>
    <span>public</span> <span>static</span> <span>let</span> <span>get</span> <span>=</span> <span>HTTPMethod</span><span>(</span><span>rawValue</span><span>:</span> <span>"GET"</span><span>)</span>
    <span>public</span> <span>static</span> <span>let</span> <span>post</span> <span>=</span> <span>HTTPMethod</span><span>(</span><span>rawValue</span><span>:</span> <span>"POST"</span><span>)</span>
    <span>public</span> <span>static</span> <span>let</span> <span>put</span> <span>=</span> <span>HTTPMethod</span><span>(</span><span>rawValue</span><span>:</span> <span>"PUT"</span><span>)</span>
    <span>public</span> <span>static</span> <span>let</span> <span>delete</span> <span>=</span> <span>HTTPMethod</span><span>(</span><span>rawValue</span><span>:</span> <span>"DELETE"</span><span>)</span>

    <span>public</span> <span>let</span> <span>rawValue</span><span>:</span> <span>String</span>
<span>}</span>
</code></pre></div></div>

<p>After the method comes the path, which should be readily recognizable as the <code>.path</code> of a <code>URL</code>.</p>

<p>Finally, there’s a bit about which HTTP spec version you’re using. HTTP 2.0 is commonly used these days, but since it mainly deals with <em>compressed</em> HTTP requests, I’ll use the 1.1 version, which describes <em>uncompressed</em> requests.</p>



<p>Headers are a series of key-value pairs, in a familiar key-value-looking format:</p>

<div><div><pre><code>Host: swapi.dev
Connection: close
User-Agent: Paw/3.1.10 (Macintosh; OS X/10.15.5) GCDHTTPRequest
</code></pre></div></div>

<p>There are a number of <a href="https://en.wikipedia.org/wiki/List_of_HTTP_header_fields">header fields commonly used with HTTP</a>, some of them defined by the specs, and some agreed upon by convention. Like with request methods, there’s no limit to the possible names of a header, nor much of a limit on the possible values.</p>

<h3 id="the-body">The Body</h3>

<p>Any HTTP request may include a body. Yes, even a <code>GET</code> request is allowed to include a body. However, most servers will only interpret the body of a request based on which request method is used, so it’s likely that even if you did include a body with a <code>GET</code> requests, the server would ignore it.</p>

<p>The body itself is just raw binary data. How it’s interpreted by the server depends entirely on conventions agreed upon between the server engineers and the client engineers.</p>

<h2 id="putting-a-request-together">Putting a request together</h2>

<p>If we want to execute a basic HTTP request to the <a href="https://swapi.dev/">Star Wars API</a>, we would construct an HTTP request that looks like this:</p>

<div><div><pre><code>GET /api/ HTTP/1.1
Host: swapi.dev
Connection: close
User-Agent: Paw/3.1.10 (Macintosh; OS X/10.15.5) GCDHTTPRequest

</code></pre></div></div>

<p>We can see the request line, 3 header lines, and an empty line at the end. It’s important to note that every line in an HTTP request is separated by <em>two</em> characters: <code>\r\n</code> (carriage return + line feed). This becomes more apparent when we look at the hex representation of this request (newlines inserted for readability):</p>

<div><div><pre><code>474554202F6170692F20485454502F312E310D0A 
486F73743A2073776170692E6465760D0A
436F6E6E656374696F6E3A20636C6F73650D0A 
557365722D4167656E743A205061772F332E312E313020284D6163696E746F73683B204F5320582F31302E31352E35292047434448545450526571756573740D0A
0D0A
</code></pre></div></div>

<p><code>0D</code> and <code>0A</code> are the hexadecimal representation of <code>\r</code> and <code>\n</code>, respectively. The empty line is how an HTTP server knows where the headers stop and the body begins.</p>

<blockquote>
  <p>As an aside, if you find yourself working with network APIs a lot, I <em>highly</em> recommend using Lucky Marmot’s fantastic app <a href="https://paw.cloud/">Paw</a>. It is an indispensable tool for analyzing and tweaking network calls.</p>
</blockquote>

<p>Another thing worth pointing out here is that <code>Host:</code> header. While it’s required by the spec, it doesn’t necessarily specify where the request is going. That’s because the host part of the URL is used before the request is ever sent by the <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS resolution process</a> as part of the whole “what server am I actually connecting to” flow. The <code>Host</code> header is included for clarity while debugging, and it may be used by the server for further internal routing. For example, you could imagine a server for all of Github Pages using the <code>Host</code> header to know which set of pages you actually want.</p>

<p>So, that’s the request.</p>

<h2 id="what-about-the-response">What about the response?</h2>

<p>The response we get back is almost identical in structure to the request. It has:</p>

<ol>
  <li>The response line</li>
  <li>Zero or more header value lines</li>
  <li>An empty line</li>
  <li>An optional body</li>
</ol>

<p>So, that request to the Star Wars API will have a response that looks like this:</p>

<div><div><pre><code>HTTP/1.1 200 OK
Server: nginx/1.16.1
Date: Sat, 27 Jun 2020 19:13:53 GMT
Content-Type: application/json
Transfer-Encoding: chunked
Connection: close
Vary: Accept, Cookie
X-Frame-Options: SAMEORIGIN
ETag: "57e8c3fe1ac5cb74e15b96dc98767ce6"
Allow: GET, HEAD, OPTIONS
Strict-Transport-Security: max-age=15768000

{"people":"http://swapi.dev/api/people/","planets":"http://swapi.dev/api/planets/","films":"http://swapi.dev/api/films/","species":"http://swapi.dev/api/species/","vehicles":"http://swapi.dev/api/vehicles/","starships":"http://swapi.dev/api/starships/"}
</code></pre></div></div>

<p>Like with the request, all lines are separated by <code>\r\n</code>, and the empty line is how we know where the headers stop and the body begins. The only other difference is that the first line now has an integer <a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes">status code</a> and a textual description of the code’s meaning.</p>

<p>Like with request methods, there’s no real limit on the status code values and message. The HTTP spec defines many that we’re familiar with, such as <code>200</code> (OK) and <code>404</code> (Not Found), as well as the allowed range of numbers (100 … 599). But… you <em>could</em> return a <code>666 Diabolical</code> code, or <code>42 Mostly Harmless</code> code. You could even return a <code>200 👍</code> response. But please don’t. 😅</p>

<p>The body, again, is raw binary data and it’s up to the recipient to correctly interpret it. The Star Wars API body is JSON-encoded text, but a body can just as easily be the raw bytes of a <code>.jpg</code> file, or the XML bytes of an RSS feed, or the text that describes an <a href="https://en.wikipedia.org/wiki/M3U">HTTP live streaming playlist</a>.</p>

<h2 id="putting-it-together">Putting it together</h2>

<p>That’s an overview of HTTP requests and responses. This simple model describes the fundamental communications used by most of the internet. It doesn’t cover things like web sockets or push notifications, but this is used by every website and most network APIs. Knowing the details of how this works continues to be one of the most valuable and consistently useful things I know and use as a software engineer.</p>

<p>In the next post, we’ll take a look at how we move from this specification to the basic structures we’ll need for our framework.</p>

  </div></div>]]>
            </description>
            <link>https://davedelong.com/blog/2020/06/27/http-in-swift-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905824</guid>
            <pubDate>Tue, 27 Oct 2020 09:50:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poland objected to use of ‘gender’ in EU digital equality text]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905648">thread link</a>) | @nathell
<br/>
October 27, 2020 | https://www.researchprofessionalnews.com/rr-news-europe-innovation-2020-10-poland-objected-to-use-of-gender-in-eu-digital-equality-text/ | <a href="https://web.archive.org/web/*/https://www.researchprofessionalnews.com/rr-news-europe-innovation-2020-10-poland-objected-to-use-of-gender-in-eu-digital-equality-text/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main" data-router-wrapper="">
		<article data-router-view="name">

			<div>
		
<article id="post-255588">
	
	<div>
		<div>
			<p><img width="738" height="443" src="https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-738x443.jpg" alt="" srcset="https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-738x443.jpg 738w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-300x180.jpg 300w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-600x360.jpg 600w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-310x186.jpg 310w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-143x86.jpg 143w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity-633x380.jpg 633w, https://researchresearch-news-wordpress-media-live.s3.eu-west-1.amazonaws.com/2020/07/engineer_computer_digital_design_woman_diversity.jpg 750w" sizes="(max-width: 738px) 100vw, 738px"></p><section>
					
<p><strong>Ambassador says government supports equality but ‘gender’ is poorly defined in EU law</strong></p>
<p>Poland’s&nbsp;government was the only one in the Council of the EU that opposed adopting draft conclusions on digital technologies and fundamental rights earlier this week, Research Professional News can reveal. A spokesperson for the government said it did so over the inclusion of the term ‘gender’ in the document.</p>
<p>The conclusions, published on 21 October, refer to the opportunities and problems that artificial intelligence poses for gender equality, and say the EU will cooperate with the human rights body the Council of Europe to promote gender equality.</p>				</section>

					<section>
		<p>This article is only available to *Research Professional subscribers. If you are a subscriber you can read the article in full on <a href="https://www.researchprofessional.com/0/rr/article/1390565" target="_blank" rel="noopener">researchprofessional.com</a></p>
	</section>
		</div>
		

	</div>
</article>

	</div>
	

		</article>	</div></div>]]>
            </description>
            <link>https://www.researchprofessionalnews.com/rr-news-europe-innovation-2020-10-poland-objected-to-use-of-gender-in-eu-digital-equality-text/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905648</guid>
            <pubDate>Tue, 27 Oct 2020 09:11:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics in Qt 6.0: QRhi, Qt Quick, Qt Quick 3D]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24905634">thread link</a>) | @MikusR
<br/>
October 27, 2020 | https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Monday October 26, 2020 by <a href="https://www.qt.io/blog/author/laszlo-agocs">Laszlo Agocs</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Last year we had a three part blog series about Qt's new approach to working with 3D graphics APIs and shading languages: <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-direct3d">part 1</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-2">part 2</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-3">part 3</a>. For <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-index.html">Qt Quick</a>, an early, opt-in preview of the new rendering architecture was shipped in Qt 5.14, with some improvements in Qt 5.15. With the release of Qt 6.0 upcoming, let's see what has happened since Qt 5.15. It will not be possible to cover every detail of the graphics stack improvements for Qt Quick here, let alone dive into the vast amount of Qt Quick 3D features, many of which are new or improved in Qt 6.0. Rather, the aim is just to give an overview of what can be expected from the graphics stack perspective when Qt 6.0 ships later this year.</p>
<p>Note that the documentation links refer to the Qt 6 snapshot documentation. This allows seeing the latest C++ and QML API pages, including all changed and new functions, but the content is also not final. These links may also break later on.</p>
<!--more-->
<h2>QRhi improvements</h2>
<p>QRhi, the Qt Rendering Hardware Interface, is Qt's internal graphics abstraction when 3D APIs, such as OpenGL, Vulkan, Metal, and Direct 3D, are involved. Compared to 5.15, the main improvements in 6.0 are a lot of polishing fixes here and there, and, most importantly, a large set of performance optimizations. While benefitting Qt Quick as well, these become especially important with Qt Quick 3D when complex scenes with many renderable objects are involved.</p>
<p>With some simplifications, the main layers of the Qt 6.0 graphics stack can be visualized like this:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png" alt="rhiarch-3" width="800" srcset="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=400&amp;name=rhiarch-3.png 400w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png 800w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1200&amp;name=rhiarch-3.png 1200w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1600&amp;name=rhiarch-3.png 1600w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2000&amp;name=rhiarch-3.png 2000w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2400&amp;name=rhiarch-3.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<h2>Shader management</h2>
<p>The Qt Shader Tools module is now a selectable module in the installer. For applications this can be relevant because this is the module that provides the <em>qsb</em> command-line tool (not to be confused with <em>qbs</em>) and its associated CMake build system integration. In addition, the module is a mandatory dependency for Qt Quick 3D at the moment.</p>
<p>Qt 6 no longer uses OpenGL-compatible GLSL source snippets directly. Rather, shaders are all written in Vulkan-style GLSL, then reflected and translated to other shading languages, and finally packaged up into a serializable QShader object that can be consumed by QRhi. The shader preparation pipeline in Qt 6 is the following:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png" alt="shaderconditioning" width="1280" srcset="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=640&amp;name=shaderconditioning.png 640w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png 1280w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1920&amp;name=shaderconditioning.png 1920w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=2560&amp;name=shaderconditioning.png 2560w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3200&amp;name=shaderconditioning.png 3200w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3840&amp;name=shaderconditioning.png 3840w" sizes="(max-width: 1280px) 100vw, 1280px"></p>
<p>In QML applications using Qt Quick, whenever working with ShaderEffect, or subclassing QSGMaterialShader, the application will need to provide a baked shader pack in form of a .qsb file. These are generated by the <em>qsb</em> tool. This does not however mean that developers have to start dealing with a new tool directly: with the CMake integration one can easily list the vertex, fragment, and compute shaders in CMakeLists.txt via the qt6_add_shaders() CMake function. Invoking qsb and packing the resulting .qsb files into the Qt resource system is then taken care of by the build system.</p>
<p>See <a href="https://doc-snapshots.qt.io/qt6-dev/qtshadertools-index.html">the shadertools documentation</a> for an overview of how graphics and compute shaders are handled in Qt 6 and the details of the qsb tool and its CMake integration.</p>
<h2>Direct OpenGL is no more for Qt Quick</h2>
<p>In Qt 5.14 and 5.15, Qt Quick shipped with an optional QRhi-based rendering path that could be enabled by setting the environment variable <em>QSG_RHI</em>. This allowed painless experimenting with the new stack, while keeping the traditional, battle tested direct OpenGL code path the default.</p>
<p>In Qt 6.0 all such switches are gone. There is no way get rendering go directly to OpenGL with Qt Quick scenes. Rather, the new default is the QRhi-based rendering path of the Qt Quick scene graph. Other than the defaults changing, the ways to configure what QRhi backend, and so which graphics API to use are mostly unchanged compared to Qt 5.15. See <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph-renderer.html#rendering-via-the-qt-rendering-hardware-interface">the documentation</a> for details. One difference is better API naming: in C++ code to request, and so effectively tie the application to, a given QRhi backend (and by extension graphics API) is now done through the <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#setGraphicsApi">QQuickWindow::setGraphicsApi()</a> function, whereas in 5.15 this task used to be pushed onto an overload of setSceneGraphBackend(), leading to fairly inaccurate naming.</p>
<p>There are a number of implications, although many applications will not notice any of these. If an application uses neither shader code (ShaderEffect, QSGMaterial) nor does it perform its own rendering with OpenGL directly, there is a very high chance that it will need no migration steps at all. (at least not because of graphics)</p>
<h4>Applications using OpenGL directly</h4>
<p>What about applications that use OpenGL directly in one way or another, and are not interested in functioning with other graphics APIs? For example, applications that use <a href="https://doc-snapshots.qt.io/qt6-dev/qquickframebufferobject.html">QQuickFramebufferObject</a>, or connect to signals like <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRendering">QQuickWindow::beforeRendering()</a> to inject their own OpenGL rendering under or above the Qt Quick scene. This is when the setGraphicsApi() function mentioned above comes into play for real: if an application wishes, it can always state that it wants OpenGL (or Vulkan, or Metal, or D3D) only, and nothing else. That way it is guaranteed that Qt Quick is going to use the corresponding QRhi backend (or else it will fail to initialize), so the application can safely assume that going directly to OpenGL is safe, because Qt Quick will also end up rendering through OpenGL. Note that this does not exempt the application from having to do other type of porting steps: for example, if it in addition uses ShaderEffect or creates its own custom materials, it will still need to migrate to the new ways of handling shaders and materials.</p>
<h4>QSG* and QQuick* API changes</h4>
<p>The API changes mainly fall into 3 categories. This is not going to be an exhaustive list, but rather just a peek at some of the important changes. Detailed change lists and porting guides are expected to be available with the final Qt 6.0 release.</p>
<ul>
<li>
<div><p>Different approach to shaders and materials: <a href="https://doc-snapshots.qt.io/qt6-dev/qsgmaterialshader.html">QSGMaterialShader</a> received a full revamp (matching more or less what the now-removed QSGMaterialRhiShader used to be in 5.14 and 5.15). <a href="https://doc-snapshots.qt.io/qt6-dev/qml-qtquick-shadereffect.html">ShaderEffect</a> no longer allows inline shader strings. Rather, the vertexShader and fragmentShader properties are URLs, similarly to <span>Image.source</span> and others. They can refer to a local .qsb file, or a .qsb file embedded via the Qt resource system (qrc).</p></div>
</li>
<li>
<p>Removing OpenGL-specifics from QQuickWindow, QSGTexture, and elsewhere. It should come as no surprise that functions like <em>GLuint textureId()</em>, <em>createTextureFromId(GLuint textureId, ...)</em>, or <em>setRenderTarget(GLuint fboId)</em> are now gone. Adopting (wrapping) an existing OpenGL texture, Vulkan image, Metal texture, or D3D11 texture, or accessing the underlying native texture for a QSGTexture is still perfectly possible, but now is done via a different set of APIs, such as <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qsgvulkantexture.html">QSGVulkanTexture</a> and the <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-sub-qtquick.html">other similar classes</a>, instances of which are <a href="https://doc-snapshots.qt.io/qt6-dev/qsgtexture.html?__hstc=233546881.8510e053e4fb66e1a58543a6e9886427.1603454017210.1603454017210.1603454017210.1&amp;__hssc=233546881.1.1603454017210&amp;__hsfp=1285229618#nativeInterface" rel="noopener">queryable from QSGTexure</a>.</p>
<ul>
<li>
<div><p>Integrating the application's own custom rendering with the graphics API that Qt Quick renders with is fully supported, not just for OpenGL, but also Vulkan, Metal, and D3D11. Due to their nature however, some of these APIs will need more than connecting to one single signal like beforeRendering() or afterRendering(). For example, we now also have <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRenderPassRecording">beforeRenderPassRecording()</a>. See the relevant section in the <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph.html#mixing-scene-graph-and-the-native-graphics-api">scenegraph overview docs</a> for more details and links to examples. Finally, the number of native graphics resources queryable via <a href="https://doc-snapshots.qt.io/qt6-dev/qsgrendererinterface.html">QSGRendererInterface</a> has been extended, now covering Vulkan, Metal, and Direct 3D too.</p></div>
</li>
</ul>
</li>
<li>
<p>Extending support for redirecting the Qt Quick scene into an offscreen render target. <a href="https://www.qt.io/blog/%3Ehttps://doc-snapshots.qt.io/qt6-dev/qquickrendercontrol.html">QQuickRenderControl</a> and the related infrastructure has been heavily enhanced. This was done not just to enable working with graphics APIs other than OpenGL the same way as in Qt 5 (for example, to render a Qt Quick scene into a Vulkan VkImage without an on-screen window), but also to enable integration with AR/VR frameworks and APIs such as <a href="https://www.khronos.org/openxr/">OpenXR</a> (in combination with any of Vulkan, D3D11, or OpenGL). Besides the slightly changed QQuickRenderControl interface, we now have a number of helper classes that improve the configurability of a QQuickWindow: <a href="https://doc-snapshots.qt.io/qt6-dev/qquickrendertarget.html">QQuickRenderTarget</a>, <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsdevice.html">QQuickGraphicsDevice</a>, and <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsconfiguration.html">QQuickGraphicsConfiguration</a>. These are essential in scenarios where a more fine grained control is needed: integrating with APIs like OpenXR is not always straightforward when an existing rendering engine is involved, with a number of potential chicken-egg problems when it comes to the creation, initialization, and ownership of instance, device, and other graphics objects: Which Vulkan instance should Qt Quick use, or should it create a new one upon initializing the scenegraph for the first time? Which Vulkan physical device or DXGI adapter should Qt Quick pick, or just stay with the default? Which VkDevice extensions should be enabled in addition to what Qt itself needs? What 2D image/texture should rendering target, who creates that and when? The expectation is that Qt 6.0 will be well-prepared and providing the foundations for further exploring the world of AR/VR during the rest of the Qt 6.x series.</p>
</li>
</ul>
<h4>New approach to handling shader code in ShaderEffect</h4>
<p>A comprehensive example of the new approach to shader code in ShaderEffect is the Qt 6 port of the classic Qt 5 Cinematic Experience demo. <a href="https://github.com/alpqr/qt5-cinematic-experience" rel="noopener">(GitHub repo)</a> This version is ported to CMake and is fully functional with all graphics APIs, including all shader and particle effects.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png" alt="cinematic" width="702" srcset="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=351&amp;name=cinematic.png 351w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png 702w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1053&amp;name=cinematic.png 1053w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1404&amp;name=cinematic.png 1404w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1755&amp;name=cinematic.png 1755w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=2106&amp;name=cinematic.png 2106w" sizes="(max-width: 702px) 100vw, 702px"></p>
<p>Looking at the QML source code, for example the code for the <a href="https://github.com/alpqr/qt5-cinematic-experience/blob/master/content/CurtainEffect.qml" rel="noopener">curtain effect </a>shows that indeed it has all inline GLSL strings removed.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png" width="354" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=177&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 177w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 354w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=531&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 531w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=708&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 708w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=885&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 885w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=1062&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 1062w" sizes="(max-width: 354px) 100vw, 354px"></p>
<p>Instead, the vertex and fragment shaders now live as <a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener">ordinary files in the source tree</a>, not bundled with the application executable anymore.</p>
<p><a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener"><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png" width="300" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=150&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 150w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 300w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=450&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 450w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=600&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 600w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=750&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 750w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=900&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 900w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>It is now up to the build system and Qt Shader Tools to compile, reflect, and translate at build time - with the added benefit of shader compilation errors becoming proper build errors instead of …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905634</guid>
            <pubDate>Tue, 27 Oct 2020 09:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReMarkable 2: my subjective review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905623">thread link</a>) | @liveweird
<br/>
October 27, 2020 | https://no-kill-switch.ghost.io/remarkable-2-my-subjective-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/remarkable-2-my-subjective-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5f973d579b10c10039cc3d9d">
	

	<section>
		<p>I am a notorious note-taker. Over the years, I've learned not to rely solely on my (or anyone else's) memory but to create well structured, concise, and adequately labeled notes for future use. It's not only required to preserve the knowledge, but it helps you develop some valuable abilities &amp; skills, e.g.:</p><ul><li>synthesis of information</li><li>clarity of thought</li><li>proper application of mental models</li><li>crafting a visual structure that carries the supplementary information</li><li>sketching :)</li></ul><p>I've tried various techniques of note-taking. Friction-less apps like Bear, personal knowledge management tools like Notion, audio recorders like Otter, outlining tools like Workflowy, Zettelkasten-inspired research tools like Roam or Obsidian. All of them have their pros, I still use some of them daily for specific purposes (Notion, Roam), but none of them has beaten the <strong>fundamental advantages</strong> of a thin sheet of paper:</p><ul><li>minimum latency (&amp; inertia)</li><li>maximum flexibility (when it comes to notation &amp; form - nothing is enforced)</li></ul><p>Obviously, <strong>paper has its flaws</strong> as well:</p><ul><li>it's immutable</li><li>digitizing it is a manual, cumbersome process</li><li>full freedom of what you draw/write/scribble is fantastic, but sometimes it would save a lot of time to have a library of stencils/templates</li><li>inventorizing the notes properly (so they're searchable/navigable in scale) is not easy</li><li>making cross-content references is also a pain</li></ul><p>Is it possible to have a solution <strong>with the advantages of paper but devoid of its flaws</strong>? In my quest to answer this question, I've decided to reach for an e-ink tablet named <a href="https://remarkable.com/store/remarkable-2">reMarkable 2</a>.</p><hr><p>It's the 2nd iteration of that concept. I was considering a purchase of the previous generation one, but in the end, I've passed because of the high price and moderately enthusiastic reviews on the Internet. According to its creators' declaration, the new edition is supposed to fix its predecessor's flaws. And the price tag is much more wallet-friendly.</p><p>So in the end I've decided to give it a go. The production and delivery cycle has been delayed due to COVID-19 (by two months), but I've finally received my device, used it for few weeks, and can now provide you my initial review.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_2.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/10/remarkable_2.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_2.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>Before I dive into the actual details - what precisely did I order? Apart from the tablet itself (there's just one model, no options/variants), I've picked the marker (more expensive version - with the eraser) and a folio case (opens like a book, covers full tablet).</p><p>I'll spare you all the specification details - screen density, dimensions, weight, etc. - you can find all of those at the manufacturer's site. I'd like to focus on impressions &amp; conclusions only.</p><p>IMHO the hardware quality is on par with <strong>Amazon Kindle Oasis 2</strong> - the e-book reader I use daily for a long time. Solid, sturdy, durable, thin &amp; aesthetic. No cheap plastic elements. The only visible differences between Oasis and reMarkable 2 (except for the size) are the lack of screen backlight and turn-page buttons. </p><p>Additional observations:</p><ol><li>the screen is not automatically turned on/off when closing the folio case - TBH I don't find it a significant flaw</li><li>the marker is attached magnetically to the side of the tablet - it snaps precisely, exactly when expected, and it doesn't drop off randomly - zero complaints here</li></ol><hr><p>Marker is not required to use reMarkable 2, but TBH using the tablet w/o it kind of misses the whole point. It's supposed to be <strong>a note-taking device, not an e-book reader</strong>. You've been probably waiting for that, so I'm not stalling anymore: the marker works surprisingly well - both accuracy and latency are more than acceptable:</p><ul><li>I don't remember getting frustrated that the effect of my scribbling doesn't match my intent (<u>precision</u>)</li><li>the <u>feedback</u> is nearly instantaneous - I didn't have a feeling I'm intentionally slowing down (writing or scribbling) to compensate for any device's speed deficiencies</li><li>the speed (of a move, while marker touches the surface) doesn't affect the <u>accuracy</u> (fluidity) - lines remain continuous, without gaps or other inaccuracies</li></ul><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_5.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/10/remarkable_5.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_5.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>Btw. the marker has a removable rod at its tip - that's the only surface that touches the screen when scribbling. I can't tell how quickly it wears out, but you get a few spare ones as replacements. So far, I didn't notice any scratches on the e-ink screen - let's hope it stays that way.</p><p>My marker (the more expensive version) theoretically works like a pencil with an eraser at the opposite end. That's the theory - in practice, it turns out that you can't rub (to erase), but you need to poke. It's not only unintuitive but also quite slow. However - it works.</p><p>Overall, reMarkable 2 hardware doesn't disappoint - it provides <u><strong>a solid base to meet expectations</strong></u>, but TBH there was no <em>"wow effect"</em> - I didn't have a feeling of handling a breakthrough <em>"next-gen"</em> device.</p><p>There are three pieces of software to evaluate pretty much independently:</p><ol><li>Tablet firmware</li><li>PC companion app</li><li>Chrome extension</li></ol><h3 id="tablet-firmware">Tablet firmware</h3><p>Needless to say, good hardware is crap w/o decent software (on the device). Surprisingly reMarkable 2 <strong>doesn't shine here</strong>. Tablet's software is very minimalistic (which is not an issue <em>per se</em>) - you can read e-books and make notes, but the software doesn't do much to improve/expand the experience:</p><ul><li>no dictionaries/Wiki support</li><li>no bookmarking/indexing</li><li>three colors (black, one shade of grey, white) for note-taking :(</li><li>the surface for scribbling is fixed (forget about infinite whiteboard ...) and in fact rather small (but you can easily add more sheets, of course)</li><li>OCR functionality is limited - whole page or nothing</li><li>there's zero integration with popular note-taking tools/platforms (like Evernote or OneNote) - all you can do is to export to image formats like PNG</li></ul><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_4.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_4.jpg 600w"></figure><p>Unfortunately, I've encountered <strong>few bugs/inconsistencies</strong> as well:</p><ol><li>there were misleading synchronization messages (<em>"failed but succeeded"</em> style of communication ;P)</li><li>once I've tried to change font settings for an article sent via Chrome extension (it was a part of Apache Arrow specification), the device started rebooting repeatedly (about five times) - I was able to replicate the issue</li></ol><hr><p>But to be honest, there are <strong>some pros worth mentioning</strong> as well:</p><ol><li>You can scribble over your e-books (!) - underline, highlight, add comments on margins. It works like a charm, is very convenient, but TBH I didn't check how foolproof it is (e.g., what happens with the notes if I adjust margin settings, so page numeration changes ...).</li><li>There's a nice variety of "pens" available - ones that imitate pencils, brushes, highlighters, or markers - I find the selection wide enough for my needs.</li><li>It's possible to add transparent layers, so you can scribble on one without affecting others.</li><li>One can also use one of many available templates (stencils) for the full pages (only): tables, grids, checklists, organizers, even perspective "helpers" or guitar chord sheets.</li><li>Selecting content is super-convenient - you just draw a shape around an item ("magic lasso" style), and then you can scale, rotate or cut the selection.</li><li>You need to get used to erasing stuff - it's impossible to "select" elements by "clicking"; you need either to use the selection tool or the opposite tip of your marker (if you have the expensive version).</li></ol><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_3.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/10/remarkable_3.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/10/remarkable_3.jpg 800w" sizes="(min-width: 720px) 720px"></figure><h3 id="pc-companion-app">PC companion app</h3><p>What about the PC companion app? I've tried the Windows version, and it ... just works. Its primary purpose is to upload e-books, and it does it in quite a convenient way - you don't need to plug the device to your PC (with USB cable), because it sends the e-book over the Internet.</p><p>When it comes to e-books, two formats are supported: PDF and epub. I have literally zero complaints regarding PDFs - due to the larger screen, the user experience (of reading PDF) was much more pleasant than with <strong>Amazon Kindle Oasis 2</strong>. But my epubs were rendered poorly, like if someone has stripped all the formatting and converted the rich text to raw text. Frankly, I can't tell whether it's the issue with epub format or reMarkable 2, because I've never used epub before (only mobi), but the effect was disappointing anyway.</p><h3 id="the-browser-extension">The browser extension</h3><p>The browser extension is available only for Chrome (sadly). All it does is send whatever page you're reading to your reMarkable 2 as either raw text or PDF (it uses PDF print functionality built into Chrome). I've already mentioned issues with changing font settings for raw text articles. Hopefully, this gets fixed soon.</p><p>I guess it's time to round things up.</p><p><strong>reMarkable 2</strong> is a great piece of hardware that needs some improvement of the software powering it. I dreamed of using it as a minimum-friction note-taking <em>"front-end"</em> for powerful knowledge management platforms I use, but it's very cumbersome at this point. It's a standalone device, <strong>reMarkable 2</strong> isn't even trying to either attach to any existing app ecosystem or creating its own (challenger) one.</p><p>That's a big disappointment. But I believe that CAN be fixed; the potential is still there. The device's essential features - <u>high responsiveness</u>, <u>remarkable accuracy</u>, and <u>low latency times</u> - are there: confirmed and unquestionable.</p><p>What kind of improvements would I gladly see? Here are some ideas:</p><ol><li>OCR for selection - replaces scribbling (in-place) with recognized text</li><li>Import/export from popular knowledge management tools</li><li>Remove the fixed boundaries of quick notes scribbling space (make it "virtually infinite")</li><li>Casting/transmitting the content of the device e.g. to computer screen in real-time (e.g. to present for the larger audience or just collaborate remotely)</li><li>Stencil library for shapes (e.g. sticky notes, basic icons, elements of the most popular visual notations)</li><li>Better UX for syncing stuff (on the tablet) - e.g. force sync button</li></ol><p>What I think is beyond the capabilities of reMarkable 2 (even with regular software updates)?</p><ol><li>More colors (I don't believe they've reduced it to 3 for kicks and giggles ...)</li><li>"Objectualizing" parts of the note and adding dynamic connectors between them (e.g. flows, arrows, lines) that adjust when objects are moved</li></ol><hr><p><strong>So, was it worth it (the price tag)?</strong></p><p>I honestly can't tell at this point. In time I will know …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://no-kill-switch.ghost.io/remarkable-2-my-subjective-review/">https://no-kill-switch.ghost.io/remarkable-2-my-subjective-review/</a></em></p>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/remarkable-2-my-subjective-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905623</guid>
            <pubDate>Tue, 27 Oct 2020 09:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga 1000 Phoenix Project]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905247">thread link</a>) | @retrohax
<br/>
October 27, 2020 | https://retrohax.net/amiga-1000-project-phoenix-motherborad/ | <a href="https://web.archive.org/web/*/https://retrohax.net/amiga-1000-project-phoenix-motherborad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11666">

<div>
<p>… or failures are your friends :&gt;</p>
<p>&lt;INTRO&gt;</p>
<figure><img src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>&lt;/INTRO&gt;</p>
<p>The story behind this whole post is a bit lengthy but I’ll try to be brief 🙂</p>
<p>In August of 2019, I’ve received an email from MrTrinsic. Back then, I didn’t yet know what is coming lol.</p>
<p>It turned out that MrTrinsic is a great Amiga enthusiast and he’d asked me to work on his Amiga 1000 … but no on a standard A1000 but with an Amiga 1000 Phoenix motherboard!</p>
<p>Amiga 1000 Phoenix Enhanced mobo is an extremely rare motherboard replacement for Amiga 1000. Some people think there were no more than 200 units manufactured, others say it was no more than 2000. I’ve no idea either but still, it is very rare so a magic smoke is not an option lol.</p>
<p>This motherboard is an awesome hack in itself and that is why MrTrinsic refers to it as DIVA 😀</p>
<p>Let me quote an excerpt from one of emails.</p>
<p><em>You should mention or point out more clearly that the Phoenix Board is a … DIVA!<br>It is a hack. Just look at the manual what kind of things you can modify and what kind of headers there are to change stuff.<br>The price is that it has an extremely bad signal quality. Plus, it lacks the Buster-Chip that the Amiga 2000 has.<br>The Phoenix is a bad version of the original A2000 from Braunschweig, which in itself was a hacked and beefed-up version of the A1000.<br>Plus, the Phoenix only has two layers. It’s a nightmare as we have seen.</em></p>
<p>It simply always has some problems like stability and compatibility issues which I’ve tried to sort out.</p>
<p>Phoenix mobo was developed in 1989/1990 by our fellow friends from Australia and was one of the very first crowd-funding campaigns! You can read/watch more on one of my fav websites -&gt; <a rel="noreferrer noopener" href="https://www.amigalove.com/viewtopic.php?t=476" target="_blank">www.amigalove.com</a></p>
<p>Hardware specs are available here -&gt;<a rel="noreferrer noopener" href="https://amiga.resource.cx/exp/phoenix" target="_blank"> amiga.resource.cx</a></p>
<h4>The plan</h4>
<p>Initially, MrTrinsic asked me to work on some external floppy replacements by Dell which I will cover in another post. Once I’ve figured out that floppy drive issue he’d decided we should start working on The Phoenix project.</p>
<p>At first, he’d send me a large box with gear that he wanted to have in this Amiga. I was like OMG! Not only Phoenix but the whole large project was about to begin!</p>
<p>The plan was to run lots of modern hardware add-ons with Amiga 1000 Phoenix and later try to squeeze it into a nice looking case, plus make it alive and stable.</p>
<p>The first package arrived and I was really excited by what I’ve seen.</p>
<p>Amiga 1000 Phoenix in an A1000 case with lots of mods and hacks already installed, plus, tons of other hardware mods still in boxes … and that was only for starters …</p>
<figure><img src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, the original plan was to MAKE Amiga 1000 Phoenix GREAT AGAIN!</p>
<p>Jokes aside, the main goal was to run a graphics card along with <a href="http://wiki.icomp.de/wiki/ACA500plus" target="_blank" rel="noreferrer noopener">ACA500plus</a> + <a href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank" rel="noreferrer noopener">ACA1233n</a> accelerator card by iComp</p>
<p>On top of tons of other minor hardware mods, He’d also sent me two graphic cards – <a rel="noreferrer noopener" href="https://shop.mntmn.com/products/zz9000-for-amiga-preorder" target="_blank">ZZ9000 by MNT</a> and GBAPII++ by KryoFlux.</p>
<figure><img src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Running it</h4>
<p>First things first. Phoenix motherboard is so rare that I first had to learn how it works and how it is all connected etc.</p>
<p>As it gave me a black screen at the very first run, I had to start learning about jumper settings and the board in general</p>
<p>Below, you can see a block diagram of particular parts location to give you an idea of what is where.</p>
<figure><img src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I would not move on quickly without MrTrinsics support. He’d pointed me to several sites and sent over some more info about the board itself. One of the most important documents I’ve received was <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/phoenix_jumpers_english.pdf" target="_blank">the jumper settings file</a> along with the <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/Phoenix.pdf" target="_blank">original manual</a>.</p>
<p>The above documents gave me the general idea of how things should work. The very first thing that I did was the removal of all added mods. I’ve then tried to run the A1K but still no luck – black screen. MrTrinsic then pointed me to jumper L35 which could cause such behavior if set incorrectly and bingo! It worked! </p>
<p>Since Phoenix has slots for more than one ROM chip, it is possible to install three KickStarts – 1.3. and 3.1 and third as a custom option. That was already done, along with a switch hack.</p>
<figure><img src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The problem was that Amiga wasn’t starting every single time. Instead, it booted every couple of times. My next move was to take it out and try running it outside of the case. This is where I’ve started noticing all the awesome texts on the PCB itself. I took PCB out started shooting pics of those texts and greetz for various hackers of that era.</p>
<figure><img src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Next, I’ve checked for any obvious problems and when I was happy with this inspection, I’ve put it back to a case to simply avoid any accidental short circuits caused by beer-drinking ;P</p>
<p>I’ve decided that I will try to run it with only Indivision ECS2, and KryoFlux GBAPII++ inserted.</p>
<p>I’ve then located the switch setting for the first ROM and put an awesome<a href="http://www.diagrom.com/" target="_blank" rel="noreferrer noopener"> DiagROM by John “<em>Chucky</em>” Hertell</a> in a socket. Yeah, I know, it is a quite a large resistor ;P</p>
<figure><img src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked flawlessly and I was greeted by a known diag info and a menu a bit later.</p>
<figure><img src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Once it worked, I’ve figured that it might be as simple as a flaky ROM socket problem. I’ve put a 2.0 ROM in the place of DiagROM and Viola! It works!</p>
<figure><img src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>When I’ve figured that part out, I could move on and start working on the alternative power supply which was …</p>
<h4>HDPLEX + Uber nice Amiga adapter</h4>
<p>MrTrinsic sent me this HQ HDPLEX Pico PSU but he’d also sent me a very cool DIY KIT – ATX2.0d-Amiga adapter which has super cool features like over-voltage/current protection outputs all needed voltages, and has additional floppy power outputs. Moreover, it generates a TICK signal which is good to have for testing.</p>
<p>However, it was a DIY KIT so I had to solder it all up first.</p>
<figure><img src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Combined together, it created an awesome and stable power source for this Amiga project.</p>
<figure><img src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>All I needed to do next was to prepare all the wiring. That was a trivial job after taking some measurements. I’ve used wires from my Nissan Patrol spare wiring kit as these are thick (copper) and nice, hence the color mismatch ;P</p>
<figure><img src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>It worked like a charm so now I had two working power supplies – original and superior to it HDPLEX with a kickass adapter.</p>
<h4>030 cards</h4>
<p>The next step was about adding 68030 CPU to the system. I had two options as MrTrinsic sent me two different solutions.</p>
<p>The First solution was an <a rel="noreferrer noopener" href="https://icomp.de/shop-icomp/en/produkt-details/product/ACA500plus.html" target="_blank">ACA500plus</a> card along with <a rel="noreferrer noopener" href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank">an ACA1233n</a> accelerator card by Individual Computers. ACA500plus also had an Ethernet add-on – X-Surf 500</p>
<p>These two make a great solution but for AMIGA 500. There are not many folks out there who played it with it in an A1000 and especially with a Phoenix mobo!</p>
<figure><img src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The first run was promising …</p>
<figure><img src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve added ACA1233n on an EXTREMELY WANTED DURING PANDEMIC stand 😀 😀 😀</p>
<figure><img src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked!</p>
<figure><img src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Below, a demo running on this setup</p>
<figure><p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/PJYyBRBnhu8?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<p>The second setup was a bit different. It is made of four devices.</p>
<ul><li>Open 68000 relocator card</li><li>68030 accelerator card </li><li>SDRam + IDE interface</li><li>IDE2CF interface</li></ul>
<p>This setup also appeared to be working nicely after some tests, however as MrTrinsic pointed out, it has some stability issues and will not allow running some software so it was a backup card in case ACA failed. I don’t have a video of it running though.</p>
<figure><img src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Other mods and add-ons</h4>
<p>Once accel-cards were tested, I’ve started installing OS and testing other mods. To name the few:</p>
<ul><li>X-surf 500 Ethernet card</li><li>RapidRoad USB</li><li>Indivision ECS v2</li><li>SCSI2SD </li><li>KryoFlux GBAPII++</li></ul>
<figure><img src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Indivision ECS v2 and SCSI2SD worked flawlessly so I started playing with other gear.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>After installing all the needed software I’ve finally managed to get an IP addr from my local DHCP server</p>
<figure><img src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, I wouldn’t be myself if I didn’t destroy something. I’ve accidentally connected the RapidRoad USB module to a clock port the other way around. The magic smoke appeared and…</p>
<figure><img src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I had to fix it. After a while, it turned out that only 3R3 resistor was fried.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>I’ve quickly replaced it and started testing USB functionality.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>GFX cards</h4>
<p>Once all other major mods were working more or less correctly, I could start testing GFX cards high-res modes.</p>
<p>This is where it all started to go wrong …</p>
<p>I had two cards to test with this setup – GBAPII++ by Kryoflux and ZZ9000 by MNT. </p>
<p>GBAPII++ worked nicely only with green 030 cards, but in such config, there would be no Ethernet card.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve tried running ZZ9000 along with green 030 and ACA cards but I’ve encountered autoconfig problems.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Finally, I’ve focused on ACA500plus with ACA1233n and I just couldn’t make it work. </p>
<p>When ACA was inserted then GBAPII++ was completely invisible to the system.</p>
<p>After updating tons of libraries, firmware and reinstalling OS a few times without any luck, we’ve figured out that it might be a power issue. MrTrinsic ordered an adapter for A500 which would allow pumping in more power.</p>
<p>I’ve first tested it with a stock A500.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Same story, GBAPII++ was invisible but I’ve checked it with A1K and power injector adapter just to be sure … unfortunately no luck again.</p>
<figure><img src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Unfinished 🙁</h4>
<p>I’ve invested weeks of time into this GFX problem research but finally, I had to give up on this project for now. It is still in an unfinished state until we will find a solution to all problems. The project is partially done but it requires more work and I hope to cover it someday in one of the future posts making Amiga 1000 Phoenix great again!</p>
<p>But worry not, this gave birth to a new project which is even more awesome.</p>
<p>Currently, it is a work-in-progress but that is a story for another blog post 🙂</p>
<figure><img src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>OUTRO</h4>
<p>If any of my readers know any solution, hints, or knows where I did mistakes, then please leave a comment here or on FB and Twitter pages.</p>
<p>If you want to get retro gear or hardware modules, please visit <a href="https://retrohax.net/shop/">our shop</a> -&gt; https://retrohax.net/shop/</p>
<p>Please support our work by commenting here and on our <a href="https://www.facebook.com/Retrohax.net">Facebook</a> and <a href="https://twitter.com/RetrohaxN">Twitter</a> pages.</p>
<p>If you want to donate a dead computer then <a href="https://retrohax.net/contact/">drop me an email</a>. Extreme cases are welcome 🙂</p>

 </div>

</article></div>]]>
            </description>
            <link>https://retrohax.net/amiga-1000-project-phoenix-motherborad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905247</guid>
            <pubDate>Tue, 27 Oct 2020 07:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personality in Open Source]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905204">thread link</a>) | @pabs3
<br/>
October 27, 2020 | https://anonymoushash.vmbrasseur.com/2020/10/26/personality-in-open-source | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2020/10/26/personality-in-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>In September, <a href="https://twitter.com/esthershein">Ether Shein</a> interviewed me for an <a href="https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/">article</a> she was writing for <a href="https://www.functionize.com/blog/">Functionize</a> about how personality affects the development process in open source projects. The article was inspired by a <a href="https://ieeexplore.ieee.org/abstract/document/8935389">study published in 2019</a> about the effects of personality traits on the acceptance of pull requests. Both the article and the study are worth a read.</p>

<p>What follows are my responses to the questions Esther sent.</p>

<h2 id="what-is-your-reaction-to-the-research-suggesting-that-a-developers-personality-has-an-impact-on-the-ability-to-successfully-contribute-to-an-open-source-project">What is your reaction to the research suggesting that a developer’s personality has an impact on the ability to successfully contribute to an open source project?</h2>

<p>What’s the adjective for “the furthest thing from surprised”? Because whatever that word is describes my reaction to this finding. While the research phrases it academically as “personality,” what they mean by that is someone’s ability to interact with others, the application of social interaction skills as well as technical skills.</p>

<p><em>Of course</em> social interaction is critical to a successful open source contribution, because it’s critical to <em>any</em> endeavour that involves more than one human being. Collaboration is difficult if not impossible when people aren’t able to interact well, whether due to personal skills, language differences, or some other obstruction. This is why we as humans spend so much time researching and discussing how to interact better: it affects everything we do as a civil society.</p>

<p>It’s also why so much of <a href="https://fossforge.com/">my book</a> ended up being about the social interactions involved with contributing to an open source project: it’s vital to the success of your contribution. We in open source have abundant documentation about the technical aspects of contributing, such as writing tests or the mechanics of sending your contribution for review. However, we have relatively little documentation about the social expectations for that contribution. Not that projects ignore the social expectations, of course; it’s simply that they rarely document them. Instead these expectations are a part of the tribal knowledge that a new contributor is expected to absorb. This can lead to a frustrating contribution experience. <a href="https://fossforge.com/">The book</a> collects these previously unwritten social rules of open source contributing in a single spot, giving people a better chance of success.</p>

<p>Which isn’t to diminish the importance of the findings of this research. These personality factors have a massive impact on the end result of an open source contribution, and this research has done a lot of work to prove that. Unfortunately, many people require that proof. They would rather throw a <code>[citation needed]</code> gauntlet on the table than make an effort to learn how to interact better with others. This research is the latest in a long line of responses to that gauntlet.</p>

<h2 id="should-maintainers-apply-personality-categorisation-methods-to-open-source-contributors">Should maintainers apply personality categorisation methods to open source contributors?</h2>

<blockquote>
  <p>People who are curious about where they score in the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits">Big Five personality traits</a> can take the test at Open Psychometrics, while simultaneously (but optionally) contributing their results to ongoing research: <a href="http://openpsychometrics.org/">http://openpsychometrics.org</a></p>
</blockquote>

<p>As pointed out by the researchers, so far Big Five holds up to rigorous study. As such, it’s proven useful for broad sociological research such as this. Other personality type methodologies, such as the Myers-Briggs Type Indicator (MBTI), do not hold up to study and <a href="https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator#Criticism">are considered problematic</a>.</p>

<p>Regardless of personality categorisation method, a category is not a judgement. For instance, scoring lower in the Neuroticism factor in Big Five simply means your emotional state is more variable <em>as compared with the others who took the test</em>. It’s a research label, not a diagnosis.</p>

<p>I believe it would be dangerous for individuals or projects to start incorporating this research into their contribution workflows at this time. It’s easy to picture some nightmare of a startup spinning up to “leverage AI, ML, and NLP to analyse your open source contributions and maximise the contributor-maintainer synergy, creating a more scaleable, sustainable, and delightful contribution experience” or <a href="https://strategy-madlibs.herokuapp.com/">some such rubbish</a>.</p>

<p>Yes, responding to and reviewing contributions can be time consuming, but applying generalisations intended for research to real-world situations typically <a href="https://twitter.com/justsaysinmice">causes more harm than good</a>. Please bury that terrible startup idea in a deep hole somewhere and pretend it never existed.</p>



<p>You can’t feasibly remove people from software development. Even if you go low-code or were to step into a sci-fi world and automate all code generation, you’re still creating software to solve problems for humans. Humans must be involved in the process somewhere, or it’s very unlikely that their needs will be met (in which case, why bother having the software at all?).</p>

<p>Right now code generation isn’t automated (for the most part); code is written by people. People creating software to solve problems for other people. With so many people in the mix, of course social interactions will have an outsized impact on the end result. Communication, conflict resolution, and empathy are key to successful social interactions. They’re important, and thankfully they’re learnable. You may never be perfect at—for instance—conflict resolution, but you can learn how to get better at it.</p>

<p>Therefore a practical takeaway from this research is that <strong>time spent learning how to improve your social interactions will have a larger return on investment for your career than the time spent improving your technical skills</strong>. Which isn’t to say that you should neglect your technical skills. This isn’t an either-or situation; it’s both-and. A software development career with technical but not social improvements is like a cake without the sugar: not very appealing.</p>

<p>Another important and practical takeaway from this research is the one that most people are overlooking: <strong>Having a diversity of social traits in an open source community leads to a better contribution experience.</strong> There’s plenty of research that supports this. <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">Homogeneous teams consistently underperform those with diverse membership</a>. In this case, the researchers found that communities with diverse social and personality traits have more successful (i.e. merged) contributions. Therefore it follows that anything you can do to increase the human diversity in your open source project will also lead to more contributions.</p>

<p>That’s a powerful finding, and is possibly more important than the findings that are focused on the individual person submitting or reviewing a contribution.</p>

        
      </section></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2020/10/26/personality-in-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905204</guid>
            <pubDate>Tue, 27 Oct 2020 07:43:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telemelt: Web-Based Multiplayer Multiemulator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905193">thread link</a>) | @polm23
<br/>
October 27, 2020 | https://www.andrewreitano.com/posts/telemelt/ | <a href="https://web.archive.org/web/*/https://www.andrewreitano.com/posts/telemelt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Ftelemelt-FINAL.png?v=1601250432872" alt="Telemelt Logo"></p>
<p><a href="https://telemelt.com/">Telemelt</a> is a web-based multi-emulator (<a href="https://www.retroarch.com/">RetroArch</a>/<a href="https://www.libretro.com/">libretro</a>) designed to recreate the experience of playing console games with a single controller in a room full of friends.</p>
<p>Gathering around a TV and collectively attempting to beat a game has been a consistent joy throughout my life, and is one of the rituals I miss the most with the ones we're separated from right now. I wanted to create a way to play single player/hotseat games with friends remotely that was free and required minimal setup. Netplay has always been unsatisfying for this, since only the host had low enough latency for games that require tight timing. I started this project in March, and have been pouring my heart into it every day possible since then.<br>
<img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2F6dfcbe63-2f80-4bb3-a780-a48a51dc0a19.image.png?v=1602011998888" alt="collage"></p>
<p>The system skips traditional netplay to allow a single player to assume host responsibility and experience <strong>zero network latency</strong> for games with demanding response times, with the viewers processing frames as broadcasted by the player. The virtual controller/host can be instantly passed to any user in the room.</p>
<p><strong>Designed to be lowest hassle way to play emulated games with a friend or loved one, even if they are not tech savvy!</strong></p>
<ul>
<li>No port forwarding, no IP addresses thanks to auto-generated URL</li>
<li>No installation or downloads, everything works in browser</li>
<li>Mappings for common/inexpensive controllers (PS3/4, XB360/1, Switch JC/Pro etc..) on both USB/BT thanks to RetroArch bindings</li>
<li>Always free! No tracking, no logins, no paid advertisements - personal budget allocated for Azure costs to serve thousands of users for months</li>
</ul>
<p><img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Fgiphy.gif?v=1602018705346" alt="Become Player"></p>
<p><strong>Focus on the experience of passing <em>a single controller</em> between people</strong></p>
<ul>
<li>This allows for a unique and efficient architecture that provides a consistent experience with minimal bandwidth</li>
<li>No AV is transmitted! Only controller and serialized state data, made even smaller by <a href="https://github.com/phretaddin/schemapack">schemapack</a></li>
<li>User state error checked per frame and reconciled via <a href="http://socket.io/">socket.io</a> server if needed</li>
<li>Takes advantage of deterministic nature of certain libretro cores - like a broadcasted <a href="https://en.wikipedia.org/wiki/Tool-assisted_speedrun">TAS</a></li>
<li>Rethink the kinds of content you would play (painting, music collaboration, RPGs, game shows)</li>
<li>Everyone working towards the same goal keeps people engaged</li>
</ul>
<p><img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Fimage90.gif?v=1602020845682" alt=""><br>
<strong>Quick start - Open up a Discord/Zoom/Meet etc.. with friends and try some of these!</strong></p>
<ul>
<li>Minigame collections (player transfer system is fast enough to keep up with switching on every stage)</li>
<li>Practice for a week then hold live olympic games (world/winter/summer/california games etc)</li>
<li>Live sound test or NSF/VGM listening party</li>
<li>Homebrews, hacks, and live demoparties (with live reactions)</li>
<li>Golf / bowling / fishing games to chill</li>
<li>Create music collaboratively in LSDJ/NTRQ</li>
<li>TV Gameshows</li>
<li>Painting games (mouse support!)<br>
<img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Fgiphy%20(1).gif?v=1602020614286" alt=""></li>
<li>Grind through an rpg over a few weeks (savestates work great for this!)</li>
<li>Alternate copiloting an game no one has played before on gamefaqs</li>
<li>Hotseat tactical / turn based games</li>
<li>Teach a friend to speedrun with the ability to demonstrate and practice together</li>
</ul>
<p><strong>A platform to experiment with multi-user experiences</strong></p>
<ul>
<li><a href="https://www.andrewreitano.com/posts/nespectre/">NESpectre support</a> – crowd control of a game by manipulating memory on the fly<br>
<img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Fgiphy%20(2).gif?v=1602020758322" alt="smb-ns"></li>
<li>Reaction system with live sfx</li>
<li>Frame accurate split timers</li>
</ul>
<p><strong>Coming soon</strong></p>
<ul>
<li><a href="https://www.andrewreitano.com/posts/super-russian-roulette/">Super Russian Roulette</a> Online</li>
<li>Homebrew and demo content library built in to showcase personal work</li>
<li>Double Ferrari, music ROM albums</li>
<li>Live read for updating CSS elements using game RAM</li>
</ul>
<!-- ![](https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Ftes0.gif?v=1601915361226) -->
<p>Telemelt is built on an Azure DevOps build and release pipeline, and takes full advantage of Azure Container Instances, Functions, Container Registry and AppInsights/Metrics to scale, handle matchmaking, and serve static assets</p>
<p><img src="https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2F6d15440e-8815-483b-95e6-159140492018.image.png?v=1601949797025" alt="Azure Backend"></p>
<!-- |![](https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Ftes0.gif?v=1601915361226)<br>|![](https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Fana-endless.gif?v=1600290723632)<br>|
|---|---| -->
<!-- ![Telemelt Screenshot](https://cdn.glitch.com/33ee6b19-10fa-4d51-8898-d35eb670b3fe%2Ftn-telemelt.png?v=1600196583685) -->


<p><a href="https://www.andrewreitano.com/">← Home</a></p>

    </div></div>]]>
            </description>
            <link>https://www.andrewreitano.com/posts/telemelt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905193</guid>
            <pubDate>Tue, 27 Oct 2020 07:40:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Productivity Guide – Scientifically Proven Techniques to Get Things Done]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905126">thread link</a>) | @iuliangulea
<br/>
October 27, 2020 | https://iuliangulea.com/productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/productivity-cover.png" alt="Productivity cover"></p><h2 id="what-is-productivity">What Is Productivity?</h2><p>Let’s define productivity first:</p><blockquote><p>Productivity represents the efficiency of a person to perform a specific task.</p></blockquote><p>We often think it is a state of constant efficiency that allows us to do everything faster and better, but this is wrong. <em>Productivity is a measurement per individual task.</em> With some assignments, you are very productive, while with others, your efficiency is terrible.</p><p>It’s because, for some tasks, you unconsciously are doing the right things, while for the others, you need to rethink your approach. And this also means that you can focus on those more important tasks and become more efficient at them.</p><p>At the end of this guide, you will have all the necessary knowledge to analyze your approach toward different assignments and make the corresponding adjustments to be more productive. It helped me <a href="https://iuliangulea.com/faang-preparation/">land an offer at facebook</a> and become a part of <a href="https://www.toptal.com/resume/iulian-gulea">Toptal</a> — one of the best freelance communities on the planet, and I hope that it will help you, too.</p><h2 id="the-four-levels-of-mastery">The Four Levels Of Mastery</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-of-mastery-1.png" alt="The Pyramid Of Mastery"></p><p>Before diving into different productivity techniques, let’s first dive into more details about the <em>essence</em> of productivity. And to do that, I will use the <a href="https://iuliangulea.com/pyramid-of-mastery/">Pyramid of Mastery</a> — a model that allows you to understand better a domain of interest, its constituent parts, and how to become an expert in it.</p><p>It does so by defining a domain through four types of entities:</p><ul><li><strong>Elements.</strong> These are the building blocks of the field of interest, that include concepts, ideas, and entities;</li><li><strong>Rules.</strong> These are the laws that govern a domain. This layer comprises both rules that define the interaction between various Elements as well as organizational and governing rules at the domain level;</li><li><strong>Tools.</strong> These are the instruments you use to perform the activities within a field;</li><li><strong>Frameworks.</strong> These are combinations of the above levels that allow for faster achievement of preset goals for which the Framework was created;</li></ul><p>For an in-depth explanation of the Pyramid of Mastery, you can read the original <a href="https://iuliangulea.com/pyramid-of-mastery/">article</a> on it.</p><p>Now, once you have an understanding of the model, let’s see how we can define productivity through the prism of it.</p><h2 id="productivity-elements">Productivity Elements</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-elements.png" alt="Pyramid of Mastery - Elements"></p><p>What are the Elements of productivity, the building blocks that you need to know about in order to excel at it?</p><p>I find this to be the most underestimated and overlooked layer. Very few people are thinking about what makes a productive person or about what productivity consists of. Instead, they try to squeeze in more time using tools, calendars, and other tools.</p><p>But knowing the fundamentals is vital if you want to become an expert in something. Therefore, here are some of the Elements that can help you be more productive if you understand them.</p><h3 id="human-senses">Human Senses</h3><p>Our senses are the only mechanisms that allow us to get information about the world around us. Humans have five main senses through which they receive information:</p><ul><li>Vision</li><li>Hearing</li><li>Touch</li><li>Smell</li><li>Taste</li></ul><p>Each sense has its own throughput:</p><p><img src="https://iuliangulea.com/images/conscious_attention_bit_sec.png#c" alt="Image with conscious attention throughput"></p><p>Therefore, we receive the most information visually, then through hearing, touch, smell, and taste.</p><p>If you are interested in the topic of human senses, I wrote a separate, in-depth <a href="https://iuliangulea.com/human-senses/">article</a> about it.</p><h3 id="attention">Attention</h3><p>We receive a flood of information through our senses at every moment, but only a tiny bit of it reaches our awareness. This filter that orients our focus toward different stimuli is <strong>attention.</strong></p><p>Attention is the process that selects which sensory information is preferentially processed and ultimately reaches our awareness.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>There are two types of attention: <em>Goal-Directed</em> attention (GDA) and <em>Stimulus-Driven</em> attention (SDA). The GDA is the voluntary effort to focus on something, be it reading this article, cutting vegetables, watching a movie, or writing code.</p><p>On the other hand, SDA is the involuntary reaction toward stimuli that are salient enough to grab our attention:</p><ul><li>contrasting things (stillness to movement, loud to soft, silence to sound, dark to bright, etc.);</li><li>intensity stimulation (extreme sounds, sights, etc.);</li><li>certain impulses we find vital or appealing (dangerous things, beautiful things, shiny things, etc.);</li></ul><p>If you are interested in the topic of attention, I wrote a separate, in-depth <a href="https://iuliangulea.com/attention/">article</a> about it.</p><h3 id="working-memory">Working Memory</h3><p>For tasks that require cognitive effort, once we focused our attention on a specific subset of stimuli we got from our senses, it is only here that we can finally perform some mental work.</p><p>Working Memory is the place in our memory where we can consciously process and manipulate data. It has a fundamental limitation, though: its processing capacity is limited to ~4 chunks of information.</p><p>A <em>chunk</em> is a relative unit of measurement that depends on different factors, such as:</p><ul><li>familiarity with the topic;</li><li>complexity of the concept;</li><li>one’s mental agility;</li></ul><p>For instance, in the simple task of solving this simple math equation <code>21 * 2</code>, you have to store number <code>21</code> as a chunk, store number <code>2</code> as another chunk, then, having these 2 in your working memory, do the multiplication, and store the result <code>42</code> as a third chunk.</p><p>However, in a debate on “homeschooling vs. formal education,” both concepts each represent a chunk. As it is a complex concept, you can then zoom in or out on either of those as information is stored in a complex network of associations in our brain.</p><p>If you would like to learn more about working memory, I wrote a separate, in-depth <a href="https://iuliangulea.com/working-memory/">article</a> about it.</p><h3 id="long-term-memory">Long-Term Memory</h3><p>Our Long-Term Memory (LTM) holds all the information, knowledge, skills, plans, and memories. What you commit to the LTM can stay there for your whole life. Although there is a tendency to forget things, you can strengthen your memories using repetition.</p><h3 id="task-process">Task Process</h3><p>A task usually represents a specific result you want to achieve (e.g., write an article, build a website, create a marketing campaign, etc.). But behind any such assignment, there is a sequence of steps necessary to complete before you can say that you have done the task. It is called a <strong>process.</strong></p><p><img src="https://iuliangulea.com/images/task-process.png" alt="Image of a task process"></p><p>Each step in the process is a smaller task that will advance you closer to your desired result.</p><p>Learn and understand the necessary steps needed to achieve the end goal — it will show you what you are doing well and where you are wasting your time. Besides this, it is always easier to follow a list of specific action steps rather than figure out what to do on the fly.</p><h3 id="domain-specific-elements">Domain Specific Elements</h3><p>Finally, since productivity is measured per task, it means that besides the Elements mentioned above, there are some domain-specific ones that you must also understand to be more effective.</p><p>And this is valid for all layers of the pyramid — you must know your domain of activity. Otherwise, you cannot be productive in it since you will have to learn a lot, and learning is a slow and effortful process in itself.</p><p>Now, once we have enumerated the primary elements, let’s discuss the Rules that govern the domain of productivity.</p><h2 id="productivity-rules">Productivity Rules</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-rules.png" alt="Pyramid of Mastery - Rules"></p><p>How the Elements we have enumerated interact? Here are some essential Rules that govern how we function and perform cognitive work.</p><h3 id="stimulus-driven-attention-overrides-goal-directed-attention">Stimulus-Driven Attention Overrides Goal-Directed Attention</h3><p>Imagine that while you are reading this article, you hear the sound of a breaking plate in the kitchen, which distracts you from reading. Or you are working on a report, and suddenly, the light starts to flash, thus distracting you from the job.</p><p>Stimulus-Driven attention can override your voluntary, Goal-Directed attention. This is bad news for productivity since, most of the time, working on a task means we have to engage this Goal-Directed attention to focus on some things consciously. And because those things might be boring, monotonous, or uninteresting, we can get distracted much easier by any unrelated stimulus.</p><p><img src="https://iuliangulea.com/images/bright-shiny-objects.jpg#c" alt="Cartoon where dogs in a meeting are being distracted by a squirrel"></p><p>The following stimuli are all capable of distracting your Goal-Directed Attention:</p><ul><li>high-contrast changes in our environment (stillness to movement, loud to soft, silence to sound, dark to bright, etc.);</li><li>intensity stimulation (extreme sounds, sights, etc.);</li><li>some certain impulses we find vital or appealing (dangerous things, beautiful things, shiny things, etc.);</li><li>“important” (e.g., one’s own name).</li></ul><h3 id="working-memory-is-physiologically-incapable-to-multitask">Working Memory Is Physiologically Incapable To Multitask</h3><p>Imagine you are in a warehouse with an immense storage capacity (that’s your Long-Term Memory), a single small table with four zones where any kind of work can be performed (that’s your Working Memory), and a storekeeper who does all the work and knows where everything is stored. One constraint is that the storekeeper can work <em>only</em> at the table, so you must first put it there before doing anything.</p><p><img src="https://iuliangulea.com/images/working-memory-analogy.png#c" alt="Image of a table with four zones and a storekeeper"></p><p>Each chunk takes one slot on the table. And you can get it either from your senses (imagine a conveyor system that brings things directly to your table) or search in the warehouse (which takes time).</p><p>Suppose you are working on a report. The storekeeper searches for relevant information in your Long-Term memory, puts it on the table, takes some from the conveyor, and puts it on the table as well, where they can manipulate, combine, dissect, and mix those concepts.</p><p>But suddenly, you are being called by your spouse regarding the plans for the weekend. Ideally, the storekeeper should take the time to carefully take the chunks off the table and put them in a dedicated place where they can find them later. In reality, however, the storekeeper sweeps off in a hurry everything from the table and rushes to put on it chunks related to plans for the weekend: movies, cuisine, activities, etc.</p><p>Then, when you are done talking with your spouse, you stare blankly at the computer screen, trying to recall what you were doing before the call. The storekeeper runs hysterically around the table in these moments, trying to find out something, but they don’t know what exactly to look for. Finally, you see the opened MS Excel window and remember you were working on the report.</p><p>But then another problem arises. You cannot recall the latest thoughts you had just before the call. The storekeeper cannot find the chunks they swept off the table. They looked everywhere, but the chunks just vanished. And …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/productivity/">https://iuliangulea.com/productivity/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905126</guid>
            <pubDate>Tue, 27 Oct 2020 07:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PHP 8 – All new features with interactive examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905120">thread link</a>) | @mpociot
<br/>
October 27, 2020 | https://pociot.dev/32-php-8-try-out-all-new-features | <a href="https://web.archive.org/web/*/https://pociot.dev/32-php-8-try-out-all-new-features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>PHP 8 is already in it's release candidate stage, with RC 3 being released on October 29th, and the general availability release targeted for November 26th. So it is time to take a look at all the new and upcoming features of PHP 8. You can take a look at PHP 8's <a href="https://wiki.php.net/todo/php80">release schedule here</a>.</p>
<p>Every feature that you see in this blogpost comes with an interactive embedded editor, where you can modify the PHP code and evaluate the results yourself.</p>
<p>The official upgrade guide can be found on <a href="https://github.com/php/php-src/blob/PHP-8.0/UPGRADING">GitHub</a>.</p>
<!--more-->
<p>Editing and evaluating the code requires cross-site cookies. If you have those disabled, you can click "Edit on Laravel Playground" to jump into the code examples and edit them.</p>

<h2 id="added-support-for-union-types-a-hrefhttpswikiphpnetrfcunion-types-v2rfca">Added support for union types (<a href="https://wiki.php.net/rfc/union_types_v2">RFC</a>) <a href="#added-support-for-union-types-a-hrefhttpswikiphpnetrfcunion-types-v2rfca">#</a></h2>
<p>A union type accepts values of multiple different types, rather than a single one.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);
 
class Number {
    private int|float $number;
 
    public function setNumber(int|float $number): void {
        $this-&gt;number = $number;
    }
 
    public function getNumber(): int|float {
        return $this-&gt;number;
    }
}

/**
 * We can pass both floats or integer values
 * to the number object. Try passing a string.
 */
$number = new Number();

$number-&gt;setNumber(5);

dump($number-&gt;getNumber());

$number-&gt;setNumber(11.54);

dump($number-&gt;getNumber());

exit;
</pre>
</pre>
<h2 id="added-weakmap-a-hrefhttpswikiphpnetrfcweak-mapsrfca">Added WeakMap (<a href="https://wiki.php.net/rfc/weak_maps">RFC</a>) <a href="#added-weakmap-a-hrefhttpswikiphpnetrfcweak-mapsrfca">#</a></h2>
<blockquote>
<p>Weak maps allow creating a map from objects to arbitrary values (similar to SplObjectStorage) without preventing the objects that are used as keys from being garbage collected. If an object key is garbage collected, it will simply be removed from the map.</p>
</blockquote>
<p>This is a very useful new feature, as it allows users to worry even less about leaving memory leaks in their code. While this might not be an issue for most PHP developers, it is certainly something to watch out for when writing long-running processes, for example using ReactPHP. With WeakMaps, references to an object automatically get garbage collected, once the object is no longer available.</p>
<p>If you would do the same thing with an array, you would still have a reference to the object, thus leaking memory.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);
 

class FooBar {
    public WeakMap $cache;
    
    public function __construct() {
    	$this-&gt;cache = new WeakMap();
    }
 
    public function getSomethingWithCaching(object $obj) {
        return $this-&gt;cache[$obj] ??= $this-&gt;computeSomethingExpensive($obj);
    }
    
    public function computeSomethingExpensive(object $obj) {
		dump("I got called");
		return rand(1, 100);
    }
}

$cacheObject = new stdClass;

$obj = new FooBar;
// "I got called" only will be printed once
$obj-&gt;getSomethingWithCaching($cacheObject);
$obj-&gt;getSomethingWithCaching($cacheObject);

dump(count($obj-&gt;cache));

// When unsetting our object, the WeakMap frees up memory
unset($cacheObject);

dump(count($obj-&gt;cache));

exit;
</pre>
</pre>
<h2 id="new-codevalueerrorcode-exception">New <code>ValueError</code> Exception <a href="#new-codevalueerrorcode-exception">#</a></h2>
<p>PHP 8 introduces a new built-in exception class called <code>ValueError</code>. It extends <code>\Exception</code> and PHP throws this exception, every time you pass a value to a function, which has a valid type - but can not be used for the operation. Prior to PHP 8, this would result in a warning.</p>
<p>Here are some examples:</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);
 
/**
 * We pass an array to array_rand,
 * which is of the correct type. But
 * array_rand expects non-empty arrays.
 *
 * This throws a ValueError exception.
 */
array_rand([], 0);

/**
 * The depth argument for json_decode is a
 * valid integer, but it must be greater than 0
 */
json_decode('{}', true, -1);
</pre>
</pre>
<h2 id="allowing-variadic-argument-when-overriding-functions">Allowing variadic argument when overriding functions <a href="#allowing-variadic-argument-when-overriding-functions">#</a></h2>
<blockquote>
<p>Any number of function parameters may now be replaced by a variadic argument, as long as the types are compatible. For example, the following code is now allowed:</p>
</blockquote>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

class A {
    public function method(int $many, string $parameters, $here) {

    }
}
class B extends A {
    public function method(...$everything) {
        dd($everything);
    }
}

$b = new B();
$b-&gt;method('i can be overwritten!');
exit;
</pre>
</pre>
<h2 id="static-return-type-a-hrefhttpswikiphpnetrfcstatic-return-typerfca">Static return type (<a href="https://wiki.php.net/rfc/static_return_type">RFC</a>) <a href="#static-return-type-a-hrefhttpswikiphpnetrfcstatic-return-typerfca">#</a></h2>
<p>The <code>static</code> return type may now be used in PHP 8 to identify that a method returns the class, that this method was actually called on - even if it was inherited (late static binding).</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

class Test {
    public function doWhatever(): static {
        // Do whatever.
        return $this;
    }
}

exit;
</pre>
</pre>
<h2 id="class-name-literal-on-object-a-hrefhttpswikiphpnetrfcclass-name-literal-on-objectrfca">Class name literal on object (<a href="https://wiki.php.net/rfc/class_name_literal_on_object">RFC</a>) <a href="#class-name-literal-on-object-a-hrefhttpswikiphpnetrfcclass-name-literal-on-objectrfca">#</a></h2>
<p>It is now possible to fetch the class name of an object using <code>$object::class</code>. The result is the same as <code>get_class($object)</code>.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

auth()-&gt;loginUsingId(1);

dump(auth()-&gt;user()::class);

// Or with a temporary variable
$user = auth()-&gt;user();

dump($user::class);
exit;
</pre>
</pre>
<h2 id="variable-syntax-tweaks-a-hrefhttpswikiphpnetrfcvariable-syntax-tweaksrfca">Variable Syntax Tweaks (<a href="https://wiki.php.net/rfc/variable_syntax_tweaks">RFC</a>) <a href="#variable-syntax-tweaks-a-hrefhttpswikiphpnetrfcvariable-syntax-tweaksrfca">#</a></h2>
<p>New and instanceof can now be used with arbitrary expressions, using <code>new (expression)(...$args)</code> and <code>$obj instanceof (expression)</code>.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

class Foo {}
class Bar {}


$class = new (collect(['Foo', 'Bar'])-&gt;random());

dd($class);

exit;
</pre>
</pre>
<h2 id="stringable-interface-a-hrefhttpswikiphpnetrfcstringablerfca">Stringable interface (<a href="https://wiki.php.net/rfc/stringable">RFC</a>) <a href="#stringable-interface-a-hrefhttpswikiphpnetrfcstringablerfca">#</a></h2>
<p>PHP 8 introduces a new <code>Stringable</code> interfaces, which gets automatically added, once a class implements the <code>__toString</code> method. You do not need to explicitly implement this interface.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

class Foo {
    public function __toString() {
        return 'I am a class';
    }
}

$obj = new Foo;
dump($obj instanceof Stringable);

exit;
</pre>
</pre>
<h2 id="traits-can-now-define-abstract-private-methods-a-hrefhttpswikiphpnetrfcabstract-trait-method-validationrfca">Traits can now define abstract private methods (<a href="https://wiki.php.net/rfc/abstract_trait_method_validation">RFC</a>) <a href="#traits-can-now-define-abstract-private-methods-a-hrefhttpswikiphpnetrfcabstract-trait-method-validationrfca">#</a></h2>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);


trait MyTrait {
    abstract private function neededByTheTrait(): string;
 
    public function doSomething() {
        return strlen($this-&gt;neededByTheTrait());
    }
}
 
class TraitUser {
    use MyTrait;
 
    // This is allowed:
    private function neededByTheTrait(): string { }
 
    // This is forbidden (incorrect return type)
    // private function neededByTheTrait(): stdClass { }
 
    // This is forbidden (non-static changed to static)
    // private static function neededByTheTrait(): string { }
}

exit;
</pre>
</pre>
<h2 id="codethrowcode-can-now-be-used-as-an-expression-a-hrefhttpswikiphpnetrfcthrow-expressionrfca"><code>throw</code> can now be used as an expression (<a href="https://wiki.php.net/rfc/throw_expression">RFC</a>) <a href="#codethrowcode-can-now-be-used-as-an-expression-a-hrefhttpswikiphpnetrfcthrow-expressionrfca">#</a></h2>
<p>The <code>throw</code> statement can now be used in places where only expressions are allowed, like arrow functions, the coalesce operator and the ternary/elvis operator.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

$callable = fn() =&gt; throw new Exception();

$nullableValue = null;

// $value is non-nullable.
$value = $nullableValue ?? throw new \InvalidArgumentException();


exit;
</pre>
</pre>
<h2 id="an-optional-trailing-comma-is-now-allowed-in-parameter-lists-a-hrefhttpswikiphpnetrfctrailing-comma-in-parameter-listrfca">An optional trailing comma is now allowed in parameter lists (<a href="https://wiki.php.net/rfc/trailing_comma_in_parameter_list">RFC</a>) <a href="#an-optional-trailing-comma-is-now-allowed-in-parameter-lists-a-hrefhttpswikiphpnetrfctrailing-comma-in-parameter-listrfca">#</a></h2>
<p>Similar to the trailing comma in arrays, you can now define a trailing comma in a parameter list.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

function method_with_many_arguments(
    $a, 
    $b,
    $c,
    $d,
) {
	dump("this is valid syntax");
}

method_with_many_arguments(
    1,
    2,
    3,
    4,
);

exit;
</pre>
</pre>
<h2 id="catching-exceptions-without-storing-in-a-variable-a-hrefhttpswikiphpnetrfcnon-capturing-catchesrfca">Catching exceptions without storing in a variable (<a href="https://wiki.php.net/rfc/non-capturing_catches">RFC</a>) <a href="#catching-exceptions-without-storing-in-a-variable-a-hrefhttpswikiphpnetrfcnon-capturing-catchesrfca">#</a></h2>
<p>It is now possible to write <code>catch (Exception)</code> to catch an exception without storing it in a variable.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

$nullableValue = null;

try {
	$value = $nullableValue ?? throw new \InvalidArgumentException();
} catch (\InvalidArgumentException) {
	dump("Something went wrong");
}


exit;
</pre>
</pre>
<h2 id="added-support-for-codemixedcode-type-a-hrefhttpswikiphpnetrfcmixed-type-v2rfca">Added support for <code>mixed</code> type (<a href="https://wiki.php.net/rfc/mixed_type_v2">RFC</a>) <a href="#added-support-for-codemixedcode-type-a-hrefhttpswikiphpnetrfcmixed-type-v2rfca">#</a></h2>
<p>PHP 8 introduces a new type called <code>mixed</code> that you can use. A type of mixed would be equivalent to array|bool|callable|int|float|null|object|resource|string.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

function debug_function(mixed ...$data) {
	dump($data);
}

debug_function(1, 'string', []);

exit;
</pre>
</pre>
<h2 id="added-support-for-attributes">Added support for Attributes <a href="#added-support-for-attributes">#</a></h2>
<p>PHP 8's attributes actually consist of a number of RFCs:</p>
<ul>
<li>RFC: <a href="https://wiki.php.net/rfc/attributes_v2">https://wiki.php.net/rfc/attributes_v2</a>
</li>
<li>RFC: <a href="https://wiki.php.net/rfc/attribute_amendments">https://wiki.php.net/rfc/attribute_amendments</a>
</li>
<li>RFC: <a href="https://wiki.php.net/rfc/shorter_attribute_syntax">https://wiki.php.net/rfc/shorter_attribute_syntax</a>
</li>
<li>RFC: <a href="https://wiki.php.net/rfc/shorter_attribute_syntax_change">https://wiki.php.net/rfc/shorter_attribute_syntax_change</a>
</li>
</ul>
<p>Attributes are definitely one of the biggest changes in PHP 8, and they can be a bit tricky to understand at first. In short, attributes allow you to add meta-data to PHP functions, parameters, classes, etc.
This meta-data can then be retrieved programatically - whereas in PHP 7 and lower, you would need to parse doclocks, attributes allow you to access this information deeply integrated into PHP itself.</p>
<p>To make this a bit clearer, lets say that you want to allow users to add a middleware to a controller class/method by using an attribute.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);
// First, we need to define the attribute. An Attribute itself is just a plain PHP class, that is annotated as an Attribute itself.

#[Attribute]
class ApplyMiddleware
{
    public array $middlware = [];

    public function __construct(...$middleware) {
        $this-&gt;middleware = $middleware;
    }
}

// This adds the attribute to the MyController class, with the "auth" middleware as an argument.

#[ApplyMiddleware('auth')]
class MyController
{
    public function index() {}
}

// We can then retrieve all ApplyMiddleware attributes on our class using reflection
// And read the given middleware arguments.

$reflectionClass = new ReflectionClass(MyController::class);

$attributes = $reflectionClass-&gt;getAttributes(ApplyMiddleware::class);

foreach ($attributes as $attribute) {
    $middlewareAttribute = $attribute-&gt;newInstance();
    dump($middlewareAttribute-&gt;middleware);
}

exit;
</pre>
</pre>

<p>This RFC proposes to introduce a short hand syntax, which allows combining the definition of properties and the constructor:</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

class User {
    public function __construct(
        public int $id,
        public string $name,
    ) {}
}

$user = new User(1, 'Marcel');

dump($user-&gt;id);
dump($user-&gt;name);

exit;
</pre>
</pre>
<h2 id="added-support-for-codematchcode-expression-a-hrefhttpswikiphpnetrfcmatch-expression-v2rfca">Added support for <code>match</code> expression. (<a href="https://wiki.php.net/rfc/match_expression_v2">RFC</a>) <a href="#added-support-for-codematchcode-expression-a-hrefhttpswikiphpnetrfcmatch-expression-v2rfca">#</a></h2>
<p>This RFC proposes adding a new match expression that is similar to switch but with safer semantics and the ability to return values.</p>
<pre data-theme="light" data-filename="index.php" data-php="8"><pre data-filename="index.php">&lt;?php
declare(strict_types=1);

echo match (1) {
    0 =&gt; 'Foo',
    1 =&gt; 'Bar',
    2 =&gt; 'Baz',
};

exit;
</pre>
</pre>
<h2 id="added-support-for-nullsafe-operator-code-gtcode-a-hrefhttpswikiphpnetrfcnullsafe-operatorrfca">Added support for nullsafe operator (<code>?-&gt;</code>) (<a href="https://wiki.php.net/rfc/nullsafe_operator">RFC</a>) <a href="#added-support-for-nullsafe-operator-code-gtcode-a-hrefhttpswikiphpnetrfcnullsafe-operatorrfca">#</a></h2>
<blockquote>
<p>When the left hand side of the operator evaluates to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pociot.dev/32-php-8-try-out-all-new-features">https://pociot.dev/32-php-8-try-out-all-new-features</a></em></p>]]>
            </description>
            <link>https://pociot.dev/32-php-8-try-out-all-new-features</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905120</guid>
            <pubDate>Tue, 27 Oct 2020 07:25:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rachel Whiteread’s House: why was this Bow landmark demolished? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905103">thread link</a>) | @BerislavLopac
<br/>
October 27, 2020 | https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/ | <a href="https://web.archive.org/web/*/https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			
<p>Every day people walk past Wennington Green, on the corner of Grove Road and Roman Road, without realising this was the spot on which stood Rachel Whiteread’s controversial inside-out concrete cast of an East End terraced house. Why was this Bow landmark demolished?</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house For Sale signs" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house For Sale © David Hoffman</figcaption></figure>



<h2>Wennington Green, Bow, London</h2>



<p>At the intersection of Roman Road and Grove Road lies Wennington Green – a patch of land in <a href="https://romanroadlondon.com/mile-end-park-history/" target="_blank" rel="noreferrer noopener">Mile End Park </a>principally sculpted by flying bombs. In fact, an English Heritage plaque on the railway bridge a little further down Grove Road commemorates the first one to strike London.</p>



<p>The blitz largely levelled the hundred or so turn-of-the-century terraces, common stock of the working class East End, on what is now the Green but up until the early ‘90s a row of dilapidated dwellings persisted. These residences were mostly derelict, abandoned and occasionally squatted, but for one, ex-docker Mr Sidney Gale of No. 193, a condemned house remained a home.</p>



<p>Indeed, in 1993, the final row was fated to be demolished as part of Tower Hamlet’s council’s plan to create a Green Corridor, unifying the broken line of parkland between the Isle of Dogs and the established lung of <a href="https://romanroadlondon.com/victoria-park-east-london-bow/">Victoria Park</a>. It was a means to cleanse the area of the legacy of prefabs that had homed the dislocated population post-war and a redemptive space for those in the high-rise accommodation which had replaced the traditional terraces. ‘What people who live in tower blocks want is parkland,’ declared Councillor Eric Flounders.</p>



<p>Yet psychogeographer Iain Sinclair was sceptical of the council’s motives, calling it ‘an Arcadia for the underclass… the whole scheme was a disinterested attempt at municipal aesthetics’. Pointedly, the area was in direct sight of Mrs Thatcher’s commerce baby, Canary Wharf, and the call for a Green was not a far cry from the original motivations to create Victoria Park, opened in 1845. Vicky Park is the oldest purpose built recreation ground in London, conceived to curb disease contracted in damp and cramped conditions and as a means harness working-class wildness. Indeed, Bow is an area rich with connotations of a strong working-class community, but also radicalism and revolt.</p>



<p>Mr Gale forcefully resisted eviction from No. 193 by the council for a number of years, even festooning the property with banners to affirm his unrelenting presence, but, realising his campaign was ultimately futile, he eventually yielded and was re-homed nearby. Gale’s loss was artist Rachel Whiteread’s gain. The practitioner had been seeking a condemned property in London for over two years to realise a project which was essentially a development upon her Turner Prize nominated sculpture, Ghost (1990); a room-sized cast of a bedsit contained in a Victorian property in Archway.</p>



<p>Whiteread, supported by art commissioners Artangel, approached the London Borough of Tower Hamlets&nbsp;council about utilising the property and the authorities duly consented. In the beginning, the council were of the opinion that, ‘It won’t cost the neighbourhood a penny and will provide an unusual landmark for the area,’ however, by the time the bricks were removed and the sculpture was exposed, Councillor Flounders, Chair of Bow Parks Board, denounced it as ‘excrescent.’</p>



<h2>Building Rachel Whiteread’s House</h2>



<figure><img loading="lazy" width="1024" height="692" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg" alt="Rachel Whiteread's House on Grove Road in Bow, photo by David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-300x203.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-768x519.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house view of Grove Road © David Hoffman</figcaption></figure>



<p>To make House, Whiteread used the physical house as&nbsp;a&nbsp;mould, making a cast from the interior by spraying a skin of liquid concrete around a metal armature constructed to support the weight of the work. Coating the whole house took over a month and an additional ten days were needed for the concrete to cure and set. Once solid, scaffolding was erected and Whiteread and her assistants began to remove the exterior brick structure.</p>



<p>What was revealed was an uncanny sight – the concrete impressed with the idiosyncrasies of over a century of domestic habitation. Depressions translated into protrusions; the industrial material betraying past human intimacies: soot marking the fire; yellow paint from a top-floor bedroom. The floors in-between stories could not be cast so, as local Markham Hall recalls, it resembled a ‘wedding cake.’ But the marriage at hand, between the art world and the East End, was to be short-lived and volatile.</p>



<h2>Reactions to Rachel Whiteread’s House</h2>



<p>It was essentially a neutral process, with no specific moral agenda, but Whiteread conceded ‘I knew of course, while I was making House, it had a political dimension. You can’t make a cast of a house in a poor area of London and not be political.’ Yet it became ‘far more political than I could have predicted.’ Seemingly, the council had also underestimated its resonance, as it quickly became front-page news, attracting scores of art-pilgrims and causing traffic chaos. Its status was even brought to debate in the House of Commons. The council couldn’t wait to get rid of the work fast enough, coming to regard it as a politically embarrassing monument to an impoverished history and standing in the way of the construction of a less threatening green space.</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house with Wot For Why Not graffiti © David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Wot For? Why Not? © David Hoffman</figcaption></figure>



<p>People reacted to House so strongly as it transcended the individual and became an archetype; an emblem for the area’s time-honoured mode of living. Indeed, it raised pressing questions regarding degrading housing stock and what should be done with it, the creeping gentrification of a historically tight working class community and scepticism towards the authority of those instigating change for the supposed ‘greater good’. In whose name was this change really for? And poignantly, it confronted these questions on its own material terms – concrete being the material used to fix the original Victorian House’s bricks; the embossed surface betraying the umbilical cords of pipes and power-lines which linked the individual house with the local, national and global public.</p>



<p>At base, Whiteread made an empty space, the negative void of the vacated property, into a positive object but insists ‘the work is to do with absence not presence.’ Implicitly, House was defined by the object it was not. When one refers to a ‘house’ we generally mean the façade as publicly viewed from the street, the interior is intimate – that is the home. Whiteread’s sculpture was resolutely an interior; an unsettling mass of inside, out.</p>



<p>The form elicited unease as when we have an intimate relationship with a space, we start to ignore its intricacies, instead handling navigating through the general form unconsciously. Thus, the sculpture was uncanny as it solidified the overlooked, demanding a long-looking, deep contemplation, as one attempted to decipher the inverted forms. Whiteread neglected to furnish her House with meaning but it was predominantly envisioned as what the populace of Bow would soon lose sight of. The interior, a family home, was left out in the cold and significantly, Whiteread chose not to cast the attic space, as if riffing on the idiom ‘left with no roof over their heads.’</p>



<p>It’s understandable then, that there was some resentment from locals towards House as they perceived it to be adding insult to injury over the demolition of such homes in the area, and a crassness in exposing working-class abode for the ‘arty’ leisure classes. Yet, this wasn’t just a case of Art World vs. East Enders, the opinions were split within both camps: in the Art World, Andrew Graham-Dixon proclaimed it ‘a strange and fantastical object which also amounts to one of the most extraordinary and imaginative public sculptures created by an English artist this century.’ To Brian&nbsp;Sewell, it was a ‘meritless gigantism.’ Sewell’s scorn found resonance in one local’s assertion that ‘an engineer could have done it; I don’t see it as creative.’ Whereas, another neighbour to the site regarded it as ‘brilliant,’ reckoning it to be ‘a new way of looking at traditional things.’</p>



<p>House’s evicted resident, Mr Gale, protested, ‘They’re taking the wee-wee.’ He questioned, ‘How can they get grants for arts projects when we can’t get grants for homes? I could have bought a new home for my family with this money.’ His sentiment was echoed in graffiti scrawled on the sculpture: ‘WOT FOR?’ Another renegade scribe rebuffing ‘Why not!’</p>



<p>House’s economics became even more contentious when Whiteread won the £20,000 Turner Prize for the work (the first woman to receive the honour), and then £40,000 from the rebel K Foundation (composed of members of the defunct pop group KLF) for the ‘worst artist of the year.’ Whiteread split the latter money between Shelter, a charity for the London’s homeless, and a fund to supplement young artists. On the same day, the&nbsp;Council made the decision to refuse House a stay of execution. By this time, many people (philanthropists, dealers, galleries) had offered to purchase House, but money offered to the Council to retain its presence was blasted by the authorities as ‘bribes.’ In any case, Whiteread was adamant that the sculpture was ‘absolutely specific to the site’ thus preferred its destruction to relocation.</p>



<p>The bulldozers came on January 11th 1994. The <em>East London Advertiser</em> reports that ‘art lovers’ chained themselves to the railings in attempt to save the work, quoting one as protesting, ‘We’re doing this because House represents the destruction of not only homes but whole communities in East London.’ Another suggested its removal was a sacrilegious act, perceiving House as ‘a headstone to the houses that were here.’ But the sculpture’s fate was sealed. As Whiteread succinctly mused ‘it took three and a half years to develop, four months to make, and thirty minutes to demolish.’</p>



<h2>The legacy of Rachel Whiteread’s House</h2>



<p>The Houseless Park has now had over 20 years to bed in to the community’s psyche and flourish naturally. In all of the articles and art history books I have trawled to substantiate …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</a></em></p>]]>
            </description>
            <link>https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905103</guid>
            <pubDate>Tue, 27 Oct 2020 07:21:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Course Announcement – Machine Learning Systems Design at Stanford]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905040">thread link</a>) | @EvgeniyZh
<br/>
October 27, 2020 | https://huyenchip.com/2020/10/27/ml-systems-design-stanford.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/10/27/ml-systems-design-stanford.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Ever since teaching <a href="https://github.com/chiphuyen/stanford-tensorflow-tutorials">TensorFlow for Deep Learning Research</a>, I’ve known that I love teaching and want to do it again.</p>

<p>In early 2019, I started talking with Stanford’s CS department about the possibility of coming back to teach. After almost two years in development, the course has finally taken shape. I’m excited to let you know that I’ll be teaching <strong>CS 329S: Machine Learning Systems Design at Stanford</strong> in January 2021.</p>

<p>The course wouldn’t have been possible with the help of many people including <a href="https://cs.stanford.edu/~chrismre/">Christopher Ré</a>, Jerry Cain, Mehran Sahami, <a href="https://pirroh.fyi/">Michele Catasta</a>, Mykel J. Kochenderfer.</p>

<p>Here’s a short description of the course. You can find the (tentative) syllabus below.</p>

<p><em>This project-based course covers the iterative process for designing, developing, and deploying machine learning systems. It focuses on systems that require massive datasets and compute resources, such as large neural networks. Students will learn about the different layers of the data pipeline, approaches to model selection, training, scaling, as well as how to deploy, monitor, and maintain ML systems. In the process, students will learn about important issues including privacy, fairness, and security.</em></p>

<p><strong>Pre-requisites</strong>: <em>At least one of the following; CS229, CS230, CS231N, CS224N, or equivalent. Students should have a good understanding of machine learning algorithms and should be familiar with at least one framework such as TensorFlow, PyTorch, JAX.</em></p>

<p>For Stanford students interested in taking the course, <a href="https://bit.ly/appy-mlsys-2021">you can fill in the application here</a>. The course will be evaluated based on one final project (at least 50%), three short assignments, and class participation.</p>

<p>For those outside Stanford, I’ll try to make as much of the course materials available as possible. I’ll post updates about the course on <a href="https://twitter.com/chipro">Twitter</a> or you can check back here from time to time.</p>

<p>Since these are all new materials, I’m hoping to get early feedback. If you’re interested in becoming a reviewer for the course materials, please shoot me an email. Thank you!</p>

<h2>Tentative syllabus</h2>

<h3>Week 1: Overview of machine learning systems design</h3>
<ul>
  <li>When to use ML</li>
  <li>ML in research vs. ML in production</li>
  <li>ML systems vs. traditional software</li>
  <li>ML production myths</li>
  <li>ML applications</li>
  <li>Case studies</li>
</ul>

<h3>Week 2: Iterative process</h3>
<ul>
  <li>Principles of a good ML system</li>
  <li>Iterative process</li>
  <li>Scoping the project</li>
</ul>

<h3>Week 3: Data management</h3>
<ul>
  <li>Challenges of real- world data</li>
  <li>How to collect, store, and handle massive data</li>
  <li>Different layers of the data pipeline</li>
  <li>Data processor &amp; monitor</li>
  <li>Data controller</li>
  <li>Data storage</li>
  <li>Data ingestion: database- engines</li>
</ul>

<h3>Week 4: Creating training datasets</h3>
<ul>
  <li>Feature engineering</li>
  <li>Data labeling</li>
  <li>Data leakage</li>
  <li>Data partitioning, slicing, and sampling</li>
</ul>

<h3>Week 5: Building and training machine learning models</h3>
<ul>
  <li>Baselines</li>
  <li>Model selection</li>
  <li>Training, debugging, and experiment tracking</li>
  <li>Distributed training</li>
  <li>Evaluation and benchmarking</li>
  <li>AutoML</li>
</ul>

<h3>Week 6: Deployment</h3>
<ul>
  <li>Inference constraints</li>
  <li>Model compression and optimization</li>
  <li>Training vs. serving skew</li>
  <li>Concept drift</li>
  <li>Server- side ML vs. client- side ML</li>
  <li>Releasing strategies</li>
  <li>Deployment evaluation</li>
</ul>

<h3>Week 7: Project milestone and discussion</h3>
<ul>
  <li>Ethical concerns</li>
</ul>

<h3>Week 8: Monitoring and maintenance</h3>
<ul>
  <li>What to monitor</li>
  <li>Metrics, logging, tags, alerts</li>
  <li>Updates and rollbacks</li>
  <li>Iterative improvement</li>
</ul>

<h3>Week 9: Hardware &amp; infrastructure</h3>
<ul>
  <li>Architectural choices</li>
  <li>Hardware design</li>
  <li>Edge devices</li>
  <li>Clouds vs. private data centers</li>
  <li>Future of high- performance computing</li>
</ul>

<h3>Week 10: Integrating ML into business</h3>
<ul>
  <li>Model performance vs. business goals vs. user experience</li>
  <li>Team structure</li>
  <li>Why ML projects fail</li>
  <li>Best practices</li>
  <li>State of ML production</li>
</ul>

<p>This blog post was edited by the wonderful <a href="https://twitter.com/andrey_kurenkov">Andrey Kurenkov</a>.</p>

  </div></div>]]>
            </description>
            <link>https://huyenchip.com/2020/10/27/ml-systems-design-stanford.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905040</guid>
            <pubDate>Tue, 27 Oct 2020 07:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Profitable Service Business Ideas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24905038">thread link</a>) | @vinrob92
<br/>
October 27, 2020 | https://manyrequests.com/blog/117-profitable-service-business-ideas/ | <a href="https://web.archive.org/web/*/https://manyrequests.com/blog/117-profitable-service-business-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="genesis-content"><article itemref="hero-section"><p><img width="1280" height="720" src="https://manyrequests.com/wp-content/uploads/2020/10/Blog-image-117-Profitable-Service-Business-Ideas-1280x720.jpg" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201280%20720'%3E%3C/svg%3E" data-lazy-src="https://manyrequests.com/wp-content/uploads/2020/10/Blog-image-117-Profitable-Service-Business-Ideas-1280x720.jpg"></p>
<p><time>October 27, 2020</time> by   </p><div>
<div><p>Want to start an online service-based business or start an agency?</p><p>Here are 117 examples of services you can sell online, in 6 different categories. </p></div>



<h2>Why we made this list:</h2>



<div><p><strong>1. To inspire you.</strong></p><p>Lots of entrepreneurs mention that one of their biggest obstacle to starting a company is finding what to work on. This list gives you not only ideas, but also examples of real successful businesses built on those ideas.</p><p><strong>2. To show you can build a successful business around one service.</strong></p><p>You don’t need to do more (or offer more) to be successful when running a service business. Pick one service (e.g. <em>Website-as-a-service</em>), one niche (e.g. <em>Lawyers</em>) and get started (e.g. <em>Done-for-you websites for lawyers</em>).</p></div>







<div><p>E-commerce is a huge industry that is <a href="https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/">projected to grow to 6.54 trillion</a> (yes, trillion) US dollars by 2022.</p><p>Can you grab a slice of this by helping e-commerce sellers with one of their tasks?</p><p>Take marketplaces for example: Etsy,&nbsp; Amazon, Red Bubble, PoshMark, Teespring) or any e-commerce platforms (Shopify or Woocommerce are two examples that come to mind), you can probably build a service just for one marketplace or platform and be successful with that.</p><p><strong>Examples of e-commerce services:</strong></p><p>1. Image retouching<br>2. Product photography (<a href="https://www.outshinery.com/">Outshinery</a>, <a href="https://feedsauce.com/">Feedsauce</a>)<br>3. Product description<br>4. Email newsletters for e-commerce stores<br>5. Pinterest product image creation<br>6. Product listing and inventory management<br>7. Store maintenance service (<a href="https://www.tailry.com/">Tailry</a>)<br>9. Product research<br>10. Store migration service</p></div>







<div><p>Content is the fuel of the Internet.</p><p>Whether it’s getting found on search results with blog posts, helping sales team perform better with custom long form sales letter or email newsletters to nurture an audience —&nbsp; you name it, content is a key part of the internet.</p><p><strong>Examples of content and design services:</strong></p><p>11. Small graphic design tasks (<a href="https://www.hatchly.co.uk/">Hatchly</a>)<br>12. Content repurposing (<a href="https://repurposehouse.com/">Repurpose House</a>)<br>13. Blog post writing service (<a href="https://contentago.com/">Contentago</a>)<br>14. Case study service (<a href="https://casestudybuddy.com/">Case Study Buddy</a>)<br>15. Podcast production service<br>16. Translation services<br>17. Podcast editing service<br>18. Video editing service (<a href="https://www.videohusky.com/">Video Husky</a>)<br>19. Presentation design<br>20. Logo design (<a href="https://photologo.co/">PhotoLogo</a>)<br>21. Landing page design<br>22. Infographics design<br>23. Ebook writing service (<a href="https://contentgravy.com/">Content Gravy</a>)<br>24. Animations (<a href="https://55knots.com.au/">55Knots</a>)<br>25. Display banner design (<a href="https://www.getads.co/">GetAds</a>)<br>26. Explainer video<br>27. How-to / tutorial videos<br>28. Illustrations<br>29. Copywriting service<br>30. Branding assets service<br>31. Brochures service<br>32. Blog post to Youtube video<br>33. Video snippets for social media<br>34. Onboarding video for new staff<br>35. Product videos<br>36. Voice over service<br>37. 3d rendering service<br>38. 2d rendering service<br>39. 3d video walkthrough<br>40. Product wireframes<br>41. Website to app service<br>42. Blog article translation<br>43. Instagram story design<br>44. Zoom background design<br>45. Speech writing service<br>46. Creative story writing<br>47. T-shirt design<br>48. Book cover design</p></div>







<div><p>Another big category of online services are marketing services. From setting up a content writing strategy, to optimizing a website for SEO, or simply creating a lead generation services, the opportunities are endless.</p><p><strong>Examples of marketing services:</strong></p><p>49. List building<br>50. Marketing strategy<br>51. Content marketing strategy (<a href="https://www.koalarank.com/">KoalaRank</a>)<br>52. Link building<br>53. Local SEO<br>54. SEO optimisation service<br>55. Video SEO audit<br>56. Blogger outreach service<br>57. Appointment setting service<br>58. Social media management<br>59. Lead generation service<br>60. Email marketing service<br>61. PR service<br>62. Keyword research for blog content<br>63. Competitor SEO analysis<br>64. Technical content<br>65. Facebook ads<br>66. Other ads (Reddit, Twitter, Google, LinkedIn)<br>67. Sales copy<br>68. Guest posting as a service<br>69. Ultimate guide service<br>70. Video case studies<br>71. Business Intelligence and reporting service<br>72. Marketing tool set up service<br>73. Sales funnels service<br>74. Podcast appointment service<br>75. Social media calendar set up<br>76. Instagram feed design&nbsp;</p></div>







<p>Virtual assistant services: From appointment setting, to research, as well as other administrative tasks is another great type of service to offer online.</p>



<p><strong>Examples of virtual assistant services:</strong></p>



<p><br>77. Appointment scheduling<br>78. Email cleanup service<br>79. HR virtual assistant (job posting, interviews, payroll,contract, …)<br>80. Facebook group moderation service<br>81. Research<br>82. Updating contacts<br>83. Scheduling tasks and planning<br>84. Creating reports<br>85. Customer service <br>86. Virtual assistant matching service (<a href="https://ask-elly.co/">Elly</a>)<br>87. Executive assistant service<br>88. Data entry<br>89. Technical support<br>90. Software tester service<br>91. Customer review management<br>92. Expense management service<br>93. Zoom meeting minutes<br></p>







<div><p>Most of websites need a payment gateway, newsletter set up, some landing pages as well as updates and maintenance. </p><p>One of such services, WPCurve, was <a href="https://techcrunch.com/2016/12/05/godaddy-wp-curve/">actually acquired</a> by GoDaddy.</p><p><strong>Example of website services:</strong></p><p>94. Website installation service (<a href="https://gloat.dev/">Gloat.dev</a>)<br>95. Website speed up service<br>96. Landing page reviews <br>97. Website maintenance services <br>98. Landing page copywriting<br>99. Website-as-a-service (<a href="https://thechurchco.com/">TheChurchCo</a>)<br>100. Design to code service (<a href="http://devondemand.co/">DevOnDemand</a>)<br>101. No-code automations service<br>102. Landing page development service<br>103. Plugin installation service<br>104. Website migration service</p></div>







<p>Here are some other services we couldn’t really fit into any niches. From bookkeping, to naming-as-a-service, as well as market and competitor research.</p>



<div><p><strong>Examples of other services: </strong></p><p>105. Bookkeeping service (<a href="https://beanninjas.com/">Bean Ninjas</a>)<br>106. Company incorporation service (<a href="http://sleek.com/">Sleek</a>)<br>107. UX / conversion review service (<a href="https://conversioncrimes.com/">Conversion crimes</a>)<br>108. Market and competitor research<br>109. Investor pitching service<br>110. Business plan service<br>111. Business name idea service<br>112. Business slogan service<br>113. Company notion board service<br>114. Resume improvement service<br>115. User interview and positioning service<br>116. Survey participants recruitment<br>117. Beta reading service</p></div>







<div><p>We hope this article gave you some inspiration.</p><p>On top of our <a href="https://www.manyrequests.com/">client portal</a> for agencies and online service businesses, we also run an awesome free community of service based service entrepreneurs called <a href="http://productize.community/">Productize Community</a>. </p><p>Join us and let us know what you’re building, we’ll see you on the inside.</p></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://manyrequests.com/blog/117-profitable-service-business-ideas/"
    dc:identifier="https://manyrequests.com/blog/117-profitable-service-business-ideas/"
    dc:title="117 Profitable Service Business Ideas"
    trackback:ping="https://manyrequests.com/blog/117-profitable-service-business-ideas/trackback/" />
</rdf:RDF>-->
</div></article><h2>Reader Interactions</h2>	<!-- #respond -->
	</main></div></div>]]>
            </description>
            <link>https://manyrequests.com/blog/117-profitable-service-business-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905038</guid>
            <pubDate>Tue, 27 Oct 2020 07:04:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you considered buying used hardware?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24904912">thread link</a>) | @todsacerdoti
<br/>
October 26, 2020 | https://www.0chris.com/consider-buying-used.html | <a href="https://web.archive.org/web/*/https://www.0chris.com/consider-buying-used.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>2020-10-23</p>
<p>For my current job I knew I wanted a Linux laptop again, after enough exposure to Apples ecosystem. Naturally a Thinkpad came to mind as an option, but I wanted to give used hardware a chance, given that Thinkpads are known to be reliable and well built.</p>
<p>I went with used/refurbished hardware from a vendor I know and trust for a while now, <a href="https://www.lapstore.de/">lapstore.de</a>, and I could not be happier with my choice. I went with a Lenovo Thinkpad T460s, as a compromise between decent performance, weight, screen size and good Linux support out of the box. This model is 5 years old, but CPUs are not evolving that fast anymore, so it still feels very snappy with everything I'm doing. The internal screen could have used a slightly higher resolution for my taste, but I am rarely using it these days.</p>
<p>One big advantage of the older models is access to the old version of the docking stations, which are totally worth it. At home the laptop sits there, gets charged and drives my 4K display easily, while being hooked up to my mouse, keyboard and network cable. Speaking of ports: the T460s still has proper Rj-45, USB 2.0/3.0 and HDMI ports. No adapters needed!</p>
<p>Summing up, here is why I think used hardware is worth considering:</p>
<ul>
<li>it is cheaper. Sure, your employer might be paying for it, but maybe you have a fixed budget and get more out of it this way.</li>
<li>it is good for the environment.</li>
<li>it will likely last for the next few years. Most of us don't need the latest hardware to do our job. I would argue that quite a bit of software could run better if developers weren't handed the latest and greatest hardware as a given</li>
<li>you are not giving up support. Sure, it might break. But so does a new one. There are quite a few respectable dealers out there who offer 3 years of warranty for little extra cost. Actually the first (used) docking station I got was not working ok, so I got an immediate, brand new replacement 2 days later.</li>
<li>Linux runs great on older hardware. With Kubuntu 20.04 everything works out of the box, including webcam, multimedia keys, docking/undocking or switching between different screen configurations.</li>
</ul>
<p>Why not give used hardware a try?</p>
<p>EDIT [2020-10-27] fixed typo "wantec"</p>


<ul>
  
</ul>

    </div></div>]]>
            </description>
            <link>https://www.0chris.com/consider-buying-used.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904912</guid>
            <pubDate>Tue, 27 Oct 2020 06:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Note on Branching Within a Shader]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24904706">thread link</a>) | @underanalyzer
<br/>
October 26, 2020 | https://www.peterstefek.me/shader-branch.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/shader-branch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>26 October 2020</strong></label></p><p>An <a href="https://www.google.com/search?q=three+weeks&amp;oq=three+weeks">eternity</a> ago, I published a <a href="https://www.peterstefek.me/focused-render.html">blog post</a> about a shader I wrote. In that post, I casually repeated a piece of gpu folklore I picked up as a wee opengl enthusiast almost a decade ago,   </p>
<p>
"Using if statements inside a shader will cause performance degradation."  
</p>

<p>People on the internet seemed a little skeptical about this statement, and I realized my advice might be outdated. So this post is a quick follow up about the cost of branching on more modern gpus.  </p>
<p>Before we talk about branching, what is a gpu? A GPU or graphics processing unit, is a special piece of hardware initially developed to crunch numbers for graphics calculations. It accomplishes this goal quickly through a large amount of parallelization.   </p>
<p>GPUs can run many threads at the same time in parallel. These threads are generally executed in groups called warps (CUDA), invocations (Vulkan) and waves (I will use the term warp, but they are all interchangeable). On recent Nvidia hardware (Ampere/ Volta / Pascal) these warps contain 32 threads. Pascal for example can theoretically run up to four independent instructions per warp over 56 warps of 32 threads which comes out to a mind blowing 7168 instructions per cycle. </p>
<p>Each warp can only execute one instruction at a time. However that instruction can be executed for each of the threads in the warp. This means the GPU can execute 32 copies of the same instruction in parallel for each thread in the warp at once.   </p>
<p>However, taking both sides of a branch will cause the threads inside a warp to "diverge". This means some threads will need to execute one side of the branch and some will need to execute the other. Unfortunately, both instructions can not be executed simultaneously for threads in the same warp. So these divergent instructions must be executed sequentially.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.  </p>
<p>Consider the <a href="https://www.shadertoy.com/view/WdyyWV">following fragment shader</a>:<br>
<code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{  <br>
  </code></p><p><code>
  // TUNE THIS AMOUNT TO YOUR GPU STRENGTH<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (mod(fragCoord.x, 2.) &lt; 1. &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
      </p></div>
  } else {
    <div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>In fragment shaders like the one above, each warp is composed of a set of spatially close pixels. Each warp in this shader should diverge because each horizontally adjacent pixel takes a different side of the branch. Let's say the cost of each inner loop is n cycles. Since each side of the branch is executed in series, each warp must take at least 2n cycles, even though each thread uses only one side of the branch. These effects scale with the number of threads in the distinct divergent paths taken (up to 32x in Nvidia hardware). Here's another shader which should have roughly four branches per warp. <a href="https://www.shadertoy.com/view/wsVyzG">This shader</a> will take at least 4n cycles.  </p>
<p>However, let's look a <a href="https://www.shadertoy.com/view/tsVyzG">second shader</a>:   </p>
<p><code>
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
  </code></p><p><code>
  // USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  int workAmount = 2000;<br>
  float incr = 1. / float(workAmount);<br>
  float outColor = 0.0;  
<p>// USE THIS VARIABLE TO TOGGLE BRANCHING<br>
  bool branch = true;  </p>
<p>if (fragCoord.x &lt; iResolution.x / 2.0 &amp;&amp; branch) {
    </p><div><p>
      for (int i = 0; i &lt; workAmount; i++) {
        </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(0.0,outColor,0.0,1.0);
    </p></div>
  } else {
    <div><p>
        for (int i = 0; i &lt; workAmount; i++) {
          </p><p>
          outColor += incr;
          </p><p>
      }<br>
      fragColor = vec4(outColor,0.0,0.0,1.0);
      </p></div>
  }
  </code></p><p><code>
}
</code></p>
<p>This shader should run roughly twice as fast as the other shader even though roughly the same number of pixels take each branch. This is because most of the warps do not diverge (with the exception of a few around half way across the screen).   </p>
<p><strong>Nvidia Specifics</strong><br>
As far as I can tell, there are roughly two different ways of nvidia graphics cards handle divergence with in a warp.</p>
<p><strong>Thread Masking (Pre Volta)</strong><br>
On pre volta Nvidia card, divergence was handled by something called thread masking.   </p>
<p>Basically when a conditional is hit, a thread mask is generated.  We can think of this mask as a 32 entry array. Each entry specifies whether the corresponding thread takes the first side of the branch or not. The first side is then executed for each of those threads. After the first side of the branch is then executed, the mask is reversed and the other side of the branch is executed.   </p>
<p>This thread mask strategy exists in part because there is only one program counter per warp on pre volta gpus. So essential every thread in the warp must be at the same place in the program. The only way we know which threads to execute, is by using the mask.</p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/pascal-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>It's worth noting that only the threads which need to execute the branch actually are assigned to computational cores. So if no threads execute one side of the branch, no work is done.</p>
<p><strong>Independent Thread Scheduling (Volta and Beyond)</strong><br>
One big change in the Volta architecture and beyond is the introduction of "Independent Thread Scheduling".   </p>
<p>In Independent thread scheduling, each thread has its own program counter. This allows each warp to track the execution of every thread at a fine grain level. However, we can still only execute only one instruction at a time. So the actual runtime of a branch does not change.  </p>
<p>So if Independent Thread Scheduling does not speed up branching, what does it do? Independent Thread Scheduling enables both sides of a branch to execute concurrently but not in parallel.   </p>
<p>
    <img src="https://www.peterstefek.me/images/shader-branch/volta-divergence.png" width="65%"> 
</p>

<p>The above image is taken from the Volta whitepaper.</p>
<p>The reason for this shift is because before Volta, branches were places where deceptive deadlocks could occur. <br>
<code>
leader_id = 0<br>
If (threadIdx.x == leader_id) {<br>
  </code></p><p><code>
    // Do some inital work
  </code></p><p><code>
} else {
  <p>
    // Wait for leader to finish it's work<br>
    // then do my work
  </p>
}<br>
</code></p>
<p>In the above compute shader pseudo code, we have 31 "follower" threads waiting for the "leader thread" to finish (using in-warp shared local memory) before executing their own instructions. </p>
<p>On a Pascal GPU or below, if the else side of the branch is executed first, a deadlock will occur. The leader will never get a chance to start it's work because its followers will be waiting for it. </p>
<p>Independent Thread Scheduling gets around these locking problems by interlacing the two diverging paths. </p>
<p><strong>Article TLDR</strong><br>
Branch divergence in warp makes all parts of the branch execute in sequence which slows down the shader. Branching divergence between warps does not affect runtime.  </p>
<p><strong>Further Reading</strong><br>
Branch execution on gpus is surprisingly deep, and there are many edge cases I didn't address and I also didn't touch gpu vendors other than Nvidia. Here are some good sources if you want to learn more:  </p>
<p><a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">The Volta Whitepaper</a> (Most of this post can be found between figures 20 and 22)<br>
<a href="http://taylorlloyd.ca/gpu,/pascal,/cuda/2017/01/07/gpu-pipelines.html">Understanding the Pascal GPU Instruction Pipeline</a><br>
<a href="https://aschrein.github.io/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html#figure-8-divergent-threads-execution-time">What's up with My Branch on GPU</a> (this post covers some diabolical edge cases, including some around texture sampling)  </p>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/shader-branch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904706</guid>
            <pubDate>Tue, 27 Oct 2020 05:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Warp Dissection: There's Hot Sauce in the Gears (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24904520">thread link</a>) | @luu
<br/>
October 26, 2020 | http://www.mandible.net/2013/01/31/warp-dissection-theres-hot-sauce-in-the-gears/ | <a href="https://web.archive.org/web/*/http://www.mandible.net/2013/01/31/warp-dissection-theres-hot-sauce-in-the-gears/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <p>Warp is a puzzle–based stealth action game where you play as Zero, a little orange alien with a big score to settle!</p>
<p>I copied that off the game's website.</p>
<p>The important part is in the first five words. Warp is puzzle-based. That's how the game is billed, that's what I expected.</p>
<p><img src="http://www.mandible.net/wp-content/uploads/2013/01/8-1-5.jpg" alt="" title="WARNING, WARNING, A CUTE ORANGE THING IS LOOSE. RUN AROUND POINTLESSLY AND DO NOT LOOK UP. WARNING." width="650" height="382" srcset="http://www.mandible.net/wp-content/uploads/2013/01/8-1-5-300x176.jpg 300w, http://www.mandible.net/wp-content/uploads/2013/01/8-1-5.jpg 650w" sizes="(max-width: 650px) 100vw, 650px"></p>
<p>And let's get this out of the way: Warp is a good game. The puzzles are fun, the game is pretty, the plot is predictable but in the good we're-all-familiar-with-this-myth-so-let's-get-the-cliches-out-of-the-way-and-have-some-puzzle-fun manner. I like myths. Myths are good. Myths attached to a puzzle game are even better.</p>
<p>Zero, the playable character, has a host of special abilities. He can warp through solid walls and obstructions, he can warp inside objects and explode them from the inside, he can swap places with objects and he can launch objects at high speed. Note that "objects" includes "people". In most puzzle games, "people" are major puzzle pieces. In Warp, the only real difference between a turret and a person is that the person is easier to lure into important locations and doesn't shoot you as quickly.</p>
<p>It's all a recipe for a great puzzle game, and it's honestly somewhat tragic that it falls short.</p>
<p>The thing about good puzzle games is that, by their very nature, you'll have trouble with them. Some puzzle games are designed so that it's impossible to get stuck. Some are designed so that restarting is easy and fast. Warp is a bit of a curious beast in that it's also a stealth action game. Your opponents have guns, they are quick with their triggers, and you will die in a single shot. So: You die. You hit the "restart" button.</p>
<p><img src="http://www.mandible.net/wp-content/uploads/2013/01/W_Screenshot2.jpg" alt="" title="DANGER! LOADING SCREEN APPROACHES" width="650" height="365" srcset="http://www.mandible.net/wp-content/uploads/2013/01/W_Screenshot2-300x168.jpg 300w, http://www.mandible.net/wp-content/uploads/2013/01/W_Screenshot2.jpg 650w" sizes="(max-width: 650px) 100vw, 650px"></p>
<p>You sit there staring at a loading screen for ten seconds.</p>
<p>Which doesn't sound like a lot, but Warp is a <i>very</i> deadly game. The wrong approach can, and will, lead to death in seconds. Even when you're not being actively shot at, the world is littered with lasers and explosives and similar instant death traps. The second level starts with a puzzle that will kill you so quickly that failure results in spending more time loading than playing. And even when your plan is perfect and the area is harmless, Warp's sensitive controls will lead to you waltzing into lasers and warping yourself straight into death far more often than you'd expect.</p>
<p>Each time, accompanied by a ten second loading screen.</p>
<p>It is hard to describe how annoying that is, and it's just a herald of what lies in store.</p>
<p>Warp is filled with minor issues. Nothing that, in itself, would cripple the game. Things that I'd normally be remarking about in passing, as a minor blemish on an otherwise good game. But they just came so quickly and so relentlessly that it seemed every time I forgot about one, I'd run into another.</p>
<p>Example: The levels are filled, not just with armed guards, but with unarmed scientists. The scientists are terrified of you. Perpetually. Doesn't matter if you've carefully avoid killing scientists. Every time you warp into a room: screaming scientists. You can stand in the room for a minute and they just keep running around panicking, you leave the room, they recover and go back to work, teleport back in and it's Screamtown USA all over again.</p>
<p><img src="http://www.mandible.net/wp-content/uploads/2013/01/warp2-620x.jpg" alt="" title="AUGH. AUUUUUGH. AUUGH. AUUUGH. AUUUUUUUUUGH. DON'T LOOK AT MY PANTS. AUUUUUUUUUUUUGH." width="620" height="349"></p>
<p>This could have been improved in several ways. Iji does it brilliantly – avoiding slaughter in Iji eventually leads to the "enemies" allying with you, followed by an entire different branch of the game with a different ending. Extra endings and game branches take time and money, of course. Here's an easier idea: <i>make the damn scientists quieter</i>. As it is, every time you jump into a room you're greeted with an atmosphere-obliterating chorus of screeches. Or make them stop paying attention to you after a while! Maybe that's a reward for not killing them: they stop setting off alarms!</p>
<p>Another example: I mentioned Warp's controls. Most of my frustration revolved around Zero's Illusion ability, which allow him to project a duplicate of himself to trick enemies. The problem is that any damage done to the illusion, or any missteps into areas where the illusion is not allowed to go, will dissipate the illusion . . . causing Zero to instantly start moving in whatever direction the illusion was moving. If you use the illusion in a place where it's not allowed – even if a valid spawn point is literal inches away – the illusion will spawn directly in front of Zero, instantly disperse, and return control to Zero when you're least expecting it.</p>
<p>So if, for example, you decide to create an illusion and move it forward, and at that very instant a laser beam fires directly ahead of you, your illusion will walk into it, disperse, and before you have time to react, Zero will troop happily into it and die.</p>
<p>Cue ten-second load screen.</p>
<p>Not that this happened to me dozens of times over during the end boss fight or anything.</p>
<p><img src="http://www.mandible.net/wp-content/uploads/2013/01/Warp-Screenshot-3.jpg" alt="" title="SIR, WE HAVE HIM IN OUR SIGHTS, AND IT DEFINITELY ISN'T AN ILLUSION THIS TIME, UNLIKE THE PREVIOUS TWENTY SEVEN TIMES" width="620" height="349"></p>
<p>I can live with issues like this if the game is a low-budget affair, and doubly so if they're easy to recover from. Hotline Miami, an even faster-paced game released lately, is buggy as hell and had many fascinating problems and glitches as I fought my way through the levels. But in Hotline Miami, restarting the level is instant. And Hotline Miami's art is relatively simple, and its budget, I suspect, was quite minimal. For an indie game, Warp is a high-budget game, built on the Unreal engine, with detailed 3d models, good texturing, copious voice acting and cutscenes, and a boss that randomly and mysteriously fails to take damage from being attacked. Given the money spent on the rest of the game, the controls, loading times, and gameplay bugs are just unacceptable.</p>
<p>In the end, I kept feeling like the actual <i>game</i> had taken second tier to the rest of Warp. Compared to the amount of polish the art and atmosphere received, the gameplay was rough and spiky.</p>
<p>Warp is a good game. But with a little more work on the interface and a little more work on the game behavior, it could have been a lot better . . . even if that meant sacrificing a bunch of polygons.</p>
            </div>
          </div></div>]]>
            </description>
            <link>http://www.mandible.net/2013/01/31/warp-dissection-theres-hot-sauce-in-the-gears/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904520</guid>
            <pubDate>Tue, 27 Oct 2020 04:39:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Least You Need to Know About GitHub Pages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24904446">thread link</a>) | @tomcam
<br/>
October 26, 2020 | https://tomcam.github.io/least-github-pages/ | <a href="https://web.archive.org/web/*/https://tomcam.github.io/least-github-pages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p><strong>What this guide is for:</strong> This guide is laser-focused on one thing: showing how to get a working informational website up and running as fast
as possible using GitHub Pages, using only the GitHub website. <em>Informational website</em> is an informal term meaning that the emphasis is on
function (structured text with simple formatting, links, images) and not form (intricate page design). It goes step by step from the very beginning
and assumes very little knowledge on your part.</p>

<p>You don’t need to learn command-line programs like Git, or install anything
on your own computer. Everything taught here does apply to advanced use patterns when you get more experienced.</p>

<p>GitHub Pages is free if your repository (file storage area) is public.</p>

<p><strong>Ways to view this site</strong></p>
<ul>
  <li><a href="https://tomcam.github.io/least-github-pages/">Github Pages</a></li>
  <li>Directly on <a href="https://github.com/tomcam/least-github-pages/">Github</a></li>
</ul>

<p>If you were pointed here by an employer or well-meaning friend and aren’t quite sure why, 
you can find plenty of reasons in <a href="https://tomcam.github.io/least-github-pages/why-use-github-pages.html">Why Use GitHub Pages?</a></p>

<p><strong>What you can get out of this guide:</strong>  If you follow through the steps in this guide you’ll have a small website demonstrating everything you need to put up an attractive, easy to maintain site using words, links, and images. 
Not covered are advanced topics such as using Git on the command line, custom themes, SEO, version control,
and advanced features of GitHub-flavored Markdown.</p>

<p><strong>If you find problems</strong></p>

<p>If there’s something missing, or you detect an error, please feel free to <a href="https://github.com/tomcam/least-github-pages/issues">file an issue</a>
or just email at <code>tomcampbell@gmail.com</code>.</p>

<h2 id="table-of-contents">Table of contents</h2>

<p>This short GitHub Pages tutorial discusses:</p>

<ul>
  <li><a href="#intended-audience">Intended audience</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/creating-github-account.html">Create a GitHub Account</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/creating-github-repository.html">Create a GitHub repository</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/enable-github-pages.html">Enable GitHub Pages</a> so you can create and publish a formatted website</li>
  <li><a href="https://tomcam.github.io/least-github-pages/set-github-pages-master-branch.html">Set the GitHub Pages master branch to the /docs folder</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/github-pages-create-readme.html">Create the main GitHub Pages README file in /docs/README.md</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/create-page-github.html">Create a web page on GitHub</a> using Markdown</li>
  <li><a href="https://tomcam.github.io/least-github-pages/github-pages-directory-file-usage.html">GitHub Pages directory and file usage</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/markdown-links.html">Create Markdown links to other pages on your own site</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/markdown-headers.html">Headers in Markdown</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/markdown-links-to-other-sites.html">Create Markdown links to other sites</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/markdown-link-page-interior.html">Create Markdown links to the interior of a page</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/adding-assets-directory-github-pages.html">Add an assets directory to your GitHub Pages site</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/github-pages-jekyll-themes.html">Change the appearance of your GitHub Pages site using Jekyll themes</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/adding-images-github-pages-site.html">Add images to your GitHub Pages site</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/github-pages-url.html">Determine your GitHub Pages URL</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/privacy-warning.html">Privacy warning</a></li>
  <li><a href="https://tomcam.github.io/least-github-pages/add-github-pages-preview.html">Add a GitHub Pages preview link to your README.md</a></li>
</ul>

<h2 id="intended-audience">Intended audience</h2>

<p>GitHub Pages uses <a href="https://jekyllrb.com/">Jekyll</a>, a publishing system based on the Ruby programming language. The Jekyll documentation is excellent, especially if you already know Jekyll, program in Ruby, and have both Ruby and Jekyll installed on your local computer. The GitHub Pages documentation is comprehensive and excellent–if you’re already a Jekyll expert.</p>

<p><a href="https://tomcam.github.io/least-github-pages/">The Least You Need to Know About GitHub Pages</a> is designed for people who don’t happen to know Jekyll already but who need to get up to speed in GitHub Pages quickly to get a job done <em>now</em>. It tells you not only <em>what</em> to do step by step,
but also briefly explains <em>why</em> you’re doing it.</p>

<p>You probably don’t want to use GitHub Pages on sites that require complex, individual formatting on a per-page basis. 
GitHub Pages uses Markdown, which has some limited formatting information but not a lot.
GitHub Pages then uses Jekyll to turn that Markdown into HTML, based on the Jekyll theme you’ve chosen. Generally speaking this approach is
absolutely ideal for blogs, technical documents and instructional materials that require versioning and collaboration, where the
main work product is words and pictures. It is not a good fit for things like boutique pages, restaurant menu sites, consumer product sites, and so on where
custom formatting is the norm.</p>

<h3 id="advantages-to-using-github-pages">Advantages to using GitHub Pages</h3>

<p>Still wondering whether to use GitHub Pages? See <a href="https://tomcam.github.io/least-github-pages/github-pages-advantages.html">Advantages to using GitHub Pages to generate static sites</a></p>

<h3 id="disadvantages-to-using-github-pages">Disadvantages to using GitHub Pages</h3>

<p>If you want to understand why GitHub pages may not suit your project, see <a href="https://tomcam.github.io/least-github-pages/github-pages-disadvantages.html">When to avoid GitHub pages</a>.</p>

<p><a href="https://tomcam.github.io/least-github-pages/creating-github-account.html">Next page</a></p>

      </section>
    </div></div>]]>
            </description>
            <link>https://tomcam.github.io/least-github-pages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904446</guid>
            <pubDate>Tue, 27 Oct 2020 04:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIOS: IBM 5150 BIOS Replacement Project]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24904148">thread link</a>) | @userbinator
<br/>
October 26, 2020 | http://www.mtmscientific.com/mios.html | <a href="https://web.archive.org/web/*/http://www.mtmscientific.com/mios.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.mtmscientific.com/mios.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904148</guid>
            <pubDate>Tue, 27 Oct 2020 03:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An App to Measure Your Coffee Grind Size Distribution]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24903834">thread link</a>) | @occupy_paul_st
<br/>
October 26, 2020 | https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/ | <a href="https://web.archive.org/web/*/https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1314">

	

	
			<figure>
				<img width="1568" height="1068" src="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1568" alt="" loading="lazy" srcset="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1568 1568w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=150 150w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=300 300w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=768 768w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1024 1024w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png 2836w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="977" data-permalink="https://coffeeadastra.com/screenshot_coffee_grind_size/" data-orig-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png" data-orig-size="2836,1932" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot_coffee_grind_size" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=300" data-large-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>[Edit April 25 2019: Please note <strong>this is not an iPhone or Android app</strong>, and I have no plans to release it as such. You can use your phone or any other camera to take pictures of your ground coffee, but then you need to install the application on either OS X or through Python (on any operating system) to analyze the data. <a href="https://github.com/jgagneastro/coffeegrindsize/archive/master.zip">Download the application package here</a>.]</p>



<p>Today I would like to present an OS X application I have been developing for a few months. It turns out writing Python software for coffee is a great way to relax after a day of writing Python software for astrophysics.</p>



<p>When I started being interested in brewing specialty coffee a few years ago, one of the first things that irritated me was our inability to recommend grind sizes for different coffee brewing methods, or to compare the quality of different grinders in an objective way. Sure, some laboratories have laser diffraction equipment that can measure the size of all particles coming out of a grinder, but rare are the coffee geeks that have access to these multi-hundred thousands of dollars kinds of equipment.</p>



<p>At first, I decided to take pictures of my coffee grounds spread on a white sheet, and to use an old piece of software called <a href="https://imagej.nih.gov/ij/">ImageJ</a>, developed by the National Institutes of Health mainly to analyze microscope images, to obtain a distribution of the sizes of my coffee grounds. This worked decently well, and allowed me to start comparing different grinders. Then <a href="https://www.scottrao.com/">Scott Rao</a> made me realize that a stand-alone application that doesn’t need a complicated installation and that is dedicated to coffee would be of interest to many people in the coffee industry. Probably just the 10% geekiest of them, but that’s cool.</p>



<p>I’m hoping that this application will help us understand the effects of particle size distributions on the taste of coffee. I don’t think the industry really kept us in the loop with all the laser diffraction experiments, so hopefully we can help ourselves as a community.</p>



<p>If you are interested in measuring the particle size distribution of your grinder, then this app is for you ‒ and it’s free. I placed it as “open source” on <a href="https://github.com/jgagneastro/coffeegrindsize">GitHub</a>, so if you are a developer, you are welcome to send me suggestions in the form of <em>push requests</em> (the developers will know what that means).</p>



<p>If you would like to get started, I suggest you read this quick <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_installation.pdf">installation guide</a>, which will explain how to download the app and run it even though I am not a registered Apple Developer. Then, you can choose to either read this <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_summarized_manual.pdf">quick summary</a> that will get you running with the basics, or this <strong><em>very</em></strong> detailed and wordy <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_manual.pdf">user manual</a> that will guide you through all the detailed options the application offers you.</p>



<p>I would like to show you an example of what can be done with the software. Below, I am comparing the particle size distribution of the Baratza Forté grinder, which uses 54 mm flat steel burrs, with that of the Lido 3 hand grinder, which uses 48 mm conical steel burrs. I set both grinders in a way that produces a similar peak of average-sized particles with diameters around 1 mm, but as you can see, the particle size distributions are very different ! The Forté generates way less fines (with diameters below 0.5 mm) and slightly less boulders (with diameters of approximately 2 mm), which is indicative of a better quality grinder.</p>



<figure><img data-attachment-id="976" data-permalink="https://coffeeadastra.com/lido3_size9_file10_hist_mass_diam/" data-orig-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png" data-orig-size="1000,780" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lido3_size9_file10_hist_mass_diam" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png?w=300" data-large-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png?w=750" src="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png" alt=""><figcaption>An example of figure that can be generated with the coffee grind size software. Each red bar corresponds to one kind of particle diameter generated by the Lido 3 grinder (smallest particles correspond to the leftmost bar, largest ones correspond to the rightmost bar), and their heights correspond to the total contribution of these kinds of particles, by mass. As you can see, the particles that contribute to the largest amount of mass have sizes just above 1 mm. The red circle shows the average particle diameter for the Lido 3, and the horizontal bars show the “characteristic width” of the distribution – this corresponds to the width that covers approximately 68% of all the distribution. Similarly, the blue line and the blue circle describe the distribution of the Forté grinder.</figcaption></figure>



<p>For now, the app is only intended to be used on OS X computers. But if you are running any other kind of system and know your way around Python, you can always download it directly from <a href="https://github.com/jgagneastro/coffeegrindsize">GitHub</a> and run it with your own installation of Python 3.</p>



<figure><video controls="" src="https://www.dropbox.com/s/66ug5i9bkhrghef/screencap_coffeegrindsize.mov?raw=1"></video><figcaption>This is an example of how to use the coffee grind size application.</figcaption></figure>



<p>I would like to thank Scott Rao for his excitement when I shared this project idea with him, and for beta testing the software. I would also like to thank Alex Levitt, Mitch Hale, Caleb Fischer, Francisco Quijano and Victor Malherbe for beta testing the software.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		I’m a researcher in astrophysics at the Rio Tinto Alcan planetarium of Espace pour la Vie, in Montreal.		<a href="https://coffeeadastra.com/author/jgagneastro/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903834</guid>
            <pubDate>Tue, 27 Oct 2020 02:02:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a 40-plus-year-old piece of code in today's browser]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24903821">thread link</a>) | @amenghra
<br/>
October 26, 2020 | https://www.quaxio.com/kaleidoscope_part1/ | <a href="https://web.archive.org/web/*/https://www.quaxio.com/kaleidoscope_part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <header>
    <img src="https://www.quaxio.com/alok_small.jpg">
    
  </header>
  <div>
    
    
    
      <p><time>Oct 25, 2020</time>
      </p>
    
    
      <p>tags: kaleidoscope | 8-bit | Intel 8080 | Cromemco Dazzler</p>
    
  </div>
  <div>
    <p>I recently came across a <a href="https://www.quaxio.com/files/2020/kaleidoscope/kscope.txt">piece of assembly</a> code, written by Li-Chen Wang, which
displays a Kaleidoscope. This code was written in 1976, and distributed for $15
on a <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Kaleidoscope_for_Cromemco_Dazzler.jpg/1920px-Kaleidoscope_for_Cromemco_Dazzler.jpg">punched tape</a>. It appears this was one of three pieces of code used to
demonstrate the capabilities of <a href="https://en.wikipedia.org/wiki/Cromemco_Dazzler">Cromemco's Dazzler</a>, the first commercial
color graphics card for microcomputers.</p>

<blockquote>Stan Veit, owner of the Computer Mart of New York, described the reaction
  when he displayed the changing patterns of Kaleidoscope on a color television
  in his store window at the corner of 5th Avenue and 32nd Street in New York
  City in early 1976. “People driving by began to stop and look – they had never
  seen anything like it before. In a short time the Dazzler had caused a traffic
  jam on 5th Avenue!” The police had to contact the building landlord and make
  him disconnect the television.</blockquote>

<p><a href="https://en.wikipedia.org/wiki/Li-Chen_Wang">Dr. Li-Chen Wang</a> made quite some important
contributions resulting in the growth of the computer industry, such as a free
and open source BASIC interpreter as well as pioneering the concept of free software.</p>

<p>It turns out running this code from the dawn of computers in a browser isn't
too hard. The code is 127 bytes long. I found an existing <a href="https://github.com/maly/8080js">8080 emulator</a>. With the help of this <a href="https://www.quaxio.com/files/2020/kaleidoscope/cromemco_dazzler_manual.pdf">technical manual</a>, I wrote
the <a href="https://www.quaxio.com/files/2020/kaleidoscope/kaleidoscope.js">bare minimum amount of code</a> to emulate a Dazzler. Computer manuals back then were very detailed, especially for hardware that came as a kit, requiring a day or two of soldering.</p>

<p>Below is the result of running the code. In a subsequent post, I will cover how the code actually works.</p>

<canvas id="canvas"></canvas>



  </div>
  
  <hr>
  
</div>

    </div></div>]]>
            </description>
            <link>https://www.quaxio.com/kaleidoscope_part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903821</guid>
            <pubDate>Tue, 27 Oct 2020 01:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become a certified Project Management Professional by PMI in 2 months]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24903788">thread link</a>) | @renanmoura
<br/>
October 26, 2020 | https://renanmf.com/how-i-became-a-certified-project-management-professional-pmp-by-the-pmi-in-2-months/ | <a href="https://web.archive.org/web/*/https://renanmf.com/how-i-became-a-certified-project-management-professional-pmp-by-the-pmi-in-2-months/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Aside from software development, I also enjoy studying other related fields like marketing, project management, and product management.</p><p>Any reasonably sized software needs planning to be executed properly and after you "finish it" (a software product is never actually "done"), you need to market it to the public in order to make sales.</p><p>In this article, I will describe the process I took to become a Project Management Professional (PMP) by the Project Management Institute (PMI), one of the most sought certifications, not only in project management but in the market as a whole.</p><p>I was able to start my studies and take the test successfully in 2 months, studying between 3 and 4 hours a day, every day, weekends included, and get the results below:</p><p>Overall performance:</p><p><img src="https://renanmf.com/wp-content/uploads/2020/10/pmp-overall-performance.png" alt="Initial"></p><p>Performance by domain:</p><p><img src="https://renanmf.com/wp-content/uploads/2020/10/pmp-exam-breakdown.png" alt="Initial"></p><h2>What is the PMI and the PMP?</h2><p>The PMI (Project management institute) is the main organization when you think about project management.</p><p>Project Management varies a lot from place to place, from project to project, and from industry to industry, but there are some standards across all of those that are considered general best practices.</p><p>The PMI publishes the PMBoK (Project Management Body of Knowledge), which is a guide of best practices in project management.</p><p>The PMBoK is <strong>not</strong> a methodology, the project team needs to decide which processes will be applied according to their needs.</p><p>The PMBoK is usually updated every 4 or 5 years with new practices and a review of the current ones.</p><h2>PMP Certification requirements</h2><p>To apply for the test, you have to meet some criteria as described by the official PMI page:</p><ul><li>A four-year degree</li><li>36 months leading projects</li><li>35 hours of project management education/training or CAPM® Certification</li></ul><p><strong>OR</strong></p><ul><li>A high school diploma or an associate’s degree (or global equivalent)</li><li>60 months leading projects</li><li>35 hours of project management education/training or CAPM® Certification</li></ul><p>You can find everything you need to know about the application and the certification process itself on the official page of the exam at <a href="https://www.pmi.org/certifications/project-management-pmp">Project Management Professional (PMP)®</a>.</p><h2>What do you need to prepare</h2><p>I had 3 things at hand to prepare:</p><ul><li><a href="https://www.pmi.org/pmbok-guide-standards/foundational/pmbok">The PMBoK</a></li><li><a href="https://www.amazon.com/PMP-Exam-Prep-Eighth-Updated/dp/1932735658">Rita Mulcahy’s PMP Exam Prep</a></li><li>An exam simulator</li></ul><h3>The PMBoK</h3><p>This is PMI’s official resource to study. In a sense, it contains everything you need regarding topics.</p><p>The problem is that the PMBoK alone is a little too dry to study for the exam and it doesn’t have exercises to practice.</p><p>This is simply because the PMBoK is a reference book, not a study guide.</p><p>The best way to get a copy is to register as a PMI Associate. As an associate, you get a free copy of the PMBoK and you also get a good discount on the exam fee.</p><h3>Rita Mulcahy’s PMP Exam Prep</h3><p>This is the book you want to have with you as your best friend.</p><p>Unlike the PMBoK, Rita’s book is a written course to help you organize ideas and absorb the topics of the exam with questions at the end of each chapter.</p><p>This one is a must, although kind of expensive, but not so much if you compare it with a live or online course that might cost you thousands of dollars instead of a few hundred like the book.</p><p>And the book has a huge advantage compared to a course: you can resell the book to somebody else and recover most of the investment you made or you can even buy a used copy from someone and save a buck.</p><h3>Exam simulator</h3><p>I did the exam back in 2018 and the simulator I used is no longer available, so I won’t recommend any specific simulator because I only recommend things I have used and can guarantee they actually work.</p><p>You can search for a "PMP exam simulator" on the internet and find lots of them.</p><p>Look for reviews to find a good one, these might be pricey, but they are worth it if you want to pass the exam.</p><p>A good simulator should allow you to practice questions by specific areas, so you can focus on one at a time when studying.</p><p>And, of course, they must have a good enough amount of questions so you can practice at least 2 complete exams, similar to the one you are actually going to take on the test day.</p><h2>How to study</h2><p>You might not be able to take the exam in 2 months and that’s ok! Actually, most people take between 3 and 6 months of study before taking the exam.</p><p>I will describe the process I used to study, each person has a rhythm and different constraints in life, so adapt this to a schedule you can actually keep.</p><p>1 – Read Rita’s book in parallel with the PMBoK, then answer the questions at the end of each chapter of Rita’s book.<br> 2 – Once a week, at least, answer questions on the exam simulator by area. Do not attempt to mix questions of many areas at first, let each one sink in.<br> 3 – Review the areas in which you are not scoring well in the simulator. You don’t need a perfect score and a good simulator will tell you where you should focus to get better.<br> 4 – Repeat steps 1,2, and 3 until you finish all the chapters in Rita’s book.<br> 5 – As soon as you feel comfortable, try as many complete exams simulator as you can, I would say something between 2 and 4 are enough.</p><p>I did 2 complete exams, on two different days, a week before the test.</p><p>You mustn’t let anyone distract you, lock yourself in a room and simulate the environment of the test so you get a feel of how to behave on the test day and how to manage your time appropriately.</p><h2>The exam day</h2><p>If you followed all steps described before and had good scores on the simulator, don’t worry, you are good to go!</p><p>Just one last tip: don’t get stuck on a question.</p><p>The exam is 4 hours long and has 200 questions, this means you have, on average 1.2 minutes per question!</p><p>Some questions will feel easier, some will feel harder, that’s normal, no one has all the answers, if you feel stuck on one question mark it for later and review it at the end if you have some time left.</p><p>Prepare well, keep calm, and good luck!</p></div></div>]]>
            </description>
            <link>https://renanmf.com/how-i-became-a-certified-project-management-professional-pmp-by-the-pmi-in-2-months/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903788</guid>
            <pubDate>Tue, 27 Oct 2020 01:55:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quefrency Split Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24903724">thread link</a>) | @hanklazard
<br/>
October 26, 2020 | https://keeb.io/collections/split-keyboard-parts/products/quefrency-rev-2-60-65-split-staggered | <a href="https://web.archive.org/web/*/https://keeb.io/collections/split-keyboard-parts/products/quefrency-rev-2-60-65-split-staggered">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://keeb.io/collections/split-keyboard-parts/products/quefrency-rev-2-60-65-split-staggered</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903724</guid>
            <pubDate>Tue, 27 Oct 2020 01:44:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Internet is Wonderland (and we are no Alice)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24903270">thread link</a>) | @mrkn1
<br/>
October 26, 2020 | https://plumebio.com/blog/ | <a href="https://web.archive.org/web/*/https://plumebio.com/blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Online discourse has recently been borrowing vocabulary from Lewis Carroll. From articles about the dangers 
of 
rabbit holes on social media, Youtube and Reddit, to QAnon's "follow the white rabbit" mantra, concepts from 
Alice's Wonderland seem to fit naturally with the internet.</p>
<p>In Lewis Carroll's book, Alice and the white rabbit are the only two characters that transition from reality 
to 
Wonderland. The white rabbit is driven by anxiety. Alice by curiosity. We are motivated to access 
the internet for these same reasons. Our curiosity is never satiated with endless content and powerful 
recommender systems. Our anxiety is consistently triggered by the fear of missing out and the need to escape 
reality.</p>
<p>Like Wonderland, the internet has become an alternate reality thanks to the breath of the content available 
and its multimedia nature. Wonderland resembled reality enough that Alice accepted it as real. The internet's 
information is realistic enough that people struggle to know what is real and what is fake.</p>
<p>As distorted realities, both the internet and Wonderland are strange and entertaining. But they are a 
dangerous type of fantasy that discourages us from returning to reality, and attemps to transform us into one of its 
cartoon characters.</p>
<p>Alice navigated Wonderland safely, staying true to herself. Her principles can help us remain active 
internet users, instead of being used by the internet. Keep an open mind, but remain logical. Think 
critically, through questions. Stay curious, with purpose.</p>
<p><i>Last updated: October 26, 2020</i>
</p></div></div>]]>
            </description>
            <link>https://plumebio.com/blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903270</guid>
            <pubDate>Tue, 27 Oct 2020 00:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The expensive lessons learned from a toxic business partnership]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24903267">thread link</a>) | @Nomlab
<br/>
October 26, 2020 | https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership | <a href="https://web.archive.org/web/*/https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Choosing a business partner could be the second most important relationship you ever choose, (the first being who you marry).&nbsp;<br></p><p>To be honest, if you don’t handle it right, ending a business partnership can be more challenging and more expensive than a divorce.&nbsp;<br></p><p>Having done both, trust me I know.&nbsp;<br></p><p>Now 5 years later -- after our “divorce” -- I want to share a little of my story and many of the things I wish I had known to discuss from the beginning.<br></p><p>The truth was I didn’t know what I didn’t know. Now I realize that if we had some hard conversations earlier, we may have had a smoother time ending the partnership.<br></p><p><strong>In this post I’ll share:</strong></p><ul role="list"><li><strong>how things went for me; the ‘A’ years</strong></li><li><strong>how to decide if you need a partner</strong></li><li><strong>qualities you should look for <em>(and what to avoid)</em></strong></li><li><strong>how do you split equity</strong></li><li><strong>the operating agreement; some key things you’ll want in there</strong></li><li><strong>buy/sell agreement</strong></li><li><strong>business partner checklist (a to-do list for following everything in this post)</strong></li><li><strong>other tips from my trauma <em>(lol… but really</em></strong><em>)</em><strong><em>‍</em></strong></li></ul><h3><strong>my story</strong><a href="https://littlemight.com/#"><br></a></h3><p>I started <a href="https://lttlmg.ht/bestself" target="_blank">BestSelf</a>, with my business partner (who I will refer to as 'A') in mid-2015, around 18-months after we initially met. </p><p>In that time we'd hung out in person around 4-5 times. To continue the analogy of business partnership being like marriage, I'd married someone that I'd only been on a few dates with and barely knew. I partnered out of insecurity with someone who talked a good game and seemed strong in the areas I felt weak.This insecurity cost me $$$</p><figure id="w-node-76af6d16a676-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f8750eb6f143d07b654067a_partnership-2.jpg" loading="lazy" alt=""></p></figure><p>We met through an entrepreneurship course online and became accountability partners soon after. With him being in New Jersey and me in NYC, we were close enough to be able to meet in person once every few months.&nbsp;<br></p><p>Through being accountability partners we became aware of each other's strengths and complementary skill sets, him with marketing and me with product design and branding.<br></p><p>As background, before <a href="https://lttlmg.ht/bestself">BestSelf</a> was born I had another Shopify store selling graphic design products that was paying all my bills and generating a good living. I considered that business my ‘Freedom vehicle’ as it allowed me to quit my Architecture job but I wasn’t passionate about doing it long-term.<br></p><p>I <em>was</em> deeply passionate about personal development during this time and was always reading and finding ways to upgrade my skills and productivity. I felt like I’d found the cheat code to life and wished I’d been introduced to it sooner. Before I quit my architecture job, I set myself a task to <a href="https://littlemight.com/articles/the-22-books-that-helped-me-quit-my-job" target="_blank">read 22 books around specific topics so I would be ready for the world of entrepreneurship.</a><br></p><p>The <a href="https://lttlmg.ht/journal" target="_blank">Self Journal</a> was later born from my personal struggle for years of finding a planner that would both keep me organized and also help me reach my most important goals.<br></p><p>I decided I wanted to turn the journal I built for myself into a product to sell, because it seemed whenever I showed it to someone they wanted to buy it.&nbsp; I didn’t think this product would be the start of something bigger, I just wanted to bring this product to life.</p><p>It was then I thought having someone who knew sales and marketing would be beneficial so I asked ‘A’ to partner with me on it. He also had his own journaling structure&nbsp; so I felt it was a common interest.<br></p><p><strong>In retrospect, I partnered out of my insecurities around marketing and selling myself. </strong></p><h6>Most entrepreneurs don't have business problems, they have emotional problems disguised as business problems —<strong> and so I disguised my fear of putting myself out there with a business partner.&nbsp;</strong><br></h6><p>And so it began.<br></p><p>The original name we came up with for the company was “Self Improvement Labs”... but I <em>hated</em> it. One weekend when ‘A’ was gone I knew I had to come up with something better to replace it with<em>.</em></p><p><em>(because I don’t like when people criticize something without giving a reasonable alternative).</em><br></p><p>In those 2 days I came up with the idea for <a href="https://lttlmg.ht/bestself">BestSelf</a>, bought the domain BestSelf.co and created a whole branding package. Thankfully there was no pushback, ‘A’ agreed it was a better name and we moved forward.<br></p><p>We launched the Kickstarter campaign in August 2015. I had experience with launching Kickstarter campaigns in the past and so I had a formula for how to do it which helped us a lot. You can read how we did it <a href="https://littlemight.com/articles/kickstarter-step-by-step" target="_blank">here</a>.<br></p><p><strong>We funded in 28 hours and over the course of 34 days we raised over $322,000 which was enough to both create the product for backers and launch the entire business.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5ea0cb1d0f854b10467cf739_5e2a2251be4a7438101d60a6_image.png" alt="funding progress graph"></p></figure><p>We launched our online store in January 2016 and the business continued to grow. We won the <a href="https://littlemight.com/articles/shopify-2016-build-a-business-experience" target="_blank">2016 Shopify Build a Business award</a> in August of 2016 and then in 2017 we scaled 4X and won the Build a BIGGER Business Award.</p><figure id="w-node-ac6b3b3d99ee-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f857aa10221b7fa4725f1a6_image5.png" loading="lazy" alt=""></p></figure><figure id="w-node-9ccd9ba5eca2-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f857aae7da8462c3bf9000a_image1.png" loading="lazy" alt=""></p></figure><p>When things are going so well business-wise it’s easy for things to run smoothly, it’s like the early dating phase when you don’t have to deal with too much harsh reality yet. Then the pandemic starts and you find out what your relationship is really made of.<br></p><p>By late 2016, while professionally things were still good with the business, cracks began appearing in our personal relationship… the 2016 election was a definite factor here. That was the first time it became clear how differently we saw the world and how opposite our backgrounds were.<br></p><p>In 2017, we’d hired out the majority of his role in marketing and by April 2018 he had stepped away from all business operations - informally anyway.&nbsp;<br></p><p>By informally I mean there was never a discussion of him passing the baton and stepping out, he just suddenly was no longer there. But he was still taking as much money out of the company as I was -- or more.<br></p><p><strong>As you can imagine being a 50/50 partner where one partner is working full-time and the other is completely disconnected is tough — really tough. I was essentially hamstrung on big decisions and company direction. </strong></p><p>And anything I could decide could be overwritten or debated even after I thought it was settled. The same went for team members, as every now and again he'd jump on calls, start giving advice or instruction (without knowing what was even happening) and cause frustration and confusion with team members. </p><p>By early 2019, I was becoming resentful as our distributions were still 50/50 <strong>but I wasn’t getting any salary for the 60+ hour weeks of time I was putting in. </strong>When I brought it up to him, as if he were my boss, he would say <em>“I don’t equate time with value,”</em> yet he wasn’t giving either to the company.<br></p><p>At the same time as he would reject my salary request, he’d post stuff like this on his Instagram:</p><figure id="w-node-be8cd5eaae18-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f873b98bd121731d6cf0d21_3-hour-week.jpg" loading="lazy" alt=""></p></figure><h6>Here's a tip, if someone’s telling you running a business is easy — they’re either lying, or trying to <strong>sell</strong> you something.<br></h6><p>In the case of ‘A’, it was both.<br></p><p>Each video “guru” post he’d share taking credit for work that wasn’t his &nbsp;felt like a slap in the face — not just to me but,&nbsp; more importantly, to the team. <strong>Being under-paid (or not paid at all) is one thing, but having my value be dismissed on top of that was actually the bigger issue -- and was the beginning of the end.</strong><br></p><p>I ended up removing him on all social media platforms in mid 2019 because posts like the one above were triggering me.<br></p><p>By July 2019, we finally agreed on a modest salary for me in lieu of taking distributions which I would be made up for later. This still meant that I was getting the same $ amount or less per month as he was but at least now I had an IOU.&nbsp;<br></p><p><em>(I did this as I didn’t want to take more cash out of the business that would negatively impact our growth.)</em><br></p><p>Yay, a salary! <strong>I was now the 3rd highest paid person on my team of 10</strong> -- and getting the same as the person that had done nothing for the company in more than a year.<br></p><figure id="w-node-cc78a0f0c1db-3448d0da"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f86195162505211420ac4da_Image%202.JPG" loading="lazy" alt=""></p></figure><p>By the end of 2019, other things happened that I won’t go into. Suffice to say, I was mentally exhausted and felt completely taken advantage of by someone I had trusted.&nbsp;<br></p><p>So we looked for options to get out...either of the business, or at least the partnership.<br></p><p>When numbers around buyout expectations came up, there was a chasm of difference between what ‘A’ felt he deserved and what was realistic -- especially given how much he’d already taken over the last 18 months without working ($400k+).&nbsp;<br></p><p>Taking on investors or another partner seemed like the only option. However, by that point, I had no interest in bringing in someone that may have me ending up in the same place.<br></p><p><strong>Better the devil you know...</strong><br></p><p>Going into 2020 I felt stuck between a rock and a hard place.&nbsp;<br></p><p>On one hand I wanted to grow the business, innovate with new products and keep my team charged. Yet, on the other hand, I knew doing so would mean eventually paying him more in a buyout situation.<br></p><p>Every year I do a yearly review to reflect on the prior year and to set some big goals for the new year. Maybe you’ve seen them. Good, bad and mixed… I've shared my review publicly in <a href="https://littlemight.com/articles/2014-review" target="_blank">2014</a>, <a href="https://littlemight.com/articles/2015-review" target="_blank">2015</a>, <a href="https://littlemight.com/articles/2016-review" target="_blank">2016</a>, <a href="https://littlemight.com/articles/2017-review" target="_blank">2017</a>, <a href="https://littlemight.com/articles/2018-review" target="_blank">2018</a>... right up until this year.<br></p><p><strong>This year I couldn't bring myself to share my review and big goal <em>publicly</em>.</strong><br></p><p><em>(It seems funny now given the dumpster fire that 2020 has been that I just knew putting plans out there might not be the best idea.)</em><br></p><p>The thing I was scared to share publicly was that <strong>my biggest goal for 2020 was to end my business partnership with ‘A’ once and for all.</strong><br></p><p>Between COVID affecting business and other extenuating factors, we could finally agree on a reasonable buyout number in August 2020 -- after over 7 months of negotiation. While it had me taking on a significant amount of personal debt, I was happy to do so because I believe so strongly BestSelf -- and in my incredible team.<br></p><p>As of September 24th 2020 I’m officially 100% owner in <a href="https://lttlmg.ht/bestself" target="_blank">BestSelf</a> - <a href="https://www.instagram.com/p/CFr72LMHSIk/?utm_source=ig_web_copy_link" target="_blank"><strong>official announcement here</strong></a><strong>.</strong><br></p><h6><strong>To say I was excited would be an understatement 🙌🏻</strong></h6><figure id="w-node-8453fbbbca5b-3448d0da"><a href="http://instagram.com/cathryn.lavery" target="_blank"><p><img src="https://uploads-ssl.webflow.com/5ea0c87d3db0d2d23479ff47/5f861a99397936d25e6798ea_giphy%20(9).gif" loading="lazy" alt=""></p></a><figcaption>yay!</figcaption></figure><h3>‍<strong>what I would do differently</strong><br></h3><p>I don’t believe in regrets or wishing things were different - everything worked out as it was meant to and this was a huge learning experience for me.&nbsp;<br></p><blockquote><em>“Don’t wish it was easier, wish you were better”</em> - Jim Rohn</blockquote><p>This famous Jim Rohn quote perfectly fits here, this whole experience taught me a lot about myself and what I’m capable of.&nbsp;<br></p><p>That said… I learned some big lessons that would make me approach any future partnership extremely differently. And I want to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership">https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership</a></em></p>]]>
            </description>
            <link>https://www.littlemight.com/articles/expensive-lessons-learned-from-a-toxic-business-partnership</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903267</guid>
            <pubDate>Tue, 27 Oct 2020 00:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TypeScript Hack – Type System Adventure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24903099">thread link</a>) | @ricksharp
<br/>
October 26, 2020 | https://ricklove.me/typescript-type-system-adventure | <a href="https://web.archive.org/web/*/https://ricklove.me/typescript-type-system-adventure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><span>title</span><span>Typescript Type System Adventure</span></span><span><span>date</span><span>2020-10-24</span></span><span><span>path</span><span>/typescript-type-system-adventure</span></span><span><span>author</span><span>Rick Love</span></span><span><span>excerpt</span><span>Text Adventure implemented in the Typescript Type System and Vscode JsDoc Viewer</span></span><span><span>image</span><span>game-screenshot-06-large.png</span></span></p><div><div><div><p>tl;dr: Play a text adventure in vscode with the typescript type system.</p><h3>Update - Added Typescript 4.1 Template String Literals</h3><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/typescript-4-1-features.png"></p><ul><li><a href="https://github.com/ricklove/rick-love-master/blob/70644a0f6cebf48132fc029e484e6f8db9e3fc19/code/typescript-type-system-adventure/game-type-system.ts#L123">https://github.com/ricklove/rick-love-master/blob/70644a0f6cebf48132fc029e484e6f8db9e3fc19/code/typescript-type-system-adventure/game-type-system.ts#L123</a></li></ul><h3>Summary</h3><p>I've always been a fan of text adventures since I first played Space Quest 1 when I was about 6 (though it was a graphical text adventure technically).</p><p>I've also always been a huge fan of typescript since it came out in 2012.</p><p>Now, since Typescript 4.1 is adding the powerful template-literal-types, I figured I could do something fun with them.</p><p>(I got the idea from here: <a href="https://github.com/codemix/ts-sql">https://github.com/codemix/ts-sql</a>)</p><p>It occured to me, "Hey! Why not a text adventure!"</p><p>Now, it turns out that the way I implemented this game, I don't need the 4.1 features. I'll probably add that in the future to support more dynamic command parsing.</p><p>If you have <code>vscode</code>, you can play now with a quick <code>npm install</code> into any node project. (See below for full installation instructions.)</p><h3>So What?</h3><p>This is a level 99 typescript wizardry demo. </p><p>If you aren't a typescript nerd, you might miss the significance of this, but here is the basic idea:</p><p>First of all, everything you see here is running in the vscode code editor (without any program running). In fact, you can't even run my code. If you compile it to javascript, this is what you will get:</p><div><div><div><div><pre><code><span>export</span> <span>const</span> gameStart = <span>null</span>;</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><p>(There might be a little more debris then that, but you get the idea.)</p><p>This screenshot should make it clear that the typescript type system is doing all the work:</p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></p><p>However, it's not very convenient to declare all those StepNN types, so I made a fluent mode that reduces the need for those:</p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></p><p>There is also an easy mode that uses only an object tree. It was very easy to make, but autocomplete ruins the fun by giving all the answers away. </p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></p><p>In the process of making the game, I discoved that vscode supports jsdoc markdown. So I decided to use that for the game output since it is so rich. It even supports images:</p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></p><h3>Features</h3><ul><li>Play in vscode using autocomplete and tooltips</li><li>Game output displayed in tooltips using jsdoc3 with markdown (including gifs)</li><li>Implemented using conditional types, string literals, and a minimal state machine</li></ul><h3>How to play</h3><ul><li><code>npm i @ricklove/typescript-type-system-adventure</code></li><li>Create a new <code>play.ts</code> file and add the below code</li><li>Hover over <code>execute</code> to see game output (see screenshots for examples)</li></ul><div><div><div><div><pre><code><span>import</span> { gameStart } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> play = <span><span>()</span> =&gt;</span> {

    <span>return</span> gameStart
        .command(<span>'look'</span>).execute
};</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><h3>Tips:</h3><ul><li><code>.command('look').execute</code> will give you an idea of what to do next</li><li><code>.command('help').execute</code> if you get stuck</li><li>If you really get stuck, just hit F12 and read the source code</li><li>You can also play the easy mode with this starter:</li></ul><div><div><div><div><pre><code><span>import</span> { gameStartEasy } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> playEasyMode = <span><span>()</span> =&gt;</span> {
    gameStartEasy
        .begin()
        .look()
};</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><h3>Screenshots</h3><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-02.png"></p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></p><p><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-06-large.png"></p><h3>Source Code</h3><p><a href="https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure">https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure</a></p></div></div></div></div>]]>
            </description>
            <link>https://ricklove.me/typescript-type-system-adventure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903099</guid>
            <pubDate>Tue, 27 Oct 2020 00:06:44 GMT</pubDate>
        </item>
    </channel>
</rss>
