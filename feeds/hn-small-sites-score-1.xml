<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 04 Oct 2020 12:32:08 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 04 Oct 2020 12:32:08 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661395">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas’ excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod’s lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet’s behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust’s type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana’s goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661395</guid>
            <pubDate>Fri, 02 Oct 2020 11:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Euro [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661368">thread link</a>) | @user1241320
<br/>
October 2, 2020 | https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661368</guid>
            <pubDate>Fri, 02 Oct 2020 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Privacy Is the Most Important Concept of Our Time]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual as partial and limiting. It could be because privacy, as <a href="https://en.wikipedia.org/wiki/Privacy">it is intended nowadays, originated from the Anglo-American world (that is what Wikipedia says</a>). </p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let’s not talk about privacy, instead let’s talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the properties of any version of the concept of privacy you might have. Take this as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is about boundaries.</strong> <strong>It is not about hiding something from someone but allowing to create a space with rules</strong> <strong>decided by its members</strong>. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by the ancient petty Greek gods. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that leaders wanted to make war all the time, they needed to do so because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also rightly pick a different king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is that without clear rules on what is private and what is public, nobody knows which stuff belongs to whom and this means that all belong to the strongest. <strong>Somebody might say that what you do in private, it is not private at all but political, it concerns the society at large. Therefore it must be regulated according to their rules</strong>.</p>



<p><strong>Privacy is about control</strong>. <strong>Without privacy we cannot decide for ourselves how to live our lives.</strong> If there is no privacy all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. When I was a child I would sometimes say and think that I wanted to kill my brother. I did not meant literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a <a href="https://en.wikipedia.org/wiki/Threat">threat</a>.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases is relative. When we speak in public, we share a different context, therefore our words have a different meaning.</p>



<p>So even I say something as an hyperbole or as an potentially implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but <em>how can they be sure of it</em>? <strong>They do not know me.</strong> <strong>And it is true that acts of violence are prepared by violent words</strong>. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimate to take your land and kingdom.</p>



<p>A clear example of the loss of privacy is the <em>rise of violent rhetoric</em>. Everybody swears and everybody threaten. However, for the most part they do not mean it. We know that because the actual rate of violence has not risen. We simply talk in public as we talk in private, because our private lives have become more public. I mean, some bosses want even to look at your Facebook profile<sup><a href="#note_2">2</a></sup><a id="link_2" href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/note_2">.</a></p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it allows to define everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules, even the whims, of somebody else.</strong></p>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the whole matter. At a first glance the first issue should not matter here, because we are talking about privacy. However, this is a bit more complicated. Violations of privacy can affect other rights and freedom. Freedom of speech is a right regarding the public sphere. You have always been able to say everything in private, for the simple fact that people cannot control that. If now the private becomes public, then either we get absolute freedom of speech (a sort of <em>speech anarchy</em>, if you will) or we lose freedom of speech.</p>



<p>Okay, then we demand to not violate privacy even in the case of bad speech. If you said something bad in private then I cannot demand your boss to fire you. I cannot do that even by maintaining privacy: <em>trust me on this, they say something really bad</em>,<em> you should fire them</em>. This is a practical example of how privacy might affect everything.</p>



<p>This is crucial, but we have to understand that simply enforcing privacy in the traditional way is not enough anymore. To protect privacy we need to re-interpret some rights we have. For instance, traditionally there have been exceptions to privacy for public interest. If you heard somebody famous saying something controversial in private you could go public about. The issue is that few people (i.e., the press) had that power. Now we all have it. <strong>So, to defend privacy we need to accept shared norms of behavior</strong>. We cannot expect consequences outside the context that caused them.</p>



<p>This is hard to do, because people have different idea of public interest. It is not true that we judge other by their actions. We judge others by <em>our intentions</em>. So, we must be strict about the norm that the answer to some speech should be only some other form speech. In other words, if somebody offended you with some method, you should respond with the same method. If somebody said something bad, you cannot shove them. <strong>Actions by a mob in order to punish an alleged transgressor, punish a convicted transgressor, or intimidate them is not an answer to a bad argument, it is a<a href="https://en.wikipedia.org/wiki/Lynching"> lynching</a></strong>.</p>



<p>There is a difference between killing somebody and just ruining their lives. However, it is still bad. It is still lynching, something we do to one to control one hundred. Making somebody lose their livelihood because of something said in private it is not fair, because they said in a different context. They were not prepared to be judged by their worst enemies. And they should not have. </p>



<p>The philosopher Jeremy Bentham described the perfect prison as the <a href="https://en.wikipedia.org/wiki/Panopticon">Panopticon</a>. A prison where in every cell there was a one-way mirror. This way the guards could watch the inmates without being seen. Therefore the inmates would have to behave as if they were always watched. That kind of sounds like the world right now. And I am ready to lose the power to punish bad people in order to protect me from people that think I am a bad guy.</p>



<p><em>Given the discussion on Hacker News, I think that I was a bit unclear here. The connection between privacy and freedom of speech is just an example. My point is that privacy affects how we enjoy other rights, too. Even though that might not seem obvious at first.  </em></p>



<div><h2>What Should We Do?</h2><p>A modest proposal</p></div>







<p>So what has to be done to defend privacy? <strong>There should be clear boundaries about private, social and public spaces</strong>:</p>



<ul><li>a private space regards only you or your family</li><li>a social space is something involving a community, either a virtual one like a forum or a real one like a city</li><li>a public space is a space for all actors of society</li></ul>



<p>By clear boundaries I mean that we should create rules, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare – two years later]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coding Graphical UIs with React and SVG Part 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661031">thread link</a>) | @moonpool
<br/>
October 2, 2020 | https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations | <a href="https://web.archive.org/web/*/https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this mini-series we’re looking at rendering interactive graphical UI’s using components built with React and SVG.</p><p>In <a href="https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-1-declarative-graphics" rel="noopener">part 1</a>, Declarative Graphics, we used React to compose simple graphical components from declarative SVG primitives, and covered the basics of the viewBox and the viewport.</p><p>Throughout the series we’ll be putting together an interactive floor-plan. In this, part 2, we’re going to add security cameras to the plan and show their field of view, giving us the opportunity to explore arcs, angles, and transformations, along with a useful little digression into alternative coordinate systems.</p><p>Let’s start by creating a simple <code>Camera</code> component that we can place inside any <code>Room</code> at a position and orientation we specify. The basic camera will look like this:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-16.31.52.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-2020-07-24-16.31.52.png 600w, https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-16.31.52.png 1000w" sizes="(min-width: 720px) 720px"><figcaption>How we'd like our camera component to look (zoomed in for clarity)</figcaption></figure><p>Our camera shape is straight-forward, and can be composed as a path with 8 straight-line segments joining up 8 coordinates. SVG <code>path</code> elements are powerful tools that create shapes from lines, curves, and arcs and can be stroked and filled just like <code>circle</code> and <code>rect</code>.</p><p>Our initial use of path is relatively simple and consists of simple straight line segments using the <code>L</code> command to join up the 8 coordinates of our camera, marked below with black circles.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-17.36.52.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-2020-07-24-17.36.52.png 600w, https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-17.36.52.png 800w" sizes="(min-width: 720px) 720px"></figure><p>We’ll make it easy on ourselves by using single digits of a 4x4 square, so our path is easy to create. The path element takes its path data in a <code>d</code> attribute <code>&lt;path d={``}/&gt;</code>.</p><p>We begin by telling it to “move” to the coordinate of the first black circle at (0,0), then proceed to draw lines to each of the other absolute coordinates. The final segment is drawn automatically when we “close” the path with <code>Z</code>.</p><pre><code>&lt;path 
  d={`M0,0 L4,0 L3,1 L4,1 L4,4 L0,4 L0,1 L1,1 Z`}
  fill="black"
/&gt;</code></pre><h3 id="relatively-simple">Relatively Simple</h3><p>Path commands such as <code>L</code> can be absolute or relative, designated by upper or lower case respectively, so an alternative way to write the same camera path is to use relative coordinates, like so:</p><pre><code>&lt;path
  d={`M0,0 l4,0 l-1,1 l1,0 l0,3 l-4,0 l0,-3 l1,0 Z`}
  fill="black"
/&gt;</code></pre><p>Alternatively, a convenient shortcut when drawing lines which are perfectly vertical or horizontal is to use <code>V</code> or <code>H</code> with absolute coords, or <code>v</code> and <code>h</code> with relative coords, yielding yet another alternative way of drawing the same path:</p><pre><code>&lt;path
  d={`M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
  fill="black"
/&gt;</code></pre><h2 id="everything-in-its-place">Everything in its place</h2><p>That’s great, we have a nice camera shape, but there’s a problem: we’ve drawn it with the top corner of the camera at the origin of our user-space. How can we place it at a specific location in our user-space? And what if we want to draw more than one Camera at different locations?</p><p>One simple option might be to use string interpolation to set the initial position <code>Mx,y</code> to something other than <code>0,0</code>.</p><pre><code>const Camera = ({x, y}) =&gt; (
  &lt;path
    d={`M${x},${y} h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
    fill="black"
  /&gt;
);</code></pre><p>OK, that works, but the camera is not positioned <em>quite</em> where we want it — we probably meant that x,y is the centre of the camera, so we need to offset it by -50% on each axis. We know that the camera is 4 user-space units wide and 4 units high, so the maths is easy:</p><pre><code>const Camera = ({x, y}) =&gt; (
  &lt;path
    d={`M${x-2},${y-2} h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
    fill="black"
  /&gt;
);</code></pre><p>This is reasonably straight-forward, and because we used relative coords to define the path we only had to do any math for the initial move <code>M</code> operation. However, there’s an alternative way of positioning things without tinkering with the path, which also opens up some exciting new opportunities…</p><h3 id="simply-transformational">Simply Transformational</h3><p>Shifting the camera to centre it on the given coordinates involved a reasonably simple change to the path, but things would rapidly get out of hand if we want to, say, rotate the camera by 45 degrees using this approach.</p><p>Instead, what if we could design our camera for the simple case of being drawn at the origin and pointing straight upwards, and then apply transformations to position and rotate it as required, avoiding any complicated maths?</p><p>In fact we can do just that using the <code>transform</code> attribute, which takes a list of transformation operations and applies them in order. Valid transform operations are:</p><ul><li><code>translate</code> — move horizontally and vertically</li><li><code>rotate</code></li><li><code>scale</code></li><li>skew (<code>skewX</code> and <code>skewY</code>)</li><li><code>matrix</code> (a mathematical expression that consolidates all of the above)</li></ul><p>We can specify a list of these operations in a single transform string like this:</p><pre><code>transform="translate(20,30) rotate(45) scale(10)"</code></pre><p>Recall from part 1 that the initial “user-space” specified by the viewBox is the coordinate system in which our SVG primitives are drawn.</p><p>By providing a transform attribute with a transform list we are creating a <em>new, nested user-space</em> — a new coordinate system in which the attributed element is drawn.</p><p>When applied to a simple element such as a <code>circle</code>, <code>rect</code>, <code>path</code>, etc., the new user-space only applies to that element. However, we can also set a transform on a group <code>&lt;g&gt;</code> element, in which case all elements nested within that group are also drawn in the user-space of the transformed <code>g</code> element.</p><p>With this in mind, we can now declare our Camera component such that it can be easily positioned and rotated:</p><pre><code>const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;
    &lt;path
      transform="translate(-2, -2)"
      d="M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z"
      fill="#000"
    /&gt;
  &lt;/g&gt;
);</code></pre><p>This is great — the code that describes the camera’s shape is now entirely static and distinct from the code that positions and orients the camera. We can make this more explicit by extracting a component for drawing the camera body:</p><pre><code>const CameraBody = () =&gt; (  
  &lt;path
    transform="translate(-2, -2)"
    d="M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z"
    fill="#000"
  /&gt;
);

const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;
    &lt;CameraBody /&gt;
  &lt;/g&gt;
);</code></pre><h3 id="adding-contrast">Adding Contrast</h3><p>The camera is quite a dark shape against the dark blue background of our floor-plan, so to increase contrast lets give it a semi-transparent circular “enclosure” that lightens the background.</p><p>Because this enclosure is nested inside our camera’s group <code>&lt;g&gt;</code> element it exists within the camera’s user-space, which means we can simply draw it at the origin and it will move and rotate with the camera — result!</p><p>Note that we draw the enclosure first, before drawing the camera body, so that the camera body appears on top of the enclosure (on the z axis) and does not get lightened by it.</p><pre><code>const CameraEnclosure = () =&gt; (
  &lt;circle
    cx="0"
    cy="0"
    r="3.5"
    fill="rgba(255,255,255,0.25)"
    stroke="#fff"
    strokeWidth={0.25}
  /&gt;
);

const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;      
    &lt;CameraEnclosure /&gt;
    &lt;CameraBody /&gt;
  &lt;/g&gt;
);</code></pre><p>And now we can render multiple cameras in different positions and orientations and see them clearly on our blueprint backdrop:</p><pre><code>{  
  Array.from({ length: 6 }).map((_, i) =&gt; (    
    &lt;Camera
      key={`camera_${i}`}
      x={Math.round(Math.random() * 5000)}
      y={Math.round(Math.random() * 3000)}
      angle={Math.random() * 360}
    /&gt;  
  ))
}</code></pre><figure><img src="https://images.datalanguage.com/2020/10/multiple-cameras.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/multiple-cameras.png 600w, https://images.datalanguage.com/size/w1000/2020/10/multiple-cameras.png 1000w, https://images.datalanguage.com/2020/10/multiple-cameras.png 1286w" sizes="(min-width: 1200px) 1200px"><figcaption>Many instances of Camera rotated to different angles</figcaption></figure><h3 id="field-of-view">Field of View</h3><p>Before we add the cameras to our floor plan, let’s look at showing the camera’s field of view as a segment of a circle centred at the camera origin, looking like this:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-17-16-00-04.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-17-16-00-04.png 600w, https://images.datalanguage.com/size/w1000/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1000w, https://images.datalanguage.com/size/w1600/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1625w" sizes="(min-width: 1200px) 1200px"><figcaption>Camera with 40 degree Field-of-View</figcaption></figure><p>We’re not really trying to model the real world here, just keeping things reasonably simple by defining the field of view as an angle describing the arc, and a distance or range that describes how far the camera can “see”. The API for the <code>FieldOfView</code> component could then just be:</p><pre><code>&lt;FieldOfView angle={40} range={500} /&gt;</code></pre><p>Note that we don’t need to specify a position for <code>FieldOfView</code> because it will be nested inside the <code>Camera</code>’s group <code>g</code> element, and therefore drawn in the user-space of the <code>Camera</code>.</p><p>We can get a feel for how the props relate to the rendered field of view from the diagram below. Remember that the camera is drawn pointing upwards, so the mid-point of the field of view needs to be directly &nbsp;up the y-axis from the origin.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-12-25-41.png 600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41.png 793w"><figcaption>How the range and angle props relate to the rendered field of view</figcaption></figure><p>A quick and dirty approximation of the field of view would be a triangle connecting the dots A, B, and C along the dashed lines in the above diagram. We already know the position of A (the origin of our <code>Camera</code>’s user-space), so we just need to work out the positions of B and C, then this approximated path is super-easy to write.</p><p>To do that we need to put our math hats on again for some basic trigonometry, but I want to take a little diversion (<em>or a tangent, ahahaha</em>) and talk a little bit about coordinate systems.</p><p>If — unlike me — you are a bit of a math whiz, you might already be familiar with Euclidean spaces and coordinate systems, in which case feel free to skim the next section. If not, follow me down the rabbit-hole, <em>I promise its worth it!</em></p><h3 id="euclidean-coordinate-systems">Euclidean Coordinate Systems</h3><p>So far we’ve been working with the familiar <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system" rel="noopener"><em>Cartesian</em></a> coordinate system for representing points in a Euclidean space, where <code>[x,y]</code> represents a distance from the origin along the x and y axes. But this isn’t the only way to represent the same point in Euclidean space!</p><p>When working with radial UI’s (think clocks, compasses, dials, and just about anything that has symmetry around a centre), there’s an alternative coordinate representation that makes everything <em>waaay</em> simpler to visualise intuitively: a <a href="https://en.wikipedia.org/wiki/Polar_coordinate_system" rel="noopener">polar coordinate system</a>.</p><p>Using polar coordinates, the Cartesian point <code>[x, y]</code> can be expressed instead as a <em>distance</em> from the origin or “pole” and an <em>angle</em> offset from a reference angle, i.e. instead of <code>[x,y]</code> we have <code>[distance, angle]</code>.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-11-55-13.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-11-55-13.png 600w, https://images.datalanguage.com/size/w1000/2020/10/Screenshot-from-2020-09-30-11-55-13.png 1000w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-11-55-13.png 1515w" sizes="(min-width: 1200px) 1200px"><figcaption>The same point represented in Cartesian and polar coordinates</figcaption></figure><p>In polar coordinates, the positions of points B and C in our field-of-view are intuitively easy to read from the diagram:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png 600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png 793w" sizes="(min-width: 720px) 720px"><figcaption>Polar coordinates are intuitive in radial UI’s</figcaption></figure><p>Both are at a distance <code>range</code> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations">https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations</a></em></p>]]>
            </description>
            <link>https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661031</guid>
            <pubDate>Fri, 02 Oct 2020 10:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU stow to manage dotfiles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660912">thread link</a>) | @mathieuh
<br/>
October 2, 2020 | http://mathieuhendey.com/posts/stowing-dotfiles/ | <a href="https://web.archive.org/web/*/http://mathieuhendey.com/posts/stowing-dotfiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>I recently found about a piece of GNU software called Stow<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>It lets you manage your dotfiles in a really simple way, meaning you can put them in git and have them easily transferable between machines.</p>
<p>What it will do is let you move all your dotfiles into a directory, and then symlink them back into your home directory with a simple command.</p>
<p>From the man page<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<blockquote>
<p>Stow is a symlink farm manager which takes distinct sets of software and/or data located in separate
directories on the filesystem, and makes them all appear to be installed in a single directory tree.</p>
</blockquote>
<h2 id="set-up">Set up</h2>
<p>First you’ll need to install <code>Stow</code> using your package manager of choice. I use a Mac so it’s just:</p>
<p>Then you’ll need to create a directory in which to store your dotfiles, and directories within it to keep them separate.</p>
<div><pre><code data-lang="sh">mkdir ~/dotfiles;
mkdir ~/dotfiles/git;
mkdir ~/dotfiles/zsh;
</code></pre></div><p>Move your dotfiles into the relevant directories:</p>
<div><pre><code data-lang="sh">mv ~/.gitconfig ~/dotfiles/git;
mv ~/.zshrc ~/dotfiles/zsh;
mv ~/.zshenv ~/dotfiles/zsh;
</code></pre></div><h2 id="the-magic-part">The magic part</h2>
<p>Now here’s where <code>stow</code> comes in. Stow will, given a source directory and a destination directory, create symlinks in the destination directory to all the files in the source directory.</p>
<p>From within <code>~/dotfiles</code></p>
<p>Here’s an explanation of what that command is doing:</p>
<ol>
<li>
<p><code>-R</code> means “restow”. This will overwrite your symlinks, say if you’ve updated your dotfiles on another machine and want to sync them to your current machine From the manpage:</p>
<blockquote>
<p>Restow packages (first unstow, then stow again). This is useful for pruning obsolete symlinks
from the target tree after updating the software in a package.</p>
</blockquote>
</li>
<li>
<p><code>-t ~</code> is the target directory. This is where the symlinks will be created.</p>
</li>
<li>
<p>The final argument is the directory containing the files to be symlinked to.</p>
</li>
</ol>
<p>Putting it all together, running <code>stow -R -t ~ git</code> will create a symlink in your home directory to <code>~/dotfiles/git/.gitconfig</code>.</p>
<p>And it’s that simple.</p>
<p>Now you can <code>git init</code> inside your <code>~/dotfiles</code> directory, push them up to your remote and have them immediately available on all your machines.</p>
<p>Here’s a simple bit of bash that will stow all the dotfiles in your home directory from your <code>~/dotfiles</code> repo:</p>
<div><pre><code data-lang="sh"><span>for</span> d in */ ; <span>do</span>
    stow -R -t ~ <span>"</span>$d<span>"</span>
<span>done</span>
</code></pre></div><p>For reference, <a href="https://github.com/mathieuhendey/dotfiles">here are my dotfiles on GitHub</a>.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.gnu.org/software/stow/">https://www.gnu.org/software/stow/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://linux.die.net/man/8/stow">https://linux.die.net/man/8/stow</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    </div></div>]]>
            </description>
            <link>http://mathieuhendey.com/posts/stowing-dotfiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660912</guid>
            <pubDate>Fri, 02 Oct 2020 10:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting EBU R128 audio loudness analysis from C to Rust – Porting Details]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660868">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/ | <a href="https://web.archive.org/web/*/https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-833">
	
	<!-- .entry-header -->

	<div>
		<p>This blog post is part two of a four part series</p>
<ol>
<li><a href="https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust/">Overview, summary and motivation</a></li>
<li><strong>Porting approach with various details, examples and problems I ran into along the way</strong></li>
<li>Performance optimizations</li>
<li>Building Rust code into a C library as drop-in replacement</li>
</ol>
<p>In this part I’ll go through the actual porting process of the <a href="https://github.com/jiixyj/libebur128">libebur128</a> C code to <a href="https://www.rust-lang.org/">Rust</a>, the approach I’ve chosen with various examples and a few problems I was running into.</p>
<p>It will be rather technical. I won’t explain details about how the C code works but will only focus on the aspects that are relevant for porting to Rust, otherwise this blog post would become even longer than it already is.</p>


<h2>Porting</h2>
<p>With the warnings out of the way, let’s get started. As a reminder, the code can be found on <a href="https://github.com/sdroege/ebur128/">GitHub</a> and you can also follow along the actual chronological porting process by going through the git history there. It’s not very different to what will follow here but just in case you prefer looking at diffs instead.</p>
<h3><span id="Approach">Approach</span></h3>
<p>The approach I’ve taken is basically the same that <a href="https://people.gnome.org/~federico/blog/librsvg-posts.html">Federico</a> took for <a href="https://gitlab.gnome.org/GNOME/librsvg">librsvg</a> or <a href="https://jneem.github.io/nnnoiseless/">Joe Neeman’s</a> took for <code>nnnoiseless</code>:</p>
<ol>
<li>Start with the C code and safe Rust bindings around the C API</li>
<li>Look for a function or component very low in the call graph without dependencies on (too much) other C code</li>
<li>Rewrite that code in Rust and add an internal C API for it</li>
<li>Call the new internal C API for that new Rust code from the C code and get rid of the C implementation of the component</li>
<li>Make sure the tests are still passing</li>
<li>Go to 2. and repeat</li>
</ol>
<p>Compared to what I did when <a href="https://coaxion.net/blog/2020/07/live-loudness-normalization-in-gstreamer-experiences-with-porting-a-c-audio-filter-to-rust/">porting</a> the FFmpeg loudness normalization filter this has the advantage that at every step there is a working version of the code and you don’t only notice at the very end that somewhere along the way you made a mistake. At each step you can validate that what you did was correct and the amount of code to debug if something went wrong is limited.</p>
<p>Thanks to Rust having a good <a href="https://doc.rust-lang.org/nomicon/ffi.html">FFI</a> story for interoperability with C in either direction, writing the parts of the code that are called from C or calling into C is not that much of a headache and not worse than actually writing C.</p>
<h3><span id="Rust_Bindings_around_C_Library">Rust Bindings around C Library</span></h3>
<p>This step could’ve been skipped if all I cared about was having a C API for the ported code later, or if I wanted to work with the tests of the C library for validation and worry about calling it from Rust at a later point. In this case I had already done safe Rust bindings around the C library before, and having a Rust API made it much easier to write tests that could be used during the porting and that could be automatically run at each step.</p>
<h4><span id="EJS28"> <code data-enlighter-language="raw">bindgen</code><br>
</span></h4>
<p>As a first step for creating the Rust bindings there needs to be a way to actually call into the C code. In C there are the header files with the type definitions and function declarations, but Rust can’t directly work from those. The solution to this was in this case <a href="https://github.com/rust-lang/rust-bindgen"><code>bindgen</code></a>, which basically converts the C header files into something that Rust can understand. The resulting API is completely unsafe still but can be used in a next step to write safe Rust bindings around it.</p>
<p>I would recommend using <code data-enlighter-language="raw">bindgen</code> for any non-trivial C API for which there is no better translation tool available, or for which there is no machine-readable description of the API that could be used instead by another tool. Parsing C headers is no fun and there is very little information available in C for generating safe bindings. For example for <a href="https://en.wikipedia.org/wiki/GObject"><code>GObject</code></a>-based libraries, using <a href="https://github.com/gtk-rs/gir/"><code>gir</code></a> would be a better idea as it works from a rich XML description of the API that contains information about e.g. ownership transfer and allows to autogenerate safe Rust bindings in many cases.</p>
<p>Also the dependency on <a href="https://clang.llvm.org/"><code>clang</code></a> makes it hard to run <code data-enlighter-language="raw">bindgen</code> as part of every build, so instead I’ve made sure that the code generated by <code data-enlighter-language="raw">bindgen</code> is platform independent and included it inside the repository. If you use <code>bindgen</code>, please try to do the same. Requiring <code data-enlighter-language="raw">clang</code> for building your crate makes everything more complicated for your users, especially if they’re unfortunate enough to use Windows.</p>
<p>But back to the topic. What <code data-enlighter-language="raw">bindgen</code> <a href="https://github.com/sdroege/ebur128/blob/0.1.1/src/ffi.rs">generates</a> is basically a translation of the C header into Rust: type definitions and function declarations. This looks for example as follows</p>
<pre data-enlighter-language="rust">\#[repr(C)]
\#[derive(Debug, Copy, Clone)]
pub struct ebur128_state {
    pub mode: ::std::os::raw::c_int,
    pub channels: ::std::os::raw::c_uint,
    pub samplerate: ::std::os::raw::c_ulong,
    pub d: *mut ebur128_state_internal,
}

extern "C" {
    pub fn ebur128_init(
        channels: ::std::os::raw::c_uint,
        samplerate: ::std::os::raw::c_ulong,
        mode: ::std::os::raw::c_int,
    ) -&gt; *mut ebur128_state;

    pub fn ebur128_destroy(st: *mut *mut ebur128_state);

    pub fn ebur128_add_frames_int(
        st: *mut ebur128_state,
        src: *const ::std::os::raw::c_int,
        frames: usize,
    ) -&gt; ::std::os::raw::c_int;
}
</pre>
<p>Based on this it is possible to call the C functions directly from <code data-enlighter-language="raw">unsafe</code> Rust code and access the members of all the structs. It requires working with raw pointers and ensuring that everything is done correctly at any point to not cause memory corruption or worse. It’s just like using the API from C with a slightly different syntax.</p>
<h4><span id="Build_System">Build System</span></h4>
<p>To be able to call into the C API its implementation somehow has to be linked into your crate. As the C code later also has to be modified to call into the already ported Rust functions instead of the original C code, it makes most sense to build it as part of the crate instead of linking to an external version of it.</p>
<p>This can be done with the <a href="https://crates.io/crates/cc"><code>cc</code></a> crate. It is called into from <code>cargo</code>‘s <code data-enlighter-language="raw">build.rs</code> for configuring it, for example for configuring which C files to compile and how. Once done it is possible to call any exported C function from the Rust code. The <a href="https://github.com/sdroege/ebur128/blob/0.1.1/build.rs"><code>build.rs</code></a> is not really complicated in this case</p>
<pre data-enlighter-language="rust">fn main() {
    cc::Build::new()
        .file("src/c/ebur128.c")
        .compile("ebur128");
}
</pre>
<h4><span id="Safe_Rust_API">Safe Rust API</span></h4>
<p>With all that in place a safe Rust API around the unsafe C functions can be written now. How this looks in practice differs from API to API and might require some more thought in case of a more complex API to ensure everything is still safe and sound from a Rust point of view. In this case it was fortunately rather simple.</p>
<p>For example the struct definition, the constructor and the destructor (<code>Drop</code> impl) <a href="https://github.com/sdroege/ebur128/blob/0.1.1/src/ebur128.rs">looks as follows</a> based on what <code data-enlighter-language="raw">bindgen</code> generated above</p>
<pre data-enlighter-language="rust">pub struct EbuR128(ptr::NonNull&lt;ffi::ebur128_state&gt;);
</pre>
<p>The struct is a simple wrapper around <a href="https://doc.rust-lang.org/std/ptr/struct.NonNull.html"><code>std::ptr::NonNull</code></a>, which itself is a zero-cost wrapper around raw pointers that additionally ensures that the stored pointer is never <code data-enlighter-language="raw">NULL</code> and allows additional optimizations to take place based on that.</p>
<p>In other words: the Rust struct is just a raw pointer but with additional safety guarantees.</p>
<pre data-enlighter-language="rust">impl EbuR128 {
    pub fn new(channels: u32, samplerate: u32, mode: Mode) -&gt; Result&lt;Self, Error&gt; {
        static ONCE: std::sync::Once = std::sync::Once::new();

        ONCE.call_once(|| unsafe { ffi::ebur128_libinit() });

        unsafe {
            let ptr = ffi::ebur128_init(channels, samplerate as _, mode.bits() as i32);
            let ptr = ptr::NonNull::new(ptr).ok_or(Error::NoMem)?;
            Ok(EbuR128(ptr))
        }
    }
}
</pre>
<p>The constructor is slightly more complicated as it also has to ensure that the one-time initialization function is called, once. This requires using <a href="https://doc.rust-lang.org/std/sync/struct.Once.html"><code>std::sync::Once</code></a> as above.</p>
<p>After that it calls the C constructor with the given parameters. This can return <code data-enlighter-language="raw">NULL</code> in various cases when not enough memory could be allocated as described in the documentation of the C library. This needs to be handled gracefully here and instead of panicking an error is returned to the caller. <code data-enlighter-language="raw">ptr::NonNull::new()</code> is returning an <a href="https://doc.rust-lang.org/std/option/enum.Option.html"><code>Option</code></a> and if <code data-enlighter-language="raw">NULL</code> is passed it would return <code>None</code>. If this happens it is transformed into an error together with an early return via the <code data-enlighter-language="raw">?</code> operator.</p>
<p>In the end the pointer then only has to be wrapped in the struct and be returned.</p>
<pre data-enlighter-language="rust">impl Drop for EbuR128 {
    fn drop(&amp;mut self) {
        unsafe {
            let mut state = self.0.as_ptr();
            ffi::ebur128_destroy(&amp;mut state);
        }
    }
}
</pre>
<p>The <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html"><code>Drop</code></a> trait is used for defining what should happen if a value of the struct goes out of scope and what should be done to clean up after it. In this case this means calling the destroy function of the C library. It takes a pointer to a pointer to its state, which is then set to <code>NULL</code>. As such it is necessary to store the raw pointer in a local variable and pass a mutable reference to it. Otherwise the <code data-enlighter-language="raw">ptr::NonNull</code> would end up with a <code data-enlighter-language="raw">NULL</code> pointer inside it, which would result in undefined behaviour.</p>
<p>The last function that I want to mention here is the one that takes a slice of audio samples for processing</p>
<pre data-enlighter-language="rust">    pub fn add_frames_i32(&amp;mut self, frames: &amp;[i32]) -&gt; Result&lt;(), Error&gt; {
        unsafe {
            if frames.len() % self.0.as_ref().channels != 0 {
                return Err(Error::NoMem);
            }

            let res = ffi::ebur128_add_frames_int(
                self.0.as_ptr(),
                frames.as_ptr(),
                frames.len() / self.0.as_ref().channels,
            );
            Error::from_ffi(res as ffi::error, || ())
        }
    }
</pre>
<p>Apart from calling the C function it is again necessary to check various pre-conditions before doing so. The C function will cause out of bounds reads if passed a slice that doesn’t contain a sample for each channel, so this must be checked beforehand or otherwise the caller (safe Rust code!) could cause out of bounds memory accesses.</p>
<p>In the end after calling the function its return value is converted into a <code>Result</code>, converting any errors into the crate’s own <code data-enlighter-language="raw">Error</code> enum.</p>
<p>As can be seen here, writing safe Rust bindings around the C API requires reading of the documentation of the C code and keeping all the safety guarantees of Rust in mind to ensure that it is impossible to violate those safety guarantees, no matter what the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/">https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/</a></em></p>]]>
            </description>
            <link>https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660868</guid>
            <pubDate>Fri, 02 Oct 2020 09:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These “typosquatting” packages served no purpose other than collecting data from the user’s device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype’s <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company’s Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package “electron”)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package “lodash”)</li></ol>



<p>All four packages were published by the same user “simplelive12” and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user’s IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device “fingerprint” was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype’s Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of – possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code “downstream” into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent “counterfeit components” such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax’s expertise lies in vulnerability research, reverse engineering, software development, and web app security. He’s an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter Calculator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660716">thread link</a>) | @nreece
<br/>
October 2, 2020 | https://hur.st/bloomfilter/ | <a href="https://web.archive.org/web/*/https://hur.st/bloomfilter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="CalculatorForm" method="get" action="/bloomfilter/">
				<fieldset><legend></legend>
					<section>
						<p><a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> are
						space-efficient probablistic data structures used to test whether an element
						is a member of a set.</p>

						<p>They're surprisingly simple: take an array of <strong>m</strong>
						bits, and for up to <strong>n</strong> different elements, either test or set
						<strong>k</strong> bits using positions chosen using hash functions. If all
						bits are set, the element <em>probably</em> already exists, with a false positive
						rate of <strong>p</strong>; if any of the bits are not set, the element
						<em>certainly</em> does not exist.</p>

						<p>Bloom filters find a wide range of uses, including tracking which
						<a href="https://blog.medium.com/what-are-bloom-filters-1ec2a50c68ff">articles you've read</a>,
						<a href="https://bitcoin.org/en/developer-guide#application-of-bloom-filters">speeding up Bitcoin clients</a>,
						<a href="http://blog.alexyakunin.com/2010/03/nice-bloom-filter-application.html">detecting malicious web sites</a>,
						and <a href="https://en.wikipedia.org/wiki/Bloom_filter#Cache_filtering">improving the performance of caches</a>.</p>

						<p>This page will help you choose an optimal size for your filter, or explore
						how the different parameters interact.</p>
					</section>

					<hr>

					<dl>
						<dt>n</dt>
						<dd><label><strong>N</strong>umber of items in the filter (optionally with <a href="https://en.wikipedia.org/wiki/Metric_prefix#List_of_SI_prefixes">SI units</a>: k, M, G, T, P, E, Z, Y)<br>
							</label>
						</dd>
						<dt>p</dt>
						<dd><label><strong>P</strong>robability of false positives, fraction between 0 and 1 or a number indicating 1-in-p<br>
							</label>
						</dd>
						<dt>m</dt>
						<dd><label>Nu<strong>m</strong>ber of bits in the filter (or a size with KB, KiB, MB, Mb, GiB, etc)<br>
							</label>
						</dd>
						<dt>k</dt>
						<dd><label>Number of hash fun<strong title="close enough">c</strong>tions<br>
							</label>
							
							<em id="WarningText"></em>
						</dd>
					</dl>

					<p id="ResultText">
						<code>n = </code>4,<wbr>000<br>
<strong><code>p = </code>1.0E-7 (1 in 9,<wbr>994,<wbr>297)</strong><br>
<strong><code>m = </code>134,<wbr>191 (16.38KiB)</strong><br>
<strong><code>k = </code>23</strong>					</p>

					
				</fieldset>
			</div></div>]]>
            </description>
            <link>https://hur.st/bloomfilter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660716</guid>
            <pubDate>Fri, 02 Oct 2020 09:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Imposing American Views about Race on Us]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 214 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it … I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country—it cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country’s flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country’s does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label “black British.” For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)—about the same number as white students. But black Caribbean students are significantly less likely to do so—while those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label “black British.” But we need to invest it with the nuance consonant with its reality—and to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism—rather than law, medicine or finance—if you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country—or the black community—really benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison’s iconic protagonist, is “invisible because no one wants to see him.”</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people—a narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Test to Figure Out Why You Feel Down Lately]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660666">thread link</a>) | @azarai
<br/>
October 2, 2020 | https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                                                            
                                                                         <p>Feeling down lately?</p>
<p>But you don’t know why?</p>
<p>This quick test helps you to figure it out and gives you tips on getting up again.</p>
<h2>Quick Test</h2>
<blockquote>
<p>Did you sleep 7-8 hours a night for most of the last 7 days?</p>
</blockquote>
<p>Sleep is essential, and we should not skip on that. While we sleep, our brain processes the day and also cleans itself of toxic waste (<a href="https://www.scientificamerican.com/article/deep-sleep-gives-your-brain-a-deep-clean1/#:~:text=Why%20sleep%20has%20restorative%E2%80%94or,is%20hugely%20improved%20during%20sleep.">see</a>)</p>
<blockquote>
<p>Did you drink less than 10 drinks of alcohol in the last 7 days?</p>
</blockquote>
<p>There is nothing to say against a drink or two. But if you take it too far, you start to feel down, groggy and more. Moreover, alcohol can be addictive, and you don’t want to become an alcoholic.</p>
<blockquote>
<p>Did you drink too much caffeine in the last 7 days? (Coffee, black tea, energy drinks, etc.)</p>
</blockquote>
<p>Caffeine is a short energy booster, but it comes with downsides too. It blocks the body’s desire to rest for a short time, but then your body is twice as tired, wanting to rest.</p>
<p>Now, if you drink caffeine again, you start a vicious cycle. You’ll only feel productive when you got your dose of caffeine. Otherwise, you feel tired again.</p>
<p>Over time you need to consume more and more caffeine to even get the effect.</p>
<p>Rest. Your body needs rest, and you should give it.</p>
<blockquote>
<p>Do you think you’re eating healthy in the last 7 days?</p>
</blockquote>
<p>Your body needs proper nutrition to function.</p>
<p>A diet of chips, chocolate bars, ice cream, or fast food is not the right thing to fuel your body the energy it needs.</p>
<p>Once in a while, it is fine but don’t thrive on it.</p>
<blockquote>
<p>Have you gone outside in the last 7 days?</p>
</blockquote>
<p>Pandemic here, pandemic there. But even without it, many of us don’t go outside enough—especially people working from home.</p>
<p>But we need movement and fresh air. So, enjoy a long walk in nature, or a park or forest near you. Or just stroll through your city.</p>
<blockquote>
<p>Have you exercised in the last 7 days?</p>
</blockquote>
<p>Move your ass. Doesn’t matter what kind of exercise you like, do it. Movement is king.</p>
<p>Not only will it lift your mood. It will also help you to think fresh and clear again.</p>
<blockquote>
<p>Have you meditated in the last 7 days? Or journaled, etc.</p>
</blockquote>
<p>Meditation is a great tool to clear your thoughts and calming down. But you don’t need to sit still.</p>
<p>You can do <a href="https://mindfuldevmag.com/issues/issue-3-mindfulness-for-skeptics/walking-meditation">walking meditations</a> or journaling or other kinds of activities that help you to focus and clear your mind.</p>
<blockquote>
<p>Have you done anything to actively relax?</p>
</blockquote>
<p>This can be taking massages, doing yoga, taking a hot bath, sauna, or anything else that helps you relax.</p>
<p>Take your time and do it on purpose.</p>
<p>Btw watching tv might feel like relaxation, but it mostly is not. Our brain’s on alert mode.</p>
<p>Can’t decide on one?</p>
<p>Go for a walk in the next park.</p>
<blockquote>
<p>Have you talked to other people or met with your friends? Preferably IRL</p>
</blockquote>
<p>Even the most introverted of us love to talk to somebody. Sure, I can go without days of talking to somebody except my family. But even that has its limit.</p>
<p>Talk or, better yet, meet your friends, and have a great time. None handy at the moment? Talk to your neighbor, cashiers, or anybody else you can have interactions with.</p>
<blockquote>
<p>If you’re in a relationship, are you with the right person?</p>
</blockquote>
<p>If your relationship sucks, your mood will drop too. But if it is a loveable and stable one, it can lift you up and help through darker times.</p>
<blockquote>
<p>Have you helped someone in the last days with something you’re good at?</p>
</blockquote>
<p>Believe it or not. It’s humans to help others and feel good about it at the same time. It’s totally refreshing and re-energizing.</p>
<blockquote>
<p>Have you made any new experiences in the last month?</p>
</blockquote>
<p>Doing the same old from day to day, week to week, and month to month can drag you down. It feels like a rut. Being stuck.</p>
<p>Energize your life and go for new experiences. Go for a hike, visit a new city, test a new restaurant. Whatever it is, pick something new.</p>
<blockquote>
<p>Are you working on stuff that’s meaningful to you?</p>
</blockquote>
<p>Does your job or the things you work on in your spare time give you enough meaning? Or does it feel like working for the devil?</p>
<p>Does it fulfill you?</p>
<blockquote>
<p>Does your current situation allow you to do what you really want to do in life?</p>
</blockquote>
<p>If not, think about what you could start to change? What are thing top 3 things holding you back?</p>
<p>How could you remove them?</p>
<blockquote>
<p>Did you create anything in the last week?</p>
</blockquote>
<p>Does not matter what it is. Maybe you draw comics or paint art, make music, build websites, or whatever.</p>
<p>Let your creativity go wild, and your mood will go up.</p>
<blockquote>
<p>Are your working on too many things at the same time?</p>
</blockquote>
<p>Pursuing multiple things at the same time makes you feel like nothing moves forward. Often paired with getting frustrated and then feeling down.</p>
<p>Set your focus on one thing for now and work on that. The down feelings will fade.</p>
<blockquote>
<p>Do you have the feeling that you accomplished something?</p>
</blockquote>
<p>Sometimes we hustle and hustle but have the feeling we got nowhere. Just being tired and running towards a burnout.</p>
<p>Think about what small things you could add that make you feel to have accomplished something? Must not be work-related. It could also be private things you pushed for years in front of you.</p>
<h2>All Positive But Still Feeling Down?</h2>
<p>If you answered all questions positively and are still feeling down, it might be time to visit a therapist. There is no shame in that. We all need help sometimes.</p>
<p>Find someone near you or use an online service like <a href="https://www.talkspace.com/">talkspace</a>.</p>
                                     
                                     <hr>
                                     
                                                                          
                                     
                                       
                                       
                            </div>

                    </div></div>]]>
            </description>
            <link>https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660666</guid>
            <pubDate>Fri, 02 Oct 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a lay-down desk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660610">thread link</a>) | @polote
<br/>
October 2, 2020 | https://blog.luap.info/i-built-a-lay-down-desk.html | <a href="https://web.archive.org/web/*/https://blog.luap.info/i-built-a-lay-down-desk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>After spending part of the last 12 months <a href="https://blog.luap.info/travelling-with-24-monitors.html">travelling in Europe</a> I'm now settling down around Paris and I need to adapt my multi-screens setup.</p>
<p>You probably have seen an ads for <a href="https://altwork.com/">the altwork desk</a> <em>a $7000 desk that let you work laying down</em>. Spending a big part of my day in front of a computer I want to have the most comfortable position as possible, but well $7000 + $1000 for the delivery seems so expensive. There is also <a href="http://www.ergoquest.com/">this company</a> but this is still about $4000 all included. Let's be creative and build it myself.</p>
<p>Here is the result</p>
<p><img alt="complete desk" src="https://blog.luap.info/static/desk/complete.jpg"> </p>
<p>The things I have to take into account are:</p>
<ul>
<li>
<p>I have three monitors</p>
</li>
<li>
<p>I have no diy tools</p>
</li>
<li>
<p>I want a laying down position</p>
</li>
<li>
<p>This should be easy to use</p>
</li>
<li>
<p>This should be light and not take too much space</p>
</li>
<li>
<p>I have only a bike to move the parts</p>
</li>
<li>
<p>I haven't found anyone who has done something similar and so don't really have examples</p>
</li>
</ul>
<p>So instead of doing the waterfall way I decided to go the agile way and to not do any plans, I didn't know what to expect, so let's do it step by step and see how it goes</p>
<h2>Take care of the chair</h2>
<p>There are several options:</p>
<ol>
<li>
<p>Built a chair from scratch including the 'mattress' part</p>
</li>
<li>
<p>Use a reclined chair</p>
</li>
<li>
<p>Adapt a chair</p>
</li>
</ol>
<p>The issue with the first option is that I will not be sure of the result, is it going to be comfortable ? How I'm going to wash the seat covers ? I have no idea of the things to take into account for building a comfortable chair.</p>
<p>Reclined chairs are great but they are very heavy (except the garden ones but not very comfortable) and expensive. So again let's be creative, I got inspired by <a href="https://www.ikeahackers.net/2017/04/poang-gravity-recliner.html">this</a> and <a href="https://www.ikeahackers.net/2020/04/remove-poang-arms.html">this</a> ikea hacks which use a IKEA POANG chair and transform it into a reclined chair.</p>
<p>Here is the result :</p>
<p><img alt="ikea poang adaptation" src="https://blog.luap.info/static/desk/chair.jpg"></p>
<p>The chair is 69 euro, I had to buy three cushion to extend it</p>
<p>The most complex part was to do 7km with the chair on a bike. I do not recommend doing the same, particularly because I have done it on a rainy day but well a bit of challenge in my life is always welcome!</p>
<p><img alt="ikea bike" src="https://blog.luap.info/static/desk/ikea_bike.jpg"></p>
<p>Great, the chair is comfortable, let's do something for the desk part.</p>
<h2>What structure for the desk</h2>
<p>The biggest issue you are going to have with the lay down position, is that the desk is going to be on your legs and you cant 'enter' or 'leave' the desk if you can't move the desk. So you need the 'desk' part to be dynamic from the 'chair' part.</p>
<p>I had two ideas for that, either the Altwork way, the structure goes above your head and can incline, or the the base is on the side and the desk can move somewhere (writing that, having the desk in front of me, I wonder if having the base where the foot are is not an even better solution ? Damn, too late). Having the base on the side seems better because it would be smaller and lighter and also you can balance the weight much better. But the structure also needs to be more rigid and I need to find a way to incline the desk, anyway I haven't found a way to do it :(, after a night of thinking I went the altwork way.</p>
<p>There are two parts to design:</p>
<ol>
<li>
<p>The base + the incline system</p>
</li>
<li>
<p>The desk + the screen supports</p>
</li>
</ol>
<h3>1. Base + incline system</h3>
<p>The base is pretty standard, you need something strong enough so that it can suppot the whole thing. At that point I still didn't know the weight of the complete platform so I didn't know how strong it should be. After a few failing choices, I ended up with a main pole of 7cm x 7cm.</p>
<p>Now the complex part, how to design the rotation part ? How heavy is going to be the rest of desk ? How much does the desk need to move so that I can 'enter' the desk ? So many questions I didnt have an answer for.</p>
<p>So let's try something and see how it goes, I bought an <a href="https://www.amazon.fr/gp/product/B00H8SZ87W">gaz actuator on Amazon</a> which can support 70kg with a range of 31cm, it is built for cars and pretty cheap, 19euro. Actually 70kg is a lot. So at least I have a some freedom on the weight of the structure.</p>
<p>I had two issues with the actuator:</p>
<ul>
<li>70kg IS A LOT, it is so much that when I was fixing it on the wood of the base, it was breaking the wood. The best would be to have an iron piece that I can fix to the wood but I didnt have the tools for that so I used stronger woods but this is still fragile. </li>
</ul>
<p><img alt="fixation verrin" src="https://blog.luap.info/static/desk/fixation_verrin.jpg"></p>
<ul>
<li>The desk follows a circular trajectory when you move it up and down. As a result the barycenter of the structure changes depending on the Y position of the 'desk part' and so there is more strength applied on the actuator when it is up than when it is down. So basically the desk will not stay by itself when in the up position.  I need to find a way to get the desk in the up position.</li>
</ul>
<p>I'm not really proud of the way I've done it, but it somewhat works. I've built a piece of wood that inserts itself in the area between the two poles where the actuator is. There is a counterweight which drags the piece into the zone when in up position, and when I want to release it, I just need to pull on the rope. (I think I will replace the actuator with a real electric actuator when the current system breaks so that I can control the movement, it is about 120euro)</p>
<p><img alt="system block" src="https://blog.luap.info/static/desk/blocking_system.jpg"></p>
<h3>2. Desk + screens support</h3>
<p>I bought a chipboard plate of 80cm x 120cm, and cut some space for my body</p>
<p><img alt="plaque bois" src="https://blog.luap.info/static/desk/agglo.jpg"> </p>
<p>This is pretty solid, so I can directly screw this plate to the pole and we have a desk surface</p>
<p><img alt="plaque bureau" src="https://blog.luap.info/static/desk/bureau_with_plaque.jpg"></p>
<p>For holding the monitors I did something pretty basic, I created a box for each screen. Then comes the position of the screen, how to know the position of each screen ? I didnt know how to know it beforehand, so I just created dynamic arms and adjusted them while in front of the screens</p>
<p><img alt="support monitor" src="https://blog.luap.info/static/desk/support_monitor.jpg"></p>
<h2>Next steps</h2>
<p>This is only a few days old so I can't really make a feedback but there are already a few things that I need to fix</p>
<ul>
<li>
<p>I can't use a mouse anymore, as the mouse would fall down, I'm probably going to replace it by a trackball</p>
</li>
<li>
<p>I need to invest in an ergonomic keyboard to get really comfortable, probably going to buy the kenesis advantage 2, but this is expensive !</p>
</li>
</ul>
<p>Here is a video of the complete desk:</p>
<video controls="">
  <source src="https://blog.luap.info/static/desk/video.mp4" type="video/mp4">
</video>

<h2>Conclusion</h2>
<p>When you want to build this kind of structure, I'm not sure you can plan everything beforehand, there are always things that will happen that you didn't expect, like when you code: if you want to modify the actuator when the 60kg setup is mounted how do you do ? (I have done it 6 times) When your base can't support the weight because it lacks one screw and you need to unmount everything what do you do ? ...</p>
<p>I'm really annoyed by the actuator part, I hope I will find something more reliable</p>
<p>Overall it cost me :</p>
<ul>
<li>
<p>45 euro for tools</p>
</li>
<li>
<p>130 euro for wood pieces, screws, joins, ...</p>
</li>
<li>
<p>110 euro for the IKEA chair + cushions</p>
</li>
</ul>
<p>and I spent 26 hours working, excluding the transport and the time shopping for pieces</p>
<p>Don't forget when you do woodworking to clean afterwards  :)</p>
<p><img alt="dirty" src="https://blog.luap.info/static/desk/dirty_floor.jpg"></p>
<p>If you have done something similar and know a few advice, please send me an email</p>
<p>PS: If you wonder whether you can do that or not, everyone can do it, basic woodworking is not complex, you need to know how to cut wood, how to join wood, how to screw and a little bit of imagination, you dont even need a car to transport parts, I transported everything: pole of 2m40, big plate ... on a bike</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/i-built-a-lay-down-desk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660610</guid>
            <pubDate>Fri, 02 Oct 2020 09:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Flancia there are no walled gardens]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660583">thread link</a>) | @ColinWright
<br/>
October 2, 2020 | https://flancia.org/mine/flanbook/ | <a href="https://web.archive.org/web/*/https://flancia.org/mine/flanbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>In Flancia the internet is truly open: they managed to get rid of <a href="https://en.wikipedia.org/wiki/Closed_platform">walled gardens</a>. How they did it is an interesting&nbsp;story.</p>
<h2>Status&nbsp;quo</h2>
<p>Let’s take just one example; it should suffice to represent the general approach they took. In Flancia they had a social network — well, they had many of course, same as we do, but one in particular had grown into dominance. People had sort of liked it at some point, then eventually didn’t anymore, but they were stuck with it by then; it had developed at just the right time in internet history, and it had done enough things right in the beginning to take over from contenders and really soar in&nbsp;usage. </p>
<p>As it often was the case in those days, this network was fully controlled by a single corporation, and although at the beginning there were some provisions in place that made it look like a relatively healthy platform eventually the company had chosen to consolidate their dominion; namely close down APIs and turn it into a walled garden. By then network effects had taken over and de facto locked people in, too: the company had gotten users to build up an expansive social graph for them and had succeeding in retaining control over it. They proceeded to use this virtual monopoly on many users’ social capital and attention to make billions selling ads — and gained the ability to significantly steer public opinion in the process, too. Many people recognized problems with this approach, but users at large mostly kept using it. It was that or being locked out of a significant portion of social activity online and&nbsp;offline. </p>
<h2>X marks the&nbsp;spot</h2>
<p>One of the obstacles that Flancians faced when trying to improve on this status quo was that there was no single clearly better platform of choice available; in areas where there were some alternatives there were often too many, so the competitive landscape was fragmented, and that played to the company’s advantage. The company also used their ad-fueled wealth to buy most promising contenders and offer them as relatively empty alternatives to their main network, while effectively gaining access to more social data and expanding their influence. After a while network effects and inertia were so strong that competitors all but stopped trying; social networks are known to be hard to decamp from, as most of their value is in the social graph that users build on them; and the oh-so-valuable graph was kept very deep within the company’s walled&nbsp;garden. </p>
<p>Flancians didn’t have much when facing this dire state of affairs, but they had one thing, and it was an important one: they had <a href="https://flancia.org/agora/">a machine for solving coordination problems</a>. So they used it. First they sketched out a declaration of intents flowing naturally from their publicly espoused&nbsp;values.</p>
<ul>
<li>Useful internet platforms should be&nbsp;open.</li>
<li><span>‘</span>Open’ means that no single monolithic entity can fully control them and that their inner workings are transparent to interested parties and appropriately&nbsp;malleable.</li>
<li><span>‘</span>Open’ is desirable because otherwise monolithic egotistical entities can gain control of the network and extort value out of its users, or mislead&nbsp;them.</li>
</ul>
<p>Then they proceeded to write a plan together. The first version was remarkably simple; a sketch to get the real discussion started. It said essentially as&nbsp;follows:</p>
<ul>
<li>For each useful internet platform X that is not&nbsp;open:</li>
<li>Let X’ be its open&nbsp;replica.</li>
<li>Write down a plan to reimplement its core functionality, F(X’) ≈&nbsp;F(X).</li>
<li>Write down a plan to reproduce its critical data set, D(X’) ≈&nbsp;D(X).</li>
<li>Add X’ to the <a href="https://anagora.org/wiki/Missing_Devices">Catalog of Missing Devices</a> in the Agora. This both marks it as a canonical replica of X and announces it as a priority for&nbsp;Flancians.</li>
</ul>
<p>Once this bootstrap process was complete, the standard Agora algorithms took over; Flancians would best-effort iterate, improving on plans and resource estimates and executing actions as available to them, until failure or&nbsp;convergence.</p>
<p>Social networks were useful internet platforms; the Agora, after all, was in many ways a social network (a focused, goal-oriented one). So Flancians set out to replicate the company’s social network. They named that particular X’ <em>Flanbook</em> — after <a href="https://en.wikipedia.org/wiki/The_Book_of_Sand">The Book of Sand</a>, of course. It was fitting because the task of replicating it seemed at that point in time infinite in&nbsp;scope.</p>
<h2>I(X’)</h2>
<p>Looking around, it turned out that Flancians were relatively lucky. Most of the tools and libraries needed to build an open replica of the social network were available off-the-shelf. From all its algorithms, its ranking algorithms were perhaps the most sophisticated; but Flancians intended to replace those anyways, thinking the community could do better, so that was not an issue. The road to I(X’) was not trivial by any means, but it wasn’t very interesting for the purpose of telling this particular&nbsp;story.</p>
<h2>D(X’)</h2>
<p>In the case of social networks, then, it followed that most of their value was in their data; and, from all their data, none was more valuable than their social graph. Here Flancians had an ideological advantage, albeit perhaps not strictly a legal one to begin with, as they were known to often burst into chant in unison in barely appropriate&nbsp;occasions:</p>
<p><em>This, which is our data,<br>
will always be our data.<br>
A Flancian and their data<br>
shall never come apart.</em><br></p>
<p>This somewhat awkward ritual came handy sometimes, though. Flancians strongly believed that any information they produced and maintained was theirs; they believed this almost as much as they believed in the Agora. To a Flancian, the idea of their part of the social graph (the piece they had contributed a node and edges to) being out of their reach, locked down somewhere deep in a walled garden, just didn’t make sense. They refused to take it. So they just agreed to take their data&nbsp;back.</p>
<p>To perform this kind of task in a scalable way, they built special devices called <em>syphons</em>. The simplest came in the form of browser extensions. Whenever a Flancian used a targeted service X, the syphon redirected relevant data in the background to the replica X’. This allowed building up D(X’) incrementally so it could eventually function as a drop-in replacement. Flancians agreed to use these devices any time they could in platforms being replicated, even when they were not otherwise directly involved in the replication&nbsp;project.</p>
<p>Now, Flancians are an altogether friendly group, and they have the added advantage of knowing how to use an Agora; but they still do sometimes come into disagreements. Here Flancians disagreed with each other in how to define <em>relevant</em> in the above paragraph. Some Flancians, believing closed platforms to be actively dangerous to society, took the position that <em>all</em> data could be considered relevant in the noble pursuit of replicating such platforms, and consequently took a relatively aggressive stance and built and used syphons that actively sought to crawl and extract the largest portion of D(X) possible as fast as possible, regardless of provenance of data. Other Flancians, mostly aligned with the Middle Way, built syphons that only extracted data that they could strongly claim to be <em>theirs</em> to begin with, according to a shared and public&nbsp;definition:</p>
<ul>
<li>If the user of the syphon added the node or edge, it is considered&nbsp;relevant.</li>
<li>If a non-Flancian added the node or edge, and they give explicit consent to extraction, it is&nbsp;relevant.</li>
<li>If a Flancian added the node or edge, it is relevant (Flancians consent by default to the rational constructive actions of other&nbsp;Flancians).</li>
</ul>
<p>The second approach introduced the additional problem of identifying users across platforms and tracking consent. The syphons offered cross-platform validation as a feature; otherwise it could be manually accomplished by cross-posting tokens and declarations of intent publicly in the relevant&nbsp;networks.</p>
<p>Once this system was in place, it would presumably make D(X’) converge into a usable&nbsp;dataset.</p>
<p>The company, of course, put up a battle. They correctly identified X’ as an existential risk, and sought to attack syphons and their users. This started an arms race. Both groups of Flancians were affected differently, with those subscribing to the Middle Way being on more solid legal footing. The fact that Flancians had enough resources and a platform to organize a united resistance (the Agora) helped them tremendously; also helpful was the fact that relatively small but dense parts of D(X’) were sufficient to bootstrap smaller social networks within the&nbsp;network.</p>
<p>It would be perhaps unwise of me to say at this point which group fared better in the end, and precisely when and how the first replication project was brought to effective completion. Suffice it to say that Flanbook was a success, at least for a while, and it remains somewhat popular among the more old school Flancians. I, myself, am more partial to&nbsp;Instaflan.</p>
</div>
    </div></div>]]>
            </description>
            <link>https://flancia.org/mine/flanbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660583</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome85 is stopping to send URL path as HTTP Referer field]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24660580">thread link</a>) | @yoshiokatsuneo
<br/>
October 2, 2020 | https://engineering.paiza.io/entry/referrer_policy | <a href="https://web.archive.org/web/*/https://engineering.paiza.io/entry/referrer_policy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div id="main-inner">
          


          
  
  <!-- google_ad_section_start -->
  <!-- rakuten_ad_target_begin -->
  
  
  

  

  
    
      
        <article id="entry-26006613635480643" data-keyword-campaign="" data-uuid="26006613635480643" data-publication-type="entry">
  <div>
    

    


    <div>
  
    <p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002144505.png" alt="f:id:paiza:20201002144505p:plain" title="f:id:paiza:20201002144505p:plain" itemprop="image"></span></p>

<div>
<p><small>(Japanese article is <a href="https://paiza.hatenablog.com/entry/2020/10/02/referrer_policy">here</a>)</small></p>
</div>


<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20151217/20151217152725.jpg" alt="f:id:paiza:20151217152725j:plain" title="f:id:paiza:20151217152725j:plain" itemprop="image"></span>Hi, I'm Tsuneo([twitter:@yoshiokatsuneo]).</p>

<p>Now, the latest Chrome is stopping to send the URL path as HTTP Referer on cross-domain access.</p>

<p>If you analyze access to your web site, you can not know which article leads the user to your site.</p>

<h2>Beginning</h2>

<p>We have a blog as our own media to lead to our web service.
And, we are monitoring the reference URLs to our web service.</p>

<p>We happen to nice that the more and more reference is from the blog top page, and less and less reference from each article URLs.</p>

<h2>Chrome 85</h2>

<p>From our access logs, it looks like the change happens only on Chrome.</p>

<p>And, we noticed that the default "Referrer Policy" is changed from <strong>no-referrer-when-downgrade</strong> to <strong>strict-origin-when-cross-origin</strong> on Chrome85.</p>

<p>For example, the reference URL "<a href="https://paiza.hatenablog.com/entry/2020/10/01/140612">https://paiza.hatenablog.com/entry/2020/10/01/140612</a>" is stripped to "<a href="https://paiza.hatenablog.com/">https://paiza.hatenablog.com/</a>" .</p>

<p><cite><a href="https://www.chromestatus.com/feature/6251880185331712">www.chromestatus.com</a></cite></p>

<p>But, actually, when I test on Chrome85 my machine, the setting was  "no-referrer-when-downgrade", yet.
It looks that the setting is changing gradually.</p>

<h2>How to see the Referrer Policy</h2>

<p>We can see that what URL is sent as Referer on the cross-domain link.</p>

<p><a href="https://webdbg.com/test/refer/">https://webdbg.com/test/refer/</a></p>

<p>If the first green box has a URL with the path, your Chrome has "no-referrer-when-downgrade" as the Referrer Policy.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�‚ã‚‹å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143005.png" alt="f:id:paiza:20201002143005p:plain" title="f:id:paiza:20201002143005p:plain" itemprop="image"></span><figcaption>URL with path(no-referrer-when-downgrade)</figcaption></figure>

<p>If the first green box has a URL without the path like below, your Chrome has the new "strict-origin-when-cross-origin" settings like below.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�ªã�„å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002142849.png" alt="f:id:paiza:20201002142849p:plain" title="f:id:paiza:20201002142849p:plain" itemprop="image"></span><figcaption>URL without path(strict-origin-when-cross-origin)</figcaption></figure>

<p>You can also see the Referrer-Policy on Chrome developer tool, network tab.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143238.png" alt="f:id:paiza:20201002143238p:plain" title="f:id:paiza:20201002143238p:plain" itemprop="image"></span></p>

<h2>Why is the "Referrer Policy" changed ?</h2>

<p>The Referrer Policy is changed because of privacy and security concerns.</p>

<p>The Referer URL may contain search keywords, account ID, e-mail address, or other IDs, and the information may be sent to the linked site as "Referer".</p>

<p><cite><a href="https://web.dev/referrer-best-practices/">web.dev</a></cite></p>

<figure title="(https://web.dev/referrer-best-practices/ ã‚ˆã‚Š)"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143341.png" alt="f:id:paiza:20201002143341p:plain" title="f:id:paiza:20201002143341p:plain" itemprop="image"></span><figcaption>(from <a href="https://web.dev/referrer-best-practices/)">https://web.dev/referrer-best-practices/)</a></figcaption></figure>

<p>Nowadays, security and privacy are getting more critical than before. So, other browsers may change the settings as Chrome does.</p>

<h2>Current Referrer Policy deployment status</h2>

<p>How many Chrome85 have new "strict-origin-when-cross-origin", at now ?</p>

<p>At first, I created a poll at Slack. It looks more than half have the new settings.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143535.png" alt="f:id:paiza:20201002143535p:plain" title="f:id:paiza:20201002143535p:plain" itemprop="image"></span></p>

<p>Also, from the access logs to our web sites, the percentage of Referer from the top page is growing from less than 10% to around 20% on  8th/Sep, and more than 50% on 29th/Sep or later.</p>

<h2>Solution</h2>

<p>If you can change the HTTP header or the HTML meta tag, you can change the Policy Referrer settings.</p>

<h3>HTTP header(Policy-Referrer) settings</h3>

<p>You can change Policy-Referrer HTTP response header field.
On nginx, you can change the configuration file like below.</p>

<pre data-lang="" data-unlink="">add_header 'Referrer-Policy' 'no-referrer-when-downgrade';</pre>


<h3>meta tag(name=referer) settings</h3>

<p>You can also change using the HTML meta tag like below.</p>

<pre data-lang="html" data-unlink=""><span>&lt;</span><span>meta</span><span> </span><span>name</span><span>=</span><span>"referrer"</span><span> </span><span>content</span><span>=</span><span>"no-referrer-when-downgrade"</span><span>/&gt;</span>
</pre>


<h3>Chrome settings</h3>

<p>You can also change on Chrome settings by putting "chrome://flags/#reduced-referrer-granularity" on the URL bar for testing.
By enabling the settings, Chrome does not send pathname on the URL.
By disabling the settings, Chrome sends pathname on the URL.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002153758.png" alt="f:id:paiza:20201002153758p:plain" title="f:id:paiza:20201002153758p:plain" itemprop="image"></span></p>



<p>On Safari 13 introducing ITP2.3, the access from the domain classified as tracker does not contain the path on Referer.</p>

<p><cite><a href="https://webkit.org/blog/9521/intelligent-tracking-prevention-2-3/">webkit.org</a></cite></p>



<p>The new Chrome85 is gradually stopping to send a URL path on Referer on cross-domain link, and it can cause huge impact on your web marketing.
I recommend checking your settings on web sites, access logs, or analysis tools.</p>

<hr>


<p>Withã€Œ<a href="https://paiza.cloud/">PaizaCloud Cloud IDE</a>ã€�, you can flexibly and easily develop your Web application or server application, and publish it, just in your browser.
<a href="https://paiza.cloud/"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20171214/20171214153422.png" alt="https://paiza.cloud"></a></p>

<hr>


    

  
</div>

    
  

  </div>
</article>

      
      
    
  

  
  <!-- rakuten_ad_target_end -->
  <!-- google_ad_section_end -->
  
  
  
  


  



        </div>
      </div></div>]]>
            </description>
            <link>https://engineering.paiza.io/entry/referrer_policy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660580</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[[ Is a Builtin, but [[ Is Part of the Shell Language (2016)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660535">thread link</a>) | @chubot
<br/>
October 2, 2020 | http://www.oilshell.org/blog/2016/10/12.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2016/10/12.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2016-10-12
</p>
<!--
Started:                  ~8:35pm
Done with second edit:     9:10pm
More edits and deployed:   9:16pm
Editing again:             11:29
Done again again:          11:45
X -->
<p>The current theme of this blog is to show how the oil parser works.  But let's
make sure we understand an important concept first: <strong>parse-time errors</strong> vs.
<strong>runtime errors</strong>.</p>
<p>The way I write conditions in shell is like this:</p>
<div><pre><span></span><span>if</span> <span>test</span> -d /tmp<span>;</span> <span>then</span>
  <span>echo</span> <span>"/tmp is a dir"</span>
<span>fi</span>
</pre></div>
<p>This is the same thing:</p>
<div><pre><span></span><span>if</span> <span>[</span> -d /tmp <span>]</span><span>;</span> <span>then</span>
  <span>echo</span> <span>"/tmp is a dir"</span>
<span>fi</span>
</pre></div>
<p>But yet another construct for conditional expressions is <code>[[</code>.  The <a href="http://www.oilshell.org/cross-ref.html#google-style-guide">Google
Shell Style Guide</a> recommends using it, reasoning that:</p>
<blockquote>
<p>[[ ... ]] reduces errors as no pathname expansion or word splitting takes
place between [[ and ]].</p>
</blockquote>
<blockquote>
<p>[[ ... ]] allows for regular expression matching where [ ... ] does not.</p>
</blockquote>
<p>That is, consider the following:</p>
<div><pre><span></span><span>x</span><span>=</span><span>'name with space.sh'</span>
<span>[</span> <span>$x</span> <span>==</span> *.sh <span>]</span>
<span>[[</span> <span>$x</span> <span>==</span> *.sh <span>]]</span>
</pre></div>
<p>On the <code>[</code> line, <code>$x</code> will be split into 3 arguments.  The glob <code>*.sh</code> is also
expanded into multiple arguments, depending on what's in the current directory.
Both of these things cause the wrong number of arguments to appear on each side
of <code>==</code>.  In contrast, the <code>[[</code> expression will have exactly one argument on
the left and right of <code>==</code>.  (It tests if <code>$x</code> matches the pattern <code>*.sh</code>,
which is true.)</p>
<p>What I didn't realize before implementing the oil parser is that this doesn't
quite capture the difference between <code>[[</code> and <code>[</code>.  The more important
difference is that <code>[[</code> is <strong>part of the shell language</strong>, while <code>[</code> is a
<strong>builtin</strong>.</p>
<p>This means that an expression inside <code>[[ ... ]]</code> is <strong>parsed up front</strong>, before
any code is executed.  In contrast, the arguments to <code>[</code> are parsed by the
builtin itself at <strong>runtime</strong>.</p>
<p>(In terms of parsing arguments, shell builtins behave like external commands.
The fact that they happen to live inside the <code>/bin/sh</code> binary doesn't change
anything.)</p>
<p>The bash help doesn't capture this difference either: see <code>help [</code> and <code>help [[</code>.  The parse-time vs. runtime distinction isn't mentioned.</p>
<p>Let's write some code to show this difference.  First we create syntax errors
by leaving off the right hand side of an equality test:</p>
<pre><span>$ <span></span><span>[</span> <span>a</span> <span>==</span> <span>]</span>
</span><span>/bin/bash: line 1: [: a: unary operator expected</span>
</pre>
<pre><span>$ <span></span><span>[[</span> <span>a</span> <span>==</span> <span>]]</span>
</span><span>/bin/bash: line 1: unexpected argument `]]' to conditional binary operator
/bin/bash: line 1: syntax error near `]]'
/bin/bash: line 1: `[[ a == ]]'</span>
</pre>
<p>On the face of it, these errors look similar.  Now let's use the general
technique of wrapping them in <code>if false</code>:</p>
<pre><span>$ <span></span><span>if</span> false<span>;</span> <span>then</span> <span>[</span> <span>a</span> <span>==</span> <span>]</span><span>;</span> <span>else</span> <span>echo</span> <span>'NOT PARSED'</span><span>;</span> <span>fi</span>
</span><span>NOT PARSED</span>
</pre>
<pre><span>$ <span></span><span>if</span> false<span>;</span> <span>then</span> <span>[[</span> <span>a</span> <span>==</span> <span>]]</span><span>;</span> <span>else</span> <span>echo</span> <span>'NOT PARSED'</span><span>;</span> <span>fi</span>
</span><span>/bin/bash: line 1: unexpected argument `]]' to conditional binary operator
/bin/bash: line 1: syntax error near `;'
/bin/bash: line 1: `if false; then [[ a == ]]; else echo 'NOT PARSED'; fi'</span>
</pre>
<p><code>bash</code> parsed the first statement without issue, and executed the <code>else</code>
clause.  The stuff inside <code>[</code> is just an opaque list of strings.  We never
executed it and never parsed it.</p>
<p>In contrast, it emitted a parse error for the second statement, and didn't
execute any code.  This is because <code>[[</code> is actually part of the language.</p>
<p>Tomorrow we will use the same <code>if false</code> technique to compare the oil parser
with popular shell parsers.  We will see which errors they can catch at parse
time, and which errors have to wait until runtime.</p>
<p>oil has the philosophy that catching errors earlier is better.  You don't want
run a 4 hour script and get a syntax error after 3 hours.</p>




</div>]]>
            </description>
            <link>http://www.oilshell.org/blog/2016/10/12.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660535</guid>
            <pubDate>Fri, 02 Oct 2020 08:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Teams and Good Time Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660510">thread link</a>) | @lucyinkedup
<br/>
October 2, 2020 | https://caylent.com/remote-teams-and-good-time-management | <a href="https://web.archive.org/web/*/https://caylent.com/remote-teams-and-good-time-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	                    <section>
	                        <div>
	                            
<p>This year’s global pandemic has forced the fast adjustment for many organizations from in-office normality to a remote working setup at whiplash speed. The rapid adoption of remote working is not easy though—even without the pressure of COVID.&nbsp;</p>



<p>Challenges are abundant for both those with remote working experience and those without. Managers and team leaders are struggling to keep their teams motivated and efficient. Remote teams are often seen as more difficult to manage, but the tips discussed in this article can help you overcome these challenges.&nbsp;</p>



<h2>Empower Remote Team Members</h2>



<p>Before digging deeper into time and task management, there are actually several basic steps that you need to complete in order to make remote teams effective. The first thing you want to do is making sure that team members can communicate easily and effectively, and that means establishing a way of communicating that everyone is comfortable with.</p>



<p>Most teams turn to <a href="https://slack.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Slack</a>, but Slack is not always the best tool for the job. If your team puts emphasis on project management, for instance, using digital Kanban tools with built-in chat feature can be more effective and other communication tools such as Google Mail with Google Chat and Meet integrations are helpful. Microsoft has a similar suite of tools if you’re inclined to that choice of software.&nbsp;</p>



<p>To further empower team members, integrate a good task management platform. There is no way to keep track of everything when team members have to organize their tasks individually. The easier way to establish a baseline for remote working is by using a project or task management tool that turns tasks into blocks waiting to be managed such as <a href="https://trello.com/en" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Trello,</a> <a href="https://asana.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Asana</a> or <a href="https://basecamp.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Basecamp</a>.</p>



<p>Lastly, encourage team members to create a productive environment that works for them. Some startups and corporations are starting to provide team members with aids to help them set up a more comfortable and functional home office. This is the kind of initiative that puts team members in the right mindset for effective remote working.</p>



<h2>Meetings and Discussions</h2>



<p>The next thing to tackle is how meetings are set up. Even when working in the office, meetings are very distracting when they are not planned properly. Too many meetings will prevent team members from completing their tasks. Too few meetings could result in the team not having clear⁠—and mutual⁠—directions and common objectives.</p>



<p>With remote working, however, limiting the number of ad-hoc, on-demand meetings is highly recommended. Meetings need to be scheduled beforehand and team members must utilize the provided communications channels⁠—such as groups in Google Chat⁠—to discuss other work-related matters.</p>



<p>Scheduling daily standups that are not too long at the beginning of every day is also a good idea. The daily standup doesn’t just function as an opportunity for everyone to stay up to date with what the rest of the team is doing, but also as an opportunity to provide moral support for each other. As mentioned before, working remotely is not easy for everyone.</p>



<p>Set aside one or two days during which team members can focus entirely on the tasks in hand. For instance, you can have Thursday and Friday free of meetings and other distractions. This will allow all team members to prepare for Thursday-Friday sprints of their own since they already know what tasks they need to finish and can plan for the two days better.</p>



<p>Speaking of planning, it is also recommended to have a predetermined timeframe for sprints. Anything shorter than six weeks⁠—but longer than two⁠—is usually ideal, but ask your team for feedback on how to compose it to determine the best way to organize sprints that work for you all. Don’t hesitate to collaborate on best practices for remote working with team members to facilitate a solution that works for everyone involved. It’s a great way to get buy in at every level.</p>



<h2>Boost Engagement</h2>



<p>That last part is important on its own. When working remotely, employee engagement becomes a crucial component. You cannot have the progress of the team hindered by one or two disengaged team members. This is where some adjustments to how you (and other members of the team) communicate become very important.</p>



<p>For starters, forget about tracking time. Switch to a result-oriented approach and let team members worry about managing their own time. At the same time, provide team members with resources that will help them manage their time better, such as the digital Kanban board mentioned earlier. Anything that helps organize tasks in a transparent way helps.</p>



<p>Next, throw micromanagement out the window. There is no way you can micro-manage team members when everyone is working remotely. Trying to do so will only disrupt the internal flow and reduce the effectiveness of the team. Instead, allow everyone to be more involved in the tasks that they are interested in the most.</p>



<p>Transparency of workloads will encourage team members to also be even more engaged. With tasks and workloads monitored closely, team members are more likely to offer help to others when their own tasks are finished. There will be a growing awareness of the mutual objectives that the team is trying to achieve.</p>



<h2>Manage Time</h2>



<p>Of course, remote working relies heavily on the ability of every team member to manage time, and there are several things you can do to encourage good time management. You can start by supporting team members to prioritize the tasks in hand accordingly. Motivation and acknowledgment are key components in the procesto.</p>



<p>More importantly, encourage team members to embrace a work-life balance. Working remotely doesn’t mean working all the time; and trying to push team members to do so will only reduce their productivity. By encouraging the team to have fun and focusing more on the results they deliver, you can facilitate time management improvement in a more positive way.</p>



<p>That’s it! Remote working is a challenge for some teams, but the tips we discussed in this article will help you transition into a remote-first organization in time.</p>



<hr>



<p><a href="http://www.caylent.com/" target="_blank" rel="noreferrer noopener">Caylent</a>&nbsp;provides a critical DevOps-as-a-Service function to high growth companies looking for expert support with Kubernetes, cloud security, cloud infrastructure, and CI/CD pipelines. Our managed and consulting services are a more cost-effective option than hiring in-house, and we scale as your team and company grow. Check out some of the use cases, learn how we work with clients, and read more about our<a href="https://caylent.com/devops-as-a-service/" target="_blank" rel="noreferrer noopener">&nbsp;DevOps-as-a-Service offering</a>.</p>
                     
	                        </div>
	                    </section>
	                </article></div>]]>
            </description>
            <link>https://caylent.com/remote-teams-and-good-time-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660510</guid>
            <pubDate>Fri, 02 Oct 2020 08:47:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I can't write a JavaScript for loop, and it does not matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660465">thread link</a>) | @slorber
<br/>
October 2, 2020 | https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj | <a href="https://web.archive.org/web/*/https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I've been using JavaScript daily for 7 years, and I'm not able to remember the syntax of a JavaScript for loop.</p>
<p>Despite this fact, I'm a rather successful freelance developer. Recently I even had the awesome opportunity to work for Facebook, as the <a target="_blank" href="https://github.com/facebook/docusaurus/issues/2336">Docusaurus lead maintainer</a>, writing the code for the framework that powers the documentation sites of Babel, Prettier, Jest, ReactNative...</p>
<p>I'll explain why I'm not able to remember such syntax, and why it does not matter much.</p>
<hr>

<p><strong>TLDR</strong>: I'm a functional programmer</p>
<p>I've really started programming at the beginning of my engineer degree, around 2004 (before that, I was only able to hack some scripts for Counter-Strike console or IRC).</p>
<p>Most of our school teaching was based on Java, but we also saw a bit of C, C++, OCaml. </p>
<p>The first loop syntax I learned probably looked like this one:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numbers.length; i++) {
   System.out.println(numbers.get(i));
}
</code></pre>
<p>Before I came out of school, Java 6 brought some new, simpler syntax:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (Integer number : numbers) {
   System.out.println(number);
}
</code></pre>
<p>At my first job, the <a target="_blank" href="https://github.com/google/guava">Google Guava</a> lib brought some new verbose functional syntax to Java, and I was able to do weird things with it 😅.</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

Lists.newArrayList(Collections2.transform(numbers, <span>new</span> Function&lt;Integer,Void&gt;() {
  <span>@Override</span>
  <span><span>public</span> Void <span>apply</span><span>(Integer number)</span> </span>{
    System.out.println(number);
    <span>return</span> <span>null</span>;
  }
}));
</code></pre>
<p>This Guava lib got me intrigued by functional programming, and lead me to become a Scala developer since 2012, and I was finally able to use functional programming concepts (loops, but not only) without the ugly Java/Guava syntax.</p>
<pre><code>val numbers = List(1, 2, 3)
numbers.foreach(println)
</code></pre>
<p>In 2013, <a target="_blank" href="https://reactjs.org/blog/2013/06/05/why-react.html">ReactJS came out</a>, and this totally changed my career path. At this time, I didn't like JavaScript much and was only able to hack some inline JQuery things in server-rendered pages. But as a startup CTO, I saw my team struggle with architecture, BackboneJS and RequireJS, and thought I had to become better at frontend to lead them.</p>
<p>AngularJS looked like the safer choice at this time, but a Scala developer colleague really pushed for React, which looked fancy and risky. All things made sense with the visionary post of David Nolen (<a target="_blank" href="https://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/">The Future of JavaScript MVC Frameworks</a>), and we finally adopted React in January 2014, as it seemed we would be able to use our functional programming knowledge to the frontend app as well, and make the UI more predictable.</p>
<p>Fast forward, it wasn't easy to be a React early-adopter for our critical app. All companies were building their own state management solution, trying to figure things out, <a target="_blank" href="https://github.com/stample/atom-react">and so we did</a>, based on the ideas of David Nolen to hold a single immutable state in an atom (I was able to get a <a target="_blank" href="https://www.youtube.com/watch?v=zxN8FYYBcrI">hacky time-travel working</a> before Redux). </p>
<p>Since then both the JavaScript language and the ReactJS ecosystem have progressed a lot, and it's very common to use functional programming principles nowadays.</p>

<p>As a long-time functional programmer, <strong>I simply don't write for loops</strong> very often. </p>
<p>Like anything you don't use regularly, you end up forgetting the syntax.</p>
<p>Today, many of us use ES5+ syntax (or Lodash/Ramda...) and some functional constructs. Using <code>map</code>, <code>forEach</code>, <code>filter</code> are the most illustrated examples in the JS community.</p>
<pre><code><span>const</span> numbers = [<span>1</span>, <span>2</span>, <span>3</span>]
numbers.forEach(<span><span>number</span> =&gt;</span> <span>console</span>.log(number));
</code></pre>
<p>But we can go much further than that once we are more experienced with functional programming, and almost never write any for loops anymore. </p>
<p>Don't get me wrong, it's not necessarily a goal to not write for loops anymore, and I'm not telling you that you should remove all for loops of your production codebase.</p>
<p>Very often there's an alternative syntax possible for your loops that might be more expressive and easier to understand. After a while, you end up seeing a for loop as an implementation detail of a more elegant functional abstraction.</p>
<p>This more expressive syntax is not only for loops, and you can as well see a functional abstraction being an implementation detail of another higher-level abstraction.</p>
<p>Let's consider we want to increment the age of 2 brothers.</p>
<pre><code><span>const</span> brothers = {
  <span>id1</span>: {<span>name</span>: <span>"Sébastien"</span>, <span>age</span>: <span>34</span>},
  <span>id2</span>: {<span>name</span>: <span>"Antoine"</span>, <span>age</span>: <span>23</span>}
};
</code></pre>
<p>I very often see the <code>array.reduce()</code> operator used when a more expressive alternative was possible.</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
    .reduce(<span>(<span>acc,[id,brother]</span>) =&gt;</span> {
      acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
      <span>return</span> acc;  
    },{})
}
</code></pre>
<p>You know what? <strong>I really struggled to write this code</strong>. </p>
<p>My first attempt was not working at all (TypeScript would have helped).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
      
      .reduce(<span>(<span>[id,brother],  acc</span>) =&gt;</span> {
        acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
        
      },{});
}
</code></pre>
<p>Yet, writing this kind of transform is idiomatic for me, using higher-level functional programming abstractions, such as <code>mapValues</code> (included in lodash).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> mapValues(
    brothers, 
    <span><span>brother</span> =&gt;</span> ({...brother, <span>age</span>: brother.age + <span>1</span>})
  );
}
</code></pre>
<p>And I think nobody would argue that this is harder to read and maintain right? If junior developers are not familiar with functional programming, they'll catch up fast and get used to it. This might even be harder to learn <code>reduce</code>.</p>

<p>I don't write for loops (or <code>reduce</code>), but I know the concepts. I know that these loops exist in different syntaxes, that can be useful for different use cases, and how to make a choice with a good tradeoff (performance, readability...).</p>
<p>I'll illustrate this with a concrete example from my daily work that actually led me to write this article.</p>
<p>I had this async function that performs some long task for a given country.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runCountryTask</span>(<span>country</span>) </span>{

  
  <span>const</span> taskDuration = <span>1000</span> + <span>Math</span>.random() * <span>4000</span>;
  <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, taskDuration));

  <span>console</span>.log(<span>`Task completed for <span>${country}</span>`</span>);
}
</code></pre>
<p>This task had to be run for many countries, but the tasks should be run sequentially, not in parallel.</p>
<p>As I know the concepts, and I knew that the following would not work, as <code>Promise.all</code> would run all tasks in parallel.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> <span>Promise</span>.all(countries.map(runCountryTask))
}
</code></pre>
<p>I also knew that there were multiple possible solutions to solve this problem:</p>
<ul>
<li>use a third-party dependency exposing the higher-level async primitive I need</li>
<li>use <code>Promise.then()</code> recursively</li>
<li>use async/await, using a for loop syntax to iterate over a fixed-size array</li>
</ul>
<p>I didn't want to introduce a new third party dependency just for a tiny utility function. </p>
<p>I also knew that using <code>Promise.then()</code> recursively could be harder to read, write, and maintain. There are many ways to write such a recursion, one of them could be:</p>
<pre><code><span>async</span> <span><span>function</span> <span>forEachAsyncSequential</span>(<span>array, asyncFn</span>) </span>{
  <span>await</span> array.reduce(<span>(<span>acc, item</span>) =&gt;</span> {
    <span>return</span> acc.then(<span>() =&gt;</span> asyncFn(item))
  }, <span>Promise</span>.resolve());
}
</code></pre>
<p>So I opted for a basic for loop, as it seemed the right tradeoff. </p>
<p>As I'm totally unable to remember the syntax (<code>in</code> vs <code>of</code>, can I actually use <code>const</code>?), I had to actually google it, and it didn't take me long to be able to write the TypeScript code that will be shipped in production.</p>
<pre><code><span>export</span> <span>async</span> <span><span>function</span> <span>forEachAsyncSequencial</span>&lt;<span>T</span>&gt;(<span>
  array: T[],
  asyncFn: (t: T) =&gt; <span>Promise</span>&lt;<span>void</span>&gt;,
</span>): <span>Promise</span>&lt;<span>void</span>&gt; </span>{
  <span>for</span> (<span>const</span> item <span>of</span> array) {
    <span>await</span> asyncFn(item);
  }
}
</code></pre>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> forEachAsyncSequencial(countries, runCountryTask);
}
</code></pre>
<p>Believe me or not, but I think It's the only for loop I actually wrote in JavaScript this year. And once it's written, I won't need to write it ever again (at least for this project), as it's now part of my functional programming abstractions, that I can reuse anywhere I need.</p>
<p><a target="_blank" href="https://jsfiddle.net/y17c6et8/1/">JsFiddle playground</a></p>
<hr>

<p>It's not very important to remember every syntax details to be productive in your daily work, particularly when you don't use them often (on purpose), as you prefer to work with more expressive, higher-level abstractions. </p>
<p>I had to google many things to write this article:</p>
<ul>
<li>Syntax for declaring a Java list</li>
<li>Syntax for iterating a Java list</li>
<li>Does <code>System.out.println</code> accept an Integer?</li>
<li>Syntax for Scala string interpolation</li>
<li>Is there a <code>forEach</code> in Guava (actually found <a target="_blank" href="https://stackoverflow.com/questions/38251257/guava-iterators-for-nested-foreach">my own StackOverflow question</a>)</li>
<li>What are the possible syntaxes for iterating over a JavaScript array</li>
<li>Signature of <code>array.reduce()</code></li>
</ul>
<p>Not remembering all this does not matter much, as long as I know what to look for.</p>
<p>In the same way, I don't know much about many other JavaScript things:</p>
<ul>
<li>prototypes: I think I never hard to use them directly in my entire life, and I'm fine</li>
<li>classes: used them temporarily when I really had to in React</li>
<li>JavaScript quirks: I know some of them, but simply avoid the others by using ESLint, <code>===</code>, TypeScript... it's not worth knowing all of them</li>
<li>...</li>
</ul>
<p>The knowledge and concepts you learn are more easily transposable from one language to another. I was able to learn React and contribute to its ecosystem quickly, thanks to my functional programming background. </p>
<p>I would argue that knowing how to do a recursive algorithm is more important than knowing the syntax of a for loop of a particular language. You will likely write many recursive algorithms in your career: the concept of recursion is not going anywhere anytime soon. But it's way more likely that you switch from one language to another from time to time. </p>
<p>Hopefully, writing this post will help me remember the syntax for a while until I forget it again 🤪.</p>
<hr>
<p>🙏 If you like this post, please like it, share it or comment it 🙏: </p>
<ul>
<li><a target="_blank" href="https://twitter.com/sebastienlorber/status/1311948662843551744">Tweet</a></li>
<li><a target="_blank" href="https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">Hashnode</a></li>
<li><a target="_blank" href="https://dev.to/sebastienlorber/i-can-t-write-a-javascript-for-loop-and-it-does-not-matter-11jb">Dev</a></li>
<li><a target="_blank" href="https://www.reddit.com/r/javascript/comments/j3r08h/i_cant_write_a_javascript_for_loop_and_it_does/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/item?id=24660465">HackerNews</a></li>
</ul>
<p>For more content like this, subscribe to <a target="_blank" href="https://mailchi.mp/4ea4df0b54f7/sebastienlorber">my mailing list</a> and follow me on <a target="_blank" href="https://twitter.com/sebastienlorber">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660465</guid>
            <pubDate>Fri, 02 Oct 2020 08:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flicker free fireworks (or how I accidentally rediscovered the regen buffer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660412">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://blog.darrien.dev/posts/flicker-free-fireworks/ | <a href="https://web.archive.org/web/*/https://blog.darrien.dev/posts/flicker-free-fireworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>In <a href="https://blog.darrien.dev/posts/fireworks-for-your-terminal/">my last post</a> I talked about
how I made a enjoyable little display of
<a href="https://gitlab.com/darrieng/term-fireworks">fireworks</a> for the terminal. It was
fun to make and it’s fun to watch when meetings get boring (always).</p>
<p><a href="https://gitlab.com/DarrienG/term-fireworks">Fireworks can be found here.</a></p>
<p>However after running my fireworks for a while, I started noticing some funky
details. The fireworks could be a little flickery at times. And not in a good
way.</p>
<p>Well we couldn’t have that! So it was time to investigate.</p>
<h2 id="what-do-the-flickers-mean-mason">What do the flickers mean Mason?<a href="#what-do-the-flickers-mean-mason" arialabel="Anchor">⌗</a> </h2>
<p>The first thing I noticed was this wasn’t a problem on Linux, it only happened
on macOS.</p>
<p>I do most of my development on a beefy Linux machine with 6 real cores (12 total
threads) and figured perhaps this was just a specs thing, so I fired up my 7
year old ThinkPad running CentOS and still didn’t have flickering. Compared to
my 2019 work MacBook, it was smooth as butter. Could this be a Mac only bug?</p>
<p>On a whim I remembered how iTerm is not the fastest terminal in the world and
decided to try my fireworks on the slowest terminal I could think of. The WSL
terminal.</p>
<p>I broke out my old Windows machine and after a half an hour, got WSL and
fireworks up and running. The result:</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/flicker.webp" alt="flickering in action"></p>
<p>The Windows terminal running WSL exhibited the same behaviors as on macOS, but
much more frequently and much more consistently. This lead me to believe that
the problem was in drawing. I must not be doing it efficiently. Other terminal
applications can run flicker free in Windows terminal, so why not me too?</p>
<h2 id="the-old-firework-rendering-pipeline">The old firework rendering pipeline<a href="#the-old-firework-rendering-pipeline" arialabel="Anchor">⌗</a> </h2>
<p>The old rendering pipeline was very simple. It used two total threads, one for
input, and one for all rendering work. This is a simple approximation of it:</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/renderer-v1.png" alt="renderer-v1"></p>
<p>If you look at this for long enough, you’re going to see some low hanging fruit
to optimize away.</p>
<ul>
<li>we’re making fireworks on the same thread we draw points</li>
<li>we’re clearing way more points than we need to</li>
<li>we’re drawing way more points than we need to</li>
</ul>
<p>Let’s dig into each one individually.</p>
<h3 id="were-making-fireworks-on-the-same-thread-we-draw-points">we’re making fireworks on the same thread we draw points<a href="#were-making-fireworks-on-the-same-thread-we-draw-points" arialabel="Anchor">⌗</a> </h3>
<p>The <em>maybe generate new firework</em> and <em>advance fireworks one step</em> happens
before drawing every single time. In order to keep a consistent framerate, this
would have to be completed in a fraction of a fraction of a second. I’ve done my
best to optimize this as much as possible, but especially with the more exciting
fireworks I plan on adding later, this won’t be possible in the future.</p>
<p>Firework generation and advancing should happen on another thread.</p>
<h3 id="were-clearingdrawing-more-points-than-we-need-to">we’re [clearing|drawing] more points than we need to<a href="#were-clearingdrawing-more-points-than-we-need-to" arialabel="Anchor">⌗</a> </h3>
<p>The painting implementation is dumb as rocks, and simply:</p>
<ul>
<li>creates a list of every single point to be drawn</li>
<li>creates a list of every single point to be cleared</li>
</ul>
<p>This means on each loop, we draw points that were already on the screen, and
clear points just to have them repainted shortly after.</p>
<p>Drawing is easily the slowest part of the application, so that’s not good at
all.</p>
<h2 id="how-do-we-deal-with-this">How do we deal with this?<a href="#how-do-we-deal-with-this" arialabel="Anchor">⌗</a> </h2>
<p>Given our two problems, I felt it would make the most sense to move as much of
the actual firework building work to another thread. While overkill for how
we’re currently figuring out the points we need to draw fireworks, if we move
the work to another thread we’ll have time for all of the set logic required to
only draw and clear the points that have changed.</p>
<h2 id="the-new-architecture">The new architecture<a href="#the-new-architecture" arialabel="Anchor">⌗</a> </h2>
<p>The new architecture revamps a few things, but mostly just moves them around
with the addition of a new compositor component.</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/renderer-v2.png" alt="renderer-v2"></p>
<p>The compositor runs in a separate thread and sets up all the points required for
all of the fireworks ahead of time.</p>
<p>Originally when planning up this v2 architecture I was only going to prep one
frame of fireworks at a time, but then I figured, why do just one? Why not get
a few ready ahead of time?</p>
<p>Rust has
<a href="https://doc.rust-lang.org/std/sync/mpsc/fn.sync_channel.html">sync_channel</a>s
which easily lets you do this. Set the max buffer size and it won’t insert more
than that. For my Java folks out there, it’s conceptually similar to a
<a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingQueue.html">LinkedBlockingQueue</a>
for sharing data across threads.</p>
<h2 id="its-just-a-regen-buffer">It’s just a regen buffer<a href="#its-just-a-regen-buffer" arialabel="Anchor">⌗</a> </h2>
<p>At this point I was thinking myself very clever for coming up with such a new
innovative idea. Imagine what others will think when I tell them about this cool
new concept of async rendering!</p>
<p>I put my head down and tried to think of all of the other applications that
might find this technique useful, only to realize… a lot of other applications
already did something like this.</p>
<p>Distraught but still hopeful I had “really done something” I Google’d around
only for my hope to meet its demise on the <a href="https://en.wikipedia.org/wiki/Framebuffer">framebuffer wikipedia
page</a>.</p>
<blockquote>
<p>In computing, a screen buffer is a part of computer memory used by a computer
application for the representation of the content to be shown on the computer
display. The screen buffer may also be called the video buffer, the
regeneration buffer, or regen buffer for short. Screen buffers should be
distinguished from video memory. To this end, the term off-screen buffer is also
used.</p>
</blockquote>
<p>Well so much for that.</p>
<h2 id="implementation">Implementation<a href="#implementation" arialabel="Anchor">⌗</a> </h2>
<p>This post would be no fun without a bit of discussing how it was made. We can
spend all day in the ivory tower talking about architecture, but entering the
trenches and actually writing the code is a little different.</p>
<h3 id="channel-setup">Channel setup<a href="#channel-setup" arialabel="Anchor">⌗</a> </h3>
<p>If you look at the <a href="https://blog.darrien.dev/posts/flicker-free-fireworks/#the-new-architecture">v2 architecture diagram</a> you’ll
see there are 3 components now. I wanted to give them all a chance to shut down
completely, so the component accepting input now takes a list of senders it will
send <em>request to kill signals</em> to.</p>
<p>Likewise, we need to set up the buffer for which we can send fireworks to the
renderer. This is all done like so:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
  <span>let</span> (input_sender_1, input_receiver_1): (Sender<span>&lt;</span><span>bool</span><span>&gt;</span>, Receiver<span>&lt;</span><span>bool</span><span>&gt;</span>) <span>=</span> mpsc::channel();
  <span>let</span> (input_sender_2, input_receiver_2): (Sender<span>&lt;</span><span>bool</span><span>&gt;</span>, Receiver<span>&lt;</span><span>bool</span><span>&gt;</span>) <span>=</span> mpsc::channel();

  <span>let</span> (regen_buffer_filler, regen_buffer): (SyncSender<span>&lt;</span>Drawables<span>&gt;</span>, Receiver<span>&lt;</span>Drawables<span>&gt;</span>) <span>=</span>
    mpsc::sync_channel(<span>5</span>);

  <span>let</span> <span>mut</span> stdout <span>=</span> stdout()
    .into_raw_mode()
    .expect(<span>"Unable to capture stdout. Exiting."</span>);

  <span>// all internal modules in fireworks
</span><span></span>  input::capture(vec<span>!</span>[input_sender_1, input_sender_2]);
  compositor::start(seed, regen_buffer_filler, input_receiver_2);
  renderer::start(<span>&amp;</span><span>mut</span> stdout, regen_buffer, input_receiver_1);
}
</code></pre></div><p>A design decision I made here was to not have the compositor be spawned by the
renderer. I didn’t want the renderer to know anything about the compositor, just
that it will receive <code>Drawables</code> from some magic buffer. Who knows what’s
filling it!</p>
<h3 id="input-capturer">Input capturer<a href="#input-capturer" arialabel="Anchor">⌗</a> </h3>
<p>This barely changes and isn’t really isn’t worth talking about. <a href="https://gitlab.com/DarrienG/term-fireworks/-/blob/168c80689612cee5442e92b4f30b2b5a5bfabe78/src/input.rs">It has now been
upgraded from an 18 line file to a 20 line
file.</a></p>
<p>Poor input capturer; perhaps you’ll get a longer section in the future.</p>
<h3 id="renderer">Renderer<a href="#renderer" arialabel="Anchor">⌗</a> </h3>
<p>The
<a href="https://gitlab.com/DarrienG/term-fireworks/-/blob/168c80689612cee5442e92b4f30b2b5a5bfabe78/src/renderer.rs">renderer</a>
changes in a few exciting ways, the most exciting in that it is gutted. No
longer does it spin up a firework state machine to get Drawables, now it just
waits at a channel, lonely and blocking until it gets some input.</p>
<div><pre><code data-lang="rust"><span>let</span> to_draw <span>=</span> regen_buffer.recv().expect(<span>"Compositor unexpectedly died!"</span>);
</code></pre></div><p>Otherwise the renderer is the same. The goal of the renderer is to be as dumb as
possible and it is certainly achieving that.</p>
<h3 id="compositor">Compositor<a href="#compositor" arialabel="Anchor">⌗</a> </h3>
<p>Finally the compositor, which is 30 or so lines that really come down to:
ticking the state machine and sending the points it made somewhere.</p>
<div><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>compositor_loop</span>(
  seed: <span>u64</span>,
  regen_buffer_filler: <span>SyncSender</span><span>&lt;</span>Drawables<span>&gt;</span>,
  end_signal: <span>Receiver</span><span>&lt;</span><span>bool</span><span>&gt;</span>,
) {
  <span>let</span> <span>mut</span> state_machine <span>=</span> state_machine::StateMachine::new(seed, terminal_width());

  <span>loop</span> {
    <span>let</span> drawables <span>=</span> state_machine.tick(terminal_width());
    <span>if</span> regen_buffer_filler.send(drawables).is_err() {
      panic<span>!</span>(<span>"Renderer unexpectedly died!"</span>);
    }
    <span>if</span> <span>let</span> Ok(v) <span>=</span> end_signal.try_recv() {
      <span>if</span> v {
        <span>return</span>;
      }
    }
  }
}
</code></pre></div><p>And that’s it for the new architecture components!</p>
<h3 id="so-then-where-are-all-the-code-changes">So then where are all the code changes??<a href="#so-then-where-are-all-the-code-changes" arialabel="Anchor">⌗</a> </h3>
<p>There are only a few. Really, the bulk of the work was in architectural changes.</p>
<p>The final changes, the ones that affect drawing are in the firework itself. We
can do a whole lot more work now that we can work in a separate thread, and so
the Drawable trait we worked with in the previous post goes from:</p>
<div><pre><code data-lang="rust"><span>impl</span> Drawable <span>for</span> TailPoints {
  <span>fn</span> <span>draw</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span>[Point] {
    <span>&amp;</span>self.tail
  }
  <span>fn</span> <span>clear</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span>[Point] {
    <span>&amp;</span>self.old_tail
  }
}
</code></pre></div><p>to:</p>
<div><pre><code data-lang="rust"><span>impl</span> Drawable <span>for</span> TailPoints {
  <span>fn</span> <span>draw</span>(<span>&amp;</span>self) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
    difference(<span>&amp;</span>self.tail, <span>&amp;</span>self.old_tail)
  }
  <span>fn</span> <span>clear</span>(<span>&amp;</span>self) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
    difference(<span>&amp;</span>self.old_tail, <span>&amp;</span>self.tail)
  }
}


<span>fn</span> <span>difference</span>(points_1: <span>&amp;</span>[Point], points_2: <span>&amp;</span>[Point]) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
  <span>let</span> set_1 <span>=</span> points_1.iter().cloned().collect::<span>&lt;</span>HashSet<span>&lt;</span>Point<span>&gt;&gt;</span>();

  <span>let</span> set_2 <span>=</span> points_2.iter().cloned().collect::<span>&lt;</span>HashSet<span>&lt;</span>Point<span>&gt;&gt;</span>();
  set_1.difference(<span>&amp;</span>set_2).cloned().collect()
}
</code></pre></div><p>Looking at the two, you’ll see the first is infinitely faster and also does
infinitely fewer allocations. And that’s how it was meant to be! As Drawables
had to be ready in real time, the implementation had to be fast as lightning.
But now they can take a little longer and do a lot more work. With async
rendering, they can do (roughly) as much work as they like and still be real
time!</p>
<p>All this extra work affords us some really slick optimizations. Post work we:</p>
<ul>
<li>paint exactly what has changed and nothing else</li>
<li>clear exactly what needs to disappear and nothing else</li>
</ul>
<p>These two things optimizations vastly increase the speed of drawing fireworks.</p>
<h2 id="downsides">Downsides<a href="#downsides" arialabel="Anchor">⌗</a> </h2>
<p>Well there is one, and if a point is ever drawn over and then cleared, it will
never be redrawn, meaning there can occasionally be small holes in the
fireworks. Something like this happens when two fireworks collide.</p>
<p>Solving this wouldn’t be too hard, but the fireworks still look pretty nice and
I think the asymmetrical nature of ones with little holes gives them some
character.</p>
<h2 id="so-was-it-all-worth-it">So was it all worth it?<a href="#so-was-it-all-worth-it" arialabel="Anchor">⌗</a> </h2>
<p>Well I’ll let the results speak for themself.</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/results.webp" alt="results"></p>
<p>Thanks for reading! If you liked this post, feel free to check out my blog posts
about the silly CLIs I made using rust :)</p>
<p>Fireworks source and binaries can be found
<a href="https://gitlab.com/DarrienG/term-fireworks">here</a>.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.darrien.dev/posts/flicker-free-fireworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660412</guid>
            <pubDate>Fri, 02 Oct 2020 08:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What (not so) recently happened in Miri]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660216">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://www.ralfj.de/blog/2020/09/28/miri.html | <a href="https://web.archive.org/web/*/https://www.ralfj.de/blog/2020/09/28/miri.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="-content">
      <header>
    
    
</header>

<p>A lot has happened in Miri over the last year and a half, and I figured it would be a good idea to advertise all this progress a bit more widely, so here we go.
We also recently performed a breaking change that affects some CI configurations, so this post serves as an announcement for you to update your CI configuration if needed.</p>

<p>For the uninitiated, <a href="https://github.com/rust-lang/miri/">Miri</a> is an interpreter that runs your Rust code and checks if it triggers any <a href="https://doc.rust-lang.org/reference/behavior-considered-undefined.html">Undefined Behavior</a>.
You can think of it a as very thorough (and very slow) version of valgrind: Miri will detect when your program uses uninitialized memory incorrectly, performs out-of-bounds memory accesses or pointer arithmetic, violates key language invariants, does not ensure proper pointer alignment, or causes incorrect aliasing.
As such, it is most helpful when writing unsafe code, as it aids in ensuring that you follow all the rules required for unsafe code to be correct and safe.
Miri also detects memory leaks, i.e., it informs you at the end of program execution if there is any memory that was not deallocated properly.</p>

<!-- MORE -->

<p>However, being an interpreter, Miri is limited in the kinds of code it can execute – everything that would usually involve interacting with C libraries or the operating system needs to be specifically supported, as C code cannot be interpreted by Miri.
Miri also lacks support for some Rust features that are hard to interpret, but we are slowly closing these gaps.</p>

<h2 id="recent-and-past-progress-in-miri">Recent and past progress in Miri</h2>

<p>During the last 1.5 years, thanks to a series of excellent contributors, we made a lot of progress towards supporting more and more Rust code to run in Miri.
I am going to list some highlights below.</p>

<p>If you want to learn how to use Miri yourself, scroll down to the end of this post.
If you are using Miri already, maybe you are still passing flags like <code>--exclude-should-panic</code> or disabling tests that require concurrency; you should be able to update those flags now.
Also note the breaking change in how <code>cargo miri</code> interprets CLI arguments below!</p>

<h3 id="randomness-and-hashmap">Randomness and <code>HashMap</code></h3>

<p>The Rust <code>HashMap</code> picks a new random seed for each execution.
This seed in obtained from the operating system, an operation which Miri did not support until @Aaron1011 implemented <code>getrandom</code> (<a href="https://github.com/rust-lang/miri/pull/683">#683</a>).
To ensure the same programs behaves the same way each time it is run by Miri, Miri internally uses a deterministic RNG (seeded with <code>0</code>, but that can be changed via <code>-Zmiri-seed</code>) to implement getrandom.
This PR also enabled Miri to be used with projects that use the <code>rand</code> crate for randomness.</p>

<p>However, this also means randomness in Miri is actually not random, so <em>do not use Miri to perform any important cryptographic operations</em>.</p>

<h3 id="unwinding">Unwinding</h3>

<p>Miri used to just abort program execution in case of a panic.
To better match the behavior of real Rust programs, @Aaron1011 implement proper unwinding support in Miri (<a href="https://github.com/rust-lang/miri/pull/693">#693</a>).
He even implemented catching panics again, which required aligning quite a few pieces across rustc, the standard library, and Miri itself.
This means Miri can finally also execute <code>#[should_panic]</code> tests.
Since recently, this is supported even for Windows targets.</p>

<h3 id="pointer-integer-casts">Pointer-integer casts</h3>

<p>Thanks to @christianpoveda, Miri now properly supports casting arbitrary pointers to integers and back (<a href="https://github.com/rust-lang/miri/pull/779">#779</a>).</p>

<p>Recently, I also adjusted the alignment check to fully take this information into account, so that Miri can now run code that performs its own alignment logic (<a href="https://github.com/rust-lang/miri/pull/1513">#1513</a>).
Notice however that this can lead to code that just happens to work by pure chance; to properly test such code, the test should be run at least 10 times.</p>

<h3 id="file-system-access">File system access</h3>

<p>@christianpoveda went on to implement file system access (this series of PRs started with <a href="https://github.com/rust-lang/miri/pull/962">#962</a>).
Later, @divergentdave improved that support with directory listing and some related operations (starting with <a href="https://github.com/rust-lang/miri/pull/1152">#1152</a>).
This means programs running in Miri can now read from and write to files on the host computer.
This is the first form of communication that we support between the interpreted program and the outside world.
Communication needs to be explicitly requested via <code>-Zmiri-disable-isolation</code>; by default, Miri isolates the program to ensure that each execution is perfectly reproducible.</p>

<p>File system access is only supported on Linux and macOS targets, but due to cross-interpretation this is not a problem even for Windows users – see the next point.</p>

<h3 id="cross-interpretation">Cross-interpretation</h3>

<p>Based on earlier work by @Aaron1011 who made Miri use check-only builds both for the standard library and the interpreted crate itself (<a href="https://github.com/rust-lang/miri/pull/1136">#1136</a>),
I made Miri support “cross-interpretation” (<a href="https://github.com/rust-lang/miri/pull/1249">#1249</a>).
This means even when you are on a Windows host, you can pass <code>--target x86_64-unknown-linux-gnu</code> so Miri will interpret the program <em>as if</em> it was running on Linux, in particular using all the Linux parts of the standard library for the interaction with the operating system.
Sine Miri supports the Linux APIs for file system access, it can interpret these programs even when running on a Windows host.</p>

<p>This is particularly useful when testing target features that differ from the host platform: for example, even on a 64bit macOS host, you can run programs for the 32bit Linux target (<code>--target i686-unknown-linux-gnu</code>), making sure your logic works for different pointer sizes.
Miri also supports big-endian targets like <code>--target mips64-unknown-linux-gnuabi64</code>, so if your code is endianess-sensitive, you can test if it behaves correctly on big-endian systems.
And finally cross-interpretation was enormously helpful for developing Miri itself; for example, I relied on this when fixing up our panic and unwinding support for Windows targets.</p>

<h3 id="concurrency">Concurrency</h3>

<p>Earlier this year, @vakaras surprised me by suddenly showing up with a series of patches that equip Miri with support for concurrency (<a href="https://github.com/rust-lang/miri/pull/1284">#1284</a>).
This is work he did during an internship with Amazon, so also thank you to Amazon for sponsoring this work!
Now Miri programs can spawn threads and interact via locks or atomics.
There are some caveats though: Miri does not detect data races, so programs with incorrect synchronization can cause Undefined Behavior through data races without Miri noticing.
Also Miri’s scheduler is rather crude, so programs can be stuck in infinite loops under some circumstances.</p>

<h3 id="better-cargo-compatibility-breaking-change">Better <code>cargo</code> compatibility (breaking change!)</h3>

<p>Recently, I mostly re-wrote the main entry point for users to execute programs in Miri, <code>cargo miri</code> (<a href="https://github.com/rust-lang/miri/pull/1540">#1540</a>).
It is now more compatible with cargo itself: <code>cargo test</code> and <code>cargo miri test</code> support the exact same flags, and likewise for <code>cargo run</code> and <code>cargo miri run</code>.</p>

<p>However, this required a breaking change: previously, the way to pass flags to Miri itself and the program when executing the test suite was <code>cargo miri test -- &lt;miri flags&gt; -- &lt;test suite flags&gt;</code>.
Now flags are passed via <code>cargo miri test -- &lt;test suite flags&gt;</code> like they are with <code>cargo test</code>; if you need to pass flags to Miri, you can set the <code>MIRIFLAGS</code> variable which works like <code>RUSTFLAGS</code>.
I also removed support for <code>cargo miri</code> without further arguments, which used to be an alias for <code>cargo miri run</code>.
The reason is that (a) <code>cargo miri test</code> is actually used much more frequently and (b) disambiguating these options while also supporting arbitrary flags is tricky.</p>

<p>If you have set up your CI to run tests in Miri, please make sure to adjust your configuration to the new format.
For now, Miri still supports the old style (and emits an appropriate warning), but the intention is to remove that support code eventually.
If your project is hosted on GitHub and is affected by the change, you should have already received a notification from me, but I might have missed some projects and of course not everything is on GitHub.
While at it, you can also remove <code>cargo miri setup</code> from your CI script; that is no longer needed as thanks to @dtolnay Miri automatically detects when it runs on CI and goes into non-interactive mode.</p>

<h3 id="-and-more">… and more</h3>

<p>This list is by far not exhaustive.
Many small functions, from trigonometry to environment variable access to timekeeping, have been implemented over the last months, ever growing the range of programs that Miri can execute.
Thank you to @Aaron1011, @christianpoveda, @divergentdave, @JOE1994, and @samrat!
I hope I did not miss anyone…</p>

<h2 id="using-miri">Using Miri</h2>

<p>If this post made you curious and you want to give Miri a try, here’s how to do that.
Assuming you have a crate with some unsafe code, and you already have a test suite (you are testing your unsafe code, right?), you can just install Miri (<code>rustup +nightly component add miri</code>) and then run <code>cargo +nightly miri test</code> to execute all tests in Miri (except for doctests, which are not supported yet).
Note that this requires the nightly toolchain as Miri is still an experimental tool.</p>

<p>Miri is very slow, so it is likely that some tests will take way too long to be feasible.
You can adjust iteration counts in Miri without affecting non-Miri testing as follows:</p>

<figure><pre><code data-lang="rust"><span>let</span> <span>limit</span> <span>=</span> <span>if</span> <span>cfg!</span><span>(</span><span>miri</span><span>)</span> <span>{</span> <span>10</span> <span>}</span> <span>else</span> <span>{</span> <span>10_000</span> <span>};</span></code></pre></figure>

<p>If your test suite needs to access OS facilities such as timers or the file system, set <code>MIRIFLAGS=-Zmiri-disable-isolation</code> to enable those.
(Miri will tell you when that is necessary.)
If your test suite runs into an unsupported operation, please <a href="https://github.com/rust-lang/miri/issues">report an issue</a>.</p>

<p>If you want to add Miri to your CI to ensure your test suite keeps working in Miri, please consult our <a href="https://github.com/rust-lang/miri/#running-miri-on-ci">README</a>.
That document is also a great starting point for any other questions you might have.</p>

<p>Miri is also integrated into the <a href="https://play.rust-lang.org/">Rust Playground</a>: you can select Miri in the “Tools” menu to check the code for Undefined Behavior.</p>

<p>If Miri complains about your code and you do not understand why, I am happy to help!
The best places to ask probably are Zulip (the #general stream seems fine), and the Miri issue tracker.
Asking publicly is strongly encouraged so other people can help answer the question, and everyone can learn from the responses.
Questions are much easier to answer if you manage to reproduce the problem in a small self-contained bit of example …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ralfj.de/blog/2020/09/28/miri.html">https://www.ralfj.de/blog/2020/09/28/miri.html</a></em></p>]]>
            </description>
            <link>https://www.ralfj.de/blog/2020/09/28/miri.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660216</guid>
            <pubDate>Fri, 02 Oct 2020 07:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress report on rustc_codegen_cranelift (Sep 2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660154">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html | <a href="https://web.archive.org/web/*/https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://github.com/bjorn3/rustc_codegen_cranelift">Rustc_codegen_cranelift</a> (cg_clif) is an alternative backend for rustc that I have been working on for the past two years. It uses the Cranelift code generator. Unlike LLVM which is optimized for output quality at the cost of compilation speed even when optimizations are disabled, Cranelift is optimized for compilation speed while producing executables that are almost as fast as LLVM with optimizations disabled. This has the potential to reduce the compilation times of rustc in debug mode.</p>

<p>I recently looked back at the <a href="https://hackmd.io/VnVX5bEHR268SDH4R7izLw">notes</a> for the <a href="https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/design.20meeting.202020-04-03.20compiler-team.23257/near/192806450">design meeting</a> (<a href="https://github.com/rust-lang/compiler-team/issues/257">meeting proposal</a>) about integrating cg_clif into rustc. I noticed that several of the challenges that needed to be solved have since been solved. Because of this I decided to give an overview of the achievements in the past six months and what the current challenges are.</p>



<h4 id="tada-building-rustc-tada">
<img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Building rustc <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">
</h4>

<p>Fixing an ABI incompatibility for proc-macros (see next section) combined with several small fixes to the 128bit support made it possible to compile rustc using cg_clif.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/743">#743</a>: Compile rustc using cg_clif</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/cd684e39e0d27513d21f15e7cc65273ec5883e1b">cd684e3</a>: Fix saturated_* intrinsics for 128bit ints</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/ef4186a85b4c9bd94d258e3280cb239f26b8436e">ef4186a</a>: Use Cranelift legalization for icmp.i128</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/8d639cd778bb11fed2c230d8071664e24d30a84f">8d639cd</a>: Test signed 128bit discriminants</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/e87651c3f23e6ad63cc1ee359115ad72e50d3ba9">e87651c</a>: Add test for SwitchInt on 128bit integers</li>
</ul>

<h4 id="abi-compatibility">ABI compatibility</h4>

<p>Proc-macro support has been implemented by fixing an ABI incompatibility.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1068">#1068</a>: Pass ByRef values at fixed stack offset for extern “C”</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/1559">wasmtime#1559</a>: SystemV struct arguments</li>
</ul>

<h4 id="inline-assembly">Inline assembly</h4>

<p>The new style <code>asm!</code> inline assembly and <code>global_asm!</code> have been implemented on Linux by compiling a separate object file using an assembler and linking the main object file for the codegen unit and the assembly object file together. On macOS linking both object files together gives a linker error. Linking both object files together is necessary as rustc expects a single object file for each codegen unit.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1062">#1062</a>: Implement global_asm! using an external assembler</li>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1064">#1064</a>: Basic inline asm support</li>
</ul>

<h4 id="simd">SIMD</h4>

<p>The cpuid x86 instruction is now emulated using code that pretends the current CPU is an Intel cpu with SSE and SSE2 support. This fixes ppv-lite86 and by extension c2-chacha and rand. It is not yet possible to use the inline assembly support as corearch uses <code>llvm_asm!</code> for the cpuid invocation. I didn’t implement this as it is currently being replaced with <code>asm!</code>.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1070">#1070</a>: Emulate cpuid</li>
</ul>

<p>Stdarch has been changed to use constify on all x86 intrinsics that use <code>rustc_args_required_const</code>. This was necessary to support <code>simd_insert</code> and <code>simd_extract</code> based intrinsics.</p>

<ul>
  <li>
<a href="https://github.com/rust-lang/stdarch/pull/876">stdarch#876</a>: Constify all x86 rustc_args_required_const intrinsics</li>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/669">#669</a>: Support simd_insert platform intrinsic</li>
</ul>

<h4 id="fixing-linking-with-lld-and-sysroot-and-executable-size">Fixing linking with lld and sysroot and executable size</h4>

<p>I assumed the sysroot and executables are much bigger for cg_clif than cg_llvm because of missing optimizations. While fixing linking with lld I discovered that for executables most of this is caused by per function sections not being used by cg_clif. Using this does significantly reduce the size of executables at the cost of significantly slowing down the linker. For this reason I put it behind the <code>CG_CLIF_FUNCTION_SECTIONS</code> env var.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1083">#1083</a>: Fix lld</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2212">wasmtime#2212</a>: Fix relocated readonly data in custom sections</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2218">wasmtime#2218</a>: cranelift-object: Support per function sections</li>
</ul>

<h4 id="unsized-locals">Unsized locals</h4>

<p>rust#77170 changed the MIR of <code>&lt;Box&lt;F&gt; as FnOnce&gt;::call_once</code> such that it doesn’t need an alloca anymore. 27a46ff removed the hack to workaround the missing alloca support for this.</p>

<ul>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/27a46ff765c26eab7b1e1f7d419cec8f5051df00">27a46ff</a>: Rustup to rustc 1.44.0-nightly (45d050cde 2020-04-21)</li>
  <li>
<a href="https://github.com/rust-lang/rust/pull/71170">rust#71170</a>: Make <code>Box&lt;dyn FnOnce&gt;</code> respect self alignment</li>
</ul>

<h4 id="rust-test-suite">Rust test suite</h4>

<p>There has been significant improvements on the amount of passing rustc tests with the previously mentioned #1068 fixing 82 tests. Except for abi incompatibilities all miscompilations seem to be fixed. There are some unimplemented features, but those are not very important for most use cases.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/381">#381</a>: Make rustc test suite pass</li>
</ul>



<h2 id="simd-1">SIMD</h2>

<p>Many intrinsics remain unimplemented.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/171">#171</a>: std::arch SIMD intrinsics</li>
</ul>

<h4 id="abi-compatibility-1">ABI compatibility</h4>

<p>There are many remaining ABI incomptibilities. I will need to rework cg_clif to reuse <code>rustc_target::abi::call::FnAbi</code>.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/10">#10</a>: C abi compatability</li>
</ul>

<h4 id="cleanup-during-stack-unwinding-on-panics">Cleanup during stack unwinding on panics</h4>

<p>Cranelift currently doesn’t have support for cleanup during stack unwinding.</p>

<ul>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/issues/1677">wasmtime#1677</a>: Support cleanup during unwinding</li>
</ul>

<h4 id="atomics">Atomics</h4>

<p>Atomic instructions are currently emulated using a global lock. This is very inefficient and only works when pthreads is available. The new style backend for Cranelift support native atomic instructions. There are several missing features before I can switch cg_clif to use the new style backends.</p>

<ul>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2077">wasmtime#2077</a>: Implement Wasm Atomics for Cranelift/newBE/aarch64.</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2149">wasmtime#2149</a>: This patch fills in the missing pieces needed to support wasm atomics…</li>
</ul>

<h4 id="windows-support">Windows support</h4>

<p>Various issues</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/977">#997</a>: Windows support</li>
  <li>branch <a href="https://github.com/bjorn3/rustc_codegen_cranelift/compare/wip_windows_support">wip_windows_support</a>
</li>
</ul>

<h4 id="git-subtree"><code>git subtree</code></h4>

<p>The plan for integration with rustc was to use <code>git subtree</code>. This git command currently has a bug for which a fix has not yet been upstreamed. It would be nice if for example <code>git submodule</code> could be used for the time being instead.</p>

<ul>
  <li>
<a href="https://github.com/rust-lang/rust-clippy/issues/5565">rust-clippy#5565</a>: git subtree crashes: can’t sync rustc clippy changes into rust-lang/rust-clippy</li>
  <li>
<a href="https://github.com/rust-lang/compiler-team/issues/270">compiler-team#270</a>: Integration of the Cranelift backend with rustc</li>
</ul>

<h4 id="maintenance">Maintenance</h4>

<p>While there have been several PR’s by other people like @osa1, @vi, @spastorino and @CohenArthur, I am the only person who has contributed more than a few changes to cg_clif.</p>

<ul>
  <li><a href="https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview">https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview</a></li>
</ul>



<p>The easiest way to help is by trying to compile and run any project and reporting any issues. You could also try to fix one of the above issues or any other issues in the issue tracker. They are not easy though. Contributing to Cranelift will also help with cg_clif.</p>



<p>I would like to thank each and every person that has supported me while working on cg_clif for the past 2 years. Whether by contributing, donating or simply mentioning cg_clif.</p>

<p>I would also like to thank @eddyb and @cfallin for reviewing a draft of this post.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660154</guid>
            <pubDate>Fri, 02 Oct 2020 07:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Google Collapsed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659499">thread link</a>) | @partingshots
<br/>
October 1, 2020 | https://dcj.dev/how-google-collapsed | <a href="https://web.archive.org/web/*/https://dcj.dev/how-google-collapsed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dcj.dev/how-google-collapsed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659499</guid>
            <pubDate>Fri, 02 Oct 2020 06:17:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659489">thread link</a>) | @lukastyrychtr
<br/>
October 1, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust introduces features that do not provide the same memory and
thread safety guarantees. This causes programs or libraries to be
susceptible to memory corruption (CWE-119)[8] and concurrency issues
(CWE-557)[9]. Modern C and C++ compilers provide exploit mitigations to
increase the difficulty to exploit vulnerabilities resulting from these
issues. Therefore, the Rust compiler must also support these exploit
mitigations in order to mitigate vulnerabilities resulting from the use of
Unsafe Rust. This post is going to document these exploit mitigations and
how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to “the Rust compiler” in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Yes (enabled when debug assertions are enabled, and disabled when debug assertions are disabled)
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) (via operating system default or specified allocator)
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">↩</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as “full ASLR”.</p>

<p>The Rust compiler supports position-independent executable, and enables it
by default since version 0.12.0 (2014-10-09)[10]–[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1. Checking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]–[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]–[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2. hello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3. Build and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4. Build and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">↩</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX’s
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as “No Execute (NX) Bit”,
“Execute Disable (XD) Bit”, “Execute Never (XN) Bit”, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]–[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5. Checking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">↩</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region—allowing arbitrary data in both to be overwritten using each
other—by reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as “stack probes” or “stack probing”.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]–[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as “partial RELRO”.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9. Checking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup, so all segments containing relocations can be marked …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659489</guid>
            <pubDate>Fri, 02 Oct 2020 06:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Software Foundation gives developers money for their first GNU contribution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659354">thread link</a>) | @protontypes
<br/>
October 1, 2020 | https://gnucode.me/make-money-contributing-to-gnu.html | <a href="https://web.archive.org/web/*/https://gnucode.me/make-money-contributing-to-gnu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So, the truth is that I and <a href="https://rednosehacker.com/">Jeremy Korwin</a> hate
having money.  It is really quite annoying.  We have decided to get rid of some
of it, and we hope you will help us.</p><p>If you have been wanting to contribute to a GNU project, but did not know how,
then here is your chance.  I will pay you $1 (and Jeremy will pay 1€) for any
single contribution to any GNU project.  The only requirement, is that it has to
be your first contribution to that project.  Examples include:</p><ul><li>Your first commit to a GNU software project</li><li>Your first commit to a GNU manual</li><li>You contribute artwork that is accepted into a GNU project.</li><li>You commit a new package or update an existing one to a <a href="https://www.gnu.org/distros/free-distros.html">GNU
distro</a>.</li><li>You help translate a GNU package or manual</li><li>Improve h-node.org <a href="https://www.gnu.org/help/help.html#hnode">h-node.org</a></li><li>Improve <a href="https://libreplanet.org/wiki/Main_Page">libreplanet.org</a></li><li>You successfully <a href="https://www.gnu.org/philosophy/selling.html">sell</a> free software for the first time.</li><li>Start a free software blog.  I can <a href="https://gnucode.me/services.html">help with this</a>.</li><li>Write for the free software bulletin. Email <a href="mailto:info@fsf.org">info@fsf.org</a>.</li><li>Post a video on <a href="https://audio-video.gnu.org/">audio-video.gnu.org</a>.  You'll
need to email <a href="https://gnucode.me/campaigns@fsf.org">info@fsf.org</a>.</li><li>Switch to a completely <a href="https://www.gnu.org/distros/free-distros.html">free operating system</a>.</li><li>Add your program as <a href="https://www.gnu.org/help/evaluation.html">a GNU package</a>.</li><li>Write a Firefox extension that will replace the nonfree Javascript code of
some useful web site (when that nonfree code is blocked by LibreJS). Either
pick a site yourself, or ask for suggestions.  I hang out in <code>#guix</code> on irc.</li><li>Convince your University to release <a href="https://www.gnu.org/philosophy/university.html">your program as free
software</a>.</li><li>Join the <a href="http://www.gnu.org/people/webmeisters.html">GNU webmasters team</a>.</li><li>Improve <a href="https://www.gnu.org/server/tasks.html">gnu.org</a>.</li><li>List your company in the <a href="https://www.fsf.org/resources/service">FSF service
directory</a>.</li></ul><p>Please keep in mind, that we will need to be able to verify that this is your
first contribution to a specific GNU project.  Ideally, you will commit some
change to a software project, and we can use <code>git-log</code> to verify this is your
first commit to that project.</p><p>We are setting aside $90 and 90€ for this "Helping GNU" campaign.  First come,
first serve.  Email me at
<a href="mailto:jbranso+helping-gnu@dismail.de">jbranso+helping-gnu@dismail.de</a> when
your submission is done.</p><p>Your email should look something like:</p><pre><code>Hey Joshua and Jeremy!

So I contributed my first change to this GNU &lt;software project&gt;.
As you can see my email address is &lt;your email address&gt;.  You can verify that
this is my first submission to the GNU &lt;software project&gt; via this &lt;method&gt;.
You can pay me via paypal.  My email address is: &lt;email address&gt;.

Thanks,

Live long and prosper,

&lt;Your Name&gt;
I'm a rock star!
</code></pre><p>Live long and prosper.</p><p>P.S.  If you know of a better payment method, please let me know.  Jeremy is in
the E.U., and I am based in the U.S.</p></div></div>]]>
            </description>
            <link>https://gnucode.me/make-money-contributing-to-gnu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659354</guid>
            <pubDate>Fri, 02 Oct 2020 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Falsehoods Programmers Believe About Map Coordinates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659039">thread link</a>) | @boyter
<br/>
October 1, 2020 | https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates | <a href="https://web.archive.org/web/*/https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Mercator projection SW" title="Mercator projection SW" src="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg" srcset="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e4a55/Mercator_projection_SW.jpg 256w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/36dd4/Mercator_projection_SW.jpg 512w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg 1024w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/ac99c/Mercator_projection_SW.jpg 1536w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e1596/Mercator_projection_SW.jpg 2048w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/1cd85/Mercator_projection_SW.jpg 2058w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
    </span>
(Map image by Daniel R. Strebe, licensed under CC BY-SA 3.0)</p><h2>1. The only projection that is important is Web Mercator</h2><p>While <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a> is
probably the most popular projection that most people will run into, the
<a href="https://en.wikipedia.org/wiki/Albers_projection">Albers</a> and
<a href="https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection">Lambert</a>
equal-area projections are fairly common for when the projection needs to maintain
the area rather than the navigational direction (which is one of the main features
of the Mercator projection).</p><h2>2. All coordinates are latitude/longitude pairs</h2><p>In addition to latitude/longitude coordinates, <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)
coordinates</a>
are also fairly common. UTM splits the Earth into 60 zones, and then
further specifies northings and eastings in metres (as opposed to degrees, minutes and seconds).</p><p>The UTM notably omits the polar areas - which are covered by the <a href="https://en.wikipedia.org/wiki/Universal_polar_stereographic_coordinate_system">Universal Polar Stereographic (UPS)
coordinate system</a>
instead.</p><h2>3. Latitude always comes before longitude in a coordinate pair</h2><p>While it is common to see items in (latitude,longitude) order, some formats
(e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>) dictate that coordinates
follow (longitude,latitude) order instead. This matches the typical way coordinates
are specified in a Cartesian coordinate system: (x,y).</p><h2>4. A degree of latitude or longitude always represents the same distance</h2><p>In the Mercator projection, the Earth - which, in reality, is an
<a href="https://en.wikipedia.org/wiki/Spheroid#Oblate_spheroids">oblate spheroid</a> -
is projected as a simple cylinder. This means that "parallel" longitude lines
meet at the poles, so the distance between degrees of longitude are much shorter
as they get closer to the poles than they are at the equator (~111 km).</p><p>The variance in latitude is not as large - but it still varies by about 1km going
from the equator to the poles.</p><h2>5. The shortest path between two points is a straight line</h2><p>The Earth isn't flat - as such, although your map may be projected to be flat,
the distance between two points needs to follow the curvature of
the Earth and can usually be approximated by the
<a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a>.</p><h2>6. Coordinates for a given landmark are always fixed</h2><p><a href="https://en.wikipedia.org/wiki/Continental_drift">Movements of the Earth's tectonic plates</a>
mean that the land masses are moving slowly with the passage of time.
For example, Australia has shifted about 1.8 metres from where it
was in 1994 (about 7 centimetres per year). This also means that <a href="http://www.ga.gov.au/scientific-topics/positioning-navigation/geodesy/datums-projections/gda2020">geocentric
datums</a>
have to be updated to account for these changes every once in a while.</p><h2>7. Given a pair of coordinates, you can plot it on a map</h2><p>In addition to coordinates, we also need to know the datum, which is
the coordinate system and its specific set of reference points on the Earth.
While most coordinates often follow the
<a href="https://en.wikipedia.org/wiki/World_Geodetic_System">WGS84 datum</a>,
care should be taken to ensure that the map and the coordinates plotted
are using the same datum.</p><h2>8. There is one global ellipsoid to base coordinates on</h2><p>Most modern datums are based on the WGS84
<a href="https://en.wikipedia.org/wiki/Ellipsoid">ellipsoid</a>
as the surveys are often completed using GPS as a reference, but notably
Russia and China still base their local datums on different reference ellipsoids.</p><p>As a result, conversions to and from datums based on different
ellipsoids may result in inaccuracies and deviations and may be of concern
if you have to deal with GPS, GLONASS, and BeiDou data at the same time.</p></div></div>]]>
            </description>
            <link>https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659039</guid>
            <pubDate>Fri, 02 Oct 2020 04:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Transport Tycoon creator Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon — who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here — or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they’ve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We’ll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making — a decade of hard work, toiling in obscurity…or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade — it’s five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since — such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he’d encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he’d become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts — where Chris set off towards the lands where he’d make his name. And I find it fascinating how serendipitous this was — for, you see, Chris’s two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he’d not had access to an assembler for that Lynx computer, so when he’d wanted to move beyond coding in BASIC he’d needed to write his programs byte-by-byte in machine code — the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he’d made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‘k’ rather than a ‘c’) as though that somehow made his unapologetic, blatant clone of another’s work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren’t much concerned. Or at least their games guy Jim Wills wasn’t much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris’s work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers — an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he’d already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he’d shifted over to the Amstrad CPC, which technologically-speaking wasn’t hugely different to the Memotech system he’d been on before — but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can’t be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn’t doing too well at managing the transition. </p><p>So Chris didn’t have a job waiting for him after all, and he’d missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry — he’d made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he’d thought it a “stop-gap” measure, just “a bit of fun” while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who’d had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[線香花火 WebGL Japanese Sparkler]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658771">thread link</a>) | @lioeters
<br/>
October 1, 2020 | https://tompng.github.io/senkouhanabi_gl/ | <a href="https://web.archive.org/web/*/https://tompng.github.io/senkouhanabi_gl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tompng.github.io/senkouhanabi_gl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658771</guid>
            <pubDate>Fri, 02 Oct 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to compute a factorial with λ calculus in a post card]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658404">thread link</a>) | @martyalain
<br/>
October 1, 2020 | http://lambdaway.free.fr/lambdawalks/?view=lambdafact | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=lambdafact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=lambdafact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658404</guid>
            <pubDate>Fri, 02 Oct 2020 03:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The (Not Failing) New York Times - How the NYT pivoted into subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658206">thread link</a>) | @ReallyFantastic
<br/>
October 1, 2020 | https://minesafetydisclosures.com/blog/newyorktimes | <a href="https://web.archive.org/web/*/https://minesafetydisclosures.com/blog/newyorktimes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-5f70e3da36b37d25b6fe92ee" data-item-id="5f70e3da36b37d25b6fe92ee">

  <!--SPECIAL CONTENT-->

  

  
  <!--POST HEADER-->
    
  <header>
    
    <div>
      <p><span><a href="https://minesafetydisclosures.com/blog/newyorktimes" title="Permalink"><time datetime="2020-10-01">October 01, 2020</time></a></span>
       in <span><a href="https://minesafetydisclosures.com/blog/category/Companies" rel="tag">Companies</a></span>
    </p></div>
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601234027667" id="item-5f70e3da36b37d25b6fe92ee"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1601572339034_143602"><div><p><strong>CLICK TO EXPAND</strong> (<a href="https://www.dropbox.com/s/qy3nfaxjiplmtcf/The%20%28Not%20Failing%29%20New%20York%20Times.pdf?dl=0">or download the PDF</a>)</p></div></div><div data-block-json="{&quot;transparentBackground&quot;:false,&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;newWindow&quot;:true,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;aspect-ratio&quot;:&quot;four-three&quot;,&quot;aspectRatio&quot;:null,&quot;auto-crop&quot;:false,&quot;autoplay&quot;:false,&quot;blockAnimation&quot;:&quot;none&quot;,&quot;collectionId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;,&quot;controls&quot;:true,&quot;design&quot;:&quot;grid&quot;,&quot;lightbox&quot;:true,&quot;lightboxTheme&quot;:&quot;dark&quot;,&quot;meta-position&quot;:&quot;bottom&quot;,&quot;padding&quot;:4,&quot;show-meta&quot;:true,&quot;show-meta-basic&quot;:true,&quot;show-meta-only-title&quot;:false,&quot;show-meta-only-description&quot;:false,&quot;show-meta-on-hover&quot;:false,&quot;square-thumbs&quot;:false,&quot;thumbnail-strip-height&quot;:130,&quot;thumbnail-strip-margin&quot;:20,&quot;thumbnails&quot;:true,&quot;thumbnails-per-row&quot;:3,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;}" data-block-type="8" id="block-yui_3_17_2_1_1601554581161_153023"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.001.jpeg" data-load="false" data-image-id="5f75feebcd2d631e090d8ecf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.002.jpeg" data-load="false" data-image-id="5f75feeb0df493541c6b0f58" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.003.jpeg" data-load="false" data-image-id="5f75feeb753f9f3986c12f5b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.004.jpeg" data-load="false" data-image-id="5f75feec2b2362390706eb55" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.005.jpeg" data-load="false" data-image-id="5f75feec753f9f3986c13128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.006.jpeg" data-load="false" data-image-id="5f75feed0dd0c87c41a98128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.007.jpeg" data-load="false" data-image-id="5f75feedd134f3794caf0000" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.008.jpeg" data-load="false" data-image-id="5f75feed8036587780b953a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.009.jpeg" data-load="false" data-image-id="5f75feee0373414277bdfd7c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.010.jpeg" data-load="false" data-image-id="5f75feef7a7dba1ef4d84dcc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.011.jpeg" data-load="false" data-image-id="5f75feef15e1c70b3500b4a9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.012.jpeg" data-load="false" data-image-id="5f75feefcd2d631e090d8f05" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.013.jpeg" data-load="false" data-image-id="5f75fef096d0d45d87873ae4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.014.jpeg" data-load="false" data-image-id="5f75fef196d0d45d87873ae5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.015.jpeg" data-load="false" data-image-id="5f75fef178c626590ead63bd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.016.jpeg" data-load="false" data-image-id="5f75fef1cd2d631e090d90d5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.017.jpeg" data-load="false" data-image-id="5f75fef20cb6f82db9374309" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.018.jpeg" data-load="false" data-image-id="5f75fef2fcfe7968a6c406c0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.019.jpeg" data-load="false" data-image-id="5f75fef31158a96d1adab031" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.020.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.021.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.022.jpeg" data-load="false" data-image-id="5f75fef5883c6055aa1defb2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.023.jpeg" data-load="false" data-image-id="5f75fef52b2362390706f660" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.024.jpeg" data-load="false" data-image-id="5f75fef59993bf06c4e0fd0b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.025.jpeg" data-load="false" data-image-id="5f75fef50dd0c87c41a983ae" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.026.jpeg" data-load="false" data-image-id="5f75fef51158a96d1adab04e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.027.jpeg" data-load="false" data-image-id="5f75fef6df48bb24d6e115b8" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.028.jpeg" data-load="false" data-image-id="5f75fef6f5a59735fc9dad85" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.029.jpeg" data-load="false" data-image-id="5f75fef705a7793966d1d02c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.030.jpeg" data-load="false" data-image-id="5f75fef70dd0c87c41a983cb" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.031.jpeg" data-load="false" data-image-id="5f75fef878c626590ead67cf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.032.jpeg" data-load="false" data-image-id="5f75fef92fbf5a3363926728" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.033.jpeg" data-load="false" data-image-id="5f75fef996d0d45d87873f25" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg">
                </a>
                
              </p></div>
            </div></div></div></div></div></div></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://minesafetydisclosures.com/blog/newyorktimes">https://minesafetydisclosures.com/blog/newyorktimes</a></em></p>]]>
            </description>
            <link>https://minesafetydisclosures.com/blog/newyorktimes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658206</guid>
            <pubDate>Fri, 02 Oct 2020 02:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[London, Ont. study reveals science behind curling's 2015 'Frankenbroom' ban]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658102">thread link</a>) | @lando2319
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658102</guid>
            <pubDate>Fri, 02 Oct 2020 02:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build Complex Entry Forms Using Only HTML and Vue Templating – Demo App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24658012">thread link</a>) | @__app_dev__
<br/>
October 1, 2020 | https://www.dataformsjs.com/examples/entry-form-demo-vue.htm | <a href="https://web.archive.org/web/*/https://www.dataformsjs.com/examples/entry-form-demo-vue.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.dataformsjs.com/examples/entry-form-demo-vue.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658012</guid>
            <pubDate>Fri, 02 Oct 2020 01:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>(<a href="https://news.ycombinator.com/item?id=24660824">caveat</a>), because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Designer's Guide to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657624">thread link</a>) | @philipcdavis
<br/>
October 1, 2020 | https://react.design/javascript | <a href="https://web.archive.org/web/*/https://react.design/javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You can learn the basics of JavaScript quickly. You don't need a engineering degree, or a front end bootcamp.</p><p>Learning the basics of JavaScript is enough to get started with modern frameworks like React.js. Once you know the basics, you can do some truly amazing things.</p><p>You can quickly spin up interactive prototypes.<br>You can use live data sets.<br>You can create web, mobile, and desktop apps.<br>You can define interfaces in high fidelity.<br>You can write scripts to automate daily tasks.<br>You can make plugins for design tools like Sketch and Figma.<br>You can build with modern frameworks like React.js.</p><p>You can't learn JavaScript in a day, but you can learn it quickly. The best way to learn is to build. This guide is meant to give you enough information to start building. </p><h2>Editor</h2><p><img src="https://react.design/assets/javascript/theme.png">
</p><p>Before we write any code, it's a good idea to get comfortable with your text editor. I'd recommend using a text editor like <a href="https://code.visualstudio.com/">VSCode</a>, or <a href="https://atom.io/">Atom</a> as you write JavaScript. They're both free and support lots of plugins to make things easier. You can also find lots of nice themes. Here's a <a href="https://marketplace.visualstudio.com/items?itemName=Framer.framer-syntax">theme</a> for VSCode that I like.</p><p>Learning keyboard shortcuts, and customizing the look of your editor will make for a much more enjoyable coding experience.</p><h2>Setup</h2><p>JavaScript is a scripting language that for our intents and purposes, will be executed by the browser.</p><p>There are multiple ways to include javascript inside your webpage. The way we will use javascript will be by including <code>&lt;script&gt;</code> tags right before the closing <code>&lt;/body&gt;</code> tag. </p><pre><code><span>&lt;!</span><span>DOCTYPE</span><span> </span><span>html</span><span>&gt;</span><span>
</span><span></span><span>&lt;</span><span>html</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>head</span><span>&gt;</span><span>&lt;/</span><span>head</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>body</span><span>&gt;</span><span>
</span>    
<span>    </span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span>        </span><span>// Javascript will go here</span><span>
</span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"Hello friend!"</span><span>)</span><span>
</span><span>    </span><span>&lt;/</span><span>script</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>body</span><span>&gt;</span><span>
</span><span></span><span>&lt;/</span><span>html</span><span>&gt;</span></code></pre><p>Weâ€™ll put our javascript inside here, but we could also reference an external file.
<code>console.log()</code> is a helpful tool for debugging. Here I'm writing "Hello Friend!" To the console. You an access the console in Chrome using the <code>CMD+Option+J</code> shortcut.</p><p><img src="https://react.design/assets/javascript/console.png">
</p><p>There are 5 core concepts in JavaScript that are important to understand.</p><p><strong>1. Variables</strong><br><strong>2. Data Structures</strong><br><strong>3. Loops</strong><br><strong>4. Conditionals</strong><br><strong>5. Functions</strong></p><h2>Variables</h2><p>Variables are containers that hold values. These values can take lots of different forms. If you wanted a variable to hold a number you could write it as <code>var num = 20;</code>. If I use <code>console.log(num)</code> it should show me the number twenty.</p><p>Variables can be referenced later. <code>var double = num * 2; // 40</code></p><p>Variables can hold lots of different data types. I want to discuss a few different common ways to hold data. There are primitive data types like numbers, which we used earlier, There are strings, which are just a way to store text, and booleans which are values that are either true or false.</p><pre><code><span>var</span><span> days </span><span>=</span><span> </span><span>40</span><span>;</span><span> </span><span>// Number</span><span>
</span><span></span><span>var</span><span> label </span><span>=</span><span> </span><span>"Hello"</span><span>;</span><span> </span><span>// String</span><span>
</span><span></span><span>var</span><span> hidden </span><span>=</span><span> </span><span>true</span><span>;</span><span> </span><span>// Boolean</span></code></pre><h2>Data Structures</h2><p>In addition to primitive data types there are others that have more complex structures. Two of these important types are objects (sometimes called object literals) and arrays. </p><p>Objects can be defined using curly braces. 
<code>var obj = {}</code></p><p>What goes inside the curly braces are a collection of key value pairs. The key goes first, followed by a colon, and then the value. </p><pre><code><span>var</span><span> obj </span><span>=</span><span> </span><span>{</span><span>
</span><span>  key</span><span>:</span><span> value
</span><span></span><span>}</span></code></pre><p>Keys are labels that help you find the data you want to store. Keys in a single object must be unique. Values can be any data type. Numbers, strings, arrays, and even other objects. 
Here's an example Object with multiple key value pairs in action:</p><pre><code><span>var</span><span> profile </span><span>=</span><span> </span><span>{</span><span>
</span><span>	name</span><span>:</span><span> </span><span>'Philip'</span><span>,</span><span> 
</span><span>	age</span><span>:</span><span> </span><span>25</span><span>,</span><span> 
</span><span>	contact</span><span>:</span><span> </span><span>{</span><span>
</span><span>		twitter</span><span>:</span><span> </span><span>'philipcdavis'</span><span>,</span><span> 
</span><span>		email</span><span>:</span><span> </span><span>'reactfordesigners@gmail.com'</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Name, age, contact, twitter, and email are all different keys in this object. The values are all different and many have different value types. Some are strings, some are numbers, and some are other objects.</p><p>This nested structure is common and you will see it a lot when working with data sets.</p><p>There are two ways to access a value inside an object. The first way is sometimes called dot notation: <code>profile.name</code>. The second way is by using brackets <code>profile['name']</code>. Bracket notion is useful when your key name is dynamic.</p><p>The other data type thatâ€™s important to know about is the Array. You define an array with square brackets. </p><p><code>var myArr = [];</code></p><p>You can store any type of data inside these arrays and they don't need to all be the same type (though they usually are). An example array might look like this: </p><pre><code><span>var</span><span> teams </span><span>=</span><span> </span><span>[</span><span>'lakers'</span><span>,</span><span> </span><span>'nuggets'</span><span>,</span><span> </span><span>'rockets'</span><span>]</span><span>;</span></code></pre><p>Instead of using keys, arrays use a built in index to keep track of location. The index of arrays starts at 0. If we wanted to access the second value of this array (nuggets) we could do so by typing <code>teams[1];</code></p><p>If your data was as simple as this, using objects and arrays might seem unnecessary. They start to shine when you have data sets that are larger. To work with more data, we'll probably want to use a loop</p><h2>Loops</h2><p>Loops enable you to run a block of code multiple times. You can use a loop with objects and arrays to execute a block of code on each item in the structure. </p><p>To loop through each value in an array you can use a for loop that executes a block. </p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Block to be executed</span><span>
</span><span></span><span>}</span></code></pre><p>What goes into the parenthesis determines how many times the block of code is executed. The first value is a counter variable. <code>i</code> is often used to refer to the fact that it's used as the index value of the array. We will start the counter at 0. </p><p>The next value is called the conditional. Once the conditional is false, the loop will end. We can set the value to be <code>i &lt; teams.length</code>. The <code>.length</code> is a helper value built into every array that will tell you how many items are in the array. Once the value of the counter is as great as the length of the array, we can stop looping. The last value <code>i++</code> is what we want to happen after our loop runs. We want our counter to increase in value by one every time the loop runs.</p><p>If we log a string, you can see that it will print out 4 times.
If we log the value i, you can see that it increments up. If you combine this incremented value i with our array, you can see how we can access each value in our array.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span><span> 
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>
</span><span></span><span>}</span><span>;</span></code></pre><p>There are other types of loops but they all are doing something pretty similar, running a block of code multiple times. Thatâ€™s the essential work of a loop.</p><h2>Conditionals</h2><p>Next up on our list is conditionals. The most common type of conditional is the if/else statement. </p><pre><code><span>if</span><span> </span><span>(</span><span>conditional</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to true'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to false'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>If the <code>conditional</code> value in the parenthesis evaluates to true, the block inside the first set of curly brackets is run, otherwise the else block is run.</p><p>Letâ€™s use it in combination with our loop to log only the first two items in our array. Because we donâ€™t need the else here, we can remove it, and weâ€™ll get the same result.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>i </span><span>&lt;</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>	  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Youâ€™ll use these conditionals to to control what gets executed when.</p><h2>Functions</h2><p>Functions allow you to create reusable and modular code.</p><p>Another way to say it is that they are blocks of code than can be executed whenever they are needed. </p><p>Here's what one looks like</p><pre><code><span>function</span><span> </span><span>add</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>var</span><span> total </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>	</span><span>return</span><span> total</span><span>;</span><span>
</span><span></span><span>}</span><span> </span></code></pre><p>Here we have a simple function that takes two input values, adds them together, and then returns the total. Weâ€™ll use generic names for our input arguments. You can name these pretty much whatever you want, but they will be used within our block so if your function is complex, itâ€™s good to have descriptive names. Because this is a pretty simple function we're using <code>a</code> and <code>b</code>. </p><p>What we've created is a function declaration. In order to execute, or invoke our function we can call <code>add(2,50)</code>.
<code>console.log(add(2,50)) // 52</code></p><p><code>console.log</code> is itself a function. Functions can be stored in variables, objects, arrays, or even passed into other functions.</p><p>One other important thing to note about functions is how they affect variables inside them. If you define a variable within a function, the variable cannot be used outside the function. That's because javascript has a function based scope.</p><hr><p>Javascript is a really fun language to learn. If you feel comfortable with the material above you can do a lot! Most of JavaScript is just building on to these core concepts.</p><h2>Modern JavaScript</h2><p>In 2015 a set of new syntax and features were introduced that made writing JavaScript easier. Many of the following updates are meant to help you write code faster and cleaner. If you're using modern frameworks like React you'll often see them in examples.</p><h3>Const / Let</h3><p>This is just a new way to write variables. </p><pre><code><span>const</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span><span>
</span><span></span><span>let</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span></code></pre><p><code>const</code> values cannot be reassigned after the initial assignment. This is usually the default way of creating variables. </p><p><code>let</code> values can be reassigned but are scoped to conditionals, the same way all variables are scoped to functions. If you declare one inside an if/else statement it won't be available outside the statement.</p><h3>Arrow Functions</h3><p>This a shorthand for writing functions.
Instead of writing:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span>{</span><span> </span><span>return</span><span> a </span><span>+</span><span> b </span><span>}</span></code></pre><p>You can use an arrow function which looks like this:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span> </span><span>=&gt;</span><span> a </span><span>+</span><span> b</span></code></pre><p>If your function takes a single parameter you can omit the parenthesis.</p><pre><code><span>const</span><span> </span><span>getStyle</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>=&gt;</span><span> a</span><span>.</span><span>style</span></code></pre><h3>Template Literals</h3><p>Previously is you wanted dynamic strings, you would insert values using the following syntax.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>"Hello my name is"</span><span> </span><span>+</span><span> firstName </span><span>+</span><span> </span><span>". Welcome!"</span></code></pre><p>Using template literals, you can use the backtick for strings, and <code>${}</code> to insert variables.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>`</span><span>Hello my name is </span><span>${</span><span>firstName</span><span>}</span><span>. Welcome!</span><span>`</span></code></pre><h3>Imports and Exports</h3><p>Instead of using large javascript files, you'll often want to break your code into smaller modules and export anything that other modules need to access.</p><pre><code><span>// Colors.js</span><span>
</span><span></span><span>export</span><span> </span><span>const</span><span> colors </span><span>=</span><span> </span><span>{</span><span>
</span><span>	blue</span><span>:</span><span> </span><span>"#EA3232"</span><span>,</span><span>
</span><span>	red</span><span>:</span><span> </span><span>"#4062F3"</span><span>,</span><span>
</span><span>	yellow</span><span>:</span><span> </span><span>"#FFAD05"</span><span>,</span><span>
</span><span></span><span>}</span></code></pre><p>In a different file you can import these colors using the following syntax.</p><pre><code><span>import</span><span> </span><span>{</span><span>colors</span><span>}</span><span> </span><span>from</span><span> </span><span>'./Color'</span></code></pre><p>You can also define default exports …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://react.design/javascript">https://react.design/javascript</a></em></p>]]>
            </description>
            <link>https://react.design/javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657624</guid>
            <pubDate>Fri, 02 Oct 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic-Differentiation-Worked-Examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657571">thread link</a>) | @formalsystem
<br/>
October 1, 2020 | http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/ | <a href="https://web.archive.org/web/*/http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h3>automatic-differentiation-worked-examples</h3>
  
<p>– forwards and reverse</p>
<h2 id="introduction">Introduction</h2>
<p>This article demonstrates how to perform source transformations on a program to generate forward mode and reverse mode derivative programs (automatic differentiation, or “AD”). My aim is to write the shortest possible article that communicates all the essential features of a source-to-source AD system with a particular focus on making the reverse mode transformation clear.</p>
<p>The goal of brevity means that a lot of possible commentary has been omitted. If you find this makes some part of the article hard to understand then please <a href="http://web.jaguarpaw.co.uk/~tom/contact">contact me</a> and I’ll do my best to clarify. In particular this article contains hardly any mathematical content at all. I hope that the reader who is familiar with multivariate calculus will be able to obtain an intuitive understanding of how AD relates to mathematical techniques he or she is already familiar with. A more in-depth description of the relationship will have to wait for another article.</p>
<h2 id="the-program">The program</h2>
<p>Let’s consider the following pseudocode program that performs some elementary arithmetic through a sequence of assignment statements.</p>
<pre><code>p = 7 * x
r = 1 / y
q = p * x * 5
v = 2 * p * q + 3 * r</code></pre>
<p><code>x</code> and <code>y</code> are not defined in the program so I’m going to informally consider them to be “inputs”; <code>v</code> is not used anywhere so I’m going to consider it to be the “output”. (I won’t burden the article by formalising these notions here.)</p>
<h2 id="preparation">Preparation</h2>
<p>We’ll do a small amount of preparation to our original program which will preserve its behaviour and get it into a form in which it is straightforward to apply the automatic differentiation (AD) algorithms. It is possible to apply AD algorithms without doing these transformations first but then the AD algorithms would have to do equivalent operations implicitly. Doing these transformations first is a kind of <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
<h3 id="use-prefix-functions-with-exactly-one-argument">Use prefix functions with exactly one argument</h3>
<p>Let’s use prefix functions instead of <a href="https://en.wikipedia.org/wiki/Infix_notation">infix operators</a>. Infix operators are more familiar for arithmetic but the AD algorithms will be clearer to present if we use prefix functions. Additionally I want every function to have exactly one argument (although that argument may be a tuple). Single-argument style will make the reverse mode transformation much clearer (although it does not make any difference for forward mode). For example, <code>x1 + x2</code> would become <code>add (x1, x2)</code>. Our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
q = mul (mul (p, x), 5)
v = add (mul (mul (2, p), q), mul (3, r))</code></pre>
<h3 id="no-nested-subexpressions">No nested subexpressions</h3>
<p>Next let’s convert to a form where every function is applied to (tuples of) variables and constants only, i.e.&nbsp;where there are no nested sub-expressions (besides potentially nested tuples). We assign each nested sub-expression to an intermediate variable. For example</p>
<pre><code>a = add (add (b, c), d)</code></pre>
<p>would become</p>
<pre><code>i = add (b, c)
a = add (i, d)</code></pre>
<p>The choice of <code>i</code> is arbitrary; it just has to be a variable that’s not used elsewhere in our program. This form without nested subexpressions is a lot like <a href="https://en.wikipedia.org/wiki/A-normal_form">ANF</a> from the field of functional compiler construction. It’s also a lot like the <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA form</a> of assembly language. After removing nested subexpressions, our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<h2 id="differentiation-line-by-line">Differentiation line-by-line</h2>
<p>We have performed all the transformations needed to prepare our program and we are ready to proceed to differentiation. We will differentiate the program line-by-line, that is, both the forward mode and reverse mode differentiation algorithms will generate one line of derivative code for each line of input code. But what <em>is</em> the derivative of an assignment statement? For forward mode, the derivatives correspond quite closely to what you might be familiar with from a first multivariate calculus course..</p>
<h3 id="examples">Examples</h3>
<h4 id="addition">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (dx1, dx2)</code></pre>
<h4 id="multiplication">Multiplication</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (mul (x2, dx1), mul (x1, dx2))</code></pre>
<h4 id="division">Division</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = div (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (div (dx1, x2), negate (mul (div (x1, mul (x2, x2)), dx2)))</code></pre>
<h2 id="forward-mode">Forward mode</h2>
<p>The forward mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a derivative line (listed on the right). To each line we apply exactly one rule and the form of the rule does not depend on any of the other lines.</p>
<pre><code>p = mul (7, x)   | dp = mul (7, dx)
r = div (1, y)   | dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)  | di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)  | dq = mul (di1, 5)
i2 = mul (2, p)  | di2 = mul (2, dp)
i3 = mul (i2, q) | di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)  | di4 = mul (3, dr)
v = add (i3, i4) | dv = add (di3, di4)</code></pre>
<p>If we form a new program consisting of the sequence of assignments on the left followed by the sequence of assignments on the right then we have a program that calculates the forward derivative! The “inputs” of this program are <code>x</code>, <code>y</code>, <code>dx</code> and <code>dy</code>. The “outputs” are <code>v</code> and <code>dv</code>.</p>
<p>(The derivatives of constants are zero and I’ve left terms that are zero out for simplicity.)</p>
<p>In fact we can be a little more clever. We can interleave the assignments, so an assignment from the left is immediately followed by its corresponding assignment from the right, that is</p>
<pre><code>p = mul (7, x)
dp = mul (7, dx)
r = div (1, y)
dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)
di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)
dq = mul (di1, 5)
i2 = mul (2, p)
di2 = mul (2, dp)
i3 = mul (i2, q)
di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)
di4 = mul (3, dr)
v = add (i3, i4)
dv = add (di3, di4)</code></pre>
<p>This interleaving demonstrates an important property of the automatic derivative: that it uses space proportional to the space usage of the original program. Specifically, as soon as we no longer need a variable that was assigned in the original program we no longer need the corresponding <code>d</code> version either.</p>
<p>We can also see another important property of the forward derivative: it runs in time proportional to the run time of the original program (assuming that the derivative of every primitive runs in time proportional to the run time of the primitive itself).</p>
<h2 id="reverse-mode-requires-two-additional-ideas">Reverse mode requires two additional ideas</h2>
<p>Now that we’ve shown how to generate the forward mode derivative we can move on to the reverse mode derivative. Reverse mode requires two additional ideas:</p>
<ol type="1">
<li><p>We need to convert our original program to “explicit duplication” form: if a variable is used more than once then we make that explicit in the structure of the program. This is unusual but straightforward.</p></li>
<li><p>We need to use a form of the derivative that will be unfamiliar to most readers. It will appear quite bizarre when seeing it for the first time but it is crucial to implementing the reverse mode derivative.</p></li>
</ol>
<h2 id="explicit-duplication-form">Explicit duplication form</h2>
<p>Before applying the reverse mode AD transformation we will convert to “explicit duplication” form. Again, the transformation is not strictly required but if we omit it then the differentiation pass will have to do it implicitly. We take the ANF form of the program and insert explicit duplications (<code>dup</code>) for any variable that is used more that once. Recall that after removing nested subexpressions our program was</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>We can see that <code>x</code> and <code>p</code> appear on the right hand side (i.e.&nbsp;are consumed) twice each. Therefore, they will need explicit duplication, so that each variable in the resulting program is used only once. With explicit duplication the program looks like</p>
<pre><code>(x1, x2) = dup x
p = mul (7, x1)
(p1, p2) = dup p
r = div (1, y)
i1 = mul (p1, x2)
q = mul (i1, 5)
i2 = mul (2, p2)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>(If a variable were used <span><em>n</em></span> times then we would have to insert <span><em>n</em> − 1</span> <code>dup</code>s for it. In our example no variable is used more than twice.)</p>
<p>Notice that now not only is every variable defined exactly once, but every variable is also <em>used</em> exactly once (except the inputs and outputs, <code>x</code>, <code>y</code> and <code>v</code> – I won’t say more here about how exactly these seemingly special cases fit into the story). This property is important for a reason which will be explained when we come to generate the reverse mode program.</p>
<h2 id="differentiation-line-by-line-1">Differentiation line-by-line</h2>
<p>The line-by-line differentiation rules for generating the reverse mode need another article to explain thoroughly, but in this article I will hope to provide some basic intuition via examples and the informal notion that the reverse mode program calculates how sensitive the output is to different variables. For example, if the variable <code>y</code> appears in the original program then the variable <code>d_dy</code> will appear in the reverse mode program and measures “how sensitive the output is to small changes in <code>y</code>”. (I’ll abbreviate this to “<code>d_dy</code> is the sensitivity to <code>y</code>”.)</p>
<h3 id="examples-1">Examples</h3>
<h4 id="addition-1">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivatives are</p>
<pre><code>d_dx1 = d_dy
d_dx2 = d_dy</code></pre>
<p>because the sensitivity to <code>x1</code> is the same as the sensitivity to <code>y</code> (and likewise for <code>x2</code>). This is written on a single line as</p>
<pre><code>(d_dx1, d_dx2) = dup (d_dy)</code></pre>
<h4 id="multiplication-1">Multiplication</h4>
<p>If a line of our program was</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>(d_dx1, d_dx2) = (mul (x2, d_dy), mul (x1, d_dy))</code></pre>
<p>because the sensitivity to <code>x1</code> is <code>x2</code> times the sensitivity to <code>y</code> (and similarly for <code>x2</code>).</p>
<h4 id="duplication">Duplication</h4>
<p>If a line of our program was</p>
<pre><code>(x1, x2) = dup (x)</code></pre>
<p>then the derivative line is</p>
<pre><code>d_dx = add (d_dx1, d_dx2)</code></pre>
<p>because the sensitivity to <code>x</code> is the sensitivity to <code>x1</code> plus the sensitivity to <code>x2</code>.</p>
<h2 id="generating-reverse-mode-code">Generating reverse mode code</h2>
<p>Like forward mode before it, the reverse mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</a></em></p>]]>
            </description>
            <link>http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657571</guid>
            <pubDate>Fri, 02 Oct 2020 00:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How YouTube Originals Shifted Prioritization to Stricter Ad Optimized Content]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657529">thread link</a>) | @godisai
<br/>
October 1, 2020 | https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/ | <a href="https://web.archive.org/web/*/https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					








<figure><p>
<iframe title="Wayne | Official Trailer | YouTube Originals" width="1100" height="619" src="https://www.youtube.com/embed/PFOtvHtyW8s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>











<p>The Wayne YouTube Original was a Gen Z version of Bonnie and Clyde mixed with Deadpool’s rough humor. This golden egg was YouTube’s hope of breaking into the world of streaming originals. Long story short, their hopes died with the failure of this show. This failure marks a critical pivot in YouTube’s business model. They transitioned to a model that prioritizes an array of content that is not just ad-friendly, but ad optimized. Understanding this pivot helps creators align their business strategy with this new direction. To understand this new business model, we need to review YouTube’s history of growth and monetization.&nbsp;</p>







<h2><strong>A History of YouTube Monetization</strong></h2>







<p>Thirteen years ago, Neil Cicierega uploaded a 2-minute video called Harry Potter Puppet Pals to YouTube. Now that video has 192,913,827 views, and YouTube enthusiasts revere it as a culture-defining classic. This democratized unfiltered viral content was YouTube’s brand in the late 2000s. The exciting start-up revolutionized how people consumed digital content but lacked a robust monetization model. At the time, YouTube only approved a handful of creators for advertising through its partnership program.&nbsp;</p>







<p>YouTube changed this In <a href="https://www.bloomberg.com/news/articles/2009-08-24/one-off-viral-videos-now-can-make-money-on-youtube">2009</a> when it updated its partnership program to include the monetization of individual videos. This move opened the door for small creators to generate revenue by making viral videos. Content like Harry Potter Puppet Pals now had a way to make money from its views.&nbsp;&nbsp;</p>







<p>Then in <a href="https://www.theverge.com/2012/4/13/2945243/youtube-partner-program-monetization">2012</a>, YouTube adjusted its partnership program again by opening monetization up to everyone. This created a new incentive structure that resulted in a production value boom. Videos like <a href="https://www.youtube.com/watch?v=Yk7SLuNG5Nk">Gangnam Style</a> and <a href="https://www.youtube.com/watch?v=avaSdC0QOUM">I’m on a Boat</a> replaced the Harry Potter Puppet Pals ascetic as YouTube’s new brand.&nbsp;</p>







<h2><strong>Hours of video uploaded to YouTube every minute as of May 2019:</strong></h2>



<figure><img src="https://lh6.googleusercontent.com/BJSwNSU5tIWygW07foEEPP9CbtROjW9W-M94HEcImnHgSZik8KO5ITInRxgN1UMo7HWmoCoUHWsZwsFIkgVVgZAxx_9fNbGXYnAy2FAYKHbT_G5CQu1p84ZhvhTUVtTj5eZ2V2HM" alt=""></figure>







<p>This era of YouTube was a gold rush for creators. The platform prioritized user-generated content and approved volumes for monetization without any question. This pattern changed in <a href="https://www.independent.co.uk/news/business/news/google-adverts-latest-youtube-extremist-videos-companies-pull-adverts-marks-spencer-companies-ku-klux-klan-isis-rape-apologists-a7638991.html">2017</a> when advertisers in the UK noticed their ads on extremist content like ISIS and KKK videos. This news hurt Google’s bottom line and forced YouTube to enforce stricter guidelines for ad-friendly content.&nbsp;&nbsp;</p>







<p>Advertising wasn’t the only growth model YouTube was using, however. Their business model included an investment strategy in subscription-based streams of revenue. In 2010, they started a rental program, then in 2014, they created a subscription service for music called YouTube Red. YouTube was splitting their efforts between an SVOD (Subscription Video On Demand) and AVOD (Advertising Video On Demand) business model.&nbsp;</p>







<h2><strong>The Difference Between SVOD and AVOD.&nbsp;</strong></h2>







<p>An SVOD (Subscription Video On Demand) model is a video-on-demand service where users pay a flat rate each month to gain access to as much content as they wish. So with this model, content is created and funded with the primary purpose of attracting and retaining viewership. This objective saves SVOD’s time and hassle of curating and promoting ad-friendly content.&nbsp;</p>







<p>The AVOD (Advertising Video On Demand) model does not charge viewers for its content; it charges advertisers access to viewer’s data and attention. In this model, YouTube needs to attract and retain viewership while also curating and promoting ad-friendly content.&nbsp;</p>







<p>The AVOD model is more labor-intensive but less competitive. After addressing concerns over inappropriate content in 2017, YouTube also invested more in its SVOD model. They dropped their most controversial YouTuber, <a href="https://techcrunch.com/2017/02/14/pewdiepies-youtube-red-series-gets-cancelled-after-vlogger-posts-anti-semitic-content/">Pewdiepie</a>, from YouTube Red and started investing in scripted shows. In <a href="https://arstechnica.com/gadgets/2018/05/youtubes-revamped-music-subscription-service-launches-on-may-22/">2018</a> they updated their YouTube Red subscription service to YouTube Premium. So subscribers now had access to exclusive ad-free YouTube Originals like Wayne, and all of their favorite channels and music services.&nbsp;</p>







<h2><strong>Why YouTube Originals Failed</strong></h2>







<p>In 2016, YouTube had just over 1 billion total users, with only <a href="https://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">1.5 million</a> monthly subscribers in YouTube Red. In 2018, YouTube believed that they could compete with Netflix, Hulu, and Amazon by attracting their 1 billion users to YouTube Premium. So they released the pilots of shows like Wayne on their central platform in a significant promotional effort.&nbsp;</p>







<p>The show was a massive success with the critics. It received a <a href="https://deadline.com/2019/08/step-up-wayne-canceled-youtube-pilot-dark-cargo-its-a-mans-wold-dead-seek-new-homes-scripted-programming-pullback-programming-shift-1202669457/">100% fresh rating on rotten tomatoes and 27 million people viewed the pilot.</a> Despite its success, Youtube couldn’t convince enough viewers to purchase a subscription to keep watching. Viewers had two reasons not to buy.</p>







<h2>Brand Conditioning and Opportunity Cost </h2>







<figure><img src="https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-683x1024.jpg" alt="" srcset="https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-683x1024.jpg 683w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-200x300.jpg 200w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-768x1152.jpg 768w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-1024x1536.jpg 1024w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-1365x2048.jpg 1365w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-600x900.jpg 600w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-scaled.jpg 1707w" sizes="(max-width: 683px) 100vw, 683px"></figure>







<p>The first reason was that YouTube’s core brand was and still is user-generated content. It is in their name. Users are not likely to pay a subscription for content that isn’t associated with YouTube’s brand. So That subscription wasn’t a purchase of Wayne; it was an investment in future YouTube originals. This investment is hard to sell when it isn’t in the company’s brand.&nbsp;</p>







<p>YouTube conditions users to receive ads. The whole model facilitates the right ads and the right amount of ads while also retaining viewership. Since most viewers are already conditioned for this, they had minimal incentive to pay extra for zero ads.&nbsp;</p>







<p>Lastly, YouTube’s investment in scripted paywall content was an opportunity cost. YouTube’s ad-supported business generates billions of dollars in revenue a year. This cash cow couldn’t compete with the revenue from subscriptions. As a result, successful shows like Wayne were costing the company money by excluding them from the ads. &nbsp;</p>







<p>In <a href="https://deadline.com/2019/08/step-up-wayne-canceled-youtube-pilot-dark-cargo-its-a-mans-wold-dead-seek-new-homes-scripted-programming-pullback-programming-shift-1202669457/">2019</a>, YouTube publicly acknowledged that the SVOD model could no longer compete with the AVOD model. As a result, they dropped these scripted shows from the paywall and quietly stopped investing in scripted content. This decision provided more room for the two leading giants, Netflix and Amazon, to duke it out in the streaming wars. We may even see one of these streaming services purchase the rights to Originals like Wayne.&nbsp;</p>







<p>This change in strategy means that YouTube pivoted its growth model. Instead of moving into the SVOD space, they reinvested that time and money to grow their ad revenue. Most of their efforts have been in setting stricter enforcement of their ad policies and incentivizing more ad-optimized content.&nbsp;</p>







<h2><strong>The Difference Between Ad Friendly and Ad Optimized Content</strong></h2>







<p>Ad-friendly content is a list of topics that YouTube will not include in its monetization program. This policy extends to all parts of the content, including the video, thumbnail, metadata, description, and tags.&nbsp;</p>







<p>If the content on the platform includes any of the topics listed in the policy, it can potentially be demonetized. The only exception to this is informative or educational content.&nbsp;</p>







<p>The “<a href="https://www.theverge.com/2019/4/5/18287318/youtube-logan-paul-pewdiepie-demonetization-adpocalypse-premium-influencers-creators">adpocalypse</a>” is evidence of stricter enforcement of YouTube’s guidelines around ad-friendly content. Since the 2017 controversy, YouTube has been increasingly enforcing their policies through demonetizing creators who violate their guidelines. They have improved their algorithm’s ability to catch this kind of content, demonetize, and even suppress it. Now that their business strategy heavily invests in the AVOD model, this will only get better and stricter.&nbsp;</p>







<p>Suppressing content isn’t the only tool in their business strategy. YouTube’s algorithm can now prioritize content optimized for ads. They do this through a backdoor curation tool set by advertisers.&nbsp;</p>







<p>YouTube’s algorithm reviews every video to determine if any of these five categories apply:</p>







<ul><li>Tragedy and conflict</li><li>Sensitive social issues</li><li>Sexually suggestive content&nbsp;</li><li>Sensational and shocking</li><li>Profanity and rough language&nbsp;</li></ul>







<p>Now, advertisers can exclude any of these categories. This ability creates a tiered categorization of all content. As a result, YouTube is incentivized to prioritize high tiered content that makes more ad revenue.&nbsp;</p>







<p>This model is very different from the golden era of viral user-generated content. The algorithm isn’t just learning what viewers like; it is learning what advertisers want. This machine learning is why users see product review channels promoted right alongside music channels. The new incentive model is why videos like Harry Potter Puppet pals no longer appear on the front page of YouTube.&nbsp;</p>







<h2><strong>What this means for creators</strong></h2>







<p>YouTube’s prioritization has evolved from user-generated content to scripted shows to a mix of ad-optimized user and network-generated content. Creators shouldn’t see this as an obstacle. YouTube isn’t a gatekeeper; it is a business partner. Our <a href="https://look.law/how-strategic-alliances-increase-youtube-revenue-per-view/">last post </a>explains how creators could benefit from strategic business alliances with other channels. This alliance can increase YouTube revenue per view and provide leverage to smaller independent channels. The key to these alliances is in structuring a business strategy that benefits both parties. YouTubers in the partner program are already in a strategic partnership with YouTube, whether they realize it or not.&nbsp;&nbsp;</p>


<div id="ub_call_to_action_8cb30d77-8501-448a-b58e-b3966e1e083b">
                <p>Look.Law</p>
                <p>Understanding YouTube’s business strategy helps creators structure their business model around a successful partnership with YouTube. As a law firm specializing in creative entrepreneurship, we can help creators innovate and restructure their business strategy in light of these trends. Contact us for more consul on this or any of our service offerings.&nbsp;</p>
                </div>



					                </div></div>]]>
            </description>
            <link>https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657529</guid>
            <pubDate>Fri, 02 Oct 2020 00:14:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Community Moderation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657148">thread link</a>) | @minimaxir
<br/>
October 1, 2020 | https://www.joinclubhouse.com/on-community-moderation | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/on-community-moderation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Oct 1, 2020</p>
      <p>Since <a href="https://www.joinclubhouse.com/check-1-2-3">our last blog post</a>, Clubhouse has gone from a small community of beta testers to a growing network of communities, made up of people with vastly different opinions, experiences, worldviews and perspectives. This past week, people on Clubhouse have hosted several intense conversations on topics of identity, ethnicity, gender, racism, and religion. These conversations led to a number of serious incident reports, and we received questions and concerns from our community about how we plan to scale safety and moderation on Clubhouse. In the wake of this, we wanted to share some thoughts regarding what we stand for as a company, what we will and will not tolerate, what we are doing to prevent abuse, and how we plan to empower conversation hosts with better moderation tools as we grow.</p>
      <p>First, we unequivocally condemn Anti-Blackness, Anti-Semitism, and all other forms of racism, hate speech and abuse on Clubhouse. Our <a href="http://community.joinclubhouse.com/">Community Guidelines</a> and <a href="http://tos.joinclubhouse.com/">Terms of Service</a> make this clear, and we have trust and safety procedures in place to address any violation of these rules. People who violate them are warned, suspended, or removed completely from the platform, depending on the severity of the offense. This is a critical area of investment for us as a company and we are working hard to continue building tools and policies that are robust and that account for the unique dynamics of real-time voice conversations and group discussions.</p>
      <p>Second, we celebrate the fact that Clubhouse is not one single community, but a network of interconnected and diverse communities. As these communities grow, we need to provide moderators and club leaders with better tools and infrastructure to bring people together. Our goal is to empower them to host important, and even difficult, conversations—because some of the most powerful moments on Clubhouse happen when you find yourself speaking with a room full of people whose backgrounds and experiences are completely different from your own. These conversations often go on for hours, spilling out into breakout rooms full of people connecting, debating, evolving their worldviews and recognizing their blindspots. Our hope for Clubhouse is that it can be a new type of network based on empathy, discussion and sensemaking, rather than polarization. We think social media needs more of this.</p>
      <p>PREVENTING ABUSE</p>
      <p>Our Terms of Service and Community Guidelines define what type of behavior is allowed on Clubhouse and we are committed to addressing behavior that violates these rules. Here is what we’re doing to help with that:</p>
      <ul>
          <li><u>We’re taking action on all incident reports.</u> Any time someone reports a violation of our Terms of Service or Community Guidelines, we immediately investigate it. We don’t discuss these investigations publicly for user privacy reasons, but they are happening, and when rules are violated, corrective action is taken. This week, we’re also shipping real-time systems to investigate incidents more quickly and empower moderators to restrict and end rooms.</li>
          <li><u>We’re continuing to scale our trust and safety operations</u>. This is an ongoing effort for us that spans people, policy and product. On the people side, we’re focused on:</li>
          <ul>
              <li><u>Adding advisors.</u> We are building a team of advisors with deep expertise in trust, safety, diversity and inclusion to provide ongoing advice and input.</li>
              <li><u>Engaging directly with the community.</u> Since the earliest days of Clubhouse we’ve been engaging deeply with a diverse cross-section of our community to understand their needs—through weekly Town Halls, New User Orientation sessions and deeper discussions, both on Clubhouse and off. We plan to continue the dialogue and see how these formats can be improved. We also use these discussions to continuously evolve our Terms of Service, Privacy Policy and Community Guidelines. These will be living documents.</li>
              <li><u>Growing our team.</u> Our trust and safety efforts are staffed to respond swiftly to incident reports, and we plan to proactively scale this operation as we grow. </li>
            </ul>
          
          <li><u>We’re shipping a wave of new safety features</u>. Over the past couple months we introduced blocking, muting, in-room reporting, and the ability for moderators to end a room. This week we are shipping a wave of new enhancements to make in-room reporting more real-time, specific and robust. We are also making the Community Guidelines accessible from every room and shipping new features to empower Clubhouse moderators.</li>
        </ul>
      
      <p>EMPOWERING MODERATORS AND CLUB LEADERS</p>
      <p>As we take these steps, we want to avoid conflating abuse with other things that can feel uncomfortable—like differences in opinion or conversational style. Abuse, racism, religious intolerance, sexism and hate speech are never okay. Targeted and coordinated harassment is never okay. But what about general rudeness? Or holding opposing political viewpoints? While these things might seem jarring, we don’t believe they should be banned. We want to make sure that when you use Clubhouse, you get to choose your communities, your rooms, and your style of conversation. Here’s what we’re working on to enable this:</p>
      <ul>
          <li><u>Allowing clubs to set their own norms.</u> With our next release, club founders will be able to write rules that are specific to their clubs—to share their community values, communicate their norms, and define the dos and don'ts for speaking. When people join the club they'll be asked to agree to the rules. And when the club hosts a public conversation, non-members will be asked to agree to the rules before speaking. We think this will help people create intentional gathering spaces that cater to many interests and styles. These rules will supplement the Community Guidelines, which still apply to everyone.</li>
          <li><u>Hosting formal moderator training sessions.</u> There is no single way to moderate, and each room can have its own style. To help with this, we’re going to start offering regular moderator training sessions on the app, to ensure that people who wish to host discussions are equipped with the tools and knowledge they need.</li>
          <li><u>Improving moderator tooling.</u> Great moderators create great conversations, and we need to empower them with the right tools. This week we are building infrastructure that will allow us to notify moderators when there is a safety concern related to their room. Moderators can also tap the “End Room” button anytime if they feel the conversation is getting out of hand.</li>
          <li><u>Adding moderator badges.</u> This is a small thing, but it’s easier to provide a speaker with feedback when you know who’s in charge of the room. These will be live in the next release.</li>
        </ul>
      
      <p>The world is not a monoculture, and we want Clubhouse to reflect that. Ideally the experience is more like a town square, where people with different backgrounds, religions, political affiliations, sexual orientations, genders, ethnicities, and ideas about the world come together to share their views, be heard and learn. Some of these communities come together to debate. Some come to relax and joke around. Others hold listening parties and fireside chats. We think many styles should be supported, and we’re working on tools to help everyone create their own space, deepen friendships, meet new people and have meaningful discussions—in the way that suits them best.</p>
      <p>Clubhouse is nothing without the community, and we are immensely grateful for all of your ideas, emails, tweets, support and critiques. We’ll continue working around the clock on all of this as we open it up to more of the world. Thank you! 🙏🏽</p>

    </div></div>]]>
            </description>
            <link>https://www.joinclubhouse.com/on-community-moderation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657148</guid>
            <pubDate>Thu, 01 Oct 2020 23:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMware Fusion 12 Metal Support]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656836">thread link</a>) | @wila
<br/>
October 1, 2020 | https://www.vimalin.com/blog/fusion-12-0-metal-support/ | <a href="https://web.archive.org/web/*/https://www.vimalin.com/blog/fusion-12-0-metal-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			<div>
				
				<article id="post-1344">	
			<figure>
		<img width="1136" height="918" src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" alt="VMware Fusion 12 Metal Support" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1136px) 100vw, 1136px" data-lazy-src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</figure>
			<div>
					
				
									<div>
				
<p>Ok.. I’m so ecstatic.. a quick blog post must be written…</p>



<p>On VMworld’s “What’s New with VMware Workstation and VMware Fusion”, Michael Roy dropped a bomb in his last “One more thing” note.</p>



<p>He showed off “Metal Support” in a macOS guest… Now we have been told for years that we cannot get 3D Acceleration in a macOS guest, so seeing that was already pretty great. Something to look forward to.<br>In that same presentation he also showed the .vmx settings in order to get that working. Once the feature lands… </p>



<p>So of course immediately after the presentation I _had_ to try, even while it is only supposed to be working in a future version of VMware Fusion 12.0.<br>I got a “Invalid configuration” error (or something along those lines). <br>OK.<br>Silly me did not look at the vmware.log file, so today I was poking Michael a bit on twitter and asking about how well Metal works on Big Sur beta 9 and that it is “so hard to wait” and he tells me “but you can try it yourself already”… 😮</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>You can totally use it today actually, but AutoFit doesn't work (needs new tools that haven't shipped yet… future versions won't require Tools at all)</p><p>svga.present="FALSE"<br>appleGPU0.present="TRUE"</p><p>appleGPU0.screenWidth=1680 appleGPU0.screenHeight=1050</p></div>— Michael Roy (@mikeroySoft) <a href="https://twitter.com/mikeroySoft/status/1311754703055675392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>OMG.. that’s when I realized that I had missed a detail..</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Ohh… I had not put the svga.present="FALSE" line and now I see what other precondition I missed (silly me)…</p><p>vmx| I005: AppleGPU: Apple GPU support is not available: requires macOS 11.</p><p>Looks like I will update that box to macOS 11 right now.</p></div>— Wil van Antwerpen (@wilva) <a href="https://twitter.com/wilva/status/1311759349572870144?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>Also my host wasn’t running Big Sur yet (I had only run it in a VM)<br>… so… next hour or so I was frantically busy installing Big Sur Beta 9 on my 2014 Mac Mini and YES… IT DOES WORK and it is SOOOO SMOOTH</p>



<figure><img loading="lazy" width="1024" height="827" src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is the best thing since sliced bread.</p>



<div><p>THANK YOU VMware Fusion team!</p><p>In summary:<br>This is not an officially released feature, treat it what it is: Experimental<br>Required: minimum of macOS Big Sur as host OS<br>Required: minimum VMware Fusion 12.0<br>Guest OS support: So far I have only gotten this to work with a macOS Big Sur guest (but I haven’t tried others beyond macOS Mojave)</p><p>You have to add the following lines to the .vmx file of your VM in order to test this:<br><code>svga.present="FALSE"<br>appleGPU0.present="TRUE"<br>appleGPU0.screen0.width = "1680"<br>appleGPU0.screen0.height = "1050"</code></p></div>



<p>To be honest I don’t even have the lines with width and height, but that’s how you can define that for now.<br>It will only get better from here on once it is officially supported.</p>
			</div>
					
			<hr>
			
					</div>
</article>						</div>	
			
		<!--/Blog Content-->
		         				</div></div>]]>
            </description>
            <link>https://www.vimalin.com/blog/fusion-12-0-metal-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656836</guid>
            <pubDate>Thu, 01 Oct 2020 22:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using artificial intelligence to make publishing profitable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24656437">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1fd98981423ebe5f9a2e"><p><h2>Artificial Intelligence has significant implications in making publishing profitable – from automation to improvements in advertising. Let’s dive into what AI is, as well as the potential applications within the publishing industry to make it profitable.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601450467819_4883"><div><h3><strong>What is AI?</strong></h3><p>Artificial intelligence, or AI, refers to the ability of tools or technology to perform tasks that would normally require human intelligence to complete.&nbsp;</p><p>Machine learning is a subset of AI in the computer science space – where the platform or model learns from an existing data set so that it can understand the underlying trends and patterns. This knowledge is then used by the machine learning models to make predictions or determine outcomes from the new data it encounters.</p><p>In other words, the computer model uses statistical techniques to learn how to get better at a task, whether that be categorizing data or predicting if a client is a good fit for a certain product. For the model to learn to do this without specific programming, it must analyze existing data that is already pre-labeled.</p><p>Deep learning is another subset of artificial intelligence that involves the creation of a neural network, which has layers and layers of data processing. This type of AI can make deep connections and gain valuable insights from a dataset since it processes information almost like the human brain does.</p><h3><strong>Goals of Artificial Intelligence in Publishing</strong></h3><p>The goals of artificial intelligence in publishing include automating story production and evaluating content automatically.&nbsp;</p><p>The Associated Press started using AI back in 2015 for story automation. They understood that machine learning could create content such as public company earnings report recaps since they need details and accuracy but do not require much creativity.&nbsp;</p><p>They took this further in 2016 when they developed an AI platform that could report on Minor League Baseball games – the machine learning model could incorporate statistics and highlights that, again, are strictly fact-based.&nbsp;</p><p>This is just the beginning for automatic story production, and as artificial intelligence platforms become more accessible there will be more publishers utilize it to create automated content.</p><p>Another goal of artificial intelligence in publishing is evaluating content. A machine learning model can help an editor when making decisions regarding moderation and editing.&nbsp;</p><p>AI can be used to automate complex tasks, such as comparing the characteristics of a manuscript to those of a bestseller to see where improvements can be made. This can help editors focus on the most marketable content and save time and effort narrowing them down.&nbsp;</p><p>Automated text analysis can optimize plagiarism detection as well as copyright enforcement! Artificial intelligence can eliminate some of the tedious work involved with researching copyrights and ensuring that the content being published is 100% authentic.&nbsp;</p><p>Comment moderation can be significantly improved as a result of artificial intelligence. Machine learning models can save publishers valuable time and resources by automatically detective inappropriate or abusive labels and comments – and removing them.&nbsp;</p><p>Reducing the workload of human moderators can allow publishers to open more content for commenting and facilitate a wider scope of articles. The New York Times has already implemented automation within the moderation space, and this has allowed them to open up more content for commenting – where previously they capped it at 10% of their articles.&nbsp;</p><h3><strong>Artificial Intelligence and Advertising</strong></h3><p>Artificial intelligence can also help publishing firms when it comes to advertising. It can improve everything from engagement to the structuring and design of content.&nbsp;</p><p>AI platforms allow publishers to personalize content for marketing campaigns since statistics have shown that personal advertisements have a higher level of engagement – and therefore, a better return on investment.</p><p>Machine learning models will analyze content and engagement to curate newsletters and articles that fit right in with your audience segment. Research performed by McKinsey found that this level of personalization is essential and can increase the efficiency of marketing budgets by up to 30%!</p><p>This type of personalization can also be used for the automation of recommendations. You can gain insights into what your readers like based on their browsing history, and then the machine learning model can identify trends and patterns.&nbsp;</p><p>With this information, you can give your readers personalized recommendations on other content they may enjoy. This will help your firm boost engagement as well as make your advertisements much more personalized.&nbsp;</p><h3><strong>Conclusion</strong></h3><p>These are just a few aspects in which artificial intelligence can impact publishing by reorganizing the workforce towards better things with the help of automation and improve revenue by personalizing content and experiences for a diverse set of users. Publishing companies can benefit a lot by using artificial intelligence in tough economic climates and weather the storm and keep the lights on. </p></div></div></div>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656437</guid>
            <pubDate>Thu, 01 Oct 2020 21:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[COVID19 Blues: My father, the immune system, & the philosophy of Thelonius Monk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656227">thread link</a>) | @jinnko
<br/>
October 1, 2020 | https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/ | <a href="https://web.archive.org/web/*/https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><img width="1688" height="2250" src="https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1.jpeg" alt="" loading="lazy" srcset="https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1.jpeg 1688w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-416x555.jpeg 416w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-225x300.jpeg 225w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-768x1024.jpeg 768w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-1152x1536.jpeg 1152w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-1536x2048.jpeg 1536w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-660x880.jpeg 660w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-450x600.jpeg 450w" sizes="(max-width: 1688px) 100vw, 1688px"></p><p>I am not a doctor.</p>



<p>But my father is.</p>



<p>In fact, he is an immunologist.</p>



<p>So what follows below is not medical advice but a story of reconciliation (with some possible medicinal effects).</p>



<p>You see, my father and I have been more or less estranged for the last few years – and even before that we only communicated once in a while, maybe once a year, since we have been living in different continents, me in Canada and my father in Japan, for more than two decades.</p>



<p>It is only really the last few months that we have had consistent amicable communication for the first time in decades.</p>



<p>As far as back as I can remember, there has been a distance in my relationship with my father, a stuckness in understanding each other’s way of seeing the world. He wanted me to follow in his footsteps and become a scientist.</p>



<p>I naturally went the opposite direction, studied comparative religions, then ditched that, went to art school, and finally, ended up as a therapist after what was basically a (still unfolding) mid-life crisis.</p>



<p>Part of me resisting his desire for me to do scientific research was undoubtedly related to his unfortunate position in our family. He has always been a kind of lone genius, whose work we understood to be incredibly impactful but had no idea what it actually meant. Like many archetypal, or maybe more appropriately, stereotypical, ‘gifted children’, he had little everyday life skills to maintain relationships – something that I have obviously inherited a bit of myself.</p>



<p>What I do remember of him fondly from my childhood is that he absolutely loved talking about pandemics. <a rel="noreferrer noopener" href="https://www.goodreads.com/book/show/7670.The_Andromeda_Strain" target="_blank">Andromeda Strain</a> was a favored book in our household.</p>



<hr>



<p>Fast forward to 2020 and there is a global pandemic phenomenon – and it has brought me back to understanding him and his work. We’re emailing back and forth.</p>



<p>It’s hard to describe the ironic humour I find in how I am spending hours obsessively trying to understand the so-called immune system and the functions of its many minions, T-cells, B-cells, lymphocytes, neutrophils, and so on – all these labels and terms that as a kid made my brain just turn off and my eyes roll into the back of my head at the dinner table.</p>



<p>But as fate has it, my foray into magick, animism, and neurobiology has ultimately led me back discover that we have been exploring the same world all along – just from different entrances – our neurological and immune systems are a part of a larger whole that modulates together.</p>



<hr>



<p>I want to switch gears here and officially welcome another character to this story: COVID19. This pandemic spirit who has caused much death and chaos has also been responsible for accelerating the timeline for my father and I’s reconciliation.</p>



<p>It’s only with the anxious fear of death that COVID19 inspired in me that I would have bothered to do the research to look up how it causes fatality, through which I learned about <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cytokine_release_syndrome" target="_blank">cytokine storms</a> – a phenomenon that happens when a viral infection of other factor triggers a hyper-inflammatory response that can overwhelm the body. In the case of COVID19, cytokine storms can be triggered by pneumonia it brings on in some patients and can cause a fatal chain of failures in the lungs and other organs.</p>



<p>Hearing that COVID19 ultimately kills through an autoimmune response brought me a bit emotional relief, being able to anchor into something I already feel confident I know something about – even though I wasn’t nearly settled about it. I’ve been intrigued by chronic autoimmune conditions and their connection to nervous system dysregulation from complex trauma, including ancestral trauma, for quite a while.</p>



<p>I emailed my father about the connection between the vagus nerve and cytokine storms.</p>



<p>His reply back was excited, even elated, and a lot of garbly jargon. To his credit though, it did have some keywords that led me on to better google searches about <a rel="noreferrer noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4082307/" target="_blank">the relationship between the inflammatory reflex and the vagus nerve</a>.</p>



<p>I have to say that it’s hilarious – even endearing – to read his emails about the vagus nerve and the way it regulates the immune response but remembering that he has had very little idea of how to do exactly that in his real daily life.</p>



<p>(Apparently though, he has purchased a <a rel="noreferrer noopener" href="https://www.goodreads.com/book/show/520624.Healing_Trauma" target="_blank">book by Peter Levine on somatic experiencing</a>, recommended by his therapist – who he has only been seeing for three months after being essentially reprimanded by me – and has also been doing loving kindness meditations, including thinking of me.)</p>



<hr>



<p>Further researching the neuroimmune modulation brought me to <a rel="noreferrer noopener" href="https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1526-0968.2002.00452.x" target="_blank">the work of another prominent Japanese immunologist, Toru Abo</a>.</p>



<p>One of Abo’s major contributions of conceptualizing how the sympathetic and parasympathetic branches of the nervous system shift our immune response:</p>



<ul><li>The sympathetic nervous system, activated in states of excited play and exploration, or fight or flight when in a survival response, tend to shift the immune system to produce granulocytes, of which the common type are neutrophils. This is significant as neutrophils and other granulocytes are specialized in handling acute distress and involved in the body’s inflammatory response. </li><li>The parasympathetic nervous system, activated in states of rest-and-digest, or freeze when in a survival response, tends shift the immune system to produce lymphocytes, which are particularly effective in managing viral infections as well as preventing chronic issues such as development tumors.</li></ul>



<p>Abo attributes the existence of these two distinct immunomodulation styles to the body’s needs in wild vs. social environments. The activities of hunting and foraging, that engage sympathetic activation, requires the body to be protected from cuts and bacterial infections that may come in through those open wounds. Hence, the production of granulocytes. On the other hand, in relaxed social environments that engage parasympathetic activation, such as a village with livestock, the main threats are viral infections that spread human-to-human or animal-to-human. This is in alignment with the production of lymphocytes when we are in rested states. </p>



<p>This leads us to consider the connection between the relationship between chronic stress and the fatality of COVID19. It is apparent from Abo’s hypothesis that constant sympathetic activation means the body’s balance of granulocytes to lymphocytes becomes deeply thrown off. Indeed, a high neutrophil-to-lymphocyte ratio is said to be a key indicator of poor COVID19 outcomes as it is connected to an increased probability of cytokine storms.</p>



<hr>



<p>Relevant to this, I watched <a href="https://www.youtube.com/watch?v=oyijHfL-W7w" target="_blank" rel="noreferrer noopener">a talk with Bruce Lipton</a>, who broke down how the fear of COVID19 is likely to create a dynamic that exacerbates the fatality of it because of fear’s impact on the nervous system. There is likely a large part of the COVID19 phenomenon that is generated by the fear-dependent nature of our communication across various media platforms – it’s bad mass hypnosis.</p>



<p>I had to agree.</p>



<p>One of our great challenges in this pandemic, and life in general, is: how do we face destabilization in a reasonably regulated state, neither overly activated or passively dissociated by threat.</p>



<p>It seems like most governments are not capable of such a neurological feat. In some ways, I can’t blame them. I’ve had great personal difficulty managing dysregulation has been for me – and I’m someone who is constantly training their nervous system.</p>



<p>So how do we deal with this fear?</p>



<p>Something that I believe is a big part of this is how we conceive of our immune system itself.</p>



<hr>


         



<hr>



<p>Someone who follows my blog sent me a reference to a book by Ed Cohen called: “<a href="https://www.dukeupress.edu/a-body-worth-defending" target="_blank" rel="noreferrer noopener">A body worth defending</a>”. It was a bit of a heady read for me, based on critical theory, but it still had important nuggets.</p>



<p>The term immunity in fact comes from law and originates in the Roman Empire. It refers to being exempt from legal bounds. Immunity began to be used in biology in the 18th century to describe the paradigm of seeing the body as a territory that is owned by man, where there is a constant need for invaders to be warded off. This means our modern conception of the immune system has an ideological connection to imperialism in all of its forms, which of course is an entirely fear-based collective behavior.</p>



<p>What I found fascinating about this was that in the end, it seemed that the operation of our immune system came down to a highly philosophical question of distinguishing between self and non-self.</p>



<p>Truth be told, I spent a few hours trying to figure out <a rel="noreferrer noopener" href="https://www.khanacademy.org/science/high-school-biology/hs-human-body-systems/hs-the-immune-system/v/self-versus-non-self" target="_blank">how the immune system determines what is self and what is not</a> and ultimately found no satisfying answers. Our entire body functions on a metaphysical self-understanding that isn’t actually quantifiable and is quite arbitrary.</p>



<p>I believe this also means that our philosophical understanding of ourselves may change how our immune system operates. And in fact, I think this is what autoimmune illnesses teach us, including COVID19.</p>



<hr>



<p>The stakes of understanding how our self-perception impacts our nervous system, and how that in turn deeply changes how we interface with the world, isn’t just applicable to the functioning of our immune system.</p>



<p>It isn’t lost on me that the mechanism of cytokine storms echo <a rel="noreferrer noopener" href="https://selfishactivist.com/understanding-accountability-abuse/" target="_blank">the self-inflicted violence of call-out/outrage culture</a>. It is again, nervous systems overloading and protection systems going into a hyperdrive that causes internal collapse.</p>



<p>In my observation of <a rel="noreferrer noopener" href="https://selfishactivist.com/understanding-accountability-abuse/" target="_blank">accountability abuse</a> in social justice communities, time and time again, I’ve seen the cultural somatic ‘immune system’ kick in to mistakenly over target individuals because of the hyper-activated voice of a few, while failing to address deeper chronic failures, leaving dysfunctional organizations and community leaders unquestioned and intact.</p>



<p>Here too, there is a deeply philosophical problem of “who are we, who are we not”, behind our failings in collective wellbeing.</p>



<hr>



<div><p>With that diversion, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/">https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/</a></em></p>]]>
            </description>
            <link>https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656227</guid>
            <pubDate>Thu, 01 Oct 2020 21:17:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer on engineering delivery metrics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656191">thread link</a>) | @Anon84
<br/>
October 1, 2020 | https://leaddev.com/primer-engineering-delivery-metrics | <a href="https://web.archive.org/web/*/https://leaddev.com/primer-engineering-delivery-metrics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div> <p>Before joining&nbsp;<a data-gc-link="https://stripe.com/" href="https://stripe.com/">Stripe</a>, I had the opportunity to build, grow, and lead the&nbsp;<a data-gc-link="https://splice.com" href="https://splice.com/">Splice</a>&nbsp;engineering organization for almost four years (yes, still I mix up the names). The most challenging engineering problem I’ve had to tackle so far has been working on accelerating software delivery in an organization that grew from 5 to 55+ engineers in my first 18 months. As the Splice team expanded, our ability to deliver software ground to a halt. The processes that worked when the company was small couldn’t support the explosive growth, and we needed to find a way to get back on track. By focusing on delivery metrics, we were able to increase the rate of software delivery drastically, and you don’t have to take my word for it, let’s look at a graph of cycle time (or delivery lead time) from May 2018 to April 2019.</p>
<p><img alt="Chart showing delivery lead time" data-id="null" src="https://lh3.googleusercontent.com/p4BZUo4UtAzkdOV3uqK88jTx34Cy6e_p1OJRC3WeEHBTdY1mobwx17QYg8zZly7NPJ0DACLoAVeP6LIo6APVbnD0wCnAYypKng1eiqT6qkZI3sIWbNfh-RjIvMktsp4FeNZvfxT2" title=""></p>
<p>This graph shows how we stabilized&nbsp;<strong>delivery lead time</strong>&nbsp;over a year. This metric’s average also decreased from a few hundred hours to the lower tens, even reaching 20 hours on our best delivery weeks despite frequent organization change. We did this without working longer hours or even weekends, but rather by engineering our processes using metrics to observe and direct the desired change. Today, any team can take control of their ability to deliver production-ready software at an accelerating tempo by understanding and adopting a few simple metrics. Let’s dive in.&nbsp;</p>
<h2>What are engineering delivery metrics?</h2>
<p>Engineering delivery metrics are a method of measuring the software delivery phase in software development. We measure delivery, and not the entire development process because the design phase of software varies significantly. In the early stages of software, we don't know what we're looking to build, so to make our lives easier, we focus on the portion of the pipeline where we can have more control as engineers. To do this, we can assume that the delivery process begins when we commit code and ends when code is running in production.</p>
<p><img alt="Diagram showing coding timeline" data-id="null" src="https://lh5.googleusercontent.com/mwxLQLKwZjLRvwgi31jE-SaioQlO77r0LlyBYghPafBpuojTbBWl_Cz3eWPZZ7n0bquUD1gBKt0-KQyMczOgCRFdBpSNrfhSwB0UrjHs-JVHusrl45ZgrAskb_wII5KjoxpDamKJ" title=""></p>

<table data-wrap-id="table-id-faaet"><tbody><tr data-wrap-id="table-row-xfuvw"><td data-wrap-id="table-cell-ysmwy">
<p><strong>Product design &amp; development</strong></p>
</td>
<td data-wrap-id="table-cell-ilfzf">
<p><strong>Product delivery</strong></p>
</td>
</tr><tr data-wrap-id="table-row-bbmel"><td data-wrap-id="table-cell-fwtnn">
<p>Create new products and services that solve customer problems using hypothesis-driven delivery, modern UX, and design thinking.</p>
</td>
<td data-wrap-id="table-cell-ihcpi">
<p>Enable fast flow from development to production and reliable releases by standardizing work, and reducing variability and batch sizes.</p>
</td>
</tr><tr data-wrap-id="table-row-zjizq"><td data-wrap-id="table-cell-pjyaq">
<p>Feature design and implementation may require work that has never been performed before.</p>
</td>
<td data-wrap-id="table-cell-hqhxx">
<p>Integration, test, and deployment must be performed continuously as quickly as possible.</p>
</td>
</tr><tr data-wrap-id="table-row-erjbr"><td data-wrap-id="table-cell-fulwo">
<p>Estimates are highly uncertain.</p>
</td>
<td data-wrap-id="table-cell-nkval">
<p>Cycle times should be well-known and predictable.</p>
</td>
</tr><tr data-wrap-id="table-row-pbjpf"><td data-wrap-id="table-cell-maaty">
<p>Outcomes are highly variable.</p>
</td>
<td data-wrap-id="table-cell-nbqab">
<p>Outcomes should have low variability.</p>
</td>
</tr></tbody></table><p><sup><a href="#footnote1">[1]</a></sup></p>
<p>We can instrument several metrics across the entire delivery process, and their effectiveness depends on the outcomes we're seeking for our organization. Before we measure, we must ask, ‘what are we trying to achieve with these?’ Metrics are neither good nor bad. They can be useful or harmful, and the results depend on our context and ability to use them.</p>
<p>Some examples of metrics can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Build time</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Code volume</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Code churn</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Time to merge</li>
</ul><p>In the absence of any context, it's hard to tell if any of these metrics will produce the desired results. For example, would we&nbsp;<a data-gc-link="https://www.infoworld.com/article/2072312/lines-of-code-and-unintended-consequences.html" href="https://www.infoworld.com/article/2072312/lines-of-code-and-unintended-consequences.html">get any positive outcomes if we measured lines of code</a>? Deleting code can sometimes produce better results than adding more.</p>
<h2>Why use delivery metrics?</h2>
<p>Knowing why we measure can be more impactful than what we measure. Software delivery is an emergent property of a software engineering team and the processes it adopts. For example, heart rate is an emergent property of the heart and can give us valuable information about its health. In conjunction with useful metrics, well-defined outcomes offer us a window into how our organization delivers software. Metrics help us observe our process and evolve it.&nbsp;<br>
&nbsp;</p>
<p>At Splice, the desired results involved eliminating roadblocks that engineers had in shipping software because we wanted to learn fast.&nbsp; Product engineering teams in early-stage companies are learning with every line of code they get in front of users. If we wanted to achieve our mission of ‘enabling Splice to learn faster than the market by delivering production-ready software at an accelerating tempo’, we needed a way to see what was holding us back so that we could change it. If we were a company that supported enterprise customers, our emphasis might have increased our services’ reliability over our iteration speed.</p>
<p><img alt="Chart showing code pushes at Splice" data-id="null" src="https://lh4.googleusercontent.com/6Br30nuJ28xuwlhfxCPSZxaR124VxWkrmrT3HQbETVsnegiB5BYwEsE8nMFwhJFoHyrTnd12wCiJ34-t1jpcx7to5-hIHnxG0NFb2OPN8TgytiACBHtGbkjzsfblLNXGUEzdWOMv" title=""></p>
<p><em><small>One year of code pushes at Splice during our delivery improvement plan, showing how we improved our throughput without growing in size or working longer hours.</small></em></p>
<p>Before you pick what you want to measure, define why you want to measure it. A few examples of outcomes you might be looking for can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Better reliability</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Improved quality</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Lower effort</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Increased throughput</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Cost-effectiveness</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Staffing efficiency</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Faster learning</li>
</ul><h2>Which delivery metrics are useful?</h2>
<p>When you search the web for "engineering delivery metrics", the results are abundant and not always useful or tailored to your outcomes. When we embarked on this journey, the most valuable resources I found were a series of reports compiled by different groups or companies we had to mix-and-match from to get actionable results. Fortunately for us, Dr. Nicole Forsgren and her team have done all the heavy lifting and summarized it in a book called&nbsp;<a data-gc-link="https://www.oreilly.com/library/view/accelerate/9781457191435/" href="https://www.oreilly.com/library/view/accelerate/9781457191435/"><em>Accelerate.</em></a>&nbsp;It sits on my desk, next to&nbsp;<a data-gc-link="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F" href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F"><em>The Manager's Path</em></a>&nbsp;by Camille Fournier. These two books mark the beginning of a new era in engineering leadership, where learning how to be a great leader doesn't require oral tradition inside an established tech company.</p>
<p>In&nbsp;<em>Accelerate</em>, Dr. Forsgren and her team set the foundation of four metrics they found to be good indicators of software delivery performance across thousands of organizations. From there, they also proposed a capabilities framework that can allow software organizations to increase their performance and drive better business outcomes. A fascinating conclusion is how they were able to find a relationship between software delivery and organizational performance. It seems that if we're good at delivering software, then our company as a whole performs better.</p>
<p>If you've read&nbsp;<a data-gc-link="https://leaddev.com/debugging-engineering-velocity-and-leading-high-performing-teams" href="https://leaddev.com/debugging-engineering-velocity-and-leading-high-performing-teams">Smruti's article on debugging engineering velocity</a>, you've already encountered the four metrics outlined by Dr. Fosgren, and the ones we found to be the most useful as we drove change at Splice.</p>
<h4>Software Delivery Performance Metrics</h4>
<p>⌚️&nbsp;<strong>Delivery lead time</strong>. How long it takes code from commit to production.&nbsp;<br>
🚢&nbsp;<strong>Deployment frequency.</strong>&nbsp;How often we are deploying to production.&nbsp;<br>
🚒&nbsp;<strong>Mean time to restore.</strong>&nbsp;How long it takes us to restore service after an incident.&nbsp;<br>
🔨&nbsp;<strong>Change failure rate.</strong>&nbsp;The percentage of changes that degrade service or require remediation.</p>
<h3>What about story points and velocity?</h3>
<p><a data-gc-link="https://www.agilealliance.org/glossary/velocity" href="https://www.agilealliance.org/glossary/velocity">Velocity</a>&nbsp;is not a good measure of the software delivery process because it's designed to be a capacity planning tool. When we use velocity to measure productivity, our approach is flawed because:</p>
<p>‘<em>First, velocity is a relative and team-dependent measure, not an absolute one. Teams usually have significantly different contexts which render their velocities incommensurable. Second, when velocity is used as a productivity measure, teams inevitably work to game their velocity. They inflate their estimates and focus on completing as many stories as possible at the expense of collaboration with as many stories as possible at the expense of collaboration with other teams (which might decrease their velocity and increase the other team’s velocity, making them look bad). Not only does this destroy the utility of velocity for its intended purpose, it also inhibits collaboration between teams.’&nbsp;</em><sup><em><a href="#footnote2">[2]</a></em></sup></p>
<h2>How should you use delivery metrics?</h2>
<p>Without knowing the exact problem you or your team faces, it's challenging to make a recommendation that can be helpful. Instead, I&nbsp;<a data-gc-link="https://twitter.com/buritica/status/1277745668505972736" href="https://twitter.com/buritica/status/1277745668505972736">asked engineering leaders for their questions</a>&nbsp;and found some common patterns.&nbsp;</p>
<h3>How do I convince my team about using metrics?</h3>
<p>In the last few years, I’ve advised several companies in the adoption of delivery metrics, and the first hurdle any leader has to cross is to sell their team on the use of these metrics. In my experience, convincing a team to adopt metrics is highly dependent on how well they understand the purpose of measuring, and how much they trust you. Unfortunately, metrics have been used to judge individual performance in ways that have negatively impacted employees beyond their actual performance, such as using lines of code. These poor management practices have eroded the trust between management and collaborators, and it’s normal for engineers to approach metrics with skepticism.&nbsp;</p>
<p>To successfully convince your team to adopt delivery metrics, you must have an obvious purpose for the metrics and solid reasoning for the outcomes you seek. Some questions you should be able to answer to your team members about your intention of measuring the delivery process can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Why do we need metrics?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">What are we going to measure?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Who will have access to these metrics?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Why did we pick these metrics, and which others could we have chosen?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">What is our plan to move these metrics forward?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">How will these metrics impact individuals?</li>
</ul><p>Engineering managers should hold their problem-solving abilities and reasoning to the same standards for engineers in their organization. In my case, writing a proposal that outlined my thinking in the form of an RFC helped iron out the details that weren’t clear, and my team helped make it more robust through their questions. You can&nbsp;<a data-gc-link="https://github.com/buritica/mgt/blob/master/rfcs/up-tempo.md" href="https://github.com/buritica/mgt/blob/master/rfcs/up-tempo.md">read the original version of this document here</a>.</p>
<p>The primary lesson I took from deploying delivery metrics was the importance of trust. For metrics to be successful, I needed my team to trust my intentions and embrace the strategy presented to them, especially when I didn’t have too many answers on the actual results we’d get. Not only should you have answers for the questions outlined above, and possibly others depending on your needs, the answers need to give confidence to your team …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leaddev.com/primer-engineering-delivery-metrics">https://leaddev.com/primer-engineering-delivery-metrics</a></em></p>]]>
            </description>
            <link>https://leaddev.com/primer-engineering-delivery-metrics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656191</guid>
            <pubDate>Thu, 01 Oct 2020 21:12:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golden Wall Post-Mortem (StarCraft II)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656063">thread link</a>) | @tosh
<br/>
October 1, 2020 | http://superouman.net/2020/08/golden-wall-post-mortem/ | <a href="https://web.archive.org/web/*/http://superouman.net/2020/08/golden-wall-post-mortem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Golden Wall’s time in the ladder and tournaments map pools has come to an end. It has been a wild ride, my favourite kind of wild ride. I’d like to take some time to share in this post-mortem what I’ve learnt from Golden Wall.</p>



<p>Creation process</p>



<p>The first version of Golden Wall had a rotational symmetry and had only one path between the two halves of the map and additional paths could be opened by mining minerals. </p>



<figure><img loading="lazy" width="1024" height="765" src="http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-1024x765.png" alt="" srcset="http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-1024x765.png 1024w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-300x224.png 300w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-768x574.png 768w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60.png 1951w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The Teamliquid Map Contest 12 judges didn’t like that the single path could be heavily abused and suggested that I turn the map into a mirror symmetry map. For some reason i only had in mind a diagonal mirror symmetry in mind at that time and I didn’t manage to fit the layout properly while keeping the golden wall landmark. When the next Teamliquid Map Contest started 6 months later, I realized that vertical symmetry was the way to go and I made the appropriate edits.<br></p>



<p>With this new layout, I was able to turn the map into an experimental map while letting players play in a totally standard way if they wish to. This is something I never thought about before and I took this opportunity to try it out. </p>







<p>Main map features</p>



<p>The backdoor in the starting base that is blocked by reduced mineral fields. Backdoors in the starting base blocked by destructible rocks are a notoriously hated map feature. The attacker can easily take them down even early in the game and deal deadly damage to the opponent. </p>



<p>In theory, reduced mineral fields fix that issue because the attacker has to bring many workers that may not be able to make a hole when the defender placed ranged units behind the mineral wall. And in practice, it worked! The defender has complete control whether the path is open or not. This is definitely a map feature I’ll use again.</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>There are reduced mineral fields in the middle. Controlling this area is important when the gold bases aren’t yet open. Players often made the effort to open that path by sending a few workers so this is a success.</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The bottom half is initially completely inaccessible to ground units.  This is a mixed bag because at the same time it allows interesting expansion layouts with different playstyles but also some really dirty strategies with Nydus/Swarm Host and Marine/Tank elevator pushes. If the defender doesn’t preemptively open the reduced mineral fields, these can be a pain to deal with. I initially expected the elevator pushes to be weaker as they require highground vision.</p>



<p>I wanted to experiment with ground area inaccessible with ground units for some time, especially lowground cliffs near expansions. What I’ve seen on Golden Wall makes me more cautious when experimenting with similar island features in the future. </p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The gold bases near the natural bases are very vulnerable to attacks. The proximity of these bases to the natural make them very strong for the extra boost to the economy. I was able to make it balance it out because of how it can be attacked from behind. It is also the shortest path to the bottom half without opening a hole in the starting base. </p>



<p>Usually, placing gold bases near natural bases allows for very strong proxy hatcheries strategies. To prevent that, the natural base has a ramp leading to it and it worked, I barely saw any proxy hatcheries there. That base was a big success!</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>How the map played out</p>



<p>Because of these map features, the games were very diverse. To the point where each player has its own stylistic approach to the map. Most maps are figured out in a few weeks with their timings, attack/drop routes, proxy locations and so on. On Golden Wall however, the meta was evolving every month with seemingly overpowered strategies finding their counter.</p>



<p>These are the final Golden Wall matchup balance stats.</p>



<figure><img loading="lazy" width="841" height="98" src="http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats.png" alt="Golden Wall balance statistics" srcset="http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats.png 841w, http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats-300x35.png 300w, http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats-768x89.png 768w" sizes="(max-width: 841px) 100vw, 841px"></figure>



<p>Source: <a href="https://liquipedia.net/starcraft2/Golden_Wall_LE" target="_blank" rel="noreferrer noopener">https://liquipedia.net/starcraft2/Golden_Wall_LE</a></p>



<p>The map ended up very well balanced for the amount of unusual features it has. With this kind of maps, it’s often a shot in the dark with the balance even with educated guesses about how it would play out theorically.</p>



<p>Conclusion</p>



<p>In the end, Golden Wall is my favourite map i’ve made to this day. It has the highest diversity of opening and strategies and it was a treat to watch them. Some players play completely standard with the top part, some use only the bottom part and others have a mixed use of the two halves. What i love the most about this left versus right map is that some games end up with a top versus bottom layout. Some games even had their players swap their main bases! Crazy.</p>



<figure><div>
<p><iframe title="StarCraft 2: NEW MAP - THE GOLDEN WALL! (uThermal vs Reynor)" width="1150" height="647" src="https://www.youtube.com/embed/3rlNKYAnKfE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>



<p>I am definetly going to reuse some of the features and lessons of Golden Wall in future maps so stay tuned!</p>
	</div></div>]]>
            </description>
            <link>http://superouman.net/2020/08/golden-wall-post-mortem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656063</guid>
            <pubDate>Thu, 01 Oct 2020 20:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Development for Hybrid Remote Dev Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656046">thread link</a>) | @davetwichell
<br/>
October 1, 2020 | https://linearb.io/blog/asynchronous-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/asynchronous-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Hope and optimism are default settings for my LinearB co-founder, Ori Keren. For Ori, one silver lining in this tumultuous year is that 2020 ushered in the age of the hybrid remote work model. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png.webp 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Asynch-2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>“Hybrid remote is how software development teams were always meant to work. It just took 20 years and a global pandemic for us to figure that out.” </p>



<p>Ori believes that, to be highly successful, developers need uninterrupted time to get into a deep state of focus on their task at hand. Getting in “the zone” is hard and when you get interrupted you can’t easily get your deep focus back. </p>



<p>Remote work has eliminated most dev interruptions, right? Not so fast. </p>



<p>Company culture is a powerful force. Like gravity, we don’t see or or think about most days but it effects everything we do. </p>



<div><p>According to Ori, culture is even more powerful than a global pandemic or a new trend like hybrid remote. </p><p>“Working remote was great for our dev team at first. Once we got over the initial disruption of getting equipment and finding a quiet place to work at home, team productivity soared. But then we started noticing our efficiency going down.” </p></div>



<div><p>What happened? Our in-the-office culture grabbed hold and brought us right back to where we were in March. </p><p>“All of the interruptions crept back in… scheduled meetings, impromptu Zoom status meetings…” </p><p>In other words, we were a hybrid remote company with an in-the-office mindset and process. </p><p>You can see the effects here in our Cycle Time trend chart. </p></div>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<div><p>“Being a remote employee used to be a semi-unique experience that came with a certain level of trust, preparation and experience. Then the entire global dev community went remote at the same time, without preparation or understanding of what needs to change.”</p><p>Hybrid remote can be a business advantage for companies embracing it. But only if we adapt our culture and process to make it work. </p></div>



<p>This is how Asynchronous Development was born. </p>







<h2>What is Asynchronous Development?</h2>



<p>Async Dev is an approach to development grounded in asynchronous communication. It works for hybrid remote, full remote and any dev teams that wants to unlock the full creative power of their developers. </p>







<iframe width="560" height="465" src="https://www.youtube.com/embed/w0pw0dcFZ-w?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<p>Async Dev builds on the foundation Agile put in place. Since the Agile Manifesto was published 20 years ago, software development has gone through some drastic changes. Many of those changes like asynchronous communication tools (e.g. Slack &amp; Teams) becoming the default form of communication and hiring remote developers were forced into the spotlight in 2020. </p>



<p>Ori  started wrote the Async Dev manifesto to help engineering and product leaders see how they can change the way they work to turn this new situation into an opportunity. </p>



<p><strong><em>Below Ori explains how Async Dev builds on the Agile and DevOps movements and talk through each of the five core tenets of Async Dev. Listen to the accompanying 60~ second audio clip from Ori in each section or just read the blog</em></strong>. </p>







<h2>The Async Dev Movement</h2>



<p>Hybrid remote development is not new, but 2020 accelerated the adoption of many of the practices already in place. As these hybrid remote methods are normalized globally, we also have to accept the way we work, the processes, and the ceremonies have changed as well. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/history-1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Asynchronous Development acknowledges the importance of movements like Agile and DevOps and offers a new way of looking at development that is a better fit for 2020.&nbsp;</p>











<h2>The 5 Tenets of Asynchronous Development</h2>



<p>There are 5 core tenets of Async Dev that we have adopted to transform the hybrid remote reality into an opportunity to strengthen the alignment between development and the business.</p>







<div><div>
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>
</div></div>







<ol><li>Asynchronous is the default form of communication</li><li>Git is the central element of your development process</li><li>Project Management tools are for planning, not status updates</li><li>Continuous improvement is a daily practice</li><li>Dev teams are the core of the business</li></ol>











<figure><blockquote><p>LinearB built a new kind of project board exclusively for hybrid remote dev teams.</p><p><span><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get our Devboard free</a></span></p></blockquote></figure>







<h2>Tenet 1 – Asynchronous is the default form of communication</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png.webp 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-1.mp3"></audio><figcaption>Click here to listen to Ori</figcaption></figure>







<p>Asynchronous communication means using collaboration tools and mentions by default. It helps reduce context switching, avoid unnecessary interruptions, and increases productivity. </p>



<p>After LinearB went full remote back in April of 2020, we analyzed our development team’s metrics to understand exactly how this change effected the productivity and efficiency of the team. </p>



<p>In true Asynchronous fashion, 92% of developers at LinearB were writing more code, while PR sizes and Cycle Times increased. This clearly tells us that fewer interruptions means greater individual productivity. It also clearly shows what we needed to adapt the way worked to the new circumstances if we were going to continue delivering at the same level as pre-wfh. </p>



<p>At LinearB we have started taking a closer look at the function of the daily stand-up and how to use that time to best suit our team. Now that we are a hybrid remote development team with up to the minute updates on issue statuses using LinearB, we use our stand-up time to connect on a personal level, and then just talk about blockers. It’s not perfect, but it’s been a nice adaptation to our new reality.</p>







<h2>Tenet 2 – Git is the central element of your development process</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png.webp 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-2_2-1.mp3"></audio><figcaption>Click here to hear Ori</figcaption></figure>







<p>Whether you use GitHub, GitLab, Bitbucket, Azure DevOps or other git flavor, most of the stages of the development cycle either start or involve your git system. How you choose to configure, deploy and utilize it has a great impact on your dev process. </p>



<p>In addition the most up to date status of work progress resides in the git system. Fortunately git was built with open source in mind so most of the phases (coding, review, merge) do not require mandatory synchronous communication and can be executed in different places and different times.</p>











<h2>Tenet 3 – Project Management tools are for planning, not status updates</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png.webp 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet3_2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Whether your team uses Jira, Trello or something else, project management tools are great for planning an iteration or the next week, but trying to use them to enrich dozens of micro decisions that dev teams are taking every day will slow down productivity. </p>



<p>Every update to the work status while in ‘building mode’ should be with dev first in mind, meaning it should automatically reflect the status based on actual git activity and it should mainly serve the people that build and ship the software.</p>







<figure><blockquote><p>Does your current project board</p><p>give you more questions than answers?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Try the LinearB Devboard free</a></p></blockquote></figure>







<h2>Tenet 4 – Continuous improvement is a daily practice</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png.webp 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/tenet4new.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Data should always be accessible to everyone – no gate keepers, not just data engineers, and not just reviewed in meetings by management.</p>



<p>Your KPIs and how you decide to utilized them will define your culture. </p>



<p>Key Principles for Data Usage: </p>



<ul><li>Team-based data over developer stack ranking</li><li>Measure process over output</li><li>Measure empiric over subjective</li><li>Focus on leading indicators vs. lagging indicators</li><li>Establish baseline data points and trends</li><li>Make sure it’s actionable</li></ul>







<p>Data should be used in an ethical way and cannot replace good managers with good soft skills and human interaction.</p>







<figure><blockquote><p>High-risk code &amp; stuck PR Slack Alerts are pretty amazing.</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get them Free with LinearB</a></p></blockquote></figure>







<h2>Tenet 5 – Dev teams are the core of the business</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png.webp 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-5_1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>The best companies in the world evolved from developers that were highly aligned with business and market needs. Dev-led companies empower developers to make decisions on behalf of customers and the business by giving them context instead of instructions.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>We believe that ‘developers’ and ‘business’ are not disjoint sets and sometimes the most important business decisions are hiding in code lines. That is why the best businesses should focus on pushing context to dev teams, and dev teams should provide transparency into their decision making so both can enjoy a refinement cycle.</p>



<p>This is probably the hardest part of making Async Dev a reality because, as dev leaders, it is the element we have least control over. We need buy-in from throughout the business. </p>







<h3><strong>Here are 5 practical steps you can take today to start practicing Async Dev:</strong></h3>







<h4>1) Cut status updates from your daily stand-up</h4>



<p>Instead focus on what matters – who needs help and whether you’re going to ship on time. Async Dev means never spending valuable meeting time on status updates when everyone could take 5 minutes on their own before the meeting to see what happened yesterday and what’s happening today. <a href="https://linearb.io/blog/make-daily-better/" target="_blank" rel="noreferrer noopener">Click here to get 16 tips</a> for how to run a better daily stand-up. </p>







<h4>2) Decouple learning and improvement from your retro. </h4>



<p>We’re not saying to cancel your retro. Getting together every few weeks to discuss learnings is great. But if you un-gate your team metrics so everyone can see bottlenecks and suggestions for how to improve each day, then improvement can be led everyone on your team (not just managers) and become part of the fabric of your team culture. <a href="https://linearb.io/blog/data-driven-dev-team/" target="_blank" rel="noreferrer noopener">Click here to see how to use data in your day-to-day</a> practices without damaging culture. </p>







<h4>3) Combine quantitative signals &amp; qualitative assessments for team health</h4>



<p>Use multiple data points to identify signs of overload and burnout. Face to face conversation is not the only way to see if a teammate is struggling. Looking at your WIP balance across the team and consecutive days worked, in combination with 1:1 conversation, can tell you a lot about a person’s work health. <a href="https://linearb.io/blog/dev-team-health/" target="_blank" rel="noreferrer noopener">Click here to see which data points can help you …</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/asynchronous-development/">https://linearb.io/blog/asynchronous-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/asynchronous-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656046</guid>
            <pubDate>Thu, 01 Oct 2020 20:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a video chat app in Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656017">thread link</a>) | @rahimnathwani
<br/>
October 1, 2020 | https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview | <a href="https://web.archive.org/web/*/https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section>
            <p>During this global pandemic, online video calls have become essential to the way we work. Millions of workers are now accustomed to hopping on calls with their colleagues to hash things out that they would previously have done in person. Zoom has shown itself to be a reliable partner for video conferencing. However, as a company, Zoom has given <a href="https://theintercept.com/2020/03/31/zoom-meeting-encryption/">plenty of</a> <a href="https://techcrunch.com/2019/07/10/apple-silent-update-zoom-app/">reasons to</a> <a href="https://www.theverge.com/2020/6/3/21279355/zoom-end-encryption-calls-fbi-police-free-users">avoid</a> <a href="https://www.npr.org/2020/06/12/876351501/zoom-acknowledges-it-suspended-activists-accounts-at-china-s-request">its software.</a></p>

<p>The world’s new reliance on video conferencing got me thinking: <em>How hard could it be to build a video conferencing web application?</em> Like most things worth doing, the answer was <em>difficult, but fun</em>.</p>

<p>When I first started researching for this project, I discovered that there isn’t much information out there about building a WebRTC-based application from start to finish. Mozilla’s WebRTC documentation is invaluable, but it lacked answers to some of the questions I had. And tutorials that exist generally only cover connecting two users in a fairly basic way. I wanted to do something more ambitious.</p>

<h2 id="what-were-going-to-build">What we’re going to build:</h2>

<p>In this article, we’re going to build a real-time video chat application with the following requirements:</p>

<ul>
  <li>The app will allow users to create video chat rooms with a unique slug, allowing any user to join.</li>
  <li>The app will keep track of which users are connected to the given room.</li>
  <li>The app will allow users to establish a group video call with eachother through WebRTC peer connections.</li>
</ul>

<p>Well, that sounds easy enough. Creating pages with central information on the fly in a web app is the bread and butter of any self-respecting web framework—and with Phoenix it’s a piece of cake. Tracking users seems a little tricky, but if you’ve heard of what LiveView and PubSub can do, you can probably guess that we’re still on the right track. WebRTC was designed for video calls, but group video calls? That might get complex. Plus, how would that even work if each of the connections is only peer-to-peer? We’ll get to that.</p>

<ul>
  <li><a href="https://littlechat.app/">We’ve wrapped up the finished product and deployed it at littlechat.app</a>. Try creating a room and hopping on it with a friend or two. That’s what we’re going to create.</li>
  <li><a href="https://github.com/littlelines/littlechat">You can also find the source code for this project here if you’re more of the self-guided type.</a></li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>

<p>I’m going to assume that you are comfortable working with Elixir and Phoenix. I’ll assume that you might have toyed around with LiveView a few times before this article, but it doesn’t take much to get up to speed. Finally, I’ll assume you have no WebRTC experience beyond having heard about it a few times.</p>

<p>We will be using the latest versions of Elixir, Erlang, Phoenix, and Phoenix LiveView in this article, which are the following at the time of writing:</p>

<ul>
  <li>Elixir 1.10.3</li>
  <li>Erlang 23.0.2</li>
  <li>Phoenix 1.5.3</li>
  <li>Phoenix LiveView 0.13.3</li>
</ul>

<h2 id="the-tech">The Tech</h2>

<h3 id="webrtc">WebRTC</h3>

<p>Web Real Time Communication, or WebRTC for short, is a technology that allows real-time, peer-to-peer communication between users. It provides an API for handling user video, audio, and other data via peer-to-peer connections.</p>

<p>WebRTC has been around since 2011, but implementation by the various browsers has been uneven over the years. Nowadays, each browser has a more consistent WebRTC implementation, making browser support much better, but implementing it can still be a dance.</p>

<p>What makes WebRTC so flexible—and, at times, confounding—is that it has no standardized server-side implementation. WebRTC does not care how users in a video chat learn about each other and send their connection information, it only handles how to connect those users once their information has been sent. This originally confused me, as I was not sure where the server-side <em>signaling</em> (the WebRTC term for the process of telling two users about each other for a peer connection) ended and the <code>RTCPeerConnection</code> began. We’ll dig into this later.</p>

<h3 id="phoenix">Phoenix</h3>

<p>Elixir’s Phoenix framework allows us to build reliable and performant web applications built on Erlang’s rock-solid foundation. On any project, my first instinct these days is to reach for Phoenix. But the motivation goes deeper.</p>

<p>Elixir is built on Erlang’s VM, which was specifically developed for the challenges of the telecoms industry, where fault-tolerance and high-availability are essential. That sounds perfect for this project.</p>

<h3 id="liveview">LiveView</h3>

<p><a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html">LiveView</a> is one of my favorite components of Phoenix. It makes real-time user interaction between the client’s UI and the server seamless, without needing to write (much) JavaScript. LiveView makes real-time user interactions much easier to build and maintain, all while working within familiar concepts: Phoenix, Elixir, and OTP.</p>

<h2 id="getting-started">Getting Started</h2>

<p>Have you got all your tools ready? Let’s go!</p>

<p>First, we’re going to create a new Phoenix project with LiveView already configured. If you’re trying to add video chat to an existing app without LiveView already configured, <a href="https://hexdocs.pm/phoenix_live_view/installation.html#content">LiveView is pretty easy to set up from scratch too.</a> We’re going to call our project Littlechat, a portmenteau of Littlelines and chat.</p>

<div><pre><code><span>$ </span>mix phx.new littlechat --live</code></pre></div>

<p>Now let’s <code>cd littlechat</code> into our brand new app and install its dependencies.</p>

<div><pre><code><span>$ </span><span>cd </span>littlechat
<span>$ </span>mix deps.get
<span>$ </span>npm install --prefix assets</code></pre></div>

<p>Standard stuff. Let’s go a little deeper.</p>

<h2 id="creating-the-rooms">Creating the Rooms</h2>

<p>Users can’t connect to each other if they don’t have a place to meet, so let’s build them a room!</p>

<p>Let’s create a <em>context</em> called <code>Organizer</code> with a schema <code>Room</code>.</p>

<div><pre><code><span>$ </span>mix phx.gen.context Organizer Room rooms title:string slug:string</code></pre></div>

<p>That generated a few files for us, <code>lib/littlechat/organizer.ex</code>, <code>lib/littlechat/organizer/room.ex</code>, and a migration file ending in <code>XXXXX_create_rooms.exs</code> Let’s start with our Room schema.</p>

<p>Our rooms will only have two data to start, <code>slug</code> and <code>title</code>, both strings. <code>slug</code> will be the unique identifier for the room, so we’ll need to add a unique index to the database to prevent collisions. Let’s set up the database:</p>

<div><pre><code><span># priv/repo/migrations/XXXXX_create_rooms.exs</span>

<span>defmodule</span> <span>Littlechat.Repo.Migrations.CreateRooms</span> <span>do</span>
  <span>use</span> <span>Ecto.Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>create</span> <span>table</span><span>(</span><span>"rooms"</span><span>)</span> <span>do</span>
      <span>add</span> <span>:slug</span><span>,</span> <span>:string</span>
      <span>add</span> <span>:title</span><span>,</span> <span>:string</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>

    <span>create</span> <span>unique_index</span><span>(</span><span>:rooms</span><span>,</span> <span>:slug</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>For the schema, we’re going to create a basic changeset function with the added <code>unique_constraint</code> on slug. But we’re also going to add a private function, <code>format_slug/1</code> for the purpose of cleaning our slug input.</p>

<div><pre><code><span># lib/littlechat/room.ex</span>

<span>defmodule</span> <span>Littlechat.Room</span> <span>do</span>
  <span>@moduledoc</span> <span>"""</span>
<span>  Schema for creating video chat rooms.</span>
<span>  """</span>

  <span>use</span> <span>Ecto.Schema</span>
  <span>import</span> <span>Ecto.Changeset</span>

  <span>schema</span> <span>"rooms"</span> <span>do</span>
    <span>field</span> <span>:title</span><span>,</span> <span>:string</span>
    <span>field</span> <span>:slug</span><span>,</span> <span>:string</span>

    <span>timestamps</span><span>()</span>
  <span>end</span>

  <span>@fields</span> <span>[</span><span>:title</span><span>,</span> <span>:slug</span><span>]</span>

  <span>def</span> <span>changeset</span><span>(</span><span>room</span><span>,</span> <span>attrs</span><span>)</span> <span>do</span>
    <span>room</span>
    <span>|&gt;</span> <span>cast</span><span>(</span><span>attrs</span><span>,</span> <span>@fields</span><span>)</span>
    <span>|&gt;</span> <span>validate_required</span><span>([</span><span>:title</span><span>,</span> <span>:slug</span><span>])</span>
    <span>|&gt;</span> <span>format_slug</span><span>()</span>
    <span>|&gt;</span> <span>unique_constraint</span><span>(</span><span>:slug</span><span>)</span>
  <span>end</span>

  <span>defp</span> <span>format_slug</span><span>(%</span><span>Ecto.Changeset</span><span>{</span><span>changes</span><span>:</span> <span>%{</span><span>slug</span><span>:</span> <span>_</span><span>}}</span> <span>=</span> <span>changeset</span><span>)</span> <span>do</span>
    <span>changeset</span>
    <span>|&gt;</span> <span>update_change</span><span>(</span><span>:slug</span><span>,</span> <span>fn</span> <span>slug</span> <span>-&gt;</span>
      <span>slug</span>
      <span>|&gt;</span> <span>String</span><span>.</span><span>downcase</span><span>()</span>
      <span>|&gt;</span> <span>String</span><span>.</span><span>replace</span><span>(</span><span>" "</span><span>,</span> <span>"-"</span><span>)</span>
    <span>end</span><span>)</span>
  <span>end</span>
  <span>defp</span> <span>format_slug</span><span>(</span><span>changeset</span><span>),</span> <span>do</span><span>:</span> <span>changeset</span>
<span>end</span></code></pre></div>

<p>Great! Now we can create rooms in the database. What about getting one from the DB? Easy.</p>

<div><pre><code><span># lib/littlechat/organizer.ex</span>

<span>defmodule</span> <span>Littlechat.Organizer</span> <span>do</span>
  <span>alias</span> <span>Littlechat.Repo</span>
  <span>alias</span> <span>Littlechat.Room</span>

  <span>import</span> <span>Ecto.Query</span>

  <span>def</span> <span>get_room</span><span>(</span><span>slug</span><span>)</span> <span>when</span> <span>is_binary</span><span>(</span><span>slug</span><span>)</span> <span>do</span>
    <span>from</span><span>(</span><span>room</span> <span>in</span> <span>Room</span><span>,</span> <span>where</span><span>:</span> <span>room</span><span>.</span><span>slug</span> <span>==</span> <span>^</span><span>slug</span><span>)</span>
    <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span><span>()</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>Now let’s build LiveViews for creating and viewing rooms.</p>

<p>We’re going to create two LiveViews, <code>LittlechatWeb.Room.NewLive</code> and <code>LittlechatWeb.Room.ShowLive</code>, the former for creating and the latter for showing the rooms. Let’s start with <code>NewLive</code>:</p>

<div><pre><code><span># lib/littlechat_web/live/room/new_live.ex</span>

<span>defmodule</span> <span>LittlechatWeb.Room.NewLive</span> <span>do</span>
  <span>use</span> <span>LittlechatWeb</span><span>,</span> <span>:live_view</span>

  <span>alias</span> <span>Littlechat.Repo</span>
  <span>alias</span> <span>Littlechat.Room</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>render</span><span>(</span><span>assigns</span><span>)</span> <span>do</span>
    <span>~L</span><span>"""</span>
<span>    &lt;h1&gt;Create a New Room&lt;/h1&gt;</span>
<span>    &lt;div&gt;</span>
<span>      &lt;%= form_for @changeset, "#", [phx_change: "validate", phx_submit: "save"], fn f -&gt; %&gt;</span>
<span>        &lt;%= text_input f, :title, placeholder: "Title" %&gt;</span>
<span>        &lt;%= error_tag f, :title %&gt;</span>
<span>        &lt;%= text_input f, :slug, placeholder: "room-slug" %&gt;</span>
<span>        &lt;%= error_tag f, :slug %&gt;</span>
<span>        &lt;%= submit "Save" %&gt;</span>
<span>      &lt;% end %&gt;</span>
<span>    &lt;/div&gt;</span>
<span>    """</span>
  <span>end</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>mount</span><span>(</span><span>_params</span><span>,</span> <span>_session</span><span>,</span> <span>socket</span><span>)</span> <span>do</span>
    <span>{</span><span>:ok</span><span>,</span>
      <span>socket</span>
      <span>|&gt;</span> <span>put_changeset</span><span>()</span>
    <span>}</span>
  <span>end</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>handle_event</span><span>(</span><span>"validate"</span><span>,</span> <span>%{</span><span>"room"</span> <span>=&gt;</span> <span>room_params</span><span>},</span> <span>socket</span><span>)</span> <span>do</span>
    <span>{</span><span>:noreply</span><span>,</span>
      <span>socket</span>
      <span>|&gt;</span> <span>put_changeset</span><span>(</span><span>room_params</span><span>)</span>
    <span>}</span>
  <span>end</span>

  <span>def</span> <span>handle_event</span><span>(</span><span>"save"</span><span>,</span> <span>_</span><span>,</span> <span>%{</span><span>assigns</span><span>:</span> <span>%{</span><span>changeset</span><span>:</span> <span>changeset</span><span>}}</span> <span>=</span> <span>socket</span><span>)</span> <span>do</span>
    <span>case</span> <span>Repo</span><span>.</span><span>insert</span><span>(</span><span>changeset</span><span>)</span> <span>do</span>
      <span>{</span><span>:ok</span><span>,</span> <span>room</span><span>}</span> <span>-&gt;</span>
        <span>{</span><span>:noreply</span><span>,</span>
          <span>socket</span>
          <span>|&gt;</span> <span>push_redirect</span><span>(</span><span>to</span><span>:</span> <span>Routes</span><span>.</span><span>room_show_path</span><span>(</span><span>socket</span><span>,</span> <span>:show</span><span>,</span> <span>room</span><span>.</span><span>slug</span><span>))</span>
        <span>}</span>
      <span>{</span><span>:error</span><span>,</span> <span>changeset</span><span>}</span> <span>-&gt;</span>
        <span>{</span><span>:noreply</span><span>,</span>
          <span>socket</span>
          <span>|&gt;</span> <span>assign</span><span>(</span><span>:changeset</span><span>,</span> <span>changeset</span><span>)</span>
          <span>|&gt;</span> <span>put_flash</span><span>(</span><span>:error</span><span>,</span> <span>"Could not save the room."</span><span>)</span>
        <span>}</span>
    <span>end</span>
  <span>end</span>

  <span>defp</span> <span>put_changeset</span><span>(</span><span>socket</span><span>,</span> <span>params</span> <span>\\</span> <span>%{})</span> <span>do</span>
    <span>socket</span>
    <span>|&gt;</span> <span>assign</span><span>(</span><span>:changeset</span><span>,</span> <span>Room</span><span>.</span><span>changeset</span><span>(%</span><span>Room</span><span>{},</span> <span>params</span><span>))</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>Let’s break this down by function.</p>

<ul>
  <li><code>render/1</code> implements a LiveView callback with the given <code>assigns</code> (variables containing session data) and expects a <code>~L</code> sigil (Live EEx). I prefer my LEEx templates inline, but you’re welcome to create a file <code>lib/littlechat_web/live/room/new_live.html.leex</code> and get rid of this function if you prefer to keep your templates separate.</li>
  <li>Inside of this template, we create a basic form for creating a new Room. Note the reference to the <code>@changeset</code> assign.</li>
  <li>We then tell the form (via LiveView) to send the event <code>"validate"</code> to the server every time user input is added.</li>
  <li>Finally, we tell the form to send the event <code>"submit"</code>, along with the associated form data, to the server when the user makes a submit action (presses enter or clicks “Submit”).</li>
  <li><code>mount/3</code> is a key callback that makes the LiveView function. It contains three arguments, <code>par…</code></li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview">https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview</a></em></p>]]>
            </description>
            <link>https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656017</guid>
            <pubDate>Thu, 01 Oct 2020 20:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authenticating with AWS Managed Microsoft Active Directory and LDAP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655887">thread link</a>) | @mooreds
<br/>
October 1, 2020 | https://fusionauth.io/blog/2020/10/01/active-directory-connector | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/10/01/active-directory-connector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Microsoft’s Active Directory is a common enterprise user data store. If you are building apps for users authenticated by Active Directory, you might want to connect FusionAuth to it. Another common use case is to have some applications for internal users which should be authenticated against Active Directory and other applications for people outside your organization, with user data stored in FusionAuth. FusionAuth can act as a CIAM for your external users, but delegate authentication of internal accounts to Active Directory.</p>

<!--more-->

<p>If you do this, applications no longer have to understand LDAP or be able to connect to your Active Directory server. Any framework or application with OAuth/OIDC or SAML support talks to FusionAuth for auth information, while user data remains in Active Directory.</p>

<p>You can achieve this with the FusionAuth LDAP connector. This post will explain how to set up a connection between FusionAuth and Active Directory. For this post, <a href="https://aws.amazon.com/directoryservice/active-directory/">AWS Microsoft Managed AD</a> is used, but the configuration and concepts will work with any Microsoft Active Directory instance.</p>

<h2 id="setting-up-microsoft-active-directory">Setting up Microsoft Active Directory</h2>

<p>There are a few steps you need to take before you can dive into configuring the LDAP Connector.</p>

<p><em>Connectors are a feature of the paid editions. You can sign up for a free trial of the <a href="https://fusionauth.io/pricing">FusionAuth Developer Edition</a>.</em></p>

<p>To fully explore this scenario, you need to have an application users can sign into with their Active Directory credentials. In this post, you are going to use ASP.NET to run such an application, so make sure you have .NET Core version 3 installed if you want to follow along with the code. I found the <a href="https://dotnet.microsoft.com/download/dotnet-core/scripts">bash script here</a> worked best for installing on macOS.</p>

<p>Then, ensure you have FusionAuth installed and running. You can download and install FusionAuth <a href="https://fusionauth.io/docs/v1/tech/installation-guide/">using Docker, RPM, or in a number of other ways</a>. You’ll need at least version 1.18. Make sure you’ve <a href="https://fusionauth.io/docs/v1/tech/reactor">activated your instance</a> by providing a license key to enable the Connector feature.</p>

<p>Next, make sure you have Active Directory accessible to the server running FusionAuth, since they will need to communicate. In my case, since AWS Microsoft Managed AD doesn’t by <a href="https://forums.aws.amazon.com/thread.jspa?messageID=688592&amp;#688592">default expose an interface to the outside world</a>, I stood up a FusionAuth server on an EC2 instance in the same subnet. You could use a VPN, SSH tunnel or HTTP proxy in front of Active Directory as well.</p>

<p>Test that you can access the Active Directory instance from your FusionAuth server by installing <code>ldapsearch</code> and running a simple LDAP query. For an EC2 instance running Amazon Linux, I ran these commands to install and then query the Active Directory server:</p>

<div><div><pre><code><span>sudo </span>yum <span>install </span>openldap-clients
ldapsearch <span>-H</span> ldap://xx.xx.xx.xx
</code></pre></div></div>

<p>Note that <code>xx.xx.xx.xx</code> is the IP address of your Active Directory instance. If you are running Active Directory with LDAPS, you may need to change the scheme.</p>

<p>If you see this error message:</p>

<div><div><pre><code>ldap_sasl_interactive_bind_s: Can't contact LDAP server (-1)
</code></pre></div></div>

<p>That means the Active Directory server is not accessible. If, on the other hand, you see this error message, you’re on the right path:</p>

<div><div><pre><code>SASL/EXTERNAL authentication started
ldap_sasl_interactive_bind_s: Unknown authentication method (-6)
	additional info: SASL(-4): no mechanism available: 
</code></pre></div></div>

<p>The above message is Active Directory telling you:</p>

<ul>
  <li>“Hey bonehead, provide me some credentials” (in a polite way).</li>
  <li>You can connect from your FusionAuth server to Active Directory.</li>
</ul>

<h3 id="configuring-aws-microsoft-managed-ad">Configuring AWS Microsoft Managed AD</h3>

<p>This post isn’t about installing AWS Microsoft Managed AD or any other Active Directory server, so I’ll mostly leave you to the tender mercies of AWS’s documentation. If, however, you have a running Active Directory instance you can access with the above <code>ldapsearch</code> commands, you can skip this entire section.</p>

<p>Here’s a brief outline of what I did to set up the Active Directory server so that I could connect it with FusionAuth:</p>

<ul>
  <li>Create a VPC with two subnets.</li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_getting_started_create_directory.html">Create an AWS Microsoft Managed AD Directory.</a></li>
  <li>Stand up a Windows server instance in the Active Directory’s subnet.</li>
  <li><a href="https://apps.apple.com/app/microsoft-remote-desktop/id1295203466">Install the MacOS RDP client</a> and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/troubleshoot-connect-windows-instance.html">connect to that instance</a>.</li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/join_windows_instance.html">Manually join the Windows EC2 instance to Active Directory.</a></li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_manage_users_groups.html">Install the AD tools and create a user.</a></li>
</ul>

<p>As mentioned, this post assumes there is an EC2 instance inside a private subnet with access to the Active Directory server, so the connection between FusionAuth and AWS Microsoft Managed AD won’t use TLS. If you are using this configuration in production, please ensure that the network connection between the two servers is secured, especially if the traffic is over the open internet.</p>

<h3 id="active-directory-users">Active Directory users</h3>

<p>You are going to want to create two users in Active Directory.</p>

<p>The first will be an administrative user who has at least read access to the section of the directory where the internal user accounts are stored. When I created the directory, there was an <code>Admin</code> account created as well, so I’ll use that.</p>

<p>The second user will log in to FusionAuth and be authenticated against Active Directory using the Connector. Below, I’m adding John Stafford.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/active-directory-add-user.png" alt="Adding a user in Active Directory."></p>

<p>I ran into an issue where when creating the user I required their password to be changed. This blocked FusionAuth from authenticating them. If you run into such issues, you can check by attempting to sign in to the domain, perhaps using the EC2 instance which is set up to auth directly against Active Directory.</p>

<h2 id="setting-up-fusionauth">Setting up FusionAuth</h2>

<p>Next, you want to add an application in FusionAuth. An application is anything a user can sign into. We’re going to reuse an <a href="https://fusionauth.io/blog/2019/05/06/securing-asp-netcore-razor-pages-app-with-oauth">existing ASP.NET Razor Pages application</a>. While required, the application isn’t the focus of this blog post, so if you want to learn more, check out the linked article. But let’s pretend this application is an internal payroll application. Only users in Active Directory should be able to access it, but we want to leverage FusionAuth for all our application auth needs.</p>

<p>To set up this application in FusionAuth, navigate to “Settings” and then “Key Master” to set up an RSA keypair. You need to do this because the default signing algorithm for a JSON Web Token (JWT) in FusionAuth is HMAC, but the ASP.NET library used doesn’t support symmetric algorithms. Below I’m generating an RSA key pair, but you can import one you’ve previously created should you need to share the keys across systems:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-add-rsa-key.png" alt="Adding an RSA key in Key Master."></p>

<p>Create an application called “Internal Payroll App”. This is what you are going to let John have access to. In the “OAuth” tab, add a redirect URL of “http://localhost:5000/signin-oidc”. Add a logout redirect of “http://localhost:5000/”.</p>

<p>Navigate to the “JWT” tab. Enable JWT application configuration and change the signing keys to the just created RSA key pair: “For Internal Payroll App”.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-jwt-config.png" alt="Configuring the application's JWT settings to sign with the generated RSA keypair."></p>

<p>Save the application and then view it by clicking on the green magnifying glass. Scroll down to the “OAuth configuration” section, noting the <code>Client ID</code> and <code>Client Secret</code> values, which you’ll need when configuring the web application in a bit:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-oauth-config.png" alt="Viewing the application's OAuth settings to record the Client ID and Client Secret values."></p>

<h2 id="configure-the-ldap-connector">Configure the LDAP connector</h2>

<p>To configure the LDAP connector, you need to do the following:</p>

<ul>
  <li>Create an LDAP reconcile lambda to map user’s directory attributes to FusionAuth user attributes.</li>
  <li>Configure the Connector with information such as the URL of the Active Directory server.</li>
  <li>Add the Connector policy to the tenant, which configures how the connector is invoked by FusionAuth.</li>
</ul>

<p>Seems pretty simple, right? Let’s take these one at a time.</p>

<h3 id="create-the-ldap-lambda">Create the LDAP lambda</h3>

<p>Because FusionAuth has no idea about the structure of your Active Directory or other LDAP database, you’ll need to create a <a href="https://fusionauth.io/docs/v1/tech/lambdas/ldap-connector-reconcile">reconciliation lambda</a> to map the attributes from LDAP to FusionAuth. At its most basic, this lambda looks like this:</p>

<div><div><pre><code><span>function</span> <span>reconcile</span><span>(</span><span>user</span><span>,</span> <span>userAttributes</span><span>)</span> <span>{</span>
  <span>// Lambda code goes here</span>
<span>}</span>
</code></pre></div></div>

<p>This code isn’t too helpful though, as no user attributes are copied. At a minimum, you must set <code>user.id</code> and either <code>user.username</code> or <code>user.email</code> values. You also probably want to configure the <code>registrations</code> collection, which is the set of FusionAuth applications for which this user is authorized. If you have multiple tenants, populate <code>user.tenantId</code> as well.</p>

<p>The lambda will receive a <code>userAttributes</code> variable from the Connector. This contains attributes requested from Active Directory. You’ll see how to request specific attributes below. From <code>userAttributes</code>, you’ll want to assemble a FusionAuth <code>user</code> object. All the normal <a href="https://fusionauth.io/docs/v1/tech/lambdas/#limitations">lambda limitations apply</a>. The attributes of the <code>user</code> object are thoroughly documented in the <a href="https://fusionauth.io/docs/v1/tech/apis/users#create-a-user">API docs</a>, but in general you’ll be copying values from <code>userAttributes</code> to <code>user</code>, or hardcoding values. Here’s a more full featured example lambda function, which copies some attributes, sets <code>active</code> to <code>true</code>, and registers the user for a given application:</p>

<div><div><pre><code><span>// Using the response from an LDAP connector, reconcile the User.</span>
<span>function</span> <span>reconcile</span><span>(</span><span>user</span><span>,</span> <span>userAttributes</span><span>)</span> <span>{</span>

  <span>user</span><span>.</span><span>email</span> <span>=</span> <span>userAttributes</span><span>.</span><span>userPrincipalName</span><span>;</span>
  <span>user</span><span>.</span><span>firstName</span> <span>=</span> <span>userAttributes</span><span>.</span><span>givenName</span><span>;</span>
  <span>user</span><span>.</span><span>lastName</span>  <span>=</span> <span>userAttributes</span><span>.</span><span>sn</span><span>;</span>
  <span>user</span><span>.</span><span>active</span>    <span>=</span> <span>true</span><span>;</span>
  
  <span>var</span> <span>reg</span> <span>=</span> <span>{};</span>
  <span>reg</span><span>.</span><span>applicationId</span> <span>=</span> <span>"</span><span>f81adc10-04f7-4546-8410-f9837ff248ab</span><span>"</span><span>;</span> <span>// the application we want the user registered for</span>
  <span>user</span><span>.</span><span>registrations</span> <span>=</span> <span>[</span><span>reg</span><span>];</span>
  
  <span>user</span><span>.</span><span>id</span> <span>=</span> <span>guidToString</span><span>(</span><span>userAttributes</span><span>[</span><span>'</span><span>objectGUID;binary</span><span>'</span><span>]);</span>
<span>}</span>

<span>function</span> <span>decodeBase64</span><span>(</span><span>string</span><span>)</span>
<span>{</span>
	<span>var</span> <span>b</span><span>=</span><span>0</span><span>,</span><span>l</span><span>=</span><span>0</span><span>,</span> <span>r</span><span>=</span><span>''</span><span>,</span>
  <span>m</span><span>=</span><span>'</span><span>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/</span><span>'</span><span>;</span>
  <span>string</span><span>.</span><span>split</span><span>(</span><span>''</span><span>).</span><span>forEach</span><span>(</span><span>function</span> <span>(</span><span>v</span><span>)</span> <span>{</span>
    <span>b</span><span>=</span><span>(</span><span>b</span><span>&lt;&lt;</span><span>6</span><span>)</span><span>+</span><span>m</span><span>.</span><span>indexOf</span><span>(</span><span>v</span><span>);</span> <span>l</span><span>+=</span><span>6</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span><span>&gt;=</span><span>8</span><span>)</span> <span>r</span><span>+=</span><span>String</span><span>.</span><span>fromCharCode</span><span>((</span><span>b</span><span>&gt;&gt;&gt;</span><span>(</span><span>l</span><span>-=</span><span>8</span><span>))</span><span>&amp;</span><span>0xff</span><span>);</span>
  <span>});</span>
  <span>return</span> <span>r</span><span>;</span>
<span>}</span>

<span>function</span> <span>guidToString</span><span>(</span><span>b64</span><span>)</span>
<span>{</span>
  <span>var</span> <span>x</span> <span>=</span> <span>decodeBase64</span><span>(</span><span>b64</span><span>);</span>
  
  <span>console</span><span>.</span><span>debug</span><span>(</span><span>"</span><span>Binary String: </span><span>"</span> <span>+</span> <span>x</span><span>.</span><span>length</span> <span>+</span> <span>"</span><span> length: </span><span>"</span> <span>+</span> <span>x</span><span>);</span>
  
  <span>var</span> <span>ret</span> <span>=</span> <span>""</span><span>;</span>
  
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>3</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>0</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>ret</span> <span>+=</span> <span>(</span><span>'</span><span>00</span><span>'</span><span>+</span><span>x</span><span>.</span><span>charCodeAt</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>)).</span><span>substr</span><span>(</span><span>-</span><span>2</span><span>,</span><span>2</span><span>);</span>
  <span>}</span>
  <span>ret</span> <span>+=</span> <span>"</span><span>-</span><span>"</span><span>;</span>
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>5</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>4</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>//ret = ret + ('00' + (charCode &amp; 0xFF00) &gt;&gt; 8);</span>
    <span>ret</span> <span>+=</span> <span>(</span><span>'</span><span>00</span><span>'</span><span>+</span><span>x</span><span>.</span><span>charCodeAt</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>)).</span><span>substr</span><span>(</span><span>-</span><span>2</span><span>,</span><span>2</span><span>);</span>
  <span>}</span>
  <span>ret</span> <span>+=</span> <span>"</span><span>-</span><span>"</span><span>;</span>
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>7</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>6</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>//ret = ret + …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/10/01/active-directory-connector">https://fusionauth.io/blog/2020/10/01/active-directory-connector</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/10/01/active-directory-connector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655887</guid>
            <pubDate>Thu, 01 Oct 2020 20:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interviewing During Covid – Google/Apple/ByteDance/Databricks/Citadel/HRT/JS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24655799">thread link</a>) | @oneraynyday
<br/>
October 1, 2020 | https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/ | <a href="https://web.archive.org/web/*/https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>I interviewed for Googleâ€™s Tensorflow, Appleâ€™s MLPT (Machine Learning Platform &amp; Technology), Bytedanceâ€™s ad infrastructure, Databrickâ€™s ML team, Citadel Securities as a quantitative research analyst, Hudson River Trading(HRT) as an algorithm engineer, and Jane Streetâ€™s research desk as SWE. I received offers from all of the companies except for Jane Street. Hereâ€™s my experience interviewing during COVID.</strong></p>

<p><em>Disclaimer: I wonâ€™t be walking on the edge of leaking confidential information like an idiot(yes, I signed an NDA for all of these companies). Donâ€™t expect to get any hints for your interviews.</em></p>

<p>The structure of this blog is inspired by my friend <a href="https://medium.com/@XiaohanZeng/i-interviewed-at-five-top-companies-in-silicon-valley-in-five-days-and-luckily-got-five-job-offers-25178cf74e0f">Hanâ€™s medium blogpost.</a></p>

<p><img src="http://oneraynyday.github.io/assets/interviews.png" alt="interviews"></p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#preparation" id="markdown-toc-preparation">Preparation</a>    <ul>
      <li><a href="#algorithms" id="markdown-toc-algorithms">Algorithms</a></li>
      <li><a href="#systems-design" id="markdown-toc-systems-design">Systems Design</a></li>
      <li><a href="#math-questions" id="markdown-toc-math-questions">Math Questions</a></li>
    </ul>
  </li>
  <li><a href="#the-interview-process" id="markdown-toc-the-interview-process">The interview process</a>    <ul>
      <li><a href="#more-interview-rounds-during-covid" id="markdown-toc-more-interview-rounds-during-covid">More interview rounds during COVID</a></li>
      <li><a href="#dealing-with-time-zones" id="markdown-toc-dealing-with-time-zones">Dealing with time zones</a></li>
      <li><a href="#which-ones-were-the-hardest" id="markdown-toc-which-ones-were-the-hardest">Which ones were the hardest?</a></li>
    </ul>
  </li>
  <li><a href="#making-a-decision" id="markdown-toc-making-a-decision">Making a decision</a>    <ul>
      <li><a href="#the-culture-and-the-small-things-count" id="markdown-toc-the-culture-and-the-small-things-count">The culture and the â€œsmallâ€� things count</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>



<p><strong>Working on machine learning infrastructure is 99% systems engineering and 1% machine learning.</strong> My experience on machine learning infrastructure teams has taught me this, and preparing for systems engineering topics was the right way to go. I did the following to prepare:</p>

<h2 id="algorithms">Algorithms</h2>

<p><strong>~50 leetcode hard questions</strong>. Some of them are DP, some are graph based, some of them are just NP-hard problems that are a pain to code(which is the point), and some include devising some clever data structure that supports a very specific access pattern. I gave myself roughly 40 minutes to solve these problems. ~15%(7 questions) of the time I couldnâ€™t figure out the correct solution because time limit exceeded, memory limit exceeded, or I was just flat out wrong. I directly read the solutions and learned the tricks necessary to solve the type of problems moving forward. Donâ€™t bother with medium or easy questions since hard questions often contain medium/easy tasks as subroutines, and these companies probably wouldnâ€™t ask you easy leetcode questions anyways.</p>

<p>I wrote the solutions in either python and C++(sometimes both) and went back to polish my code for minor optimizations or readability improvements. For C++, I made sure I wasnâ€™t using raw pointers unless appropriate and I was using C++17 (<code>constexpr</code> functions, <code>std::array</code> instead of raw arrays, smart pointers, template type deduction with lambdas, etc) features. The reason I wasnâ€™t using C++20 was because the online coding platforms(like coderpad) likely use stable distributions of GCC and clang, which means some of the new features are in their experimental phase. <strong>I didnâ€™t want to encounter a bug with concepts or <code>std::ranges</code>  in the middle of the interview.</strong> (In fact, I found a <a href="https://stackoverflow.com/questions/62398252/why-likely-attribute-in-c20-raises-a-warning-here">bug with attributes</a> recently in a new version of gcc)</p>

<p>I also spent a few days on problems elsewhere:</p>

<ul>
  <li><a href="https://codingcompetitions.withgoogle.com/codejam/archive">Codejam problems</a>. Round 1 and 2 are feasible, but round 3 was very difficult. Iâ€™d suggest studying round 1â€™s if you only care about interviews.</li>
  <li><a href="https://codeforces.com/">Codeforce contests</a>. There are 3 tiers(or Divs, as they call it), and for interviews I suggest Div 3 and Div 2. Donâ€™t bother with the D+ questions in Div 2, and definitely donâ€™t bother with Div 1.</li>
</ul>

<h2 id="systems-design">Systems Design</h2>

<p>Working at Airbnb has made me pretty familiar with high level distributed systems design, but of course I worked only with a subset of them. I think Martin Kleppmanâ€™s book <a href="https://www.google.com/books/edition/Designing_Data_Intensive_Applications/p1heDgAAQBAJ?hl=en">Designing Data Intensive Applications</a> is a great read, but youâ€™ll have to pick and choose which sections you want to go over as itâ€™s a pretty dense book. If you donâ€™t have time, maybe just try understanding how Kubernetes works with Marko Luksaâ€™s <a href="https://www.manning.com/books/kubernetes-in-action">Kubernetes in Action</a>, which is a much easier read. You can then draw parallels with the distributed design for K8s against whatever systems design question the interviewer has for you.</p>

<p>Make sure you know some fundamental ideas about distributed systems like the <strong>map reduce paradigm</strong>, <strong>sharding</strong>, <strong>asynchronous and synchronous follower replicas</strong>, <strong>CAP theorem</strong>, etc. <em>What you donâ€™t want to do is read 3 sentences about each of the terms above and regurgitate it in your interviews. Interviewers have been doing this for a while, they know you donâ€™t actually understand the concepts.</em> Donâ€™t be that guy.</p>

<h2 id="math-questions">Math Questions</h2>

<p><strong>These are only asked in finance firms.</strong> Honestly, these are just all over the place. I read this green book called <a href="http://quantfinanceinterviews.com/">A Practical Guide to Quantitative Finance Interviews</a> by Xinfeng Zhou, but only doing a single problem in each section by myself. Hedge funds will quiz you on discrete math to probability theory to geometry to information theory to literally anything. My advice is if youâ€™re a software engineer interviewing for a hybrid of finance and tech places, timebox yourself in this category.</p>

<hr>

<p>I have not seen an interview question this cycle that was an exact question Iâ€™ve seen online or in books. Your mileage may vary.</p>



<p>Interviewing and talking with all of these companies was a great experience, even with COVID in place. Obviously, as shelter-in-place continues, these companies are conducting virtual on-site interviews and trying to make this process as smooth as possible. Without getting into the specifics, Iâ€™ll outline some common things Iâ€™ve noticed during the process in the COVID era.</p>

<ul>
  <li>Many companies use Zoom or Google Hangouts for their on-sites.</li>
  <li>They give you ~15 minute breaks in between interviews for water breaks.</li>
  <li>Some companies give you a longer lunch break (45 mins to an hour).</li>
  <li>If youâ€™re interviewing for a company in another time zone, prepare to wake up in the early AMâ€™s or interview in the late afternoon (sometimes after dinner).</li>
  <li>Conveying an idea takes slightly longer because youâ€™re not drawing on a whiteboard. Some companies have virtual whiteboard apps and others allow the use of Zoom whiteboards.</li>
  <li><strong>Some companies added more interview rounds for virtual on-sites.</strong> Apparently more people are getting into companies with subpar technical skills during COVID and theyâ€™re making the process more selective. I think this can also be due to the increase in competition due to unemployment rates increasing.</li>
  <li>Feedback and communications with recruiters is generally faster.</li>
</ul>

<h2 id="more-interview-rounds-during-covid">More interview rounds during COVID</h2>

<p>The bolded text might scare you as a potential candidate, but donâ€™t worry too much. The added questions arenâ€™t testing you if you know how to implement a bloom filter or a fibonacci heap or something niche. They usually test on the <em>coding abilities of the person and how well theyâ€™d actually ramp up in a novel, collaborative environment</em>. This can manifest itself in multiple ways - live debugging session with a new codebase, reading documentation to work with new technology, or a collaborative brainstorming sesion for a hard(er) problem. If youâ€™re a decent software engineer you shouldnâ€™t worry about these as much.</p>

<h2 id="dealing-with-time-zones">Dealing with time zones</h2>

<p><em>One of the biggest struggles I had during the interview process was adjusting my sleep schedule to wake up at 5-6AM to make sure Iâ€™m awake and on time for the interviews in New York/Chicago (Iâ€™m in California so this was a 3 hour gap)</em>. Usually, companies would fly you out the day-of or the day before the on-site. Iâ€™ve always felt tired after a plane flight and was able to get a good nightâ€™s rest before the interviews in the past. With COVID, everything is virtual and the companies expect you to interview at their hours.</p>

<p>Even with slowly adjusting my sleep schedule over a week or two I still had trouble with sleep. Personally, I get pretty nervous before an on-site and Iâ€™d need to feel adequately tired to get a good nightâ€™s rest instead of tossing and turning in bed. With the clock turned 3 hours back, I suddenly found myself not tired enough to sleep on time the night before the interview(even with a whole week of adjusting). This led to me consistently getting 6-7 hours of sleep instead of the 9 hours of sleep I usually get on game day, which really sucked.</p>

<p>Ultimately, I have no idea how much the sleep problem really affected my performance, but it was enough to shake my confidence going in.</p>

<p><em>NOTE: +1 to Citadel for proactively breaking my on-site over multiple days so I can have a sane sleep schedule for their interviews. This might depend on the specific team youâ€™re interviewing with.</em></p>

<h2 id="which-ones-were-the-hardest">Which ones were the hardest?</h2>

<p>This is subjective, and the question can be broken up into multiple components:</p>

<ul>
  <li><strong>Time pressure - Jane Street</strong>. This is probably why I failed their interviews, which were a bit longer than usual. I tend to explain my approach before coding anything to get a confirmation on the interviewerâ€™s side that Iâ€™m on the right track. I probably spent too much time explaining and didnâ€™t have enough time to finish the code for some interviews.</li>
  <li><strong>Math questions - Citadel</strong>. They asked me some <em>really</em> interesting math problems that arenâ€™t related to finance at all. I donâ€™t think they expect the interviewer to get 100% of the questions since whenever I solved one the interviewer was ready with another. HRT also asked some.</li>
  <li><strong>Systems design - HRT</strong>.</li>
  <li><strong>Outside-the-box problems - Databricks</strong>. They conduct one of the most unique interviews Iâ€™ve ever had.</li>
  <li><strong>Language specific questions - Citadel/HRT</strong>. Grilled me a lot on low level C++ stuff.</li>
  <li><strong>Length of interview - HRT</strong>. I started at 8AM PST (I requested to move it to 8AM from 7AM) and finished at ~2:30PM. <strong>That is a whopping 6 hours and 30 minutes.</strong> I also did a coding challenge and 2 phone screens before I moved to on-site, totalling almost 10 hours for interviews.</li>
  <li><strong>General algorithm questions - Jane Street/HRT</strong>. I think Jane Street was a bit harder given the time pressure. The flavor of algorithm questions are also different between these firms.</li>
</ul>

<p>Once again, this breakdown is <strong>subjective</strong>. I obviously have a lot of experience interviewing with Silicon Valley companies so the novelty of questions from the finance companies added to the difficulty.</p>



<p>This was the hardest part for me. I spent two weeks suffering from analysis paralysis. I would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</a></em></p>]]>
            </description>
            <link>https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655799</guid>
            <pubDate>Thu, 01 Oct 2020 20:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use the internet, not just companies (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655745">thread link</a>) | @downshun
<br/>
October 1, 2020 | https://sive.rs/netskill | <a href="https://web.archive.org/web/*/https://sive.rs/netskill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-02-12</small>
</header>

<p>
	I’ve been online since 1994, and seen so many companies come and go.
</p><p>
	In the year 2000, the place to be was mp3.com.
	Every musician would keep all of their music and fans there.
	A few years later, it was gone — shut down — all music and fan lists deleted.
</p><p>
	In 2005, it was MySpace.
	Again, musicians kept all of their music, photos, and fans there.
	A few years later, it was gone.
	Not shut down, but basically moot.
	There was no way to communicate with all of those people, because you didn’t have their direct contact info — you only had their MySpace inbox, which nobody checked anymore.
</p><p>
	As I’m writing this now in 2018, it’s Facebook, YouTube, and Spotify.
	Just like with mp3.com and MySpace, people act like these websites are everything, and keep all of their music, photos, and fans there.
	By the time you read this, they might be gone.
</p><p>
<strong>
	Don’t depend on a company.
	They come and go.
</strong>
	Think long-term.
	You’re going to be creating stuff, making fans, and building relationships for the rest of your life — much longer than these companies will last.
</p><p>
<strong>
	So have your own website.
</strong>
	Instead of sending your fans to some company’s site, send them to yours.
	Get everyone’s direct contact information so you don’t have to go through a company to reach them.
</p><p>
<strong>
	Your website should be the definitive place to get everything you create.
</strong>
	If you put your stuff on some company’s site, have it be secondary — a copy of the stuff that’s already on your site.
	That way you can use the popular networks without depending on them.
</p><p>
	Only rely on open standards that aren’t owned by any company — like email and the web.
</p>
<h3>
	Email skills:
</h3>
<p>
	Go into your email settings, and make sure you <strong>have a signature</strong>.
	You need this because you’re going to be emailing people who have no idea who or where you are!
	Give them some context.
	Your signature should say who, what, and where, with a URL or two.
	For example:
</p>
<pre>--
Maya Danubé, fragrant jazz bass clarinet, New York City
http://mayadanube.com  <a href="https://sive.rs/cdn-cgi/l/email-protection" data-cfemail="7c11193c111d051d181d12091e19521f1311">[email&nbsp;protected]</a>  (917)611-5310
Watch &amp; listen: https://www.youtube.com/user/mayadanube
Friend me, baby: https://www.facebook.com/mayadanube
</pre>
<p>
	When you email people, write a <strong>descriptive subject</strong>.
	Never “hey” or “booking”.
	Try “Available June 6 for showcase?” or “introduction to photographer”.
	This is considerate.
	Now when your email is one of hundreds in an inbox, it will say exactly what is contained inside.
</p><p>
	Make it <strong>as short as possible</strong>.
	The shorter your email, the more likely it will get a response.
	Be direct.
	Five sentences is ideal.
	If your email is too long, they are likely to procrastinate, and never get back to it.
</p><p>
	Use short paragraphs.
	Leave plenty of space.
	Reading a screen is different from reading a book.
</p>
<h3>
	Web skills:
</h3>
<p>
<strong>
	Know how to update your website.
</strong>
	Don’t depend on someone else to do this for you.
	Know how to add new songs or videos, and how to make any changes.
</p><p>
<strong>
	Know your URLs.
</strong>
	Telling someone to go search for you is like telling them to look up your phone number.
	Instead, know your exact URLs (yoursite.com, twitter.com/something, facebook.com/whatever) so you can give it to people directly.
	If you don’t, they’ll probably never bother to go search for you.
</p><p>
<strong>
	Know how to make an MP3.
</strong>
	Give it a good filename like YOUR_NAME-Song_Title.mp3 (not mix7.mp3)
	Don’t use spaces in the filename.
	Edit the ID3 tags to put your full name and URL in the info, so whoever has this MP3 knows who it is and how to find you.
</p><p>
	Sorry if these sound too basic to you.
	But you’d be surprised by how many people don’t know these skills, and so are silently handicapped when interacting with the world.
</p>
<img alt="" src="https://sive.rs/images/internet-skills.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/netskill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655745</guid>
            <pubDate>Thu, 01 Oct 2020 20:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Shape of Belief Curves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655726">thread link</a>) | @avoidboringppl
<br/>
October 1, 2020 | https://www.leonlinsx.com/belief-curve-shape/ | <a href="https://web.archive.org/web/*/https://www.leonlinsx.com/belief-curve-shape/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <h2 id="takeaway">Takeaway</h2>

<p>We draw our beliefs from others but are ultimately responsible for them ourselves.</p>





<h2 id="belief-curves">Belief curves</h2>

<p><strong>We aren’t born with our beliefs.</strong></p>

<p>We grow into them over time, influenced by our experiences.</p>

<p>It’s fun to debate <a href="https://www.simplypsychology.org/naturevsnurture.html" title="nature">nature vs nurture</a>, biology vs behaviourism, <a href="https://www.whatisepigenetics.com/what-is-epigenetics/" title="epigenetics">genes vs epigenetics</a>, but what we believe and <a href="https://www.amazon.com/dp/0143110918/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1" title="behave">how we behave</a> is unquestionably influenced by others.</p>

<p><strong>We aren’t sure what our beliefs are either.</strong></p>

<p>We have a small set of strong beliefs, and a large set of vague ones.</p>

<p>It’s worth trying to write down all your core beliefs, the issues you feel most strongly about, your raison d’etre. If you’re like me, <a href="https://www.leonlinsx.com/about-me/" title="me">your list likely doesn’t extend much beyond 20 items</a> [1]. Yet, based on that short list of ideals, we have to make decisions in reality.</p>

<p><strong>We aren’t making decisions on just our beliefs alone.</strong></p>

<p>We realise we don’t live in a simple single person scenario, but a complex society of people.</p>

<p>We both influence and are influenced by the actions of others, and over time define <a href="https://en.wikipedia.org/wiki/Zeitgeist" title="zeit">the cultural zeitgeist</a>. Since we’re playing a relative status game, we need to consider what others believe. We behave in ways that we think will enhance our status in others’ eyes.</p>

<p><strong>Most of our time is then figuring out what others believe.</strong></p>

<p>In investing, we try to figure out <a href="https://avoidboringpeople.substack.com/p/relatively-speaking-the-billionaire?r=1b9e6&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=copy" title="cons">what market consensus is.</a> If you knew exactly where consensus was, you’d print money.</p>

<p>In tech, we try to figure out what customers desire. If you knew exactly what consumers would buy, you’d print money.</p>

<p>In life, we try to figure out what society demands. If you knew exactly what others wanted you to do, you’d print money.</p>

<p>“No way, I spend my time gathering as much information as possible, I adjust my <a href="https://en.wikipedia.org/wiki/Prior_probability" title="bayes">bayesian priors,</a> I’m a man of math”</p>

<p>If so, would evidence showing that <a href="https://scholarsbank.uoregon.edu/xmlui/bitstream/handle/1794/23607/928.pdf?sequence=3&amp;isAllowed=y" title="confidence">more information increases your confidence, but not your accuracy,</a> affect how strongly you hold your beliefs?</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20vs%20information.png" alt="post"></p>

<p>The graph above comes from a study in which bettors were given different amounts of information. The more information they got, the more confident they got in their decision, as see by the upward sloping confidence line. However, that had little to no impact on the accuracy of their bets. More isn’t better, when it’s hard to evaluate the quality of the information.</p>

<p>Most of us, myself included, like to think we’re well calibrated like the below:</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20belief%201.png" alt="post"></p>

<p>When we’re usually more like this instead:</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20belief%202.png" alt="post"></p>

<p>“No way, I’m an independent thinker, I don’t care what others think, I’m a man of science”</p>

<p>There’s less difference between you and someone who <a href="https://en.wikipedia.org/wiki/Reptilian_conspiracy_theory" title="lizards">believes in lizard people.</a> [2]</p>

<p>Let’s take something like the discovery of <a href="https://home.cern/science/physics/higgs-boson" title="Higgs">the Higgs Boson</a>, a elementary particle in physics. As a man of science, you celebrated when you read the news that it was discovered. Another advancement for the ages.</p>

<p>How can you be so sure though? It’s based on a news report, from conclusions of a paper, of a study in advanced physics that you’re unlikely to understand, let alone replicate. Try as you might, you’re not going to be able to build another Large Hadron Collider in your backyard [3]. You have to assume that what others believe is true.</p>

<p><img src="https://www.leonlinsx.com/assets/images/Lizard%20people%20vs%20Higgs.png" alt="post"></p>

<p>So that’s the bad news. You’re not much better than those of the lizard laity.</p>

<p>Here’s the good news. You still get to decide what you believe in, changing that as you learn more than before. You’re not fixed to any one opinion.</p>

<p>In those confidence vs evidence graphs above, it’s up to you to decide which type of graph you want to be. Whether that’s through <a href="https://www.theatlantic.com/politics/archive/2017/06/the-highest-form-of-disagreement/531597/" title="steelman">steelmanning the other side’s arguments</a>, doing an <a href="https://www.econlib.org/archives/2011/06/the_ideological.html" title="test">ideological turing test</a>, or just reading and talking to more people outside of your comfort zone. The choice is yours, whether to change or be constant.</p>

<p>And while that does mean that some people will be reluctant to update their harmful beliefs, it also means that there’s always hope that they can change. We can help make that happen, by being a voice of reason. When enough people express their beliefs, over time that influences others to slowly change their minds.</p>

<p><a href="https://www.youtube.com/watch?v=4QJIu15VjQg&amp;feature=youtu.be&amp;t=243" title="racist">Nobody’s born a racist;</a> everybody can change.</p>

<p>I want to believe.</p>



<ol>
  <li>For those unaware, I have a personal site as well in case substack goes away. There’s also other things I can post there like a list of websites I follow.</li>
  <li>The phrasing for polls like this <a href="https://slatestarcodex.com/2020/05/28/bush-did-north-dakota/" title="poll">can be bad</a>, but even if you haircut the numbers by 99% there is still &gt; 1 person who seriously believes in a lizard king.</li>
  <li>Well, if you somehow are able to build the next large particle accelerator in your backyard, I’d be happy to admit I’m wrong. You can even put my name down as the person who you had a bone to pick with and wanted to prove wrong.</li>
</ol>

<h2 id="paid-reader-survey-discussion">Paid reader survey discussion</h2>

<p>I did a survey on a small group of you paying subscribers; thank you to everyone who filled it out. The feedback was helpful in seeing what people have actually liked recently (the <a href="https://avoidboringpeople.substack.com/p/authentic-contrarians-vs-consensus" title="Josh">Josh Wolfe</a> and the <a href="https://avoidboringpeople.substack.com/p/picassos-new-painting-perspectives" title="Picasso">Picasso</a> profiles came up often) and also for knowing what people want more of (more finance, more tech, more random interesting things).</p>

<p>It’s also flattering and frustrating to realise that people found the recent talk summaries boring, and would rather hear my opinion instead of CEOs. Given the amount of time involved in transcribing, summarising, and cleaning those up, vs the value that people are getting out of them, it makes sense to reduce the frequency of such posts in the future.</p>

<p>Sometimes I don’t add much to something because I don’t have a strong opinion, or a high enough conviction level in the point I want to make. However, I understand the desire for more of my personal voice, and will adjust this moving forward too. This also implies that future posts will naturally be <a href="https://devonzuegel.com/post/epistemic-statuses-are-lazy-and-that-is-a-good-thing" title="status">things I’m less confident in, as I try to push the boundary of what I cover.</a></p>

<p>If there’s one thing I want to be known for, it’s that I listen to feedback seriously. I might not make all the changes that people want, but I will adjust to the extent possible so that this newsletter continues getting better. Many features of the current version were due to suggestions by readers like you, such as the takeaways up top or separate sections in the monthly. Keep the feedback coming, it’s much appreciated.</p>

<p><em>If you liked this, sign up for my <a href="https://avoidboringpeople.substack.com/" title="ABP">finance and tech newsletter:</a></em></p>



        
      </section></div>]]>
            </description>
            <link>https://www.leonlinsx.com/belief-curve-shape/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655726</guid>
            <pubDate>Thu, 01 Oct 2020 20:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Solved Problems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655637">thread link</a>) | @headalgorithm
<br/>
October 1, 2020 | https://ahmadnassri.com/blog/solving-solved-problems/ | <a href="https://web.archive.org/web/*/https://ahmadnassri.com/blog/solving-solved-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <h6 id="top"><a href="https://ahmadnassri.com/">Home</a> › <a href="https://ahmadnassri.com/blog">blog</a></h6>


  <header>
    
    <h2> — Lessons from my journey</h2>
  </header>

  <h5>How seemingly “solved problems” in technology keep repeating themselves, and how developers keep falling into the trap of reinventing the wheel
</h5>

  
    
  

  

  

  

  <p>When I started my professional journey, the technology landscape looked completely different, yet the patterns in which people operate within this ever-changing landscape keep repeating themselves.</p>

<p>It’s interesting and somewhat frustrating that the challenges I experienced leading small teams in small companies are the same challenges in  leading teams of hundreds in large enterprise businesses!</p>

<p>The interesting part is <strong>recognizing the patterns</strong> shared across all these experiences and creating solutions that scale up and down to accommodate the context. The frustrating part is how seemingly <strong>solved problems keep repeating themselves</strong>, and <strong>developers keep falling into the trap</strong> of reinventing the wheel.</p>

<p>No-one actually has a foolproof plan; people that claim they do are either faking it or miscommunicating their ability to identify patterns. This is especially true in software technology. Our industry‘s <a href="https://en.wikipedia.org/wiki/Half-life_of_knowledge">half-life of knowledge</a> is rapidly shrinking from a few years to a few months, as the rate of change and innovation keeps increasing. And while change is constant for us, so are the patterns!</p>

<p>Or as popularized by Mike Tyson’s quote: <em><strong>“Everybody has a plan until they get punched in the mouth.”</strong></em></p>

<p>In almost every team that I led, the following “solved problems” keep coming up: <em>user authentication/authorization, logging &amp; monitoring, data warehousing &amp; BI, data management &amp; security, infrastructure automation, etc …</em></p>

<p>These are but a small set of “solved problems” that kept on being reinvented, despite many products and service providers that exist solely to solve these problems for you! And I often found myself in the position of being “that guy” who has to pull the brakes and say, <em>“how about we don’t waste time reinventing the wheel here!”</em></p>

<p>One of the fundamental principles I try to instill in every team is <strong>“we should only build things that ONLY WE CAN build.”</strong> While that might seem obvious on the surface, it’s hard for many development teams to realize that they don’t have to reinvent the wheel and roll out custom <em>authentication systems, deployment tools, or monitoring solutions…</em></p>

<p>Our industry’s communities tend to believe that certain companies, which are seen as “leaders” or drivers of “innovation”, somehow have all the answers and know exactly what they are doing. I’m here to tell you that they don’t. Humans tend to put people and companies they admire on pedestals and then blindly copy or mimic them. This is dangerous, especially for technology teams.</p>

<h2 id="technical-debt-and-reinventing-the-wheel">Technical Debt and Reinventing the Wheel</h2>

<p>My first exposure to a wildly popular company and product was at <a href="https://www.itbusiness.ca/news/toronto-developers-viigo-top-download-on-blackberry-app-store/13369">Viigo</a>, a BlackBerry app that predates the iPhone and Android smartphone world. In this world, everybody had a BlackBerry in their pocket, and on that BlackBerry, they had Viigo installed. The app was so popular, it topped the BlackBerry App Store charts for years, even outranking Facebook in downloads and popularity!</p>

<p>I remember getting on subways and streetcars in Toronto, and seeing everybody on their phones using the app I worked on! The local tech community ended up putting the company and development team on a pedestal as if we were creating some groundbreaking technology</p>

<p>In reality, it was a glorified RSS reader with some additional functionality and hackery to get around the limitations of the BlackBerry OS. Most of the content was funnelled through some bat-shit-crazy XML/XSLT processing in PHP that I put together and threw on a couple of EC2 servers … there was no reason this janky XML/XSLT/PHP combo should have scaled to support tens of millions of users and a vast amount of rich media content and real-time sports events (we even covered the Olympics live with nothing but an XML feed and XSLT!). Still, it worked, and it served millions of users across the world! I led the Web Services team at the time, which consisted of myself and two developers mucking around with XSLT templates all day long!</p>

<p>Years later, I joined Mashape <em>(now known as Kong Inc.)</em> as VP of Engineering where we began with an <a href="https://konghq.com/blog/the-api-marketplace-joins-rapidapi/">API Marketplace</a> that grew from 50 users during our Alpha launch in 2010 to over 350,000 users, powering billions of real-time API calls! We later built out a standalone API Management Proxy called Kong, which took all the experience we gained to build and maintain the Marketplace into a standalone product meant for Enterprise-scale API management. The company has since shifted entirely to operating as <a href="https://konghq.com/">Kong Inc.</a> and focuses solely on the Enterprise API product space, with multiple products and services.</p>

<p>When we would go to conference events, we would have a line at our booths that sometimes stretched across the entire booth area, much to the dismay and irks of fellow booth exhibitors! People wanted our cute gorilla mascot t-shirts, and they wanted to chat with us about the “amazing” products we were producing that made their lives easier.</p>

<p>At the time, the engineering team was no more than ten developers that built and maintained four products with massive adoption and massive amounts of traffic—the secret technology behind it all: Nginx and Redis. There was nothing fancy or exceptional about the stack, and we barely managed to keep our heads above water as we proxied billions of business-critical API calls for our users through our systems.</p>

<p>My most recent role was as CTO of npm, Inc. With a massive worldwide community of users that looked to us to provide them with critical services that directly affect their productivity and daily work. Every web developer in the world used our products, with over 1.3 million open-source packages, and serving ~125 billion requests at a whopping six petabytes per month!</p>

<p>A small team of ~25 developers were responsible for this large-scale &amp; critical product, dealing with the same challenges and technical debt problems as any other startup or enterprise team. If it weren’t for a CDN partner taking care of the majority of the traffic at a HIGHLY discounted flat rate, there would have been no way a small team like that could maintain that level of scale!</p>

<p>All these teams were burnt-out. None of them were happy. But we were and still are proud of the large-scale work we accomplished with such small team sizes.</p>

<p>The other common thread in all these experiences was that they were all <em><strong>massively popular technology products mired with technical debt and reinventing-the-wheel syndrome</strong></em>. Some of that debt was created by me back when I didn’t know any better, the rest I inherited. This debt usually comes with a breakdown of technical culture and business growth challenges. While not simple nor easy, the remedy was always about focusing on <em>only building things that only the company can build</em>.</p>

<p>Viigo was <a href="https://www.theglobeandmail.com/globe-investor/rim-buying-toronto-firm-creator-of-popular-app/article4312875/">acquired by BlackBerry in 2010</a>, Kong <a href="https://konghq.com/blog/the-api-marketplace-joins-rapidapi/">sold the API Marketplace to RapidAPI in 2017</a>, and npm was just <a href="https://ahmadnassri.com/blog/so-long-and-thanks-for-all-the-packages/">recently acquired by GitHub</a>.</p>

<h2 id="enter-the-enterprise">Enter the Enterprise</h2>

<p>Before joining npm and soon after the Viigo acquisition, I went into the Enterprise world for a change of pace. In 2013 I joined the <a href="https://en.wikipedia.org/wiki/Canadian_Broadcasting_Corporation">CBC</a> as Development Manager, Digital Operations leading a team of 35, and in 2017 I was Chief Architect at <a href="https://en.wikipedia.org/wiki/Telus">TELUS</a> leading all technology practices and teams spanning over 450+ technologists. And while I’ve had many years of experience in servicing and selling technology products to Enterprise companies, my years inside the Enterprise were perhaps the most eye-opening to our industry’s patterns!</p>

<p>The main takeaway:</p>

<p><strong>There are no differences in technology operations and software development practices between Enterprises and Startups</strong>; the only differences that exist are in communications and processes, which are <em><strong>fundamentally human—not technological—problems</strong></em>.</p>

<p>Enterprise teams are also stuck solving the same “solved problems” and accumulating technical debt, rather than focusing on building the things only they can build. The difference, though, is while these were the same problems, they were distributed across departments and repeated across many teams, which <strong>ultimately adds up to hundreds of millions of dollars in waste</strong>.</p>

<p>Lacking centralized technical leadership and unified vision in the Enterprise world is the root cause for teams to fall into these traps and continue going deeper into the cycle of reinventing the wheel and creating technical debt.</p>

<picture>
  <img src="https://ahmadnassri.com/blog/solving-solved-problems/enterprise-innovation.png">
</picture>

<p>In both worlds, Enterprises and Startups require a centralized model of technical leadership. A clear and measured technical vision to avoid reinventing the wheel and minimizing technical debt can only be achieved by <strong>investing in people</strong> first, ensuring you have the right leaders, the right members, and the right tools to help them succeed. <strong>The responsibility to establish such leadership and vision lies in the hands of the CTO</strong>.</p>

<h2 id="are-there-any-answers">Are there any answers?</h2>

<p><em>Spoiler Alert!</em> there is no ONE answer to address these challenges, and that’s okay! If there was just one answer, then the entire industry will fold into itself, and we’d all be working for Microsoft!</p>

<p>And to pay respect to Mike Tyson’s wisdom again, I can’t suggest having a “plan” to address these challenges, as the next “punch” life delivers will throw any plan out the window!</p>

<p>There are, however, some <strong>key patterns that we share and pitfalls we know to avoid</strong>. My focus will be on building and sharing a body of knowledge in these areas so that CTOs, Founders and Engineering Leaders can benefit from and contribute to each other’s success!</p>

<p>I’m planning to use this space to start tackling some of those patterns one by one, and I’m looking for the community’s feedback &amp; contribution to surface our collective body of knowledge higher and higher!</p>

<h2 id="need-help-now">Need help now?</h2>

<p>While writing and sharing lessons are helpful, it takes time, and it may not be the thing you need RIGHT NOW. But don’t worry, I might still be able to help you!</p>

<p>I’ve started …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahmadnassri.com/blog/solving-solved-problems/">https://ahmadnassri.com/blog/solving-solved-problems/</a></em></p>]]>
            </description>
            <link>https://ahmadnassri.com/blog/solving-solved-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655637</guid>
            <pubDate>Thu, 01 Oct 2020 20:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why plain text emails perform better than HTML designed ones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655493">thread link</a>) | @pau_alcala
<br/>
October 1, 2020 | https://blog.palabra.io/plain-text-engagement | <a href="https://web.archive.org/web/*/https://blog.palabra.io/plain-text-engagement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a></em></p><p>Plain text sounds boring? Well, let me tell you that plain text is more important than you can imagine. At <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a> we love plain text to send every email, specially our onboarding sequences. And in this article we’ll share why we think you should start using it too.</p><h2>Isn’t plain text for grannies?👵🏼</h2><p>Plain text has been around since the beginnings of the Internet. So it is understandable that some people think it is obsolete. Maybe there was a time where HTML emails were on a boom, but plain text today is more functional than ever.</p><p>Before we continue we’d like all of us to be in the same page about what plain text is:</p><p>The term Plain text, when we talk about an email, refers to the composition that consists of the copy within the style. Which means that it does not include complex formatting or styled fonts. Although it can have images and links.</p><p>Even if plain text could sound boring at first compared with HTML emails, you will discover that their use can bring many benefits in general, and especially for onboarding sequences.</p><h2>Use plain text for onboarding sequences 🏆</h2><p>When you have a service or a product that depends, on a large portion, of having a constant flow of users, you might want to apply an onboarding sequence in order to avoid the churn rate and to connect with your community.</p><p>If you’re still in the early stage of your strategy, we recommend to read our article about <strong><a href="https://blog.palabra.io/questions-onboarding">5 questions to ask yourself before creating an onboarding email sequence</a></strong>, it will guide you in the process.</p><p>Over the years, new technologies have risen in the field of user experience. We now have many tools to call the attention of customers. This means people are getting a bunch of emails that now look like ads delivered right to your inbox.</p><p>Onboarding should look nothing like ads. That's when you start a close relationship with early users, you educate them about how to use your product better, and open communication channels.</p><h2>5 reasons why plain text is always a good idea</h2><h3>📩 It ensures deliverability</h3><p>The number one thing that you need to do to engage with someone is to get their attention. And for that, you need to get them to open your emails.</p><p>As we said before, HTML emails have images, links, GIFs, all sorts of things that attract the attention of email filters. So they’re more susceptible to being redirected to the spam folder if they have broken links or suspicious behaviours.</p><p>Since plain text emails don’t contain much more information than text, it’s much more likely that they will not alert spam filters.</p><p>Also, plain text emails seem more “real” to your email filters. And that's also handy for your readers!</p><h3>📜 It feels more personal</h3><p>Once your customers open your emails, you don’t want them to say “ugh, another stupid corporative email. DELETE”. That’s probably the worst case scenario.</p><p>Plain text has been proved to have higher click-through rates. Not just because they can pass spam filters, but also because they feel more personal. They look like something a real person sends, to offer information instead of driving sales.</p><p>Then, when you receive a plain text email, it is more associated with a regular person, someone who just wants to talk and know about you as an individual (and not as a target). Your users can perceive you more relatable, human and trust-worthy ✨.</p><h3>🗣️ Starts 1-1 conversations</h3><p>As you can see, there’s a progression. And with plain text you help your emails to be delivered and opened. Do you know what is even better? If your users answer the email!</p><p>We like plain text precisely because of this. Through this kind of emails, we’ve received feedback from our users that was very valuable for us to grow as a company and as a team. They respond because there's a real email address from a real person to answer to.</p><p>We send onboarding emails that appeal to conversation. Having a dialog is the fuel to power the relationship with the users. We try to build a space where the user can feel part of the process and can say something to improve the use of a tool that is so necessary in his life.</p><h3>👩🏼‍🦽 Is more accessible</h3><p>Now we want to highlight something that usually goes unnoticed. Plain text is readable for accessibility systems. This kind of emails has an ethical benefit, because they’re reachable for people with different needs.</p><p>When you send an HTML email, you’re making it more difficult for a blind person, for example, to understand your message.</p><p>At this point, it is good to ask ourselves if our emails can be accessed by a blind person using a screen reader.</p><h3>🔮 Adapts to new technology</h3><p>From the previous point it follows the fact that plain text is more readable. I personally was surprised to discover that you can read your emails in smartwatches and smart assisters,or that you can obtain a more comprehensible preview of the content.</p><p>I know, it is super obvious when you think about it. But we do not always have in mind that there are other kinds of displays where people read their emails or notifications. And that we have to be ahead of the new possibilities, because we don’t know what type of devices will be developed in the future.</p><p>In this case, keeping it simple will ensure you that people can read your messages.</p><p>So, now you know, don’t be shy and start sending those emails and talking to your users. You may be pleasantly surprised with what you discover.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/plain-text-engagement</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655493</guid>
            <pubDate>Thu, 01 Oct 2020 19:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subsumptions of Regular Polytopes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655303">thread link</a>) | @mathgenius
<br/>
October 1, 2020 | https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/ | <a href="https://web.archive.org/web/*/https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>We say that a regular <em>n</em>-dimensional polytope P <em>subsumes</em> a regular <em>n</em>-dimensional polytope Q if the vertex-set of Q is geometrically similar to a subset of the vertex-set of P.</p>
<p>For instance, the dodecahedron subsumes a cube (the convex hull of the red and blue vertices below), which in turn subsumes a tetrahedron (the convex hull of the blue vertices alone):</p>
<p><img loading="lazy" src="https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption.png" alt="" width="440" height="429" srcset="https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption.png 440w, https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption-300x293.png 300w" sizes="(max-width: 440px) 100vw, 440px"></p>
<p>Note that the centroid of a regular polytope is also the circumcentre — the unique point equidistant from all of the polytope’s vertices — which implies that if one polytope subsumes another, the two vertex-sets must share the same centre. Consequently, we assume without loss of generality that regular polytopes are always centred on the origin.</p>
<h3>Two and three dimensions</h3>
<p>The only regular polytopes in two dimensions are the regular polygons. Using the above reasoning, it is straightforward to see that an <em>m</em>-gon subsumes an <em>n</em>-gon if and only if <em>n</em> is a divisor of <em>m</em>.</p>
<p>In three dimensions, there are exactly five regular polytopes, the Platonic solids. We have already seen that the tetrahedron, cube, and dodecahedron form a chain of subsumptions. It can be shown that these are the only subsumptions between Platonic solids. In particular, if we normalise the solid P to be centred on the origin and have unit radius, we can calculate the set S(P) of pairwise inner products between the vertices of the polyhedron. If P subsumes Q, then S(Q) must necessarily be a subset of S(P).</p>
<h3>Four dimensions</h3>
<p>In four dimensions, there are six ‘Platonic solids’. Five of these form a subsumption chain:</p>
<ul>
<li>the orthoplex (generalised octahedron) is subsumed by</li>
<li>the hypercube, which is subsumed by</li>
<li>the 24-cell, which is subsumed by</li>
<li>the 600-cell, which is subsumed by</li>
<li>the 120-cell.</li>
</ul>
<p>There’s a really elegant way to see these inclusions in terms of quaternions. The group Q8 of eight quaternions {±1, ±i, ±j, ±k} form the vertices of an orthoplex.</p>
<p>This is an index-3 subgroup of the <em>binary tetrahedral group</em>, which contains these eight quaternions together with the 16 unit quaternions of the form:</p>
<p>½(±1 ± i ± j ± k)</p>
<p>These 16 quaternions manifestly form the vertices of a hypercube. Moreover, because we can partition the binary tetrahedral group into cosets with respect to the subgroup Q8, it follows that this hypercube is the union of two disjoint orthoplexes. Taken together, these 24 quaternions form the vertices of a 24-cell, a four-dimensional regular polytope which has no analogue in three dimensions.</p>
<p>Greg Egan’s animation below shows the three cosets in red, green, and blue. Each coset forms the vertices of an orthoplex; the union of any two cosets forms the vertices of a hypercube; the union of all three cosets forms the vertices of a 24-cell:</p>
<div id="attachment_6198"><p><img aria-describedby="caption-attachment-6198" loading="lazy" src="https://cp4space.hatsya.com/wp-content/uploads/2020/10/greg-egan-24-cell.gif" alt="" width="506" height="506"></p><p id="caption-attachment-6198">Animation by Greg Egan of a 24-cell undergoing a double rotation.</p></div>
<p>The 600-cell has 120 vertices which can be identified with the <a href="https://en.wikipedia.org/wiki/Icosian"><em>unit icosians</em></a>, a group of 120 unit quaternions which contains the binary tetrahedral group as an index-5 subgroup. It follows, therefore, that the 600-cell subsumes the 24-cell.</p>
<p>If you take the ring generated by the unit icosians, the 600 norm-2 elements form a scaled copy of the 120-cell, a four-dimensional analogue of a dodecahedron. We can identify norm-2 elements if one can be obtained from the other by right-multiplication by a unit icosian; this partitions these 600 vertices into five equivalence classes, each geometrically similar to the 120 vertices of a 600-cell.</p>
<p>The remaining four-dimensional regular polytope, the simplex, is not subsumed by any of these polytopes; again, this can be deduced from looking at the set S of inner products.</p>
<h3>Higher dimensions</h3>
<p>In higher dimensions, there are only three regular polytopes: the simplex, the orthoplex, and the hypercube.</p>
<p>S(simplex) is the set {1, −1/n}, and S(orthoplex) is the set {1, 0, −1}. It follows that neither of these can subsume each other. This leaves the question of whether the hypercube can subsume either of the other two regular polytopes. The answer is that it depends on <em>n</em>, and is an unsolved problem!</p>
<p>The orthoplex consists of n orthogonal pairs of opposite vertices. For this to be subsumed by a hypercube is equivalent to the existence of a matrix M consisting entirely of entries ±1 such that H := M / √d is a real orthogonal matrix. Such <em>Hadamard matrices</em> exist whenever <em>n</em> is a power of 2. If <em>n</em> ≥ 3, it is easy to show that <em>n</em> must be a multiple of 4, and the converse is conjectured to be true:</p>
<blockquote><p>Does a Hadamard matrix exist in dimension <em>n</em> whenever <em>n</em> is divisible by 4?</p></blockquote>
<p>The first unsolved case is <em>n</em> = 668.</p>
<p>When does the hypercube subsume a simplex? This is equivalent to having <em>n</em>+1 vectors with entries ±1 such that, for every pair of vectors, they disagree in sign in (<em>n</em>+1)/2 coordinates and agree in sign in the other (<em>n</em>−1)/2 coordinates. If we appended an (<em>n</em>+1)th coordinate which is identically 1 to every vector, they would all be orthogonal and therefore form a Hadamard matrix. The converse is also true: removing a column of a Hadamard matrix results in a set of rows which form the vertices of a regular simplex.</p>
<p>To conclude:</p>
<ul>
<li>The hypercube subsumes the simplex if and only if there is a Hadamard matrix of dimension n+1;</li>
<li>The hypercube subsumes the orthoplex if and only if there is a Hadamard matrix of dimension n.</li>
</ul>
											</div></div>]]>
            </description>
            <link>https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655303</guid>
            <pubDate>Thu, 01 Oct 2020 19:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MBA: Useless? Worth It?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655248">thread link</a>) | @william_blount
<br/>
October 1, 2020 | https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you | <a href="https://web.archive.org/web/*/https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5f739a1d700a470284ca17f2" data-item-id="5f739a1d700a470284ca17f2">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601418418482" id="item-5f739a1d700a470284ca17f2"><div><div><div data-block-type="2" id="block-03961952396bc7b16512"><div><div><p>I’ve been asked 27 times if getting an MBA is worth it. </p><p>I started counting after two close friends texted me essentially the same question:</p><p>‘Considering going back to school... do you think I should get an MBA?’</p><p>I love helping out. But there comes a point when answering the same question 27 times is a little absurd. This essay is my no-bullshit attempt to help people answer that question. </p><p><strong>Disclaimer: </strong>I have an MBA. It was worth it. I doubled my salary, made life-long friends, and learned a hell of a lot. <em>But it’s not worth it for most people.</em><strong>TL;DR - there are only two good reasons to get an MBA</strong>If you stumbled across this essay because you’re considering an MBA I want you to have a definitive answer by the time you’re finished reading. </p><p>Not some wishy-washy ‘well it depends on these 13 factors and if you have kids and if you can ace the GMAT and if you can get into a top school and if if if.’</p><p>Here’s your answer - there are only two GOOD reasons to get an MBA:</p><p>- You want to pivot your career, <em>fast.<br></em>- Your company requires an MBA for promotion - a.k.a. you need to ‘check the box.’</p><p>That’s it. All other reasons aren’t good enough. There’s the ‘TL;DR’ version of this essay.&nbsp; </p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_27853"><p><h2 id="Table1">1. My personal MBA journey</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411557388_15111"><div><div><p>I started my career as a microbiologist and quality engineer for a large food manufacturing company. It didn’t take long to realize I hated my work.&nbsp;</p><p>About a year and a half into my first job a senior sales executive <a href="https://www.adamtank.com/new-blog/2020/6/27/slumdog-millionaire-how-i-found-new-purpose-getting-lost-in-rio-de-janeiro" target="_blank">opened my eyes to business</a>, and specifically, the importance of concepts like branding, value propositions, supply chain, and other terms I hadn’t ever heard of or thought about. </p><p>I knew I needed to make a career change and started to look for ways to switch roles inside of the company. I was especially interested in sales and marketing roles because when I interacted with those types of employees I felt my strengths, namely <a href="https://www.adamtank.com/new-blog/2020/3/31/most-presentations-suck-heres-what-you-can-do-about-it" target="_blank">public speaking and presentation</a> skills, were more closely aligned with what they did day-to-day.</p><p>After attempting to navigate the internal political structure I came to the realization I wouldn’t be able to switch roles (engineer -&gt; sales) without it taking multiple years and a ton of headaches. Big companies aren’t set up for employees to readily explore their career interests, much less make job function changes in a short amount of time.</p><p>I started looking externally for opportunities that would expose me to other functions and divisions of a business, in addition to the possibility of living and working abroad. I settled on a small food manufacturing company in Rio de Janeiro, Brazil with the goal of getting their processes up to international export certification standards.&nbsp;</p><p>After a year or so living and working in Rio (and also having to embarrassingly <a href="https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child" target="_blank">learn Portuguese</a>), I came back to the U.S. to help them sell their products. I loved sales and decided to solidify my interest in becoming a full-blown sales &amp; marketing person by getting an MBA. I felt, and still feel, that it was the quickest path to redefine myself in the eyes of future employers as a business person and not just a quality/manufacturing engineer.</p><p>I studied for and took the GMAT twice, researched potential schools, and applied to a half dozen. I settled on the University of Arizona because of their highly ranked entrepreneurship program and the affordability (free with my GMAT score of 690 - above average but nothing too spectacular).&nbsp;</p><p>My two year, full-time experience was definitely worth it. I doubled my salary, made life-long friends, and learned a hell of a lot.&nbsp;</p><p>But it’s not worth it for most people.</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_39092"><p><h2 id="Table2">2. The most commonly used BAD reasons to get an MBA</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601418515090_40006"><div><div><p>This section lists the top five reasons I’ve heard from friends considering an MBA. The list is not complete and a <a href="https://www.postgrad.com/business-schools/mba-program/reasons-to-study-an-mba/" target="_blank">quick google search</a> will bring up dozens of others. But none of these are good enough to justify spending two years of your life and hundreds of thousands of dollars on a business degree.</p><p><strong>&nbsp;- <em>“I want the network”</em></strong>Although you can develop a great network in business school it should only be a consideration for what full-time school you choose (discussed below), but not a reason to go in the first place.<strong><em></em></strong>This was a good reason before the internet really took off. You can meet, interact, and network with <strong><em>anyone</em></strong> using the power of the internet and social media… specifically <a href="https://twitter.com/artank/status/1304116979985457155?s=20" target="_blank">Twitter.</a></p><p>Elite individuals including business professionals and entrepreneurs all congregate in like-minded groups around the internet. You have to do some digging to find them. But that digging will cost you far less in both time and money than an MBA.&nbsp;</p><p>Take, for instance, one of <a href="https://www.inc.com/bill-murphy-jr/ubers-original-ceo-resigns-the-guy-before-travis-k.html" target="_blank">Travis Kalanick’s first employees</a> at Uber who became CEO… all because he responded to one of Travis’ tweets.&nbsp;</p><p><em>I’ve built a broader AND deeper network</em> than I ever did in grad school by having an active <a href="https://twitter.com/artank" target="_blank">Twitter presence</a>, <a href="https://www.adamtank.com/new-blog/2020/4/30/the-cost-of-writing-well" target="_blank">taking online courses</a>, and a <a href="https://www.adamtank.com/contact" target="_blank">contact me</a> form on this blog.&nbsp;</p><p>If network is the primary reason you’re considering business school think about <em>who</em> you want to network with and <em>why</em>. Create ‘personas’ of those people you imagine surrounding yourself with and then go and find them on the internet. Engage. And see what happens.</p><p><strong>&nbsp;- “<em>I want to learn more about business”</em></strong>That’s what YouTube and Wikipedia are for. That’s also what colleagues in other departments of your workplace are for. You could also try a career in a small business or work for an entrepreneur as a ‘side hustle.’&nbsp;</p><p>There’s also the option of free or heavily discounted online courses through <a href="https://www.udemy.com/course/an-entire-mba-in-1-courseaward-winning-business-school-prof/" target="_blank">Udemy</a>, <a href="https://www.coursera.org/business/collections/mini-mba/" target="_blank">Coursera</a>, or something like <a href="https://altmba.com/" target="_blank">Seth Godin’s altMBA</a>. </p><p>If you really feel motivated try <a href="https://www.adamtank.com/new-blog/2020/4/12/my-failed-attempt-at-the-4-hour-workweek" target="_blank">starting your own company</a>. The best way to learn about business is to do it, not study it. <strong> <p>&nbsp;- “<em>I want to increase my salary”</em></p></strong>Getting an MBA doesn’t guarantee you anything, much less a salary increase, just like getting an undergrad degree doesn’t guarantee you a job.&nbsp;</p><p>MBA students who work hard, go to top schools, and enter highly-paid industries like consulting (despite what they <em>really</em> want out of life) typically see salary increases… but if getting an MBA guaranteed a salary increase there’d be a hell of a lot more people getting MBAs.</p><p><a href="https://bschool.pepperdine.edu/blog/posts/how-does-mba-impact-salary.htm" target="_blank">Pepperdine’s blog</a> sums it up well:</p></div></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601411557388_18755"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>A survey of over 100,000 respondents indicates the average MBA salary is $86,000. According to the U.S. News &amp; World Report article Find MBAs That Lead to Employment, High Salaries, among the 130 ranked full-time MBA programs that reported data, the highest average MBA salary and bonus paid to 2018 graduates was $102,495...<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411557388_20396"><div><div><p>Keep in mind that the highest <em>AVERAGE</em> MBA salary and bonus in 2018 was $102k. So half of the graduates fell below that… and the upper half likely already had lucrative careers lined up with a former employer before they even started their graduate program.</p><p>Pepperdine then says, “<strong>While there is no guarantee your MBA salary will fall within or beyond this range</strong>, data does show that MBA graduates tend to make good money.”</p><p>What is ‘good money’ anyway? <a href="https://www.cnbc.com/2020/05/26/how-your-salary-and-the-way-you-spend-money-affect-your-happiness.html#:~:text=There%20is%20a%20sort%20of%20perfect%20'happiness'%20salary&amp;text=But%20more%20recently%2C%20a%202018,%2475%2C000%20for%20emotional%20well%2Dbeing." target="_blank">Studies have shown</a> that happiness levels start to fall off after an individual makes more than ~105k/yr. - or right about the highest average starting salary + bonus of an MBA graduate (how ironic…).</p><p>As Biggie says… mo’ money, mo’ problems.</p><p><strong>- <em>“It will help me figure out what to do with my life”</em></strong>If this is a top reason you’re likely a recent college grad, &lt;5 yrs into your career, or recently unemployed.</p><p>Using an MBA to switch careers is great (discussed below). Using an MBA to find a new career is not. Ask yourself if you’re truly using business school to explore an alternate career path (unlikely) or just using it to kill time until you find your next job (likely).&nbsp;</p><p><strong>Grad school will not help you figure out your path in life.&nbsp;</strong>Only you can do that.</p><p>And spending $100k and two years trying to do that is a waste of time and money.&nbsp; An MBA is a safe choice, not a life-changing choice. Don’t conflate the two.&nbsp;</p><p>As John Shedd says, “A ship in harbor is safe, but that is not what ships are built for.”</p><p><strong><em>&nbsp;- “An MBA will impress employers and people in my network”</em></strong>Publicly posting the ‘alphabet soup’ of credentials makes you look like an ass and nobody cares. Here’s a real example on a LinkedIn profile:</p><p>MBA, PMP®, CSM®, PMI-ACP®, ITIL®&nbsp;</p><p>If an employer requires those credentials that’s fine… but they belong on your resume, not as a publicly visible badge of honor.</p><p>As fellow MBA and <a href="https://www.adamtank.com/new-blog/2020/4/30/the-cost-of-writing-well" target="_blank">Write of Passage</a> friend <a href="http://camhouser.com/" target="_blank">Cam Houser</a> says, “MBA is particularly useless here. PhD actually (sometimes) carry weight. MBA on your list looks weak.”</p></div><div><p>The problem with MBA-types - myself included - is that we overanalyze decisions. Paralysis by analysis. I’m trying to help you avoid that. The intent of this section is to help you think critically about a big life decision and come to a definitive answer on what you should do.&nbsp;</p><p>The question you’re asking - should I get an MBA? - is the wrong question. Instead, you should be brutally honest with yourself and answer this question: <strong>What am I trying to accomplish by getting an MBA?</strong>Unlike medicine or law there’s not an MBA requirement (or any degree, for that matter) to have a career in business. You can be wildly successful without any credentials. </p><p>Want proof? If money is your measurement, 30% of billionaires in 2015 didn’t even have a <a href="https://fortune.com/2016/08/08/billionaires-no-degree/#:~:text=About%20three%20out%20of%2010,billionaire%20census%20by%20Wealth%2DX.&amp;text=The%20percent%20of%20billionaires%20with,of%20billionaires%20had%20no%20degree.">bachelor’s degree</a>.&nbsp;</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_47805"><p><h2 id="Table3">3. The only two GOOD reasons to get an MBA</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601418515090_55018"><div><div><p>This leads me to the only two good reasons to get an MBA. </p><p><strong><em>&nbsp;- You want to pivot your career, fast </em></strong>What I mean by pivot is someone going from an <a href="https://www.punchlistzero.com/this-is-the-best-minor-to-supplement-your-engineering-degree/">engineer</a> to a finance professional, or a non-profit employee to a marketer. Without an MBA this process can take YEARS and come with a lot of headaches, salary reductions, and overall misery.</p><p>The beauty of an MBA is that the first day you set foot on campus you get to choose your ‘new persona.’ And it’s totally acceptable in the eyes of employers!&nbsp;</p><p>As an example, I was a quality and manufacturing engineer that <em>in the first week on campus</em> applied for sales and marketing internships. Many of my classmates were non-profit employees their entire …</p></div></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you">https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you</a></em></p>]]>
            </description>
            <link>https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655248</guid>
            <pubDate>Thu, 01 Oct 2020 19:31:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next-Gen Rust Web Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654891">thread link</a>) | @yannikyeo
<br/>
October 1, 2020 | https://blog.shortepic.com/blog/first/ | <a href="https://web.archive.org/web/*/https://blog.shortepic.com/blog/first/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>This is an homage to this absolute <a href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">work of art</a> by Shesh Babu.</p>

<p>Rust's strong typing and fearless concurrency means we can skip virtual DOM differencing. </p>
<p>In the JavaScript world, avoiding the vDOM is the bread and butter of <a href="https://svelte.dev/">Svelte</a> 
started by Rich Harris, which uses compile-time code generation to assist.</p>
<p>When I can't have static typing I love Clojure, and have spent some time reviewing and 
playing with the stupendous full-stack Clojure SPA framework <a href="http://book.fulcrologic.com/">Fulcro</a> 
by Tony Kay (and associated back-end enabler <a href="https://blog.wsscode.com/pathom/">Pathom</a> 
by Wilker Lucio). It does use vDOM, leveraging Clojure immutable/concurrent data structures 
for time travel superpowers.</p>
<p>For me, the major innovation (among many) in Fulcro is the use of a browser-side normalised database 
which is queried to populate properties for components. This means that updating (<em>mutating</em>) 
a uniquely-keyed item results in the update trivially propagating to any and all components 
referencing the data through that identifier. In Shesh Babu's language: all state is App state.</p>
<p>This article, or series of articles, is going to share my findings and thinking on the 
state of the nation in Rust front-end frameworks which are avoiding the vDOM strategy.</p>
<p>There are actually two Rust front-end frameworks with significant progress already, and they are 
awesome:</p>
<ul>
<li><a href="https://crates.io/crates/mogwai">mogwai</a> by Schell Scivally</li>
<li><a href="https://crates.io/crates/valerie">valerie</a> by Emmanuel Antony</li>
</ul>

<p>The official React site offers a <a href="https://reactjs.org/tutorial/tutorial.html">guided introduction</a> 
by progressively implementing a client-side tic-tac-toe game (also known as <em>noughts and crosses</em>). 
They don't explore a back-end, routing or forms, or many of the other SPA complexities. </p>
<p>For us, it is just enough to highlight the potential of the two Rust frameworks above and paint 
a picture of how those advanced extensions can be easily incorporated, and gives us a solid 
reference point from the old world.</p>

<p>This is the first in a series of articles showing how the two frameworks might attack the example 
application, and then show some code which extends the frameworks to incorporate Fulcro-like app 
state.</p>
<p>My code will concentrate on the ergonomics of the frameworks from the perspective of the SPA-writer.</p>
<p>Next up, I'll show an implementation of the game in Valerie.</p>
<p><a href="https://blog.shortepic.com/blog/second/">On to the first code sample</a>.</p>

  </article></div>]]>
            </description>
            <link>https://blog.shortepic.com/blog/first/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654891</guid>
            <pubDate>Thu, 01 Oct 2020 19:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incarceration in Real Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654820">thread link</a>) | @tmsh
<br/>
October 1, 2020 | https://mkorostoff.github.io/incarceration-in-real-numbers/ | <a href="https://web.archive.org/web/*/https://mkorostoff.github.io/incarceration-in-real-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="prisoners">
    
    
    
    

    <div>
      <p>The United States holds more people in jails and prisons than any other country by far, both in absolute numbers and as a percentage of population.</p>
    </div>

    <div id="per-one-hundred">
      <div id="per-one-hundred-inner">
        <h2>Incarcerated per 100,000 residents <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p><span>USA (698)</span></p>
        <p><span>El Salvador (590)</span></p>
        <p><span>Turkmenistan (552)</span></p>
        <p><span>Thailand (531)</span></p>
        <p><span>Rwanda (511)</span></p>
        <p><span>Cuba (510)</span></p>
        <p><span>Panama (401)</span></p>
        <p><span>Costa Rica (374)</span></p>
        <p><span>Cayman Islands (365)</span></p>
        <p><span>Russia (363)</span></p>
        <p><span>Belize (356)</span></p>
        <p><span>Brazil (348)</span></p>
        <p><span>Belarus (343)</span></p>
        <p><span>Nicaragua (332)</span></p>
        <p><span>Turkey (324)</span></p>
        <p><span>Puerto Rico (313)</span></p>
        <p><span>Brunei Darussalam (307)</span></p>
        <p><span>Cape Verde (296)</span></p>
        <p><span>Uruguay (295)</span></p>
        <p><span>Namibia (295)</span></p>
        <p><span>Iran (294)</span></p>
        <p><span>Trinidad and Tobago (292)</span></p>
        <p><span>Guyana (284)</span></p>
        <p><span>Peru (278)</span></p>
        <p><span>South Africa (275)</span></p>
        <p><span>Georgia (262)</span></p>
        <p><span>Taiwan (258)</span></p>
        <p><span>Swaziland (258)</span></p>
        <p><span>Greenland (249)</span></p>
        <p><span>Colombia (246)</span></p>
        <p><span>French Guiana (243)</span></p>
        <p><span>Gabon (241)</span></p>
        <p><span>Morocco (237)</span></p>
        <p><span>Dominican Republic (237)</span></p>
        <p><span>CuraÃ§ao (236)</span></p>
        <p><span>Azerbaijan (235)</span></p>
        <p><span>Israel (234)</span></p>
        <p><span>Bahrain (234)</span></p>
        <p><span>Ecuador (233)</span></p>
        <p><span>Macau (233)</span></p>
        <p><span>Chile (232)</span></p>
        <p><span>Argentina (230)</span></p>
        <p><span>Malaysia (230)</span></p>
        <p><span>Honduras (229)</span></p>
        <p><span>Lithuania (221)</span></p>
        <p><span>Cambodia (220)</span></p>
        <p><span>Martinique (215)</span></p>
        <p><span>Fiji (210)</span></p>
        <p><span>Botswana (208)</span></p>
        <p><span>Mauritius (203)</span></p>
        <p><span>New Zealand (201)</span></p>
        <p><span>Paraguay (199)</span></p>
        <p><span>Singapore (199)</span></p>
        <p><span>Jordan (198)</span></p>
        <p><span>Saudi Arabia (197)</span></p>
        <p><span>Czech Republic (197)</span></p>
        <p><span>Poland (195)</span></p>
        <p><span>Tunisia (195)</span></p>
        <p><span>Slovakia (195)</span></p>
        <p><span>Moldova (194)</span></p>
        <p><span>New Caledonia (189)</span></p>
        <p><span>Estonia (187)</span></p>
        <p><span>Latvia (183)</span></p>
        <p><span>Montenegro (183)</span></p>
        <p><span>Suriname (183)</span></p>
        <p><span>Philippines (179)</span></p>
        <p><span>Venezuela (178)</span></p>
        <p><span>Albania (177)</span></p>
        <p><span>Hungary (173)</span></p>
        <p><span>Myanmar (171)</span></p>
        <p><span>Australia (170)</span></p>
        <p><span>Mexico (163)</span></p>
        <p><span>Kyrgyzstan (161)</span></p>
        <p><span>Bolivia (158)</span></p>
        <p><span>Kazakhstan (156)</span></p>
        <p><span>Serbia (156)</span></p>
        <p><span>Algeria (151)</span></p>
        <p><span>Uzbekistan (150)</span></p>
        <p><span>Scotland (149)</span></p>
        <p><span>Ukraine (148)</span></p>
        <p><span>Bhutan (145)</span></p>
        <p><span>Lebanon (144)</span></p>
        <p><span>Guatemala (143)</span></p>
        <p><span>England &amp; Wales (140)</span></p>
        <p><span>Nauru (140)</span></p>
        <p><span>Libya (139)</span></p>
        <p><span>Jamaica (138)</span></p>
        <p><span>Malta (131)</span></p>
        <p><span>Laos (130)</span></p>
        <p><span>Vietnam (128)</span></p>
        <p><span>Ethiopia (127)</span></p>
        <p><span>Micronesia (127)</span></p>
        <p><span>Guernsey (127)</span></p>
        <p><span>Iraq (126)</span></p>
        <p><span>Portugal (125)</span></p>
        <p><span>Bulgaria (125)</span></p>
        <p><span>Isle of Man (125)</span></p>
        <p><span>Spain (124)</span></p>
        <p><span>Uganda (124)</span></p>
        <p><span>Cameroon (124)</span></p>
        <p><span>Zambia (123)</span></p>
        <p><span>Tajikistan (121)</span></p>
        <p><span>China (120)</span></p>
        <p><span>Kuwait (117)</span></p>
        <p><span>Egypt (116)</span></p>
        <p><span>Zimbabwe (114)</span></p>
        <p><span>North Macedonia (112)</span></p>
        <p><span>Mongolia (110)</span></p>
        <p><span>Canada (107)</span></p>
        <p><span>Romania (107)</span></p>
        <p><span>Hong Kong (106)</span></p>
        <p><span>France (105)</span></p>
        <p><span>Sri Lanka (105)</span></p>
        <p><span>Luxembourg (105)</span></p>
        <p><span>UAE (104)</span></p>
        <p><span>Kenya (102)</span></p>
        <p><span>Italy (101)</span></p>
        <p><span>Indonesia (99)</span></p>
        <p><span>Austria (98)</span></p>
        <p><span>Belgium (95)</span></p>
        <p><span>Greece (95)</span></p>
        <p><span>Kosovo (95)</span></p>
        <p><span>Madagascar (93)</span></p>
        <p><span>Angola (93)</span></p>
        <p><span>Lesotho (92)</span></p>
        <p><span>Afghanistan (87)</span></p>
        <p><span>Cyprus (86)</span></p>
        <p><span>Burundi  (85)</span></p>
        <p><span>Monaco (83)</span></p>
        <p><span>Cote d'Ivoire  (82)</span></p>
        <p><span>Switzerland  (81)</span></p>
        <p><span>Haiti  (80)</span></p>
        <p><span>Croatia  (79)</span></p>
        <p><span>Ireland (79)</span></p>
        <p><span>Nepal  (79)</span></p>
        <p><span>Northern Ireland (78)</span></p>
        <p><span>Germany  (77)</span></p>
        <p><span>Armenia  (76)</span></p>
        <p><span>Malawi (76)</span></p>
        <p><span>Slovenia (69)</span></p>
        <p><span>Benin  (68)</span></p>
        <p><span>Senegal  (68)</span></p>
        <p><span>Djibouti (66)</span></p>
        <p><span>Togo (66)</span></p>
        <p><span>Andorra  (64)</span></p>
        <p><span>Denmark  (63)</span></p>
        <p><span>Equatorial Guinea  (63)</span></p>
        <p><span>Mozambique (63)</span></p>
        <p><span>Papua New Guinea (62)</span></p>
        <p><span>Sweden (61)</span></p>
        <p><span>Netherlands  (61)</span></p>
        <p><span>Norway (60)</span></p>
        <p><span>Sierra Leone (60)</span></p>
        <p><span>Syria  (60)</span></p>
        <p><span>Chad (59)</span></p>
        <p><span>Tanzania (59)</span></p>
        <p><span>Finland  (53)</span></p>
        <p><span>Mauritania (53)</span></p>
        <p><span>Qatar  (53)</span></p>
        <p><span>Yemen  (53)</span></p>
        <p><span>Bangladesh (52)</span></p>
        <p><span>Ghana  (52)</span></p>
        <p><span>Sudan  (52)</span></p>
        <p><span>Timor-Leste (52)</span></p>
        <p><span>Liberia  (50)</span></p>
        <p><span>South Sudan  (50)</span></p>
        <p><span>Niger  (44)</span></p>
        <p><span>Burkina Faso (39)</span></p>
        <p><span>Japan  (39)</span></p>
        <p><span>Pakistan (38)</span></p>
        <p><span>Iceland  (37)</span></p>
        <p><span>Nigeria  (36)</span></p>
        <p><span>Oman (36)</span></p>
        <p><span>India  (34)</span></p>
        <p><span>Mali (33)</span></p>
        <p><span>Gambia (31)</span></p>
        <p><span>Liechtenstein  (31)</span></p>
        <p><span>Democratic Republic of Congo (29)</span></p>
        <p><span>Guinea (28)</span></p>
        <p><span>Congo (27)</span></p>
        <p><span>Central African Republic (16)</span></p>
        <p><span>Guinea Bissau  (10)</span></p>
        <p><span>San Marino (6)</span></p>
      <p><a onclick="toggleExpand('per-one-hundred', 'per-one-hundred-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div id="country-rank">
      <div id="country-rank-inner">
        <h2>Number of people incarcerated <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p>USA (2.3M)</p>
        <p><span>China (1.7M)</span></p>
        <p><span>Brazil (747K)</span></p>
        <p><span>Russian Federation (524K)</span></p>
        <p><span>India (466K)</span></p>
        <p><span>Thailand (368K)</span></p>
        <p><span>Indonesia (267K)</span></p>
        <p><span>Turkey (265K)</span></p>
        <p><span>Iran (240K)</span></p>
        <p><span>Philippines (215K)</span></p>
        <p><span>Mexico (203K)</span></p>
        <p><span>South Africa (163K)</span></p>
        <p><span>Vietnam (124K)</span></p>
        <p><span>Colombia (123K)</span></p>
        <p><span>Ethiopia (114K)</span></p>
        <p><span>Egypt (106K)</span></p>
        <p><span>Argentina (103K)</span></p>
        <p><span>Myanmar  (92K)</span></p>
        <p><span>Peru (91K)</span></p>
        <p><span>Bangladesh (88K)</span></p>
        <p><span>Morocco (86K)</span></p>
        <p><span>United Kingdom: England &amp; Wales (83K)</span></p>
        <p><span>Pakistan (77K)</span></p>
        <p><span>Poland (74K)</span></p>
        <p><span>Malaysia (74K)</span></p>
        <p><span>Nigeria (73K)</span></p>
        <p><span>France (71K)</span></p>
        <p><span>Rwanda (65K)</span></p>
        <p><span>Germany (64K)</span></p>
        <p><span>Algeria (63K)</span></p>
        <p><span>Saudi Arabia (61K)</span></p>
        <p><span>Taiwan (61K)</span></p>
        <p><span>Italy (61K)</span></p>
        <p><span>Spain (58K)</span></p>
        <p><span>Cuba (57K)</span></p>
        <p><span>Venezuela (57K)</span></p>
        <p><span>Uganda (55K)</span></p>
        <p><span>Republic of  (55K)</span></p>
        <p><span>Ukraine (53K)</span></p>
        <p><span>Kenya (51K)</span></p>
        <p><span>Japan (49K)</span></p>
        <p><span>Iraq (45K)</span></p>
        <p><span>Uzbekistan (44K)</span></p>
        <p><span>Australia (43K)</span></p>
        <p><span>Chile (43K)</span></p>
        <p><span>Ecuador (40K)</span></p>
        <p><span>Canada (40K)</span></p>
        <p><span>El Salvador (38K)</span></p>
        <p><span>Cambodia (37K)</span></p>
        <p><span>Tanzania (36K)</span></p>
        <p><span>Belarus (33K)</span></p>
        <p><span>Afghanistan (31K)</span></p>
        <p><span>Cameroon (31K)</span></p>
        <p><span>Turkmenistan (30K)</span></p>
        <p><span>Kazakhstan (29K)</span></p>
        <p><span>Dominican Republic (26K)</span></p>
        <p><span>Guatemala (25K)</span></p>
        <p><span>Madagascar (25K)</span></p>
        <p><span>Angola (24K)</span></p>
        <p><span>Nepal (24K)</span></p>
        <p><span>Sri Lanka (23K)</span></p>
        <p><span>Azerbaijan (23K)</span></p>
        <p><span>Zambia (23K)</span></p>
        <p><span>Tunisia (23K)</span></p>
        <p><span>Cote d'Ivoire (21K)</span></p>
        <p><span>Czech Republic (21K)</span></p>
        <p><span>Sudan (21K)</span></p>
        <p><span>Nicaragua (21K)</span></p>
        <p><span>Romania (21K)</span></p>
        <p><span>Democratic Republic of Congo (21K)</span></p>
        <p><span>Honduras (21K)</span></p>
        <p><span>Jordan (20K)</span></p>
        <p><span>Mozambique (20K)</span></p>
        <p><span>Zimbabwe (19K)</span></p>
        <p><span>Israel (19K)</span></p>
        <p><span>Costa Rica (19K)</span></p>
        <p><span>Bolivia (18K)</span></p>
        <p><span>Panama (17K)</span></p>
        <p><span>Hungary (17K)</span></p>
        <p><span>Ghana (15K)</span></p>
        <p><span>Malawi (15K)</span></p>
        <p><span>Yemen (14K)</span></p>
        <p><span>Paraguay (14K)</span></p>
        <p><span>Portugal (13K)</span></p>
        <p><span>Singapore (12K)</span></p>
        <p><span>Senegal (12K)</span></p>
        <p><span>Belgium (11K)</span></p>
        <p><span>Serbia (11K)</span></p>
        <p><span>Burundi (11K)</span></p>
        <p><span>Slovakia (11K)</span></p>
        <p><span>Syria (11K)</span></p>
        <p><span>Puerto Rico  (10K)</span></p>
        <p><span>Netherlands (10K)</span></p>
        <p><span>Uruguay (10K)</span></p>
        <p><span>Greece (10K)</span></p>
        <p><span>Kyrgyzstan (10K)</span></p>
        <p><span>New Zealand (10K)</span></p>
        <p><span>United Arab Emirates (10K)</span></p>
        <p><span>Georgia (10K)</span></p>
        <p><span>Niger (10K)</span></p>
        <p><span>Tajikistan (9K)</span></p>
        <p><span>Libya (9K)</span></p>
        <p><span>Bulgaria (9K)</span></p>
        <p><span>Laos (9K)</span></p>
        <p><span>Haiti (9K)</span></p>
        <p><span>Chad (9K)</span></p>
        <p><span>Austria (9K)</span></p>
        <p><span>United Kingdom: Scotland (8K)</span></p>
        <p><span>Hong Kong  (8K)</span></p>
        <p><span>Benin (8K)</span></p>
        <p><span>Burkina Faso (8K)</span></p>
        <p><span>Namibia (7K)</span></p>
        <p><span>South Sudan (7K)</span></p>
        <p><span>Lebanon (7K)</span></p>
        <p><span>Switzerland (7K)</span></p>
        <p><span>Moldova  (7K)</span></p>
        <p><span>Sweden (6K)</span></p>
        <p><span>Lithuania (6K)</span></p>
        <p><span>Mali (5K)</span></p>
        <p><span>Togo (5K)</span></p>
        <p><span>Papua New Guinea (5K)</span></p>
        <p><span>Albania (5K)</span></p>
        <p><span>Sierra Leone (5K)</span></p>
        <p><span>Kuwait (5K)</span></p>
        <p><span>Gabon (4K)</span></p>
        <p><span>Botswana (4K)</span></p>
        <p><span>Trinidad and Tobago (4K)</span></p>
        <p><span>Ireland, Republic of (4K)</span></p>
        <p><span>Jamaica (4K)</span></p>
        <p><span>Guinea  (4K)</span></p>
        <p><span>Denmark (4K)</span></p>
        <p><span>Latvia (4K)</span></p>
        <p><span>Bahrain (3K)</span></p>
        <p><span>Swaziland/eSwatini (3K)</span></p>
        <p><span>Mongolia (3K)</span></p>
        <p><span>Croatia (3K)</span></p>
        <p><span>Norway (3K)</span></p>
        <p><span>Finland (3K)</span></p>
        <p><span>Mauritius (3K)</span></p>
        <p><span>Estonia (2K)</span></p>
        <p><span>Liberia (2K)</span></p>
        <p><span>North Macedonia (2K)</span></p>
        <p><span>Mauritania (2K)</span></p>
        <p><span>Armenia (2K)</span></p>
        <p><span>Guyana (2K)</span></p>
        <p><span>Lesotho (2K)</span></p>
        <p><span>Fiji (2K)</span></p>
        <p><span>Maldives (2K)</span></p>
        <p><span>Bahamas (2K)</span></p>
        <p><span>Bosnia and Herzegovina: Federation (2K)</span></p>
        <p><span>Kosovo/Kosova (2K)</span></p>
        <p><span>Macau  (2K)</span></p>
        <p><span>Cape Verde  (2K)</span></p>
        <p><span>United Kingdom: Northern Ireland (1K)</span></p>
        <p><span>Slovenia (1K)</span></p>
        <p><span>Brunei Darussalam (1K)</span></p>
        <p><span>Oman (1K)</span></p>
        <p><span>Belize (1K)</span></p>
        <p><span>Congo  (1K)</span></p>
      <p><a onclick="toggleExpand('country-rank', 'country-rank-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div>
      <p>There are more incarcerated people than members of almost any profession. There are more incarcerated people than military personnel. There are more incarcerated people than bus drivers, bar tenders, and hair dressers combined. [<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-compared-to-professions"></a>]</p>
    </div>

    <div>
      <p>
        More Americans are incarcerated today than there have been Americans killed in all of the wars in all of history combined.
      </p>
    </div>

    <div id="casualties">
      <div>
        <h2>Incarceration compared to casualties of war <sup>[<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#american-war-dead"></a>]</sup></h2>
        <p>Americans currently incarcerated (2.3M)</p>
        <p>American war dead, all of history combined (1.3M)</p>
        <p>American war wounded, all of history combined (1.5M)</p>
      </div>
    </div>

    <div>
      <p>While the incarcerated population is unfathomably large, it is just the tip of the iceberg.</p>
    </div>

    <div id="correctional-population">
      <div>
        <h2>The total correctional population <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#total-correctional-population" target="_blank"></a>]</sup></h2>
        <div>

          <div>
            <p>Currently incarcerated (2.3M)</p>
          </div>

          <div>
            <p>Will be incarcerated this year (4.9M)</p>
          </div>

          <div>
            <p>Alive currently, will go to prison ever (10.9M)</p>
          </div>

          <div>
            <p>Has a criminal record (77M)</p>
          </div>

          <div>
            <p>Ever had an immediate family member incarcerated (113M)</p>
          </div>

        </div>
      </div>
    </div>

    <div>
      <p>Almost no one gets a trial.</p>
    </div>

    <div>
      <p><img src="https://mkorostoff.github.io/incarceration-in-real-numbers/img/person/blue.svg">Notice that the background icons have changed. The blue icons are the portion of incarcerated people who got trials, around 2%.</p>
    </div>

    <div>
      <p>Almost all accused people are extorted into taking plea bargains under the threat of a longer sentence, the ruinous cost of mounting a defense, and the wildly under-resourced public defender system. [<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#plea-bargains" target="_blank"></a>]</p>
    </div>

    <div>
      <p>No other country on earth incarcerates so many people without trial. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mkorostoff.github.io/incarceration-in-real-numbers/">https://mkorostoff.github.io/incarceration-in-real-numbers/</a></em></p>]]>
            </description>
            <link>https://mkorostoff.github.io/incarceration-in-real-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654820</guid>
            <pubDate>Thu, 01 Oct 2020 18:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing spam emails from 43% to 1% (after a spammer exploited our SaaS)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654762">thread link</a>) | @kareemm
<br/>
October 1, 2020 | https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/ | <a href="https://web.archive.org/web/*/https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <p>Last month spammers found a hole in our app that let them send spam emails.   Our customers use Savio to track feature requests.  When those requests get deployed, our customers send a "<a href="https://www.savio.io/use-cases/close-the-loop/">close the loop</a>" email so requesters know the feature they wanted is now live.</p>
<p>Spammers exploited this feature to send about 20,000 unsolicited emails.  Fortunately there was a bit of friction if you're trying to use Savio to spam; it wasn't as easy as pasting in a list of email addresses and hitting send so the spammers weren't able to do major damage.  Plus, we noticed the problem within an hour or so and were able to close the exploit quickly.</p>
<p>Here's our daily email sent volume (the attack happened on August 27):</p>
<p><img alt="Sending volume went up significantly.  Thanks Spammers!" src="https://a.storyblok.com/f/84825/1902x1002/736c27b517/sending-volume.png"> </p>
<p>We only had 4 spam complaints. But we also had 3744 bounces:</p>
<p><img alt="Not too many bounces" src="https://a.storyblok.com/f/84825/2022x1042/bd71153076/bounces.png"> </p>
<p>Doesn't sound terrible, but it had some bad downstream implications for our email deliverability...</p>
<h2>Problem: Our Customers' "Close the Loop" Emails were being marked as spam</h2>
<p>We ran a few tests to see if email deliverability was impacted and didn't notice anything bad.  But we got an email from a customer who was seeing her "Close the Loop" emails end up in spam:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1588x394/43eac609fe/going-to-spam.png">  </p>
<p>So it was time to dig in and see what was going on.</p>
<h2>Diagnosing our deliverability problem</h2>
<p>There were two things we did to understand what might be causing the deliverability problem:</p>
<ol>
<li>
<p>We verified we had legit SPF, DMARC, and DKIM DNS records</p>
</li>
<li>
<p>We used GlockApps to test deliverability (thanks to my pal <a href="https://twitter.com/CollinYVR">@Collin</a> for the tip)</p>
</li>
</ol>
<h3>1. Verifying DNS records</h3>
<p>We used <a href="https://www.mail-tester.com/spf-dkim-check">MailTester</a> to verify our SPF and DKIM records, and <a href="https://mxtoolbox.com/dmarc.aspx">MXToolbox's DMarc Tool</a> to verify we had properly added our deliverability-related DNS records. These records help email services like Gmail know whether emails sent from your domain are legit or not.  All came back good, so we didn't have to mess around with those.</p>
<h3>2. Run deliverability test with GlockApps</h3>
<p>I'd never heard of <a href="https://glockapps.com/">GlockApps</a> before Collin suggested trying them.  It's a fantastic service.  It works by:</p>
<ol>
<li>
<p>Giving you a bunch of email addresses at different providers to send your email to.  </p>
</li>
<li>
<p>Analyzing whether those emails end up in the inbox or spam folder</p>
</li>
<li>
<p>Showing you the results</p>
</li>
<li>
<p>Giving you steps to take to fix things</p>
</li>
</ol>
<p>On the first test we ran with Glock, we sent our "Close the Loop" email to 73 GlockApps-provided email addresses at Gmail, Yahoo, Hotmail, Fastmail, GSuite, AOL, and a few other providers.  </p>
<p>Here were the high-level results:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2210x420/809475f09f/report1-annotated.png"></p>
<p>43.7% of our emails ended up in the spam folder - NOT good.</p>
<p>When we looked at the heuristics Glock ran, things didn't look <strong>too</strong> bad...</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2218x706/b76ad08837/report1-results.png"> </p>
<p>... but even so, all the emails we sent to AOL, Gmail, GSuite, and Yahoo addresses ended up in spam 😱</p>
<p>Yahoo:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2138x584/0e7a9f0e82/yahoo-annotated.png"></p>
<p>Gmail and GSuite:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2196x1144/3bccd33a21/gmail-annotated.png"></p>
<p>Aol:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2158x478/8cdb38db63/aol-annotated.png"></p>
<p>Yikes.</p>
<h2>Fixing our deliverability problem</h2>
<p>Luckily Glock gives you some ideas about how to improve deliverability.  Specifically:</p>
<ul>
<li>
<p>They show you if you're on any email blacklists</p>
</li>
<li>
<p>They analyze your email's content and tell you if there are issues you can fix </p>
</li>
<li>
<p>They provide a list of action steps you can take to improve deliverability</p>
</li>
<li>
<p>They also provided two articles - one of which included advice that moved the dial most for us! </p>
</li>
</ul>
<h3>1. Getting off email Blacklists</h3>
<p><a href="https://www.leadfuze.com/email-blacklist/">Leadfuze says</a>:</p>
<blockquote>
<p>An email Blacklist is a real-time database that uses criteria to determine if an IP is sending email it considers to be SPAM. There are several blacklists… Each list [has] a unique way of accepting inbound mail and determining if email is considered SPAM. They can all impact deliverability for your emails.</p>
</blockquote>
<p>We had ended up on two blacklists: <a href="http://www.sorbs.net/">SORBS</a> and <a href="https://www.justspam.org/">JustSpam</a>.  It's not entirely clear whether our spammer put us on either list.  That's because:</p>
<ol>
<li>
<p>We are using a shared <a href="https://www.mailgun.com/">Mailgun</a> server to send email.  Others using the same box (and therefore same IP address) would impact our sending.  Being on the same box as a spammer would impact deliverability for everybody who sent email via that IP.</p>
</li>
<li>
<p>SORBS showed multiple spam incidents, none of which seemed to be ours (which occurred on August 27 2020):</p>
</li>
</ol>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1368x1026/4a1cdc6755/sorbs-annotated.png"></p>
<p>Getting off of the SORBS blacklist required us to sign up for an account and write up a ticket explaining what happened.  I got a response quickly:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1600x864/56d66b5f4d/sorbs-response.png"></p>
<p>I was hard-pressed to come up with a good reply to that - the clear answer seemed that we should use a different IP address to send emails.</p>
<p>Getting off of JustSpam.org's list was a lot easier: one click and an hour later our server's IP was off:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2508x904/13a8b46ebb/justspam-response.png"></p>
<p>Ultimately the solution to an IP address with reputation problems is moving servers.  Not hard to do but we didn't want to try that just yet. </p>
<h3>2. Fixing our content issues</h3>
<p>We had three quick fixes here:</p>
<ol>
<li>
<p>We didn't have a TITLE tag inside our HTML email's HEAD section.  That was a quick fix.</p>
</li>
<li>
<p>We weren't including a text version of our emails alongside the HTML version, so we added that.  Google apparently regards emails with no text version as spammier than those with both text and HTML.</p>
</li>
<li>
<p>We included a "Sent with Savio" link in the email footer. I removed that just to make the email as low-risk as possible.</p>
</li>
</ol>
<h3>3. Other action steps</h3>
<p>Glock provided a list of other action steps we could take:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2262x1448/93fa1d6acb/more-action-steps.png"></p>
<p>Many seemed like they didn't apply (use fewer exclamation marks in your emails!), weren't helpful (Google Postmaster literally told us to come back later after we signed up), or would take days / weeks to test and didn't stand out as things that were likely to work.</p>
<h2>More resources (and the eventual fix!)</h2>
<p>Glock also pointed us to two other articles, one which ended up containing the secret to fixing our deliverability issue:</p>
<ol>
<li>
<p><a href="https://glockapps.com/blog/how-i-decreased-my-spam-rate/">How this guy decreased his spam rate from 35.2% to 2.8%</a>.  Spoiler: he sent emails from his spammy domain to friends, had those friends reply, and continued the conversation for a couple weeks.  Google weighs replies and engagement very highly when determining whether an email or sender is spammy.  In my work with <a href="https://www.predictablerevenue.com/">Predictable Revenue</a> I know that warming up email accounts like this is hugely important.  But since our account had already been operating for nearly two years, this didn't seem like low-hanging fruit.</p>
</li>
<li>
<p><a href="https://glockapps.com/tutorials/fix-email-deliverability/">How to Find and Fix Email Deliverability Issues</a>.  This article was gold.  It covered:</p>
<ul>
<li>email content (ours was good)</li>
<li>server config like DKIM, SPF, etc (also good)</li>
<li>IP address reputation (not great, but fixable by switching boxes)</li>
<li>and email and domain reputation (unexplored)</li>
</ul>
</li>
</ol>
<p>Seemed like it was worth exploring email and domain reputation in a little bit more depth.</p>
<h2>Testing email and Domain Reputation</h2>
<p>Glock described how to test whether email providers saw your email address as spammy:</p>
<blockquote>
<p>Use GlockApps to test different sender addresses on the same domain. Remember to keep other variables the same. If the same email (from the same IP and domain) is delivered to more Inboxes with a different sender email address, the problem could be in your old email address.  </p>
</blockquote>
<p>That seemed like a super easy experiment to run.  So we changed our sending email address from notifications@savio.io to email@savio.io.</p>
<p>Here were the results:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2076x410/f5e3fb35ef/report2-annotated.png"></p>
<p><strong>Incredibly, the percentage of emails marked as spam had dropped from 43.7% to 1.4%!</strong></p>
<p>To be fair, this test also included the fixes I mentioned above:</p>
<ul>
<li>
<p>The HTML email included a TITLE tag</p>
</li>
<li>
<p>The email also included a text version</p>
</li>
<li>
<p>I removed the "Sent with Savio" link from the email footer</p>
</li>
</ul>
<p>But my guess is that changing the sending address is the major factor that solved the spam problem.</p>
<p>Compare the two tests side by side:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2076x532/f258e9d5be/comparison-annotated.png"></p>
<h2>What next</h2>
<p>There are still a few steps we can take to ensure deliverability stays high.</p>
<ol>
<li>
<p>Think like an attacker when building features that customers can use to contact others.  Given previous businesses we worked on we really should have spotted this before it went to production.  We've now added an "Possible Exploits and Mitigation" section to our requirements document.  This is to prompt us to identify potential major exploits worth devoting dev resources to when building a new feature.</p>
</li>
<li>
<p>Move email sending to a dedicated IP address.  This would ensure we wouldn't be impacted by the spammy neighbour problem.</p>
</li>
<li>
<p>Isolate "Close the Loop" emails to a different sending subdomain.  We provide a template, but ultimately our customers write the emails that get sent on our domain.  Isolating these emails to their own subdomain would ensure that and reputation issues would not affect email sent from the rest of the app or from the email accounts we use to conduct business.     </p>
</li>
</ol>

      <p><i>Last Updated: October 1, 2020</i></p><div>
        <p><img src="https://www.savio.io/static/images/founder-headshot-kareem.png" alt="" height="150" width="150">
        </p>
        <div>
            <h4>Kareem Mayan</h4>
            <p>Kareem is a co-founder at <a href="https://www.savio.io/">Savio</a>. He's been prioritizing customer feedback professionally since 2001. He likes tea and tea snacks, and dislikes refraining from eating lots of tea snacks.</p>
        </div>
      </div>

      <form method="post" action="https://sendfox.com/form/1dze03/1y0wom" id="1y0wom" data-async="true">

      <h4>Want more articles like this?</h4>
      <p>Leaders from Slack, Zapier, and Appcues read our newsletter to delight customers, lower churn, and grow expansion revenue.</p>
      

      <!-- no botz please -->
      
      
      <p>Max 2 emails/month. Unsub anytime.</p>

      </form>
    </div></div>]]>
            </description>
            <link>https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654762</guid>
            <pubDate>Thu, 01 Oct 2020 18:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All you need to build a product is a mission]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654576">thread link</a>) | @dvt
<br/>
October 1, 2020 | http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/ | <a href="https://web.archive.org/web/*/http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

			
<article id="post-385">

	

	
			<figure>
				<img width="1568" height="1045" src="http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-1568x1045.jpg" alt="" loading="lazy" srcset="http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-1568x1045.jpg 1568w, http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-300x200.jpg 300w, http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-1024x683.jpg 1024w, http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-768x512.jpg 768w, http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-1536x1024.jpg 1536w, http://noemititarenco.com/wp-content/uploads/2020/09/mr-tt-xb0wLfZH9Zo-unsplash-2048x1365.jpg 2048w" sizes="(max-width: 1568px) 100vw, 1568px">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>One of the most common pitfalls of product development is too many ideas.</p>



<p>Some investors are dead set on how it will look. Some builders fall in love with a product philosophy. Some want to build exactly what the customer is asking for. And still others think they already know exactly what the result will be like, and they call it their vision.</p>



<p>It is difficult for a product pulled in so many directions to succeed.</p>



<p>You need less ideas anchoring the product, not more. <strong>A product must solve a problem</strong>. Everything else is a distraction.</p>



<p><strong>The mission is <em>how </em>you want to solve the problem</strong>. The mission can remain as abstract as needed, to allow for exploration and iteration.</p>



<p>The difference between the problem and the mission is that when you state your mission, you are taking a clear stance on how the problem is best solved. Providing a pathway, no matter how abstract, is inspiring.</p>



<p>Inspiration is fuel to product development. Many people think building software is a technical, precise process. This is not true. It is emotional – we build, design, and ideate better when our work nourishes us with inspiration.</p>



<p>Before you figure out your mission, you need to obsess over your problem. Here are three simple questions to ask.</p>



<h2>Questions for your problem</h2>



<ol><li><strong>Is it really a problem?</strong> Some problems appear only when people start looking for or measuring them. Take a critical look at the impact of your problem.</li><li><strong>Who is being impacted by this problem?</strong> This a trick question. Identify these people, talk to them and practice some active listening. You need to understand their story. If you have the problem, find someone else. Elevate their story above your own.</li><li><strong>What does it look like when the problem is solved?</strong> I recommend timed brainstorming for this question. Keep in mind that there is no right answer. Pay attention to how you react to each answer you come up with.</li></ol>



<p>Once you understand your problem pretty well, you will start getting ideas on how to solve it.</p>



<h2>Questions for your mission</h2>



<ol><li><strong>What are common themes in solutions or ideas that make you feel something?</strong> I recommend timed brainstorming for this – list out everything you can in a few separate 10 minute sessions.</li><li><strong>Who are you helping?</strong> What inspires us even more than solutions and ideas is people. Get specific with who you want to help.</li><li><strong>Are you trying to make it sound good? </strong>One of the best mission statements I used was grammatically clunky and a mouthful. An effective mission doesn’t need to sound poetic or balanced. It does need to be accurate and meaningful.</li></ol>



<p>It’s easy to know when a mission is polished – it motivates you. It doesn’t make you question the approach and the motivation doesn’t fade. A mission inspires even during the tiring mundane tasks needed for success.</p>



<p>Sometimes, what inspires you sounds crazy. It’s too wild, too unorthodox. Or like I said before, it doesn’t sound good grammatically. Let marketing redo a version for the public-facing product if needed. For the builders, they’re going to need the truth.</p>



<p>The mission will serve as the test during the entire building process. Every prototype, experiment and idea will be judged against the mission. Does it support the mission? Or does it distract from it?</p>



<p>Which brings me back to the beginning. The CEOs and investors who think they already have the solution don’t understand where solutions come from. Solutions are the result of a process. We can call it the creative process, we can call it experimentation, we can call it “data driven product development.” Whatever you call it, it’s the creation, testing and adjustment of solutions until your problem is solved.</p>



<p>Creativity is a dynamic process that requires boundaries to solve a problem. The mission is that boundary, gently nudging us to be critical of our own work, and energizing us to try again.</p>



<p>noemi titarenco</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				

</article><!-- #post-${ID} -->

<!-- #comments -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654576</guid>
            <pubDate>Thu, 01 Oct 2020 18:37:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a blog on Azure for $2.5 per month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654536">thread link</a>) | @fleide
<br/>
October 1, 2020 | https://www.eiden.ca/azure-static-blog/ | <a href="https://web.archive.org/web/*/https://www.eiden.ca/azure-static-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>High level picture of hosting a static site (blog) on Azure with details on how to wire a custom domain (root and www) with HTTPS support. It’s actually easier that it sounds.</p>

<!--more-->

<p>Let’s start by noting that $2 out of the $2.5 mentioned in the title are for the custom domain name and associated SSL certificate (for HTTPS). Static content hosting, CDN (<a href="https://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a>) and networking in Azure cost less than 50 cents per month for this application. To be fair, this is not the most read blog of the Internet.</p>

<p>Also I’m using <a href="https://jekyllrb.com/">Jekyll</a> for this blog, and it’s been good to me so far.</p>

<h2 id="summary">Summary</h2>

<p>The main components used are:</p>

<ul>
  <li>From non-Microsoft providers
    <ul>
      <li>a <strong>custom domain name</strong> from a registrar of our choosing (I’m using <a href="https://www.gandi.net/en-CA">Gandi</a>) - here <code>eiden.ca</code></li>
      <li>a <strong>SSL certificate</strong> to enable HTTPS, I recommend Namecheap (<a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">PositiveSSL</a>) to procure one. This certificate will need to be generated for the custom domain name we created above (we’ll see how). <strong>THIS IS IF</strong> you want HTTPS for the <strong>root</strong> of the custom domain (<a href="https://eiden.ca/">https://eiden.ca</a>), even if you just want it to redirect to <strong>www</strong>. This was a must have for me, and the reason for the existence of this very article. If you don’t care about the root, you can use the <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-custom-ssl?tabs=option-1-default-enable-https-with-a-cdn-managed-certificate">managed certificate included</a> in Azure CDN (which at the time of writing doesn’t support root).</li>
    </ul>
  </li>
  <li>In Azure
    <ul>
      <li>a <strong>Storage Account</strong> with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website">static web hosting</a> enabled. That feature allows to serve static content (html, css, javascript, images) directly from a container</li>
      <li>a <strong>Key Vault</strong> to help generate the certificate and store it once issued by the provider</li>
      <li>a <strong>CDN Profile</strong>, to cache the content and optimize performance and cost. The CDN profile loads our content from the storage account, distributes in its worldwide network, and serves to visitors in a scalable fashion automatically</li>
      <li>a <strong>DNS Zone</strong>, to manage the name resolution of our custom domain and point the traffic towards the CDN profile</li>
    </ul>
  </li>
</ul>

<p>On a picture:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, all details will be explained below in this post"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 1 : Schema of the solution</a></em></p>

<p>Let’s jump into it.</p>

<h2 id="step-1-and-2--starting-with-the-static-website-and-the-cdn-profile">Step 1 and 2 : Starting with the Static Website and the CDN Profile</h2>

<p>First we will follow the <strong>parts 1 and 2</strong> from this <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">awesome tutorial</a> from John M. Wright to get the storage account and CDN profile set up. <strong>Let’s not go further than part 2</strong>, we’ll switch to another guide for the following step.</p>

<p>In part 2, I’ve personally used the <code>Azure CDN from Microsoft</code> and it went great.</p>

<p>At this point, what we should have is this:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png" alt="Step 1 : a storage account with static hosting and a CDN endpoint"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png">figure 2 : a storage account with static hosting and a CDN endpoint</a></em></p>

<p>We can already see our content online at the following URLs:</p>

<ul>
  <li><code>https://&lt;sa&gt;.web.core.windows.net</code>, directly from the storage account</li>
  <li><code>https://&lt;cdn&gt;.azureedge.net</code>, from the CDN endpoint</li>
</ul>

<p>To be noted that to upload our content to the <code>$web</code> container of the storage account, the best option is to use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">Azure Storage Explorer</a>. I tend to default on PowerShell but here <code>Set-AzStorageBlobContent</code> doesn’t manage the content-types of the files it uploads.</p>

<p>The syntax in the CLI is straightforward (in a PowerShell host, cmd or bash terminal) :</p>

<pre><code># Here the parameter syntax is PowerShell and I'm already logged in the CLI via az login
$contentLocalPath = "C:\..."
$storageAccountName = "mystorageaccount"
az storage blob upload-batch -s $contentLocalPath -d '$web' --account-name $storageAccountName
</code></pre>

<h2 id="step-3--adding-a-dns-zone">Step 3 : Adding a DNS Zone</h2>

<p>To add the DNS Zone, let’s switch to the <strong>part 3</strong> of this <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-3-set-up-dns-configuration">exhaustive guide</a> from Rune Aamodt.</p>

<p>Here we will <strong>not only</strong> create a record for the <strong>www subdomain</strong> (type <code>CNAME</code>, alias record set to the CDN endpoint) like in the guide, but also for the <strong>root (apex) domain</strong> (type <code>A</code>, alias record set to the same CDN endpoint).</p>

<p>This is how it should look now (<strong>bold</strong> being the ones we created above):</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>TTL</th>
      <th>Value</th>
      <th>Alias resource type</th>
      <th>Alias target</th>
      <th>Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>@</strong></td>
      <td><strong>A</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>Root/apex domain record</strong></td>
    </tr>
    <tr>
      <td>@</td>
      <td>NS</td>
      <td>172800</td>
      <td>ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>SOA</td>
      <td>3600</td>
      <td>Email:… Host: ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>MX</td>
      <td>3600</td>
      <td>10 spool.mail.gandi.net.,50 fb.mail.gandi.net.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>@</td>
      <td>TXT</td>
      <td>3600</td>
      <td>“v=spf1 include:_mailcust.gandi…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>cdnverify</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
    <tr>
      <td>sa</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>external.simpleanalytics.com.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Record required by the analytics provider I use here</td>
    </tr>
    <tr>
      <td><strong>www</strong></td>
      <td><strong>CNAME</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>www subdomain record</strong></td>
    </tr>
    <tr>
      <td>cdnverify.www</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
  </tbody>
</table>

<p>This is where we will have to log in to the admin portal of our Domain Registrar (Gandi for me) to switch our custom domain to use <strong>external nameservers</strong>. We will provide the 4 Azure ones listed in our DNS zone.</p>

<p>This can be a frustrating step since making changes to DNS records can take hours to take effect. Let’s try and be patient…</p>

<p>On <strong>Gandi</strong> it looks like this:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg" alt="Step 3 : Screenshot of the admin portal in Gandi"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg">figure 3 : updating nameservers in Gandi</a></em></p>

<p>Now that we have the DNS Zone setup, the situation looks like that:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png" alt="Step 3 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png">figure 4 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated</a></em></p>

<p>Now let’s head back to the CDN endpoint to add the custom domains we just created here.</p>

<h2 id="step-4--enabling-https-for-the-cdn-endpoint-custom-domains">Step 4 : Enabling HTTPS for the CDN Endpoint Custom Domains</h2>

<p>We will head back to the first tutorial, but <strong>before let’s quickly sum up the situation</strong>. As I mentioned in the summary, Azure CDN offers managed certificate for HTTPS, but at the time of writing they are not available for the root / apex domain.</p>

<p>This is why we need to bring our own certificate.</p>

<p>Before heading back into the tutorial, let’s review the 3 high level steps of that process:</p>

<ol>
  <li>In an Azure Key Vault, we will create a new certificate that will be issued by a <strong>non-integrated</strong> CA (Namecheap). <strong>Contrary</strong> to what’s in the guide, use <strong>PKCS#12</strong> (even if we don’t understand the details, it’s just easier)</li>
  <li>We will then download the CSR (<code>Certificate Signing Request</code>) from Azure Key Vault, upload it to our SSL certificate provider to get processed, get the PKCS#12 file generated there back into Azure Key Vault (<code>merge signed request</code>)</li>
  <li>Back in the CDN Endpoint, we will create the custom domains (root and www), with HTTPS, using our own certificate hosted in Key Vault</li>
</ol>

<p>So let’s head back to <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">the tutorial</a> from John for <strong>part 4 and 5</strong> (sorry there’s no direct links) that explains everything in details.</p>

<h2 id="step-5--adding-cdn-rules">Step 5 : Adding CDN rules</h2>

<p>Finally, we need to add some rules in the CDN Rules engine to sort traffic coming from the root and subdomain on both HTTP and HTTPS. I wanted everything to end on <code>https://www.eiden.ca</code>, but you can adapt the rules below for a different result:</p>

<ul>
  <li>Rule 1 : <code>http://</code> requests need to be redirect to <code>https://www...</code></li>
  <li>Rule 2 : root requests need to be redirected to <code>https://www...</code></li>
</ul>

<p>For that we can get inspiration from the <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-5-enforce-https">step 5</a> of the second guide to get something looking like that:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg" alt="Step 5 : Screenshot of the CDN endpoint rules engine configuration, details below"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg">figure 5 : Rules to manage traffic across domains and protocols</a></em></p>

<p>The details of these rules:</p>

<ul>
  <li>Rule 1
    <ul>
      <li>Name : <strong>http2https</strong></li>
      <li>If Request <strong>protocol</strong>
        <ul>
          <li>Operator : <code>Equals</code></li>
          <li>Request URL : <code>HTTP</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Rule 2
    <ul>
      <li>Name : <strong>root2www</strong></li>
      <li>If Request <strong>URL</strong>
        <ul>
          <li>Operator : <code>Begins with</code></li>
          <li>Request URL : <code>https://eiden.ca</code></li>
          <li>Case transform : <code>To lowercase</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>The picture is now complete:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, everything has been explained above"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 6 : The whole thing wired up together</a></em></p>

<h2 id="step-6--flushing-the-cdn-profile">Step 6 : Flushing the CDN profile</h2>

<p>As discussed earlier, the CDN caches our files to serve them in an optimal fashion. Like any cache, it will need to be expired and reloaded when new content is uploaded to the storage account. This is not done automatically.</p>

<p>In the Azure CDN world, this operation is called a <strong>purge</strong>. It can be done in <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-purge-endpoint">the Azure portal</a> or via script.</p>

<p>In my case I’m using the <a href="https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az?view=azps-4.7.0">PowerShell Az module</a> (not to be mistaken with the AzureRM module) to do that every time I publish a new article:</p>

<pre><code># Already logged via Connect-AzAccount

$cdnProfileName = "eiden-ca"

Get-AzCdnProfile `
  | Where-Object {$_.Name -eq $cdnProfileName} `
  | Get-AzCdnEndpoint `
  | Unpublish-AzCdnEndpointContent -PurgeContent "/*"

</code></pre>

<h2 id="closing">Closing</h2>

<p>So really, $2.5 per month?</p>

<ul>
  <li><a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">Namecheap</a> SSL Certificate : $9 per year</li>
  <li><a href="https://www.gandi.net/en-CA">Gandi</a> custom domain (<code>.ca</code>) : $15 per year</li>
  <li>Everything <a href="https://azure.microsoft.com/en-us/free/">Azure</a> : $.5 per month</li>
</ul>

<p><strong>Total : $2.5 per month!</strong></p>

      </article></div>]]>
            </description>
            <link>https://www.eiden.ca/azure-static-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654536</guid>
            <pubDate>Thu, 01 Oct 2020 18:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an open source business]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654427">thread link</a>) | @mattgreg
<br/>
October 1, 2020 | https://www.ockam.io/learn/blog/zero_ipo/ | <a href="https://web.archive.org/web/*/https://www.ockam.io/learn/blog/zero_ipo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s Zero-to-IPO map is a key strategy input to our tactical short, medium and long-term business planning. It focuses on the one-thing that <em>really</em> matters, at specific points in time. We live our values at Ockam, and as an open source company, we want to share our roadmap.</p><p font-family="body" font-weight="body" font-size="body" color="text">As outlined in the progression below, we’ve plotted a course from stoking awareness to operating an enterprise sales machine.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" alt="Zero to IPO map" title="Zero to IPO map" srcset="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a2ead/map.png 259w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/6b9fd/map.png 518w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png 1035w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/44d59/map.png 1553w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a6d66/map.png 2070w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png 3652w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The time scale for our route to IPO is, as you’d expect, years long. Given that startups plan around funding cycles, let’s plot funding cycles as waypoints on our course. It can generally be assumed that there is 18-24 months between these waypoints.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" alt="Funding time scale" title="Funding time scale" srcset="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a2ead/funding.png 259w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/6b9fd/funding.png 518w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png 1035w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/44d59/funding.png 1553w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a6d66/funding.png 2070w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png 3660w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The cloud, edge, and open source landscape continues to evolve - which means that we need to chart our own course into the future. However, Ockam’s route to IPO also considers the various ways that other companies have run the gauntlet from Zero-to-IPO. I’ve been fortunate to have been ‘in the rooms where it happened’. Over the past 10 years I’ve directly worked with well over 100 companies that were underpinned by open source software projects. I’ve seen spectacular successes, breathtaking failures, modest acquisitions, and some companies that simply fade into the darkness. I'll save those stories for another time, maybe over a beer.</p><p font-family="body" font-weight="body" font-size="body" color="text">In the image below are experiences that I’ve drawn from the previous decade in the open source, cloud, and developer tool space.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" alt="Rooms where it happened" title="Rooms where it happened" srcset="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a2ead/rooms.png 259w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/6b9fd/rooms.png 518w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png 1035w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/44d59/rooms.png 1553w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a6d66/rooms.png 2070w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png 3724w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">Let’s dive into each stage, in turn, to unpack what we are doing, when we are doing it, and how we are going to measure it.</p><h2 id="motion" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">In order to recruit our team, or for a developer to consider using Ockam, first they have to know we exist. We create and distribute a tremendous amount of content at Ockam with one goal - driving developer awareness.</p><p font-family="body" font-weight="body" font-size="body" color="text">For example, The first product Ockam shipped was <a href="https://www.ockam.io/learn/guides/team/values_and_virtues_on_the_Ockam_Team/">a blog on our Values</a>. The second was a white paper that shared our vision. Even this post is an example!  We have a learning library that outlines our thesis on the open source ecosystem, teaches computer science fundamentals, gives insights into our team culture, and demonstrates our technology. We’ve sat down for dozens of podcasts and interviews over the past two years. Ockam’s content is based around teaching. Being an effective listener and a great teacher are core underpinnings when building an open source community.</p><h2 id="metrics" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">To gauge awareness we track activity including page views on ockam.io, 'contact us' webform inquiries, GitHub stars, social media mentions, followers and, most importantly, applications to join our team.</p><h2 id="motion-1" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a critically important step in our progression to IPO. Building Ockam's community is a never-ending endeavor. It takes years of focus and unrelenting attention to get this step right. For example, Kafka spent it's first 5 years in this phase as an Apache project before Confluent was started.</p><p font-family="body" font-weight="body" font-size="body" color="text">We have three code interfaces to Ockam, which means that there are three different personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Application layer developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s users build systems and applications with our simple APIs, OckamD binary downloads, and hosted cloud services.</p><p font-family="body" font-weight="body" font-size="body" color="text">To simplify what’s going on at this stage, we create packages that any developer can grab in the middle of the night, on the other side of the world, and get a quick win for their demo day at work. You’ve got a job to be done, and we’ve got a simple solution for you. You can get it right now and we will measure your time to a technical-win in the scale of minutes.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Partners</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Community partners build add-ons, connectors, and plug-ins to connect Ockam to other codebases, cloud services and hardware components. Examples include InfluxData, Confluent - Kafka, Microchip, NXP, MacOS, and Microsoft Azure.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Open source developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s open source builders are engaged in development of Ockam's core codebase. They attend our monthly community meetings, and are hands-on with our OSS codebase on GitHub. Their participation ranges from updating a typo in documentation, to building complex features.</p><h2 id="metrics-1" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">We track Monthly Active Users across all three personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text">Binary downloads, account signups, or SaaS service IOPS are all indicators of usage. As hinted above, time to ‘technical win’, for an individual developer is also paramount. We’ve defined time to ‘technical win’ as the time it takes to go from an individual developer’s initial discovery to a working prototype that includes Ockam features.</p><p font-family="body" font-weight="body" font-size="body" color="text">The easiest user growth to track is the number of partner integrations. Since partners engage with us 1:1 on an integration, we are highly selective and deliberate about the partnerships that we support. Eventually the development of our technical partnerships will become programmatic. Programmatic examples from my past include the partner program for Heroku Add-ons and the Azure Marketplace partner portal.</p><p font-family="body" font-weight="body" font-size="body" color="text">We also track the intersection of partnerships and usage. For example, the number of Ockam Daemons that run alongside Influx Telegraf, or the number of IOPS in Ockam Routers that securely move packets to a Kafka Connector.</p><p font-family="body" font-weight="body" font-size="body" color="text">Finally open source activity and engagement is transparent through the tools in GitHub. Check out <a href="https://github.com/ockam-network">how we are doing</a> with stars, forks and commits.</p><h2 id="motion-2" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a really fun stage for a product-and-pricing-nut like me. By this point in our journey we have users, but not customers. To satisfy investor expectations and to further fund product development, we start to feed our product development machine with revenue.</p><p font-family="body" font-weight="body" font-size="body" color="text">This stage is far simpler than it’s often made out to be. Here’s my basic formula;</p><ul><li>If you are an individual developer, then Ockam is free.</li><li>If you are a commercial enterprise, but have not yet had a ‘technical win’ with Ockam, then Ockam is free.</li><li>If you are a commercial enterprise, and have had a ‘technical win’ with Ockam, then you pay.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">From here things get a bit more complicated. Services need to be packaged and priced. This, in my opinion, is the most challenging, but also the most fun part of product development. The classic product marketing mix (aka the 4P’s) framework is durable and applies for Ockam’s planned product offerings. In this phase we are packaging <strong>P</strong>roducts (say S, M, L sizes), establishing a <strong>P</strong>rice for each product, <strong>P</strong>romoting the product through rigorous segmentation and targeting, and <strong>P</strong>lacing it into various channels and partner marketplaces for distribution.</p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s SaaS products will have a freemium pricing and packaging structure. It’s worth calling out that freemium is not a pricing strategy. It’s a customer acquisition tactic that aligns with the formula above.</p><h2 id="metrics-2" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Monthly Recurring Revenue (MRR) is the top line / key metric during this phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">The free-to-paid funnel is another key metric since it is a leading indicator and helps to forecast MRR. We will track both conversion and velocity of our freemium SaaS users.</p><p font-family="body" font-weight="body" font-size="body" color="text">The metrics we track in the Self-Serve SaaS phase allow us to A/B test in our demand generation funnel. A/B testing allows us to optimize month-over-month revenue growth.  The target is 10-15% MoM growth.</p><h2 id="motion-3" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Inside Sales is a channel strategy for specific types of large customers we already have. This is mainly a cultivate-and-grow tactic. Our bottoms-up, Self Serve SaaS product model feeds leads to our Inside Sales Team. This team is technical, includes sales engineers and provides world-class support.</p><p font-family="body" font-weight="body" font-size="body" color="text">There are two separate objectives during this phase.</p><ul><li>Increase MRR through an increase in our customer base, and in the average ticket size.</li><li>Learn about Customer Acquisition Costs (CAC) for specific segments, prior to launching the Enterprise Sales phase.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">Monthly recurring revenue is still our top priority during the Inside Sales phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">What’s less obvious is the second objective. Understanding CAC prepares us for an all-in Enterprise Sales motion. Moving from here onto the Enterprise Sales waypoint is probably the most challenging. It’s fraught with peril. Many, many smart companies, with great products, and ‘developer love’ die right here.</p><p font-family="body" font-weight="body" font-size="body" color="text">How can that be? It’s because Inside Sales is bottoms-up and Enterprise Sales is tops-down. This means entirely new buyers, new product-marketing mix, and new internal talent. We must hold onto our developer roots, while we also learn to sell to the suits. While we are executing on Inside Sales we are doing the primary research that will help spawn a new company from our company.</p><p font-family="body" font-weight="body" font-size="body" color="text">This is fantastically difficult - mostly from a cultural standpoint. Fortunately there are a lot of people with a lot of scar tissue from the past 10 years - including myself - and we will push through. The key is patience. We need to use our inside sales motion to find specific beachheads to land our Enterprise Sales motion.</p><h2 id="metrics-3" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">MRR carries over as our key metric from the Self Serve SaaS phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">CAC analysis for multiple customer segments.</p><h2 id="anti-metrics" color="heading" font-family="heading" font-weight="heading">Anti-Metrics<a href="#anti-metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">There will be noise in our Inside Sales data!</p><p font-family="body" font-weight="body" font-size="body" color="text">The noise is any sale that looks like it could be Enterprise Sales. Up to this point, non-recurring engineering (NRE) and enterprise-like sales don’t count as Enterprise Sales, as we define the term in the next section. Typically they are one-off deals because the motion to win these deals isn’t scalable. We will do large custom deals to gain access to smart teams that deploy interesting technology. I prefer to categorize this class of revenue as ‘business development’ or even R&amp;D.</p><p font-family="body" font-weight="body" font-size="body" color="text">Why is this an anti-metric? Because other Open Source startups typically stand up a couple one-off enterprises like sales as a way to puff themselves up and to convince themselves that they are ready to move to the next phase. I strongly caution my future self to parse the noise from the signal prior to launching Enterprise Sales.</p><p font-family="body" font-weight="body" font-size="body" color="text">Furthermore, there are other Open Source companies that entirely bypass the Self Serve SaaS phase in favor of the chunky revenue that comes with Enterprise Sales. Those companies tend not to be product companies. They become …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ockam.io/learn/blog/zero_ipo/">https://www.ockam.io/learn/blog/zero_ipo/</a></em></p>]]>
            </description>
            <link>https://www.ockam.io/learn/blog/zero_ipo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654427</guid>
            <pubDate>Thu, 01 Oct 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video encoded neck scarves of New York City neighborhoods]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654352">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://thebrooklynblock.com/collections/all | <a href="https://web.archive.org/web/*/https://thebrooklynblock.com/collections/all">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
  

  

  <div>
    
      <ul>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
      </ul>
    

    
    <p role="contentinfo">Copyright © 
      2020
     The Brooklyn Block.</p>
  </div>

</div></div>]]>
            </description>
            <link>https://thebrooklynblock.com/collections/all</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654352</guid>
            <pubDate>Thu, 01 Oct 2020 18:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short-form podcasts are the future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654292">thread link</a>) | @dazzn
<br/>
October 1, 2020 | https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/ | <a href="https://web.archive.org/web/*/https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-149">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p> Long story short, after coronavirus made me come back from the Los Angeles part of my March&nbsp;<a href="https://martinsthoughts.com/how-i-almost-become-an-importer/">business trip</a>&nbsp;early and importing was out of the question, I decided to start a podcasting company.</p>



<p>By myself, with my $150 Blue Yeti mic. Not much, but certainly enough to get started – or so I thought.</p>



<p>During the first recording session, I realized there’s one big problem: I sound terrible. Proper intonation and voice acting were more difficult than I expected.</p>



<p>I’ve spent 3 weeks trying to get it to an acceptable level – speaking faster, slower, louder, quieter, with more pauses, with fewer pauses… it just wasn’t there. Not being a native English speaker didn’t help, either.</p>



<p>So eventually there was no podcasting company.</p>



<p>But when figuring things out, I came to something that can be a big trend in the coming years: short-form podcasts.</p>



<p>When writing a script for the first episode that was meant to be about 20 minutes long, I found it pretty time-consuming.</p>



<p>Considering I wanted to start multiple podcasts, releasing at least 1 episode a week for each of them, it wasn’t possible to spend that much time just writing.</p>



<p>The solution proved to be very simple: why not just make the episodes shorter?</p>



<p>Instead of producing 1 20-minute episode, I’d produce 3 7-minute episodes. That meant 3 weeks’ worth of content instead of 1 week’s worth of content.</p>



<p>I needed some rationale to potentially explain why the heck are all podcasts so short. After some research, it started to make even more sense than I expected.</p>



<p>First, Edison Research&nbsp;<a href="https://medium.com/s/story/podcastings-next-frontier-a-manifesto-for-growth-7e8b88d32fde">found out in 2018</a>&nbsp;that 50% of people not listening to podcasts don’t listen&nbsp;<a href="https://miro.medium.com/max/875/0%2ApLy2M94ZPgs6wCm9">because they’re too long</a>.</p>



<p>Second, the video &amp; audio analytics platform Pex&nbsp;<a href="https://twitter.com/Pex/status/1262924202870337536">tweeted</a>&nbsp;the average length of a podcast episode fell from 45:44 in 2015 to 35:27 in 2020. The trend of shrinking episode length is there.</p>



<p>Third, the idea of short-form content is already getting a lot of attention, although in a different field – it’s Quibi with $1.75 billion raised to produce short-form mobile-only TV series.</p>



<p>Fourth, there already are some successful short-form podcasts like&nbsp;<a href="https://chartable.com/podcasts/six-minutes">Six Minutes</a>, so it isn’t completely uncharted territory.</p>



<p>The decision was made: I’m going to start the first short-form podcasting company. All podcasts will be 10 minutes or less.</p>



<p>I was aware my podcasts won’t be anywhere near the best ones quality-wise, and I wanted to build the company to sell it, just like Gimlet did.</p>



<p>So I needed something more.</p>



<p>I needed to create and represent the short-form podcasting movement.</p>



<p>One of the reasons companies are acquired is that they provide the acquirer access to a new (sub-) industry. If I started a regular podcasting company, I would have to be too freaking good to stand out among tons of others.</p>



<p>By being a short-form podcasting company, I wanted to create a league of my own.&nbsp;</p>



<p>Sometimes the positions of brands are so strong not necessarily because their product or service is the best, but because they were the first, good, and fast enough to make their brand represent their niche.</p>



<p>That means I’d focus almost as much on promoting and associating my company with short-form podcasts as on the podcasts themselves.</p>



<p>Who knows, maybe it would have worked.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654292</guid>
            <pubDate>Thu, 01 Oct 2020 18:15:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biopharma Startup Funding Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654255">thread link</a>) | @aaavl2821
<br/>
October 1, 2020 | https://www.baybridgebio.com/startup_database.html | <a href="https://web.archive.org/web/*/https://www.baybridgebio.com/startup_database.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <nav>
    

    
</nav></header>

 <section>
    <div>
      
      
      <p>This dashboard covers biopharma VC, IPO and M&amp;A trends.  Explore more of our data <a href="https://www.baybridgebio.com/biotech-screener.html">here</a>.</p>
      <br>
      <h2>Biopharma venture funding over time</h2>
        <p>
        <span id="startup-dashboard-loading"><h3>Loading...</h3></span></p>
      <br>
      <h2>2019 topline data</h2>
      <div>
          <div>
              <div>
                  <h3>VC funding, 2019</h3>
                  <p>
                      <h2>$<span id="vc-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="vc-updated-date">March 2019</span></p>
              </div>
          </div>
          <div>
              <div>
                  <h3>IPO proceeds, 2019</h3>
                  <p>
                      <h2>$<span id="ipo-proceeds-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="ipo-updated-date">March 2019</span></p>
              </div>
          </div>
          <div>
              <div>
                  <h3>M&amp;A total consideration, 2019</h3>
                  <p>
                      <h2>$<span id="ma-total-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="ma-updated-date">March 2019</span></p>
              </div>
          </div>
      </div>
      <p>The database is updated several times per month.  We periodically publish deep dives on <a href="https://www.baybridgebio.com/blog/ipo_2018_q12019.html">startup valuation</a>, <a href="https://www.baybridgebio.com/blog/venture_returns_ipo.html">venture returns</a>, <a href="https://www.baybridgebio.com/blog/jan_2019_funding.html">funding trends</a> and more on our <a href="https://www.baybridgebio.com/blog.html">blog</a>.  Sign up for our newsletter to receive updates.</p>
      
      <div>
        <h2>2020 on pace to be biggest year ever for biopharma venture investing</h2>
        
      </div>
      <div>
        <h2>Venture round sizes increasing</h2>
        <div>
          <div>
            <p>Most Series A rounds are between $10-60M, but there is a long tail of "megarounds" of $100M or more.  Since 2018, Series A sizes have been increasing.  Thus far in 2020, 75% of Series A deals have been greater than $30M.</p>
            <p>Series B and C rounds have been increasing as well.  Series B and C megarounds of $100M or more are increasingly common.  31% of Series B rounds and 38% of Series C rounds in 2020 have been over $100M, compared to 10% for Series B and 26% for Series C in 2018.</p>
            <p>The average post-money valuation of Series A companies is $79M.  More info on venture-stage valuations <a href="https://www.baybridgebio.com/blog/ipo_2018_q12019.html">here</a>.</p>
          </div>
          
        </div>
        
        
      </div>
      <div>
          <div>
              <h3>Valuations of 250+ biopharma VC rounds</h3>
              <p>Access detailed financial profiles of 100+ biopharma startups that went public in 2018 through 1H 2020, including estimated private-round valuations.</p>
          </div>
          
      </div>
      <div>
        <h2>US-based biotech VCs and crossover investors dominate</h2>
        <div>
          <div>
            <p>US-based specialist biotech VCs dominate biotech venture, especially at the Series A stage.  Due to 2020's active IPO market, crossover investors (investors who participate in late-stage private rounds as well as IPOs) have become increasingly active.</p>
            <p>Generalist tech VCs have increased their investment levels to that of pharma corporate VCs, but they still make up a small amount of overall funding.</p>
            <p>In 2018, Chinese investors were the biggest leaders of Series B investments into US biopharma companies.  Due to recent trade tensions between the US and China, but in 2019 Chinese investors led nearly zero deals (although they did participate as non-lead investors).  More on that <a href="https://www.baybridgebio.com/blog/chinese_investment_down_1h2019.html">here</a>.</p>
          </div>
        </div>
        <div>
          <h3>Lead investors by type, all rounds</h3>
          
        </div>
        <div>
          <h3>Lead investors by type, Series A</h3>
          
        </div>
        <div>
          <h3>Lead investors by type, Series B</h3>
          
        </div>
        </div>
      <div>
        <h2>Few active lead investors</h2>
        <div>
          <div>
            <p>The most active VCs generally only lead a handful of deals per year.  Many of these Series A investors create many of the companies they fund in-house.</p>
            <p>These investors are generating outsized returns.  Series A investments in companies that IPO <b>return an average of 10.8x</b>, with on average 3.5 years from Series A to IPO.  More on returns <a href="https://www.baybridgebio.com/blog/venture_returns_ipo.html">here</a>.</p>
          </div>
        </div>
        <div>
          <h3>Most active lead investors, all stages</h3>
          
        </div>
        <div>
          <h3>Most active lead investors, Series A</h3>
          
        </div>
        <div>
          <h3>Most active lead investors, Series B</h3>
          
        </div>
      </div>
      <div>
        <h2>Oncology and rare disease declining, neuro and autoimmune rising</h2>
        <div>
          <div>
            <p>Oncology represents about a quarter of venture-funded programs from 2018-2019</p>
            <p>While rare disease has historically received the second-most funding after oncology, neuro + neurodegenerative programs now receive more Series A funding than rare disease</p>
            <p>These charts represent the therapeutic areas of all companies receiving funding.  Many companies have programs in multiple therapeutic areas</p>
          </div>
          
        </div>
        
        <div>
          <div>
            <p>Series A investment trends can inform what kinds of companies will get funded in future rounds</p>
            <p>Oncology makes up a lower percentage of Series A-funded programs than rare disease, autoimmune and neuro combined, though oncology is still the single most funded therapeutic area</p>
          </div>
          
        </div>
      </div>
      <div>
        <h2>2020 on pace to be record year for VC-backed biopharma IPOs</h2>
        <p>2020 is on pace to be a record year for VC-backed biopharma IPOs in terms of proceeds raised.</p>
        
        
      </div>
      <div>
        
        <p><a href="https://goo.gl/forms/kHRFwxfXidRVZsDf1">Sign up</a> for our newsletter for periodic updates and analyses on biopharma VC trends.</p>
        <p>Do you have questions about our data?  Are there other analyses you'd like to see?  <a href="https://baybridgebio-report.herokuapp.com/contact">Contact us</a>, or chat with us here if we're available (you'll see an icon on the bottom-right of the screen).</p>
        <p>Our database contains additional detailed data on startups, IPOs and M&amp;A activity.  Explore our database <a href="https://www.baybridgebio.com/biotech-screener.html">here</a>.</p>
      </div>
    </div>
  </section>
  
  <!--Start of Tawk.to Script-->
      
    <!--End of Tawk.to Script-->
    
    


</div>]]>
            </description>
            <link>https://www.baybridgebio.com/startup_database.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654255</guid>
            <pubDate>Thu, 01 Oct 2020 18:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the difference between Docker and a Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654229">thread link</a>) | @championshuttle
<br/>
October 1, 2020 | https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>While in principle they are very similar, it might be more common to know about Virtual Machines than Docker Containers. Virtual Machines are like Inception, but with computers; you’re running another computer inside your computer. A usual use-case for this setup that’s applicable even to people not working in tech, is for example, you have a Windows machine (your Host OS) and you want to somehow have Ubuntu (your Guest OS) just to test a software that only runs on Linux machines. You just want to quickly try it out, so you don’t want to go through the process of installing another OS in your system (dual booting).</p>
<p><span>
      <a href="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Running an Ubuntu session using VirtualBox" title="Running an Ubuntu session using VirtualBox" src="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg" srcset="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/7237a/ubuntu-vm.jpg 148w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/0cfdf/ubuntu-vm.jpg 295w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg 590w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Now let’s discuss the underlying technology a bit. A virtual machine is a system which emulates a computer system. It has its own CPU, memory, hard disk, network and other hardware resources which are managed by a ‘virtualization layer’. This layer then translates these requests to the physical hardware (host computer).</p>
<p>If you have tried running a VM in your machine, you know how your machine started heating up. This whole process is resource-intensive, because hey, you’re practically running a full version of another machine! That’s definitely something you won’t do when you want to solve a bigger use-case that requires this setup.</p>
<p><span>
      <a href="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Virtual Machine Simple Architecture" title="Virtual Machine Simple Architecture" src="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" srcset="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/00d96/vm-architecture.png 148w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/0b23c/vm-architecture.png 295w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>What if my colleagues also want to try that software? Do they also have to install the same heavy thing on their system? What if their hardware can’t handle it?</p>
<p>That’s where Docker comes in. It’s like milk, but the leanest version with the least amount of fat that you can find (sort of).</p>
<p>With Docker, you can run applications on your host operating system (e.g. Windows), in what is called a Container. A container is almost similar to an operating system minus the graphical user interface (the stuff you can click). It technically functions just like running a session on a VM, but here’s the magic: unlike in a VM where you have to run a session of an entire OS to use an application, with Docker, you are able to run the application in light-weight containers AND control it from the host OS. The part where you see another OS running? The part where you turn on Ubuntu on your VM Manager that you installed on your Windows machine? That part has been scrapped, making the whole setup way lighter. Instead, you just write some commands on the command line and you go directly into running your application.</p>
<p><em>Whuuuut?</em></p>
<p>Let’s try to visualize that with this image, compared to our previous one.</p>
<p><span>
      <a href="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker vs VM Visualized" title="Docker vs VM Visualized" src="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png" srcset="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/00d96/docker-vm.png 148w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/0b23c/docker-vm.png 295w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png 590w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The game-changing advantage of Docker is that it allows you to package any software with all of its dependencies into a single standardized unit called image.</p>
<p>Virtual machines run on a host OS and make guest OS available inside each VM, each OS needs to be booted individually. On the other hand, Docker containers are hosted on a single docker engine on a host OS. All the containers share the docker instance. Sharing the engine between containers makes them light and decreases the boot time. While Docker Containers boot in a few seconds, VMs take a few minutes to boot. </p>
<p><span>
      <a href="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker Architecture" title="Docker Architecture" src="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" srcset="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/00d96/docker-architecture.png 148w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/0b23c/docker-architecture.png 295w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>Now that we have that background, let’s take a look at some real examples of how these can be applied:</p>
<p><strong>Virtual machine</strong></p>
<p>You have a Windows machine and want to try out GIMP on Ubuntu. Here’s how the process will look like:</p>
<ol>
<li>Install an Ubuntu VM on a Windows machine</li>
<li>Go inside the VM window and operate Ubuntu</li>
<li>Install GIMP there and use it.</li>
</ol>
<p>The host OS (Windows) is totally unaware of what is being done inside VM (Ubuntu).</p>
<p><strong>Docker</strong></p>
<p>You use Wordpress.com and discovered that there is an open source version of it that you can run yourself, so you want to test it out on your own computer first. Now, setting up a Wordpress site has dependencies, that is, your system needs to have Apache, MySQL database and PHP installed.</p>
<p>Using Docker, here’s how the process will look like.</p>
<ol>
<li>Create a container using a <a href="https://hub.docker.com/_/wordpress">Wordpress image</a>. We’re able to jump directly to this step because the Wordpress image has already been packaged by the Docker community. It contains all the dependencies needed to run Wordpress.</li>
<li>Run Wordpress on your browser!</li>
</ol>
<p>In a nutshell, Docker containers support OS virtualization, and VM supports hardware virtualization.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654229</guid>
            <pubDate>Thu, 01 Oct 2020 18:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Lessons I Needed to Learn First Hand (But Maybe You Don’t)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654192">thread link</a>) | @jlrubin
<br/>
October 1, 2020 | http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/ | <a href="https://web.archive.org/web/*/http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1586">
		<!-- .entry-header -->

	
	<div>
		
<p>When I stepped down as CEO in 2018, I wrote a post mortem and shared it privately with founder friends who directly asked <a rel="noreferrer noopener" href="http://www.nancyhua.com/2020/01/06/2019-2020-post-pre-mortems/" target="_blank">when I blogged here</a>. The company got acquired in 2019 and now I’m sharing the post mortem publicly because readers told me they saw novel concepts in my document they hadn’t heard elsewhere (as I write this I wonder if it’s because I was wrong. LMK!). </p>



<p>I used to abhor failure, but publicly releasing this post mortem no longer holds charge for me. Through Apptimize, I’ve learned and changed such that my subsequent companies will be very different. One of my biggest learnings is that I’d played a finite game and missed <a rel="noreferrer noopener" href="https://youtu.be/3QyurhNwk14?t=56" target="_blank">the infinite game</a>. I didn’t know those concepts at the time and saw “product innovation” as a separate category of work. After shifting my reference frame, I now know innovation as a sign of infinite game behavior. Anyway, I hope the below is useful to founders whose sales motions aren’t getting easier years into their venture backed company and want to consider frameworks for evaluating their position.&nbsp;</p>



<p>=================</p>



<p><strong>Startup Post Mortem, </strong>written Q3 2018</p>



<p>At times, the company we founded in 2013 seemed to be doing well by various objective metrics— we had a prestigious customers list ranging from CNN to Comcast, we raised 3 funding rounds summing to over $20MM in venture capital investment, and our revenue grew exponentially for the first few years (obviously easier to 3x when x is small). As the cofounder and CEO, I always bet on our ability to figure it out and be a financial success. I put in the first $50K and bought our domain for an additional $10K, which isn’t much money in the scheme of startup funding, but this was before we had users, before we’d gotten into Y Combinator, before it was anyone other than me and my cofounder. I used to be a trader, so I wasn’t goofing around— I fully expected to eventually make tons of money off our startup. I wrote a draft S-1 for how we would IPO, I didn’t pay myself for the first year, I was the lowest paid person in the company for years, and I guarded our equity like it was the blood of my children. I always wanted more equity because I valued it so highly. When founder friends told me to pay myself more, I asked for more equity instead. When we raised an oversubscribed Series B, founder friends told me to ask if I could sell some of my shares or take money off the table, but again I asked for more equity instead. Suggestions to get cash seemed ridiculous to me because I didn’t think I deserved cash yet; we weren’t a success and I, more than anyone, knew all our warts. When we were getting acquired, founder friends suggested I block the acquisition unless I made money off it, but that also sounded ridiculous to me because I felt I deserved money least of all. I’m sure my VC’s would’ve agreed.</p>



<p>Our company didn’t exit at anywhere near as well as I’d pitched, and I felt sad to fail after so many years of everyone working so hard. For years, we worked weekends and holidays, regularly in the office till 10pm. My VP of marketing was back at work weeks after birthing each of her babies, working through her pregnancies, and we forced anyone who entered my house or office to do user tests. Had it all been a waste? Should we have spent that time partying instead? Being successful is important to me and I felt ashamed my company wasn’t a financial success despite how hard everyone worked on it and how much money we raised. Sure, I could twist the story to make it sound like a success in terms of learning and building, and we made a product people used, and we got acquired, but the fact is that the company didn’t make money the way I’d imagined and pitched. I felt scared my investors would view me as a failure and dislike me or view me as incompetent. We should’ve done better— we had some of the smartest people you’d ever meet working on this problem that I convinced them was important enough to warrant their time and resources. How had I been so wrong about the financial outcome?&nbsp;</p>



<p><strong>Two Key Qualifying Questions:</strong></p>



<p>One of my investors put it well: everyone in a company is either a) making the product or b) selling the product. I learned there were 2 key questions that separated successful vs unsuccessful hires in our company:</p>



<ol><li>How hard is it to make this product?</li><li>How hard is it to sell this product?</li></ol>



<p>Our product was both hard to make and hard to sell. What do I mean by this and how does this impact the hiring profile?</p>



<p><strong>Product vs Sales Driven Company:</strong></p>



<p>On the spectrum of how hard it is to build a product, web forms are on the easier side. Easy products are anything that a person could do with a series of google docs and sheets, anything that you’re 100% sure is possible to make. On the harder side, there are products like a rocket or a flying car, where it’s &lt;100% guaranteed the engineering will get there in the time required. If the product is easy to build, then engineering is easier and it’s more on the sales and marketing teams to drive the company forward and show why your company is better even though others can make this commoditizable product (through network effect/ better land grab execution, brand/ trust, integrations/ partnerships, “thought leadership,” customer service/ support, etc).&nbsp;</p>



<p>In contrast, the harder a product is to build, the better engineers you need and the more everything depends on the product team shipping something 10x better.&nbsp;</p>



<p>Our product was nowhere as hard to build as a rocket, but it was harder than a webapp, and we made design choices that increased the difficulty of building and maintaining our product in exchange for gaining competitive advantage, which was high at one point but eroded. This means our company had to be product driven. But after the first few years, we failed to be product driven because 1) I struggled to hire product leadership that was technical enough and 2) I was short term focused on revenue goals. Single-threaded on sales, I didn’t focus on the product roadmap because all I cared about were short term goals to lead us to the next funding round because I was mainly driven by my fear of the startup failing versus any love for shipping a better product.&nbsp;</p>



<p><strong>Transactional vs. Consultative Sales:</strong></p>



<p>Everyone in B2B SaaS knows from SaaStr etc you’re supposed to distinguish between sales people who sold to technical vs non-technical teams, and differentiate sales candidates based on the price point they were comfortable selling at, but I learned an additional point of differentiation: how consultative must the sale be? On the spectrum of how hard it is to sell a product, widgets like video conferencing software are on the easier end, easy to explain and demo. On the harder end, there’s consulting services to suggest TBD process improvements. Even harder is stuff that’s a new category where you have to educate the buyer on the need. The hardest sales require founders to drive sales; the salesperson needs to be at least as smart as the buyer so they can credibly educate the buyer on how the product will urgently impact their revenue. Buyers of video conferencing software don’t expect to get promoted because they chose Zoom over Webex or talk about the impact of their choice at a conference, but buyers of analytics software do want to hear how they’re going to become Chief Product Officer vs VP, that they’re going to show their CEO a powerpoint with graphs clearly illustrating the revenue their analytics choices have created for their team, and how they’re going to speak at the conference on their data driven decision making processes.</p>



<p>If the product fulfills a clear, established need, you can hire a wider variety of salespeople. But when the product’s harder to sell, you need a “consultative” salesperson, a specific profile correlated but distinct from price point. When the product differences/ usage/ impact are hard to explain, or there’s no category yet, or it’s not a drastic, budgeted need, you need sales people who are like consultants, subject matter experts who are smarter than the buyers.&nbsp;</p>



<p>If the sales person is interested in presenting a custom, strategic overview of how our product impacts the buyer’s product strategy, they eventually want to become customer success managers. Other than our first business hire, who was more like a cofounder to me and eventually founded his own company, I couldn’t get anyone to do both sales and customer success at the same time. I think our deals weren’t big enough and our customer success process was in the awkward gap between easy and hard— not hard enough to warrant consulting services, but not easy enough to remain a yearly check-in to upgrade the account.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="856" src="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png" alt="" srcset="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png 1024w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--400x334.png 400w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--768x642.png 768w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups-.png 1404w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption><em>Pros and cons of product vs. sales driven startups</em></figcaption></figure>



<p><strong>Fear/ Ego:</strong></p>



<p>Shifting gears from the tactical company building stuff to the touchy feely, the following section is philosophical.</p>



<p>It had started out really fun. In the 2nd year of the company, one executive told me that she got all her social fulfillment from our work. We were always together, working from my house on weekends, engineers sleeping over when they got tired, cooking together, talking about each other’s love languages, a group of friends going on an adventure together.&nbsp;</p>



<p>But now I see that I didn’t start the company with a pure heart. I started the company because I thought it’d be successful and I wanted to prove I could contribute something to the world, not because I specifically cared about our product or market, which I learned matters for me as time passes.&nbsp;</p>



<p>I thought I could get passionate about anything, and that was true at first, but it drained me to force myself to be an expert on our product for years because it wasn’t something I would’ve done if it weren’t for the company, the team, and my ego. For years, I always knew the most about our market and would send links to the rest of the team for news that had come out, anything they …</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</a></em></p>]]>
            </description>
            <link>http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654192</guid>
            <pubDate>Thu, 01 Oct 2020 18:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spaced Repetition, Anki and Execute Program]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654071">thread link</a>) | @williamsmj
<br/>
October 1, 2020 | https://mike.place/2020/executeprogram/ | <a href="https://web.archive.org/web/*/https://mike.place/2020/executeprogram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
            
            <p><span>2020-09-02</span></p><p>Here’s the tl;dr</p>
<ul>
<li>memorizing stuff is good</li>
<li>spaced repetition is a good way to memorize things</li>
<li><a href="https://www.executeprogram.com/">Execute Program</a> is a subscription
learning site that uses spaced repetition</li>
<li>Execute Program has good lessons (especially on regular expressions and
concurrency)</li>
<li>Ergo Execute Program is good</li>
<li>Also <a href="https://ankiweb.net/">Anki</a> is good</li>
</ul>
<p>QED.</p>
<h2 id="memorizing-stuff-is-useful">Memorizing stuff is useful</h2>
<p>It seems almost self-evident to me that this <a href="https://overcast.fm/+R7DUeyopY/2:03:38">John Siracusa
quote</a>
(<a href="https://twitter.com/garybernhardt/status/1287883217450614784">via</a>) is true:</p>
<blockquote>
<p>It’s good to reach the level of competence where you can write [programs] from
top to bottom and never have to look anything up.</p>
</blockquote>
<p>There are two steps to reaching this enlightened state. The first is learning
the facts in the first place. The second is <em>remembering</em> them. That second step
is crucial because, by storing this stuff in your head, rather than offloading
it to search engines and man pages, you make the connection between your brain
and the computer higher bandwidth. Programming then becomes more more fun in the
same way a conversation between two people who are fluent in the same language
is often more fun.</p>
<h2 id="spaced-repetition">Spaced repetition</h2>
<p>Most of us stop making time for memorization when we stop taking exams. That’s
probably because it’s insanely boring and time-consuming. But that is less true
if you use spaced repetition, a family of algorithms for memorizing things
efficiently.</p>
<p>Spaced repitition works like this: on day 0, you’re shown a question or prompt
and asked to recall the response. You’re shown it again on day 1. And then again
on (for example) day 3, day 8, day 20, etc. These growing intervals are chosen
such that, just when you’re on the verge of forgetting something, you’re asked
to dredge it up from the back of your mind. If you can’t do that then you go
back to the beginning of the sequence of intervals for that prompt. The growing
intervals mean that you’re using your time efficiently while minimizing (not
eliminating!) the boringness.</p>
<p>It’s a simple and very natural idea so it’s a little surprising just how well it
works. I used spaced repetition to learn German. I haven’t used German for
nearly ten years. I have a terrible memory. I <em>still</em> remember not only the
words, but the <em>layout</em> of specific flashcards I used to learn pretty obscure
bits of vocabulary.</p>
<h2 id="anki">Anki</h2>
<p>Natural language learning is probably the most common use case for spaced
repetition, but <a href="https://sive.rs/srs">lots</a> of
<a href="https://sasha.wtf/anki-post-1/">people</a> use it to memorize bits of things they
learn while programming. Anything that I have to look up more than a couple of
times goes in my list of prompts and responses. Some examples from my “deck” of
prompts and responses:</p>
<ul>
<li>
<p>curl switch to follow redirects (short and long versions)<br>
<code>-L --location</code></p>
</li>
<li>
<p>Makefile alias for current target<br>
<code>$@</code></p>
</li>
<li>
<p>Find and replace string <code>foo</code> in a bash <code>$variable</code><br>
<code>${variable//foo/bar}</code></p>
</li>
<li>
<p><a href="https://xkcd.com/1168/">Tar a directory</a><br>
<code>tar cf file.tar directory/</code></p>
</li>
</ul>
<p>I only add things I have to look up. I don’t add things my editor helps me with,
such as the calling signatures of functions. I might benefit from doing that,
but that’s where I draw the line.</p>
<p>To manage my “deck” of prompts and responses, and to review them at
appropriately spaced intervals I use <a href="https://apps.ankiweb.net/">Anki</a>.</p>
<p>Anki is a charmingly crusty bit of open-source cross-platform software. It uses
<a href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html">its own spaced repetition
algorithm</a>. It’s
ugly. It’s confusing. The mobile versions are $25! But it’s extremely popular,
very flexible, and better than <a href="https://getpolarized.io/2020/02/03/anki-ripped-off.html">the scummy
rip-off</a>.</p>
<p>You can and should assemble your own deck. But that’s a lot of work (more work
than the remembering). So, if you want to give it a try first, download a small
public deck <a href="https://ankiweb.net/shared/decks/">from the shared library</a>. I
started with the <a href="https://ankiweb.net/shared/info/959976866">US state capitals</a>.</p>
<h2 id="execute-program-and-spaced-repetition">Execute Program and spaced repetition</h2>
<p><a href="https://www.executeprogram.com/">Execute Program</a> is a subscription learning
site by <a href="https://www.destroyallsoftware.com/">Gary Bernhardt</a>. You work your way
through courses on Javascript, TypeScript, SQL and Regex and then you get
pestered by a spaced repetition algorithm to review, i.e. regurgitate what you
learned by completing tiny programs.</p>
<p>Each course takes perhaps 20 minutes/day for a couple of weeks (you have to wait
for the reviews so you can’t do the whole course in a day). Once the lessons are
over, the reviews take about ten minutes/day at first, but that approaches zero
as the spaces between the repetitions grow.</p>
<p><img src="https://mike.place/post/executeprogram/executeprogram.png" alt="Execute Program"></p>
<p>The Execute Program review UI</p>
<p>The spaced repetition is a little crude relative to Anki. For example, I miss
being able to <a href="https://docs.ankiweb.net/#/background?id=spaced-repetition">say if something was easy or
hard</a>. After you get
something right for the fourth time, on day 64, even it doesn’t feel like it’s
stuck, you’re congratulated and told you’re never going to see it again. And
related reviews all come on the same day, which makes them artificially easy.</p>
<p>But you can’t argue with results. I can say with a straight face that I “know”
this stuff after spending four months as a subscriber, and doing the reviews.
So, very highly recommended!</p>
<h2 id="execute-programs-courses">Execute Program’s courses</h2>
<p>In what sense do you “know” these subjects after completing the Execute Program
course? Firstly, you have the syntax at your fingertips thanks to spaced
repetition. For example, I’m not an experienced TypeScript programmer. But I
know the syntax well, and that makes occasionally writing crappy little
TypeScript programs at work much less frustrating. Secondly, the courses
themselves are incredibly well done. They’re not a parade of facts. I
<em>understand</em> stuff I didn’t understand before I used the site.</p>
<p>I joined planning to learn concurrency but I ended up doing all of the other
courses: regular expressions, JavaScript arrays, Modern JavaScript, TypeScript,
and SQL.</p>
<p>They’re all really good! My only complaint (and the reason I’ve let my
subscription lapse) is that they’re not longer and there aren’t more of them.
The <a href="https://www.executeprogram.com/faq">FAQ</a> explains the teaching philosophy
better than I can, so I won’t repeat it here. But I will make some comments on
my two favorite courses.</p>
<h3 id="regular-expressions">Regular Expressions</h3>
<p>This topic is the perfect fit for spaced repetition because there is no way
around the fact that you just gotta learn a bunch of facts (the same goes for
the course on JavaScript Arrays). The course stops before named groups and
lookback/ahead, so I had to learn that stuff myself (from <a href="https://learning.oreilly.com/library/view/learning-regular-expressions/9780134757056/">the second half of
this perfect, short
book</a>).
But if you want to learn 90% of what you need to read and write regular
expressions in the absolute shortest amount of time, conditional on being able
to remember any of it, this course is the way to go.</p>
<h3 id="concurrency">Concurrency</h3>
<p>Concurrency is <em>not</em> the perfect fit for spaced repetition. It’s subtle. There
are often many different solutions to a problem. And the review “answers” tend
to be quite long in terms of number of characters. Nevertheless, this course is
probably my favorite.</p>
<p>I have been banging my head against a brick wall with concurrency for years. It
clicked for me this year in great part because of this course. (Shout out to
this talk about <a href="https://www.youtube.com/watch?v=8aGhZQkoFbQ&amp;feature=youtu.be">the JS event
loop</a> and some
Python async content too, especially <a href="https://www.youtube.com/watch?v=Xbl7XjFYsN4&amp;list=PLhNSoGM2ik6SIkVGXWBwerucXjgP1rHmB">Łukasz Langa’s
videos</a>
and <a href="https://realpython.com/async-io-python/">Brad Solomon’s Real Python
article</a>.)</p>
<p>Why is this course so good? Because it doesn’t start from the assumption that
you know or care what <a href="http://callbackhell.com/">callback hell</a> is, or even that
you’re a particularly experienced JavaScript programmer (I’m not). Assuming you
know and hate JavaScript is a widespread antipattern in JavaScript writing: “you
think this sucks” is the starting point. Well, I didn’t! But now you’re making
me nervous (and confused because you’re teaching me about a bunch of stuff that
I apparently should not do?!) In other words, <a href="https://mkremins.github.io/blog/doors-headaches-intellectual-need/">as Max Kreminski
says</a>:</p>
<blockquote>
<p>One of the worst things you can do is force people who don’t feel pain to take
your aspirin.</p>
</blockquote>
<p>The Execute Program Concurrency course just gets straight to the point:
timeouts, promises. I hope they add async/await.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Execute Program is good. It’s fun. The lessons are extremely thoughtfully put
together. I hope they add more!</p>
<p>And every time you have to search for something for the third time, add it to
an Anki deck.</p>

        </div>

        
    </div></div>]]>
            </description>
            <link>https://mike.place/2020/executeprogram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654071</guid>
            <pubDate>Thu, 01 Oct 2020 17:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Faster CouchDB View Server in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653369">thread link</a>) | @bryanrasmussen
<br/>
October 1, 2020 | https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server | <a href="https://web.archive.org/web/*/https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653369</guid>
            <pubDate>Thu, 01 Oct 2020 17:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hub-and-Spoke vs. Point-to-Point Data Synchronization: There's One Clear Winner]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653337">thread link</a>) | @knes
<br/>
October 1, 2020 | https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <div><p>Consistent, accurate data is the foundation of your operational success as a business. For your marketing to make sense, you need a clear (and accurate) picture of your buyer personas. For your sales team to be successful, they need up-to-date records of which companies you’ve already spoken with, who is interested in what services, and who the point of contact is for each lead.</p><p>So how do you ensure that your data is accurate and accessible to everyone who needs it? You choose the best data synchronization architecture. In this article, we’re going to show you why the hub-and-spoke method will prevail over point-to-point data synchronization every time, with a five-round fight. </p><p>But first, let’s review what each method looks like. Point-to-point integration is an architectural system in which each individual point (in this case, app or software) is connected to every other point it needs to share information with.</p></div><figure><img src="https://blog.getcensus.com/content/images/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 1600w, https://blog.getcensus.com/content/images/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 2300w" sizes="(min-width: 720px) 720px"><figcaption>Point to Point and Hub &amp; Spoke Infrastructures</figcaption></figure><p>The hub-and-spoke system, on the other hand, is laid out so that one central hub connects to all of the spokes. Now, let’s dive into how our two contenders match up:</p><h2 id="round-1-which-scales-more-easily">Round 1: Which Scales More Easily?</h2><div><p>Point-to-point data synchronization is messy, which makes scaling a serious challenge. When you add a new app to your business, you may initially need to connect it to only one other app. But as your business grows and your teams get larger, you’ll eventually want to connect your tech stack so that each team has access to as much information as possible, so they are empowered to make the best decisions for your business’s success.</p><p>But the point-to-point method requires exponentially more connections (or integrations) to achieve a fully connected data and tech stack. In fact, the number of connections grows by the square of the number of apps. So, if you have eight apps, you may need as many as 64 connections to achieve full data synchronicity—and a fully scalable business.</p><p>As <a href="https://www.christiernan.com/why-point-to-point-integrations-are-evil/">Chris Tiernan</a>, senior director of software engineering for IT business applications at Splunk, wrote:</p></div><blockquote>“Many organizations have learned the hard way, an infrastructure based on P2P integration quickly becomes unmanageable, brittle, and damaging to both the IT budget and the organization’s ability to meet current and changing business needs.”</blockquote><p>The hub-and-spoke system, on the other hand, requires only one connection (to the hub) for each app. So no matter how many apps your business needs as you grow, your integration and setup time won’t go through the roof. &nbsp;If we use the same example of a business with eight apps, the maximum number of connections required for a fully synchronized data and tech stack is only eight. That’s 56 fewer integrations to set up and maintain. </p><h2 id="round-2-which-synchronizes-more-accurately">Round 2: Which Synchronizes More Accurately?</h2><div><p>When it comes to data consistency, point-to-point synchronization falls short again. Disparate apps within a point-to-point system often wind up with conflicting data because there is no one central point, or hub, that determines which information is the most up-to-date or accurate. Once this happens, it’s a nightmare to figure out which data set is correct.</p><p>Data quality is a huge concern for businesses of all sizes. You don't want your teams making strategic decisions or developing business processes based on bad information. If Salesforce, for instance, shows 160 active clients but Marketo only shows 130, your marketing team could be tailoring ad campaigns based on a misrepresented user base. If your data transfer between Salesforce and SalesLoft is broken, you may wind up with two sales reps who waste time reaching out to the same company. Or, worse yet, one of your sales reps could cold call an existing client and unintentionally put that account at risk.</p><p>Point-to-point data synchronization also makes you more vulnerable to data stomping—where information submitted by one app is overwritten and completely deleted by another unintentionally. Say, for instance, you have two employees working on the same account. Each employee adds notes to your client’s file at the same time, one in your CRM tool and one in your sales engagement tool. If you’re using a point-to-point integration to share information across this software, you risk losing part or all of that data as the two apps struggle to sort out which information is the most current. One set of data may completely overwrite the other, or you may wind up with an unintelligible jumble of both sets of notes. And if you don’t catch that error right away, valuable client notes may be lost forever.</p><p>Luckily, our second contender solves this problem. It’s a lot easier to ensure data consistency across your company with the hub-and-spoke model since all apps have the same source of truth—your data warehouse or hub. </p><p>Think of the hub as the brain of your operation and the spokes as your five senses. If you smell smoke at the same time you see someone grilling burgers, your brain will know which information should supersede the other and determine that there is no immediate risk.</p></div><h2 id="round-3-which-is-easier-to-maintain">Round 3: Which Is Easier to Maintain?</h2><p>Spoiler alert: point-to-point is going to lose this round, too. The more API integrations you have, the harder your system is to maintain. In <a href="http://tray.io/">Tray.io</a>’s guide, <a href="https://tray.io/blog/what-is-an-api-integration-for-non-technical-people">What are APIs and API Integrations</a>, they explain that:</p><blockquote>“trying to get your data to sync up [using API integrations] usually requires error-prone manual work, jury-rigged workarounds, or filing a ticket for IT support.”</blockquote><p>The image below is an actual diagram of GitLab’s point-to-point data infrastructure in 2020.<br></p><figure><img src="https://blog.getcensus.com/content/images/2020/09/gitlab_data_infrastructure.png" alt="gitlab data infrastructure" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/gitlab_data_infrastructure.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/gitlab_data_infrastructure.png 1000w, https://blog.getcensus.com/content/images/2020/09/gitlab_data_infrastructure.png 1510w" sizes="(min-width: 720px) 720px"><figcaption>Gitlab Data Infrastructure (<a href="https://twitter.com/dwr/status/1260432470262059008">source</a>)</figcaption></figure><div><p>A web with this many lines, or API integrations and webhooks, requires <em>a lot</em> of maintenance. Whenever one of those apps or programs is updated, you run the risk of the connecting API integrations failing. So, for GitLab, based on this diagram, a Marketo update could mean eight different integrations will need to be fixed. If Salesforce updates, 26 integrations may need recoding or fixing.</p><p>Hub-and-spoke is—you guessed it—easier to maintain because each application your team requires only needs to be integrated with your hub instead of every other app in your tech stack. If one of those apps is updated to a new version, you don’t need to worry about recoding five or more connections to ensure it keeps syncing with all of your other apps. The same thing is true if you want to add a new app.</p><p>Hub-and-spoke also makes it easier to clean up or transform data and have those adjustments reflected everywhere that data appears. Say, for instance, that you want to add a customer persona to your target audience divisions. You only need to do this once for it to be reflected across your entire tech stack (in your marketing, sales, and other apps) rather than adding it to each app individually and then having to check the integrations to make sure all of your coding is compatible.</p></div><h2 id="round-4-which-is-more-secure"><strong>Round 4: Which Is More Secure?</strong></h2><div><p>The point-to-point model poses a serious security risk, whether you’re using it for data synchronization or even network architecting. Doug Guth, managing architect at <a href="https://corebts.com/">Core BTS</a>, explained that “when you go to a point to point [system]... security is next to impossible. Your visibility of who’s accessing what and where and how, what’s flowing where and how... it’s difficult at best, if not impossible to do.”</p><p>When it comes to data synchronization specifically, point-to-point systems require numerous API user accounts. And as <a href="https://www.christiernan.com/why-point-to-point-integrations-are-evil/">Tiernan</a> wrote</p></div><blockquote>“In general security terms, the more API user accounts available, the more exposure to risk the company has for security breaches.” </blockquote><div><p>In addition, if you’re synchronizing information with third-party vendors from app to app using various APIs, it’s very hard to protect confidentiality and maintain compliance. You can't create clear and consistent access control lists if your data is spread across 30 different apps. </p><p>Hub-and-spoke, on the other hand, provides a sort of vault, in the form of your hub, that allows you to protect and limit what information is shared, with which apps or vendors, and how that information is shared. Using the hub-and-spoke model, you can define permissions based on data and people, rather than apps, which ensures more reliable and trustworthy data.</p><p>Hub-and-spoke data synchronization seriously limits your exposure to data breaches. <a href="https://www.ellucian.com/insights/hubs-spokes-and-point-point-quick-guide-common-integration-terminology#:~:text=hub%2Dand%2Dspoke%20integration&amp;text=Point%2Dto%2Dpoint%20integration%20uses,data%2Dsharing%20between%20two%20systems.&amp;text=Hub%2Dand%2Dspoke%20integration%2C,to%20any%20other%20sharing%20system">Ben Morley</a>, director of product management at Ellucian, wrote, “The bottom line is that it’s [hub and spoke] a more secure approach because you're reducing the number of factors of attack.” </p></div><h2 id="round-5-which-is-more-affordable"><strong>Round 5: Which Is More Affordable?</strong></h2><div><p>Those of you rooting for the underdog, here’s where point-to-point throws a punch: on an individual project level, point-to-point data synchronization can be cheaper, which is why you’ll still find it in use. </p><p>But zoom out and you’ll quickly see that the total operational cost of managing a point-to-point infrastructure can quickly become cost-prohibitive, even for small businesses with only a few apps. Gartner Research recently <a href="https://www.gartner.com/en/documents/3986583/cost-optimization-is-crucial-for-modern-data-management-">published a report</a> on modern data management where they referred to point-to-point integrations as “haphazard reactive measures” that cause costs to “escalate uncontrollably.”</p><p>It’s a common misconception that hub-and-spoke data synchronization comes with a large upfront cost. Historically, there was truth to this belief, but this is no longer the case thanks to data warehouses like <a href="https://www.snowflake.com/">Snowflake</a> and <a href="https://cloud.google.com/bigquery">BigQuery</a> with flexible pricing structures. BigQuery’s <a href="https://cloud.google.com/bigquery#section-10">pay-as-you-go</a> subscription is just $5 per TB per month. Once you’ve got your <a href="https://blog.getcensus.com/graduating-to-the-modern-data-stack-for-startups/">data storage set up</a>, you can use synchronization tools such as <a href="https://fivetran.com/">Fivetran</a> and <a href="https://getcensus.com/">Census</a> to easily move information to and from all of your apps. And each of these software offers a free trial.</p></div><h2 id="the-modern-tech-stack-champion">The Modern Tech Stack Champion</h2><figure><img src="https://blog.getcensus.com/content/images/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 1000w, https://blog.getcensus.com/content/images/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 1040w" sizes="(min-width: 720px) 720px"><figcaption>Hub &amp; Spoke vs Point to Point Summary</figcaption></figure><p>The hub-and-spoke model is the clear champion of data synchronization. And we designed Census to make this winning system easily accessible for businesses of all sizes. Forget …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/">https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/</a></em></p>]]>
            </description>
            <link>https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653337</guid>
            <pubDate>Thu, 01 Oct 2020 16:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Tips to Build Your Blog from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653236">thread link</a>) | @gergelyke
<br/>
October 1, 2020 | https://nemethgergely.com/blog/building-your-blog-from-scratch | <a href="https://web.archive.org/web/*/https://nemethgergely.com/blog/building-your-blog-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-baseweb="block"><p data-baseweb="block">Modern web development came a long way. The blog that you are currently reading was built in about ten days, with not more than an hour spent on it on those days. Because of all the open-source libraries available, the site is fast and accessible, with little extra work required on my end.</p><p data-baseweb="block">This article contains a few quick tips that will help you build your blog from scratch, should you choose to go down on that path.</p><h2 data-baseweb="block" id="why-building-a-blog-from-scratch-in-2020">Why building a blog from scratch in 2020? <a href="#why-building-a-blog-from-scratch-in-2020"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">First, let's address the elephant in the room! Why would anyone build their blog from scratch in 2020, when we have services like <a data-baseweb="link" rel="noopener" href="https://ghost.org/" target="_blank">Ghost</a> or <a data-baseweb="link" rel="noopener" href="https://wordpress.com/" target="_blank">Wordpress</a>?</p><p data-baseweb="block">Previously, I used a blog engine called <a data-baseweb="link" rel="noopener" href="https://hexo.io/" target="_blank">Hexo</a>. While it worked well for a few years, it became increasingly hard to maintain and update. It doesn't have a vibrant plugin ecosystem, so quite a few times, I ended up monkey-patching it's build pipeline to include support for web workers or webp images formats. So maintaining the old blog was not an option anymore.</p><p data-baseweb="block">Secondly, I wanted to have a small side project to learn and experiment with new technologies and language features. As I wrote in the article <a data-baseweb="link" href="https://nemethgergely.com/blog/coding-as-an-engineering-manager">Coding as an Engineering Manager</a>, as a manager, I usually work on bug fixes when it comes to coding. This website allows working on a project end-to-end and keeps my technical chops up-to-date.</p><p data-baseweb="block">Be aware, working on your blog can also result in endless procrastination <em>(let me quickly fix that one LAST thing)</em>. I have been there done that.</p><h2 data-baseweb="block" id="1-use-nextjs-with-a-component-library">1. Use Next.js With a Component Library <a href="#1-use-nextjs-with-a-component-library"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block"><a data-baseweb="link" rel="noopener" href="https://nextjs.org/" target="_blank">Next.js</a> is a web framework built for React. The reasons I picked it for my blog:</p><ul><li data-baseweb="block"><strong>Zero configuration</strong>: it comes batteries-included, so you don't have to deal with Webpack configurations if you don't want to.</li><li data-baseweb="block"><strong>Static site generation</strong>: there is barely anything dynamic on my blog, so I wanted to pick a tool that supports static site generation.</li><li data-baseweb="block"><strong>Code splitting</strong>: by using <a data-baseweb="link" rel="noopener" href="https://nextjs.org/docs/advanced-features/dynamic-import" target="_blank">dynamic imports</a>, one can reduce the main JavaScript's bundle size dramatically to improve page load times.</li></ul><p data-baseweb="block">I picked <a data-baseweb="link" rel="noopener" href="https://baseweb.design/" target="_blank">Base Web</a> as the component library for this site. While it doesn't matter which component library you choose from a stylistic point of view, do pay attention to the following technical details:</p><ul><li data-baseweb="block"><strong>Built-in accessibility</strong> to ensure that you don't have to invest a vast amount of time making your website accessible. The component library should do the heavy-lifting here.</li><li data-baseweb="block"><strong>Reasonable CSS/JS footprint</strong>, so your website loads quickly on slower networks too.</li><li data-baseweb="block"><strong>Extensibility/theme-ability</strong>, so you can easily create your visual language.</li></ul><h2 data-baseweb="block" id="2-leverage-the-mdx-file-format">2. Leverage the MDX File Format <a href="#2-leverage-the-mdx-file-format"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">Once you start using Next.js or any React frameworks, I highly recommend starting using <a data-baseweb="link" rel="noopener" href="https://mdxjs.com/" target="_blank">MDX</a>. MDX is a format that lets you write JSX in your Markdown documents. So in practice, you can keep wiring markdown-based blog posts that Next.js/Gatsby can easily pick up.</p><p data-baseweb="block">Read more on it <a data-baseweb="link" rel="noopener" href="https://mdxjs.com/" target="_blank">here</a>.</p><h2 data-baseweb="block" id="3-reduce-the-amount-of-javascript-your-site-needs">3. Reduce the Amount of JavaScript Your Site Needs <a href="#3-reduce-the-amount-of-javascript-your-site-needs"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">It may be tempting to utilize external libraries for things like share buttons that enable your readers to post content to Twitter, Facebook or LinkedIn. <strong>It doesn't just add a lot of external dependencies to your site and slows it down, but it also adds additional trackers to your site.</strong></p><p data-baseweb="block">Instead, you can rely on share URLs that most social networks provide:</p><ul><li data-baseweb="block">For LinkedIn, you can use <code>https://www.linkedin.com/shareArticle?url=</code>.</li><li data-baseweb="block">For Twitter, you can use <code>https://twitter.com/intent/tweet/?url=</code>.</li><li data-baseweb="block">For Facebook, you can use <code>https://www.facebook.com/sharer/sharer.php?u=</code>.</li></ul><p data-baseweb="block">Similarly, you can integrate most newsletter services, like Mailchimp, without any additional JavaScript dependencies. For example, check out the Mailchimp integration at the bottom of this page.</p><h2 data-baseweb="block" id="4-leverage-cloudflare-workers-for-redirects">4. Leverage Cloudflare Workers for Redirects <a href="#4-leverage-cloudflare-workers-for-redirects"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">Originally, the blog posts I wrote lived under the root of the domain, without name namespace, like: <code>https://nemethgergely.com/coding-as-an-engineering-manager</code>. While initially it worked well, it became problematic as the number of blog posts increased.</p><p data-baseweb="block">Because of that, I've decided to move all blog posts under the namespace <code>/blog/</code>. So the previously mentioned article would be accessible from <code>https://nemethgergely.com/blog/coding-as-an-engineering-manager</code>. To ensure that I don't break any previous links to the site, I wanted to create redirects to the new locations.</p><p data-baseweb="block">This is where Cloudflare Workers become super handy - they provide extreme flexibility and are simple to write. This is the script that I use today to create the redirects:</p><div><div data-baseweb="block"><div><pre dir="ltr"><p><span>const</span><span> base </span><span>=</span><span> </span><span>"https://nemethgergely.com"</span><span></span></p><p><span></span><span>const</span><span> statusCode </span><span>=</span><span> </span><span>301</span><span>;</span><span></span></p><p><span></span><span>const</span><span> routes </span><span>=</span><span> </span><span>[</span><span></span></p><p><span>  </span><span>"engineering-productivity"</span><span>,</span><span></span></p><p><span>  </span><span>...</span><span></span></p><p><span></span><span>]</span><span>;</span><span></span></p><p><span></span><span>addEventListener</span><span>(</span><span>'fetch'</span><span>,</span><span> </span><span>event</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  event</span><span>.</span><span>respondWith</span><span>(</span><span>handleRequest</span><span>(</span><span>event</span><span>.</span><span>request</span><span>)</span><span>)</span><span></span></p><p><span></span><span>}</span><span>)</span><span></span></p><p><span></span><span>async</span><span> </span><span>function</span><span> </span><span>handleRequest</span><span>(</span><span>request</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> url </span><span>=</span><span> </span><span>new</span><span> </span><span>URL</span><span>(</span><span>request</span><span>.</span><span>url</span><span>)</span><span></span></p><p><span>  </span><span>let</span><span> </span><span>{</span><span> pathname </span><span>}</span><span> </span><span>=</span><span> url</span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>routes</span><span>.</span><span>includes</span><span>(</span><span>pathname</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>return</span><span> Response</span><span>.</span><span>redirect</span><span>(</span><span>`</span><span>${</span><span>base</span><span>}</span><span>/blog/</span><span>${</span><span>pathname</span><span>}</span><span>`</span><span>,</span><span> statusCode</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>fetch</span><span>(</span><span>request</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre></div></div></div><p data-baseweb="block">Twitter, Facebook or LinkedIn display an image in users' feed when you share one of your articles. These images are coming from <a data-baseweb="link" rel="noopener" href="https://ogp.me/" target="_blank">OpenGraph tags</a>, and you can set almost any image <em>(with some requirements)</em> to be displayed. However, creating these images whenever you write a new article can be taxing at times.</p><p data-baseweb="block">Because of this, and to ensure that these images are consistent, I implemented the following automation:</p><ol><li data-baseweb="block">Created a simple HTML page used as a template, screenshot below.</li><li data-baseweb="block">A small script goes through all the blog posts I have, replaces the <code>undefined</code> title in HTML, and creates screenshots.</li><li data-baseweb="block">Profit!</li></ol><p data-baseweb="block"><picture><source srcset="https://nemethgergely.com/webp/social-card-html-template.webp" type="image/webp"><source srcset="https://nemethgergely.com/social-card-html-template.png" type="image/png"><img src="https://nemethgergely.com/social-card-html-template.png" alt="social card html template"></picture></p><h2 data-baseweb="block" id="6-have-some-test-coverage">6. Have Some Test Coverage <a href="#6-have-some-test-coverage"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">When I started building this blog, I broke it a few times (mostly the layout or links). That's when I realized that I should add some basic sanity tests. As of today, I have two checks:</p><ul><li data-baseweb="block">a <strong>broken link checker</strong>, built on top of <a data-baseweb="link" rel="noopener" href="https://pptr.dev/" target="_blank">puppeteer</a>,</li><li data-baseweb="block"><strong>screenshots</strong>, where a CI job takes a few screenshots of some of the pages, and display them as artifacts on Circle CI <em>(built on puppeteer too)</em></li></ul><h2 data-baseweb="block" id="takeaways">Takeaways <a href="#takeaways"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">It always fun for me to build something. If you decide to create your blog too, keep these in mind:</p><ul><li data-baseweb="block">Procrastination is real. Focus on writing blog posts instead of always finding something you can improve on the technical side.</li><li data-baseweb="block">At the same time, try to automate as many of the repeated tasks of blog post writing, as possible, like social card generation or basic test coverage for sanity checks.</li></ul><div data-baseweb="block"><p data-baseweb="typo-paragraphsmall">October 1, 2020</p><div data-baseweb="block"><form action="https://nemethgergely.us2.list-manage.com/subscribe/post?u=f87b0ce29bc7e4718c40739f4&amp;id=ac4c709a2b" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate=""><p>Did you like this article? Subscribe to get notified about new ones on engineering management, open-source and the web!</p><label data-baseweb="form-control-label" for="email-address">Your email address</label></form></div></div></div></div>]]>
            </description>
            <link>https://nemethgergely.com/blog/building-your-blog-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653236</guid>
            <pubDate>Thu, 01 Oct 2020 16:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  • <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business’ specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single σ. You cannot."></p>
<p><span> AWS can afford to stay within a single σ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‘follow the money’ works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience – metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction – but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform’s domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product’s lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classic Paper: Go to Statement Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652958">thread link</a>) | @chsasank
<br/>
October 1, 2020 | https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html | <a href="https://web.archive.org/web/*/https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

  

  <p><span>Edsger W. Dijkstra</span> |
    <time datetime="01 October 2020">01 October 2020</time>
  </p>

  <section>
    <blockquote>
  <p><strong>NOTE</strong>: This is <em>not</em> my article. This is a classic paper originally published in <em>Communications of the ACM</em>, 1968 by Edsger W. Dijkstra  and a mirror of <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.4846&amp;rep=rep1&amp;type=pdf">another mirror</a>. Blue highlights/annotations are my own.</p>
</blockquote>

<p>Editor,</p>

<p>For a number of years I have been familiar with the observation that the quality of programmers is a decreasing function of the density of <code>go to</code> statements in the programs they produce. More recently I discovered why the use of the <code>go to</code> statement has such disastrous effects, and I became convinced that the <code>go to</code> statement should be abolished from all “higher level” programming languages (i.e. everything except, perhaps, plain machine code). At that time I did not attach too much importance to this discovery; I now submit my considerations for publication because in very recent discussions in which the subject turned up, I have been urged to do so.</p>

<p>My first remark is that, although the programmer’s activity ends when he has constructed a correct program, the process taking place under control of his program is the true subject matter of his activity, for it is this process that has to accomplish the desired effect; it is this process that in its dynamic behavior has to satisfy the desired specifications. Yet, once the program has been made, the ‘making’ of the corresponding process is delegated to the machine.</p>

<p>My second remark is that our intellectual powers are rather geared to master static relations and that our powers to visualize processes evolving in time are relatively poorly developed. For that reason we should do (as wise programmers aware of our limitations) our utmost to shorten the conceptual gap between the static program and the dynamic process, to make the correspondence between the program (spread out in text space) and the process (spread out in time) as trivial as possible.</p>

<blockquote>
  <p>Our intellectual powers are rather geared to master static relations and that our powers to visualize processes evolving in time are relatively poorly developed.</p>
</blockquote>

<p>Let us now consider how we can characterize the progress of a process. (You may think about this question in a very concrete manner: suppose that a process, considered as a time succession of actions, is stopped after an arbitrary action, what data do we have to fix in order that we can redo the process until the very same point?) If the program text is a pure concatenation of, say, assignment statements (for the purpose of this discussion regarded as the descriptions of single actions) it is sufficient to point in the program text to a point between two successive action descriptions. (In the absence of <code>go to</code> statements I can permit myself the syntactic ambiguity in the last three words of the previous sentence: if we parse them as “successive (action descriptions)” we mean successive in text space; if we parse as “(successive action) descriptions” we mean successive in time.) Let us call such a pointer to a suitable place in the text a “textual index.”</p>

<p>When we include conditional clauses (<code>if B then A</code>), alternative clauses (<code>if B then A1 else A2</code>), choice clauses as introduced by C. A. R. Hoare (case[i] of (A1, A2,···, An)),or conditional expressions as introduced by J. McCarthy (B1 -&gt; E1, B2 -&gt; E2, ···, Bn -&gt; En), the fact remains that the progress of the process remains characterized by a single textual index.</p>

<p>As soon as we include in our language procedures we must admit that a single textual index is no longer sufficient. In the case that a textual index points to the interior of a procedure body the dynamic progress is only characterized when we also give to which call of the procedure we refer. With the inclusion of procedures we can characterize the progress of the process via a sequence of textual indices, the length of this sequence being equal to the dynamic depth of procedure calling.</p>

<p>Let us now consider repetition clauses (like, <code>while B repeat A</code> or <code>repeat A until B</code>). Logically speaking, such clauses are now superfluous, because we can express repetition with the aid of recursive procedures. For reasons of realism I don’t wish to exclude them: on the one hand, repetition clauses can be implemented quite comfortably with present day finite equipment; on the other hand, the reasoning pattern known as “induction” makes us well equipped to retain our intellectual grasp on the processes generated by repetition clauses. With the inclusion of the repetition clauses textual indices are no longer sufficient to describe the dynamic progress of the process. With each entry into a repetition clause, however, we can associate a so-called “dynamic index,” inexorably counting the ordinal number of the corresponding current repetition. As repetition clauses (just as procedure calls) may be applied nestedly, we find that now the progress of the process can always be uniquely characterized by a (mixed) sequence of textual and/or dynamic indices.</p>

<blockquote>
  <p>The reasoning pattern known as “induction” makes us well equipped to retain our intellectual grasp on the processes generated by repetition clauses.</p>
</blockquote>

<p>The main point is that the values of these indices are outside programmer’s control; they are generated (either by the write-up of his program or by the dynamic evolution of the process) whether he wishes or not. They provide independent coordinates in which to describe the progress of the process.</p>

<p>Why do we need such independent coordinates? The reason is - and this seems to be inherent to sequential processes - that we can interpret the value of a variable only with respect to the progress of the process. If we wish to count the number, <em>n</em> say, of people in an initially empty room, we can achieve this by increasing n by one whenever we see someone entering the room. In the in-between moment that we have observed someone entering the room but have not yet performed the subsequent increase of n, its value equals the number of people in the room minus one!</p>

<p>The unbridled use of the <code>go to</code> statement has an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress. Usually, people take into account as well the values of some well chosen variables, but this is out of the question because it is relative to the progress that the meaning of these values is to be understood! With the <code>go to</code> statement one can, of course, still describe the progress uniquely by a counter counting the number of actions performed since program start (viz. a kind of normalized clock). The difficulty is that such a coordinate, although unique, is utterly unhelpful. In such a coordinate system it becomes an extremely complicated affair to define all those points of progress where, say, <em>n</em> equals the number of persons in the room minus one!</p>

<blockquote>
  <p>The unbridled use of the go to statement has an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress.</p>
</blockquote>

<p>The <code>go to</code> statement as it stands is just too primitive; it is too much an invitation to make a mess of one’s program. One can regard and appreciate the clauses considered as bridling its use. I do not claim that the clauses mentioned are exhaustive in the sense that they will satisfy all needs, but whatever clauses are suggested (e.g. abortion clauses) they should satisfy the requirement that a programmer independent coordinate system can be maintained to describe the process in a helpful and manageable way.</p>

<p>It is hard to end this with a fair acknowledgment. Am I to judge by whom my thinking has been influenced? It is fairly obvious that I am not uninfluenced by Peter Landin and Christopher Strachey. Finally I should like to record (as I remember it quite distinctly) how Heinz Zemanek at the pre-ALGOL meeting in early 1959 in Copenhagen quite explicitly expressed his doubts whether the <code>go to</code> statement should be treated on equal syntactic footing with the assignment statement. To a modest extent I blame myself for not having then drawn the consequences of his remark.</p>

<p>The remark about the undesirability of the <code>go to</code> statement is far from new. I remember having read the explicit recommendation to restrict the use of the <code>go to</code> statement to alarm exits, but I have not been able to trace it; presumably, it has been made by C. A. R. Hoare. In [1, Sec. 3.2.1.] Wirth and Hoare together make a remark in the same direction in motivating the case construction: “Like the conditional, it mirrors the dynamic structure of a program more clearly than <code>go to</code> statements and switches, and it eliminates the need for introducing a large number of labels in the program.”</p>

<p>In [2] Guiseppe Jacopini seems to have proved the (logical) superfluousness of the <code>go to</code> statement. The exercise to translate an arbitrary flow diagram more or less mechanically into a jump-less one, however, is not to be recommended. Then the resulting flow diagram cannot be expected to be more transparent than the original one.</p>

<p>References:</p>

<ol>
  <li>Wirth, Niklaus, and Hoare C. A. R. A contribution to the development of ALGOL. Comm. ACM 9(June 1966), 413-432.</li>
  <li>BÖhm, Corrado, and Jacopini Guiseppe. Flow diagrams, Turing machines and languages with only two formation rules. Comm. ACM 9 (May 1966), 366-371.</li>
</ol>

<p>Edsger W. Dijkstra,<br>Technological University Eindhoven,<br>The Netherlands</p>

  </section>

    


  
</article></div>]]>
            </description>
            <link>https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652958</guid>
            <pubDate>Thu, 01 Oct 2020 16:33:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the “Compiling a Lisp” series. Last time we added a reader
(also known as a parser) to our compiler. This time we’re going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> — the
rest of the S-expression — and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it’s a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It’s <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness’ sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You’ll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>“Environment” is just a fancy word for “look-up table”. In order to implement
this table, we’re going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we’re using this data structure to implement
environments. Didn’t I even take a data structures course in college?
Shouldn’t I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we’re also compiling small <em>programs</em>,
we’ll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we’ll first draw up an association list. We’ll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I’ve done the usual thing and overloaded <code>Env</code> to mean both “a node in the
environment” and “a whole environment”. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we’re
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We’ll learn more about why later, but the
“TL;DR” is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let’s learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it’s equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we’re <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you’ve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we’ve got names and data structures. Let’s implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we’re
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let’s go ahead and compile the expressions
that bind them.</p>

<p>We’ll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It’s a bit of a misnomer, since it’s not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We’ll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we’re
evaluating the expressions that we’re binding the names to, we can’t add
bindings iteratively. We have to evaluate them in the parent environment. It’ll
be come clearer in a moment how that works.</p>

<p>We’ll tackle the simple case first — no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We’ll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We’re compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don’t want the previous bindings to be visible.</p>

<p>Once we’ve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we’re binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we’ve done all the work required for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Data Science Pull Requests– Review and merge code, data and experiments]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24652832">thread link</a>) | @Dean-DAGsHub
<br/>
October 1, 2020 | https://dagshub.com/blog/data-science-pull-requests/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-science-pull-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="a-step-forward-for-mlops-and-unlocking-open-source-data-science">A step forward for MLOps and unlocking Open Source Data Science</h3><p>Today, we're releasing Data Science Pull Requests (DS PRs), which are Pull Requests (PRs), re-imagined for the data science (DS) workflow. This new capability unlocks a standard review process for data science teams, enabling them to merge data across different branches and accept data contributions across forks. This provides a better collaborative experience for teams in data science organizations and enables truly Open Source Data Science (OSDS) projects. </p><p>For more details, read on...</p><h2 id="introduction">Introduction</h2><p>When we started DAGsHub, we were focused on making data science collaboration possible. Specifically, we deeply <em>care</em> and <em>rely on</em> Open Source Software (OSS), and we set out on a mission to make OSDS as accessible and prevalent as OSS is today.</p><p>This meant that we were concerned about <strong><em>discoverability </em></strong>of data science projects and experiments to work on, <strong><em>understandability</em></strong> of the context of an experiment, <strong><em>reproducibility</em> of </strong>its results, and finally, <strong><em>contributability</em></strong> of code-, data- and models- changed back to the original project.</p><p>When reviewing these processes and the existing solutions some things become clear:</p><ul><li><em><strong>Discoverability </strong></em>means being able to answer the question "<em>What should I do next?</em>" – finding a project to work on, and within that project finding what experiments might be interesting or important. <br>It is solved mainly by <strong>experiment tracking</strong> systems, many of them using proprietary or black box formats that are hard to understand and migrate to/from.<p>DAGsHub goes beyond this by creating an experiment tracking system that relies on simple open formats (<code>YAML</code> and <code>CSV</code>). This means you don't need to add obscure lines of code – everything works by automatically scanning and analyzing the git commits pushed into the platform.</p></li><li><em><strong>Understandability</strong></em> means being able to answer the question "<em>How should I do what I want to do?</em>" – this usually consists of reviewing why, how, and what was already done in a project or experiment. The solution for this step is mostly manual and relies on self-documenting one's work and discussions with collaborators.<p>DAGsHub improves on this by providing a convenient interface into projects' code, data, models, and pipelines which give users a window into their projects' components, and how they interact with each other.</p></li><li><em><strong>Reproducibility</strong></em> means setting up an exact copy of the experiment you want to work on. Many times this process is reduced to a Git commit and the experiment parameters (logged in the experiment tracking system). However, the true standard for reproducibility involves <em><strong>easily </strong></em>retrieving the same version of data, models, and other artifacts. It is best solved by using Git with some dedicated data versioning solution.<p>DAGsHub solves this by relying on open source tools such as Git and DVC to provide the standard discussed above – a complete copy of your project (code, data, models, parameters, and other artifacts) with one (or two) commands.</p></li><li><em><strong>Contributability</strong></em> means that you can take a new experiment or result, and incorporate them back into the project you started from so that you don't need to maintain your result separately. Today, this is entirely manual, full of friction, and fundamentally <strong>non-existent</strong>.</li></ul><p>We have many more things to build, but it was clear that one aspect needed to be covered first – a <strong><em>CONTRIBUTION </em></strong>mechanism.</p><h2 id="contributing-data-science-pull-requests">Contributing – Data Science Pull Requests</h2><p>The final step of the collaborative process is arguably the most important one. Without it, the workflow is one-sided, a monologue, which means collaboration isn't happening. Practically, <strong><em>Contributing</em></strong> can be broken down into two tasks - <strong>reviewing</strong> and <strong>merging </strong>contributions.</p><p>In software, both reviewing and merging are a part of the <strong>pull request</strong> process, but their focus was solely on code. </p><blockquote>Data Science Pull Requests let you <strong>review experiments<u>,</u></strong> <strong>code, data, models, </strong>and your<strong> pipelines</strong>, and <strong><u>merge changes to all of them automatically.</u></strong> </blockquote><h3 id="data-science-review">Data Science Review</h3><p>If you've ever worked on a data science project with other people or tried reviewing someone else's data science work, you know how hard it is to get the information you need to understand someone else's work, or explain your own, so that the review process is meaningful. The process is slow and manual because systems are not built for review.</p><p>An automatic review process means changes and updates can be discussed and integrated faster into your project.<strong> You need to quickly see what has changed, discuss it, in context, and decide how to move forward.</strong></p><p>What this means in practice:</p><ul><li>Commenting on experiments, in context – you can look at the new experiments that are being contributed as part of the DS PR, and compare them to the base experiment in the original project. See all the visualization and information, and add comments on these within the PR discussion with links to the relevant comparison/visualization.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/exp-comment-long-hq.gif" alt="Commenting on experiments"><figcaption>Commenting on experiments in DS PRs</figcaption></figure><ul><li>See what data and models have changed (not just code) – view what data, model, and artifact files were added, removed, or modified. This means you can easily pinpoint changes and focus the discussion on what's important.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png" alt="Viewing data changes in a DAGsHub project" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1189w" sizes="(min-width: 720px) 720px"><figcaption>Data Comparison Example</figcaption></figure><ul><li>Compare and diff notebooks side-by-side – notebooks are an important part of many data science projects. However, for a very long time, they haven't received adequate treatment in the review process, relying on diffs to the raw <code>JSON</code> file, which were mostly unreadable. You can now review the changes in an intuitive UI as part of the DS PR. Another benefit of this is that if you require a special visualization, you can commit a notebook with that visualization, and view the changes conveniently.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png" alt="Notebook comparison" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 2298w" sizes="(min-width: 720px) 720px"><figcaption>Notebook Diffing Example</figcaption></figure><p>After reviewing a collaborator's work, we need a way to incorporate those changes, automatically. That's why we built data science merging.</p><h3 id="data-science-merging">Data Science Merging</h3><p>Merging code is possible with Git, but as we already discussed, that is not the full picture for data science projects. With DS PRs, you can merge your data and other artifacts as well. </p><h4 id="data-merging">Data Merging</h4><p>Everyone knows about bugs in code, but you might also have data bugs that you're not aware of. Examples include data that is not up to date, biased, or mislabeled. Assuming you found out about such a bug and you wanted to fix it – that would usually mean you need to agree on and perform some manual operation to update or add new data. With data merging, once you accept a DS PR, the new data would automatically be copied into your project in an entirely automatic process.</p><h4 id="artifact-merging">Artifact Merging</h4><p>This doesn't end with just the <em>raw data – </em>data merging lets you merge models and any other artifact of your data pipeline (e.g. preprocessed data or 3d models). Take a case where one of the steps in a pipeline takes 2 weeks to run and results in some trained model or a processed dataset. If only raw data was merged, you'd have to run that excruciating 2-week process again. Artifact merging means that after a DS PR is merged, the resulting project is as reproducible as the original contribution.</p><p>After accepting a DS PR you are in the same state of your DS project, as you would after accepting a PR in a software project.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png" alt="Data Merging on DAGsHub" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1846w" sizes="(min-width: 720px) 720px"><figcaption>Data Science Merging – Note that 171 MB of data will be copied on accepting this DS PR</figcaption></figure><p>Data merging means you can accept data and models from contributors with ease, without giving each one full access to your data storage. This can reduce friction and speed up team efforts.</p><p>This last capability is especially useful for OSDS.</p><h2 id="what-does-this-mean-for-osds">What does this mean for OSDS?</h2><p><a href="https://dagshub.com/blog/a-case-for-open-source-data-science/">Open Source Data Science (OSDS) has the potential to have a similar effect on the world</a>, as Open Source Software (OSS) had. It is DAGsHub's stated goal to promote OSDS and build the technology to make it as easy as possible. OSDS must come first, and industry workflows will mirror those in OSDS projects, as they have for OSS. </p><p>But let's face it – OSDS doesn't <em>really</em> exist yet. If you maintain some OSDS project and you want to accept contributions from people (like you would for OSS) – you have to do it entirely manually or <strong>resort to accepting only code changes</strong> (no way to accept data bug fixes – and we all know there are plenty).</p><p>From the individual contributor side, if you want to improve your ML portfolio by contributing to some OSDS project, you're also stuck. You have to either fork the project and not contribute your changes (which means their quality is never reviewed – you don't learn as much) or go through a painstaking manual effort<sup>[1]</sup>.</p><blockquote>DS PRs make OSDS possible by providing a standard interface and workflow to review and accept contributions from anyone, anywhere, and for any type of data science component.</blockquote><p><strong>We'd love to support open source data science projects that want to accept data science contributions from the community. Please reach out to us at <a href="mailto:osds@dagshub.com">osds@dagshub.com</a> if this is relevant for you.</strong></p><h2 id="thank-you-">Thank You!</h2><p>Thank you to all the people that gave us feedback before and while we were building DS PRs. We'd love to get your feedback as well on how DS PRs could be improved for the community – the best way to do this is to join our <a href="https://discord.com/invite/9gU36Y6">Discord channel</a>. Looking forward to hearing your thoughts and seeing what people build with open source data science.</p><hr><!--kg-card-begin: markdown--><p>
[1] Kaggle is worth a mention here – It is a common way to show some of your DS chops. However, it's competitive (as opposed to collaborative). Furthermore, data science projects in the wild rarely have one all-encompassing metric to optimize at the expense of everything else - 80% of the work is just gathering data and deciding what is even worth optimizing! 
Our goal with DAGsHub is to enable a collaborative way to showcase your capabilities while encouraging interoperability – i.e. working together rather than everyone doing their own thing and ending up with a ton of fragmentation.
</p><!--kg-card-end: markdown-->
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science-workflow/" title="Data Science Workflow">Data Science Workflow</a>
                      </li>
                      <li>
               …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-science-pull-requests/">https://dagshub.com/blog/data-science-pull-requests/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-science-pull-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652832</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at PostGIS vs. Geocoder in Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652608">thread link</a>) | @leighhalliday
<br/>
October 1, 2020 | https://pganalyze.com/blog/postgis-rails-geocoder | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgis-rails-geocoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
This article sets out to compare PostGIS in Rails with Geocoder and to highlight a couple of the areas where you'll want to (or need to) reach for one over the other. I will also present some of the terminology and libraries that I found along the way of working on this project and article as I set out to understand PostGIS better and how it is integrated with Rails.</p>

<p><span>
      <span></span>
  <img alt="PostGIS vs. Geocoder in Rails" title="PostGIS vs. Geocoder in Rails" src="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg" srcset="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e52aa/postgis_rails_geocoder_pganalyze.jpg 175w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/70ebb/postgis_rails_geocoder_pganalyze.jpg 350w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg 700w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/9ecec/postgis_rails_geocoder_pganalyze.jpg 1050w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e5166/postgis_rails_geocoder_pganalyze.jpg 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span>
Picture via <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> on Unsplash</p>
<p>I have built a number of Rails applications over the years that show locations on a map, have nearby search functionality, and I had never used <a href="https://postgis.net/">PostGIS</a> before! How was this possible? The reason is that there is a Ruby gem named <a href="https://github.com/alexreisner/geocoder">Geocoder</a> which enables you to do these sorts of queries, and it's quite efficient! That said, there is a reason that PostGIS exists. For more complex geo queries I’d recommend reaching beyond Geocoder to PostGIS.</p>
<p>As an example, if you wanted to find homes which have a school within 1km of them, or if you wanted to draw an oddly shaped polygon on a map and search within it, this is the world where PostGIS shines and makes these complex geo queries possible.</p>
<p>In this article we will be covering:</p>
<ul>
<li>PostGIS in Rails setup</li>
<li>Finding nearby records (Geocoder + PostGIS)</li>
<li>Finding records within a bounding box (Geocoder + PostGIS)</li>
<li>Finding records within a polygon (PostGIS)</li>
<li>Finding nearby related records (PostGIS)</li>
</ul>
<p>The source code referenced in this article can be <a href="https://github.com/pganalyze-resources/rails-postgis-demo">found here</a>.</p>
<h2 id="installing-postgis"><a href="#installing-postgis" aria-label="installing postgis permalink"></a>Installing PostGIS</h2>
<p>Postgres comes with a number of built-in extensions that you can enable, but unfortunately PostGIS (Spatial and Geographic objects for Postgres) isn't one of them. In order to enable this extension, you will have to use a Postgres install with PostGIS support. I recommend using the <a href="https://registry.hub.docker.com/r/postgis/postgis">official postgis docker image</a>, but luckily many hosted Postgres solutions come with PostGIS already available. If you are not sure, you can query the available extensions with the following query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span>
<span>from</span> pg_available_extensions
<span>where</span> name <span>like</span> <span>'%postgis%'</span></code></pre></div>
<p>If you'd like to see if the extension is <em>already</em> enabled, you can run this query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> pg_extension</code></pre></div>
<p>And finally, to enable this extension, you can use the command <code>create extension postgis</code>, but since we're working within Rails, there is a Gem that will take care of this step for us as we'll see below.</p>
<h2 id="activerecord-postgis-adapter"><a href="#activerecord-postgis-adapter" aria-label="activerecord postgis adapter permalink"></a>ActiveRecord PostGIS Adapter</h2>
<p>If you have confirmed that your version of Postgres supports the <code>postgis</code> extension, you're ready to integrate it with your Rails application. This can be done by using the <a href="https://github.com/rgeo/activerecord-postgis-adapter">activerecord-postgis-adapter</a> gem. Two things need to be done to get up and running. The first is to update the <code>adapter</code> within <code>config/database.yml</code> to be set to <code>postgis</code>. Next, if this is a new application, you can run <code>rails db:create</code> as normal, but if it is an existing one, you'll have to run the command <code>rake db:gis:setup</code>. This command is enabling the postgis extension in your database.</p>
<h2 id="our-example-data"><a href="#our-example-data" aria-label="our example data permalink"></a>Our Example Data</h2>
<p>We'll be working with sample data for a realtor website that allows us to find homes in a variety of ways, including homes that are nearby a local school. There are two models: <code>homes</code> and <code>schools</code>. The Rails migration to create these tables is below:</p>
<div data-language="ruby"><pre><code><span>class</span> <span>CreateHomes</span> <span>&lt;</span> <span>ActiveRecord</span><span>:</span><span>:</span><span>Migration</span><span>[</span><span>6.0</span><span>]</span>
  <span>def</span> <span><span>change</span></span>
    create_table <span>:homes</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>string <span>:name</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>string <span>:status</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>bigint <span>:price</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>integer <span>:beds</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>integer <span>:baths</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>
      t<span>.</span>float <span>:longitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>float <span>:latitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>timestamps

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>index <span>%i[latitude longitude]</span>
      t<span>.</span>index <span>:status</span>
      t<span>.</span>index <span>:price</span>
    <span>end</span>

    create_table <span>:schools</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>timestamps
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>By using <code>activerecord-postgis-adapter</code> we are able to define PostGIS columns within our migration file. When working with PostGIS you can store a point (latitude + longitude) as a single column of type <code>ts_point</code>, whereas when working with <a href="https://github.com/alexreisner/geocoder">Geocoder</a> the latitude and longitude are stored as floats in separate columns. Because we are comparing the two approaches, we will store the data both ways, but typically you would choose one approach or the other.</p>
<p>PostGIS <strong>geographic</strong> columns can be indexed using <a href="https://www.postgresql.org/docs/current/gist-intro.html">GiST</a> style indexes. GiST indexes are required over B-Tree indexes when working with geographic data because coordinates cannot be easily sorted along a single axis (such as numbers, letters, dates, etc...) in a way that would allow the database to speed up common geographic operations.</p>
<p>The example project for this article contains a seeds file (run with <code>rake db:seed</code>) which will generate 100k homes and 100 schools in and around the Atlanta, Georgia area.</p>
<h2 id="building-a-geo-helper-class-with-postgis"><a href="#building-a-geo-helper-class-with-postgis" aria-label="building a geo helper class with postgis permalink"></a>Building a Geo Helper Class with PostGIS</h2>
<p>The Rails PostGIS adapter is based on a library named <a href="https://github.com/rgeo/rgeo">RGeo</a>, which while incredibly powerful, I found a little bit confusing due to a lack of documentation. I ended up building a small helper class to generate different geo objects for me. The first thing to point out is what <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">SRID</a> is. Just like the imperial and metric systems are used to measure and weigh amounts using an agreed upon reference point, coordinates also need a coordinate reference system to ensure that the latitude and longitude that one uses means the same thing to different people when referring to a single place on earth. <a href="https://spatialreference.org/ref/epsg/wgs-84/">4326</a> is the spatial system used for GPS satellite navigation systems and the one we will be using within this article.</p>
<p>One last thing to define is what <a href="https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry">WKT</a> is. Well-known Text representation of geometry is a string representation of a point, line string, and polygon (among other things) that we will be using in our examples in this article. This is the format Postgres (PostGIS) receives and displays geographic data types in.</p>
<div data-language="ruby"><pre><code><span>class</span> <span>Geo</span>
  <span>SRID</span> <span>=</span> <span>4326</span>

  <span>def</span> <span><span>self</span><span>.</span><span>factory</span></span>
    <span>@@factory</span> <span>||</span><span>=</span> <span>RGeo</span><span>:</span><span>:</span><span>Geographic</span><span>.</span>spherical_factory<span>(</span>srid<span>:</span> <span>SRID</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>pairs_to_points</span></span><span>(</span>pairs<span>)</span>
    pairs<span>.</span>map <span>{</span> <span>|</span>pair<span>|</span> point<span>(</span>pair<span>[</span><span>0</span><span>]</span><span>,</span> pair<span>[</span><span>1</span><span>]</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>point</span></span><span>(</span>longitude<span>,</span> latitude<span>)</span>
    factory<span>.</span>point<span>(</span>longitude<span>,</span> latitude<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>line_string</span></span><span>(</span>points<span>)</span>
    factory<span>.</span>line_string<span>(</span>points<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>polygon</span></span><span>(</span>points<span>)</span>
    line <span>=</span> line_string<span>(</span>points<span>)</span>
    factory<span>.</span>polygon<span>(</span>line<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>to_wkt</span></span><span>(</span>feature<span>)</span>
    <span>"srid=<span><span>#{</span><span>SRID</span><span>}</span></span>;<span><span>#{</span>feature<span>}</span></span>"</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h2 id="finding-nearby-records-with-postgis-and-geocoder"><a href="#finding-nearby-records-with-postgis-and-geocoder" aria-label="finding nearby records with postgis and geocoder permalink"></a>Finding Nearby Records with PostGIS and Geocoder</h2>
<p>One of the most common geo queries used in applications is to find all records within X distance from a known point (the user's location, an event, a search, etc...). Because we installed <code>Geocoder</code> and added <code>reverse_geocoded_by :latitude, :longitude</code> to our <code>Home</code> class, we can use the <code>nearby</code> method to find all homes within 5km of this latitude and longitude (which happens to be Atlanta, Georgia). Geocoder likes to have arrays with latitude and then longitude, as opposed to PostGIS which <strong>prefers the exact opposite</strong> order!</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>near<span>(</span><span>[</span><span>33.753746</span><span>,</span> <span>-</span><span>84.386330</span><span>]</span><span>,</span> <span>5</span><span>)</span><span>.</span>count<span>(</span><span>:all</span><span>)</span> </code></pre></div>
<p>This query ran in about 5ms on my computer (searching through 100k records)... pretty fast! The reason it is fast is because we added an index on the latitude and longitude fields, but also because Geocoder applies a bounding box filter which utilises the index. Remember the Spatial Reference System (SRID) that we mentioned above? Because our coordinates do not take place on a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian plane</a>, we can’t use a standard distance formula to calculate the <a href="https://www.mathsisfun.com/algebra/distance-2-points.html">distance between two points</a>. Although we won’t venture further into the math of this query below, it takes into consideration the Earth’s spherical nature when calculating the distance between two coordinates as specified by latitude and longitude. <a href="https://www.movable-type.co.uk/scripts/latlong.html">This article</a> dives into more detail on these calculations if you are interested.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.708779919704064</span> <span>AND</span> <span>33.798712080295935</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.44041260768655</span> <span>AND</span> <span>-</span><span>84.33224739231345</span> <span>AND</span> <span>(</span><span>6371.0</span> <span>*</span> <span>2</span> <span>*</span> ASIN<span>(</span>SQRT<span>(</span>POWER<span>(</span>SIN<span>(</span><span>(</span><span>33.753746</span> <span>-</span> homes<span>.</span>latitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span> <span>+</span> COS<span>(</span><span>33.753746</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> COS<span>(</span>homes<span>.</span>latitude <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> POWER<span>(</span>SIN<span>(</span><span>(</span><span>-</span><span>84.38633</span> <span>-</span> homes<span>.</span>longitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>BETWEEN</span> <span>0.0</span> <span>AND</span> <span>5</span><span>)</span></code></pre></div>
<p>We'll have to build our own <code>near</code> query when working with PostGIS, but don't worry, it's pretty straight forward! The <code>g_near</code> method lives within the <code>Home</code> model, and takes advantage of the <a href="https://postgis.net/docs/ST_DWithin.html">ST_DWithin</a> function provided by PostGIS. Remember that we have to convert our point into the correct WKT format so that PostGIS understands the data we are passing it.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_near</span></span><span>(</span>point<span>,</span> distance<span>)</span>
  where<span>(</span>
    <span>'ST_DWithin(coords, :point, :distance)'</span><span>,</span>
    <span>{</span> point<span>:</span> <span>Geo</span><span>.</span>to_wkt<span>(</span>point<span>)</span><span>,</span> distance<span>:</span> distance <span>*</span> <span>1000</span> <span>}</span> 
  <span>)</span>
<span>end</span>

<span>Home</span><span>.</span>g_near<span>(</span><span>Geo</span><span>.</span>point<span>(</span><span>-</span><span>84.386330</span><span>,</span> <span>33.753746</span><span>)</span><span>,</span> <span>5</span><span>)</span><span>.</span>count </code></pre></div>
<p>This query performs just about as fast as the Geocoder version (because of our GiST index on the <code>coords</code> column), but is definitely a little easier on the eyes to read.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>ST_DWithin<span>(</span>coords<span>,</span> <span>'srid=4326;POINT (-84.38633 33.753746)'</span><span>,</span> <span>5000</span><span>)</span><span>)</span></code></pre></div>
<h2 id="finding-records-within-a-bounding-box-with-postgis-and-geocoder"><a href="#finding-records-within-a-bounding-box-with-postgis-and-geocoder" aria-label="finding records within a bounding box with postgis and geocoder permalink"></a>Finding Records Within a Bounding Box with PostGIS and Geocoder</h2>
<p>Geocoder provides us a way to find all records within a bounding box (roughly a rectangle, ignoring projection onto a sphere), and we just have to pass it the bottom left (south west) and top right (north east) coordinates.</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>within_bounding_box<span>(</span>
  <span>[</span><span>33.7250057553</span><span>,</span> <span>-</span><span>84.4224209302</span><span>]</span><span>,</span>
  <span>[</span><span>33.774350796</span><span>,</span> <span>-</span><span>84.3570139222</span><span>]</span>
<span>)</span><span>.</span>count </code></pre></div>
<p>Because it can use the index on latitude and longitude, it is quite efficient.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.7250057553</span> <span>AND</span> <span>33.774350796</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.4224209302</span> <span>AND</span> <span>-</span><span>84.3570139222</span><span>)</span></code></pre></div>
<p>To perform a bounding box query using PostGis, we'll create a method named <code>g_within_box</code> inside of the <code>Home</code> model, and utilize a PostGIS function named <a href="https://postgis.net/docs/ST_MakeEnvelope.html">ST_MakeEnvelope</a> along with the <code>&amp;&amp;</code> operator.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_within_box</span></span><span>(</span>sw_point<span>,</span> ne_point<span>)</span>
  where<span>(</span>
    <span>"coords &amp;&amp; ST_MakeEnvelope(:sw_lon, …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgis-rails-geocoder">https://pganalyze.com/blog/postgis-rails-geocoder</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgis-rails-geocoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652608</guid>
            <pubDate>Thu, 01 Oct 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building your own air pollution monitor with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24652488">thread link</a>) | @stevenhubertron
<br/>
October 1, 2020 | https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>With all the wildfires happening around the US this summer (2020) I finally got motivated enough to put together an air quality monitor home base station to see air quality in person, on the web and on my phone. &nbsp;If you has a Raspberry Pi plus a few other items you can set this up in an afternoon. I have it tuned to measure PM1.0, PM2.5, PM10, and Carbon Monoxide inside my house. </p><p>As an example, here is what I see in my Adafruit Dashboard</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1000w, https://www.drkpxl.com/content/images/size/w1600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1600w, https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 2024w" sizes="(min-width: 720px) 720px"><figcaption>My Adafruit dashboard.&nbsp;</figcaption></figure><p>I already had most of the the supplies but here is a list of what you will need:</p><ul><li><a href="https://shop.pimoroni.com/products/raspberry-pi-zero-wh-with-pre-soldered-header">Raspberry Pi Zero WH</a></li><li><a href="https://shop.pimoroni.com/products/enviro?variant=31155658489939">Enviro+</a></li><li><a href="https://shop.pimoroni.com/products/pms5003-particulate-matter-sensor-with-cable">PMS50003</a> Particulate Matter Sensor with cable</li><li>A free <a href="https://io.adafruit.com/">Adafruit IO</a> account</li></ul><p>Once you get it all plugged into, the Enviro+ into the Pi, and the PMS5003 into the Enviropi you can get the OS setup with a standard install.</p><p>I'll assume you know how to get Raspberry setup on your PI as well as SSH into it. If not there are a great number of <a href="https://desertbot.io/blog/headless-raspberry-pi-4-ssh-wifi-setup">tutorials</a> <a href="https://www.tomshardware.com/reviews/raspberry-pi-headless-setup-how-to,6028.html">out</a> <a href="https://medium.com/@jay_proulx/headless-raspberry-pi-zero-w-setup-with-ssh-and-wi-fi-8ddd8c4d2742">there</a>.</p><p>Once you are SSHed in, you can follow along with the instructions on the Pimoroni site or just run this script after an <code>apt upgrade</code> and <code>apt update</code></p><pre><code>git clone https://github.com/pimoroni/enviroplus-python
cd enviroplus-python
sudo ./install.sh</code></pre><p>This will install all the various code and samples to get playing with the sensors. The Enviro+ has a bunch of different sensors and LCDs in one making it extremely easy.</p><p>My goals for the setup are:</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5163-1.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5163-1.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg 1500w" sizes="(min-width: 720px) 720px"></figure><h3 id="lcd">LCD</h3><p>The LCD displays PM10, PM2.5 and PM1, temp, and noise level on the screen by default. If the pollution spikes, or the gas spikes the LCD will turn red and display a warning.</p><h3 id="adafruit-io">Adafruit IO</h3><p>All the LCD data <strong>plus</strong> Carbon Monoxide, CPU Temp, and CPU load so that I just have a view that everything is healthy on the Pi.</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5168.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5168.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg 1123w" sizes="(min-width: 720px) 720px"></figure><h3 id="ifttt">IFTTT</h3><p>Push alerts to high pollution or gas to my phone so I can be notified immediately if something is at issue.</p><h2 id="key-code-snippets">Key Code Snippets</h2><h3 id="get-the-cpu-temp">Get the CPU Temp</h3><figure><pre><code>def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())</code></pre><figcaption>Get CPU temp, convert to F and send both temp and usage to Adafruit</figcaption></figure><h3 id="get-noise">Get Noise</h3><figure><pre><code>def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))</code></pre><figcaption>Get noise within a wide range, round it and send off to display and Adafruit</figcaption></figure><h3 id="get-ambient-temps-w-corrections">Get Ambient Temps w/ Corrections</h3><pre><code>def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array so it doesn't overflow memory
    if (len(cpu_temps) &gt; 10):
        cpu_temps.pop(0)
        aio.send('temp', tempf)</code></pre><p>The thing you would think would be the easiest is actually the hardest due mainly to the fact the themometer is so close to the CPU that it's picking up ambient heat from it. What this does (and is heavily cribbed from the Pimoroni example) is use the CPU temp as a baseline measure that fills up an array, correct for it and convert it to F. Since this "app" is basically one big loop I want to clear the array out after 10 readings or 10 minutes. That should give me enough history to get a good average and the temps I see pass the gut check. </p><p>The <code>factor</code> float may need to be adjusted for your specfic needs. For example if you don't have the Pi in a Lego case, or have different airflow the factor you need to adjust it to may need to be different. </p><h3 id="get-gas-specfically-reducing-aka-carbon-monoxide">Get Gas, specfically Reducing AKA Carbon Monoxide </h3><figure><pre><code>def gas_func():
    global gas_reading, gas_average, gas_warning_amount
    # Get Gas
    gas_reading = gas.read_all()
    gas_array.append(gas_reading.reducing)
    # If the array is larger than 8 items dump the first one
    if (len(gas_array) &gt; 8):
        gas_array.pop(0)
        #print("Popped!")
        aio.send('gas', round(gas_reading.reducing))
    gas_average = (sum(gas_array) / len(gas_array))
    gas_warning_amount = str(round(gas_reading.reducing))
</code></pre><figcaption>Get an average gas reading, current reading and send to Adafruit</figcaption></figure><h3 id="get-air-pollution">Get Air Pollution</h3><figure><pre><code>def pollution_func():
    global pm25, pm10_display, pm25_display, pm1_display
    # Read Particulate Matter
    readings = pms5003.read()
    pm25 = readings.pm_ug_per_m3(2.5)
    pm10 = readings.pm_ug_per_m3(10)
    pm1 = readings.pm_ug_per_m3(1)
    # Send to Adafruit
    aio.send('pollution.pm25', pm25)
    aio.send('pollution.pm1', pm1)
    aio.send('pollution.pm10', pm10)
    # Draw on Screen
    pm10_display = "PM10: " + str(pm10) + " ug/m3"
    pm25_display = "PM25: " + str(pm25) + " ug/m3"
    pm1_display = "PM10: " + str(pm1) + " ug/m3"</code></pre><figcaption>Get the standard ug/m3 readings, send to Adafruit and display</figcaption></figure><h3 id="display-logic">Display Logic</h3><pre><code># Display output of sensors on display
        disp.set_backlight(1)
        if (gas_reading.reducing &gt; (gas_average * 1.05) and len(gas_array) == 8):
            print("High Pollution Warning")
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), gas_warning_amount, font=font, fill=text_colour)
        elif (pm25 &gt; 50):
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), pm25_display, font=font, fill=text_colour)
        else:
            draw.rectangle((0, 0, 160, 80), back_colour)
            draw.text((0, 0), pm10_display, font=font, fill=text_colour)
            draw.text((0, 20), pm25_display, font=font, fill=text_colour)
            draw.text((0, 40), pm1_display, font=font, fill=text_colour)
            draw.text((0, 60), tempf_display, font=font, fill=text_colour)
            draw.text((80, 60), noise_display, font=font, fill=text_colour)
        disp.display(img)
        time.sleep(60)</code></pre><p>This is a basic if else statement that has the following rules:</p><ul><li>If gas is higher than the average + 5% (indicating a spike) push an alarm to the Pi's display</li><li>If gas is ok, but PM2.5 pikes over 50 push an alarm to the Pi's display</li><li>Otherwise just show the PM numbers, Temp and Noise</li></ul><p>As you can see it's all pretty straightforward code in one big loop. If you just copy and paste the code following, add your Adafruit key, and do some additional setup in Adafruit IO you can have this up and running very quickly.</p><h2 id="the-complete-code">The Complete Code</h2><pre><code>import psutil
from gpiozero import CPUTemperature
import time
import datetime
from Adafruit_IO import Client
from bme280 import BME280
from enviroplus.noise import Noise
import colorsys
import sys
import ST7735
try:
    # Transitional fix for breaking change in LTR559
    from ltr559 import LTR559
    ltr559 = LTR559()
except ImportError:
    import ltr559

try:
    from smbus2 import SMBus
except ImportError:
    from smbus import SMBus


from pms5003 import PMS5003, ReadTimeoutError as pmsReadTimeoutError, SerialTimeoutError
from enviroplus import gas
from subprocess import PIPE, Popen
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
from fonts.ttf import RobotoMedium as UserFont
from datetime import timedelta



# Initial Setup of sensors / API
bus = SMBus(1)
bme280 = BME280(i2c_dev=bus)
aio = Client('XXX', 'aio_XXX')
pms5003 = PMS5003()
noise = Noise()

# Create LCD class instance.
disp = ST7735.ST7735(
    port=0,
    cs=1,
    dc=9,
    backlight=12,
    rotation=270,
    spi_speed_hz=10000000
)

# Create array for averages
gas_array = []
cpu_temps = []

# Initialize display.
disp.begin()

# Width and height to calculate text position.
WIDTH = disp.width
HEIGHT = disp.height

# New canvas to draw on.
img = Image.new('RGB', (WIDTH, HEIGHT), color=(0, 0, 0))
draw = ImageDraw.Draw(img)

# Text settings.
font_size = 20
small_font_size = 12
font = ImageFont.truetype(UserFont, font_size)
small_font = ImageFont.truetype(UserFont, small_font_size)
text_colour = (255, 255, 255)
back_colour = (0, 0, 0)
#size_x, size_y = draw.textsize(message, font)
warning = "Warning!"

# Calculate text position
#x = (WIDTH - size_x) / 2
#y = (HEIGHT / 2) - (size_y / 2)
x = 0
y = 0


def warm_func():
    currentTime = datetime.datetime.now()
    draw.rectangle((0, 0, 160, 80), (30, 160, 30))
    draw.text((10, 20), "Warming Up", font=font, fill=text_colour)
    draw.text((0, 66), currentTime.strftime("%a, %b %d %I:%M:%S %p"), font=small_font, fill=text_colour)
    disp.display(img)
    print("Warming Up at " + currentTime.strftime("%a, %b %d %I:%M:%S %p"))

def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())

def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))

def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    #print("CPU Temp: " + str(cpu_temp))
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array …</code></pre></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652488</guid>
            <pubDate>Thu, 01 Oct 2020 16:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming Netflix 4K on macOS Big Sur requires a Mac with a T2 security chip]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652462">thread link</a>) | @bangonkeyboard
<br/>
October 1, 2020 | https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/ | <a href="https://web.archive.org/web/*/https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork">
<div id="primary" data-v-spacing="top:bottom">
<div data-sidebar="left">
<section>
<article id="post-17376" data-structure="default:boxed">
<section data-type="type-1">

</section>
<div>
<figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" width="1024" height="576" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-1024x576.jpg" alt="netflix 4k needing a t2 secuirty chip rect 1" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-1024x576.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-300x169.jpg 300w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-768x432.jpg 768w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" title="Streaming Netflix 4K on macOS Big Sur requires a Mac with a T2 security chip 1"></figure>
<p>Safari on macOS Big Sur enables websites to stream content in 4K with supported Mac displays. Given macOS Big Sur is yet to be released, it’s difficult to come to a conclusion on which websites support it and don’t. One that is known to support the feature however is Netflix, with a catch.</p>
<p>Netflix <a href="https://www.macg.co/mac/2020/09/netflix-en-4k-sur-mac-uniquement-pour-les-machines-avec-puce-t2-116775?amp&amp;__twitter_impression=true" target="_blank" rel="noopener">explains</a> in a <a href="https://help.netflix.com/fr-ca/node/55764" target="_blank" rel="noopener">support page</a> that the feature will only be available to Macs with a T2 security chip. It seems unlogical at first, however one <a href="https://www.reddit.com/r/apple/comments/j2cik9/youll_need_a_mac_with_a_t2_chip_to_be_able_to/" target="_blank" rel="noopener">Reddit</a> users tries to make sense of it:</p>
<blockquote><p>This makes zero sense to me. The only Macs, that could really benefit from 4k streaming, without an external monitor, are the 4k and 5k iMacs yet only 2 models (the Pro and the new 2020 27″) will be able to stream it. Windows machines don’t have any kind of T2 alternative and are still able to stream 4k via Edge or via the native app, their only requirement is a 7th gen intel cpu or a dedicated graphics card. Does anyone know why that is?</p></blockquote>
<p>macOS Big Sur has yet to be released to the public, however a launch this month prior to an expected revamp of the Mac lineup, including the first Apple Silicon in November is likely. Here are the supported Macs for streaming 4K Netlfix on macOS Big Sur:</p>
<ul><li>iMac Pro (late 2017)</li><li>Mac mini (late 2018)</li><li>MacBook Air ( 2018 and up)</li><li>MacBook Pro (2018 and up)</li><li>Mac Pro (2019)</li><li>iMac (2020)</li></ul>
</div><nav>
<a href="https://appleterm.com/2020/09/30/apple-says-it-was-doing-anything-to-prevent-fortnite-users-from-using-sign-in-with-apple/">
<figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-912x912.jpg 912w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-550x550.jpg 550w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-470x470.jpg 470w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="0,7.5 5.5,13 6.4,12.1 2.4,8.1 20,8.1 20,6.9 2.4,6.9 6.4,2.9 5.5,2 "></polygon></svg><span></span></figure>
<p><span> Previous <span>Post</span> </span> <span> Emails show Apple had clear intent to disable Sign in with Apple for Fortnite users, contradicting public statements </span></p></a>
<a href="https://appleterm.com/2020/10/01/iphone-12-series-to-include-5-models-not-4-according-to-a-new-report/">
<p><span> Next <span>Post</span> </span> <span> iPhone 12 series to include 5 models, not 4, according to a new report </span></p><figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-912x912.jpg 912w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-550x550.jpg 550w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-470x470.jpg 470w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="14.5,2 13.6,2.9 17.6,6.9 0,6.9 0,8.1 17.6,8.1 13.6,12.1 14.5,13 20,7.5 "></polygon></svg><span></span></figure> </a>
</nav>
</article>
</section>
</div></div></div></div>]]>
            </description>
            <link>https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652462</guid>
            <pubDate>Thu, 01 Oct 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a JavaScript Neural Network in less than 500kb with NectarJS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652389">thread link</a>) | @seraum
<br/>
October 1, 2020 | https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/ | <a href="https://web.archive.org/web/*/https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="527" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4740b1" data-element_type="section">
						<div>
							<div>
					<div data-id="76f1811" data-element_type="column">
			<div>
							<div>
						<div data-id="7c2eb337" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="707" height="707" src="https://nectarjs.com/wp-content/uploads/2020/06/adrien.jpg" alt="" loading="lazy" srcset="https://nectarjs.com/wp-content/uploads/2020/06/adrien.jpg 707w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-300x300.jpg 300w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-150x150.jpg 150w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-570x570.jpg 570w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-510x510.jpg 510w" sizes="(max-width: 707px) 100vw, 707px">											</p>
				</div>
				</div>
				
				
				
				
						</div>
					</div>
		</div>
				<div data-id="13b89b9d" data-element_type="column">
			<div>
							<div>
						
				<div data-id="5b0756a1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Reaching a new milestone in the NectarJS journey,&nbsp;<span>an open source JavaScript native compiler (</span><a href="https://github.com/nectarjs/nectarjs" target="_blank" rel="noopener">Github repo</a><span>).</span></p>
				</div>
				</div>
				
				<div data-id="1d7f6c5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>For the version 0.7, we started a big refactoring of the code, initiated by @saiv46 (on Discord). The objectives were:&nbsp;</span></p><p>– To reach a new level with the EcmaScript compliance</p><p>– To benefit of the new c++17 (and soon c++20) features.</p><p>We achieved a considerable success by covering a major part of ES3 specifications with a much simpler code base. To demonstrate what we can do with NectarJS we lately focus on compiling a Neural Network script written by @wesley1989 (thanks to him).</p></div>
				</div>
				</div>
				
				<div data-id="1c2b6be" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>The script we will compile is a Neural Network using classes, this, Math functions and more. The main algorithm of this script trains a XOR Neural Network.</span></p><p><span>Here is the code:</span></p></div>
				</div>
				</div>
				<div data-id="2eabc88" data-element_type="widget" data-widget_type="elementor-syntax-highlighter.default">
				<div>
			<pre><code>/*
	Neural Network example by @wesley1989
	v1.2
*/

function sigmoid(x) {
  return 1 / (1 + Math.exp(-x));
}

function derivativeOfSigmoid(y){  
  return y * (1 - y); 
}

  class Matrix {
    constructor(rows, cols) {  
      this.rows = rows;
      this.cols = cols;
      this.data = [];
      for (let i = 0; i &lt; this.rows; i++) {
          this.data[i] = [];
        for (let j = 0; j &lt; this.cols; j++) {
          this.data[i][j] = Number(((Math.random() * 2) - 1).toFixed(2)); 
        }
      }           
    }

    static transposeMatrix(matrix) {
      let result = new Matrix(matrix.cols, matrix.rows);
      for (let i = 0; i &lt; matrix.rows; i++) {
        for (let j = 0; j &lt; matrix.cols; j++) {
          result.data[j][i] = matrix.data[i][j];
        }
      }
      return result;
    }
  
    static dotProduct(matrix1, matrix2) {
      if (matrix1.cols !== matrix2.rows) {
        return 1;
      } 
      let result = new Matrix(matrix1.rows, matrix2.cols); 
      for (let i = 0; i &lt; result.rows; i++) {
        for (let j = 0; j &lt; result.cols; j++) {
          let sum = 0;
          for (let k = 0; k &lt; matrix1.cols; k++) {
            sum = sum + matrix1.data[i][k] * matrix2.data[k][j];
          }
            result.data[i][j] = sum;
            result.data[i][j] = Number((result.data[i][j]).toFixed(2))
        }
      }
       return result;
    }

    static fromArray(arr) {
      let m = new Matrix(arr.length, 1);
      for (let i = 0; i &lt; arr.length; i++) {
        m.data[i][0] = Number((arr[i]).toFixed(2));
      }
      return m;
    }
  
    static subtract(a, b) {
      let result = new Matrix(a.rows, a.cols);
      for (let i = 0; i &lt; result.rows; i++) {
        for (let j = 0; j &lt; result.cols; j++) {
          var sub = a.data[i][j] - b.data[i][j]
          result.data[i][j] = Number((sub).toFixed(2));
        }
      }
      return result;
    }
    
    static map(matrix, activation) {
      let result = new Matrix(matrix.rows, matrix.cols);
      for (let i = 0; i &lt; matrix.rows; i++) {
        for (let j = 0; j &lt; matrix.cols; j++) {
          result.data[i][j] = Number((activation(matrix.data[i][j])).toFixed(2));
        }
      }
      return result;
    }
  
    toArray() {
      let arr = [];
      for (let i = 0; i &lt; this.rows; i++) {
        for (let j = 0; j &lt; this.cols; j++) {
          arr.push(this.data[i][j]);
        }
      }
      return arr;
    }
    
    add(n) {
      if (n instanceof Matrix) {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] = this.data[i][j] + n.data[i][j];
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      } else {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] =this.data[i][j] + n;
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      }
    }
  
    multiply(n) {  
      if (n instanceof Matrix) {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] = this.data[i][j] * n.data[i][j];
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      } else {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt;  this.cols; j++) {
            this.data[i][j] = this.data[i][j] * n;
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      }
    }

    map(otherFunction) {
      for (let i = 0; i &lt; this.rows; i++) {
        for (let j = 0; j &lt; this.cols; j++) {
          this.data[i][j] = Number((otherFunction(this.data[i][j])).toFixed(2));
        }
      }
    }
  }

class NeuralNetwork {

  // length of input
  // length of output
  constructor(input_length, output_length) {
    // weights = (input length + output length) times 2 
    // for a better nn training
    this.weights_1 = new Matrix((input_length + output_length) * 2, input_length);
    this.weights_2 = new Matrix(output_length, (input_length + output_length) * 2); 
    this.bias_1 = new Matrix((input_length + output_length) * 2, 1);
    this.bias_2 = new Matrix(output_length, 1);
    this.learning_rate = 0.9;  
  }

  feed_forward(inputs) {
    let inputs_from = Matrix.fromArray(inputs);
    let hidden = Matrix.dotProduct(this.weights_1, inputs_from);
    hidden.add(this.bias_1);
    hidden.map(sigmoid);
    let output = Matrix.dotProduct(this.weights_2, hidden);
    output.add(this.bias_2);
    output.map(sigmoid);
    return output.toArray();
  }

  // feedforward with backpropagation
  train(input_array, target_array) {  
    let inputs = Matrix.fromArray(input_array);

    let hidden = Matrix.dotProduct(this.weights_1, inputs);  
    hidden.add(this.bias_1);
    hidden.map(sigmoid);
    
    let outputs = Matrix.dotProduct(this.weights_2, hidden);
    outputs.add(this.bias_2);
    outputs.map(sigmoid); 

    
    let targets = Matrix.fromArray(target_array);
    let output_errors = Matrix.subtract(targets, outputs);

    let gradients = Matrix.map(outputs,derivativeOfSigmoid);
    gradients.multiply(output_errors);
    gradients.multiply(this.learning_rate);

    let hidden_transposed = Matrix.transposeMatrix(hidden);
  
    let weights_2_deltas = Matrix.dotProduct(gradients, hidden_transposed);

    this.weights_2.add(weights_2_deltas);
    this.bias_2.add(gradients);
    let who_t = Matrix.transposeMatrix(this.weights_2);
    let hidden_errors = Matrix.dotProduct(who_t, output_errors);
    
    let hidden_gradient = Matrix.map(hidden,derivativeOfSigmoid);
    hidden_gradient.multiply(hidden_errors);
    hidden_gradient.multiply(this.learning_rate);

    let inputs_transposed = Matrix.transposeMatrix(inputs);
    let weights_1_deltas = Matrix.dotProduct(hidden_gradient, inputs_transposed);
    this.weights_1.add(weights_1_deltas);
    this.bias_1.add(hidden_gradient);
  }

}

function shuffle(a) {
  var j, x, i;
  for (i = a.length - 1; i &gt; 0; i--) {
      j = Math.floor(Math.random() * (i + 1));
      x = a[i];
      a[i] = a[j];
      a[j] = x;
  }
  return a;
  }

// XOR example
// NeuralNetwork takes as params 
// input and output length
// 2 inputs and 1 output

var NN = new NeuralNetwork(2, 1);

var defined_data = [
  {
  input:[0,0],
  output:[0]
  },
 {
  input:[0,1],
  output:[1]
},
{
  input:[1,0],
  output:[1]
},
{
  input:[1,1],
  output:[0]
},
]

for (let i = 0; i &lt; 1000; i++) {
    var shuffled = shuffle(defined_data)
    for (let j = 0; j &lt; shuffled.length; j++) {
      NN.train(shuffled[j].input,shuffled[j].output)
    }
} 

console.log("[0,1] =&gt;", NN.feed_forward([0,1]));
console.log("[0,0] =&gt;", NN.feed_forward([0,0]));
console.log("[1,0] =&gt;", NN.feed_forward([1,0]));
console.log("[1,1] =&gt;", NN.feed_forward([1,1])); </code></pre>		</div>
				</div>
				<div data-id="3ef05d2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>And now, the compilation and execution process:</p>
				</div>
				</div>
				<div data-id="b334533" data-element_type="widget" data-widget_type="elementor-syntax-highlighter.default">
				<div>
			<pre><code>&gt; nectar neural_network.js --preset speed --run --verbose
[*] Generating source file
[*] Compiling with preset: speed

[*] Informations :

Size      : 412.16 ko
Main file : neural_network.js
Output    : C:\Users\NectarJS\Desktop\neural_network.exe
Preset    : speed

[*] Executing C:\Users\NectarJS\Desktop\neural_network.exe
[0,1] =&gt;  [ 0.95 ]
[0,0] =&gt;  [ 0.01 ]
[1,0] =&gt;  [ 0.93 ]
[1,1] =&gt;  [ 0.07 ] </code></pre>		</div>
				</div>
				<div data-id="f407729" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>Hurray !</strong></p>
<p>We just compiled into a native binary a full (easy) neural network, written in JavaScript in less than 500Kb!</p>
<p>The next step is to be compliant with the ES3 specifications at more than 90% to be able to compile a big part of the JS ecosystem.</p>
<p>Stay tuned,</p>
<p>Adrien.</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652389</guid>
            <pubDate>Thu, 01 Oct 2020 15:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Not to Get Fired as a CTO]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651834">thread link</a>) | @abyx
<br/>
October 1, 2020 | https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/ | <a href="https://web.archive.org/web/*/https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1818">
	
	
	<!-- .entry-header -->

	
	<div>
		
<p>Over the past month or so, I’ve consulted several CEOs who have had trouble with their tech executives. Some are now with or searching for their third or fourth CTO/VP of Engineering. More often than not, these mismatches are not the fault of just one of the parties: both sides need to be better vetting and expectation setting as part of the hiring process. Some also need more coaching or mentoring after the tech executive has joined (for the CEO, for the tech exec, or both). If you’re a CEO hiring a tech executive or struggling with your current one, or an aspiring tech executive, here are some tips to reduce your risks of ending up in the wrong position.</p>



<h3>The Job-To-Be-Done of a Job</h3>



<p>Jobs-to-be-done (JTBD) is a framework pioneered by Clayton Christensen. If you’ve been involved in tech at all, you likely have already heard of it by now from your Product peers. In JTBD, you consider what job a product is hired to provide, be that product an app, SaaS service, a mattress, or a milkshake. Many CEOs grasp this concept when it comes to their product, but fail to do so when defining a <em>job</em>.</p>



<p>No matter if you are interviewing or being interviewed, you should clarify what job the tech executive position is intended to achieve. Failing to do so before accepting the job or making an offer will make things blow up at a later stage, which is a lot riskier and grossly more expensive to remedy.</p>



<p><em>Define Success:</em> What would be considered a success for the tech executive within the next 6, 12, and 24 months? It is near-impossible to hit a target if you don’t know how it looks like or where it is.</p>



<p><em>Define Responsibilities:</em> Tech executives are often in charge of People, Architecture, or Evangelism. <em>People</em> management is usually under a VP of Engineering, who is in charge of the delivery of software in the company, and the entire engineering team. <em>Architecture</em> has many forms, but most frequently means leading the tech capabilities of the organization or introducing technological innovation. Think Chief Architect roles, and sometimes a CTO. Lastly, <em>Evangelism</em> is used for companies that have a significant part of their product facing other technologists external to the company—platforms, SDKs, and APIs most often. A tech executive responsible for evangelism is likely to be speaking at conferences, creating partnerships, and so on. Knowing which of these responsibilities the CEO has in mind will help find the right person to fill the position.</p>



<p><em>Define Values:</em> It is vital for executives of the company to share its values and mission. However, this is not often given enough attention during interviews. Both parties should discuss their ideology, beliefs, and motivation. I’ve seen mismatches between executives and CEOs stemming from not agreeing on basic culture. Some people want to keep the scrappy, garage-like behavior for years and others prefer a more relaxed and “grown-up” way of doing things. Some people might want to work at a company that takes a political stand in areas not directly related to it, and others prefer to remain focused on what the company is working to solve. Ensure that you have an accord here.</p>



<p><em>Discuss the Path:</em> Every executive, being truly an executive and not a glorified manager, should have an idea about achieving and accomplishing the goals discussed. While not everything will be known beforehand, and some things are bound to change, candidates should have a sense of how to get these objectives done. Talking about the path forward provides both sides with more confidence: the CEO can see that there’s a plan that she can get behind, and the tech executive gains general agreement for her ideas.</p>



<h3>Sometimes It Takes Three to Tango</h3>



<p>When the tech executive is finally there and starts working, new issues will arise. It is just the way things are. However, there are situations where merely doing their best is not going to cut it. Sometimes, one of the sides needs to be coached (e.g., teaching the CEO to provide autonomy, or helping the tech executive speak business so the rest of the executive team can understand her). Other times, the relationship itself between them needs to be worked on.</p>



<p>I may be biased, as I do this for a living, but have another person involved in the first few months as a coach and advisor gets things up and running significantly faster. A typical example: CEOs often feel relieved when they hear it is perfectly natural, even for an experienced executive, to require a few months to grok the team’s situation and start showing improvement. This removes a lot of tension (the constant “did I make the right hire” question looping in their mind) and allows trust to be built.</p>



<p>If you find that you are struggling in the first few months, I highly recommend seeking support (even internally, e.g., another co-founder who’s not the CEO). </p>



<p>And, lastly, always remember that things always turn out to be different than how you first imagined them. It doesn’t necessarily mean that you made the wrong choice.</p>
 <div data-ck-version="6">   <div>   <div>     <h3>Get the Tech Executive Operating System</h3>     <p>Get the best newsletter for tech executives online. Tailored for your daily work. Weekly, short, and packed with exclusive insights.</p>            <!--  Form starts here  -->        </div>  </div>  </div>    			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651834</guid>
            <pubDate>Thu, 01 Oct 2020 15:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing TikTok’s multi-billion dollar algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651822">thread link</a>) | @ailon
<br/>
October 1, 2020 | https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573 | <a href="https://web.archive.org/web/*/https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="aae4">Almost a month ago my wife wanted to register on TikTok and was experiencing some odd difficulties. As our family’s tech-support person I ended up registering myself in the process of helping her. After posting a random TikTok (again, to help with some issues) I realized that it’s a good opportunity to put TikTok’s mighty algorithm to the test.</p><p id="8ee7">Since I went deep(ish) into my music making hobby this year, I decided to make <a href="https://www.tiktok.com/@ailonid" rel="noopener">my TikTok</a> focused on that. Both as a content consumer and creator. To try to preserve the “purity” of the experiment I decided not to tell anyone about my TikTok for the duration of this experiment. Well, my wife knew, obviously, and “contaminated” the results a bit. But I don’t think that was a major factor. So, here’s what I find out…</p><h2 id="168f">TikTok’s Algorithm for Consumers</h2><p id="571d">In the onboarding process you get asked very little. You pick some very wide-ranging themes of interest like entertainment, sports, music, etc. And that’s about it. Not surprisingly the initial experience is quite random — you get a bunch of half-naked beautiful people, kitty-puppy videos, poor dad joke reenactments and alike.</p><p id="c9fc">I tried not to “like” any of the above and not to follow any celebrities. I went into search and tried to look up people posting TikToks about music production, music theory, audio engineering, music business and similar. After I followed a bunch of those not much changed in the first couple of days. But then my “For You” feed (TikTok’s algorithmic feed) improved dramatically and became quite on-point.</p><p id="8d99">Interestingly, I was traveling for a couple of days (yes, this still happens once in a while in our neck of the woods) and didn’t use TikTok for a day or two. When I launched it after the break I got quite an increase in “funny” videos again. I guess this is AI’s idea of how to best “reactivate” churning users. But after a day or two it got back to my regular programming.</p><p id="a2bb">So, from the consumer’s side the algorithm works quite well. On the other hand, so does the algorithm on YouTube or Instagram. As <a href="https://twitter.com/mattcutts" rel="noopener">Matt Cutts</a> (one of the early Googlers) <a href="https://youtu.be/kpmbptHDVJg?t=1335" rel="noopener">said on TWiT</a>:</p><blockquote><p id="8242">You can probably do a pretty good approximation [of TikTok’s algorithm] in like a thousand lines of code. You are looking for engagement, you are looking for growth, you are looking at the first derivative… it’s gonna be pretty simple…</p></blockquote><p id="4112">In any case, it does work fine but this wasn’t the most interesting part to me. I’d be more surprised if it didn’t work well for consumers.</p><p id="cde4">What I was more interested in is the constant stream of raving comments on how well it works for creators — “nobodies” can reach millions with a good video, they said. Let’s see how that works…</p><h2 id="3e43">TikTok’s Algorithm for Creators</h2><p id="1833">I tried to post TikToks regularly. Not exactly every day but so far I posted 17 videos in about 4 weeks.</p><p id="8bc1">Quite obviously TikTok’s “hook” is that they over-expose TikToks from newbies and make you feel really good in your first few days. (How do they deal with bots and trolls trying to abuse this is an interesting question but beside the point here.) My first 5 TikToks (the first one was just a random test) got between 500 and 700 views. Not bad for someone with 1 follower. But then the views started to go down.</p><p id="2433">Obviously, I didn’t produce any stunning content and I don’t think I deserve more views from the algorithm pushing me. But I’ve noticed something peculiar…</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2070/1*TlzZOu5ZTizu7xsCT9oaNQ.png" width="1035" height="483" srcset="https://miro.medium.com/max/552/1*TlzZOu5ZTizu7xsCT9oaNQ.png 276w, https://miro.medium.com/max/1104/1*TlzZOu5ZTizu7xsCT9oaNQ.png 552w, https://miro.medium.com/max/1280/1*TlzZOu5ZTizu7xsCT9oaNQ.png 640w, https://miro.medium.com/max/1400/1*TlzZOu5ZTizu7xsCT9oaNQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TlzZOu5ZTizu7xsCT9oaNQ.png?q=20"></p></div></div></div><figcaption>Typical stats for most of my recent TikToks</figcaption></figure><p id="2de3">While all of my TikToks (except one) are in [mostly broken] English, and I added relevant hashtags and descriptions in English, they were primarily shown in my home country of Lithuania. That’s a very small niche. Add that TikToks were for a niche subject of “music-making” and you get close to zero of overlap.</p><p id="2d64">Interestingly, I got similar results on a couple of videos that I posted from Poland and Germany.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png" width="506" height="368" srcset="https://miro.medium.com/max/552/1*A0bxyk6k9iMsg6XC5xs4kg.png 276w, https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png 506w" sizes="506px" data-old-src="https://miro.medium.com/max/60/1*A0bxyk6k9iMsg6XC5xs4kg.png?q=20"></p></div></div><figcaption>Stats for TikTok posted from Germany</figcaption></figure><p id="d459">As you can see there’s Germany present here but the majority is still from Lithuania. The one from Poland had more Polish viewers but still fewer than Lithuanians. (FYI, the population of Poland is about 14x of Lithuania)</p><p id="569a">So the “almighty algorithm” somehow prioritizes your profile’s country over everything else. Not very smart, if you ask me. You may not notice this if you live in the US or some other big country, or if you create content for your local market. But, anecdotally, it feels like TikTok’s algorithm is quite discriminatory towards people from small countries trying to create global content.</p><p id="9aa2">To add insult to injury, I’m pretty sure TikTok never asked me for my country (I registered with email address, not phone or other account), and it doesn’t require location permissions (kudos for that). So basically they took my IP address at the time of registration and hard-coded my profile’s country to what they got from the IP lookup. Good thing I didn’t register at the office as many services think we are in Norway based on that IP. Or maybe that’s a bad thing given my goals.</p><blockquote><p id="e552"><strong>Untested pro-tip</strong>: create your account over VPN to US (or whatever location you care about) for better distribution.</p></blockquote><p id="5b0f">The bottom line is that TikTok’s algorithm still gave me more exposure than probably any other service would, considering I didn’t do anything to assist it (I didn’t tell anyone about my TikTok, remember?). Having said that, it handicapped me for no apparent reason purely based on my home country.</p><p id="2686">And that’s the main problem with all the algorithmic social media — you are at the mercy of a bunch of “if-then” statements with their bugs, quirks, and oddities.</p><p id="cef8">Now that you know <a href="https://www.tiktok.com/@ailonid" rel="noopener">I have TikTok</a>, we can proceed to the phase 2 of the experiment. If you are even remotely interested in music production and don’t live in Lithuania, please <a href="https://www.tiktok.com/@ailonid" rel="noopener">follow me on TikTok @ailonid</a> and in another month I will report if having followers outside of Lithuania had any impact on the algorithm.</p></div></div></div>]]>
            </description>
            <link>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&amp;sk=a736bbdd904768fa4d7bcfb536615573</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651822</guid>
            <pubDate>Thu, 01 Oct 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julian Assange Acted Responsibly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651796">thread link</a>) | @DiogenesKynikos
<br/>
October 1, 2020 | https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen | <a href="https://web.archive.org/web/*/https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-css-88vvl0=""><p data-pos="0-0" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Bieler Professor Christian Grothoff hat keine Ahnung, wer M.Â&nbsp;I.Â&nbsp;A. ist. Schade eigentlich. Schon allein wegen ihres spektakulÃ¤ren, verstÃ¶renden und kontrovers diskutierten Ausblicks auf das Trump-Zeitalter aus dem Jahr 2010, des zehnÂ­minÃ¼tigen Videos zu ihrer Single Â«Born FreeÂ». Darin werden in einer alternativen RealitÃ¤t Rothaarige als verfolgte ethnische Minderheit von paraÂ­militÃ¤rischen US-Truppen zu Tode gejagt.</p><figure data-pos="0-1" data-css-1esus25=""><a data-css-11au926=""><span data-css-mcluq8=""><svg width="26" height="36.01" viewBox="0 0 26 36"><path d="M25.956 18.188L.894 35.718V.66" fill="#fff"></path></svg></span><span data-css-fijd0m="">Dies ist ein Vimeo-Video. Wenn Sie das Video abspielen, kann Vimeo Sie tracken.</span><span data-css-1bqahl="" role="img" aria-label=""></span></a><figcaption data-css-s9b1dj="" data-css-qc9yqx="">M.I.A, Born Free</figcaption></figure><p data-pos="0-2" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">DafÃ¼r weiss M.Â&nbsp;I.Â&nbsp;A. aber, wer Christian Grothoff ist.</p><p data-pos="0-3" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A.Â&nbsp;â€“ jene englische Rapperin, die 2012 von der NFL auf eine Million Dollar SchadenÂ­ersatz verklagt worden war, weil sie wÃ¤hrend ihres Super-Bowl-PausenÂ­auftritts mit Nicki Minaj und Madonna den MittelÂ­finger <a href="https://www.youtube.com/watch?v=qlEUz1IlN70&amp;ab_channel=ATownHR23" data-css-9r2oe9="" data-css-1exity3="">in die Kameras gehalten hatte</a>. Oder 2016: Verklagt vom FussballÂ­club Paris Saint-Germain, weil sie im Video zu ihrem Song Â«BordersÂ» ein T-Shirt des franzÃ¶sischen Vereins trug und dabei den SchriftÂ­zug des Sponsors Â«Fly EmiratesÂ» <a href="https://www.youtube.com/watch?v=r-Nw7HbaeWY&amp;ab_channel=MIAVEVO" data-css-9r2oe9="" data-css-1exity3="">in Â«Fly PiratesÂ» abgeÃ¤ndert hatte</a>. </p><p data-pos="0-4" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die 45-jÃ¤hrige Musikerin und politische Aktivistin setzt sich derzeit mit zahlÂ­reichen KÃ¼nstlerinnen, darunter <a href="https://www.washingtonpost.com/entertainment/dissident-ai-weiwei-protests-possible-extradition-of-assange/2020/09/28/89e17c56-0183-11eb-b92e-029676f9ebec_story.html" data-css-9r2oe9="" data-css-1exity3="">Ai Weiwei oder Designerin Vivienne Westwood</a>, dafÃ¼r ein, dass Wikileaks-GrÃ¼nder Julian Assange nicht an die USA ausgeliefert wird. Seit dem 7.Â&nbsp;September lÃ¤uft an einem Londoner Gericht die zweite Runde des AuslieferungsÂ­verfahrens, das wegen Covid-19 im April unterbrochen worden war. Die USA beschuldigen Assange, mit der VerÃ¶ffentlichung von 250â€™000Â&nbsp;Depeschen aus US-Botschaften das Leben von Diplomaten und amerikanischen Helfern weltweit gefÃ¤hrdet zu haben.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="der-zeuge-aus-der-schweiz"></a>Der Zeuge aus der Schweiz</h2><p data-pos="0-6" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. war es mÃ¶glich, das Verfahren per VideoÂ­stream live zu verfolgenÂ&nbsp;â€“ was alles andere als selbstÂ­verstÃ¤ndlich ist: Im Gericht waren fÃ¼r die neue AnhÃ¶rungsÂ­runde nur noch fÃ¼nf Journalistinnen und ein paar wenige GÃ¤ste zugelassen, diversen ProzessÂ­beobachtern wie Amnesty International wurde am ersten AnhÃ¶rungsÂ­tag kurzfristig der Zugang verweigert, zugesagte BeobachterÂ­plÃ¤tze wurden gestrichen, ihnen wurde zusammen mit vierzig anderen Organisationen oder akkreditierten Medien die MÃ¶glichkeit entzogen, <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">das Verfahren wenigstens per Stream verfolgen zu kÃ¶nnen</a>.</p><p data-pos="0-7" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Dieser Vorgang wurde laut Amnesty International <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">nicht weiter begrÃ¼ndet</a> und sei Â«sehr beunruhigendÂ». Â«Mit diesem Schritt missachtet das Gericht das GrundÂ­prinzip der Ã–ffentlichkeitÂ», schrieb die MenschenrechtsÂ­organisation: Â«Konkret, dass internationale ProzessÂ­beobachterinnen nachvollziehen kÃ¶nnen, ob nationales und internationales Recht eingehalten wird.Â» Und dies in einem Verfahren, in dem die RechtÂ­sprechung sowieso ziemlich eigenwillig interpretiert wird. Assange, dem der Zugang zu seinen eigenen AnwÃ¤lten in den letzten sechs Monaten verweigert worden war, sitzt mittlerweile seit 16Â&nbsp;Monaten ohne juristische Grundlage in IsolationsÂ­haft, wasÂ&nbsp;â€“ Grundlage hin oder herÂ&nbsp;â€“ als Folter gesehen werden muss. (Sein Vergehen, <a href="https://www.forbes.com/sites/thomasbrewster/2019/05/01/assange-given-50-weeks-in-prison-for-breaking-bail/#2af1cd5fa1d8" data-css-9r2oe9="" data-css-1exity3="">der Verstoss gegen Kautionsauflagen</a>, wird in Grossbritannien normalerÂ­weise nicht einmal mit einer kurzen GefÃ¤ngnisÂ­strafe geahndet.)</p><p data-pos="0-8" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. also war es mÃ¶glich, den Prozess live zu verfolgen.</p><p data-pos="0-9" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und am Morgen des 21.Â&nbsp;September twitterte die Rapperin:</p><div data-css-wnj6iv="" data-pos="0-10"><p data-css-87w1y="" data-css-5rrfwp="">Â«Ich beobachtete diesen Zeugen. Ziemlich intensive Befragung, sogar die Richterin wurde wÃ¼tend wegen des schonungsÂ­losen KreuzÂ­verhÃ¶rs, das er zu erdulden hatte. Ich empfehle es allen: Studiert bei Professor Dr.Â&nbsp;Christian Grothoff. Grothoff ist Professor der Informatik in der Schweiz. Er war brillant.Â»</p><figcaption data-css-s9b1dj="" data-css-qc9yqx=""><a href="https://twitter.com/MIAuniverse/status/1308129185240580096" data-css-9r2oe9="" data-css-1exity3="">Tweet von @MIAuniverse</a></figcaption></div><p data-pos="0-11" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Am Tag darauf rief ich den InformatikÂ­professor an. </p><figure data-pos="0-12" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehenÂ»: Christian Grothoff. <span data-css-puup3u="">Martin Gross/youtube/gnunet</span></figcaption></figure><p data-pos="0-13" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«KÃ¶nnen Sie mir sagen, was da los war?Â», fragte ich.</p><p data-pos="0-14" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ja, natÃ¼rlichÂ», sagt er. Â«Nach meinem Auftritt vor Gericht ist es mir jetzt erlaubt, meine Erkenntnisse mit der Presse zu teilen.Â»</p><p data-pos="0-15" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Sie waren Zeuge im Assange-Prozess?Â»</p><p data-pos="0-16" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«JaÂ», sagte Professor Grothoff. Â«Ich habe meine Expertise dem Gericht zur VerfÃ¼gung gestellt, einen dicken Stapel Unterlagen.Â»</p><p data-pos="0-17" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Was fÃ¼r eine Expertise?Â»</p><p data-pos="0-18" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ich sollte im Auftrag der Verteidigung nach bestem Wissen und Gewissen analysieren, wie es dazu kam, dass die DiplomatenÂ­depeschen, die Chelsea Manning Wikileaks Ã¼bergeben hatte, spÃ¤ter komplett ungeschwÃ¤rzt im Internet kursierten. Das ist ja eigentlich einer der zentralen AnklageÂ­punkte: Diese Publikation der gesamten Depeschen. Wer hat sie zuerst ins Netz gestellt? Wikileaks, wie es die USA behaupten?Â»</p><p data-pos="0-19" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Haben Sie eine Antwort gefunden?Â»</p><p data-pos="0-20" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehen.Â»</p><p data-pos="0-21" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Wir trafen uns einen Tag spÃ¤ter zum AbendÂ­essen in einem chinesischen Imbiss in der Berner Altstadt.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="die-hauptschuld-liegt-beim-guardian"></a>Â«Die Hauptschuld liegt beim â€¹Guardianâ€ºÂ»</h2><p data-pos="0-23" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und die Geschichte, die der Bieler Professor Christian Grothoff an jenem Abend im September zu erzÃ¤hlen hat, ist hÃ¶chst erstaunlich.</p><figure data-pos="0-24" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Assange-UnterstÃ¼tzerinnen: Chelsea Manning (Mitte) und Dame Vivienne Westwood, hier mit ihrem Mann Andreas Kronthaler. <span data-css-puup3u="">David M. Benett/Getty Images</span></figcaption></figure><p data-pos="0-25" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Zehn Jahre lang <a href="https://www.bbc.com/news/technology-37165230" data-css-9r2oe9="" data-css-1exity3="">behaupteten die US-BehÃ¶rden (ohne jemals einen einzigen Beweis dafÃ¼r zu erbringen</a>), dass Julian Assange MenschenÂ­leben gefÃ¤hrdet habe, weil er die ihm von Chelsea Manning anvertrauten diplomatischen Depeschen der US-Regierung komplett und einfach so ins Netz gestellt habe, und deswegen sei Assange kein Journalist.</p><p data-pos="0-26" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die ErzÃ¤hlung von der GefÃ¤hrdung hat sich bis heute gehalten, obwohl Mitarbeitende des State Department bereits Ende 2010 gegenÃ¼ber dem US-Kongress hatten durchsickern lassen (wÃ¤hrend die Obama-Administration Ã¶ffentlich das Gegenteil behauptete), <a href="https://www.reuters.com/article/us-wikileaks-damage-idUSTRE70H6TO20110118" data-css-9r2oe9="" data-css-1exity3="">dass Wikileaks die USA zwar blossgestellt habe, dabei aber niemand zu Schaden gekommen sei</a>.</p><p data-pos="0-27" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Bei seiner Analyse fand Grothoff zudem heraus: Die BehauptungÂ&nbsp;â€“ ein zentraler AnklageÂ­punkt der US-JustizÂ&nbsp;â€“, Wikileaks habe als erste Quelle die Depeschen komplett und unbearbeitet ins Netz gestellt und sei deshalb unter dem Â«Espionage ActÂ» zu verfolgen, ist nachweislich falsch. Mit dem nÃ¶tigen FachÂ­wissen sei im Netz nachvollziehbar und unzweifelhaft belegbar, so Grothoff in seiner Expertise, dass Wikileaks erst im Nachgang die gesamten Depeschen publiziert habeÂ&nbsp;â€“ nachdem diese von anderen Quellen bereits online gestellt worden waren.</p><p data-pos="0-28" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Informatiker Christian Grothoff mit akademischen und beruflichen Stationen in Los Angeles, Denver, MÃ¼nchen und Rennes ist ein international angesehener Fachmann unter anderem fÃ¼r VerschlÃ¼sselungsÂ­techniken, aber auch in der Analyse von Peer-to-Peer-Netzwerken und der Ãœberlastung von Servern zum Beispiel durch sogenannte DDOS-Angriffe.</p><p data-pos="0-29" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Kurz: Grothoff vereint so ziemlich das ganze FachÂ­wissen, das in dieser Angelegenheit gefragt ist.</p><p data-pos="0-30" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Es ist im Ãœbrigen so, dass Assange die diplomatischen Depeschen derart gut geschÃ¼tzt hatÂ», sagte Grothoff im GesprÃ¤ch mit der Republik und auch vor Gericht, Â«dass sie auch von der NSA nicht hÃ¤tten geknackt werden kÃ¶nnen.Â»</p><p data-pos="0-31" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Bild, das Grothoff stattdessen zeichnet, ist ein ArmutsÂ­zeugnis fÃ¼r den Journalismus: Die Journalisten des Â«GuardianÂ», mit denen sich Assange bald Ã¼berwarf, hefteten sich wie BlutÂ­sauger an den Wikileaks-GrÃ¼nder, um mit seiner Hilfe die grossen Geschichten fahren zu kÃ¶nnen. Der Â«GuardianÂ»-Journalist David Leigh Ã¼bte dabei massiven Druck auf Assange aus: Er solle ihm das Passwort fÃ¼r die verschlÃ¼sselten Depeschen nennen, fÃ¼r den Fall, dass Assange verhaftet werde und dann keine weiteren Geschichten mehr publiziert werden kÃ¶nnten.</p><p data-pos="0-32" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Quelle dafÃ¼r: das Buch Â«Wikileaks: Inside Julian Assangeâ€™s War on SecrecyÂ», das David Leigh im Februar 2011 selbst publiziert hatte. Dort steht auch, Assange habe schliesslich eingewilligt, Leigh das Passwort auszuhÃ¤ndigenÂ&nbsp;â€“ mit der eindringlichen Bitte, es niemals irgendwo als Ganzes aufzuschreiben.</p><p data-pos="0-33" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Assange, das steht in meiner Expertise fÃ¼r das Gericht, ist verantwortungsÂ­voll mit den Daten umgegangenÂ», sagt Grothoff. Â«Das lÃ¤sst sich alles nachvollziehen und belegen.Â» Doch was nach der PasswortÂ­Ã¼bergabe passiert sei, kÃ¶nne er als Fachmann nur als Â«grob fahrlÃ¤ssigÂ» bezeichnen, und zwar nicht von Wikileaks, sondern vom Â«GuardianÂ»: Â«Der Journalist David Leigh schwatzt Julian Assange das Passwort abÂ&nbsp;â€“ und dann publiziert er es ein paar Monate spÃ¤ter als KapitelÂ­titel in seinem Buch â€¹Inside Wikileaksâ€º.Â»</p><p data-pos="0-34" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Ja, Sie haben richtig gelesen.</p><p data-pos="0-35" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Passwort, 58Â&nbsp;Buchstaben, Ziffern und SonderÂ­zeichen, als Ãœberschrift in einem Buch. Der Â«GuardianÂ»-Journalist habe spÃ¤ter behauptet, er sei davon ausgegangen, das Passwort sei veraltet gewesen. Als VerschlÃ¼sselungsÂ­experte, sagte Grothoff, mÃ¼sse er entgegnen, dass man in der Pflicht sei, sich zu informieren, mit welcher Technik man es zu tun habe, wenn man mit derartig sensiblen Daten operiere. </p><p data-pos="0-36" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es dauerte nicht lange, da wurde in den Medien (namentlich im Â«FreitagÂ» und im Â«SpiegelÂ») ein ZusammenÂ­hang zwischen dem Passwort aus dem Buch des Â«GuardianÂ»-Journalisten und der Depeschen-Datei hergestellt, die nach massiven sogenannten DDOS-Angriffen auf den Wikileaks-Server (Angriffe, um den Server lahmzulegen) und Spiegelungen ebenjenes Servers durch Dritte irgendwo unkontrolliert als Kopie in den Weiten des Netzes umherschwirrte. Am 1.Â&nbsp;September 2011 sei diese dann unverschlÃ¼sselt auf einer Plattform namens Â«CryptomeÂ» aufgetaucht. </p><p data-pos="0-37" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">TatsÃ¤chlich sagte der Betreiber von Â«CryptomeÂ» nun vor dem Londoner Gericht aus, er habe als Erster die Depeschen vollumfÃ¤nglich, ungeschwÃ¤rzt und unverschlÃ¼sselt hochgeladenÂ&nbsp;â€“ <a href="https://www.fr24news.com/a/2020/09/us-never-asked-wikileaks-rival-to-remove-leaking-cables-court-says-julian-assange.html" data-css-9r2oe9="" data-css-1exity3="">und bis heute habe die US-Regierung bei ihm nichts von sich hÃ¶ren lassen</a>.</p><p data-pos="0-38" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Die Depeschen finden sich immer noch dortÂ», sagt Grothoff. </p><p data-pos="0-39" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es sei problemlos chronologisch aufzuzeigen, sagte InformatikÂ­professor Grothoff im Berner Imbiss, dass die HauptÂ­schuld fÃ¼r die Publikation der gesamten Depeschen beim Â«GuardianÂ» liege. Â«WÃ¤re man …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</a></em></p>]]>
            </description>
            <link>https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651796</guid>
            <pubDate>Thu, 01 Oct 2020 15:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on QA]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24651571">thread link</a>) | @tigranhakobian
<br/>
October 1, 2020 | https://blog.superannotate.com/how-to-detect-mislabeled-annotations | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/how-to-detect-mislabeled-annotations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>Manual QA is a significant part of the annotation pipeline. Annotation companies report that 40 percent of the annotation time can be spent on manual QA. As a result, finding ways to reduce QA testing time can have a significant impact on annotation costs.&nbsp;</em></p>
<!--more--><p><em>At SuperAnnotate, we’ve developed a tool to accelerate the QA process. This article discusses SuperAnnotate’s features that speed up the quality assurance process substantially. It presents several automation tools within the platform listing specific use cases in which a major acceleration of the QA process can be obtained. We also explored various ML algorithms that can detect over 90 percent of mislabeled instances in data while accelerating the QA process up to 4 times.&nbsp;</em></p>
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li><em>Problem with noisy annotation in data&nbsp;</em></li>
<li><em>Manual QA acceleration</em></li>
<li><em>QA automation</em></li>
<li><em>Conclusion</em></li>
</ul>
<h2><span>Problem with annotation noise in data</span></h2>
<p><strong><span>1.1. The importance of model accuracy and the impact of annotation noise&nbsp;&nbsp;</span></strong></p>
<p>In real-world applications, the performance of machine learning (ML) systems is of crucial importance. ML models heavily rely on the quality of annotated data, but obtaining high-quality annotations is costly and requires extensive manual labor.&nbsp;</p>
<p><span>In any annotation pipeline, regardless of the data collection method, i.e., human or machine, several factors inject annotation noise in data. As a result, even the most celebrated datasets contain mislabeled annotations.</span></p>

<p><img src="https://lh3.googleusercontent.com/mL1r0JU9VM5-WflEsLU04zQ7vhYhl8cKRux8LvOnUTYEKZvnIUD9Gv8HmkVTqPfgoDtEkb_5ApX3SjgJjdTAHNfG6I-5Q7_fag_cra8IhXTWp-uVdrvQCf7kzoqt03BwtgKlTb4i" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"><em>Figure: Ambiguous or Mislabeled annotations from ImageNet. Source (</em><a href="https://arxiv.org/abs/2001.10528"><em><span>Pleiss et al</span></em></a><em>.)</em></p>

<p><span>Recent studies show that both natural and malicious corruptions of annotations tend to radically degrade the performance of machine learning systems. Deep Neural Networks (DNNs) tend to memorize noisy labels in data, resulting in less generalizable features and poor model performance (<a href="https://arxiv.org/abs/1611.03530">Zhang et al.</a>)</span></p>
<p><span>Therefore, extensive quality control of annotated data is required to clean annotation noise and improve model performance.</span><em><br></em></p>

<p><img src="https://lh4.googleusercontent.com/7BKHH4Am8Z_PZebzMe7mkbGCA6J_UyNRZE-ClAMwP5qVo52ZEuybUx81EOWYSdKrz2Mz7P4zf2cHuoz9nlyl4Alg-D16cD58mSCLf1CAOUwwDEp2MUkIsaTi37D6y9aliNShqdUz" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Accuracy drop in multiple datasets when injecting label noise. Source (</em><a href="https://arxiv.org/abs/1611.03530"><em><span>Rolnick et al.</span></em></a><em>)</em></p>

<h2>Manual QA Acceleration</h2>
<p><strong><span>2.1 SuperAnnotate’s QA pipeline&nbsp;</span></strong></p>
<p><span>Quality Assurance of annotated data is time-consuming and requires particular attention. Annotation tools need to provide reliable and scalable QA pipelines to accelerate the QA process. <a href="https://annotate.online/login">SuperAnnotate</a> provides interlinked annotation and QA processes within the same platform. As a result, QA systems do not require additional management.</span></p>
<p><span>The design of SuperAnnotate’s QA system guarantees an efficient process and ensures a minimal probability of error.&nbsp;</span></p>
<p><strong><span>2.2 Pinning images to reduce common errors&nbsp;</span></strong></p>
<p><span>Sharing repetitive labeling mistakes across the annotation team is essential to reduce systematic errors throughout single or multiple annotation projects. </span>SuperAnnotate’s pin functionality is designed specifically for this cause.&nbsp;</p>
<p>Once the reviewer notices a recurring error, they can share this information through pinned annotations instead of extensive project instructions. Pinned annotations will appear first in the annotation editor to immediately grab the annotation team’s attention.&nbsp;</p>
<p>This functionality is highly efficient since it allows the project coordinator to instantly share common instructions, eliminating the spread of systematic errors.&nbsp;</p>

<p><img src="https://lh6.googleusercontent.com/g1sh6D7Xy1hLYBMczMWfFGdO1_1gktJn7dNF1Spx3lwUxeZd8isGaMHgYLB1GoT0lY8jJKTemdqvtExgPJIocgjNEFuzYGjbPQYeRo31873mdN3U4U10DMjW7DZOnr1eAh5_o-bc" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Pin functionality</em></p>

<p><strong><span>2.3 Approve/Disapprove functionality</span></strong></p>
<p>Apart from various image-level QA tools, SuperAnnotate also provides instance-level QA functionalities. The latter is designed to help the QA focus on a specific instance area. As a result, no error is overlooked, at the time a meticulous QA is time-efficient.</p>
<p>Additionally, the Approve/Disapprove functionality works on the level of individual instances<span>.</span> If a QA specialist disapproves of an annotation, they can send it back to the Annotator for correction. The QA specialist can send the annotation back to the Annotator as many times as needed until the annotation is corrected. Once approved, the annotations can be exported from the platform.</p>

<p><img src="https://lh4.googleusercontent.com/BpQPXRUuTMRYUP-YGJTSRJwFUtdLr6wsB5LVwn66wK6TqFJCTRW5LLwhTp4sRttqgzQaCngKzm7Z6ONZBpPhwzxifj1KlBRs5_FOl_Nk0cFpaC_jn7-l9CMn1WJX2FENx9f9NI24" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p>Figure: Approve/Disapprove functionality</p>

<p><span>The QA mode is another useful tool for manual instance inspection. When enabled, the annotations are visually isolated from the background. This allows the user to distinguish between instances and the underlying objects, making the instance inspection easier.</span></p>
<p><span>All listed features extensively accelerate the manual QA process. However, machine learning techniques that automatically detect annotation noise can provide an additional level of automation.</span></p>

<h2><span>QA Automation</span></h2>
<p><strong><span>3.1 ML for QA Automation</span></strong></p>
<p><span>QA of annotated data takes around 40 percent of the annotation time.</span></p>
<p><span>On average, only a small fraction of annotated data contains noise. Still, QA is applied to the entire dataset, and monitoring clean data costs the annotators extra time and resources. An automation method could substantially cut down the QA process of clean data by isolating a set of risky annotations. So, our goal is to determine ML techniques that identify noisy annotations in data with high precision and recall.</span></p>
<p><strong><span>3.2 Current research</span></strong></p>
<p><span>Learning on datasets that contain annotation noise has been an active research area in ML. Several methods use predictions from DNNs to detect label noise and modify training loss (Reed et al., 2015; Tanaka et al., 2018). These methods do not perform well under high noise ratio as the domination of noisy annotations in data causes overfitting of DNNs. Another approach is to treat small loss samples as clean annotations and allow only clean samples to contribute to the training loss (Jiang et al., 2017). Ultimately, this research area’s core challenge is to design a reliable criterion capable of identifying the annotation noise.</span></p>
<p><span>A significant amount of research in this area is focused on classification with noisy labels. The proposed methods range from detecting and correcting noisy samples to using noise-robust loss functions. Unsupervised and semi-supervised learning techniques are also relevant to this task since those require few or no labels. Mislabeled samples that are detected without label correction can be used as unlabeled data in a semi-supervised setting (Li et al. 2020).&nbsp;</span></p>
<p><span>Going beyond classification makes things far more challenging. In classification, the existence of an object per image is guaranteed. So, the noisiness criterion can be defined between predicted and annotated image labels. However, in more complex tasks such as object detection, the correspondence between predicted and annotated instances is less trivial. Even though research in this area is in its initial state, several methods suggest valid measures to indicate both localization and label noise in object detection (Pleiss et al 2020, Chadwick et al. 2019).</span></p>
<p><strong><span>3.3&nbsp; Proposed method</span></strong></p>
<p>Consider the task of object detection on a dataset that contains mislabeled annotations. Several techniques use DNN predictions to identify label noise in data. Based on this concept, we propose the following algorithm.</p>
<ul>
<li>For each bounding box annotation, we obtain the matching prediction that has the maximum IOU.&nbsp;</li>
<li><span>Compute <strong>L2 distance</strong> between one hot vector of an annotated class and Fast RCNN softmax logits of the matched prediction. </span>This distance serves as a mislabel metric for annotations. We treat this number as the probability of annotation being mislabeled. As we aim to achieve maximal recall and precision in mislabel detection, we select an optimal threshold to attain the desired objective. This defines the split of data between clean and mislabeled annotations by the given criterion.</li>
</ul>

<p><img src="https://lh6.googleusercontent.com/JJtyM51584r8uJCIbHuW0UKhdgxQIIMm4G23vuD8lxnn5yrYHONPRytIxl-9QjFodM51zy7d8pvswhiMYokXY8XOz-DxqTd4ua-_DHGemiuXULNKqCbq_ePQfzulkbsrNu_jyX0D" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: L2 distance on gt one hot and prediction logits</em></p>

<p>Along with mislabeled detections, we also suggest considering the most confident predictions as missing annotations.&nbsp;</p>
<p><strong><span>3.4 Experiments and results</span></strong></p>
<p>To evaluate the performance of our method, we used PASCAL VOC as a toy dataset. When we manually injected asymmetric label noise in 20 percent of bbox annotations, the described mislabel criterion resulted in the precision-recall curve shown below.</p>
<p><img src="https://lh5.googleusercontent.com/OhgoPNrwmPWqR21Y1jnMY-1rbgKV8cxdFd8F0lZsVCZTcrN9C77EBX-0yqvZfVbYOVAFH_pxHNh88T7r26Gbp6hxWWdF5XqyLkN8SS5G46q512ZOHILlP1wmeR20aCo2QDWsOMms" width="400" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: PR curve with optimal mismatch threshold selected</em></p>

<p>Here, recall determines the portion of annotation noise captured, and precision identifies the fraction of data validated as clean.</p>
<p><span>Based on the PR curve above, using optimal mislabel threshold results in over 93 percent recall. This proves the reliability of our method, as we capture the dominant fraction of annotation noise. Along with high recall, we obtained over 75 percent precision, which attributes to validating ¾ of annotations as clean. This cuts manual inspection time over the whole dataset by a margin of 4, resulting in extensive automation for the manual QA.&nbsp;</span></p>
<p>Note that detected risky annotations contain clean samples apart from correctly detected mislabeled instances. Those are the images that were hard to capture by the detection model and thus are misclassified as risky. Distinguishing between these two categories is a challenging problem for further research.&nbsp;</p>
<p>You can find the source code for the discussed experiments at our <a href="https://github.com/superannotateai/qa-automation"><span>GitHub repository</span></a>.</p>
<p>Also, consider our <a href="https://colab.research.google.com/drive/1Xbt3dxkmX4ozQhdY_vnHXAH67OUeg0Nj#scrollTo=7unkuuiqLdqd&amp;uniqifier=2"><span>Colab tutorial</span></a> as a step-by-step guide to reproduce the given results.&nbsp;</p>
<p><strong><span>3.5 Automate Approve/Disapprove functionality&nbsp;</span></strong></p>
<p>Once mislabeled annotations are captured by ML techniques, SuperAnnotate allows users to import the detected information to the platform through the <strong>error </strong>key of SA formatted annotations. Just set the <strong>error</strong> key in mislabeled annotations and import SA formatted JSONs to SuperAnnotate via Python SDK.&nbsp;</p>

<p><img src="https://lh3.googleusercontent.com/to5CwRUFKERkSeyPgA1Nzl84I0ijhR8bQCpsUHhIxi_zhsm7FnNGOxSJ-i0V8HXnJSzN4VOxDnVgj_JWo2QCwQF6ECSjO4CrLShBB9V3YPHp8SWxO9D2CEwC6UbfqClElWgxIOf3" width="654" height="183" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: JSON Code Block</em></p>

<p><img src="https://lh3.googleusercontent.com/0SJ8E5OnOSxB50Fh_4d4_qjJNT0lygY1yHzFGuFlZ9fMDjIGyUGQDqxGsDDG9j2dMcfmf6PLOHvj3JRJ4F3UtaQup-muynR2TFd18W6vbjI1ANF8Ll99dK_b8v1GIzkBUbpwVaPn" width="654" height="121" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: SDK Code Block</em></p>

<p><span>Discussed pipeline provides complete automation of Approve/Disapprove functional.</span></p>

<p><img src="https://lh5.googleusercontent.com/w9VXvs6INaP4WaEADW2pW6fEVj6s8sj5FZd44gN-10LcKplspRX3N7tt-aRuV1BUmNFzANwQTjKgq9rt-EbND0_SpY2z5Ikcpc3xo6wZHQMm2-TB3iY6ao5LboT86FK8qaw8ZwPu" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Before v.s After autoqa in SA platform&nbsp;</em></p>

<h3><span>Conclusion</span></h3>
<p><span>QA automation is of crucial importance as it constitutes a significant portion of annotation time. This article shows that using proper algorithms and associated tools can help us detect mislabeled annotations with high precision while spending 4x less time on QA.</span></p></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/how-to-detect-mislabeled-annotations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651571</guid>
            <pubDate>Thu, 01 Oct 2020 14:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CodeShip Status – Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651240">thread link</a>) | @jwilk
<br/>
October 1, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users’ pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I’d like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651240</guid>
            <pubDate>Thu, 01 Oct 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Scraping Newegg RTX Inventory with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651154">thread link</a>) | @antonb90
<br/>
October 1, 2020 | https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/ | <a href="https://web.archive.org/web/*/https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Introduction</h2>
<p>In this post, we'll cover how to scrape <strong>Newegg</strong> using <strong>python, lxml</strong> and <strong>requests</strong>. Python is a great language that anyone can pick up quickly and I believe it's also one of the more readable languages, where you can quickly scan the code to determine what it is doing.</p>
<p>Just look at this <strong>loop</strong> with auto incrementing index:</p>
<pre><code><p><span>for</span> index, element <span>in</span> enumerate(href_elements):</p></code></pre>
<p>We'll scrape <strong>Newegg</strong> with the use case of monitoring prices and inventory, especially the RTX 3080 and RTX 3090.</p>
<h2>Setting up</h2>
<p>We're going to work in a <a href="https://virtualenv.pypa.io/en/stable/">virtual python environment</a> which helps us address dependencies and versions separately for each application / project. Let's create a virtual environment in our home directory and install the dependencies we need.</p>
<p>Make sure you are running at least python 3.6, <a href="https://www.python.org/downloads/">3.5 is end of support</a>.</p>
<pre><code><p>mkdir ~/intro-web-scraping</p><p><span>cd</span> ~/intro-web-scraping</p><p>virtualenv env</p><p>. env/bin/activate </p><p>pip install lxml requests</p></code></pre>
<p>Let's create the following folders and files.</p>
<pre><code><p>|-- env </p><p>|-- core</p><p>|   |-- crawler.py</p><p>|   |-- scraper.py</p><p>|   |-- utils.py</p><p>|-- newegg</p><p>|   |-- __main__.py</p></code></pre>
<p>We created a <code>__main__.py</code> file, this lets us run the <strong>Newegg</strong> scraper with the following command (nothing should happend right now):</p>
<pre><code><p>python -m newegg</p></code></pre>
<h2>Crawling the content</h2>
<p>We need to write code that can crawl the content, by crawl I mean fetch or download the HTML from the target website. Our first target is <strong>Newegg</strong>, this website doesn't seem to require javascript for the data we need. We'll get into rendering javascript in a future post that covers <strong>headless scraping</strong> using <strong>requests-html</strong> on <strong>Google Places</strong>.</p>
<p>Open <code>core/crawler.py</code> which we created earlier. Now, we'll begin by requesting the HTML content from Newegg's domain.</p>
<pre><code><p><span>import</span> requests</p><p>newegg = <span>"https://newegg.com"</span></p><p>response = requests.get(newegg)</p><p>print(response.status_code)</p></code></pre>
<p>In <code>newegg/__main__.py</code> we can import crawler and the code above will execute.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p></code></pre>
<p>Remember you can execute and test your code with the previous python command in your terminal (must be run in the root folder <code>~/intro-web-scraping</code>).</p>
<pre><code><p>python -m newegg</p></code></pre>
<p>It looks like the request succeeded, the status code should of been printed to your terminal with a success of <code>200</code>.
Let's clean up the code to make it reusable and define a function for returning the response text.</p>
<p>In <code>core/crawler.py</code> we'll define a <code>crawl_html</code> function (we want to reuse it and this lets us redefine where the HTML comes from in the future).</p>
<pre><code><p><span>import</span> requests</p><p><span><span>def</span> <span>crawl_html</span>(<span>url</span>):</span></p><p>    response = requests.get(url)</p><p><span>return</span> response.content </p></code></pre>
<p>In <code>newegg/__main__.py</code> we'll use the function, you can run it and see the HTML being printed. We use an uppercased variable <code>NEWEGG_URL</code> to define a constant - something that shouldn't change.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>html = crawler.crawl_html(NEWEGG_URL)</p><p>print(html)</p></code></pre>
<h2>Scraping the data we need</h2>
<p>Now that we have access to the HTML content from <strong>Newegg</strong>, we want a way to pull out stock information and price for the RTX 3080 and RTX 3090.
Let's find the page from <strong>Newegg</strong> that has that information first.</p>
<p>Navigate to <a href="https://www.newegg.com/p/pl?N=100007709%20601357282">https://www.newegg.com/p/pl?N=100007709%20601357282</a> in your browser and you'll see we have filters applied for RTX 30 series.</p>
<p><img src="https://www.usetrove.io/images/newegg-screenshot.png" alt="Newegg Category Page"></p>
<p>We'll take that path and append it to our <code>NEWEGG_URL</code>. We do this using <a href="https://docs.python.org/3/reference/lexical_analysis.html#f-strings">f-strings</a> in python, which is a way to interpolate variables in strings.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>print(html)</p></code></pre>
<p>From this URL we can start scraping the data we need. Let's start by creating a few useful functions in the file <code>core/scraping.py</code>. These functions wrap lxml and handle some of the type conversions to make it easier for us to work with.</p>
<pre><code><p><span>from</span> lxml <span>import</span> html</p><p><span><span>def</span> <span>get_tree</span>(<span>html_content</span>):</span></p><p><span>return</span> html.fromstring(html_content)</p><p><span><span>def</span> <span>get_text</span>(<span>tree, xpath_selector</span>):</span></p><p>    elements = tree.xpath(xpath_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element.text_content(), elements))</p><p><span><span>def</span> <span>get_attributes</span>(<span>tree, xpath_selector, attribute</span>):</span></p><p>    elements = tree.xpath(xpath_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element.get(attribute), elements))</p></code></pre>
<h3>Finding the data</h3>
<p>We'll first try to get the prices with XPath. I highly recommend you use XPath instead of CSS selectors which is much more declarative and more expressive, you can use this simple <a href="https://devhints.io/xpath">cheat sheet</a> for quickly finding out how to specify selectors. A more in-depth guide can be found from <a href="https://librarycarpentry.org/lc-webscraping/02-xpath/index.html">librarycarpentry</a>.</p>
<p>Open your chrome browser and visit the crawl url we defined earlier: <a href="https://www.newegg.com/p/pl?N=100007709%20601357282">https://www.newegg.com/p/pl?N=100007709%20601357282</a>.</p>
<p>Press F12 on your keyboard or open the developer console by right-clicking one of the prices on the page and selecting <code>inspect</code>.</p>
<p><img src="https://www.usetrove.io/images/newegg-inspect.png" alt="Newegg Inspect"></p>
<h3>Using XPath</h3>
<p>We'll use the inspector and practice our XPath to figure out how to get all prices on the page (there are <strong>29</strong> items listed). This selector: <code>//li[contains(@class, 'price-current')]</code> grabs all relevant prices.</p>
<p><img src="https://www.usetrove.io/images/newegg-inspector.png" alt="Newegg Inspector"></p>
<p>With the selector in hand, let's modify our <code>newegg/__main__.py</code> entry file by adding a new function to grab the prices.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler, scraper</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p><span><span>def</span> <span>get_rtx_prices</span>(<span>tree</span>):</span></p><p>    price_selector = <span>"//li[contains(@class, 'price-current')]"</span></p><p><span>return</span> scraper.get_text(tree, price_selector)</p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>tree = scraper.get_tree(html)</p><p>prices = get_rtx_prices(tree)</p><p>print(prices)</p></code></pre>
<p>We should see output like the following.</p>
<pre><code><p>[<span>'$1,499.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$809.99\xa0–'</span>, <span>'$1,619.99\xa0–'</span>, <span>'$1,549.99\xa0–'</span>, <span>'$1,549.99\xa0–'</span>, <span>'$729.99\xa0–'</span>, <span>'$759.99\xa0–'</span>, <span>'$1,589.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$1,799.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$1,799.99\xa0–'</span>, <span>'$1,599.99\xa0–'</span>, <span>'COMING SOON'</span>, <span>'$739.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$1,579.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$729.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$1,729.99\xa0–'</span>, <span>'$789.99\xa0–'</span>, <span>'COMING SOON'</span>, <span>'$1,499.99\xa0–'</span>]</p></code></pre>
<p>Let's clean this extra HTML entity appearing at the end of our prices with a utility function. We'll make use of <code>re</code> for regex and <code>unescape</code> from html module to cleanup our data. We need to check if the input contains numbers in order to account for the <code>COMING SOON</code> labels. We'll keep this logic encapsulated in our <code>get_rtx_prices</code> by mapping over each item and then converting it back to a list (<code>map</code> returns an object iterator).</p>
<pre><code><p><span>from</span> core <span>import</span> crawler, scraper</p><p><span>from</span> html <span>import</span> unescape</p><p><span>import</span> re</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p><span><span>def</span> <span>clean_price</span>(<span>price</span>):</span></p><p>    price_contains_numbers = bool(re.search(<span>r'[\d+,]+(\d+)'</span>, price))</p><p><span>if</span> price_contains_numbers:</p><p>        price = unescape(price).split()[<span>0</span>]</p><p><span>return</span> price</p><p><span><span>def</span> <span>get_rtx_prices</span>(<span>tree</span>):</span></p><p>    price_selector = <span>"//li[contains(@class, 'price-current')]"</span></p><p>    price_text = scraper.get_text(tree, price_selector)</p><p><span>return</span> list(map(<span>lambda</span> price: clean_price(price), price_text))</p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>tree = scraper.get_tree(html)</p><p>prices = get_rtx_prices(tree)</p><p>print(prices)</p></code></pre>
<pre><code><p>[<span>'$1,499.99'</span>, <span>'$749.99'</span>, <span>'$809.99'</span>, <span>'$1,619.99'</span>, <span>'$1,549.99'</span>, <span>'$1,549.99'</span>, <span>'$729.99'</span>, <span>'$759.99'</span>, <span>'$1,589.99'</span>, <span>'$699.99'</span>, <span>'$749.99'</span>, <span>'$749.99'</span>, <span>'$1,799.99'</span>, <span>'$1,499.99'</span>, <span>'$1,799.99'</span>, <span>'$1,599.99'</span>, <span>'COMING SOON'</span>, <span>'$739.99'</span>, <span>'$699.99'</span>, <span>'$1,579.99'</span>, <span>'$1,499.99'</span>, <span>'$699.99'</span>, <span>'$699.99'</span>, <span>'$729.99'</span>, <span>'$1,499.99'</span>, <span>'$1,729.99'</span>, <span>'$789.99'</span>, <span>'COMING SOON'</span>, <span>'$1,499.99'</span>]</p></code></pre>
<p>Let's grab the item names.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_names</span>(<span>tree</span>):</span></p><p>    name_selector = <span>"//div[@class='item-info']/a"</span></p><p><span>return</span> scraper.get_text(tree, name_selector)</p></code></pre>
<p>We also want the link to the item.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_links</span>(<span>tree</span>):</span></p><p>    link_selector = <span>"//div[@class='item-info']/a"</span></p><p><span>return</span> scraper.get_attributes(tree, link_selector, <span>"href"</span>)</p></code></pre>
<h3>More complex XPath</h3>
<p>Next we want the stock information (out of stock or in stock). To do this we need to add another function called <code>get_children_text</code> to <code>core/scraper.py</code>. This will allow us to specify a parent selector and a child selector, which will return the first child that matches. If our parent selector has many matches it will try to find a matching child and if it does not find one it will return <code>None</code>. In our case we have many parent matches but some of them may not contain the <code>OUT OF STOCK</code> element.</p>
<p>In <code>core/scraper.py</code> add the new function.</p>
<pre><code><p><span><span>def</span> <span>get_children_text</span>(<span>tree, xpath_parent_selector, xpath_child_selector</span>):</span></p><p>    parent_elements = tree.xpath(xpath_parent_selector)</p><p>    children_texts = []</p><p><span>for</span> element <span>in</span> iter(parent_elements):</p><p>        child = element.xpath(xpath_child_selector)</p><p><span>if</span> child:</p><p>            children_texts.append(child[<span>0</span>].text_content())</p><p><span>else</span>:</p><p>            children_texts.append(<span>None</span>)</p><p><span>return</span> children_texts</p></code></pre>
<p>Back in <code>newegg/__main__.py</code> we can add the stock selector.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_stock_information</span>(<span>tree</span>):</span></p><p>    item_selector = <span>"//div[@class='item-container']"</span></p><p>    child_selector = <span>"div[@class='item-info']/p[contains(., 'OUT OF STOCK')]"</span></p><p>    stock_details = scraper.get_children_text(tree, item_selector, child_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element <span>or</span> <span>"IN STOCK"</span>, stock_details))</p></code></pre>
<p>We also want the product id, having this can help us track changes to the product in the future. Here's how we can find the item id from the page.</p>
<p><img src="https://www.usetrove.io/images/newegg-item-id.png" alt="Item id selector"></p>
<p>If you notice on the highlighted lines below, you can see we added another function to our scraper. Because we are using the <code>text()</code> function of XPath, we are asking for the text node which ignores the other <code>strong</code> label node in the tree seen in the screenshot above.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_ids</span>(<span>tree</span>):</span></p><p>    item_id_selector = <span>"//ul[@class='item-features']/li[contains(., 'Item #')]/text()"</span></p><p><span>return</span> scraper.get_nodes(tree, item_id_selector)</p></code></pre>
<p>Let's add <code>get_nodes</code> to our <code>core/scraper.py</code> module.</p>
<pre><code><p><span><span>def</span> <span>get_nodes</span>(<span>tree, xpath_selector</span>):</span></p><p><span>return</span> tree.xpath(xpath_selector)</p></code></pre>
<h3>Our final output structure</h3>
<p>Let's put it all together now to generate the final structure for our output which will contain basic <strong>stock</strong> information, <strong>price</strong>, <strong>product name</strong>, <strong>product id</strong> and <strong>product link</strong>.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_items</span>(<span>tree</span>):</span></p><p>    prices = …</p></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/">https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/</a></em></p>]]>
            </description>
            <link>https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651154</guid>
            <pubDate>Thu, 01 Oct 2020 14:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Recommendations for October 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651117">thread link</a>) | @bojanvidanovic
<br/>
October 1, 2020 | https://devandgear.com/posts/5-book-recommendations-for-october-2020/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/5-book-recommendations-for-october-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you have noticed the cover image for this post, you might ask what it has to
do with books? Well, because I have included the autobiography of Edward
Snowden titled Permanent Record. After listening to his last interview on the
Joe Rogan Experience podcast, I decided to include it in the list books for
this October 2020. If you haven’t already listened to the podcast, go check it out on <a href="https://www.youtube.com/watch?v=_Rl82OQDoOc">YouTube</a>,
lots of eye-opening stuff.</p>
<p>Moving from the surveillance stuff, we have Continuous Delivery, lots of useful
techniques for those who want to deploy, and sleep tight. Then from code
deployment to mastering the editor for code creation which brings us to Visual
Studio Code, covering end-to-end editing, and debugging tools.</p>
<p>Outside the code, I added The 4-Hour Workweek, a book on productivity, which is
one with the highest ratings on Amazon. And Universal Principles of Design,
it’s a comprehensive, cross-disciplinary encyclopedia of design.</p>
<p>If you haven’t seen the book recommendations for the previous month, go check
it out <a href="https://devandgear.com/posts/books-recommendations-for-september-2020/">here</a>.</p>
<p>If you have already read any of these books, let us know in the comments your
opinion.</p>
<h2 id="1-permanent-record">1. Permanent Record</h2>
<article>
<p><a href="https://devandgear.com/books/edward-snowden-permanent-record/">
<img data-src="https://m.media-amazon.com/images/I/51z1ZaEn6sL.jpg" alt="Edward Snowden Permanent Record" src="https://m.media-amazon.com/images/I/51z1ZaEn6sL.jpg">
</a>
</p>

</article>
<h2 id="2-continuous-delivery">2. Continuous Delivery</h2>
<article>
<p><a href="https://devandgear.com/books/continuous-delivery/">
<img data-src="https://m.media-amazon.com/images/I/51NbiDn81NL.jpg" alt="Continuous Delivery" src="https://m.media-amazon.com/images/I/51NbiDn81NL.jpg">
</a>
</p>

</article>
<h2 id="3-visual-studio-code">3. Visual Studio Code</h2>
<article>
<p><a href="https://devandgear.com/books/visual-studio-code/">
<img data-src="https://m.media-amazon.com/images/I/51Je7J+HS2L.jpg" alt="Visual Studio Code" src="https://m.media-amazon.com/images/I/51Je7J+HS2L.jpg">
</a>
</p>

</article>
<h2 id="4-universal-principles-of-design">4. Universal Principles of Design</h2>
<article>
<p><a href="https://devandgear.com/books/universal-principles-of-design/">
<img data-src="https://m.media-amazon.com/images/I/41nQFR+FSCL.jpg" alt="Universal Principles of Design" src="https://m.media-amazon.com/images/I/41nQFR+FSCL.jpg">
</a>
</p>

</article>
<h2 id="5-the-4-hour-workweek">5. The 4-Hour Workweek</h2>
<article>
<p><a href="https://devandgear.com/books/the-4-hour-workweek/">
<img data-src="https://m.media-amazon.com/images/I/51I2EIRF44L.jpg" alt="The 4 Hour Workweek" src="https://m.media-amazon.com/images/I/51I2EIRF44L.jpg">
</a>
</p>

</article>

<section>
<h2>Author</h2>
<div>
<p><img data-src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg" width="200" height="200" src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg"></p><div>
<p>Bojan Vidanovic is a front-end web developer and tech geek. Love making internet products, blogging, learning, reading,
calisthenics and fitness enthusiast.<br>
More on <a href="https://bojanvidanovic.com/">www.bojanvidanovic.com</a>.</p>
<address>

</address>
</div>
</div>
</section>
</div></div>]]>
            </description>
            <link>https://devandgear.com/posts/5-book-recommendations-for-october-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651117</guid>
            <pubDate>Thu, 01 Oct 2020 14:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.1 Up to 50% Better Memory Usage and Higher Throughput]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24651091">thread link</a>) | @karimtr
<br/>
October 1, 2020 | https://memgraph.com/blog/memgraph-1-1-benchmarks | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-1-benchmarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>At Memgraph, we put great effort into delivering a high-performance in-memory graph storage and analytics engine. We do this by investing a lot of time optimizing and continuously improving various aspects of the Memgraph core engine. In this blog post, we will explore some of the improvements we have made on the storage layer and their impact on performance and memory usage.</p>
<p>The two most significant improvements we introduced in recent years are a new storage engine and a new way of storing properties on both nodes and edges.  Prior to version v0.50.0 Memgraph had an <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> storage where copies of nodes and edges were used to version the data. <strong>Memgraph v0.50.0</strong> introduced a new way of managing graph data where each node or edge consists of the latest version of data, and associated changes of data required to reconstruct previous versions.</p>
<p><img src="https://i.imgur.com/bQbvvp6.png" alt=""></p>
<p><strong>Memgraph v1.1.0</strong> introduced a new way of storing properties. Each node or edge has a property store that takes at least 16B of memory. Memgraph tries to hold properties data in 16B on the stack, if possible. If the properties data exceeds 16B, the first 8B of the stack buffer indicates the total number of bytes required for the storage of properties, and the second 8B a pointer to the array on the heap that stores properties. This technique is called small buffer optimization.</p>
<p><img src="https://i.imgur.com/LWP2te8.png" alt=""></p>
<p>Additionally, there were various other smaller improvements of existing internal data structures, most notably the <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> which is used as an indexing data structure. The combined result was a massive improvement in memory usage with a substantial reduction in memory fragmentation while ensuring equivalent or better performance. Before jumping into the analysis and explanations, let’s have a look at the benchmark setup.</p>
<h2>Setup</h2>
<h3>Target Systems</h3>
<p>The benchmark tests different Memgraph versions. The release dates and details of each version are the following:</p>
<ul>
<li><strong>v0.15.2</strong>, October 23, 2019, the last version of Memgraph that used an in-memory storage engine based on copies of nodes/edges.</li>
<li><strong>v0.50.0</strong>, December 11, 2019, introduced the new in-memory storage engine based on data changes and a C-based storage API.</li>
<li><strong>v1.0.0</strong>, April 6, 2020, introduced a Python-based storage API.</li>
<li><strong>v1.1.0</strong>, July 1, 2020, added encoding and compression to node and edge properties.</li>
</ul>
<p>The <a href="https://docs.memgraph.com/memgraph/changelog">Memgraph Changelog Docs</a> page contains more details about changes in each version.</p>
<h3>Hardware</h3>
<ul>
<li>Server: HP DL360 G6</li>
<li>CPU: 2x Intel Xeon X5650 6C12T @ 2.67GHz</li>
<li>RAM: 144GB</li>
<li>Disk: 120GB SSD</li>
<li>OS: Debian 9 Stretch</li>
</ul>
<h3>Workload</h3>
<p>The benchmark consists of several different queries that test the performance of the graph database. Typical graph database workloads consist of READ, CREATE, and ANALYZE queries.</p>
<p>Memgraph is particularly well suited for hybrid transactional-analytical workloads where it’s crucial to ingest data as fast as possible and simultaneously deliver analytics as quickly as possible. For this reason, we are mostly interested in traversal queries (1-Hop, 2-Hop, etc.) which represent the majority of analytical queries.</p>
<p>In the following table, you can find the exact queries we have used for benchmarking.</p>
<pre><code>|            Query Name             |                                                Query                                                        |  Query Type |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------- |
| Aggregation                       | `MATCH (n:User) RETURN n.age, COUNT(*);`                                                                    | ANALYZE     |
| 1-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;(n:User) RETURN n.id;`                                                          | ANALYZE     |
| 2-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                            | ANALYZE     |
| 3-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                       | ANALYZE     |
| 4-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                  | ANALYZE     |
| 2-Hop Variable Expand             | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id;`                                          | ANALYZE     |
| 2-Hop Variable Expand with Result | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id, n;`                                       | ANALYZE     |
| Shortest Path                     | `MATCH p=(n:User {id: $from})-[*bfs..15]-&gt;(m:User {id: $to}) RETURN extract(n in nodes(p) | n.id) AS path;` | ANALYZE     |
| Insert New Relationship           | `MATCH (n:User {id: $from}), (m:User {id: $to}) WITH n, m CREATE (n)-[e:Temp]-&gt;(m) RETURN e;`               | CREATE      |
| Find Node                         | `MATCH (n:User {id : $id}) RETURN n;`                                                                       | READ        |
| Insert a New Node                 | `CREATE (n:UserTemp {id : $id}) RETURN n;`                                                                  | CREATE      |
</code></pre>
<p>The benchmarking harness executed all queries against the <a href="https://snap.stanford.edu/data/soc-Pokec.html">Pokec dataset</a> which contains 1.6M nodes and 30.6M edges. Given that the goal of each benchmark is to saturate the target system to extract its peak characteristics, we took great care in carefully designing and polishing our setup. Some of the essential elements of the harness are:</p>
<ul>
<li>optimized C/C++ client to minimize client overhead.</li>
<li>fresh dataset load before each execution.</li>
<li>concurrent execution (up to 12 cores) to push Memgraph to its limits.</li>
</ul>
<h2>Data Import Analysis</h2>
<p>Before delving deep into the workload queries execution analysis, a couple of notes about the data import.</p>
<p>The harness imported data in a real-time manner, equivalent to normal query execution by running queries. The data was imported using 8 concurrent clients.  Throughput and peak memory usage were measured during the data import. A couple of interesting insights emerged. On the memory usage side, there is already a massive difference between Memgraph versions. <strong>Before v0.50.0</strong>, Memgraph stored all data modifications as whole copies of the modified objects. By removing the need to make whole copies of database objects, versions <strong>after v0.50.0</strong> provide a significantly less memory usage. The same benefits apply to the runtime environment since the import uses regular queries.</p>
<p><img src="https://i.imgur.com/VfDzuCw.png" alt=""></p>
<p>At this point, you might be wondering about the import speed. As the chart below shows, throughput on basic CREATE queries also improved. Since data copying is generally a fast operation, throughput improvement is not huge but is still significant. One important thing to notice is the difference between v1.0.0 and v1.1.0. <strong>v1.1.0</strong> has almost the same throughput as versions before even though more work is involved in property compression.</p>
<p><img src="https://i.imgur.com/hsh6uDj.png" alt=""></p>
<h2>Query Execution Analysis</h2>
<p>Let’s start analyzing the <strong>workload queries</strong>. The following radar chart shows peak memory usage during query execution across different Memgraph versions. Keep in mind that less is better.</p>
<p>As you can see, <strong>v1.1.0 uses ~50%</strong> less memory compared to v0.15.2. v0.50.0 and v1.0.0 fall in-between with almost no difference because not much from the storage perspective changed between these two versions. The most significant difference is between v0.15.2 and v0.50.0 (introduction of the new storage engine), and v1.0.0 and v1.1.0 (introduction of encoded and compressed properties).</p>
<p><img src="https://i.imgur.com/4ETpDXT.png" alt=""></p>
<p>On the other hand, while looking at memory, it’s also critical to observe what is happening with the throughput. Generally, there is a well-known trade-off between space and time. But, as you can see in the following chart, v1.1.0 has the best performance. Please note that in this case, more is better.</p>
<p><img src="https://i.imgur.com/c0nBqJS.png" alt=""></p>
<p>Of course, not all queries yield significant throughput improvements. E.g., the <code>Insert New Node</code> query performance stayed similar across different Memgraph versions. Nonetheless, the following chart illustrates well how Memgraph scales with the number of concurrent requests.</p>
<p><img src="https://i.imgur.com/vIy7rTM.png" alt=""></p>
<p>The new storage engine also introduced a feature where it is possible to disable storing properties on edges. Sometimes graph datasets don’t have any data attached to edges. Memgraph offers a configuration option to remove all associated data structures required to store data on edges. As you can see in the following chart, by not having properties on edges, memory usage goes down by almost 50% (in addition to the reductions mentioned above). v0.15.2 can’t disable the property storage on edges, so the chart shows nothing there. Using all the improvements in new versions of Memgraph you can store the same dataset in 3.36x less memory (comparing v0.15.2 with properties enabled and v1.1.0 with properties disabled).</p>
<p><img src="https://i.imgur.com/PtQviBf.png" alt=""></p>
<p>The rest of the charts show performance for each query with regards to linear scalability. Linear scalability is the ability of a system to handle more work by adding more resources linearly. E.g., by doubling the number of cores, the system is capable of executing twice as many queries. In practice, it’s impossible to reach perfect linear scalability due to various overheads.  The real question is how far Memgraph is from linear scalability? As you can see below, not by a lot.</p>
<p>The following chart shows throughput data for the simple read query (Find Node). The node lookup inside Memgraph has an O(logN) complexity.</p>
<p><img src="https://i.imgur.com/0z46Rg5.png" alt=""></p>
<p>In the next case, instead of reading, Memgraph creates an edge. The operation contains two node lookups and one edge write. Which means it’s very similar to the Find Node query. Instead of one lookup, the action has two lookups and one write. The chart looks very similar to the Find Node chart.</p>
<p><img src="https://i.imgur.com/ZWzeFc6.png" alt=""></p>
<p>By moving towards more complex queries, there is a more significant scalability difference between previous versions of Memgraph and the latest ones. v0.15.2 is far behind the latest versions.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-1-benchmarks">https://memgraph.com/blog/memgraph-1-1-benchmarks</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-1-benchmarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651091</guid>
            <pubDate>Thu, 01 Oct 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slide deck presentations are the worst way to share knowledge remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650821">thread link</a>) | @mcrittenden
<br/>
October 1, 2020 | https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1717">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Nobody is paying attention to your remote slide deck presentation. In person? Sure. But not remote. They’re distracted. They’re multitasking. The internet is irresistible when there’s nobody watching over their shoulder.</p>



<p>They’re catching up on email or checking Slack or playing online poker or getting some actual work done. At best, they’re listening to you in the background.</p>



<p>Give it up. Stop spending hours putting together presentations that help no one. </p>



<p>Instead, write up a document and share it around ahead of time. Let people read it and understand it on their own. Or, <a href="https://www.cnbc.com/2019/10/14/jeff-bezos-this-is-the-smartest-thing-we-ever-did-at-amazon.html">do what Amazon does</a> and set aside reading time for it at the beginning of the meeting to remove all excuses. </p>



<p>Then the meeting itself can be a Q&amp;A or a discussion instead of a presentation. You can use your time together to be <em>together</em> and to dig into the topic as a group. It’ll be more valuable for everyone, including yourself. </p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650821</guid>
            <pubDate>Thu, 01 Oct 2020 13:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using His Bike as an Ambulance, Man Saves 5k Lives]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650761">thread link</a>) | @stanrivers
<br/>
October 1, 2020 | https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/ | <a href="https://web.archive.org/web/*/https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mh-wrapper">

<!-- Easy Plugin for AdSense V8.7 -->
<!-- [leadin: 0 urCount: 0 urMax: 0] -->

<!-- Easy Plugin for AdSense V8.7 -->
<p><strong>Using His Bike Ambulance, this Man Saved 5000 Lives from 20 Villages!</strong></p>
<p><img loading="lazy" src="https://www.myindiamyglory.com/wp-content/uploads/2017/08/bike-ambulance.jpg" alt="Karimul Haque and his bike ambulance" width="600" height="315"></p>
<p>Humanity does exist amid adversity. For a person to help a fellow being and the society at large, riches aren’t all that is required. And this happens only in India! This is best corroborated by the selfless service of a tea-garden worker who earns a monthly salary of just Rs. 5000. And he is happy running his family as well as serving people from his village and neighboring villages with this meager amount. He is Karimul Haque from Dhalabari in Jalpaiguri district of West Bengal.</p>

<p>50 year old Karimul Haque runs a bike ambulance for free. He is known in his region as the ‘Bike Ambulance <em>Dada</em>’. The tea garden area is a feast for the eyes, but lack of proper roads, basic amenities and medical facilities are the disadvantages. He ferries the sick to the nearest hospital for free. Till date, Karimul has ferried 5000 poor patients from 20 villages in Jalpaiguri to the hospital since the last 14 years. He is a ray of hope to the poor and needy in his village and neighboring villages.</p>

<p>Karimul says, “Many years ago, my mother suddenly fell ill in the middle of the night. She was in dire need of medical attention. But the hospital was located several kilometers away. I had no vehicle in my house then. Neither was there any ambulance facility nearby. I went from door to door for help, but in vain. And my mother breathed her last. I failed to save her.”</p>

<p>An inconsolable Karimul decided that night that thenceforth he would not let any sick person in his village die due to lack of ambulance facilities. He somehow managed to buy a bike. Some 14 years ago, a co-worker collapsed while on duty. There was no ambulance or four-wheeler to take him to the hospital. Hospital authorities, on knowing about the incident, sent an ambulance. But it would take time. Immediately, an idea struck his mind, as he could not afford his co-worker risk his life waiting for the ambulance. He tied the patient to his back, made him ride pillion and took him to the nearest hospital. His bike ambulance saved his co-worker’s life!</p>

<!-- Easy Plugin for AdSense V8.7 -->
<!-- [midtext: 1 urCount: 1 urMax: 0] -->

<!-- Easy Plugin for AdSense V8.7 -->

<p>And then there was no looking back. He made himself available for 24 hours to ferry any sick person from his village or nearby areas to the hospital for free. With the help of the local doctors, he also started organizing healthcare camps. He has even trained himself in medical first aid from the local doctor to control emergency situations.</p>

<p>“I told my wife that I get a salary of Rs. 5000 per month. When my mother was alive, I spent Rs. 1000 on her for her basic needs. She is no more. I can use that amount of 1000 to buy petrol for my bike ambulance so that I could ferry the sick to the hospital,” said Karimul. He continued after a pause, his eyes already turning moist, “My wife agreed. She had no objection.”</p>

<p>Recently Karimul was invited to the sets of Zee TV’s <em>Sare Ga Ma Pa Little Champs</em> where he was honored with a momento. The audience’s eyes turned moist listening to his story. Famous singer Neha Kakkar, a judge in the singing show, declared that she would donate Rs. 1 lakh to Karimul Haque so that he could use the money over time to buy petrol for his bike ambulance to ferry the sick to the hospital. It was then learnt that Karimul had bought the motorbike on loan. He felt happy to use part of the donated amount to pay his loan.</p>

<p>Karimul Haque’s dream is to make an advanced ambulance equipped with all necessary facilities, available at his village. He was rightly honored with the Padma Shri Award for his efforts.</p>

<p>Bike ambulance image courtesy: Hindustan Times.</p>
<div id="ts-fab-below"><p><span>The following two tabs change content below.</span></p><ul><li><a href="#ts-fab-bio-below">Bio</a></li><li><a href="#ts-fab-latest-posts-below">Latest Posts</a></li></ul><div>
	<div id="ts-fab-bio-below">
		<div><p><img src="https://www.myindiamyglory.com/wp-content/uploads/2016/11/me1-150x150.jpg" width="80" height="80" alt="manoshi sinha"></p>
		</div>
		
		<div>
			<!-- /.ts-fab-header -->
			<p>Manoshi Sinha is a writer, history researcher, avid heritage traveler; Author of 8 books including 'The Eighth Avatar', 'Blue Vanquisher', 'Saffron Swords'.</p>
		</div>
	</div>
	<div id="ts-fab-latest-posts-below">
		<div><p><img src="https://www.myindiamyglory.com/wp-content/uploads/2016/11/me1-150x150.jpg" width="80" height="80" alt="manoshi sinha"></p>
		</div>
		
	</div>
		</div>
	</div><!-- Facebook Comments Plugin for WordPress: http://peadig.com/wordpress-plugins/facebook-comments/ --><h3>Comments</h3>
</div></div>]]>
            </description>
            <link>https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650761</guid>
            <pubDate>Thu, 01 Oct 2020 13:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ElasticSearch Query Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650651">thread link</a>) | @piranha
<br/>
October 1, 2020 | https://solovyov.net/blog/2020/elasticsearch-query-builder/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/elasticsearch-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>This post strives to be useful to anyone who uses ElasticSearch, but all examples are going to be in Clojure since it’s what we use.</p>
<p>ElasticSearch is a wildly useful database (if I may say so), but at times it feels like its query language evolved rather than was planned. This manifests in it being rather ad-hoc and non-orthogonal. Plus using JSON with its low expressiveness adds quite a bit of verbosity. All of this leads to code which builds ES queries being messy and unpleasant to use.</p>
<h2 id="jump-in">Jump in</h2>
<p>Certainly, this was our case a few years ago. Our code was a bunch of functions calling one another, which sounds like functional programming and should be fine, right? Well, as always, the devil is in the detail, and:</p>
<ul>
<li><code>if</code>/<code>case</code>/<code>cond</code> everywhere, various cases were piling on top of each other</li>
<li><a href="https://solovyov.net/blog/2020/higher-order-functions/">functions parametrized with functions</a> — it’s a good tool if you make some higher-order well-documented/understood function, but your business logic should be free of this stuff in general; makes logic hard to be understood</li>
<li>code factorization was quite a bit off: function boundaries felt a bit random</li>
<li>it was written at the start of the current codebase, grew with it and just happened, was never planned</li>
</ul>
<p>Our use case, by the way, is a product filtering API (facets and all that stuff) for an ecommerce site, <a href="https://kasta.ua/">Kasta</a>. Apply some filters and retrieve some aggregations, which is enough of a problem to need a proper solution.</p>
<h2 id="what-is-out-there">What is out there</h2>
<p>So where to go? I looked around and saw stuff like <a href="https://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a>, which was just like ES data structures, but methods on mutable objects. Ugh. Also, <a href="https://elastic-builder.js.org/docs/">ElasticBuilder</a>, which is similar, but with different names, so you have to remember two layers of abstraction. Thanks, but no.</p>
<p>And there are a lot of articles on how to make a query to get what you need from ES, but nobody wrote an article on how to make an ES query builder! Well, except for me. :-)</p>
<h2 id="solution">Solution</h2>
<p>What I like in terms of API is <a href="https://github.com/seancorfield/honeysql">HoneySQL</a>, which is a compiler from maps/vectors to SQL queries. This got me thinking and it turns out that a good question is half of the answer.</p>
<p>What we need is a compiler from our API interface — GET request query string — to an ES query.</p>
<p>Rephrased like this it makes the task almost a walk in the park. A long-long walk, but much less “here be dragons” if-peppered abomination of the past. And the design cornerstones are:</p>
<ul>
<li>branchless pipeline</li>
<li><a href="https://clojuredocs.org/clojure.core/defmulti">multimethods</a></li>
<li>small dictionary of verbs on top of ES incantations</li>
</ul>
<h3 id="data-format">Data format</h3>
<p>Some time ago I stumbled upon a great article about working with ES, and one of its parts <a href="https://project-a.github.io/on-site-search-design-patterns-for-e-commerce/#generic-faceted-search">describes a data model</a> they have used. It proposes that instead of a map like <code>{:brand "wow" :color "red"}</code> you use a following structure:</p>
<pre><code>{:facets [{:name "brand"
           :value "wow"}
          {:name "color"
           :value "red"}]}
</code></pre>
<p>This allows you to query all those facets with a single definition, rather than sending a separate aggregation for every field. More than that, you don’t need to know which facets are available for filtering upfront, since you’ll receive all of them from ES.</p>
<p>In practice, two lists of facets are needed - regular ones and ranged facets. Regular facets are aggregated by <code>terms</code> aggregation, and ranged are aggregated by a combo of <code>ranges</code> and <code>percentiles</code>.</p>
<h3 id="verbs">Verbs</h3>
<p>So we have several functions like <code>not</code>, <code>and</code>, <code>or</code>, <code>term=</code>. They signal intent rather than what ES is doing inside and make reading aggregations and filters much easier. Or should I say <code>should</code> easier? Or <code>must</code> easier? :-) You can understand what’s it doing without opening ES docs. Some examples:</p>
<pre><code>(defn or* [&amp; clauses]
  (let [clauses (filterv identity clauses)]
    (cond
      (empty? clauses)
      {:bool {}}

      (= 1 (count clauses))
      (first clauses)

      :else
      {:bool {:should               clauses
              :minimum_should_match 1}})))


(defn facet= [k v]
  {:nested {:path  "facets"
            :query (and* (term= "facets.id" k)
                         (term= "facets.value" v))}})
</code></pre>
<p>What they accomplish is that most of our lower-level use cases are covered with “loaded” terminology rather than “neutral” (and often cryptic) ES maps.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline is 4 steps:</p>
<ul>
<li><code>qs-&gt;query</code> parses query string, cookies, headers into a basic query data structure</li>
<li><code>make-aggs-q</code> loops through supplied filters and known aggregations, and builds an ES query</li>
<li>then a query is executed</li>
<li><code>aggs-&gt;response</code> converts ES response to what our API returns</li>
</ul>
<p>We represent a user query internally with a map like that:</p>
<pre><code>{:base    {"menu" "pants"}
 :filters {"1" #{"123" "456"}}
 :sort    :default
 :cursor  "ZXCVB"
 :limit   100}
</code></pre>
<p>This is easier to interact with than with just a raw query string.</p>
<h3 id="make-aggs-q">make-aggs-q</h3>
<p>This part is the most convoluted one. It builds the essence of an ES query for aggregations, and consists of:</p>
<ul>
<li>loop over known non-facet aggregations</li>
<li>loop over every facet which was used as a filter in a query</li>
<li>query for regular facets</li>
<li>query for ranged facets</li>
</ul>
<p>What is a facet aggregation is described in <a href="#data-format">data format</a> section. All other aggregations are non-facet and should be explicitly mentioned. Those are filters such as price, depot (whenever they are on stock in our warehouse rather than supplier’s one), supplier, etc. When I look there it feels like most of them need to be in facets. Historical reasons. :)</p>
<p>Every loop then delegates to <code>make-agg</code> multimethod, which builds its piece of the query. Here is an example of a filter for colors - it’s one of the simplest aggregations, just generates a list of colors available for selected products.</p>
<pre><code>(def NESTED-AGG :_nest)

(defn agg-filter [agg filter-data]
  {:filter filter-data
   :aggs   {NESTED-AGG agg}})

(defmethod make-agg :color [filter-name _ filters options]
  [filter-name
   (-&gt; {:terms {:field "color_group"
                :size  (:max-buckets options)}}
       (agg-filter (filters/make filters)))])

</code></pre>
<p><code>filters</code> are filters for the given query except for the one for the given aggregation, so that you’ll receive all possible values for the current aggregation in a given context. So we apply them with an <code>agg-filter</code> function.</p>
<p><code>-&gt;</code> could be confusing, but look at it as a pipeline operator: every function you give it is executed in order.</p>
<p>ElasticSearch aggregation rules are nested, read on to discover why we need <code>NESTED-AGG</code>.</p>
<h3 id="aggs-response">aggs-&gt;response</h3>
<p>This stage loops over response and converts data from ES into API response format. Fortunately most parts of the response are independent, so it’s pretty clean and simple: it’s a loop, which calls <code>extract-agg</code> on every aggregation:</p>
<pre><code>(defn agg-recur [{:keys [doc_count] :as agg}]
  (loop [agg agg]
    (if-let [nested (get agg NESTED-AGG)]
      (recur nested)
      (if-not (:doc_count agg)
        (assoc agg :doc_count doc_count)
        agg))))

(defn aggs-&gt;response [query es-response]
  (for [[k agg] (:aggregations es-response)
     (extract-agg k (agg-recur agg) query))
</code></pre>
<p><code>agg-recur</code> is a way to get to the real data: ES aggregations are very nested. To get through we use key <code>:_nest</code> (value of <code>NESTED-AGG</code>), and then use this <code>agg-recur</code> function.</p>
<p>Unfortunately, there is no good way to pass additional information from <code>make-agg</code> to <code>extract-agg</code>, so it’s stringly-typed, as is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/returning-aggregation-type.html">recommended by ES</a>. Look at our <code>extract-agg</code> multimethod (<code>defmulti</code> defines dispatcher, this is a function which determines which method to call):</p>
<pre><code>(defmulti extract-agg
  (fn [filter-name data query]
    (condp #(str/starts-with? %2 %1) filter-name
      "facet_"      :facet
      "percentile_" :percentile
      "range_"      :range
      :else         filter-name)))
</code></pre>
<p><code>extract-agg</code> methods extract data, sort if necessary (so brands are alphabet-sorted rather than count of matches-sorted), fix up document count (in case of nested aggregations). Here’s an example processing <code>:depot</code>:</p>
<pre><code>(defmethod extract-agg :depot [filter-name agg query]
  (let [cnt (-&gt; agg :real_count :doc_count)]
    [{:id        filter-name
      :widget    :toggle
      :values    [{:key       "true"
                   :doc_count cnt}]
      :doc_count cnt}]))
</code></pre>
<p>That part is pretty simple since you just have to massage data into whatever you need for the API. :)</p>
<h2 id="divide-and-conquer">Divide and conquer</h2>
<p>There is nothing new under the sun. If only the right idea would appear right at the start. :-) Just factor your functions correctly and you’re golden.</p>
<p>In the end what we’ve got is a straightforward pipeline, no parametrization with functions, every chunk of a query is as simple as it gets, and extensibility is just great! It’s been in production for 1.5 years now with no significant changes to the logic, received some new features, and doesn’t feel like it was holding us back.</p>
<p>I hope this post can serve as an inspiration for your code. If you feel confused or have questions, please contact me by email — I would love to make this post more approachable.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/elasticsearch-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650651</guid>
            <pubDate>Thu, 01 Oct 2020 13:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not PHP?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650385">thread link</a>) | @muglug
<br/>
October 1, 2020 | https://mattbrown.dev/articles/why-not-php | <a href="https://web.archive.org/web/*/https://mattbrown.dev/articles/why-not-php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                                
                <p>
                    October 1, 2020 - 
                                            4&nbsp;minute&nbsp;read
                                    </p>
                                <!--
	title: Why not PHP?
	date: 2020-10-01
    author: Matt Brown
    author_link: https://twitter.com/mattbrowndev
-->
<p>I was intrigued by <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust</a>, a list of compelling disadvantages written by someone who uses Rust a lot, and the author of <a href="https://github.com/rust-analyzer/rust-analyzer">a popular Rust static analysis tool</a>. I have a similar relationship to PHP – I use it every day (at <a href="https://vimeo.com/">Vimeo</a>), and I’m the author of <a href="https://psalm.dev/">a popular PHP static analysis tool</a>.</p>
<p>The similarities end there, though – Rust and PHP are very different languages, with very different reputations in the wider programming community. Rust has been getting a lot of hype in the last few years, while PHP has been getting the opposite. Indeed, a lot has been written about PHP from a place of contempt. Here’s my attempt to argue against PHP, but from a place of admiration:</p>
<h2 id="its-mainly-for-serving-simple-http-requests">It’s mainly for serving simple HTTP&nbsp;requests</h2>
<p>PHP was originally designed for the then-nascent world wide web, and its popularity has risen (and, lately, fallen) with the popularity of server-rendered HTML.</p>
<p>Its process model (no shared memory between requests) makes it ideal for serving HTML on a case-by-case basis. If that’s what you’re after, it’s incredibly easy to get started.</p>
<p>On the one hand that means the average PHP programmer never has to worry about memory-related race conditions within a single request, because they simply can’t happen.</p>
<p>But all of PHP’s optimisations for serving individual HTML requests will get in the way if you do, in fact, want to run your own service with shared memory between requests, or any other long-running process. While PHP <em>can</em> do that, its implementation won’t be half as pretty as it would be in a language like Go.</p>
<h2 id="its-relatively-old">It’s (relatively)&nbsp;old</h2>
<p>New programming languages are often a thoughtful combination of languages that came before them. Writing code in a recently-written language can expose you to new idioms, and helps you see the world of programming through a different lens.</p>
<p>PHP is not a new language – it’s 26 years old, and pretty thoroughly-cooked at this point.</p>
<h2 id="no-large-corporate-backers">No large corporate&nbsp;backers</h2>
<p>Some languages come directly from large profitable companies that devote considerable resources to their development (e.g. Go, TypeScript, C#, Swift, Java, Kotlin) while others are sort of adopted by companies (Python at Dropbox, OCaml at Jane St, JS interpreters at Google &amp; Mozilla).</p>
<p>PHP hasn’t had a large corporate backer for a while. As far as I know, only one PHP core engineer is <a href="https://blog.jetbrains.com/phpstorm/2019/01/nikita-popov-joins-phpstorm-team/">paid to work on the language full-time</a>.</p>
<p>Large corporate sponsors can be great for a language. Sponsorship sends a message to other companies that “we trust X to help run our billion-dollar business” and also “if you use X you’ll benefit from the work we’re putting into it”.</p>
<p>PHP’s community is pretty strong, though, and has produced some <a href="https://getcomposer.org/">great</a> <a href="https://phpunit.de/">pieces</a> of <a href="https://symfony.com/">software</a> that have moved the entire ecosystem forward.</p>
<h2 id="many-beginners-few-experts">Many beginners, few&nbsp;experts</h2>
<p>PHP is very easy to get into, and it’s easy to make things in PHP that other people find useful.</p>
<p>PHP’s community is also sort of like a high school, where other language communities (e.g. Rust) are like universities: the teachers in a high school can make you a productive member of society, but if you’re looking to surround yourself with professors who are specialists in things you find interesting, universities are a better bet.</p>
<p>This reputation problem isn’t unique to PHP – other popular interpreted languages like Ruby have it too – but it can deter people who want to feel smart when writing code.</p>
<p>JavaScript had this problem for years, but in the last decade several big internet companies have thrown tons of money at its language ecosystem, and JavaScript experts are now plentiful.</p>
<h2 id="it-has-many-minor-potholes">It has many minor&nbsp;potholes</h2>
<p>API inconsistency comes up repeatedly in peoples’ criticism of PHP. While it’s something the vast majority of PHP developers get used to quickly, there’s no getting around the clunkiness of some core library functions: <code>strpos($haystack, $needle)</code> vs <code>in_array($needle, $haystack)</code> and <code>array_map($callback, $array)</code> vs <code>array_filter($array, $callback)</code>.</p>
<hr>
<h2 id="where-do-we-go-from-here">Where do we go from&nbsp;here?</h2>
<p>People have been predicting its demise for a couple of decades, but PHP’s still a pretty popular option. Why? Despite everything written above, there’s never been a better time to start a new PHP project.</p>
<p>PHP now has a huge ecosystem of open-source packages, and its main download hub has been accessed <a href="https://packagist.org/statistics">over a billion times last month</a> by developers around the world. That’s up roughly 50% from the year before, and doubly impressive once you factor in all the things PHP can do natively.</p>
<p>There’s also good reason to be optimistic about PHP’s future. Ten years ago, things were looking much more dire, but the community has invested a lot of time and effort into improving things:</p>
<ul>
<li>
<strong>Package management</strong><br>
<a href="https://getcomposer.org/">Composer</a>, introduced in 2012, has made setting up a new project a breeze</li>
<li>
<strong>Static analysis</strong><br>
A bunch of great competing static analysis tools (including my own, <a href="https://psalm.dev/">Psalm</a>) have been released in the last five years</li>
<li>
<strong>Raw performance</strong><br>
At Vimeo time spent in PHP itself has roughly halved since we upgraded from PHP 5 to PHP 7. Each new version squeezes out a little more speed, and PHP handily outperforms similar interpreted languages like Ruby, Python and Node</li>
<li>
<strong>Standard ways to write modern PHP</strong><br>
<a href="https://www.php-fig.org/psr/">PSR</a> emerged from a primordial soup of spaghetti code, and now pretty much all modern PHP looks very similar</li>
</ul>
<hr>
<p><a href="https://www.reddit.com/r/PHP/comments/j37zih/why_not_php/">Discuss on /r/php</a></p>
            </article>
        </div></div>]]>
            </description>
            <link>https://mattbrown.dev/articles/why-not-php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650385</guid>
            <pubDate>Thu, 01 Oct 2020 13:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Opposition Leader Navalny on His Poisoning: “Putin Was Behind the Crime”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650372">thread link</a>) | @rerx
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;54d78056-207d-4c6f-b894-b46c2774c039&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;49f4ff5c-1177-424f-bbd1-64d7a2588452&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg" srcset="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w520_r1.77_fpx58_fpy45.jpg 520w, https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto: <p>Peter Rigaud / DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p>It's six o'clock in the morning on Wednesday when Alexei Navalny shows up at the Berlin editorial office of DER SPIEGEL for an interview. The office is located a few hundred meters from Charité University Hospital, where Navalny spent a month receiving treatment, hovering between life and death.</p>


<div>
<p>Navalny, who was poisoned with the nerve agent Novichok, was only released from the hospital last week.</p><p>Four agents from the State Office of Criminal Investigation (LKA) accompanied him during his visit. Navalny, who wasn't able to walk not long ago, took the stairs to the office rather than the elevator.</p><p>Alexei Navalny, 44, is Russia's most prominent opposition politician. Following the attempt on his life on August 20 in the Siberian city of Tomsk, however, he is now squarely in the international spotlight. German Chancellor Angela Merkel intervened for him to be allowed to leave Russia for treatment in Germany. Because he was poisoned with a substance that can essentially only come from state-run laboratories in Russia, the question of Russian President Vladimir Putin's personal responsibility is one that many around the world are asking. It's not the first time that a Russian opposition politician was to be killed, but it is the first time that the circumstances seem to so clearly point at the Kremlin.</p>
</div>

<div>
<p>The interview with DER SPIEGEL is the first that Navalny has given since the attack. He is alert at the meeting and he remembers many things - and yet the impact of the poisoning is still clear. Scars on his neck show where he was hooked up to a ventilator. When he pours water from the bottle into his glass, it is obvious that it requires effort and he has to use both hands. But he refuses assistance. "My physical therapist says I should try to do everything myself," he says</p><p>Navalny&nbsp;seems more nervous than he did at previous meetings. His face is gaunter and his figure more angular after losing 12 kilos. But his voice is the same as it has always been, as is his humor, his irony. Sitting next to him is his spokeswoman, Kira Yarmysh, who was with him on the plane on August 20 when he first began showing signs of having been poisoned.</p>
</div>

<p>Before the interview begins, he has something he wants to say.</p>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;02a833ee-fba3-4850-98b7-7c4ed3654454&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;1cb8d8b5-40f6-4b1c-b63a-25195830e469&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," width="683" height="498" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," title="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison." alt="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.">
</span>
</span>
</span>
</p><figcaption>
<p>This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.</p>
<span>
Foto: AFP
</span>
</figcaption>
</div>
</div>
</div>
</figure><p><strong>Navalny:</strong> It is important to me that this interview appears in the German press. I have never been closely associated with Germany. I don't know anyone here. I didn't know a single politician. And yet it turned out - you see, my voice is trembling, I have become so emotional - that German politicians and Angela Merkel have taken an interest in my fate and saved my life. The doctors at Charité saved my life a second time and, more importantly, they gave me back my personality. So, the first thing I want to say is: I feel a tremendous gratitude to all Germans. I know it sounds a bit overblown, but Germany has become a special country for me. I had few connections here before and only visited Berlin for the first time three years ago! And then so much human compassion from so many people.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Our readers will be happy to hear that. How are you doing Mr. Navalny?</p><p><strong>Navalny:</strong> Much better than three weeks ago, and it is getting better each day. Not long ago, I could only climb 10 steps, but now I can make it up to the 5th floor. The most important thing for me is that my mental abilities have returned. Well, maybe we will find the opposite to be true during this interview (<em>laughs</em>).</p><p><strong>DER SPIEGEL:</strong> You wrote on Instagram that you are no longer able to stand on one foot.</p><p><strong>Navalny:</strong> Now I can again. My next challenge is to stand on one leg and stretch the other leg forward, which I practice every day. These are actually exercises that ninety-year-olds do in the park.</p><p><strong>DER SPIEGEL:</strong> Are you able to sleep well?</p><p><strong>Navalny:</strong> That's my biggest problem. I used to laugh about people with sleep problems because I never had them myself. But then came the coma, the anesthesia, the weaning off of the sedatives, that long hovering state when I was neither asleep nor awake. I haven't been able to sleep without sleeping pills since.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;ae3d6308-8e23-4f16-b6a0-25e3b742c41c&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;021a5ae5-3451-4625-ade5-73f7a5f75406&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," width="683" height="497" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," title="Navalny was flown from Omsk to Berlin on this chartered plane." alt="Navalny was flown from Omsk to Berlin on this chartered plane.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny was flown from Omsk to Berlin on this chartered plane.</p>
<span>
Foto: Kira Yarmysh / dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> When you lost consciousness, you were a figure in Russian politics. When you woke from the coma, you were a global political figure. Chancellor Merkel even visited you at your bedside. What did you talk about?</p><p><strong>Navalny:</strong> That was last week. It was totally unexpected. The door opened, my doctor came in - and Merkel. It was a private meeting with my family - my wife Julia and my son Zahar were there. I can't tell you the details, but we didn't discuss anything secret or sensational. The visit was a gesture. I was impressed by how precisely she knows Russia and my case. She knows some of the details better than I do. She really has a deep understanding of what is going on in Russia. And when you talk to her, you understand why she has been at the top in Germany for so long. I thanked her for her efforts and she said: "I only did my duty."</p><p><strong>DER SPIEGEL:</strong> What has daily life been like for you since you left the hospital? Where are you living?</p><p><strong>Navalny:</strong> I live with my wife and my son here. My daughter has returned to Stanford University. We've rented an apartment. My everyday life is monotonous. I exercise daily - that's all I do. In the morning, I take a walk in the park - that's my job. Then I do the exercises with the doctor. In the evening, I go for another walk. During the day, I try to work on the computer. The doctors say I can be restored to 90 percent of my former self, maybe even 100 percent, but nobody really knows for sure. Basically, I'm a bit of a guinea pig. After all, there aren't many people you can observe who are still alive after being poisoned with a nerve agent. At some point, I will probably be written about in medical journals. And I am happy to share my experiences. Seriously: The Russian leadership has developed such a penchant for poisoning that it is not going to stop doing so anytime soon. My medical history will be instructive.</p><p><strong>DER SPIEGEL:</strong> Going by your posts on social media, it appears that you left your bed in the hospital often.</p><p><strong>Navalny:</strong> The doctors and nurses at Charité are the most tolerant people in the world. I was a difficult patient. I would get up at night in the intensive care unit, and one time I tore all the tubes out of my body and started bleeding. Later, when I was already conscious and could recognize and talk to the people around me, I had hysterical fits. I said I was healthy and wanted to go to a hotel. Weeks later, I understood that this strange behavior was a consequence of the poisoning.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;39d3599b-4262-4232-b6f7-b6016c2162e6&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;b9fc5afa-c7c7-4363-b4a4-32e473212560&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" width="718" height="508" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" title="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital" alt="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital">
</span>
</span>
</span>
</p><figcaption>
<p>A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital</p>
<span>
Foto: Alexei Navalny / ddp media
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> Let's go over what happened to you, and we'll start with your last memory before you lost consciousness. It's August 20, at eight o'clock in the morning. You're sitting in a plane from Tomsk to Moscow. You had spent a few days in Siberia. What was going through your head?</p><p><strong>Navalny:</strong> It was a wonderful day. I'm on my way home, with a strenuous and successful business trip behind me. We shot videos for the regional election campaign, and everything had gone according to plan. I'm sitting comfortably in my seat and I'm looking forward to a quiet flight during which I can watch a series. Once I get back to Moscow, I am looking forward to recording my weekly YouTube show and then spending the weekend with my family. I feel good, as I did at the airport. And then… it's hard to describe because there is nothing to compare it with. Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you. You can no longer concentrate. I can feel that something is&nbsp;wrong. I break out in a cold sweat. I ask Kira beside me for a tissue. Then I say to her: Speak to me. I need to hear a voice - something's wrong with me. She looks at me like I'm crazy and starts talking.</p><p><strong>DER SPIEGEL:</strong> What happened then?</p><p><strong>Navalny:</strong> I don't understand what is happening to me. The stewards come by with the trolley. I first want to ask them for water, but I then say: No, let me by, I'm going to the bathroom. I wash myself with cold water, sit down and wait and then wash myself again. And then I think: If I don't get out now, I'll never get out. The most important feeling was: You are feeling no pain, but you know you're dying. And I mean, right now, yet nothing hurts. I leave the toilet, turn to the steward - and instead of asking for help, I say, to my own surprise: "I've been poisoned. I'm dying." And then I lay down on the ground in front of him to die. He’s the last thing I see - a face that looks at me with slight astonishment and a light smile. He says: "Poisoned?" and by that he probably means I was served bad chicken.</p><p>And the last thing I hear, already on the floor is: Do you have heart problems? But my heart doesn't hurt. Nothing hurts. All I know is that I am dying. Then I hear voices growing ever quieter, and a woman calling: "Don't leave us! Don't leave us!" Then it's over. I know I'm dead. Only later would it turn out that I was wrong.</p><p><strong>DER SPIEGEL:</strong> There's a video shot by a passenger in which your screams can be heard on the plane. It sounds horrible, almost like the cries of an animal.</p><p><strong>Navalny:</strong> I've watched it - it's circulating on the internet under the title: "Navalny screaming in pain." But it wasn't pain. It was something else, worse. Pain makes you feel like you're alive. But in this case, you sense: This is the end.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;fe4efb86-8391-4038-9e36-19f7e61bb096&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;1da9b8ff-013c-43d3-92c1-036cb38a026e&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," width="655" height="757" sizes="655px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," title="Navalny posted photos of himself on Instagram showing him on the balcony of his room." alt="Navalny posted photos of himself on Instagram showing him on the balcony of his room.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny posted photos of himself on Instagram showing him on the …</p></figcaption></div></div></div></figure></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650372</guid>
            <pubDate>Thu, 01 Oct 2020 13:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A free remote desktop client for macOS, Linux und Windows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650312">thread link</a>) | @aphelion_
<br/>
October 1, 2020 | https://thincast.com/en/products/client | <a href="https://web.archive.org/web/*/https://thincast.com/en/products/client">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div uk-grid="">
        <p><img width="96" height="96" src="https://thincast.com/images/client.png">
        </p>
        <p><img width="48" height="48" src="https://thincast.com/images/client.png">
        </p>
        
    </div>
                <h3>A free Remote Desktop Client for Linux, macOS and Windows.</h3>
        <p>A free Remote Desktop Client for Linux, macOS and Windows.</p>
        <p>Thincast Client turns your computer into a fully Remote Desktop Protocol (RDP) Client, making it easy to connect remotely to your company's infrastructure. Using the Remote Desktop (RD) WebAccess Client you gain easy access to and control of published virtual machines (with Thincast Workstation), desktop sessions and applications. Its built-in, hardware-accelerated Remote Desktop Client (RDC) delivers a rich user experience by saving valuable CPU power.</p>
           </div></div>]]>
            </description>
            <link>https://thincast.com/en/products/client</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650312</guid>
            <pubDate>Thu, 01 Oct 2020 12:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China forces international birding organization to eject Taiwan, gags employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650128">thread link</a>) | @ilamont
<br/>
October 1, 2020 | https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/ | <a href="https://web.archive.org/web/*/https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<hr>



<p><strong>The&nbsp;</strong><a href="https://www.theguardian.com/world/2020/sep/25/hawk-or-dove-birdwatching-worlds-feathers-ruffled-over-taiwan-independence"><strong>ejection</strong></a><strong>&nbsp;of Taiwan’s Chinese Wild Bird Federation (CWBF) from BirdLife International and the subsequent&nbsp;</strong><a href="https://www.reuters.com/article/us-taiwan-environment-politics/british-bird-group-issues-gag-order-over-taiwan-china-issue-idUSKBN2690BX"><strong>gag order</strong></a><strong>&nbsp;asking BirdLife employees to refrain from speaking to the press may appear at first glance to be the smallest of China’s many micro-aggressions, but is indicative of a serious security threat.&nbsp;</strong></p>



<hr>



<p>BirdLife notified the CWBF on September 7 that their 24-year-old partnership had ended. The reason? BirdLife asked the Taiwanese partner to change their official Chinese name and to sign a document promising to neither promote the independence of Taiwan from China nor to advocate the legitimacy of the Republic of China (Taiwan’s official name). It didn’t matter that the Federation had never taken a political stance on Taiwan’s status. It didn’t matter that they had already changed their English name three times at the behest of BirdLife, even twisting facts to alter the name from “Wild Bird Federation Taiwan” to “Chinese Wild Bird Federation” in 2007. BirdLife wouldn’t even give them time, as a democratically run NGO, to debate this at the Annual General Meeting. They simply kicked them out of the nest.&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/29/mbss-admits-full-responsibility-for-the-khashoggi-murder-what-this-means-for-the-kingdoms-allies/"><strong>🏅2020 CIPS Blog Award Winner! MBS admits “full responsibility” for the Khashoggi murder: What this means for the Kingdom’s allies</strong></a></p>



<hr>



<p>Taiwan protested. The&nbsp;<a href="https://focustaiwan.tw/politics/202009150029">Ministry of Foreign Affairs</a>&nbsp;condemned China for interfering in international conservation NGOs and BirdLife for cooperating with China to coerce the CWBF into taking a political stance.&nbsp;On September 19, the General Assembly of the CWBF decided to finally revert to the more accurate name in English as the&nbsp;<a href="https://www.bird.org.tw/news/602?fbclid=IwAR1RgQoW9nXgZCHRBxlGgr7qamTs_nRhbUyffndt5WEbziqkX92HmKTIdDA">Taiwan Wild Bird Federation</a>.&nbsp;</p>



<p><strong>What is BirdLife?</strong></p>



<p>BirdLife, a global coalition of scientific and conservation NGOs, is active in Canada through Nature Canada and Birds Canada. It coordinates the IBA (Important Bird and Biodiversity Areas) program that identifies and manages important bird habitat sites. Because birds do not respect borders, collaboration between countries is central to BirdLife’s mandate. Since 2000, Taiwan’s Forestry Bureau has contributed to BirdLife conservation projects in Madagascar, Cambodia, and Sao Tome.&nbsp;</p>



<p>Taiwan is second only to Japan in Asia for bird conservation and scientific research. Taiwan hosts 682 bird species, 29 endemic species, and 43 endangered species. Taiwanese birders are active contributors to eBird, the world’s most comprehensive citizen science project in ornithology. The CWBF does important work to protect the Chinese Crested Tern and Black-faced Spoonbill. In 2020, the 4,864 Black-faced Spoonbills that wintered in Taiwan accounted for 57.3% of the population of that endangered species. Migratory birds along the East Asian-Australasian Flyway depend on Taiwan because of its strategic location on their pathways that stretch from Siberia to Australia. Taiwan’s expulsion from BirdLife will hinder cross-border cooperation on conservation, just because China prioritizes its political goals over even pragmatic scientific cooperation. China makes everything into a zero-sum game.&nbsp;</p>



<figure><p>
https://twitter.com/TaiwanBirding/status/1309409778393776128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1309409778393776128%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FTaiwanBirding2Fstatus2F1309409778393776128widget%3DTweet
</p></figure>



<p><strong>China Curtails Freedom of International Civil Society</strong></p>



<p>BirdLife is a dangerous precedent for other NGOs. Because China can pressure one leading NGO into cutting out Taiwan, they will feel emboldened to go after other NGOs – including in Canada. NGOs hoping to expand into China will hesitate to build partnerships with Taiwan. This is a shame because Taiwanese NGOs have strong expertise as well as the financial means to get things done. It is even more unfortunate because democratic Taiwan, like Canada, actually has real social movements run by civilians without government interference. China, on the other hand, strictly limits the freedoms of Chinese NGOs. Since 2017, when China changed its NGO regulations in line with broader security-related legislation, international NGOs have been required to register with the Ministry of Public Security and must have an approved local partner. This means the Chinese Communist Party can use NGOs to export their standards to the world.&nbsp;</p>



<p>Until now, China has not permitted BirdLife to enter China, which means the closest they get is collaboration with the Hong Kong Birdwatching Society. Maybe that is the point. Quite possibly, BirdLife is negotiating with China and took action against Taiwan as a precondition for collaboration. The cost is high. It means letting China dictate the norms of how international NGOs operate. BirdLife even imported Chinese norms on media freedom by issuing a gag order to their employees. And this is in Great Britain, which takes pride in the Magna Charta as one of the founding documents of democracy.&nbsp;</p>



<p>Because of China’s sheer size and long coastlines used by migratory birds, BirdLife is badly needed in China. International bird conservation would improve if China were to open up its own borders to free, unfettered cooperation between Chinese and international NGOs. Bird habitats along migration routes would be best protected if China were to set aside politics and collaborate with Taiwanese ornithologists and conservation scientists&nbsp;&nbsp;like Japan and Russia do in spite of long-standing territorial disputes that straddle bird habitats.&nbsp;&nbsp;</p>



<p><strong>The Bigger Picture</strong></p>



<p>China’s pressure on BirdLife is part of a new strategy. For decades, BirdLife’s Taiwanese partner could simply accept a compromise name of “Chinese Wild Bird Federation” internationally; and “Republic of China Wild Bird Federation” at home. BirdLife and the CWBF could collaborate as long as they remained silent about China-Taiwan relations. The most troubling sign is not the requested name change, but the fact that the CWBF was asked to commit themselves to a political stance. China is trying to shape a world in which even silence is not an option. China’s goal is to get the entire world to parrot its claims that Taiwan is part of the People’s Republic of China. This must be seen as part of a larger strategy in which the Chinese military during a global pandemic feels emboldened to practice invasion of Taiwan and to regularly send jets into Taiwanese airspace.&nbsp;</p>



<p>BirdLife should be reminding the world that coastal birds inhabiting wetlands along the Taiwan Straits would be the first victims if China were to ever invade Taiwan. Instead, their abandonment of the Taiwan Wild Bird Federation gives Beijing one more sign that the world does not oppose their strategy to annex Taiwan. Acquiescing to Chinese micro-management of international NGOs is not good for the birds and, in the long run, it is dangerous for the security of the entire region.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/27/twitter-conference-understanding-the-five-eyes/"><strong>Twitter Conference: Understanding the Five Eyes</strong></a></p>




</div></div></div>]]>
            </description>
            <link>https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650128</guid>
            <pubDate>Thu, 01 Oct 2020 12:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segment Tree – Competitive Programming Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650084">thread link</a>) | @pmoriarty
<br/>
October 1, 2020 | https://cp-algorithms.com/data_structures/segment_tree.html | <a href="https://web.archive.org/web/*/https://cp-algorithms.com/data_structures/segment_tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    


<p>A Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. 
This includes finding the sum of consecutive array elements $a[l \dots r]$, or finding the minimum element in a such a range in $O(\log n)$ time. 
Between answering such queries the Segment Tree allows modifying the array by replacing one element, or even change the elements of a whole subsegment (e.g. assigning all elements $a[l \dots r]$ to any value, or adding a value to all element in the subsegment).</p>

<p>In general a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. 
Additionally it is also possible to apply more complex operations and answer more complex queries (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#advanced-versions-of-segment-trees">Advanced versions of Segment Trees</a>).
In particular the Segment Tree can be easily generalized to larger dimensions. 
For instance with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix.
However only in $O(\log^2 n)$ time.</p>

<p>One important property of Segment Trees is, that they require only a linear amount of memory.
The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.</p>

<h2>Simplest form of a Segment Tree</h2>

<p>To start easy, we consider the simplest form of a Segment Tree. 
We want to answer sum queries efficiently. 
The formal definition of our task is:
We have an array $a[0 \dots n-1]$, and the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). 
The Segment Tree should be able to process both queries in $O(\log n)$ time.</p>

<h3>Structure of the Segment Tree</h3>

<p>So, what is a Segment Tree?</p>

<p>We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \dots n-1]$. 
We then split the array into two halves $a[0 \dots n/2]$ and $a[n/2+1 \dots n-1]$ and compute the sum of each halve and store them. 
Each of these two halves in turn also split in half, their sums are computed and stored. 
And this process repeats until all segments reach size $1$. 
In other words we start with the segment $a[0 \dots n-1]$, split the current segment in half (if it has not yet become a segment containing a single element), and then calling the same procedure for both halves. 
For each such segment we store the sum of the numbers on it.</p>

<p>We can say, that these segments form a binary tree: 
the root of this tree is the segment $a[0 \dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. 
This is why the data structure is called "Segment Tree", even though in most implementations the tree is not constructed explicitly (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#implementation">Implementation</a>).</p>

<p>Here is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree.png" alt="&quot;Sum Segment Tree&quot;"></p>

<p>From this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. 
The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. 
Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \dots + 2^{\lceil\log_2 n\rceil} = 2^{\lceil\log_2 n\rceil + 1} \lt 4n$.</p>

<p>It is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. 
We can see that behavior in the image.
For now we can forget about this fact, but it will become important later during the implementation.</p>

<p>The height of the Segment Tree is $O(\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.</p>

<h3>Construction</h3>

<p>Before constructing the segment tree, we need to decide:</p>

<ol>
<li>the <em>value</em> that gets stored at each node of the segment tree.
For example, in a sum segment tree, a node would store the sum of the elements in its range $[l, r]$.</li>
<li>the <em>merge</em> operation that merges two siblings in a segment tree.
For example, in a sum segment tree, the two nodes corresponding to the ranges $a[l_1 \dots r_1]$ and $a[l_2 \dots r_2]$ would be merged into a node corresponding to the range $a[l_1 \dots r_2]$ by adding the values of the two nodes.</li>
</ol>

<p>Note that a vertex is a "leaf vertex", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.</p>

<p>Now, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the <code>merge</code> function.
And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.</p>

<p>It is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:</p>

<ol>
<li>recursively construct the values of the two child vertices</li>
<li>merge the computed values of these children.</li>
</ol>

<p>We start the construction at the root vertex, and hence, we are able to compute the entire segment tree.</p>

<p>The time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).</p>

<h3>Sum queries</h3>

<p>For now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \dots r]$ in $O(\log n)$ time.</p>

<p>To do this, we will traverse the Segment Tree and use the precomputed sums of the segments.
Let's assume that we are currently at the vertex that covers the segment $a[tl \dots tr]$.
There are three possible cases.</p>

<p>The easiest case is when the segment $a[l \dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \dots r] = a[tl \dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.</p>

<p>Alternatively the segment of the query can fall completely into the domain of either the left or the right child.
Recall that the left child covers the segment $a[tl \dots tm]$ and the right vertex covers the segment $a[tm + 1 \dots tr]$ with $tm = (tl + tr) / 2$. 
In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.</p>

<p>And then there is the last case, the query segment intersects with both children. 
In this case we have no other option as to make two recursive calls, one for each child.
First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. 
In other words, since the left child represents the segment $a[tl \dots tm]$ and the right child the segment $a[tm+1 \dots tr]$, we compute the sum query $a[l \dots tm]$ using the left child, and the sum query $a[tm+1 \dots r]$ using the right child.</p>

<p>So processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). 
And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. 
In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.</p>

<p>In other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.</p>

<p>Obviously we will start the traversal from the root vertex of the Segment Tree.</p>

<p>The procedure is illustrated in the following image.
Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\sum_{i=2}^4 a[i]$.
The colored vertices will be visited, and we will use the precomputed values of the green vertices.
This gives us the result $-2 + 1 = -1$.</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree-query.png" alt="&quot;Sum Segment Tree Query&quot;"></p>

<p>Why is the complexity of this algorithm $O(\log n)$?
To show this complexity we look at each level of the tree. 
It turns out, that for each level we only visit not more than four vertices. 
And since the height of the tree is $O(\log n)$, we receive the desired running time.</p>

<p>We can show that this proposition (at most four vertices each level) is true by induction.
At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. 
Now let's look at an arbitrary level.
By induction hypothesis, we visit at most four vertices. 
If we only visit at most two vertices, the next level has at most four vertices. That trivial, because each vertex can only cause at most two recursive calls. 
So let's assume that we visit three or four vertices in the current level. 
From those vertices, we will analyze the vertices in the middle more carefully. 
Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. 
Therefore these vertices will not make any recursive calls. 
So only the most left, and the most right vertex will have the potential to make recursive calls. 
And those will only create at most four recursive calls, so also the next level will satisfy the assertion.
We can say that one branch approaches the left boundary of the query, and the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cp-algorithms.com/data_structures/segment_tree.html">https://cp-algorithms.com/data_structures/segment_tree.html</a></em></p>]]>
            </description>
            <link>https://cp-algorithms.com/data_structures/segment_tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650084</guid>
            <pubDate>Thu, 01 Oct 2020 12:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT new large tokamak to be the first in history to do self-sustaining reaction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650030">thread link</a>) | @vermontdevil
<br/>
October 1, 2020 | https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/ | <a href="https://web.archive.org/web/*/https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Scientists at the Massachusetts Institute of Technology <a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?smtyp=cur&amp;smid=tw-nytimes&amp;utm_source=Default+audience&amp;utm_campaign=88af7df3e9-EMAIL_CAMPAIGN_2020_09_29_06_13&amp;utm_medium=email&amp;utm_term=0_3cb9478f4c-88af7df3e9-193252502" target="_blank">are developing</a> a type of reactor, called a tokamak, which if it works as intended will generate conditions of sufficient intensity to fuse hydrogen isotopes and harness all the incredible energy released in the process. Their goal is super ambitious: There are other tokamaks, but the MIT scientists expect their large tokamak to be the first in history that is capable of a self-sustaining reaction, and the first that generates more energy than it uses. And they expect to pivot immediately from this historic engineering feat to commercial energy production, and to do all of this on a relatively modest budget, and on a timeline of just three to four years. They expect, in other words, to build the world’s first fully operational thermonuclear fusion reactor, pumping out infinitely sustainable energy right here in the U.S. of A.</p>



<p>I expect to walk up to this tokamak, engage the help of several brawny nuclear engineers, and to be hurled bodily into the inconceivable heat and indescribable beauty of the radiant plasma cloud magnetically suspended in its core, so that I am instantaneously vaporized and eradicated altogether from this plane of existence. The sooner the better.</p>



<p>Initially it seemed that the best choice for this job would be the International Thermonuclear Experimental Reactor, or ITER, in Provence, France. Whereas the <a href="https://www.psfc.mit.edu/sparc" target="_blank">SPARC tokamak</a> being developed by MIT will be the size of a tennis court, <a href="https://www.iter.org/mach" target="_blank">the ITER</a>, which has been in various phases of development and construction for something like 13 years, will eventually be the size of a soccer field. The specs on this thing <a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">are mind-boggling</a>:</p>



<blockquote><p>At its core, densely packed high-precision equipment will encase a cavernous vacuum chamber, in which a super-hot cloud of heavy hydrogen will rotate faster than the speed of sound, twisting like a strand of DNA as it circulates. The cloud will be scorched by electric current (a surge so forceful that it will make lightning seem like a tiny arc of static electricity), and bombarded by concentrated waves of radiation. Beams of uncharged particles—the energy in them so great it could vaporize a car in seconds—will pour into the chamber, adding tremendous heat. In this way, the circulating hydrogen will become ionized, and achieve temperatures exceeding two hundred million degrees Celsius—more than ten times as hot as the sun at its blazing core.</p><cite>&nbsp;Raffi Khatchadourian, <em><a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">The New Yorker</a></em></cite></blockquote>



<p>“Tremendous heat” is an understatement of brain-scrambling, laugh-out-loud proportions. This cloud of plasma will be so hot that no physical substance on Earth or known to humankind could contain it for even a fraction of a second: “Metals, plastics, ceramics, concrete, even pure diamond—all would be obliterated on contact.” The only way to keep the plasma cloud in place, and thus concentrated enough to trigger nuclear fusion, is to squeeze it into a pocket of space using the “titanic forces” of “the largest system of superconducting magnets in the world,” actively cooled to deep-space temperatures in order to survive the heat of an actual star.</p>



<p>So in an ultra-secure chamber in a pit in the countryside of Provence, a blob of the hottest substance in our entire solar system will hang in the air, consuming hydrogen isotopes and generating enough energy to turn diamonds into vapor on contact. There are those who would point out that it is probably a bad idea to let humanity just have the Sun, that inevitably some technician is going to want to pull a viral YouTube prank by aiming a beam of the God Cloud at his buddy’s balls and wind up boring a hole through the planet itself. Or that a janitor will absentmindedly unplug the supercooling systems that allow the mega-magnets to contain the reaction and accidentally atomize the Western Hemisphere. Those people are probably right. Humanity can’t be counted upon to safely handle livestock—putting it in charge of a star seems like something that should not be allowed, by the universe.</p>



<p>But since we are building these things anyway, all I ask is that I be lifted by the scruff of my shirt and the seat of my pants by two strong nuclear technicians and, on the count of three, heaved face-first into whichever of the two God Clouds is completed first. It’s nice to think of all my atoms instantly dispersing into the fabric of the universe, but mostly it will be extremely bitchin’ to be devoured by a star. If this cannot be arranged for whatever reason, I will accept having a beam of the star juice fired into my chest, so that I may utter “fuck yeah” before it is over.</p>
</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650030</guid>
            <pubDate>Thu, 01 Oct 2020 12:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New white paper on open-source Edge Computing with OpenNebula]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649831">thread link</a>) | @amarti
<br/>
October 1, 2020 | https://opennebula.io/get-edge-computing-whitepaper/ | <a href="https://web.archive.org/web/*/https://opennebula.io/get-edge-computing-whitepaper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="full-width-page-wrapper-enterprise">
    <!-- .entry-header -->

	<div id="content">

		<div>

			<div id="primary">

				<main id="main" role="main">

					
						
<article class="page" id="post-27526">

	
	<div>

		
<p>Complete the form below to receive an email with the instructions to download our new white paper on <strong>Edge Computing with OpenNebula</strong> and to subscribe to receive communications like new releases, events, tutorials, workshops, webinars, and more. If you want to learn more about OpenNebula’s open source edge computing platform, please visit <a href="http://oneedge.io/" target="_blank" rel="noreferrer noopener">ONEedge.io</a></p>







<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/09/EdgeWP.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/09/EdgeWP.png 622w, https://opennebula.io/wp-content/uploads/2020/09/EdgeWP-300x216.png 300w" sizes="(max-width: 622px) 100vw, 622px"></figure></div>
















		
	</div><!-- .entry-content -->

</article><!-- #post-## -->

						
					
				</main><!-- #main -->

			</div><!-- #primary -->

		</div><!-- .row end -->

	</div><!-- #content -->

</div></div>]]>
            </description>
            <link>https://opennebula.io/get-edge-computing-whitepaper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649831</guid>
            <pubDate>Thu, 01 Oct 2020 11:49:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We’re working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user’s skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend’s
face. The application analyses the friend’s emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">§ 2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand①"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString①"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand②"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor①"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand③"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype①"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext②"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand④"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand⑤"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑥"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑦"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑧"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑨"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float①"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①①">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①②">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Sortition?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649577">thread link</a>) | @a_imho
<br/>
October 1, 2020 | https://equalitybylot.com/introduction-to-sortition-government-by-jury/ | <a href="https://web.archive.org/web/*/https://equalitybylot.com/introduction-to-sortition-government-by-jury/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<h2>Sortition – government by jury</h2>
<p>In our society elections and democracy are considered inseparable. In fact, this connection is far from clear. The ancient Greeks, for example, thought that elections are part and parcel of an oligarchy<sup><a href="#foot1">1</a></sup>. It was oligarchical Sparta, rather than democratic Athens, that elected its government.</p>
<p>The Athenians had a very different system: political offices were distributed using a lottery. The lottery method – known as Sortition – could be implemented here. If Congresspeople were drawn at random from the U.S. citizenry, Congress would not be an elite body made predominantly of rich, male, white, old lawyers<sup><a href="#foot2">2</a></sup>. Rather, it would look like a statistical sample of the people: it would contain 50% women, 28% hispanics and blacks, rich and poor, young and old, straight and gay, and very few lawyers.</p>
<p>More information on the sortition system can be found on Wikipedia at <a href="http://en.wikipedia.org/wiki/Sortition">http://en.wikipedia.org/wiki/Sortition</a>, and other online resources. One such resource is <em>A Citizen Legislature</em> by Ernest Callenbach and Michael Phillips – a book with a specific proposal for using sortition to select the U.S. House of Representatives. The book is available <a href="https://people.well.com/user/mp/citleg.html">here</a>.</p>
<p>This blog, <a href="https://equalitybylot.wordpress.com/">Equality-by-Lot</a>, is devoted to discussion of issues associated with sortition and with the promotion of sortition as a tool of democracy.</p>
<hr>
<p>Notes:<br>
[1]<a title="foot1" name="foot1"></a> “[T]he appointment of magistrates by lot is thought to be democratic, and the election of them oligarchical, democratic again when there is no property qualification, oligarchical when there is.” Aristotle, Politics, book IV, 9.</p>
<p>[2]<a title="foot2" name="foot2"></a> Of the 535 members of the 112th Congress there were 75 (14%) blacks and hispanics, 91 (17%) women, and 222 (41%) lawyers. The average age in Congress was 62, vs. 37 in the population. Sources: <a href="http://www.senate.gov/reference/resources/pdf/R41647.pdf">http://www.senate.gov/reference/resources/pdf/R41647.pdf</a>, 2009 population data – Statistical abstract of the U.S., 2011, Table 6.</p>
										

				</div></div>]]>
            </description>
            <link>https://equalitybylot.com/introduction-to-sortition-government-by-jury/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649577</guid>
            <pubDate>Thu, 01 Oct 2020 11:09:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supporting a misbehaving NAND ECC engine in the Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649565">thread link</a>) | @pabs3
<br/>
October 1, 2020 | https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/ | <a href="https://web.archive.org/web/*/https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13845">
	<!-- .entry-header -->

	
	
	<div>
		<p>Over the years, Bootlin has grown a significant expertise in U-Boot and Linux support for flash memory devices. Thanks to this expertise, we have recently been in charge of rewriting and upstreaming a driver for the <a href="https://www.arasan.com/products/nand-flash/">Arasan NAND controller</a>, which is used in a number of <a href="https://www.xilinx.com/products/silicon-devices/soc.html">Xilinx Zynq SoCs</a>. It turned out that supporting this NAND controller had some interesting challenges to handle its ECC engine peculiarities. In this blog post, we would like to give some background about ECC issues with NAND flash devices, and then dive into the specific issues that we encountered with the Arasan NAND controller, and how we solved them.</p>

<p>NAND flash memories are known to be intrinsically rather unstable: over time, external conditions or repetitive access to a NAND device may result in the data being corrupted. This is particularly true with newer chips, where the number of corruptions usually increases with density, requiring even stronger corrections. To mitigate this, Error Correcting Codes are typically used to detect and correct such corruptions, and since the calculations related to ECC detection and correction are quite intensive, NAND controllers often embed a dedicated engine, the ECC engine, to offload those operations from the CPU.</p>
<p>An ECC engine typically acts as a DMA master, moving, correcting data and calculating syndromes on the fly between the controller FIFO’s and the user buffer. The engine correction is characterized by two inputs: the size of the data chunks on which the correction applies and the strength of the correction. Old SLC (Single Level Cell) NAND chips typically require a strength of 1 symbol over 4096 (1 bit/512 bytes) while new ones may require much more: 8, 16 or even 24 symbols.</p>
<p>In the write path, the ECC engine reads a user buffer and computes a code for each chunk of data. NAND pages being longer than officially advertised, there is a persistent Out-Of-Band (OOB) area which may be used to store these codes. When reading data, the ECC engine gets fed by the data coming from the NAND bus, including the OOB area. Chunk by chunk, the engine will do some math and correct the data if needed, and then report the number of corrected symbols. If the number of error is higher than the chosen strength, the engine is not capable of any correction and returns an error.</p>

<p>As explained in our introduction, as part of our work on upstreaming the Arasan NAND controller driver, we discovered that this NAND controller IP has a specific behavior in terms of how it reports ECC results: the hardware ECC engine never reports errors. It means the data may be corrected or uncorrectable: the engine behaves the same. From a software point of view, this is a critical flaw and fully relying on such hardware was not an option.</p>
<p>To overcome this limitation, we investigated different solutions, which we detail in the sections below.</p>
<h2>Suppose there will never be any uncorrectable error</h2>
<p>Let’s be honest, this hypothesis is highly unreliable. Besides that anyway, it would imply that we do not differentiate between written/erased pages and users would receive unclean buffers (with bitflips), which would not work with upper layers such as UBI/UBIFS which expect clean data.</p>
<h2>Keep an history of bitflips of every page</h2>
<p>This way, during a read, it would be possible to compare the evolution of the number of bitflips. If it suddenly drops significantly, the engine is lying and we are facing an error. Unfortunately it is not a reliable solution either because we should either trigger a write operation every time a read happens (slowing down a lot the I/Os and wearing out very quickly the storage device) or loose the tracking after every power cycle which would make this solution very fragile.</p>
<h2>Add a CRC16</h2>
<p>This CRC16 could lay in the OOB area and help to manually verify the data integrity after the engine’s correction by checking it against the checksum. This could be acceptable, even if not perfect in term of collisions. However, it would not work with existing data while there are many downstreams users of the vendor driver already.</p>
<h2>Use a bitwise XOR between raw and corrected data</h2>
<p>By doing a bitwise XOR between raw and corrected datra, and compare with the number of bitflips reported by the engine, we could detect if the engine is lying on the number of corrected bitflips. This solution has actually been implemented and tested. It involves extra I/Os as the page must be read twice: first with correction and then again without correction. Hence, the NAND bus throughput becomes a limiting factor. In addition, when there are too many bitflips, the engine still tries to correct data and creates bitflips by itself. The result is that, with just a XOR, we cannot discriminate a working correction from a failure. The following figure shows the issue.</p>
<p><a href="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png"><img loading="lazy" src="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png" alt="Show the engine issue when it creates bitflips when trying to correct uncorrectable data" width="840" height="377" srcset="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png 1024w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-300x135.png 300w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-768x345.png 768w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1200x539.png 1200w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png 1458w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></p>
<h2>Rely on the hardware only in the write path</h2>
<p>Using the hardware engine in the write path is fine (and possibly the quickest solution). Instead of trying to workaround the flaws of the read path, we can do the math by software to derive the syndrome in the read path and compare it with the one in the OOB section. If it does not match, it means we are facing an uncorrectable error. This is finally the solution that we have chosen. Of course, if we want to compare software and hardware calculated ECC bytes, we must find a way to reproduce the hardware calculations, and this is what we are going to explore in the next sections.</p>

<p>There is already a BCH library in the Linux kernel on which we could rely on to compute BCH codes. What needed to be identified though, were the BCH initial parameters. In particular:</p>
<ul>
<li>The BCH primary polynomial, from which is derived the generator polynomial. The latter is then used for the computation of BCH codes.</li>
<li>The range of data on which the derivation would apply.</li>
</ul>
<p>There are several thousands possible primary polynomials with a form like <code>x^3 + x^2 + 1</code>. In order to represent these polynomials more easily by software, we use integers or binary arrays. In both cases, each bit represents the coefficient for the order of magnitude corresponding to its position. The above example could be represented by <code>b1101</code> or <code>0xD</code>.</p>
<p>For a given desired BCH code (ie. the ECC chunk size and hence its corresponding Gallois Field order), there is a limited range of possible primary polynomials which can be used. Given <code>eccsize</code> being the amount of data to protect, the Gallois Field order is the smallest integer <code>m</code> so that: <code>2^m &gt; eccsize</code>. Knowing <code>m</code>, one can check <a href="https://www.partow.net/programming/polynomials/index.html">these tables</a> to see examples of polynomials which could match (non exhaustive). The Arasan ECC engine supporting two possible ECC chunk sizes of 512 and 1024 bytes, we had to look at the tables for <code>m = 13</code> and <code>m = 14</code>.</p>
<p>Given the required strength <code>t</code>, the number of needed parity bits <code>p</code> is: <code>p = t x m</code>.</p>
<p>The total amount of manipulated data (ECC chunk, parity bits, eventual padding) <code>n</code>, also called BCH codeword in papers, is: <code>n = 2^m - 1</code>.</p>
<p>Given the size of the codeword <code>n</code> and the number of parity bits <code>p</code>, it is then possible to derive the maximum message length <code>k</code> with: <code>k = n - p</code>.</p>
<p>The theory of BCH also shows that if <code>(n, k)</code> is a valid BCH code, then <code>(n - x, k - x)</code> will also be valid. In our situation this is very interesting. Indeed, we want to protect <code>eccsize</code> number of symbols, but we currently cover <code>k</code> within <code>n</code>. In other words we could use the translation factor <code>x</code> being: <code>x = k - eccsize</code>. If the ECC engine was also protecting some part of the OOB area, <code>x</code> should have been extended a little bit to match the extra range.</p>
<p>With all this theory in mind, we used GNU Octave to <a href="https://github.com/miquelraynal/find-bch-prim-poly/blob/master/find_bch_polynomial.m">brute force the BCH polynomials</a> used by the Arasan ECC engine with the following logic:</p>
<ul>
<li>Write a NAND page with a <code>eccsize</code>-long ECC step full of zeros, and another one full of ones: this is our known set of inputs.</li>
<li>Extract each BCH code of <code>p</code> bits produced by the hardware: this is our known set of outputs.</li>
</ul>
<p>For each possible primary polynomial with the Gallois Field order <code>m</code>, we derive a generator polynomial, use it to encode both input buffers thanks to a regular BCH derivation, and compare the output syndromes with the expected output buffers.</p>
<p>Because the GNU Octave program was not tricky to write, we first tried to match with the output of Linux software BCH engine. Linux using by default the primary polynomial which is the first in GNU Octave’s list for the desired field order, it was quite easy to verify the algorithm worked.</p>
<p>As unfortunate as it sounds, running this test with the hardware data did not gave any match. Looking more in depth, we realized that visually, there was something like a matching pattern between the output of the Arasan engine and the output of Linux software BCH engine. In fact, both syndromes where identical, the bits being swapped at byte level by the hardware. This observation was made possible because the input buffers have the same values no matter the bit ordering. By extension, we also figured that swapping the bits in the input buffer was also necessary.</p>
<p>The primary polynomial for an <code>eccsize</code> of 512 bytes being already found, we ran again the program with <code>eccsize</code> being 1024 bytes:</p>
<p><code>     eccsize =  1024<br>
     eccstrength =  24<br>
     m =  14<br>
     n =  16383<br>
     p =  336<br>
     k =  16047<br>
     x =  7855<br>
     Trying primary polynomial #1: 0x402b<br>
     Trying primary polynomial #2: 0x4039<br>
     Trying primary polynomial #3: 0x4053<br>
     Trying primary polynomial #4: 0x405f<br>
     Trying primary polynomial #5: 0x407b<br>
     [...]<br>
     Trying primary polynomial #44: 0x43c9<br>
     Trying primary polynomial #45: 0x43eb<br>
     Trying primary polynomial #46: 0x43ed<br>
     Trying primary polynomial #47: 0x440b<br>
     Trying primary polynomial #48: 0x4443<br>
     Primary polynomial found! 0x4443</code></p>

<p>With the two possible primary polynomials in hand, we could finish the support for this ECC engine.</p>
<p>At first, we tried a “mixed-mode” solution: read and correct the data with the hardware engine and then re-read the data in raw mode. Calculate the syndrome over the raw data, derive the number …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</a></em></p>]]>
            </description>
            <link>https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649565</guid>
            <pubDate>Thu, 01 Oct 2020 11:08:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Deep Learning Toolchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649488">thread link</a>) | @rosshemsley
<br/>
October 1, 2020 | https://rosshemsley.co.uk/posts/deep_learning_toolchain/ | <a href="https://web.archive.org/web/*/https://rosshemsley.co.uk/posts/deep_learning_toolchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Successful model development can be surprisingly dependent on good engineering practices. Despite this, many model implementations scattered about Github are difficult to follow and hard to recreate locally.
</p>

<p>
But what should a <em>good model</em> look like? I would propose that the gold standard for a model implemented on Github could be:
</p>
<ol>
<li> The dependencies may be installed automatically, using a single command.</li>
<li> I can build the model in a sandbox without polluting with my dev. environment.</li>
<li> I can easily retrain (and retune!) the model the model exactly as the author did during their development.</li>
<li> I can easily test the inference pass.</li>
<li> I can easily import the model into my own workflow and use it as part of my own code.</li>
</ol>
<p>
It may be that I've never come across a model that met this standard in practical day-to-day development...! But I claim that achieving these things is surprisingly easy given the modern tools available to us.
</p>
<p>
Furthermore, many may simply respond "just ship everything in a Docker container". My response to this is that Docker is a great tool for
<em>deploying</em> a stable, reproducible environment, but Docker images provide a poor basis for sharing code and enabling collaboration.
In this post, we'll focus on designing models that can be <em>installed and imported with a single command, without Docker, on any OS, on any platform,
using the vanilla tools our language provides</em>.
</p>
<p>
So, let's dive in and look at the tools that I use to train models, and how they can be used to meet the gold standard I gave above.
</p>

<h2>Python 3 for model development</h2>
<p><img src="https://rosshemsley.co.uk/posts/deep_learning_toolchain_images/python_logo.png"></p><p>
It may not be controversial these days, but it's worth highlighting that Python 3 is an excellent choice for prototyping and releasing deep learning models. The key feature here is the library support, which is unmatched by other languages.
I tend to target <strong>Python 3.7.5</strong> or later, because I make heavy use of <em><a href="https://docs.python.org/3/library/dataclasses.html">dataclass</a></em>, and it's recent enough to support type annotations. Ubuntu Focal now includes Python 3.8 by default,
so many users will start being able to support this out of the box.
</p>
<h3>Bonus pionts: type annotations</h3>
<p>
If you use type annotations (correctly) in your model, you will get serious points from me.
It's very common that models use native lists, tensors, and numpy arrays almost interchangeably as function
arguments, and so using type hints can make the data flow in your model easier to follow and debug.
</p>
<div><pre><code data-lang="python"><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> typing <span>import</span> List, Optional

<span>import</span> numpy <span>as</span> np
<span>from</span> PIL <span>import</span> Image

<span>@dataclass</span>
<span>class</span> <span>DataSample</span>:
    img: Image
    bboxes: List[np<span>.</span>ndarray]
    scores: Optional[List[float]]

<span>...</span>

sample <span>=</span> DataSample(Image(), [np<span>.</span>array([<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>])], scores<span>=</span>None)</code></pre></div>
<p><em><strong>Above:</strong> an example of using modern Python features to write a clear and simple data container
for a training sample in a model. The dataclass decorator adds all of the utility functions we may want (including
a pretty string reprsentation so we can print the object), and the type annotations make it clear what the user 
should expect the fields to contain.</em></p><h2> Use <em>pyenv</em> to manage Python versions</h2>
<p>
For better or worse, many incompatible versions of Python now exist, and it's easy to get
in a tangle with different Python installs, especially when making system-wide changes.
</p>
<p>
My advice here is to do it properly, and do it once: learn to use <em>pyenv</em> to manage all of your Python
installs.
</p>
<p>
Pyenv is a tool that provides a shim around the <em>python</em> command which redirects it to the correct version 
of Python for the current context. For a given project, you can use <em>pyenv local 3.7.5</em> in a directory
to tell pyenv to use Python 3.7.5 from now on when calling Python in that directory.
</p>
<p>
If you don't have the version of Python installed that you need, you can use pyenv to install it.
If the universe is feeling good to you today, <em>pyenv install 3.7.5</em> should be sufficient to fetch and install Python 3.7.5
for you automatically on any platform.
</p>
<p>
<strong>In practice</strong>, things don't always go so smoothly with pyenv, however I really believe
it's really worth the hassle of spending the time and getting it working - most issues you might enouncter are well understood, and documented on stackoverflow.
</p>
<h3>A few common tips for common pyenv issues</h3>
<ul>
<li><strong>It's not working!</strong> - make sure you have activated it (google "pyenv activate"). Typically you need to add this to e.g. your .bashrc</li>
<li><strong><em>pyenv install</em> failed!</strong> - you may be missing system dependencies. Be patient, and trawl stackoverflow. It can be made to work!</li>
</ul>


<h2>Use <em>poetry</em> to manage your project and dependencies</h2> 
<p>
Keeping your Python project sandboxed is crucial aspect of remaining sane when using Python.
We typically use <em>virtualenvs</em>, or virtual environments, to achieve this. These are are essentially directories containing their own
Python install, and a local copy of all the packages your project needs. 
</p>
<p>
A separate but related problem is ensuring you actually <em>have</em> the dependencies your project needs
installed into that virtualenv. 
</p>
<p>
Once upon a time, you may have used `virtualenv` and `requirements.txt` or `anaconda` or `pipenv` to do these things.
</p>
<p>
Well, my advice is <strong>steer clear from all of them</strong> and move straight to <a href="https://python-poetry.org/">poetry</a>.
It's very much the new kid on the block, but from my perspective it's already miles ahead of the competition.
I have managed to deploy a number of complex Python applications in a professional capacity using
poetry, and I have found it both plays very well with other tools and is generally well designed.
</p>
<p>
Poetry uses the modern <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">pyproject.toml</a> way of defining a package, and this essentially replaces the old setup.py and friends.
It would be out of scope to explain why pyproject.toml is important and worth learning about, so I recommend some googling here!
</p>
<p>
Ok, so let's create a new project! ... don't forget to `pyenv local 3.7.5` first, to ensure you are using the correct version of Python (if you forgot, you can run it later, and then go
back and edit pyproject.toml to make sure it's set correctly.)
</p>

<p>
Yes, it's as easy as that. Go ahead and move in the directory poetry created for you, and you can now
</p>
<p>
and poetry will automatically create a managed virtualenv for you. Let's now install some of the tools of our trade,
</p><div><pre><code data-lang="bash">$ poetry add torch
$ poetry add numpy</code></pre></div>
<p>
Poetry will install them to the virtualenv and add them to the pyproject.toml. It will 
also <strong>pin</strong> the exact versions of the dependencies into a lock file so that <strong>other users installing your package
can reproduce precisely the same environment as you</strong>. This is perhaps the most important step here, and is worth underscoring:
this is how we are able to achieve <em>reproducibility</em>. 
</p>
<h3>The Best Bit About Poetry</h3>
<p>
Poetry was designed to be good at both developing packages and <em>building/sharing/publishing</em> them.
These latter features are sorely missing from other tools (such as pyenv), and they are really the killer
feature of poetry.
</p>
<p>
Let's suppose you pushed your <em>fancynet</em> package to github (don't forget to check in the lock file!).
Now, <strong>anyone using a recent version of pip can install your package with a single command</strong>,
</p><div><pre><code data-lang="bash">$ pip install git+https://github.com/myusername/fancynet</code></pre></div>
<p>
Pip will fetch the code from github, look into the pyproject.toml, see it uses poetry, and then just do
everything for you, including installing poetry, and fetching the correct versions of the pinned dependencies!
<strong>
This is totally magic and not enough people know this trick.</strong> Go forth and spread this knowledge!
</p>
<p>
If your package reaches a level of maturity where you'd like to publish it to a public package repository (e.g. pypi),
you can use poetry to manage this. To bump the version (you can also bump the minor and major versions this way), use
</p><p>
Then to build and publish to pypi, use
</p><div><pre><code data-lang="bash">$ poetry build
$ poetry publish</code></pre></div><p>
The defaults used by poetry are spookily well designed, and I have never had any problems publishing packages in this way.
</p>

<h2>Use <em>click</em> to manage your entrypoint</h2> 
<p>
An oft-overlooked step in building a good python package is organising the files and "entrypoints" (or "executables"). 
I believe it's worth imagining that someone else is going to use your code at somepoint, and so I try to create nicely named
subdirectories for each part of my model: "datasets", "models", "inference", but also <strong>"cli"</strong>.
In this "cli" directory, I usually have several subdirectories "train", "tune", "test". Each of these contains a single
"__main__.py", which contains the (small!) shim code needed to perform those actions.
</p>
<p>
Inside "__main__.py" I then use <a href="https://click.palletsprojects.com/en/7.x/">click</a> to manage arguments and the entrypoint.
I have found it much easier to use than argparse, and I do think it's worth the effort!
</p>
<div><pre><code data-lang="python"><span>import</span> click
<span>from</span> omegaconf <span>import</span> OmegaConf
<span>from</span> pytorch_lightning <span>import</span> Trainer

<span>from</span> mynet.models <span>import</span> MyNet

<span>@click.command</span>()
<span>@click.option</span>(<span>'--dataset-root-dir'</span>, help<span>=</span><span>'directory containing the dataset'</span>)
<span>@click.option</span>(<span>'--config-path'</span>, default<span>=</span><span>"config.yaml"</span>, help<span>=</span><span>'The config file to use.'</span>)
<span>def</span> <span>train</span>(dataset_root_dir: str, config_path: str):
    cfg <span>=</span> OmegaConf<span>.</span>load(config_path)

    model <span>=</span> MyNet(cfg)
    trainer <span>=</span> Trainer(gpus<span>=</span><span>1</span>, profiler<span>=</span>True)
    trainer<span>.</span>fit(model)

<span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    train()</code></pre></div>
<p>
Now, if we are developing locally, we can run this using
</p><div><pre><code data-lang="bash">$ poetry run python -m mynet.cli.train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
Which is fine and good, but if we want to go 10X, we can also use a neat future of project.toml and add an entrypoint
</p><div><pre><code data-lang="toml">[<span>tool</span>.<span>poetry</span>.<span>scripts</span>]
<span>train</span> = <span>"mynet.cli.train.__main__:train"</span></code></pre></div><p>
Once we do this, users can run training using
</p><div><pre><code data-lang="bash">$ poetry run train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
or if you "activate" the environment, simply
</p><div><pre><code data-lang="bash">$ train --dataset-root-dir /foo/bar/baz</code></pre></div>

<p>
It's possible to add multiple entrypoints to the pyproject.toml, so you can easily create one for training, tuning, testing.
This is helpful for users trying to discover how to train or evaluate your model from scratch!
</p>
<p>
Do note that if a user installs your package into a shared virtualenv, you may wish to choose a more meaningful name than train!
</p>

<h2>Use <em>pytorch</em> to develop your net</h2>
<p></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rosshemsley.co.uk/posts/deep_learning_toolchain/">https://rosshemsley.co.uk/posts/deep_learning_toolchain/</a></em></p>]]>
            </description>
            <link>https://rosshemsley.co.uk/posts/deep_learning_toolchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649488</guid>
            <pubDate>Thu, 01 Oct 2020 10:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I’m pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we’re releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We’ve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We’ve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it’s not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We’ve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You’ll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We’ve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won’t start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn’t affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We’ve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We’ve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We’ve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We’ve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn’t a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially “on the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we’re going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We’re going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let’s jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they’re all different ways to amplify your content, and we’ll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it’ll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you’ve created, but that’s a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it’s not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“You’ve written an amazing article – and now what? You can’t expect the results to happen without some distribution work on your end. This includes content amplification – a multi-channel approach to increase your brand’s reach. It’s taking your owned media, and combining it with paid and earned media. It’s really knowing the right places – and people – to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you’re able to extend your reach into new areas you couldn’t achieve on your own through organic methods. It’s getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn’t have necessarily heard of you otherwise. Amplification done right brings customers to you who didn’t yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that’s a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It’s wonderful. If you’re getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You’ve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that’s not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it’s a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We’re not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don’t have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“Imagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google’s search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).”</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That’s right. All that time you spent researching, planning, creating and publishing content is less than half of what’s required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let’s not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it’s easy …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Proposed Standard to ensure secure time on the Internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649121">thread link</a>) | @fogihujy
<br/>
October 1, 2020 | https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet | <a href="https://web.archive.org/web/*/https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                  
                
            <p>Stockholm, Sweden - 1 October 2020 - The Proposed Standard for Network Time Security (NTS) has today been published by the IETF as RFC8915. This comes at the end of a five year development process. As one of the leading figures in NTS, Netnod has worked on all stages of NTS development from the IETF standard to software and hardware implementations at client and server levels. The publication of the NTS Proposed Standard as an RFC marks an important milestone in the development of secure time on the Internet.&nbsp;</p>
      
        
            <div><p><span><span><span><span><span><span><span>The current standard for receiving time information over the internet, the Network Time Protocol (NTP), was created in 1985</span></span></span></span></span></span></span><span><span><span><span><span><span>. Over the last 35 years, a number of issues as well as some high-profile attacks have shown that NTP needs an increased level of security. The new Network Time Security (NTS) standard has been designed to fix that.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>NTS uses modern cryptography to add an essential layer of security to NTP. It prevents a range of security vulnerabilities including amplification attacks, packet manipulation, and replay attacks. The protection against packet manipulation and replay attacks secures NTP against Man-in-the-Middle (MITM) attacks. MITM attacks are used by malicious actors to sit between the client and the NTP server, forge messages and lie about time. Since many processes are dependent on accurate time, the consequences here are very serious. </span></span></span></span></span></span><span><span><span><span><span><span><span>Everything from establishing encrypted sessions and using DNSSEC to time-stamping financial transactions and preventing online fraud depends on accurate and secure time.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>In March 2015, the first Internet-Draft of the NTS standard was published by the NTP working group in the IETF. Over the next 5 years, the draft went through 28 further iterations until </span></span></span></span></span></span><a href="https://datatracker.ietf.org/doc/draft-ietf-ntp-using-nts-for-ntp/" target="_blank"><span><span><span><span><span><span><span><span>the Internet Draft ‘Network Time Security for the Network Time Protocol’ </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>was approved as a Proposed Standard in March 2020. Following some time in the RFC editor queue and final approval from the authors, </span></span></span></span></span></span><a href="https://www.rfc-editor.org/info/rfc8915" target="_blank"><span><span><span><span><span><span><span><span>the RFC proper </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>has today been published.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>“The publication of </span></span></span></span></span></span><span><span><span><span><span><span><span>RFC8915 is an important moment both for the development of NTS</span></span></span></span></span></span></span><span><span><span><span><span><span> and for security on the Internet in general,” said Lars Michael Jogbäck, Netnod CEO. “Netnod is proud to have been at the forefront of developing the NTS standard and implementations. We will continue to focus on services such as NTS to make the Internet as secure and robust as possible for everyone.”</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides NTP, NTS and Precision Time Protocol (PTP) services offering a robust, reliable and highly accurate source for time and frequency traceable to official Swedish time UTC(SP). Netnod’s time service, funded by the Swedish Post and Telecom Authority (PTS), uses a distributed timescale on multiple, autonomous sites throughout Sweden to provide a time service available over IPv4 and IPv6. Each site has full redundancy: multiple servers, caesium clocks, and FPGA boards provide an extremely fast hardware implementation of NTP. The service is available to the general public worldwide for free on ntp.se, which resolves to anycast IPv4 and IPv6 addresses. The NTS-enabled service is available at: nts.ntp.se. More information about Netnod’s NTS service is available </span></span></span></span></span></span><a href="https://www.netnod.se/time-and-frequency/network-time-security"><span><span><span><span><span><span><span><span>here</span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>. </span></span></span></span></span></span><span><span><span><span><span><span><span>&nbsp;</span></span></span></span></span></span></span></p>
<p><span><span><span><strong><span><span>About Netnod</span></span></strong></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides critical infrastructure support ranging from interconnection services and Internet Exchanges to DNS services, root server operations, and time and frequency services. With a worldwide reputation for its services and the expertise of its staff, Netnod ensures a stable and secure Internet for the Nordics and beyond.Established in 1996 as a neutral and independent Internet infrastructure organisation, Netnod is fully owned by the non-profit foundation TU-stiftelsen (Stiftelsen för Telematikens utveckling). More information is available at:</span></span></span></span></span></span><a href="http://www.netnod.se/"><span><span><span><span><span><span><span><span> www.netnod.se</span></span></span></span></span></span></span></span></a></p>
</div>
      
        

      </div></div>]]>
            </description>
            <link>https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649121</guid>
            <pubDate>Thu, 01 Oct 2020 09:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot…&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don’t rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don’t share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‘attack surface’. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations’ control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>“ Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ”<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic—that is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren’t secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don’t know how many needles might be in the haystack. In the case of secrets detection, you don’t even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: «What is the percentage of the secrets that you detect that are actual secrets?». This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don’t miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn’t put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>“DevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.”<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers’ workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It’s used to inspect the snapshot that’s about to be committed, to see if you’ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don’t pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system – you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can’t stop the push process, but the client doesn’t disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer’s workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers’ responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>“You could compare the brain, as it were, to a large string orchestra”, explains fellow researcher Hisse Arnts.  “With Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‘pianissimo’, so that everyone back within time. “</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard’s situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;0b31947a-bc9d-4a4c-a578-89e12878edc8&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto: Peter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charité University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I’m a bit of a guinea pig," he says. "There aren’t many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you’re dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn’t afraid. And I’m not afraid! When my hands shake, it’s not from fear – it’s from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn’t want to answer. "That’s Germany’s business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-b3693e18-823c-4442-8363-e28508cb6714" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-b3693e18-823c-4442-8363-e28508cb6714">Icon: Der Spiegel</title><g id="l-s-flag-b3693e18-823c-4442-8363-e28508cb6714"><path id="vector-b3693e18-823c-4442-8363-e28508cb6714" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checking Out Quest DB]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648455">thread link</a>) | @asafg6
<br/>
October 1, 2020 | https://www.turtle-techies.com/checking-out-quest-db/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/checking-out-quest-db/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                
                <h4>We decided to check out Quest DB, an open-source Time Series database</h4>
                        <h6>
                            By Suresh Regmi, Published 2020-08-31
                        </h6>
            </p><div itemprop="articleBody"><h2 id="what-is-quest-db">What is Quest DB?</h2>
<p>QuestDB is an open-source Time Series database that uses a column-oriented storage approach and vectored execution for simple and extremely quick query execution.<br>
It was developed by QuestDB Limited in 2014.<br>
It is written in Java and supports Linux, macOS and Windows as the server operating system.<br>
The query language utilized for QuestDB is SQL (Structured Query Language) alongside its expansion for time series-analysis.<br>
QuestDB depends on the relational data model, normally found in some of the popular relational databases like PostgreSQL, MySQL, SQL Server, Oracle, and so forth which means that each time-series estimation is recorded in its row, with a time field followed by other fields.</p>
<h2 id="features">Features</h2>
<p>Some of the best features of QuestDB are as follows.</p>
<ul>
<li>Time series database with a relational data model.</li>
<li>SIMD optimized analytics</li>
<li>Uses column-oriented storage technologies with each column stored continuously in sequential blocks</li>
<li>It allows columns to be chosen as a designated timestamp to utilize it’s high-performance time series functions</li>
<li>Comes with a built-in SQL optimizer</li>
<li>InfluxDB line and Postgres wire protocol support</li>
<li>Supports time series and relational joins</li>
<li>It supports horizontal partitioning (by timestamps)</li>
<li>Supports ACID</li>
</ul>
<p>The setting up of QuestDB can be done easily by following the <a href="https://questdb.io/docs/introduction/" target="_blank">QuestDB documentation</a><a>.<br>
It runs on port 9000 (by default) and provides a web console to interact with the database. The web console has a schema/table browser, query tool and visualization window where the query results can be shown either in tabular form or using graphs.</a></p><a>
<p>Here is how the web console looks like:</p>
</a><p><a></a><a href="https://www.turtle-techies.com/checking-out-quest-db/image1.png" target="_blank"><img src="https://www.turtle-techies.com/checking-out-quest-db/image1.png" alt="QuestDB web console"></a></p>
<h2 id="how-to-setup-questdb">How to setup QuestDB</h2>
<p>If like me, you want to setup QuestDB for learning or for a development environment, I would recommend using Docker.
Here are the instructions I used:
<a href="https://questdb.io/docs/packages/docker/" target="_blank"> </a><a href="https://questdb.io/docs/packages/docker/">https://questdb.io/docs/packages/docker/</a> </p>
<p>Your other options are:</p>
<ol>
<li>
<p>Using binaries:
For setting up QuestDB using binaries, you can refer to QuestDB's documentation <a href="https://questdb.io/docs/packages/binaries/" target="_blank"> </a><a href="https://questdb.io/docs/packages/binaries/">https://questdb.io/docs/packages/binaries/</a> .</p>
</li>
<li>
<p>Homebrew:
For macOS users, QuestDB is available via Homebrew <a href="https://questdb.io/docs/packages/homebrew/"> </a><a href="https://questdb.io/docs/packages/homebrew/">https://questdb.io/docs/packages/homebrew/</a> .</p>
</li>
</ol>
<h2 id="why-should-you-choose-questdb">Why should you choose QuestDB?</h2>
<p>The one thing I like most about QuestDB is that despite the fact that its engineering is planned from the ground up to be close to the hardware.
It offers advanced execution and is additionally centered around making it simpler for designers to integrate and query.</p>
<p>Following are the reasons you should choose QuestDB</p>
<h3 id="easy-to-set-up-and-use">Easy to set up and use</h3>
<p>QuestDB is a lightweight open-source database and is anything but difficult to set up without any conditions.
It will take just a couple of minutes to download and you can begin playing with it.
Its official website provides detailed technical documentation which makes installation, configuration and running the database very simple.
Its web console enables us to perform real-time analytics with easy visualization using different types of charts like bar, line area etc.</p>
<h3 id="supports-sql">Supports SQL</h3>
<p>One reason for utilizing QuestDB is its SQL-like query language.
On the off chance that you know about SQL, utilizing QuestDB would be simpler as it depends on SQL with its very time-series alterations.</p>
<h3 id="performance">Performance</h3>
<p>Execution is one of the fundamental rules that ought to be thought of while picking the database.
QuestDB offers better execution while managing time-series data like data from IoT gadgets, stock value information and DevOps measurements.
For a database that is new in the TSDB field, it gives seemingly preferable execution over other entrenched time-series databases.</p>
<h2 id="why-questdb-is-not-a-good-choice">Why QuestDB is not a good choice?</h2>
<h3 id="new-to-the-tsdb-ecosystem">New to the TSDB ecosystem</h3>
<p>QuestDB is a less mature product than other time-series databases like TimescaleDB and InfluxDB, which implies that there are a ton of integrations and features that are yet to be worked from the developers’ side.
So if you are searching for a well established time-series database with an extraordinary help network and discussion, QuestDB isn't there yet.</p>
<h3 id="oltp-support">OLTP Support</h3>
<p>OLTP databases require frequent inserts, updates, and deletes with user-defined constraints to be kept up.
If you are intending to utilize a database that likewise supports Online Transaction Processing, QuestDB is not a solid match.</p>
<h2 id="how-does-it-compare-with-other-databases">How does it compare with other databases?</h2>
<h3 id="questdb-vs-sql-databases">QuestDB vs SQL Databases</h3>
<p>QuestDB is like a SQL database (MySQL, Oracle, PostgreSQL) however unique from multiple points of view.<br>
Other relational databases can also handle time-series data but they tend to offer worse performance while dealing with common time-series operations like real-time aggregations of data.</p>
<p>On the other hand, QuestDB is purpose-built for fast storage and processing of time series data.
The data model followed by QuestDB is a relational data model which means that data is stored in a table and each row in a table represents a collection of related values.
It also follows the ACID property and supports joins like relational databases but does not allow user-defined constraints and triggers.</p>
<h3 id="alternatives-to-questdb">Alternatives to QuestDB</h3>
<p>Some of the best alternatives to QuestDB are as follows</p>
<h4 id="influxdb">InfluxDB</h4>
<p>InfluxDB is an open-source time-series database designed for high-availability storage and retrieval of data.<br>
It is a part of the TICK (Telegraf, InfluxDB, Chronograf, Kapacitor) stack and has a non-relational, NoSQL data model. It has SQL-like query language to handle interactions with the data</p>
<h4 id="timescaledb">TimescaleDB</h4>
<p>Built on the top of the Postgres database, TImescaleDB is optimized for fast ingest and complex queries with full SQL support like traditional relational databases.</p>
<h5 id="kdb">KDB+</h5>
<p>KDB+ is also a high performance column-store relational time-series database with in-memory abilities.<br>
It is commonly used to store, analyze and process high-frequency financial time series data.</p>
<p>I hope you enjoyed, and of course as always, feel free to comment or share.<br>
Thank you for reading.</p>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/checking-out-quest-db/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648455</guid>
            <pubDate>Thu, 01 Oct 2020 07:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that …</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">Žan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {🚀} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet 👨‍🎓</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way …</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Elucidating Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648046">thread link</a>) | @Topolomancer
<br/>
September 30, 2020 | https://bastian.rieck.me/blog/posts/2020/elucidating_examples/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/elucidating_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I tend to learn new concepts best by seeing an <em>example</em> of them. This
dates back to when I first started studying mathematics: I felt that I
was able to actually <em>work</em> with a certain definition once I had at
least an intuitive grasp of what is meant. I quickly discovered that
there are at least three kinds of examples. The first kind is trivial,
leading to even more confusion, the second kind is too complex, and the
third kind is actually elucidating. It is the third kind of example that
I am primarily interested in here, so let’s quickly discuss the other
two and move on.</p>
<p>Examples of the first kind are trivial. Suppose you want to illustrate
the concept of addition and state that $1 + 0 = 1$. This is obviously
correct but does not teach you anything because it contains the idea
that $a + 0 = a$ as a <em>confounding property</em>. Likewise, mentioning the
empty set $\emptyset$ as an example of a certain kind of structure is
always good for some laughs,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> but it does not really help you
understand what is going on.</p>
<p>Examples of the second kind are not more helpful. They are characterised
by a rapid increase in complexity that just bogs you down without really
helping you gain intuition or understanding. <a href="https://abstrusegoose.com/474">This Abstruse Goose comic</a>
provides a marvellous instance.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Other examples include, say, teaching
you about <a href="https://en.wikipedia.org/wiki/Determinant">determinants</a> by
letting you invert a $10 \times 10$ matrix, when a smaller dimension
would have been sufficient.</p>
<p>Examples of the third kind help you grow and understand. I call these
examples <em>minimum elucidating examples</em>: they have <em>just</em> the right
amount of complexity to not be wholly trivial, but they are simple
enough to be remembered and understood correctly. For instance, when
learning about group theory, some elucidating examples are the additive
group over the integers, $\mathbb{Z}/2\mathbb{Z}$&nbsp;(the group with
only two elements), or, to be a little bit more complex, the general
linear group of all real invertible matrices. The utility of such an
elucidating example depends heavily on the context—as a student,
I preferred learning about the ‘number groups’ first, but nowadays, my preferred
go-to example is the general linear group, because it is more
abstract and provides a better glimpse into the power of group theory.</p>
<p>Closely related to such elucidating examples are elucidating
<em>non-examples</em>&nbsp;(or counterexamples). In group theory, the natural
numbers $\mathbb{N}$ come to mind: lacking an additive
inverse for every element except $0$, every student can easily grasp
that the additional requirements raise the bar for something to be
called a group, while at the same time illustrating that a much richer
structure is exposed by demanding these properties.</p>
<p>Of particular pedagogical interest are examples that <em>defy</em> our
presuppositions. These are counterexamples to our misplaced intuitions!
For instance, the <a href="https://en.wikipedia.org/wiki/Cantor_set">Cantor set</a>
is a marvellous counterexample in measure theory:<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> typically,
students only encounter sets with measure zero that are <em>countable</em>.
This can lead to the wrong impression that ‘measure zero’ and
‘countable’ are somewhat equivalent. The Cantor set destroys this
illusion, as it constitutes a set that is <em>uncountable</em> while having
measure zero! My mind was shattered when I first learned about this, and
since then, the Cantor set has been a cherished counterexample in my
toolbox.</p>
<p>Having switched academic fields for a while now, I sometimes wonder what
minimum elucidating examples <em>we</em> should develop for machine
learning&nbsp;(ML).  What is the smallest useful architecture and data set that demonstrates
issues such as <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">vanishing gradients</a>?
Is there a way to store and disseminate such counterexamples? Would the
aspiring ML researcher find them useful and digest them, or are we still
in the ‘pragmatic phase’ of our field and use whatever works, without
caring too much about the theoretical underpinnings? Time will
tell—and I for one hope to collect as many juicy minimum elucidating
(counter)examples as I possibly can.</p>
<p>Until next time, have fun being exemplary!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Full disclosure: as a cheeky undergraduate, I did this a few times
in oral exams. It is funny but probably less so for the professors who
have to endure that sort of humour all day long. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I disagree with the comic on one thing, though: maths textbooks
tend to follow this recipe more often than computer science textbooks,
in my experience. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Measure theory deals with <em>measuring</em> subsets of Euclidean space,
assigning them a number that describes their ‘size’; think of a generalisation of
the concepts of <em>area</em> or <em>volume</em>. Measure theory is often invoked
when dealing with problematic solutions or inputs to
functions—essentially, one tries to show that while such degenerate
inputs may exist, they are ‘too small’&nbsp;(in the sense of measure
theory) to worry about. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/elucidating_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648046</guid>
            <pubDate>Thu, 01 Oct 2020 06:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here’s a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn’t be smart to blindly apply the same set of software development best-practices for all three cases. You probably don’t need a perfectly polished code for a single-use report. A startup that operates in the “rush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you’re working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it’s not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we’ve all heard stories where things went wrong because of misaligned goals. “Premature optimization” is a common special case. Refactoring an old codebase that rarely changes, just so it’s pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You’ve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don’t know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that’s familiar often gets selected over the tool that fits. Don’t think this advice only applies to „macro“ decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It’s impossible to keep up with the pace modern tech is moving. Doesn’t matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It’s an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn’t take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a „wrapper“ to expose their work to the outside world through some kind of API (i don’t mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that’s too „technical“, i.e. leaking it’s abstractions to the consumer. It’s hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user’s most common usage pattern? What’s the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It’s up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that’s easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of „moving parts“ you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The „small enough“ parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you’ll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn’t stay in “kinda-finished” state for long (“finished but not deployed”, “finished but not reviewed”, “finished but not tested” or “finished but waiting for authorization from XYZ department”). Finished is when you don’t think about it anymore and it doesn’t drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer’s work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 5 days ago</small>
                            <span>|</span>
                <small>Updated 4 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! 😉</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Literal String Matching in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647210">thread link</a>) | @boyter
<br/>
September 30, 2020 | https://boyter.org/posts/faster-literal-string-matching-in-go/ | <a href="https://web.archive.org/web/*/https://boyter.org/posts/faster-literal-string-matching-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>TL/DR:</strong> I wrote a fast literal string matching library in Go get it here <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a></p>
<p>Recently I rebuilt <a href="https://searchcode.com/">searchcode</a> in Go, as <a href="https://boyter.org/posts/searchcode-rebuilt-with-go/">mentioned</a>.</p>
<p>While there was a variety of reasons for this one was that performance in the previous Python version was not great. Please note this was mostly due to my own shortcomings and not the language itself. However I have always used searchcode as a test bed for interesting problems, since it gets enough traffic to verify things at scale, and I wanted to get better at Go.</p>
<p>One of the main performance hotspots in searchcode has always been finding lines to display based on the search query and then highlighting them. While most search index tools can do this for you, I have always done this myself, because I want to control whats displayed as I find it an interesting problem to solve.</p>
<p>It sounds simple, for some search terms “sally sea shell” find all the locations of inside a string “Sally sells sea shells by the sea shore” and then wrap them in a tag. This seems to be a trivial, since all you need a <code>indexOf</code> in a loop and some string splitting and insertion.</p>
<p>I had previously written about some of the issues with the above when writing about <a href="https://boyter.org/posts/unicode-support-what-does-that-actually-mean/">unicode support</a> with the relevant portion below,</p>
<blockquote>
<p>At which point you go, fine i’ll just search for all case variants of Java and use that to work things out, and then realise adding case folding is a small addition to what you just wrote and working with just bytes to save time was a red-herring.</p>
</blockquote>
<p>The generally always correct answer to case insensitive matching is to use Regular Expressions. However there can be issues with it. Firstly the regular expression engine in Go is slower than you think, and for matching string literals its a very large hammer for a smallish nail.</p>
<p>So I wrote my own implementation which does the same thing but without touching the regular expression engine <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a> thus making it much faster than using FindAllIndex for the majority of cases.</p>
<p>Talk is cheap… show me the benchmarks. Included below is the output from a small application I wrote. A small program which you supply a search string and a filename. I have tested it against a 550MB file. First it runs case insensitive search using FindAllIndex in the regex package, then against IndexAllIgnoreCase my own implementation. The number on the end of each line is the number of matches found.</p>
<pre><code>$ ./csperf ſecret 550MB
File length 576683100

FindAllIndex (regex ignore case)
Scan took 25.403231773s 16680
Scan took 25.39742299s 16680
Scan took 25.227218738s 16680

IndexAllIgnoreCase (custom)
Scan took 2.04013314s 16680
Scan took 2.019360935s 16680
Scan took 1.996732171s 16680
</code></pre><p>Note using the long s, <code>ſ</code> in the search term so both solutions are unicode aware!</p>
<p>The results speak for themselves. The case insensitive search is considerably faster. For pure literal case insensitive searches based on wall clock time it can be 10 times faster. I also added an implementation of <code>IndexAll</code> for case sensitive matches saving you from having to do your own logic there or again falling back to regular expressions, although its speedup will depend on your needle and haystack.</p>
<p>If you are curious about I did this read on. Otherwise feel free to just suck down the library and use it. It’s published under either MIT or The Unlicense so be as liberated as I can make it. There is also some other useful functions in there such as the highlight function which I am not going to discuss here.</p>
<p><strong>So how does it work?</strong></p>
<p>The code itself is reasonably <a href="https://github.com/boyter/go-string/blob/master/index.go#L98">well commented</a> so you may want to just read the code.</p>
<p>In short it copies some techniques from tools like ripgrep.</p>
<p>When looking at string matching algorithms, you run into algorithms such as Boyer-Moore, Aho-Corasick and Rabin-Carp. It may then surprise you to learn that Go’s implementation of strings.Index does not use them, well at least not till the needle is over 64 characters when 64 bit compiled where it starts to use Rabin-Carp, presumably as a CPU cache line optimisation.</p>
<p>What strings.Index actually does a simple loop through each byte checking for a match, and then when one is found starts checking against the needle. This means it does not do any byte skipping which Boyer-Moore does! Naturally, I was appalled by this and looked for a Boyer-Moore implementation to swap it out for. Turns out there is one inside the Go codebase which made me very curious. Why was it not used? Well after trying a few implementations each turned out to be much slower than the simple one Go uses. As it turns out, that implementation compiles down to fancy vector instructions on modern CPU’s. It’s pretty hard to beat silicon with algorithms, unless you algorithm happens to be massively more efficient so there was no trivial gains to be made there with a fancy algorithm.</p>
<p>So what actually happens in the code is that it takes the needle, and uses the first 3 characters (if over 3 characters long) to create a string of every possible case. So <code>foo</code> would return the following strings <code>foo Foo fOo FOo foO FoO fOO FOO</code>. It then searches using each one of those cases and collecting all the resulting matching locations. For strings over 3 characters (note characters, not bytes so it is unicode aware for simple case fold rules), as mentioned the first 3 characters are used, and then when a possible match is found the rest of the characters are checked to see if there is actually a match before recording the location.</p>
<p>In theory Aho-Corasick would be faster than the above as you could use maybe the first 4 characters and use that for matching each byte, however I was not going for extreme performance, but something much faster than regular expressions. Also its reasonably simple to follow, while leveraging the Go SDK which is a massive win in my opinion.</p>
<p>The result is currently running in searchcode. This replaces what was the slowest portion of the code in the old version of searchcode and is much faster reducing the load on the servers considerably. Every string runs through the implementation and as such its fairly battle tested. It might not be perfect, but there has been no crashes to date with the v1.0.0 tag release so it should be reasonably safe to use, but of course there is no warranty. As mentioned a few times the code is open and on github, so feel free to bash against it <a href="https://github.com/boyter/go-string">https://github.com/boyter/go-string</a> and report bugs! If you do run into an interesting case where you use it let me know and ill add it to the README.</p>

</div></div>]]>
            </description>
            <link>https://boyter.org/posts/faster-literal-string-matching-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647210</guid>
            <pubDate>Thu, 01 Oct 2020 03:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn’t. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i’ve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i’ve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73ºC</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn’t seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn’t really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I’ve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67ºC</code>.</li>
</ul>
</li>
</ul>
<p>That’s a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It’s a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn’t even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i’m seriously thinking on ditching this software and using it’s web version only. Firefox is a software I already use so, there’s nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mouth Dreams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646471">thread link</a>) | @bangonkeyboard
<br/>
September 30, 2020 | http://www.neilcic.com/mouthdreams/ | <a href="https://web.archive.org/web/*/http://www.neilcic.com/mouthdreams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.neilcic.com/mouthdreams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646471</guid>
            <pubDate>Thu, 01 Oct 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here’s What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrkšić</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here’s a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p>As far as we’re aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I’m incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we’d say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller’s request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant — Siri or Alexa, for example — to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel’s individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‘AI system for accomplishing real-world tasks over the phone’. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I’ll be the first to point out how incredible Google’s TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human – it does mention that it’s an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you’ll hear our voice assistant ask the caller when they’d like to come in, and Duplex speaks over it. In reality, these are machines – no-one’s getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it’s practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley – but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we’ll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary “Dr Livingstone, I presume” moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned – and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design (2010)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this “classical” picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman’s approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today’s science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth’s surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn’t cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges—for example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth’s entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer—us—from our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception—and hence the observations upon which our theories are based—is not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck’s constant. That’s a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don’t usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell’s equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That’s not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don’t have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn’t.</li><li>What makes this universe interesting is that although the fundamental “physics” of this universe is simple, the “chemistry” can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as …</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
    </channel>
</rss>
